dataset,encounter_id,dialogue,note
ami_abstractive_summary,Bed013.txt,"B: almost forgot about the meeting . woke up twenty minutes ago , thinking , what did forget ?
D: it 's great how the br brain does that .
E: something 's not right here .
D: so the news for me is , my forthcoming travel plans in two weeks from today ? more or less ? 'll be off to sicily and germany for couple , three days .
B: now what are what are you doing there ?
D: 'm flying to sicily to drop off simon there with his grandparents . and then 'm flying to germany to go to moku - treffen which is the meeting of all the module - responsible people in smartkom , and , represent ici and myself there . that 's the mmm actual reason . and then 'm also going up to eml for day , and then 'm going to meet the very big boss , wolfgang walster , in saarbruecken and the system system integration people in kaiserslautern and then 'm flying back via sicily pick up my son come back here on the fourth of july .
E: what great time to be coming back to the
B: god bless america .
E: you 'll see maybe see the fireworks from your plane coming in .
D: and 'm all the people at the airport will be happy to work on that day .
E: you 'll get even better service than usual .
B: aren't you flying on lufthansa though ? then the , it 's not big deal . once you get to the united states it 'll be problem ,
D: that 's that bit of news , and the other bit of news is we had , , was visited by my german project manager who , did like what we did what we 're doing here , and , is planning to come here either three weeks in july or three weeks in august , to actually work . and we sat around and we talked and he came up we came up with pretty strange idea . and that 's what 'm gonna lay on you now . and , maybe it might be ultimately the most interesting thing for eva because she has been known to complain about the fact that the we do here is not weird enough . so this is so weird it should even make you happy . imagine if you will , that we have system that does all that understanding that we want it to do based on utterances . it should be possible to make that system produce questions . so if you have the knowledge of how to interpret "" where is ? "" under given conditions , situational , user , discourse and ontological conditions , you should also be able to make that same system ask "" where is ? "" in sper certain way , based on certain intentions . so in instead of just being able to observe phenomenon , , and , the intention we might be able just to give it an intention , and make it produce an utterance .
B: like in ai they generally do the take in , and then they also do the generation phase , like nancy 's thing . you remember , in the hand thing in one - eighty - two , like not only was it able to recognize but it was also to generate based upon situations . you mean that thing ?
D: and once you 've done that what we can do is have the system ask itself . understand the answer , ask something else , and enter dialogue with itself . so the ba basic the same idea as having two chess computers play against each other .
E: except this smacks little bit more of schizophrenic computer than ai .
D: you if you want , you can have two parallel machines , asking each other . what would that give us ? would be something completely weird and strange , and , if you look the factors , we will never observe people let 's say , in wheelchairs under , in under all conditions ,
E: that 's good .
D: when they say "" "" , and there is ride at the goal , and the parking is good , we can never collect enough data . it 's it 's not possible .
E: right , right .
D: but maybe one could do some learning . if you get the system to speak to itself , you may find break downs and errors and you may be able to learn . and make it more robust , maybe learn new things . so there 's no end of potential things one could get out of it , if that works . and he would like to actually work on that with us .
B: then , he probably should be coming back year from now .
D: see the generation bit , making the system generate something , is shouldn't be too hard .
B: once the system understands things . don't think we 're probably year away from getting the system to understand things .
D: , if we can get it to understand one thing , like our "" where is "" run through we can also , maybe , make it say , or ask "" where is ? "" or not .
E: 'm have the impression that getting it to say the right thing in the right circumstances is much more difficult than getting it to understand something given the circumstances and so on , just cuz it 's harder to learn to speak correctly in foreign language , rather than learning to understand it . right ? just the fact that we 'll get that getting it to understand one construction doesn't mean that it will always know exactly when it 's correct to use that construction . right ?
D: it 's it 's 've 've done generation and language production research for fo four and half years . and so it 's you 're right , it 's not the same as the understanding . it 's in some ways easier and some ways harder . nuh ? it 'd be fun to look at it , or into that question . it 's pretty strange idea . and so that 's but
B: the basic idea would be to give allow the system to have intentions , ? cuz that 's what needs to be added to the system for it .
D: eee , even think even what it would be the prior intention . so let 's , let 's say we have this
B: we 'd have to seed that ,
D: no . let 's we have to we have some top - down processing , given certain setting . now we change nothing , and just say ask something . what would it ask ?
B: it wouldn't to ask . unless it was in situation . we 'd have to set up situation where , it didn't know where something was and it wanted to go there . which means that we 'd need to set up an intention inside of the system . right ? which is , "" where something is and need to go there "" .
D: do we really need to do that ? it 's 's it 's strange , but look at it look at our bayes - net . if we don't have let 's assume we don't have any input from the language . right ? so there 's also nothing we could query the ontology , but we have certain user setting . if you just ask , what is the likelihood of that person wanting to enter some something , it 'll give you an answer . that 's just how they are . and so , @ @ whatever that is , it 's the generic default intention . that it would find out . which is , wanting to know where something is , maybe nnn and wanting what it 's gonna be , but there 's gonna be something that
E: you 're not gonna are you gonna get variety of intentions out of that then ? you 're just talking about like given this user , what 's the th what is it what is that user most likely to want to do ?
D: you can observe some user and context and ask , what 's the posterior probabilities of all of our decision nodes .
E: and , have it talk about
D: you could even say , "" let 's take all the priors , let 's observe nothing "" , and query all the posterior probabilities . it - it 's gonna tell us something .
B: it will assign values to all the nodes . yes .
D: yes . and come up with posterior probabilities for all the values of the decision nodes . which , if we have an algorithm that filters out whatever the best or the most consistent answer out of that , will give us the intention ex nihilo . and that is exactly what would happen if we ask it to produce an utterance , it would be based on that extension , ex nihilo , which we what it is , but it 's there . so we wouldn't even have to to kick start it by giving it certain intention or observing anything on the decision node . and whatever that maybe that would lead to "" what is the castle ? "" , or "" what is that whatever "" .
B: what 'm afraid of is if we don't , , set up situation , we 'll just get bunch of garbage out , like , everything 's exactly thirty percent .
D: so what we actually then need to do is write little script that changes all the settings , go goes through all the permutations , which is we did didn't we calculate that once ?
B: that was that was absurdly low , in the last meeting , cuz went and looked at it cuz was thinking , that could not be right , and it would it was on the order of twenty output nodes and something like twenty
C: and like thirty input nodes
B: thirty input nodes . so to test every output node , , would at least let 's see , so it would be two to the thirty for every output node ? which is very th very large .
D: that 's that 's nothing for those neural guys . they train for millions and millions of epochs .
B: was gonna take drink of my water . 'm talking about billions and billions and two to the thirty is like bhaskara said , we had calculated out and bhaskara believes that it 's larger than the number of particles in the universe .
E: if that 's right or not . th - that 's big . that 's just that 's it 's billion , right ?
B: two to the thirty ? two to the thirty is billion , but if we have to do it two to the twenty times , then that 's very large number .
E: , that 's big .
B: cuz you have to query the node , for every , or query the net two to the twenty times . or not two to th excuse me , twenty times .
E: so , is it comes to twenty billion ? that 's pretty big , though .
B: that 's @ @ that 's big . ! we calculated different number before . how did we do that ?
E: remember there being some other one floating around . but anyway , .
C: don't really know .
E: it 's anyway , that given all of these different factors , it 's it 's it 's still going to be impossible to run through all of the possible situations or whatever .
C: ooo , it 's just big .
E: but , this 'll get us bit closer at least , right ?
B: if it takes us second to do , for each one , and let 's say it 's twenty billion , then that 's twenty billion seconds , eva , do the math . hours and hours and hours . but we can do randomized testing .
E: tah - dah !
B: which probabilistically will be good enough .
D: so , it be it 's an idea that one could run past , , what 's that guy 's name ? ? he - he 's usually here .
E: here in the group ?
D: . that 's the guy .
E: that would the the bald guy .
B: ! my advisor !
D: so this is just an idea that 's floating around and we 'll see what happens . what other news do have ? we fixed some more things from the smartkom system , but that 's not really of general interest , 'll ask eva about the bayes and she 's working on that . how is the generation xml thing ?
B: 'm gonna work on that today and tomorrow .
D: no need to do it today or tomorrow even . do it next week or
B: 'm gonna finish it today , hopefully . wanna do one of those things where stay here . cuz , if go home , 't finish it . 've tried about five times so far , where work for while and then 'm like , 'm hungry . so go home , and then
E: 'm not going back .
B: either that or to myself , work at home . and then try to work at home , but fail miserably . like ended up at blakes last night .
E: non - conducive .
B: almost got into brawl . but did not finish the , but 've been looking into it . th @ @ it 's not like it 's blank slate . found everything that need and stu and , furthermore , told jerry that was gonna finish it before he got back .
E: that 's approaching . he 's coming back when ?
B: we think we 'll see him definitely on tuesday for the next or , no , . the meetings are on thursday . we 'll see him next week .
D: that 's good .
B: was thinking about that . will try to work on the smartkom and 'll if finish it today , 'll help you with that tomorrow , if you work on it ? don't have problem with us working on it though ?
D: so you would say it 's funky
B: we just it wouldn't hurt to write up paper , cuz then , , was talking with nancy and nancy said , you whether you have paper to write up until you write it up . and since jerry 's coming back , we can run it by him too .
D: what 's your input ?
E: , don't have much experience with , conference papers for compu in the computer science realm , and so when looked at what you had , which was complete submission , said didn't really to do with it , like , this is the the basic outline of the system or whatever , "" here 's an idea "" , right ? that 's what that paper was , "" here 's here 's one possible thing you could do "" , and what you have in mind for expanding . like 'd what didn't do is go to the web site of the conference and look at what they 're looking for or whatever .
D: it seems to me that
B: is this computer science conference
D: it 's both , right ? it 's it 's cognitive , neural , psycho , linguistic , but all for the sake of doing computer science . so it 's cognitive , psycho , neural , plausibly motivated , architectures of natural language processing . so it seems pretty interdisciplinary , and , the keynote speaker is tomasello and blah - blah ,
E: right . , .
D: the question is what could we actually do and and keep straight face while doing it .
B: really can't keep straight face doing anything .
D: my idea is ,
E: setting that aside .
D: you can say we have done little bit and that 's this , and the rest is position paper , "" we wanna also do that "" . which is not too good . might be more interesting to do something like let 's assume , we 're right , we have as jerry calls it , delusion of adequacy , and take "" where is "" sentence , and say , "" we will just talk about this , and how we cognitively , neurally , psycho - linguistically , construction grammar - ally , motivated , envision , understanding that "" . so we can actually show how we parse it . that should be able to we should be able to come up with , , parse . it 's on , just put it on .
B: did ben harass you ?
A: was he supposed to harass me ? he just told me that you came looking for me . figure this out .
D: you will suffer in hell ,
E: there 's diagram somewhere which tells you how to put that
A: didn't understand that either !
B: no . you have to put it on exactly like that ,
D: this is it .
B: so put that those things over your ears like that . see the how the plastic things ar arch out like that ? there we go . it hurts . it hurts real bad .
A: 'm didn't mean to
E: but that 's what you get for coming late to the meeting .
A: 'm , these are all the same . ! th this is not very on target .
B: is your mike on ?
A: alright , you guys can continue talking about whatever you were talking about before .
D: we 're talking about this , alleged paper that we may , just ,
A: ! which johno mentioned to me .
D: and brought forth the idea that we take sentence , "" where is the powder - tower "" , and we pretend to parse it , we pretend to understand it , and we write about it .
E: about how all of these things
A: what 's the part that 's not pretend ?
D: then we pretend to write about .
E: the submitting to major international conference . .
A: tha - which conference is it for ?
D: it 's the whatever , architectures , , where there is this conference , it 's the seventh already international conference , on neu neurally , cognitively , motivated , architectures of natural language processing . and the keynote speakers are tomasello , macwhinney ?
A: whinney . macwhinney - .
D: we - macwhinney , .
A: so , interesting , both , like , child language people .
D: so maybe you wanna write something too .
A: maybe wanna go . why are they speaking at it if it
E: mmm . mmm .
A: is it normally like , dialogue systems , or , , other nlp - ish things ?
D: no no no . it 's it 's like
A: it 's cognitive . both learning and like , comprehension , production , that kinda .
D: you could look at the web site . and the ad and the deadline is the fifteenth of june .
A: that 's pretty soon .
D: hey . plenty of time .
E: why , we 've got over week !
D: it would be to go write two papers actually . and one from your perspective , and one from our peve per
A: th that 's the kinda thing that maybe like , , the general con like ntl - ish like , whatever , the previous simulation based pers maybe you 're talking about the same thing . general paper about the approach here would probably be appropriate . and good to do at some point anyway .
D: also think that if we write about what we have done in the past six months , we we could craft little paper that if it gets rejected , which could happen , doesn't hurt because it 's something we
A: having it is still good thing .
D: having it is good thing . it 's exercise , usually enjoy writing papers . it 's not don't re regard it as painful thing .
A: - . it 's fun .
D: and , we should all do more for our publication lists . and . it just never hurts . and keith and - or johno will go , probably .
A: when is it and where ?
D: it 's on the twenty second of september , in saarbruecken germany .
A: it 's in germany . tomasello 's already in germany anyway , so makes sense . . so , is the what are you just talking about , the details of how to do it , or whether to do it , or what it would be ?
E: what would one possibly put in such paper ?
D: what to write about .
A: or what to write about ?
D: what is our what 's our take home message . what what do we actually because , it don't like papers where you just talk about what you plan to do . it 's obvious that we can't do any evaluation , and have no , we can't write an acl type paper where we say , "" , we 've done this and now we 're whatever percentage better than everybody else "" . . it 's far too early for that . but , we can tell them what we think . never hurts to try . maybe even that 's maybe the time to introduce the new formalism that you guys have cooked up .
E: are in the process of
A: how many pages ?
B: don't they need to finish the formalism ?
D: it 's just like four pages . it 's it 's not even
A: so it 's little thing .
B: you said it was four thousand lines ? is that what you
A: four pages is , like , really not very much space .
D: did you look at it ? it depends on the format .
E: my gosh . , you were we were talking about something which was much more like ten .
D: no that 's that 's actually problem . it 's difficu it 's more difficult to write on four pages than on eight .
A: and it 's also difficult to even if you had lot of substance , it 's hard to demonstrate that in four pages , .
E: that would be hard .
A: it 's still it 's still
D: maybe it 's just four thousand lines . do don't they don't want any they don't have tex style @ @ guide .
A: - , - .
D: they just want ascii . pure ascii lines , why , for whatever reason ,
A: not including figures and such ?
D: very unspecific unfortunately .
B: would say that 's closer to six pages actually . four thousand lines of ascii ?
E: four thousand lines . isn't isn't it about fifty fifty five , sixty lines to page ?
D: don't quote me on this . this is numbers have from looking
B: how many characters are on line ?
D: let 's let 's wh what should we should we , , discuss this over tea and all of us look at the web ? 'm wizarding today .
A: look at the web page ?
D: look at the web page and let 's talk about it maybe tomorrow afternoon ?
A: more cues for us to find it are like , neural cons
D: johno will send you link .
A: you have link . .
B: got an email . keith is comfortable with us calling him "" keith "" .
E: he he decided 'm chilling in the five - one - .
A: "" keith "" . that 's very - shirt .
D: and 'm also flying
E: got this from the two one two .
D: 'm flying to sicily next in two weeks from now , and week of business in germany . should mention that for you . and otherwise you haven't missed much , except for really weird idea , but you 'll hear about that soon enough .
A: the idea that you and already know about ? that you already told me ?
D: no , no . that is something for the rest of the gang to
E: the thing with the goats and the helicopters ?
D: change the watchband . it 's time to walk the sheep . did you catch thusion ? it 's time to walk the sheep ? it 's presumably one of the watergate codes they don't make any plans for spring break next year . that 's the other thing . we 're gonna do an int edu internal workshop in sicily .
A: that 's what that 's what he says .
D: 've already got the funding .
A: kn that 's great ! does that mean does that mean you 'll get you 'll fly us there ?
E: we 'll see .
D: no , that 's that 's what it means .
B: and he 'll put us up , too .
A: know about that part . know about the almond trees and . , , kiwi ?
D: mmm , too easy . mangos go everywhere . so do kiwi .
A: , but was trying to find something that he didn't grow on his farm .
D: but coconut anana pineapple , that 's that 's tricky , .
E: so , but we have to decide what , like , the general idea of we 're gonna have an example case to like this "" where is "" case , .
D: maybe you have it would be the paper ha would have , in my vision , flow if we could say , here is th the th here is parsing if you wanna do it right , here is understanding if you wanna do it right , and without going into technical
A: but then in the end we 're not doing like those things right yet , right ? would that be clear in the paper or not ?
D: that would be clear , mailed around little paper that have
A: it would be like , this is the idea . didn't get that ,
D: we could say , this is
B: no , don't think you got it .
D: see this , if you if you 're not around , and don't partake in the discussions , and you don't get any email ,
A: 'm . 'm , 'm . . so parsing done right is like chicken done right .
D: so we could we could say this is what 's state of the art today . nuh ? and say , this is bad . nuh ? and then we can say , what we do is this .
A: parsing done right , interpretation done right , example .
D: - . . and
A: and how much to get into the cognitive neural part ?
B: that 's the only that 's the question mark . don't you need to reduce it if it 's or reduce it , if it 's cognitive neuro
A: the conference may be cognitive neural , doesn't mean that every paper has to be both . like , nlp cognitive neural .
D: and you can you can just point to the to the literature , you can say that construction - based
A: so so this paper wouldn't particularly deal with that side although it could reference the ntl - ish , like , , approach . the fact that the methods here are all compatible with or designed to be compatible with whatever , neurological neuro - biol su . four pages you could you could definitely it 's definitely possible to do it . it 's just it 'd just be small . like introducing the formalism might be not really possible in detail , but you can use an example of it .
E: looking at that paper that you had , , like , you didn't really explain in detail what was going on in the xml cases or whatever you just sorta said , , here 's the general idea , some gets put in there . hopefully you can you can say something like constituents tells you what the construction is made out of , , without going into this intense detail .
A: so it be like using the formalism rather than , introducing it per se .
E: give them the one paragraph whirlwind tour of what this is for ,
A: and people will figure out or ask about the bits that are implicit .
D: so this will be documenting what we think , and documenting what we have in terms of the bayes - net . and since there 's never bad idea to document things , no ?
A: that 's th that 's definitely good idea .
D: that would be my , we we should sketch out the details maybe tomorrow afternoon - ish , if everyone is around . you probably wouldn't be part of it . maybe you want ? think about it . you may ruin your career forever , if you appear .
B: you might get blacklisted .
D: the , other thing , we actually have we made any progress on what we decided , , last week ? 'm you read the transcript of last week 's meeting in red so sh so you 're up to dated caught up . we decided that we 're gonna take "" where is something "" question , and pretend we have parsed it , and see what we could possibly hope to observe on the discourse side .
B: remember came in and started asking you about how we were sor going to sort out the , decision nodes ?
A: what 'd you say ?
B: remember you talking to me , just not what you said .
A: do remember you talking to me . few more bits .
B: there was like we needed to or , in my opinion we need to design bayes another sub - bayes - net it was whether it was whether we would have bayes - net on the output and on the input , or whether the construction was gonna be in the bayes - net , and outside of it ,
A: so that was that the question ?
B: that was related to what we were talking about .
D: should introduce it as sudo - square ? we have to put this in the paper . if we write it . this is this is my only constraint . the sudo - square {nonvocalsound} is , "" situation "" , "" user "" , "" discourse "" , right ? "" ontology "" .
E: saw the diagram in the office ,
A: my god , that 's amazing ! someone 's gonna start making phil collins jokes .
E: god , hope not .
A: you guys are too young .
E: like "" sussudio "" , that horrible , horrible song that should never have been created .
A: know , that was horrible .
B: 've blocked every aspect of phil collins out of my mind .
A: 'm , haven't . not on purpose .
D: also he 's talking about suicide , and that 's that 's not notion wanna have evoked .
A: no , he 's not . didn't really listen to it , was too young .
E: it sounds too rocking for that . anyway . so , what 's going on here ? so what are what was wollte der kuenstler uns damit sagen ?
A: stop excluding me .
D: so we have tons of little things here ,
A: 't believe that 's never been thought of before .
B: what are the dots ? don't remember what the dots were .
E: those are little bugs .
D: these are our , whatever , belief - net decision nodes , and they all contribute to these {nonvocalsound} things down here .
A: , what 's the middle thing ?
D: that 's edu .
A: but what is it ?
D: in the moment it 's bayes - net . and it has fifty not - yet - specified interfaces . have taken care that we actually can build little interfaces , {nonvocalsound} to other modules that will tell us whether the user likes these things and , the or these things , and he whether he 's in wheelchair or not ,
A: is that supposed to be the international sign for interface ?
B: 'd 'd never seen it before either .
D: mmm . so .
E: cuz things fit onto that , see ? in vaguely obscene fashion .
D: no , this is rme core by agent design ,
A: that 's so great .
D: there 's maybe different
E: what what are these letters again , situr - situation , user , discourse and
D: situation , user , ontology .
A: what about the utterance ?
D: that 's here .
A: so that 's not like context , .
E: discourse is all things linguistic , .
D: so this includes the current utterance plus all the previous utterances . and irena gurevich is going to be here , end of july . she 's new linguist working for eml . and what she would like to do is great for us . she would like to take the ent ontolog we have discussed in terms of the eva
A: grateful for us ? did you just say grateful for us ?
D: think of back at the eva vector , and johno coming up with the idea that if the person discussed the discussed the admission fee , in previously , that might be good indication that , "" how do get to the castle ? "" , actually he wants to enter . or , , "" how do get to ? "" discussing the admission fee in the previous utterance , is good indication . we don't want hard code , set of lexemes , or things , that person 's , filter , or search the discourse history . so what would be is that if we encounter concepts that are castle , tower , bank , hotel , we run it through the ontology , and the ontology tells us it has , admission , opening times , it has admission fees , it has this , it has that , and then we we make thesaurus lexicon , look up , and then search dynamically through the , discourse history for occurrences of these things in given window of utterances . and that might , , give us additional input to belief versus .
A: so it 's not just particular word 's so the you 're looking for few keys that are cues to , few specific cues to some intention .
B: you can dynamically look up keys , .
E: so , so , since this since this technical is going over my head ,
B: and then grep , .
E: that you that when someone 's talking about castle , that it 's the thing that people are likely to wanna go into ? or , is it the fact that if there 's an admission fee , then one of the things we know about admission fees is that you pay them in order to go in ? and then the idea of entering is active in the discourse ? and then blah - blah ?
D: the idea is even more general . the idea is to say , we encounter certain entity in in utterance . so le let 's look up everything we the ontology gives us about that entity , what it does , what roles it has , what parts , whatever it has . and , then we look in the discourse , whether any of that , or any surface structure corresponding to these roles , functions aaa has ever occurred . and then , the discourse history can tell us , "" "" , or "" no "" . and then it 's up for us to decide what to do with it .
E: no , go ahead .
D: so , we may think that if you say , "" where is the theater "" , , whether or not he has talked about tickets before , then we he 's probably wanna go there to see something . or "" where is the opera in par - paris ? , lots of people go to the opera to take pictures of it and to look at it , and lots of people go to attend performance . and , the discourse can maybe tell us what 's more likely if we to look for in previous statements . and so we can hard code "" for opera , look for tickets , look for this , look for that , or look for mozart , look for thi "" but the smarter way is to go via the ontology and dynamically , then look up .
E: but you 're still doing look up so that when the person so that when the person says , "" where is it ? "" then you say , let 's go back and look at other things and then decide , rather than the other possibility which is th through discourse as they talk about different things prior to the "" where is it "" question they say , , "" how much does it cost to get in , , to see movie around here "" , "" where is the closest theater "" the that by mentioning admission fees , that just stays active now . that becomes part of like , their current ongoing active conceptual structure . and then , , over in your bayes - net or whatever , when the person says "" where is it "" , you 've already got , since they were talking about admission , and that evokes the idea of entering , , then when they go and ask "" where is it "" , then you 're enter node is already active because that 's what the person is thinking about . that 's the cognitive linguistic - way ,
D: ultimately that 's also what we wanna get at .
E: and probably not practical .
D: that 's that 's the correct way . so , we have to keep memory of what was the last intention , and how does it fit to this , and what does it tell us , in terms of the what we 're examining . and furthermore , we can idealize that , , people don't change topics , but they do . but , even th for that , there is student of ours who 's doing dialogue act , recognition module . so , maybe , we 're even in position where we can take your approach , which is much better , as to say how do these pieces
E: and much harder to program . and much harder to to program .
D: how how do these pieces fit together ? but , , nevertheless . so these are issues but we what we actually decided last week , is to , and this is , again , for your benefit is to , pretend we have observed and parsed an utterance such as "" where is the powder - tower "" , or "" where is the zoo "" , and specify , what we think the output , observe , out input nodes for our bayes - nets for the sub - , for the discourse bit , should be . so that and will will then come up with the ontology side , bits and pieces , so that we can say , we always just look at this utterance . that 's the only utterance we can do , it 's hard coded , like srini , hand parsed , but this is what we hope to be able to observe in general from utterances , and from ontologies , and then we can fiddle with these things to see what it actually produces , in terms of output . so we need to find out what the "" where is "" construction will give us in terms of semantics and simspec type things .
A: just "" where is "" ? or any variants of that .
D: look at it this way , what did we decide . we decided the prototypical "" where is "" , where , we don't really know , does he wanna go there , or just wanna know where it is . so the difference of "" where is the railway station "" , versus where "" where is greenland "" . nuh ?
B: was just dancing , .
D: we 're not videotaping any of this .
E: so , , we 're supposed to we 're talking about anything that has the semantics of request for location , right ? anyway , the node in the the ultimate , , in the bayes - net thing when you 're done , the node that we 're talking about , is one that says "" request for location , true "" , like that , right ? and exactly how that gets activated , , like whether we want the sentence "" how do get there ? "" to activate that node or not , , that 's that 's the issue that the linguistic - side has to deal with , right ?
D: actually more more the other way around . we wanted something that represents uncertainty we in terms of going there or just wanting to know where it is , . some generic information . and so this is prototypically @ @ found in the "" where is something "" question , surface structure , which can be , should be maps to something that activates both . the idea is to let 's have it fit nicely with the paper .
B: don't see unde how we would be able to distinguish between the two intentions just from the utterance , though . bef or , before we don't before we cranked it through the bayes - net .
D: that 's exactly what we want . we want to get no . we wouldn't .
B: but then so it 's just for every construction we have node in the net , right ? and we turn on that node .
D: what what is this gonna
B: and then given that we know that the construction has these two things , we can set up probabilities we can define all the tables for ev for those
D: it should be so we have let 's assume we call something like loc - node and path - node . and what we actually get if we just look at the discourse , "" where is "" should activate should be both , whereas maybe "" where is located "" , we find from the data , is always just asked when the person wants to know where it is , and "" how do get to "" is always asked when the person just wants to know how to get there . so we want to come up with what gets , input , and how inter in case of "" where is "" question . so what would the outcome of your parser look like ? and , what other discourse information from the discourse history could we hope to get , squeeze out of that utterance ? so define the input into the bayes - net based on what the utterance , "" where is "" , gives us . so definitely have an entity node here which is activated via the ontology , so "" where is "" produces something that is stands for , whether it 's castle , bank , restroom , toilet , whatever . and then the ontology will tell us
A: that it has location like that ? or th the ontology will tell us where actually it is located ?
D: no . not . where it is located , we have , user proximity node here somewhere , which tells us how far the user how far away the user is in respect to that entity .
A: so you 're talking about , , the construction involves this entity or refers to this entity , and from the construction also that it is location is or thing that can be located . right ? ontology says this thing has location slot . sh - and that 's the thing that is being that is the content of the question that 's being queried by one interpretation of "" where is "" . and another one is , , path from current user current location to that location . so is the question it 's just that 'm not what the is the question , for this particular construction how we specify that 's the information it provides ? or or asked for ? both sides , right ?
D: you don't need to even do that . it 's just what would be @ @ observed in in that case .
A: observed when you heard the speaker say "" where is "" , or when that 's been parsed ? so these little circles you have by the ?
D: that 's exactly what we 're looking for .
B: don't like having characterizing the constructions with location and path , or li characterizing them like that . cuz you don't it seems like in the general case you wouldn't know how to characterize them . or , for when . there could be an interpretation that we don't have node for in the it just seems like @ @ has to have node for the construction and then let the chips fall where they may . versus , saying , this construction either can mean location or path . and , in this cas and since it can mean either of those things , it would light both of those up .
D: it 's the same .
E: 'm thinking about it .
D: it will be the same . so in here we have "" 'll go there "" , right ? and we have our info - on . so in my my case , this would make this happy , and this would make the go - there happy . what you 're saying is we have where - question , where - node , that makes both happy . that 's what you 're proposing , which is , in my mind just as fine . so if we have construction node , "" where is "" , it 's gonna both get the po posterior probability that it 's info - on up , info - on is true - up , and that go - there is true - up , as . which would be exactly analogous to what 'm proposing is , this makes makes something here true , and this makes something also something here true , and this makes this true - up , and this makes this true - up as .
E: kinda like it better without that extra level of indirection too . with this points to that , and so on
D: because we get we get tons of constructions . because , , mmm people have many ways of asking for the same thing ,
B: change changed my mind actually .
A: so agree with that . have different kinda question , might be related , which is , so implicitly everything in edu , we 're always inferring the speaker intent , right ? like , what they want either , the information that they want , or it 's always information that they want probably , of some kind . or what 's something that they
D: the system doesn't massage you , no . no .
A: let 's see . so if the if th just there 's more here that 's not shown that you it 's already like part of the system whatever , but , "" where is "" , like , the fact that it is , , speech - act , whatever , it is question . it 's question that , , queries on some particular thing , and is that location . there 's , like , lot of structure in representing that . so that seems different from just having the node "" location - "" and that goes into edu , right ?
D: that 's that 's
A: so tha is that what you 're talking about ?
D: exactly . we have su we have specified two .
A: wh what kinds of structure we want .
D: the next one would be here , just for mood . the next one would be what we can squeeze out of the maybe we wanna observe the , , the length of the words used , and , or the prosody and and make conclusions about the user 's intelligence .
A: so in some ways so in some ways in the other parallel set of mo more linguistic meetings we 've been talking about possible semantics of some construction . the simulation that 's , according to it , that corresponds to it , and as the as discourse , whatever , conte infor in discourse information , such as the mood , and , , other . so , are we looking for abbreviation of that , that 's tailored to this problem ? cuz that has , , , , it 's in progress still it 's in development still , but it definitely has various feature slots , attributes , , bindings between things
D: that 's exactly , why 'm proposing it 's too early to have to think of them of all of these discourse things that one could possibly observe , so let 's just assume
A: for the subset of
D: human beings are not allowed to ask anything but "" where is "" . this is the only utterance in the world . what could we observe from that ?
A: that exactly "" where is "" , not the choices of "" where is "" or "" how do get to "" . just "" where is "" .
D: just just "" where is "" . and , but , do it do it in such way that we know that people can also say , "" is the town hall in front of the bank "" , so that we need something like wh focus . nuh ? should be should be there , that , , this the whatever we get from the
A: so do , or do not take other kinds of constructions into account ?
D: if you if you can , definitely do , where possible . right ? if if it 's not triggered by our thing , then it 's irrelevant , and it doesn't hurt to leave it out for the moment .
A: it seems like , "" where is "" , the fact that it might mean , "" tell me how to get to "" , do so , would you wanna say that those two are both , like those are the two interpretations , right ? the ones that are location or path . so , you could say that the construction is question asking about this location , and then you can additionally infer , if they 're asking about the location , it 's because they wanna go to that place , in which case , the you 're jumping step and saying , "" , know where it is but also know how to get they wanna seem they seem to wanna get there so 'm gonna tell them "" . so there 's like structure
E: right , th this it 's not that this is like semantically ambiguous between these two .
A: do you kn , that
E: it 's really about this but why would you care about this ? it 's because you also want to know this , like that right ?
A: so it 's like you infer the speaker intent , and then infer plan , larger plan from that , for which you have the additional information , you 're just being extra helpful .
D: think , this is just mental exercise . if you think about , focus on this question , how would you design that ? is it do you feel confident about saying this is part of the language already to detect those plans , and why would anyone care about location , or do you actually , this is perfectly legitimate , and would not have any problems with erasing this and say , that 's all we can activate , based on the utterance out of context .
A: and just by an additional link
D: and then the the miracle that we get out the intention , go - there , happens , based on what we know about that entity , about the user , about his various beliefs , goals , desires , blah - blah .
A: with context and enough user information ,
D: but this is the thing , propose that we think about , so that we actually end up with , nodes for the discourse and ontology so that we can put them into our bayes - net , never change them , so we all there is "" where is "" , and , eva can play around with the observed things , and we can run our better javabayes , and have it produce some output . and for the first time in th in the world , we look at our output , and and see whether it 's any good .
E: here 's hoping . here 's hoping . right ? now cross your fingers .
D: , for me this is just ba matter of curiosity , wanna would like to look at , what this ad - hoc process of designing belief - net would actually produce . if if we ask it where is something . and , maybe it also enables you to think about certain things more specifically , come up with interesting questions , to which you can find interesting answers . and , additionally it might fit in really nicely with the paper . because if if we want an example for the paper , suggest there it is . so th this might be opening paragraph for the paper as saying , "" people look at kinds of at ambiguities "" , in the literature there 's "" bank "" and whatever kinds of garden path phenomenon . and we can say , , that 's all nonsense . , these things are never really ambiguous in discourse , , don't ever occur really in discourse , but normal statements that seem completely unambiguous , such as "" where is the blah - blah "" , actually are terribly complex , and completely ambiguous . and so , what every everybody else has been doing so far in , has been completely nonsensical , and can all go into the wastepaper bin ,
E: that 's always good way to begin . .
D: and the the only
E: all others are useless . that 's good .
D: but , , just not really 'm eja exaggerating , but that might be , , saying "" hey "" , , some is actually complex , if you look at it in in the vacuum and ceases to be complex in reality . and some that 's as that 's straightforward in the vacuum , is actually terribly complex in reality . would be , , also , , bottom - up linguistics , , type message . versus the old top - down school . 'm running out of time .
B: when do you need to start wizarding ?
D: at four ten . this is the other bit of news . the subjects today know fey , so she can't be here , and do the wizarding . so 'm gonna do the wizarding and thilo 's gonna do the instructing . also we 're getting person who just got fired , from her job . person from oakland who is interested in maybe continuing the wizard bit once fey leaves in august . and , she 's gonna look at it today . which is good news in the sense that if we want to continue , after the thir after july , we can . and that 's also maybe interesting for keith and whoever , if you wanna get some more into the data collection . remember this , we can completely change the set - up any time we want . look at the results we 've gotten so far for the first , whatever , fifty some subjects ?
A: you 've had fifty so far ,
D: no , we 're approaching twenty now . but , until fey is leaving , we surely will hit the some of the higher numbers . so that 's . can do more funky .
E: 'll have to look more into that data . is that around ? like , cuz that 's getting posted right away when you get it ? it has to be transcribed , ?
D: we have , found someone here who 's hand st hand transcribing the first twelve . just so we can build language model for the recognizer . but , so those should be available soon . the first twelve .
E: that that looked at the first the first one and got enough data to keep me going for , , probably most of july . so . but , . probably not the right way to do it actually .
D: but you can listen to you can listen to all of them from your solaris box . if you want . it 's always fun .
","An idea for future work was suggested during the visit of the german project manager: the possibility to use the same system for language generation.
Having a system able to ask questions could contribute significantly to training the belief-net.
Setting up certain inputs in the Bayes-net would imply certain intentions , which would trigger dialogues.
There is potential to make a conference paper out of presenting the current work and the project aspirations within a parsing paradigm.
The focus should be the Bayes-net , to which all other modules interface.
Situation , User , Discourse and Ontology feed into the net to infer user intentions.
Someone asking where the castle is after having asked about the admission fee , indicates that -given that the castle is open to tourists- they want to go there , as opposed to knowing its whereabouts.
It was suggested that they start analysing what the Discourse and Ontology would give as inputs to the Bayes-net by working on simple utterances like ""where is X?"".
With this addition , all input layers of the net would be functioning.
Although this function would be limited , it would allow for the Bayes-net to be tested in its entirety and , henceforth , extended.
The possibility of incorporating language generation into the system will have to be discussed further.
Similarly , as no one could recall some of the points of the conference call , the group will have to meet again and define the exact structure and content of the paper they are going to submit.
The Bayes-net is going to be the focus of the presentation.
In order to complete a functioning prototype of the belief-net , it was decided to start expanding the Ontology and Discourse nodes by working with a simple construction , like ""where is X?"".
A robust analysis of such a basic utterance will indicate what the limits of the information derived from the construction are , as well as ways to design the whole module and fit other constructions in.
The idea to create a language generation module for the system , along with the language understanding , was met with interest , although it was made clear that generation is not just the inverse of understanding.
Understanding what a construction entails does not mean the system can use the construction in all appropriate circumstances.
A dialogue producing system would be useful for training the system further , even though the number of input permutations could render the process computationally unwieldy.
Regarding the conference paper , it was noted that at this stage they have not completed any big parts of the system and there is no evaluation.
Similarly , the length of the paper would not allow for presentation of the formalism in detail.
The focus would have to be on cognitive motivations of the research , and not on system design , anyway.
Such motivations also apply to the belief-net: there are various direct or indirect ways to link features of the Ontology or Discourse with specific intentions.
The originating observation behind the whole project is that utterances like ""Where is X?"" are seemingly unambiguous , but , in context , they can acquire much more complex interpretations.
The SmartKom prototype was in need of de-bugging , which is now on its way.
Similarly , the work on XML is going to be finished within a day.
On the other hand , the data recording has started: almost twenty subjects have already taken part and the transcription of the recordings is running in parallel.
Meanwhile a new person , who is also a possible replacement for the wizard's task in the data collection , has been hired.
"
ami_abstractive_summary,Bed015.txt,"B: what things to talk about .
F: that 's horrible !
A: we 're recording .
B: alright . good .
F: are you doing something ? then 'm doing something . so the result of much thinking since the last time we met , , but not as much writing , , is sheet that have lot of , like , thoughts and justification of comments on but 'll just pass out as is right now . if you could pass this around ? and there 's two things . and so one on one side is on one side is the revised updated semantic specification . and the other side is , , revised construction formalism .
E: this is just one sheet , right ?
D: just one sheet .
F: it 's just one sheet . it 's just nothing else .
D: front , back .
F: enough to go around ? and in some ways it 's it 's very similar to there are very few changes in some ways from what we 've , , , done before but don't think everyone here has seen all of this . so , , 'm not where to begin . as usual the disclaimers are there are all these things are it 's only slightly more stable than it was before . and , , after little bit more discussion and especially like keith and have more linguistic things to settle in the next few days , , it 'll probably change again some more . let 's start let 's start on number two actually on the notation , because that 's , 'm thinking , possibly little more familiar to , to people . so the top block is just abstract nota it 's like , , listings of the kinds of things that we can have . and certain things that have , , changed , have changed back to this . there there 's been little bit of , , going back and forth . but all constructions have some name . forgot to include that you could have type included in this line . so something like , there 's an example the textual example at the end has clausal construction . just to show it doesn't have to be beautiful it could be , , simple old text as . there are couple of these three have various ways of doing certain things . so 'll just try to go through them . so they could all have type at the beginning . and then they say the key word construction and they have some name .
C: so so the current syntax is if it if there 's type it 's before construct that 's fine .
F: and then it has block that is constituents . and as usual all the constructions her all the examples here have only , , tsk one type of constituent , that is constructional constituent . that 's actually gonna turn out to be certainly the most common kind . but in general instead of the word "" construct "" , th here you might have "" meaning "" or "" form "" as . so if there 's some element that doesn't that isn't yet constructional in the sense that it maps form and meaning . the main change with the constructs which each of which has , , the key word "" construct "" and then some name , and then some type specification , is that it 's it 's pro it 's often sometimes the case in the first case here that what construction it is . so whatever have here is gonna be form of the word "" throw "" , or it 's gonna be form of the word , , , "" happy "" , like that . or , , some it 'll be specific word or maybe you 'll have the type . you 'll say "" need spatial relation phrase here "" or "" need directional specifier here "" . so - you could have actual type here . or you could just say in the second case that you only know the meaning type . so very common example of this is that , , in directed motion , the first person to do something should be an agent of some kind , so if , the , , run down the street then run down the street , it 's typed , , "" "" , meaning category is what 's there . the the new kind is this one that is pair skipping fonts and whatever . the idea is that sometimes there are , , general constructions that , that you 're going to need . it 's it 's the equivalent of noun phrase or prepositional phrase , like that there . and usually it has formal , considerations that will go along with it . and then , you might know something much more specific depending on what construction you 're talking about , about what meaning what specific meaning you want . so the example again at the bottom , which is directed motion , you might need nominal expression to take the place of , , , "" the big th "" , , "" the big the tall dark man "" , , "" walked into the room "" . but because of the nature of this particular construction not just that it 's nominal of some kind but in particular , that it 's some animate nominal , and which will apply just as to like , , per , simple proper noun or to some complicated expression . so if the syntax will hold but something that gives you way to do both constructional and meaning types . then don't think the , none of these examples have anything different for formal constraints ? but you can refer to any of the , , available elements and scope , right ? which here are the constructs , to say something about the relation . and if you not if you compare like the top block and the textual block , , we dropped like the little subscript . the subscripts refer to the "" form "" piece of the construct . and that , , in general it 'll be unambiguous . like if you were giving formal constraint then you 're referring to the formal pole of that . so so by saying if said "" name one "" then that means name one formal and we 're talking about formal struc which which makes sense . there are certain times when we 'll have an exception to that , in which case you could just indicate "" here the meaningful for some reason "" . or actually it 's more often that , only to handle this one special case of , , "" george and jerry walk into the room in that order "" . so we have few funny things where something in the meaning might refer to something in the form . but but we 're not gonna really worry about that for right now and there are way we can be more specific if we have to later on . and so in terms of the relations , as usual they 're before and ends . should have put an example in of something that isn't an interval relation but in form you might also have value binding . you could say that , , , "" name - one dot "" , , "" number equals "" , , plural like that . there are certain things that are attribute - value , similar to the bindings below but they 're just us usually they 're going to be value fillers , right ? and then again semantic constraints here are just are just bindings . there was talk of changing the name of that . and johno and you and like fight about that if you like ? but about changing it to "" semantic effects "" , which was little bit too order - biased and "" semantic bindings "" , which might be too restrictive in case we don't have only bindings . and so it was an issue whether constraints , there were some linguists who reacted against "" constraints "" , saying , "" , if it 's not used for matching , then it shouldn't be called constraint "" . but we want to be uncommitted about whether it 's used for matching or not . right ? cuz there are we thought of some situations where it would be useful to use whatever the bindings are , for actual , , like modified constraining purposes .
C: you definitely want to de - couple the formalism from the parsing strategy . so that whether or not it 's used for matching or only for verification ,
F: it 's used shouldn't matter , right ?
C: what , , term we want to use but we don't want to
F: , there was one time when hans explained why "" constraints "" was misleading word for him . and the reason that he gave was similar to the reason why johno thought it was misleading term , which was just an interesting coincidence . and so was like , "" , both of you don't like it ?
C: it 's it 's gone .
F: fine , we can change it "" . but 'm starting to like it again . so that 's why that 's why 'll stick with it .
A: if you have an "" if - then "" phrase , do what the "" then "" phrase is called ?
F: con - , consequent ? but it 's not an "" if - then "" .
C: anyway , so the other the other strategy you guys could consider is when you what word to put , you could put no word , and the then let
F: that 's true .
B: so that 's why you put semantic constraints up top and meaning bindings down here ?
F: no . that was just mistake of cut and paste from when was going with it . so , 'm . didn't mean that one 's an in unintentional .
B: so this should be semantic and
F: sometimes 'm intentionally inconsistent cuz 'm not yet . here , actually it was just mistake .
B: th - so this definitely should be "" semantic constraints "" down at the bottom ?
F: unless go with "" meaning "" but , like "" meaning "" better than "" semantic "" but there 's vestiges of other people 's biases . so the middle block doesn't really give you any more information , ex than the top block . and the bottom block similarly only just illus , all it does is illustrate that you can drop the subscripts and that you can drop the , , that you can give dual types . one thing should mention is about "" designates "" . 'm actually inconsistent across these as . so , , strike out the subscript on the middle block . so now , , this is actually this little change actually goes along with big linguistic change , which is that "" designates "" isn't only something for the semantics to worry about now . so we want "" designates "" to actually know one of the constituents which acts like head in some respects but is , , really important for say composition later on . so , if some other construction says , , "" are you of type is this part of type whatever "" , , the "" designates "" tells you which part is the meaning part . so if you have like "" the big red ball "" , , you wanna there 's an object or noun . ball is going to be the designated element of that phrase . there is slight complication here which is that when we talk about form it 's useful sometimes to talk about , to talk about there also being designated object and we think that 'll be the same one , right ? so the ball is the head of the phrase , "" the the "" , , "" big red ball "" , and the entity denoted by the word "" ball "" is the semantic head in some ways of this , , in interesting larger element .
C: and there 's there 's ca some cases where the grammar depends on some form property of the head . and and this enables you to get that , if understand you right .
F: right , right .
E: that 's the idea .
F: and , , you might be able to say things like if the head has to go last in head - final language , you can refer to the head as the , the formal head as opposed to the rest of the form having to be at the end of that decision . so that 's useful thing so that you can get some internal structural constraints in .
C: so th looks good . were you finished ?
F: there was list of things that isn't included but you can you can ask question . that might @ @ it .
C: so , if understand this the aside from , , construed and all that , the differences are mainly that , we 've gone to the possibility of having form - meaning pairs for type or actually gone back to , if we go back far enough
F: except for their construction meaning , so it 's not clear that , right now it 's contr construction type and meaning type . so what form type is .
C: you 're right . that 's fine .
F: and previous , , , version of the notation certainly allowed you to single out the meaning bit by it . so you could say "" construct of type whatever designates something "" . but that was mostly for reference purposes , just to refer to the meaning pole . don't think that it was often used to give an extra meaning const type constraint on the meaning , which is really what we want most of the time . if we 'll ever have case where we actually if there is form category constraint , you could imagine having triple there that says , that 's weird .
C: no , no , don't . that you 'll you 'll do fine . these are , , as long as mark isn't around , these are form constraints . so nominal expression is , the fact that it 's animate , is semantic . the fact that it 's , nominal expression would say on most people 's notion of , higher form types , this this is one .
F: right , right .
C: and that 's just fine .
F: which is fine , .
E: it 's that now , , 'm mentioned this , if ever explained this but the point of , , mentioned in the last meeting , the point of having something called "" nominal expression "" is , , because it seems like having the verb subcategorize for , , like say taking as its object just some expression which , , designates an object or designates thing , or whatever , , that leads to some syntactic problems ? so you wanna , you have this problem like "" , , 'll put the word "" , , let 's say , the word "" dog "" , and that has to come right after the verb cuz we know verb meets its object . and then we have construction that says , , you can have "" the "" preceding noun . and so you 'd have this problem that the verb has to meet the designatum . and you could get , , "" the kicked dog "" like that , meaning "" kicked the dog "" . so you have to let this phrase idea in there
C: that have no problem with it . it 's fine .
F: you may be you may not be like everyone else in berkeley , but that 's .
E: we we thought we were getting away with , with ,
F: we don't mind either ,
E: this is not reverting to the - bar theory of phrase structure . know that this is like , we didn't originally have in mind that , that verbs would subcategorize for particular form .
C: but they do .
E: but they does .
F: there 's an alternative to this
E: at least in english .
F: which is , the question was did we want directed motion , which is an argument structure construction did we want it to worry about , , anything more than the fact that it , , has semantic it 's frame - based construction . so one option that , , keith had mentioned also was like , if you have more abstract constructions such as subject , predicate , things like grammatical relations , those could intersect with these in such way that subject , predicate , or subject , predicate , subject , verb , ob , verb object would require that those things that fill subject and object are nom expressions . and that would be little bit cleaner in some way . but , for now , ,
C: but it it 's , just moving it moving the the cons the constraints around .
F: moving it to another place , right . but there does , there has to be that constraint somewhere , right ?
C: and so that was the
F: robert 's not happy now ?
C: and going with that is that the designatum also now is pair . instead of just the meaning . and that aside from some terminology , that 's it . want to 'm 'm asking .
F: the un the un - addressed questions in this , , definitely would be semantic constraints we talked about . here are just bindings we might want to introduce mental spaces there 's all these things that we don't
C: the whole the mental space thing is clearly not here .
F: so there 's going to be some extra , definitely other notation we 'll need for that which we skip for now .
C: do want to get on that as soon as robert gets back . so , , the mental space thing . , construal is is big component of that so this probably not worth trying to do anything till he gets back . but as soon as he gets back , we ought to
E: so what 's the what 's the time frame ? you 're going away for how long ?
A: just , , as mental bridge , 'm not 'm skipping fourth of july . so , , right afterwards 'm back .
F: you 're missing like the premier american holiday ? what 's the point of spending year here ?
A: 've had it often enough .
F: so , anyway .
B: he he went to college here .
C: and furthermore it 's worth missing .
F: not in california . that 's true . like like spending fourth of july in other countries , whenever .
C: so that 's great .
F: so there was one question that came out . hate this thing . so something like "" past "" which , we very simple , we 've often just stuck it in as feature , "" , this event takes place before speech time "" , , is what this means . it 's often thought of as it is also considered mental space , by , , lots of people around here . so there 's this issue of sometimes there are really exotic explicit space builders that say "" in france , blah - blah "" , and you have to build up you ha you would imagine that would require you , , to be very specific about the machinery , whereas past is very conventionalized one and we it means but it we doesn't don't necessarily want to , , unload all the notation every time we see that it 's past tense . so , , we could think of our , just like - schema "" walk "" refers to this complicated structure , past refers to , , certain configuration of this thing with respect to it .
C: that 's exactly right .
F: so so we 're like having our cake and eating it having it both ways , right ?
C: no , that we 'll have to see how it works out when we do the details but my intuition would be that 's right .
A: do you want to do the same for space ?
F: , , instead of just time ? so there are very conventionalized like deictic ones , right ? and then for other spaces that you introduce , you could just attach you could build up an appropriately , appropriate structure according to the the sentence .
A: this would involve everything you can imagine to fit under your dot something where it 's contextually dependent , "" what is now , what was past , what is in the future , where is this , what is here , what is there ,
F: so time and space . we 'll we 'll get that on the other side little , like very minimally . there 's there 's slot for setting time and setting place . you could imagine for both of those are absolute things you could say about the time and place , and then there are many in more interestingly , linguistically anyway , there are relative things that , , you relate the event in time and space to where you are now . if there 's something lot more complicated like , or so hypothetical or whatever , then you have to do your job , like or somebody 's job anyway . 'm gonna point to at random .
E: 'm 'm curious about how much of the mental 'm not that the formalism , the grammatical side of things , is gonna have that much going on in terms of the mental space . , all of these so - called space builders that are in the sentence are going to of it as , giving you the coordinates of , assuming that at any point in discourse there 's the possibility that we could be talking about bunch of different world scenarios , whatever , and the speaker 's supposed to be keeping track of those . the , the construction that you actually get is just gonna give you cue as to which one of those that you 've already got going , , you 're supposed to add structure to . so "" in france , , watergate wouldn't have hurt nixon "" like that . , you say , "" alright , 'm supposed to add some structure to my model of this hypothetical past france universe "" like that . the information in the sentence tells you that much but it doesn't tell you like exactly what it what the point of doing so is . so , depending on the linguistic con , context it could be like the question is , what does "" watergate "" refer to there ? does it , does it refer to , if you just hear that sentence cold , the assumption is that when you say "" watergate "" you 're referring to "" watergate - like scandal as we might imagine it happening in france "" . but in different context , "" , , if nixon had apologized right away it wouldn't , watergate wouldn't have hurt him so badly in the us and in france it wouldn't have hurt him "" . now we 're now that "" watergate "" we 're now talking about the real one ,
F: they 're real , right .
E: and the "" would "" it 's different dimension of hypothe - theticality , right ? we 're not saying what 's hypothetical about this world . in the first case , hypothetically we 're imagining that watergate happened in france . in the second case we 're imagining hypothetically that nixon had apologized right away so lot of this isn't happening at the grammatical level . where that sits then , the idea of sorting out what the person meant .
F: it seems like , , the grammatical things such as the auxiliaries that introduce these conditionals , whatever , give you the most basi th those we we can figure out what the possibilities are , right ? there are relatively limited number . and then how they interact with some extra thing like "" in france "" or "" if such - and - such "" , that 's like there are certain ways that they they can one is more specific version of the general pattern that the grammat grammar gives you . but , , whatever ,
C: in the short run all we need is enough mechanism on the form side to get things going .
E: but the whole point of the whole point of what fauconnier and turner have to say about , , mental spaces , and blending , and all that is that you don't really get that much out of the sentence . there 's not that much information contained in the sentence . it just says , "" here . add this structure to this space . "" and exactly what that means for the overall ongoing interpretation is quite open . an individual sentence could mean hundred different things depending on , quote , "" what the space configuration is at the time of utterance "" . and so somebody 's gonna have to be doing whole lot of work but not me , .
C: that 's right . , , that 's not th don't 's completely right . sentence examples you gave in did constrain the meaning the form did constrain the meaning , and so , , it isn't ,
E: but like what was the point of saying that sentence about nixon and france ? that is not there is nothing about that in the in the sentence really .
F: we usually the point of the sentence . but we it 's trying to say . we we know that it 's what predication it 's setting up .
C: but but bottom line , agree with you ,
F: that 's all .
C: that that we 're not expecting much out of the ,
F: purely linguistic cues , right ?
C: the purely form cues , . and , , you 're you 're the linguist but , , it seems to me that th these we , we 've talked about maybe half dozen linguistics theses in the last few minutes . , that 's my feeling that these are really hard , problems that decide exactly what 's going on .
F: so , , one other thing want to point out is there 's lot of confusion about the terms like "" profile , designate , focus "" , et cetera , et cetera .
C: right , right .
F: for now 'm gonna say like "" profile "" 's often used like two uses that come to mind immediately . one is in the traditional like semantic highlight of one element with respect to everything else . so "" hypotenuse "" , you profiled this guy against the background of the right right triangle . and the second use , , is in framenet it 's was asking hans about this . they use it to really mean , , this in frame th this is the profiles on the these are the ones that are required . so they have to be there or expressed in some way . which which 'm not saying one and two are mutually exclusive but they 're they 're different meanings . so the closest thing so was thinking about how it relates to this notation . so how is it
C: does that is that really what they mean in
F: so "" designate "" framenet ?
C: didn't know that .
F: was little bit surprised about it too . that would be something like there 's another term that 've heard for that thing but they , , at least hans says they use it that way . and may maybe he 's wrong . the "" designate "" that we have in terms of meaning is really the "" highlight this thing with respect to everything else "" . ? so this is what it means . but the second one seems to be useful but we might not need notation for it ? we don't have notation for it but we might want one . so we 've talked about if you 're talking about the lexical item "" walk "" , it 's an action . it also has this idea it carries along with it the idea of an actor or somebody 's gonna do the walking . or if you talk about an adjective "" red "" , it carries along the idea of the thing that has the property of having color red . so we used to use the notation "" with "" for this and that 's closest to their second one . so don't yet know , have no commitment , as to whether we need it . it 's the thing that parser might want to think about whether we require these things are like it 's semantically part of it
C: no , no . , th critically they 're not required syntactically . often they 're pres presu presupposed and all that .
F: right , right . , , definitely . "" in "" was good example . if you walk "" in "" , like , in what ?
C: right , there 's
F: like you have to have the so so it 's only semantically is it it is still required , say , by simulation time though to have something . so it 's that the idea of like that the semantic value is filled in by sim simulation . if that 's something we need to spa to like say ever as part of the requirement ? or the construction ? we 'll we 'll again defer .
C: or , or ,
F: have it construed , is that the idea ? just point at robert . whenever 'm confused just point to him .
C: it 's it 's his thesis , right ?
F: you tell me .
C: right , , this is gonna be you 're right , this is bit of in mess and we still have emphasis as , or stress , or whatever .
F: we 'll get , , we have thoughts about those as . some of this is just like my , by fiat . 'm going to say , this is how we use these terms . don't - , there 's lots of different ways in the world that people use it .
C: that 's fine .
F: that , , the other terms that are related are like focus and stress . that the way we would like to think , , is focus is something that comes up in , , lots of this is the information structure . it 's like , it 's not it might be that there 's syntactic , , device that you use to indicate focus or that there are things like , , keith was telling me , things toward the end of the sentence , post - verbal , tend to be the focused element , the new information . if "" walked into the room "" , you tend to think that , whatever , "" into the room "" is like the more focused thing . and when you , , you have stress on something that might be , , cue that the stressed element , or , the negated element is related to information structure . so that 's like the new the like import or whatever of this thing . so that 's to keep "" focus "" being an information structure term . th and then there are different kinds of focus that you can bring to it . so , , like "" stress "" , th stress is pun on you might have like whatever , like , , accent stress . and that 's just we 'll want to distinguish stress as form device . like , , high volume or whatever . and distinguish that from it 's effect which is , "" , the focus we have is we 're emphasizing this value often as opposed to other values "" , right ? so focus carries along scope . like if you 're gonna focus on this thing and you wanna evokes all the other possibilities that it wasn't . so my classic my now - classic example of saying , "" , he did go to the meeting ? "" , that was my way of saying as opposed to , , "" , he didn't "" or "" there was meeting ? "" that was the example that was caught on by the linguists immediately . and so , , the like if you said he there 's all these different things that if you put stress on different part of it then you 're , focusing , whatever , on , "" he walked to the meeting "" as opposed to "" he ran "" , or "" he did walk to the meeting "" as opposed to "" he didn't walk "" . , so we need to have notation for that that 's still in progress . so , 'm still working it out . but it did one implication it does have for the other side , which we 'll get to in minute is that couldn't think of good way to say "" here are the possible things that you could focus on "" , cuz it seems like any entity in any sentence , , or any meaning component of anyth all the possible meanings you could have , any of them could be the subject of focus . but one the one thing you can schematize is the focus , right ? so , you could say it 's the tense on this as opposed to , , the action . . or it 's , it 's an identity thing or contrast with other things , or stress this value as opposed to other things . it 's it is like profile - background thing but 't think of like the limited set of possible meanings that you would that you would focu
E: light up with focus , .
F: as opposed to other ones . so it has some certain complications for the , later on . li - , , the best thing come up with is that information has list of focused elements . you , one other type that forgot to mention is like query elements and that 's probably relevant for the like "" where is "" , , "" the castle "" thing ? because you might want to say that , , location or cert certain wh words bring , automatically focus in , , "" the identity of this thing "" way on certain elements . anyway . so that 's onl there are there are many more things that are uncl that are like little bit unstable about the notation but it 's most it 's this is , , the current form . other things we didn't deal with , ,
E: there 's bunch .
F: we 've had lot of other that keith and have them working on in terms of like how you deal with like an adjective . we should have put an example of this and we could do that later . but the not inherently like the general principles still work though , that , , we can have constructions that have constituent structure in that there is like , , , one , they have constituents , right ? so you can like nest things when you need to , but they can also overlap in flatter way . so if you don't have like lot of grammar experience , then like this might , , be little opaque . but , , we have the properties of dependency grammars and some properties of constituents constituent - based grammar . so that 's that 's the main thing we wanted to aim for and so far it 's worked out .
A: say two things about the maybe you want to forget stress . no , as just don't don't think about it .
F: what 's that ?
A: canonically speaking you can if you look at curve over sentence , you can find out where certain stress is and say , "" hey , that 's my focus exponent . "" it doesn't tell you anything what the focus is . if it 's just that thing ,
F: or the constituent that it falls in .
A: little bit more or the whole phrase .
F: you mean forget about stress , the form cue ?
A: because , , as form cue , , not even trained experts can always , they can tell you where the focus exponent is sometimes . and that 's also mostly true for read speech . in in real speech , , people may put stress . it 's so context dependent on what was there before , phrase ba breaks , , restarts . it 's just , it 's absurd . it 's complicated .
E: , 'm inclined to say let 's worry about specifying the information structure focus of the sentence
F: believe you , . ways that you can get it come from th
E: hhh , the phonology component can handle actually assigning an intonation contour to that . , later on we 'll worry about exactly how
A: or or map from the contour to what the focus exponent is .
E: but figure out how the
A: but , , if you what you 're what you 're focus is then you 're you 're hopeless - - ly lost anyways ,
F: that 's fine , .
A: and the only way of figuring out what that is , is , , by generating all the possible alternatives to each focused element , decide which one in that context makes sense and which one doesn't . and then you 're left with couple three . so , , again , that 's something that humans can do , but far outside the scope of any anything .
F: , , , wouldn't have assumed that it 's an easy problem in absence of all the oth you need all the other information .
A: but it 's what it , it 's pretty easy to put it in the formalism , though . you can just say whatever , "" is the container being focused or the entire whatever , both , and . ""
F: - , - . exactly . so the effect of it is something we want to be able to capture .
C: so but the poi but here 's what th going on . that if we do the constructions right when particular construction matches , it the fact that it matches , does specify the focus .
F: 'm not about that . or it might limit it cert certainly constrains the possibilities of focus .
C: at the very least it constrai
F: that 's that 's , th that 's certainly true . and depending on the construction it may or may not specify the focus , right ?
C: , for , yes . there are constrai , it 's not every but there are constructions , , where you explicitly take into account those considerations that you need to take into account in order to decide which what is being focused .
A: so we talked about that little bit this morning . "" john is on the bus , not nancy . "" so that 's focuses on john . "" john is on the bus and not on the train . "" "" john is on the bus "" versus "" john is on the train . "" and "" john is on the bus "" versus "" was "" , and
F: "" john is on the bus "" .
A: "" it 's the bu "" so
C: all of those .
A: and will we have is it all the same constructions ? just with different foc focus constituent ?
F: would say that argument structure in terms of like the main like , the fact that you can get it without any stress and you have some whatever is predicated anyway should be the same set of constructions . so that 's why was talking about overlapping constructions . so , then you have separate thing that picks out , , stress on something relative to everything else .
C: so , the question is actually
F: and it and that would have to it might be ambiguous as , , whether it picks up that element , or the phrase , like that . but it 's still is limited possibility . so that should , , interact with it should overlap with whatever other construction is there .
C: the question is , do we have way on the other page , , when we get to the semantic side , of saying what the stressed element was , or stressed phrase , .
F: so that 's why was saying how since couldn't think of an easy like limited way of doing it , , all say is that information structure has focused slot and that should be able to refer to
C: so that 's down at the bottom here when we get over there .
F: and , infer and don't have don't have great way or great examples
C: 'll - 'll .
F: but that something like that is probably gonna be , , more what we have to do . that was one comment . and you had another one ?
A: the once what the focus is the everything else is background . how about "" topic - comment "" that 's the other side of information .
F: how about what ?
A: topic - comment .
F: so that was the other thing . and so didn't realize it before . it 's like , "" ! "" it was an epiphany that it , topic and focus are contrast set . topic - focused seems to me like , , background profile , , or landmark trajector , or some something like that . there 's there 's definitely , , that thing going on . don't have as many great examples of like topic - indicating constructions on like focus , right ? topic it seems , that might be an ongoing thing .
E: japanese has this though . that 's what "" wa "" is , just to mark which thing is the topic . it doesn't always have to be the subject .
F: so again , information structure has topic slot . and , , stuck it in thinking that we might use it . stuck it in .
C: it 's there .
F: one thing that didn't do consistently , , is when we get there , is like indicate what thing fits into every role . have an idea of what it should be so far we 've been getting away with like either type constraint or , , , whatever . forg it 'll be frame . it 'll be it 'll be another predication or it 'll be , , , some value from some something , some variable and scope like that , or slot chain based on variable and scope . should we flip over to the other side officially then ? keep , , like , pointing forward to it . now we 'll go back to so this doesn't include something which mi may have some effect on it , which is , , the discourse situation context record , right ? so didn't just like draw line and like , , you also have , , some tracking of what was going on . and this is big scale comment before , , look into the details of this . but you could imagine instead of having changed the name of it used to be "" entities "" . so you see it 's "" scenario "" , "" referent "" and "" discourse segment "" . and "" scenario "" is essentially what what 's the basic predication , what event happened . and actually it 's just list of various slots from which you would draw in order to paint your picture , bunch of frames , bi and bindings , right ? and there are other ones that are not included here , general cultural frames and general like , , other action specific - schema frames . the middle thing used to be "" entities "" because you could imagine it should be like really list where here was various information . and this is intended to be grammatically specifiable information about referent , , about some entity that you were going to talk about . so "" harry walked into the room "" , "" harry "" and "" room "" , th but they would be represented in this list somehow . and it could also have , it has this category slot . it should be either category or in or instance . it could be pointer to ontology . so that everything about this could be could be drawn in . but the important things for grammatical purposes are for things like number , gender , ki the ones included here are slightly arbitrary but you could imagine that , , you need to figure out wheth if it 's group whether , , some event is happening , linear time , linear spaces , like , , are they doing something serially or is it like , 'm 'm not . because this partly came from , , talmy 's schema and 'm not we 'll need all of these actually . and then the "" status "" used was like , again , in some languages , , like in child language you might distinguish between different status . so , th the big com and finally "" discourse segment "" is about speech - act - information structure - , like utterance - specific kinds of things . so the comment was going to make about , , changing entity the entity 's block to reference is that you can imagine your discourse like situation context , you have set of entities that you 're referring to . and you might that might be general , , database of all the things in this discourse that you could refer to . and changed to "" reference "" cuz would say , for particular utterance you have particular referring expressions in it . and those are the ones that you get information about that you stick in here . 's going to be plural . 's gonna be feminine like that . and and these could actually just point to , , the id in my other list of enti active entities , right ? th there 's there 's all this about discourse status . we 've talked about . almost listed "" discourse status "" as slot where you could say it 's active . there 's this , , hierarchy there 's schematization of , , things can be active or they can be , , accessible , inaccessible . it was the one that , , keith , , emailed to us once , to some of us , not all of us . that noticed that , , list was discourse dependent . it was like in this particular set , , instance , it has been referred to recently or it hasn't been , or this is something that 's like in my world knowledge but not active .
C: there seems to be context properties .
F: they 're contex and , used to have location thing there but actually that 's property of the situation . and it 's again , time , at cert certain points things are located , , near or far from you
C: , this is recursive cuz until we do the , mental space story , we 're not quite th - th which is fine . we 'll just we 'll
F: so some of these are ,
C: we just yet .
F: so so for now , maybe 'll just have in this list the things that are relevant to this particular utterance , right ? everything else here is utterance - specific . and left the slot , "" predications "" , open because you can have , , things like "" the guy know from school "" . or , , like your referring expression might be constrained by certain like unbounded na amounts of prep , predications that you might make . and it 's unclear whether you could just have in your scenario , "" here are some extra few things that are true "" , right ? and then you could just not have this slot here . right ? you 're but it 's used for identification purposes . so it 's it 's little bit different from just saying "" all these things are true from my utterance "" .
E: right , "" this guy know from school came for dinner "" does not mean , , "" there 's guy , know him from school , and he came over for dinner "" . that 's not the same effect .
F: it 's little bit it 's little bit different . or maybe that 's like restrictive , non - restrictive it 's like it gets into that thing for but maybe 'm mixing , this is like the final result after parsing the sentence . so you might imagine that the information you pass to , in identifying particular referent would be , "" , some "" , "" it 's guy and it 's someone know from school "" . so maybe that would , , be some intermediate structure that you would pass into the disc to the , whatever , construal engine or whatever , discourse context , to find , either create this reference , in which case it 'd be created here , so you could imagine that this might not so , , 'm uncommitted to couple of these things .
A: but to make it precise at least in my mind , , it 's not precise . so "" house "" is gender neuter ?
F: it could be in semantically , . . so it , table . thing that doesn't have gender . so . , it could be that , maybe you 'd maybe not all these wou would say that tried to keep slots here that were potentially relevant to most things .
A: no , just to make that we everybody that 's completely that it has nothing to do with , , form .
F: that is semantic as opposed to that 's right .
A: then "" predications "" makes sense to have it open like , , accessibility or not .
F: open to various things . so . let 's see . so maybe having made that big sca like large scale comment , should go through each of these slots , each of these blocks , , little bit ? mostly the top one is image schematic . and just note , which was that , so when we actually ha some of them seem more inherently static , , like container or support - ish . and others are little bit seemingly inherently dynamic like "" source , path , goal "" is often thought of that way or "" force "" , like that . but in actual fact , that they 're intended to be neutral with respect to that . and different - schemas use them in way that 's either static or dynamic . so "" path "" , you could just be talking about the path between this and this . and , "" container "" that you can go in and out . all of these things . and so , , this came up when , , ben and were working with the spaniards , , the other day the "" spaniettes "" , as we called them to decide like how you want to split up , like , image schematic contributions versus , like , - schematic contributions . how do you link them up . , it 's gonna be something in the - schema that tells you "" is this static or is this dynamic "" . so we definitely need that aspectual type gives you some of that . that , , is it , , state or is it change of state , or is it , , action of some kind ?
A: is there any meaning to when you have parameters behind it and when you don't ?
F: ! you mean , in the slot ? no , it 's like - sc it 's it 's like was thinking of type constraints but - schema , it has to be an - schema . "" agent "" , , the performer of the - schema , that depends on the - schema . and in general it would probably be ,
E: so the difference is whether you thought it was obvious what the possible fillers were .
F: "" aspectual type "" probably isn't obvious but should have so , neglected to stick something in . "" perspective "" , "" actor "" , "" undergoer "" , "" observer "" , , we 've often used "" agent "" , "" patient "" , obser
E: "" whee ! "" that 's that one , right ?
F: exactly . exactly . and so one thing that , , we had talked about is this example of like , if you have passive construction then one thing it does is ch definitely , it is one way to for you to , , specifically take the perspective of the undergoing object . and so then we talked about , , whether , does that specify topic as ? maybe there are other things . now that it 's subject is more like topic . and now that , anyway . so . 'm gonna trail off on that one cuz it 's not that important right now .
C: now , for the moment we just need the ability to write it down if somebody figured out what the rules were .
F: some of these other ones , let 's see . one thing 'm uncertain about is how polarity interacts . so polarity , , is using for like action did not take place . so by default it 'll be like "" true "" , , if you 're specifying events that did happen . you could imagine that you skip out this , leave off this polarity , not don't have it here . and then have it part of the speech - act in some way . there 's some negation . but the reason why left it in is cuz you might have change of state , let 's say , where some state holds and then some state doesn't hold , and you 're just talking , if you 're trying to have the nuts and bolts of simulation you need to know that , , whatever , the holder doesn't and
C: no , th at this lev which is it should be where you have it .
F: it 's so it 's it 's fine where it is .
C: how you get it may in will often involve the discourse
F: may come from few places .
C: but by the time you 're simulating you sh you should know that .
E: so , 'm still just really not clear on what 'm looking at . the "" scenario "" box , like , what does that look like for an example ? like , not all of these things are gonna be here . this is just says
F: it 's grab bag of
E: "" part of what 'm going to hand you is whole bunch of , schemas , image , and - schemas . here are some examples of the sorts of things you might have in there "" .
F: so that 's exactly what it is . and for particular instance which will , , make an example of something , is that you might have an instance of container and path , let 's say , as part of your , , "" into "" , definition . so you would eventually have instances filled in with various values for all the different slots . and they 're bound up in , , their bindings and and values .
E: do you have to say about the binding in your is there slot in here for that tells you how the bindings are done ?
C: no , no . let 's see , we 're we 're not don't think we have it quite right yet . so , , what this is , let 's suppose for the moment it 's complete . , then this says that when an analysis is finished , the whole analysis is finished , you 'll have as result , , some resulting semspec for that utterance in context , which is made up entirely of these things and , , bindings among them . and bindings to ontology items . so that the who that this is the tool kit under whi out of which you can make semantic specification . so that 's . but , which is more relevant to your life , is this is also the tool kit that is used in the semantic side of constructions . so this is an that anything you have , in the party line , anything you have as the semantic side of constructions comes , from pieces of this ignoring li in general , you ignore lots of it . but it 's got to be pieces of this along with constraints among them . so that the , , goal of the , , "" source , path , goal "" has to be the landmark of the conta , the interior of this container . or whate whatever . so those constraints appear in constructions but this is the full range of semantic structures available to you .
F: except for "" "" , that forgot . but anyway , there 's som some causal structure for composite events .
C: let 's let 's mark that .
F: , so it gets little funny . these are all so far these structures , especially from "" path "" and on down , these are relatively familiar , , image schematic slots . now with "" "" , , the fillers will actually be themselves frames . right ? so you 'll say , "" event one causes event
C: and and this this again may ge our , and we and , , worlds .
F: event two "" , so that 's , these are all implicitly one within , within one world . even though saying that place takes place , whatever . if if said "" time "" is , , "" past "" , that would say "" set that this world "" , , "" somewhere , before the world that corresponds to our current speech time "" . so . but that that 's . the the within the event it 's st it 's still one world . so "" "" and other frames that could come in , unfortunately you could bring in say , , , "" desire "" like that , like "" want "" . and actually there is right now under "" discourse segments "" , , "" attitude "" ? "" volition "" ? could fill that . so there are couple things where like , "" , 'm not if wanted to have it there or "" there was whole list of possible speaker attitudes that like say talmy listed . and , like , , don't , it was like "" hope , wish . desire "" , blah - blah . and it 's like , , feel like if wanted to have an extra meaning if those are grammatically marked in the first place . so they 're more lexically marked , right ? at least in english . so if wanted to would stick in an extra frame in my meaning , saying , so th it 'd be hierarchical frame them , right ? like "" naomi wants su certain situation and that situation itself is state of affairs "" .
C: so so , "" want "" itself can be
F: can be just another frame that 's part of your
C: and it it 's an action . in in our in our in our
F: situation . right , right .
C: in our in our terminology , "" want "" can be an action and "" what you want "" is world . so that 's , it 's certainly one way to do it . there are other things . causal we need . mental space we need . the context we need . so anyway , keith so is this comfortable to you that , , once we have this defined , it is your tool kit for building the semantic part of constructions . and then when we combine constructions semantically , the goal is going to be to fill out more and more of the bindings needed in order to come up with the final one . and that 's the wh and , that according to the party line , that 's the whole story .
E: right . that makes sense . so , there 's this in the off in the scenario , which just tells you how various what schemas you 're using and they 're how they 're bound together . and that some of the discourse segment is that where you would sa that 's where the information structure is which is profiling on different parts of , , of this . what 's interesting is that the information structure there 's almost , we keep coming back to how focus is like this , , trajector - landmark thing . so if say , , , "" in france it 's like this "" . we 've learned something about france but the fact is that utterances of that sort are generally used to help you draw conclusion also about some implicit contrast , like "" in france it 's like this "" . and therefore you 're supposed to say , "" boy , life "" "" in france kids are allowed to drink at age three "" . and you 're that 's not just fact about france . you also conclude something about how boring it is here in the . right ?
F: right , right . so would prefer not to worry about that for right now and to think that there are , , discourse level constructions in sense , topic - focus constructions that would say , "" , when you focus something "" then just done the same way just actually in the same way as the lower level . if you stressed , , "" john went to the "" , , "" the bar "" whatever , you 're focusing that and in possible inference is "" in contrast to other things "" . so similarly for whole sentence , , "" in france such - and - such happens "" . so the whole thing is like again implicitly as opposed to other things that are possible .
A: just , , look read even sem semi formal mats rooth . if you haven't read it . it 's . and just pick any paper on alternative semantics . so that 's his that 's the best way of talking about focus , is his way .
E: what was the name ?
A: yes , th . never know how to pronounce his name because he 's , and , but very confused background . so and , , and sadly enough he also just left the ims in stuttgart . so he 's not there anymore . where he is right now but alternative semantics is if you type that into an , , browser or search engine you 'll get tons of . and what 'm confused about is what the speaker and the hearer is doing there .
F: so for particular segment it 's really just reference to some other entity again in the situation , right ? so for particular segment the speaker might be you or might be me . hearer is little bit harder . it could be like multiple people . that that 's not very clear from here
A: but you don't we ultimately want to handle that analogously to the way we handle time and place ,
F: that 's not allowed here .
A: because "" you "" , "" me "" , "" he "" , "" they "" , "" these guys "" , all these expressions , nuh , are in much the same way contextually dependent as "" here , "" and "" now , "" and "" there ""
C: now , this is this is assuming you 've already solved that . so it 's it 's fred and mary , so the speaker would be fred
F: right , so the constructions might will refer , using pronouns or whatever . in which case they have to check to see , , who the , , speaker in here wa in order to resolve those . but when you actually say that "" he walked into "" , whatever , , the "" he "" will refer to particular you you will already have figured who "" he "" or "" you "" , mmm , or "" "" , maybe is bett better example , who "" "" refers to . and then you 'd just be able to refer to harry , , in wherever that person whatever role that person was playing in the event .
A: that 's up at the reference part . and down there in the speaker - hearer part ?
F: so , that 's that 's just speaker is known from the situation , right ? you 're when you hear something you 're told who the speaker is who the speaker is . that 's constraining how in some ways this before you get to the you fill in all the rest of it . how else would you
A: , it 's the speaker may in english is allowed to say "" . "" among the twenty - five percent most used words . but wouldn't the "" "" then set up the referent that happens to be the speaker this time and not "" they , "" whoever they are .
F: right , right .
A: or "" you "" much like the "" you "" could
F: so , so would say ref under referent should be something that corresponds to "" "" . and maybe each referent should probably have list of way whatever , the way it was referred to . so that 's "" "" but , , should we say it refers to , what ? if it were "" harry "" it would refer to like some ontology thing . if it were if it 's "" "" it would refer to the current speaker , which is given to be like , , whoever it is .
A: so there 's "" and then he said , "" - .
F: "" "" within the current world .
C: that 's right . so so again , this , this is gonna to get us into the mental space and because , "" fred said that mary said "" , and whatever . and and so we 're , gonna have to , , chain those as .
A: twhhh - whhh .
F: so this entire thing is inside world , not just like the top part .
C: except it 's it 's trickier than that because , the reference so he where it gets really tricky is there 's some things , and this is where blends and all terribl so , some things which really are meant to be identified and some things which aren't . all we need for the moment is some way to say that .
F: so of having like for each referent , having the list of the things with which it is identified . which , , you you
C: you could do that .
F: it depends on if it is referring exp if it 's identifiable already or it 's new thing . if it 's new thing you 'd have to like create structure or whatever . if it 's an old thing it could be referring to , , usually something in situation , right ? there 's , whatever , it it could point at one of these .
C: had had an idea that would be very if it works . , haven't told you what it is yet .
F: if it works .
C: this was my build - up .
F: - . mmm .
C: an an idea that would be
F: we 're crossing our fingers .
B: so we 're building mental space , good .
C: if it worked . right , it was space builder . we might be able to handle context in the same way that we handle mental spaces because , , you have somewhat the same things going on of , , things being accessible or not . it it , if we did it right we might be able to get at least lot of the same structure .
F: use the same .
C: so that pulling something out of discourse context is similar to other kinds of , , mental space phenomena . 've 've never seen anybody write that up but maybe they did . that may be all over the literature .
E: there 's things like ther , there 's all kinds of like , , in mentioned last time in czech if you have verb of saying then
F: so so by default
E: , you say something like or was thinking you can say something like , "" , , , you are republican "" like that . where as in english you would say , "" you were "" . , the past tense being copied onto the lower verb doesn't happen there , so you have to say something about , , tense is determined relative to current blah - blah . same things happens with pronouns . there 's languages where , , if you have verb of saying then , so situation like "" bob said he was going to the movies "" , where that lower subject is the same as the person who was saying or thinking , you 're actually required to have "" "" there . and it 's in an extended function
C: so we would have it be in quotes in english .
E: but it 's not perceived as quotative construction . it 's been analyzed by the formalists as being logophoric pronoun , which means pronoun which refers back to the person who is speaking or that thing , right ?
F: right . , that makes sense .
E: but , that happens to sound like the word for "" "" but is actually semantically unrelated to it .
C: good , love the formali
F: you 're kidding .
E: there 's whole book which operates on this assumption . this book , ninety - three book on , on pronoun .
F: no , that 's horrible . that 's horrible . .
E: . and then the same thing for asl where , , you 're signing and someone says something . and then , , so "" he say "" , and then you do role shift . and then you sign "" , this , that , and the other "" . and , "" did this "" . that 's also been analyzed as logophoric and having nothing to do with "" "" . and the role shift thing is completely left out and so on . that pronoun references , , , ties in with all this mental space and so on , and . and so , ,
C: so that that does sound like it 's co consistent with what we 're saying , .
F: so it 's like the unspecified mental spaces just are occurring in context . and then when you embed them sometimes you have to pop up to the , depending on the construction or the whatever , , you you 're scope is might extend out to the base one . it would be to actually use the same , , mechanism since there are so many cases where you actually need it 'll be one or the other . it 's like , , actually , it 's the same operation .
C: , so this is worth some thought .
E: it 's like it 's like what 's happening that , , what 's happening , , there is that you 're moving the base space like that , right ? so that 's that 's how fauconnier would talk about it . and it happens diff under different circumstances in different languages . things like pronoun reference and tense which we 're thinking of as being these discourse - things actually are relative to bayes space which can change . and we need all the same machinery .
C: but , , this is very good actually cuz it to the extent that it works , it
F: ties it all into it .
C: it ties together several of these things .
A: and 'm gonna read the transcript of this one . but the , , but it 's too bad that we don't have camera . all the pointing is gonna be lost .
B: every time nancy giggles it means it means that it 's your job .
F: that 's why said "" point to robert "" , when did it .
A: mmm , isn't , 'm was dubious why he even introduces this reality , , as your basic mental space and then builds up doesn't start with some because it 's so obvi it should be so obvious , at least it is to me , that whenever say something could preface that with "" . "" so there should be no categorical difference between your base and all the others that ensue .
C: no , but there 's there 's gricean thing going on there , that when you say "" "" you 're actually hedging .
F: it 's like don't think
E: it 's an it 's an evidential . it 's semi - grammaticalized . people have talked about it this way . and , you can do special things . you can , th put just the phrase "" "" as parenthetical in the middle of sentence and so on , and .
F: actually one of the child language researchers who works with tomasello studied bunch of these constructions and it was like it 's not using any interesting embedded ways just to mark , , uncertainty like that .
A: but about linguistic hedges , those tend to be , , funky anyways
C: so we don't have that in here either do we ?
F: hhh , there used to be slot for speaker , , it was something like factivity . couldn't really remember what it meant so took it out . but it 's something
E: we were just talking about this evidentiality and like that , right ?
F: we were talking about sarcasm too , right ?
E: that 's what is , telling you what percent reality you should give this
C: so we probably should . confidence like that .
E: and the fact that 'm , the fact maybe if it versus he thinks that might , , depending on how much you trust the two of us or whatever ,
A: great word in the english language is called "" about "" . if you study how people use that it 's also
F: what 's the word ?
A: "" about . ""
C: that in that use of "" about "" , .
F: , as hedge .
C: and if you want us to spend pleasant six or seven hours you could get george started on that .
E: he wrote paper about thirty - five years ago on that one .
B: read that paper , the hedges paper ? read some of that paper actually .
E: would you believe that paper lead directly to the development of anti - lock brakes ? ask me about it later 'll tell you how . when we 're not on tape .
F: 'd love to know . so , and , , someone had raised like sarcasm as complication at some point .
C: there 's all that .
F: we just won't deal with sarcastic people .
E: we we don't have to care too much about the speaker attitude , right ? like there 's not so many different
F: certainly not as some they 're intonational markers for the most part . too much about the like grammatical
E: there 's lots of different attitudes that the speaker could have and that we can clearly identify , and so on , and . but like what are the distinctions among those that we actually care about for our current purposes ?
C: right , so , , this raises the question of what are our current purposes .
F: , do we have any ?
E: here it is three - fifteen already .
C: but , , it does seem that , this is this is coming along . it 's it 's converging . it 's as far as tell there 's this one major thing we have to do which is the mental the whole mental space thing . and then there 's some other minor things . and we 're going to have to bound the complexity . if we get everything that anybody ever thought about , we 'll go nuts . so we had started with the idea that the actual , , constraint was related to this tourist domain and the kinds of interactions that might occur in the tourist domain , assuming that people were being helpful and weren't trying to there 's all sorts of god knows , irony , and like which you isn't probably of much use in dealing with tourist guide . no end of things th that , , we don't deal with .
A: isn't that part easy though because in terms of the simspec , it would just mean you put one more set of brack brackets around it , and then just tell it to negate whatever the content of that is in terms of irony
F: in model theory cuz the semantics is always like "" speaker believes not - "" , like "" the speaker says and believes not - "" .
E: we have theoretical model of sarcasm now .
C: no , no .
F: right , right , but ,
C: anyway , so , , let me make proposal on how to proceed on that , which is that , , it was keith 's , , job over the summer to come up with this set of constructions . and my suggestion to keith is that you , over the next couple weeks , don't try to do them in detail or formally but just try to describe which ones you think we ought to have . and then when robert gets back we 'll look at the set of them . just just , , define your space . and , , so th these are this is set of things that we ought to deal with . and then we 'll we 'll go back over it and people will give feedback on it . and then we 'll have at least initial spec of what we 're actually trying to do . and that 'll also be useful for anybody who 's trying to write parser .
E: in case there 's any around .
F: if we knew anybody like that .
C: "" who might want "" so and we get this , , portals fixed and then we have an idea of the initial range . and then nancy you 're gonna have to , , do your set of but you have to do that anyway .
F: for the same , , data . , - .
C: so so we 're gonna get the we 're dealing with two domains , the tourist domain and the and the child language learning . and we 'll see what we need for those two . and then my proposal would be to , , not cut off more general discussion but to focus really detailed work on the subset of things that we 've we really want to get done . and then as separate thread , think about the more general things and all that .
A: also think the detailed discussion will hit , bring us to problems that are of general nature even suggest some solutions .
C: but what want to do is is to constrain the things that we really feel responsible for . so that we say these are the things we 're really gonna try do by the end of the summer and other things we 'll put on list of research problems , because you can easily get to the point where nothing gets done because every time you start to do something you say , "" , , but what about this case ? "" this is this is called being linguist .
B: there 's that quote in jurafsky and martin where it goes where some guy goes , "" every time fire linguist the performance of the recognizer goes up . ""
C: so , is that does that make sense as , general way to proceed ?
E: , we 'll start with that , just figuring out what needs to be done then actually the next step is to start trying to do it .
A: we have little bit of news , , just minor .
B: ooo , can ask
E: you ran out of power .
B: can ask quick question about this side ? is this , was it intentional to leave off things like "" inherits ""
F: just on the constructions , right ?
B: like constructions can inherit from other things ,
F: didn't want to think too much about that for now . so , , maybe it was subconsciously intentional .
E: , there should be wanted to find out someday if there was gonna be some way of dealing with , , if this is the right term , multiple inheritance , where one construction is inheriting from , from both parents , or different ones , or three or four different ones . cuz the problem is that then you have to which of , which are how they 're getting bound together .
F: refer to them .
C: right , right .
F: and there are certainly cases like that . even with just semantic schemas we have some examples . and we 've been talking little bit about that anyway .
C: so what would like to do is separate that problem out . my argument is there 's nothing you can do with that you can't do by just having more constructions . it 's uglier and it doesn't have the deep linguistic insights and .
E: that 's right . no , no .
F: those are over rated .
E: no , by all means ,
C: and so what 'd like to do is in the short run focus on getting it right .
E: right . , .
C: and when we think we have it right then saying , "" aha ! , can we make it more elegant ? "" can can we , what are the generalizations , and ?
E: connect the dots .
C: but rather than try to inheritance structure and all that before we we 're doing . so would say in the short run we 're not gonna first of all , we 're not doing them yet . and and it could be that half way through we say , "" aha ! , we now see how we want to clean it up . "" and inheritance is only one , that 's one way to organize it but there are others . and it may or may not be the best way . you had news .
A: to eva on our web site we can now , if you want to run javabayes , , you could see get download these classes . and then it will enable you she modified the gui so it has now button menu item for saving it into the embedded javabayes format . so that 's wonderful . and , and she , you tested it out . do you want to say something about that , that it works , right ?
D: was just checking like , when we wanna , , get the posterior probability of , like , variables . how you asked whether we can , like , just observe all the variables like in the same list ? you have to make separate queries every time .
A: that 's that 's bit unfortunate for the time being it 's it 's fine to do it
D: you just have to have long list of , , all the variables .
F: all the things you want to query , you just have to like ask for separately .
A: that 's probably maybe in the long term that 's good news because it forces us to think little bit more carefully how we want to get an out output . but that 's different discussion for different time . we 're really running late , so had , , an idea yesterday but , , whether we should even start discussing .
C: , tell us what it is .
A: the construal bit that , , has been pointed to but hasn't been , , made precise by any means , , may may work as follows . that we would , that the following thing would be in incredibly and have no clue whether it will work or nothing . so that 's just tangent , couple of mental disclaimers here . imagine you write bayes - net , bayes - net , completely from scratch every time you do construal . so you have nothing . just white piece of paper . you consult your ontology which will tell you bunch of , and parts , and properties , -
F: grout out the things that you need .
A: then you 'd simply write , , these into onto your white piece of paper . and you will get lot of notes and out of there . you won't get you won't really get any 's , therefore we need everything that configures to what the situation is , ie , the context dependent . so you get whatever comes from discourse but also filtered . so only the ontology relevant from the discourse plus the situation and the user model . and that fills in your cpt 's with which you can then query , , the net that you just wrote and find out how thing is construed as an utterance . and the embedded javabayes works exactly like that , we have , , precise format in which to write it , so we write it down . you query it . you get the result , and you throw it away . and the thing about this idea is that you don't ever have to sit down and think about it or write about it . you may have some general rules as to how things can be can be construed as what , so that will allow you to craft the the initial notes . but it 's in that respect it 's completely scalable . because it doesn't have any prior , , configuration . it 's just you need an ontology of the domain and you need the context dependent modules . and if this can be made to work , that 'd be funky .
C: it sounds to me like you want
A: ms - , prm since you can unfold prm into straightforward bayes - net
C: beca - because it because no , no , you can't . see the critical thing about the prm is it gives these relations in general form . so once you have instantiated the prm with the instances and ther then you can then you can unfold it .
A: then you can . no , was using it generic . so , , probabilistic , whatever , relational models . whatever you write it .
C: no , but it matters lot because you what you want are these generalized rules about the way things relate , th that you then instantiate in each case .
A: and then instantiate them . that 's ma maybe the way the only way it works .
C: that 's the only way it could work . we have our local expert on but my is that they 're not currently good enough to do that . but we 'll we 'll have to see . this is that 's that would be good thing to try . it 's related to the hobbs abduction story in that you th you throw everything into pot and you try to come up with the ,
A: except there 's no theorem prover involved .
C: no , there isn't theorem prover but there but the , , the cove the ms are like rules of inference and you 're you 're coupling bunch of them together . and then ins instead of proving you 're trying to , , compute the most likely . but you , it 's good it 's good thing to put in your thesis proposal .
A: what 's it ?
C: so are you gonna write something for us before you go ? you have something .
A: in the process thereof , or whatever .
C: so , what 's what when are we gonna meet again ?
F: when are you leaving ?
A: thursday 's my last day here . would suggest as soon as possible . do you mean by we , the whole ben gang ?
C: no , didn't mean just the two of us . we we can we can do this . but the question is do you want to , , send the little group , , draft of your thesis proposal and get , , another session on feedback on that ?
A: we can do it th - thursday again .
E: fine with me . should we do the one pm time for thursday since we were on that before
A: thursday at one ? also maybe then run through the , the talk have to give at eml which highlights all of our work . and we can make some last minute changes on that .
B: you can just give him the abstract that we wrote for the paper .
C: that - that 'll tell him exactly what 's going on .
F: can we do can we do one - thirty ? you already told me no .
A: but we can do four .
F: it 's fine . it 's fine . it 's fine .
A: one or four .
E: to me this is equal .
A: if it 's equal for all ? what should we do ?
F: it 's fine . no , no , , don't care . it 's fine .
A: it 's equal to all of us , so you can decide one or four .
B: the pressure 's on you nancy .
A: liz actually said she likes four because it forces the meeting recorder people to cut , the discussions short .
E: if you insist , then .
","The discussion concerned the revised semantic specification and the construction formalism.
The different levels of the latter focus on what construction types are encountered and what bindings there are between them.
The notation maintains properties of both dependency and constituent-based grammars.
The encoding of features is still incomplete: frame profiles , focus , adjectives , nominal expressions are phenomena in the process of being integrated.
Similarly , ways to handle mental spaces will have to be added on top.
On the other hand , the semantic specification structures information in terms of ""scenario"" , ""referent"" and ""discourse segment"".
Each category comprises a number of slots filled in by information derived from the utterance.
It is , essentially , a toolkit with which to create semantic constructions , as well as the bindings between them and with the ontology.
Among the issues still being defined , mental spaces and context ( eg pronoun references ) present similarities that can be echoed in the specification.
Work on both of these formalisms will continue with circumscription of the construction space that will be studied in more detail.
Work on construal will use Bayes-nets , which will be fed information from other modules and implement general rules to infer how utterances are construed.
The semantic specification requires some adjustments.
Amongst other things ""cause"" has to be added as another X-schema.
Linguistic hedging will also be encoded as a demarcation of evidentiality or speaker confidence.
Mental spaces can be tackled with mechanisms that can also deal with context issues ( time , space etc . ): creating a base space and rules of interaction with other interconnected spaces.
However , the complexity of these mechanisms has to be bound as well: it is necessary to define the range of constructions to be studied.
Given the domains currently used ( tourist , child language learning ) , some features , like speaker attitude , are not of equal importance at this stage.
On the other hand , it was decided for the inheritance between constructions to be left out for now , as the notation can be rendered more elegant later on.
Finally , a preliminary presentation on the idea of how to use Bayes-nets for construal will take place in the next meeting.
The construction formalism is not yet complete as to the semantic constraints -the terminology has also been met with objections- and does not deal with mental spaces.
On their own , constructions can only give limited information regarding mental spaces: forms can provide cues to create a different mental space , but the semantic nuances are defined by context.
It is not decided at this stage whether the necessary values should be coded within the construction or as part of construal.
Other issues concern focus and stress: focus is seen as an information structure device , but there has been no suggestion as to how to predict its effects or break it down in possible focused elements; as to stress , it may not be useful as a form value , as it shows the focus exponent , but not what the focus is on.
Moving to the semantic specification , the analysis still needs mechanisms to deal with causality , as well as mental spaces and bindings between them.
Additionally , how referring expressions are linked to referents or even how mental spaces affect this linking are still to lay down in detail.
The revised semantic specification and construction formalism are more stable than the previous versions.
In the latter , we find both construction types and meaning types along with formal considerations like verb subcategorisation , or the ones a ""directed motion"" construction would dictate.
Semantic constraints also come into play.
The semantic specification , on the other hand , is split into three levels: ""scenario"" is a list of schemas and bindings between them , which describes the current event in terms of Source-Path-Goal , Container , etc.; ""referent"" is about the entities in the discourse and includes grammatical information and pointers to the ontology; ""discourse segment"" comprises utterance-specific things.
Apart from the presentation , JavaBayes can now run through the modified web page of the project.
"
ami_abstractive_summary,Bed012.txt,"B: so this is more or less now just to get you up to date , johno . this is what , ,
C: this is meeting for me .
B: eva , bhaskara , and did .
D: did you add more to it ? later ? there were , like , the , @ @ and all that . but . you said you were adding
B: so we thought that , we can write up , an element , and for each of the situation nodes that we observed in the bayes - net ? what 's the situation like at the entity that is mentioned ? if we know anything about it ? is it under construction ? or is it on fire happening to it ? or is it stable ? going all the way , through parking , location , hotel , car , restroom , @ @ riots , fairs , strikes , or disasters .
C: so is this is situation are is all the things which can be happening right now ? or , what is the situation type ?
B: that 's just specifying the input for the what 's
C: why are you specifying it in xml ?
B: just because it forces us to be specific about the values here ? and , also , , this is what the input is going to be . so , we will , this is schema . this is
C: . if this is th what the does this is what java bayes takes ? as bayes - net spec ?
B: no , because if we we 're gonna interface to we 're gonna get an xml document from somewhere . and that xml document will say "" we are able to we were able to observe that the element , , @ @ of the location that the car is near . "" so that 's gonna be .
C: so this is the situational context , everything in it . is that what situation is short for , shi situational context ?
B: so this is just , again , an xml schemata which defines set of possible , , permissible xml structures , which we view as input into the bayes - net .
C: and then we can possibly run one of them transformations ? that put it into the format that the bayes or java bayes or whatever wants ?
B: yea - are you talking are you talking about the structure ? when you observe node .
C: when you when you say the input to the java bayes , it takes certain format , which don't this .
B: no , it 's certainly not this .
C: so you could just couldn't you just run to convert it into the java bayes for format ?
B: that 's that 's no problem , but even think that , once once you have this as running as module what you want is you wanna say , "" , give me the posterior probabilities of the go - there node , when this is happening . "" when the person said this , the car is there , it 's raining , and this is happening . and with this you can specify the what 's happening in the situation , and what 's happening with the user . so we get after we are done , through the situation we get the user vector . so , this is
C: so this is just specification of all the possible inputs ?
B: all the possible outputs , too . so , we have , , , the , , go - there decision node which has two elements , going - there and its posterior probability , and not - going - there and its posterior probability , because the output is always gonna be all the decision nodes and all the all the posterior probabilities for all the values .
C: and then we would just look at the , , struct that we wanna look at in terms of if we 're only asking about one of the so like , if 'm just interested in the going - there node , would just pull that information out of the struct that gets return that would that java bayes would output ?
B: but it 's little bit more complex . as , if understand it correctly , it always gives you all the posterior probabilities for all the values of all decision nodes . so , when we input something , we always get the , , posterior probabilities for all of these . so there is no way of telling it not to tell us about the eva values .
C: that 's , use , , .
B: so so we get this whole list of , , things , and the question is what to do with it , what to hand on , how to interpret it , so you said if you "" 'm only interested in whether he wants to go there or not "" , then look at that node ,
C: look at that struct in the output ,
B: look at that struct in the output , even though wouldn't call it "" struct "" .
C: it 's an xml structure that 's being res returned ,
B: so every part of structure is "" struct "" .
C: was abbreviated it to struct in my head , and started going with that .
B: that element or object , would say .
C: not struct . that 's not what was trying to
B: the reason is why it 's little bit more complex or why we can even think about it as an interesting problem in and of itself is so . the , let 's look at an example .
C: wouldn't we just take the structure that 's outputted and then run another transformation on it , that would just dump the one that we wanted out ?
B: we 'd need to prune . throw things away .
C: actually , you don't even need to do that with xml . can't you just look at one specific
B: exactly . the @ @ xerxes allows you to say , "" just give me the value of that , and that . "" but , we don't really we 're interested in before we look at the complete at the overall result . so the person said , , "" where is ? "" we want to know , , is does he want info ? or know the location ? or does he want to go there ? let 's assume this is our question . do this in perl . let 's assume this is the output . we should con be able to conclude from that it 's always gonna give us value of how likely we it is that he wants to go there and doesn't want to go there , or how likely it is that he wants to get information . but , maybe we should just reverse this to make it little bit more delicate . so , does he wanna know where it is ? or does he wanna go there ?
C: he wants to know where it is .
B: tend to agree . and if it 's if
C: now , , you could
B: and if there 's clear winner here , and , and this is pretty , indifferent , then we then we might conclude that he actually wants to just know where , , he does want to go there .
C: out of curiosity , is there reason why we wouldn't combine these three nodes ? into one smaller subnet ? that would just be the question for we have "" where is ? "" is the question , that would just be info - on or location ?
B: or go - there . lot of people ask that , if they actually just wanna go there . people come up to you on campus and say , "" where 's the library ? "" you 're gonna say you 're gonna say , "" go down that way . "" you 're not gonna say "" it 's it 's five hundred yards away from you "" or "" it 's north of you "" , or "" it 's located ""
C: but the there 's so you just have three decisions for the final node , that would link thes these three nodes in the net together .
B: whether understand what you mean . but . again , in this given this input , we , also in some situations , may wanna postulate an opinion whether that person wants to go there now the nicest way , wants to wants to know where it is because he wants something fixed there , because he wants to visit it or whatever . so , it all 'm saying is , whatever our input is , we 're always gonna get the full output . and some things will always be too not significant enough .
C: or or it 'll be tight . you won't it 'll be hard to decide . but , , , this is another , smaller , case of reasoning in the case of an uncertainty , which makes me think bayes - net should be the way to solve these things . so if you had if for every construction , you could say , "" , there here 's the where - is construction . "" and for the where - is construction , we know we need to look at this node , that merges these three things together as for th to decide the response . and since we have finite number of constructions that we can deal with , we could have finite number of nodes . say , if we had to deal with arbitrary language , it wouldn't make any sense to do that , because there 'd be no way to generate the nodes for every possible sentence . but since we can only deal with finite amount of
B: so , , the idea is to to feed the output of that belief - net into another belief - net .
C: so take these three things and then put them into another belief - net .
B: but , why why only those three ? why not the whol
C: , for the where - is question . so we 'd have node for the where - is question .
B: but we believe th the decision nodes are can be relevant for the where - is , and the where how - do - - get - to or the tell - me - something - about .
C: you can come in if you want .
B: yes , it is allowed .
C: as long as you 're not wearing your headphones . do see , if this is good idea or not . 'm just throwing it out . but , it seems like we could have mea or we could put all of the information that could also be relevant into the where - is node answer
B: let 's not forget we 're gonna get some very strong input from these sub dis from these discourse things , "" tell me the location of . "" or "" where is located at ? ""
C: know , but the bayes - net would be able to the weights on the on the nodes in the bayes - net would be able to do all that , 'll until you 're plugged in . don't sit there . how you don't like that one . that 's the weird one . that 's the one that 's painful . that hurts . it hurts so bad . 'm 'm happy that they 're recording that . that headphone . the headphone that you have to put on backwards , with the little thing and the little foam block on it ? it 's painful , painful microphone .
B: it 's th called "" the crown "" . versus "" the sony "" .
A: is that the actual name ?
C: don't see manufacturer on it . here it is . it 's "" the crown "" . the crown of pain !
B: you 're on - line ?
C: are you are your mike is your mike on ? so you 've been working with these guys ? what 's going on ?
A: and , do . so where are we ?
B: we 're discussing this .
A: don't can handle french ,
B: assume we have something coming in . person says , "" where is ? "" , and we get certain we have situation vector and user vector and everything is fine ? an - an and our and our
C: did you just sti did you just stick the the the microphone actually in the tea ?
A: 'm not drinking tea . what are you talking about ?
B: let 's just assume our bayes - net just has three decision nodes for the time being . these three , he wants to know something about it , he wants to know where it is , he wants to go there .
C: in terms of , these would be wha how we would answer the question where - is , this is that 's what you it seemed like , explained it to me earlier
B: but , mmm .
C: we we 're we wanna know how to answer the question "" where is ? ""
B: no , do the timing node in here , too , and say "" . ""
C: , but in the , let 's just deal with the the simple case of we 're not worrying about timing or anything . we just want to know how we should answer "" where is ? ""
B: go - there has two values , go - there and not - go - there . let 's assume those are the posterior probabilities of that . info - on has true or false and location . so , he wants to know something about it , and he wants to know something he wants to know where - it - is , has these values .
C: see why we can't do that .
B: and , , in this case we would probably all agree that he wants to go there . our belief - net thinks he wants to go there , in the , , whatever , if we have something like this here , and maybe here also some
A: you should probably make them out of
B: something like that , then we would , "" aha ! he , our belief - net , has stronger beliefs that he wants to know where it is , than actually wants to go there . ""
C: that it doesn't this assume , though , that they 're evenly weighted ? they are evenly weighted .
A: the different decision nodes , you mean ?
C: the go - there , the info - on , and the location ?
A: , this is making the assumption .
B: what do you mean by "" differently weighted "" ? they don't feed into anything really anymore .
A: but , why do we if we trusted the go - there node more th much more than we trusted the other ones , then we would conclude , even in this situation , that he wanted to go there . so , in that sense , we weight them equally
C: so the but the the question that was as er wondering or maybe robert was proposing to me is how do we make the decision on as to which one to listen to ?
A: so , the final decision is the combination of these three . so again , it 's it 's some ,
C: bayes - net . so , then , the question so then my question is to you then , would be so is the only reason we can make all these smaller bayes - nets , because we know we can only deal with finite set of constructions ? cuz oth if we 're just taking arbitrary language in , we couldn't have node for every possible question ,
A: decision node for every possible question , you mean ?
C: like , in the case of . in the ca any piece of language , we wouldn't be able to answer it with this system , if we just cuz we wouldn't have the correct node . what you 're proposing is where - is node , and and if we and if someone says , , , something in mandarin to the system , we 'd - wouldn't know which node to look at to answer that question , so , but if we have finite
B: don't see your point . what what am thinking , or what we 're about to propose here is we 're always gonna get the whole list of values and their posterior probabilities . and now we need an expert system or belief - net that interprets that , that looks the values and says , "" the winner is timing . now , go there . "" "" , go there , timing , now . "" or , "" the winner is info - on , function - off . "" so , he wants to know something about it , and what it does . regardless of of the input . wh - regardle
C: but but how does the expert but how does the expert system know how who which one to declare the winner , if it doesn't know the question it is , and how that question should be answered ?
B: based on the what the question was , so what the discourse , the ontology , the situation and the user model gave us , we came up with these values for these decisions .
C: know . but how do we weight what we get out ? as , which one which ones are important ? so my so , if we were to it with bayes - net , we 'd have to have node for every question that we knew how to deal with , that would take all of the inputs and weight them appropriately for that question . does that make sense ?
A: , are you saying that , what happens if you try to scale this up to the situation , or are we just dealing with arbitrary language ? is that your point ?
C: no . my question is , is the reason that we can make node or . so , lemme see if 'm confused . are we going to make node for every question ? does that make sense ?
A: for every question ? don't not necessarily , would think . it 's not based on constructions , it 's based on things like , , there 's gonna be node for go - there or not , and there 's gonna be node for enter , view , approach .
C: so , someone asked question . how do we decide how to answer it ?
B: look at look face yourself with this pr question . you get this you 'll have this is what you get . and now you have to make decision . what do we think ? what does this tell us ? and not knowing what was asked , and what happened , and whether the person was tourist or local , because all of these factors have presumably already gone into making these posterior probabilities . what what we need is just mechanism that says , "" aha ! there is ""
C: don't think "" winner - take - all "" type of thing is the
A: in general , like , we won't just have those three , we 'll have , , like , many nodes . so we have to , like so that it 's no longer possible to just look at the nodes themselves and figure out what the person is trying to say .
B: because there are interdependencies , no . so if , the go - there posterior possibility is so high , , if it 's if it has reached certain height , then all of this becomes irrelevant . so . if even if the function or the history is scoring pretty good on the true node , true value
C: cuz that would suggest that
B: he wants to go there and know something about it ?
C: do they have to be mutual do they have to be mutually exclusive ?
B: to some extent they are . or maybe they 're not .
C: cuz , the way you describe what they meant , they weren't mutu , they didn't seem mutually exclusive to me .
B: if he doesn't want to go there , even if the enter posterior proba go - there is no . enter is high , and info - on is high .
C: , just out of the other three , though , that you had in the those three nodes . the - they didn't seem like they were mutually exclusive .
B: no , there 's no . it 's through the
C: so th so , , but some so , some things would drop out , and some things would still be important . but what 's confusing me is , if we have bayes - net to deal another bayes - net to deal with this , is the only reason , so , , if we have ba - another bayes - net to deal with this , the only reason we can design it is cuz we each question is asking ?
A: that 's true .
C: and then , so , the only reason way we would question he 's asking is based upon so if let 's say had construction parser , and plug this in , would each construction the communicative intent of the construction was and so then would know how to weight the nodes appropriately , in response . so no matter what they said , if could map it onto where - is construction , could say , "" ! the intent , here , was where - is "" , and could look at those .
A: you do need to know , to have that information .
B: 'm also agreeing that simple pru take the ones where we have clear winner . forget about the ones where it 's all middle ground . and just hand over the ones where we have winner . because that would be the easiest way . we just compose as an output an xml mes message that says . "" go there now . "" "" enter historical information . "" and not care whether that 's consistent with anything . but in this case if we say , "" definitely he doesn't want to go there . he just wants to know where it is . "" or let 's call this "" look - at - "" he wants to know something about the history of . so he said , "" tell me something about the history of that . "" now , the but for some reason the endpoint - approach gets really high score , too . we can't expect this to be at point three , three , point , three , three , three . somebody needs to zap that . or know there needs to be some knowledge that
C: we , but , the bayes - net that would merge realized that had my hand in between my mouth and my micr er , my and my microphone . so then , the bayes - net that would merge there , that would make the decision between go - there , info - on , and location , would have node to tell you which one of those three you wanted , and based upon that node , then you would look at the other . does that make sense ?
B: it 's one of those , that 's it 's more like decision tree , if you want . you first look at the lowball ones ,
C: didn't intend to say that every possible there was confusion there , didn't intend to say every possible thing should go into the bayes - net , because some of the things aren't relevant in the bayes - net for specific question . like the endpoint is not necessarily relevant in the bayes - net for where - is until after you 've decided whether you wanna go there or not . show us the way , bhaskara .
A: the other thing is that , . when you 're asked specific question and you don't even like , if you 're asked where - is question , you may not even look like , ask for the posterior probability of the , , eva node , cuz , that 's what , in the bayes - net you always ask for the posterior probability of specific node . you may not even bother to compute things you don't need .
B: aren't we always computing all ?
A: you can compute , , the posterior probability of one subset of the nodes , given some other nodes , but ignore some other nodes , also . things you ignore get marginalized over .
B: but that 's that 's just shifting the problem . then you would have to make decision ,
A: so you have to make
B: "" , if it 's where - is question , which decision nodes do query ? ""
A: but would think that 's what you want to do .
D: eventually , you still have to pick out which ones you look at . so it 's the same problem ,
B: it 's it 's apples and oranges . maybe it does make difference in terms of performance , computational time . so either you always have it compute all the posterior possibilities for all the values for all nodes , and then prune the ones you think that are irrelevant , or you just make @ @ priori estimate of what you think might be relevant and query those .
C: so , you 'd have decision tree query , go - there . if if that 's false , query this one . if that 's true , query that one . and just do binary search through the ?
A: if it would necessarily be that , , complicated .
C: in the case of go - there , it would be . cuz if you needed an if if go - there was true , you 'd wanna endpoint was . and if it was false , you 'd wanna look at either lo - income info - on or history .
A: that 's true , . so , in way you would have that .
C: also , 'm somewhat boggled by that hugin software .
A: why 's that ?
C: 't figure out how to get the probabilities into it . like , 'd look at it 's somewha it 's boggling me .
A: hopefully it 's fixable . it 's there 's
C: . haven't figured out what the terms in hugin mean , versus what java bayes terms are .
B: , are do we know whether jerry and nancy are coming ?
A: so we can figure this out . they should come when they 're done their , , whenever that is .
C: what what do they need to do left ?
A: jerry needs to enter marks , but if he 's gonna do that now or later . but , , if he 's gonna enter marks , it 's gonna take him awhile , , and he won't be here .
C: and what 's nancy doing ?
A: she was sorta finishing up the , , calculation of marks and assigning of grades , but if she should be here . or , she should be free after that , assuming she 's coming to this meeting . if she knows about it .
C: she 's on the email list ,
B: what where we also have decided , prior to this meeting is that we would have rerun of the three of us sitting together sometime this week again and finish up the , , values of this . so we have , believe it or not , we have all the bottom ones here .
D: you added bunch of nodes , for ?
B: we we have actually what we have is this line .
C: what do the , , structures do ? so the , this location node 's got two inputs ,
A: those are the bottom things are inputs , also .
C: that makes lot more sense to me now . cuz it was like , that one in stuart 's book about , , the
A: alarm in the dog ?
C: or the earthquake and the alarm .
A: , 'm confusing two .
C: there 's dog one , too , but that 's in java bayes , but there 's something about bowel problems with the dog .
B: and we have all the top ones , all the ones to which no arrows are pointing . what we 're missing are the these , where arrows are pointing , where we 're combining top ones . so , we have to come up with values for this , and this , this , and . and maybe just fiddle around with it little bit more . and then it 's just , , edges , and , , we won't meet next monday .
C: cuz of memorial day ?
A: we 'll meet next tuesday , .
C: when 's jerry leaving for italia ?
B: on on friday . this this friday .
C: as in , four days ? or , three days ?
A: is he how long is he gone for ? what 's , what 's there ?
B: it 's country .
C: but it 's not conference or anything . he 's just visiting .
A: it 's pretty place , in my brief , , encounter with it .
B: . so . part of what we actually want to do is schedule out what we want to surprise him with when he comes back .
C: we should disappoint him .
B: you or have finished construction parser and working belief - net ,
C: that wouldn't be disappointing . we should do no work for the two weeks that he 's gone .
B: that 's actually what had planned , personally . had had scheduled out in my mind that you guys do lot of work , and do nothing .
C: , that sounds good , too .
B: bask in your glory . but , , do you guys have any vacation plans , because myself am going to be , , gone , but this is actually not really important . just this weekend we 're going camping .
C: 'm wanna be this gone this weekend , too .
B: but we 're all going to be here on tuesday again ? looks like it ? then . let 's meet again next tuesday . and , , finish up this bayes - net . and once we have finished it , we can , and that 's going to be more just you and me , because bhaskara is doing probabilistic , recursive , structured , object - oriented , ,
C: killing , reasoning . what 's the difference ?
D: so you 're saying , next tuesday , is it the whole group meeting , or just us three working on it , or ?
B: the whole group . and we present our results ,
D: so , when you were saying we need to do re - run of , like what like , just working out the rest of the
B: we should do this th the upcoming days . so , this week , .
C: when you say , "" the whole group "" , you mean the four of us , and keith ?
B: and , ami might .
C: ami might be here , and it 's possible that nancy 'll be here ?
B: because , th , once we have the belief - net done
C: you 're just gonna have to explain it to me , then , on tuesday , how it 's all gonna work out .
B: because then , once we have it up and running , then we can start , defining the interfaces and then feed into it and get out of it , and then hook it up to some fake construction parser
C: that you will have in about nine months or so . the first bad version 'll be done in nine months .
B: worry about the ontology interface and you can keith can worry about the discourse . this is pretty , , hope everybody knows that these are just going to be dummy values , so if the endpoint if the go - there is yes and no , then go - there - discourse will just be fifty - fifty .
A: what do you mean ? if the go - there says no , then the go - there is
D: don't get it .
A: like , the go - there depends on all those four things .
B: but , what are the values of the go - there - discourse ?
A: it depends on the situation . if the discourse is strongly indicating that
B: but , , we have no discourse input .
A: see . the see , , specifically in our situation , and are gonna be , so , whatever .
D: so , so far we have is that what the keith node is ? and you 're taking it out ? for now ?
B: this , get it in here .
D: all the 's are
B: get it in here , so th we have the , , , sk let 's let 's call it "" keith - johno there is an somewhere printed .
C: there you go .
A: people have the same problem with my name .
C: does th does the go before the or after the ?
A: in my name ?
C: cuz you kn when you said people have the same problem , cuz my goes after the the
A: people have the inverse problem with my name .
C: always have to check , every time send you an email , past email of yours , to make 'm spelling your name correctly .
A: that 's good .
C: worry about you .
B: but , when you abbreviate yourself as the "" basman "" , you don't use any 's .
A: "" basman "" ? it 's because of the chessplayer named michael basman , who is my hero .
C: you 're geek . how do you pronou how do you pronounce your name ? what if were what if were to call you eva ?
D: 'd probably still respond to it . 've had people call me eva ,
C: no , not just eva , eva . like if take the and pronounce it like it was german ?
D: no idea then .
C: it sounds like an . there 's also an in german ,
B: it 's just the difference between voiced and unvoiced .
C: as long as that 's . might slip out and say it accidentally . that 's all 'm saying .
D: that 's fine .
A: it doesn't matter what those nodes are , anyway , because we 'll just make the weights "" zero "" for now .
B: we 'll make them zero for now , because it who knows what they come up with , what 's gonna come in there . should we start on thursday ? and not meet tomorrow ? 'll send an email , make time suggestion .
C: maybe it 's , so that that we can that we have one node per construction . cuz even in people , like , they what you 're talking about if you 're using some strange construction .
B: they would still get the closest , best fit .
C: , but , the , , that 's what the construction parser would do . , if you said something completely arbitrary , it would find the closest construction , but if you said something that was completel er theoretically the construction parser would do that but if you said something for which there was no construction whatsoever , people wouldn't have any idea what you were talking about . like "" bus dog fried egg . "" .
B: or , if even something chinese , .
C: or , something in mandarin , . or cantonese , as the case may be . what do you think about that , bhaskara ?
A: but how many constructions do could we possibly have nodes for ?
C: in this system , or in
A: no , we . like , when people do this thing .
C: when how many constructions do people have ? have not the slightest idea .
A: is it considered to be like in are they considered to be like very , , abstract things ?
C: every noun is construction .
A: so it 's like in the thousands .
C: any any form - meaning pair , to my understanding , is construction . and form starts at the level of noun or actually , maybe even sounds . until you get the ditransitive construction . and then , , the , maybe there can be the can there be combinations of the dit
A: discourse - level constructions .
C: the "" giving speech "" construction ,
B: but , , , you can probably count the ways .
C: it 's probab , would definitely say it 's finite . and at least in compilers , that 's all that really matters , as long as your analysis is finite .
A: how 's that ? {nonvocalsound} how it can be finite , again ?
C: nah , 't think of way it would be infinite .
B: you can come up with new constructions .
C: if the if your brain was non - deterministic , then perhaps there 's way to get , , infin an infinite number of constructions that you 'd have to worry about .
A: but , , in the {nonvocalsound} practical sense , it 's impossible .
C: right . cuz if we have fixed number of neurons ? so the best - case scenario would be the number of constructions or , the worst - case scenario is the number of constructions equals the number of neurons .
A: two to the power of the number of neurons .
C: but still finite . not necessarily , is it ? we can end the meeting . can't you use different var different levels of activation ? across , lots of different neurons , to specify different values ?
A: , but there 's , like , certain level of
C: there 's bandwidth issue ,
A: bandw - , so you can't do better than something .
B: turn off the mikes . otherwise it gets really tough for the tr
","The focus of the meeting was on a presentation of the work done already on the building of the Bayes-net.
The input layer deriving information from things like the user and situation models , feeds into a set of decision nodes , such as the Enter/View/Approach ( EVA ) endpoint.
In any particular situation , most of the outputs will not be relevant to the given context.
Therefore , they will either have to be pruned a posteriori , or only a subset of the possible decision nodes will be computed in each occasion.
The latter option could could follow a binary search-tree approach and it could also be better in computational terms.
In any case , on what basis the ""winner"" output is chosen is not clear.
One suggestion was discussed: the particular constructions used can determine the pertinent decision ( output ) nodes.
The complete prototype of the Bayes-net will be presented in the next meeting.
After that , it will be possible to define interfaces and a dummy construction parser , in order to test and link modules together.
The suggestion that the most appropriate decision node of the belief-net in each situation could be chosen as a function of what construction was used , was deemed unsuitable at this stage.
There are many interdependencies between the output nodes that this approach could not take into account.
The rest of the values for the Bayes-net nodes will be built in within the week.
The finished prototype will be presented during the next meeting.
Any set of inputs will provide either the whole range of output values of the Bayes-net or an a priori selection of those outputs.
In both cases , what is needed is a way to single out the appropriate outputs for any given context.
For example , in the case of a ""where is"" question , whether the prevalent output should be ""Go-there"" or ""Info-on"" or even a third option has to be computed somehow.
In any case , there are many input values that have not been entered in the Bayes-net at this stage.
Furthermore , no inputs for the Ontology and Discourse can be built in yet , as they involve research that will be carried out in the future.
Finally , there has been a problem with adding probabilities in a net created with the Hugin software , but this should be overcome very shortly.
The presented Bayes-net takes inputs from the Situation , User , Discourse and Ontology models.
There are several values ( elements ) defined in each of these models.
The inputs are fed into the belief-net , which , in turn , outputs the posterior probabilities for the values of all the decision nodes.
These comprise ""Go-there"" , ""EVA"" , ""Info-on"" , ""Location"" , ""Timing"" , etc.
At this stage , all the decision nodes are evenly weighted: regardless of the context , each output is trusted equally.
Input and output node structure was presented in XML , as this is the format that will be used for the system.
A large number of the value probabilities have already been set.
"
ami_abstractive_summary,Bmr003.txt,"A: this is one channel . can you , say your name and talk into your mike one at time ?
C: this is eric on channel three , believe .
A: don't 's on there , jane .
D: tasting one two three , tasting .
E: this is jane on channel five .
A: still don't see you jane .
E: darn , what am doing wrong ?
D: can you see me on channel four ? my lucky day .
E: maybe it just warmed up ? can you can't see channel five yet ?
A: , the mike isn't close enough to your mouth ,
E: is that better ?
A: try speaking loudly ,
D: like the high quality labelling . david , can we borrow your labelling machine to improve the quality of the labelling little bit here ? how how many are there , one to five ?
E: would you like to join the meeting ?
A: we don't wanna renumber them , cuz we 've already have like , forms filled out with the numbers on them . so , let 's keep the same numbers on them .
B: that 's good idea .
A: dan , are you on ?
B: 'm on 'm on two and should be on .
D: want to join the meeting , dave ? do we do we have spare ,
A: and 'm getting lots of responses on different ones , so assume the various and assorted ms are on .
D: we ' we 're we ' this is this is meeting .
E: this is abou we 're we 're mainly being taped but we 're gonna talk about , , transcription for the future meeting meetings .
A: this is not something you need to attend .
C: you 're always having one of those days , dave .
E: you 'd be welcome .
A: besides , don't want anyone who has weird accent .
E: you 'd be welcome .
A: right , dan ?
D: so , don't understand if it 's neck mounted you don't get very good performance .
C: it 's not neck mounted . it 's supposed to be head mounted .
D: it it should be head mounted .
A: then put it on your head . what are you doing ?
D: cuz when you do this , you can rouww - rouww .
E: why didn't you were saying that but could hear you really on the on the transcription on the , , tape .
A: would prefer that people wore it on their head but they were complaining about it . because it 's not it doesn't go over the ears .
E: it 's badly designed .
A: it 's very badly designed so it 's
B: it 's very badly designed ?
D: what do you mean it doesn't go over the ears ?
B: it 's not it 's not supposed to cover up your ears .
A: but , there 's nowhere to put the pad so it 's comfortable .
B: it 's only badly
E: so that 's what you 're he 's got it on his temples so it cuts off his circulation .
B: that 's strange .
C: that 's that 's what have .
A: and it feels so good that way .
C: it feels so good when stop .
A: so again would like to do some digits .
D: somebody wanna close the door ?
E: we could do it with noise .
C: you 're always doing digits .
A: , 'm just that digit - sorta guy . so this is adam .
E: this is the same one had before .
B: it 's still the same words .
A: we 're session four . or it might be five .
D: that 's good .
A: didn't bring my previous thing .
E: now , just to be , the numbers on the back , this is the channel ?
B: that 's the microphone number .
E: that 's the microphone number .
A: leave the channel blank .
D: but number has to be ? so we have to look up the number .
E: this is jane , on mike number five . do need to say anything more ?
C: this is eric on microphone number three ,
D: this is beck on mike four .
A: should turn off the vu meter dan ? do you think that makes any difference ?
B: no , let me do it .
A: are you gonna do something other than hit "" quit "" ?
B: but 'm gonna look at the , logs as .
A: should have done it before .
E: you said turn off the what ?
A: the vu meter which tells you what the levels on the various mikes are and there was one hypothesis that perhaps that the act of recording the vu meter was one of the things that contributed to the errors .
D: but eric , , you didn't think that was reasonable hypothesis , right ?
A: that was me ,
D: that was malarkey .
A: the only reason that could be is if the driver has bug . because the machine just isn't very heavily loaded .
D: no chance of that .
A: no chance of that . just because it 's beta .
B: there there was there was bug . there was glitch last time we ran .
D: are - are yo are you recording where the table mikes are ?
A: we usually do that .
B: no , we don't . but we ought to st we ought to standardize . , spoke to somebody , morgan , about that . we should put mar , no , we can do that .
D: why don't you just do this ?
A: that 's what we 've done before .
B: they 're they 're four , three , two , one . in order now . two , and one . but we should put them in standard positions . we should make little marks on the table top .
A: which means we need to move this thing , and sorta decide how we 're actually going to do things .
B: so that we can put them that 's the point . it 'll be lot easier if we have if we have them permanently in place like that .
E: do wish there were big booms coming down from the ceiling .
C: would it make you feel more important ?
D: till the projector gets installed .
A: that 'll work .
E: that 'll be good .
A: that 'll work .
D: cuz it 's gonna hang down , make noise .
B: when 's it gonna be installed ?
D: is this is this being recorded ?
A: that 's right .
D: lila actually is almost getting pretty close to even getting ready to put out the purchase order . handed it off to her about month ago .
A: topic of this meeting is wanna talk little bit about transcription . 've looked little bit into commercial transcription services and jane has been working on doing transcription . and so we wan wanna decide what we 're gonna do with that and then get an update on the electronics , and then , , maybe also talk little bit about some infrastructure and tools , and so on . , eventually we 're probably gonna wanna distribute this thing and we should decide how we 're gonna how we 're gonna handle some of these factors . so we 're we 're collecting corpus and it 's gonna be generally useful . it seems like it 's not corpus which is , has been done before . and so people will be interested in having it , and so we will
D: using , like , audio ds like that ?
A: and and so how we do we distribute the transcripts , how do we distribute the audio files , how do we how do we just do all that infrastructure ?
C: , for that particular issue ther there are known sources where people go to find these things like the ldc .
A: but so should we do it in the same format as ldc
E: that 's right .
A: and what does that mean to what we 've done already ?
B: it 's not so much the actu the logistics of distribution are secondary to preparing the data in suitable form for distribution .
A: as it is , it 's ad - hoc combination of dan set and set up , which we may wanna make little more formal .
B: and the other thing is that , , university of washington may want to start recording meetings as , in which case we 'll have to decide what we 've actually got so that we can give them copy .
A: that 's right . was actually thinking wouldn't mind spending the summer up there . that would be fun . visit my friends and spend some time
B: different for you .
A: and then also have bunch of for doing this digits . so have bunch of scripts with waves , and some perl scripts , and other things that make it really easy to extract out and align where the digits are . and if uw 's going to do the same thing it 's worth while for them to do these digits tasks as . and what 've done is pretty ad - hoc , so we might wanna change it over to something little more standard . stm files , or xml , .
D: an - and there 's interest up there ?
A: what 's that ?
D: there 's interest up there ?
A: they certainly wanna collect more data . and so they 're applying , is that right ? something like that . for some more money to do more data . so we were planning to do like thirty or forty hours worth of meetings . they wanna do an additional hundred or so hours . so , they want very large data set . but we 're not gonna do that if we don't get money . and would like that just to get disjoint speaker set and disjoint room . one of the things morgan and were talking about is we 're gonna get to know this room really , the acoustics of this room .
B: all about that .
D: including the fan .
A: including the fan .
D: did you notice the fan difference ?
B: now you 've touched the fan control , now all our data 's gonna be
D: hear the difference ?
A: it 's enormous .
B: it 's great .
E: that 's better .
D: do you wanna leave it off or not ?
E: that 's better .
A: all the others have been on .
D: things after the then this fan 's wired backwards . this is high speed here .
E: it 's noticeable .
B: it 's like "" low "" is mid - scale .
D: maybe it maybe it isn't .
B: so it could be that it 's not actually wired backwards
D: that 's right .
B: it 's just that ambiguous .
D: was wondering also , get ready . whether the lights made any noise . so , do our meetings in the dark with no air conditioning in the future .
A: just get variety .
E: candles would be if they don't make noise .
A: they 're very good .
C: it would , it would real really mean that we should do short meetings when you turn off the turn off the air conditioning ,
A: carbon monoxide poisoning ?
D: that 's right .
C: got to finish this meeting .
D: tear tear your clothing off to stay .
C: that 's right .
D: actually , the th air the air conditioning 's still working , that 's just an auxiliary fan .
C: in addition to this issue about the uw there was announced today , , via the ldc , , corpus from believe santa barbara .
E: 've been watching for that corpus .
C: of general spoken english . and exactly how they recorded it but there 's lot of different styles of speech and what not .
E: they had people come in to certain degree and they and they have dat recorders .
C: so it is far field .
E: assume so , actually , hadn't thought about that . unless they added close field later on but , , 've listened to some of those data and , , 've been was actually on the advisory board for when they set the project up .
B: what 's it sound like ?
E: 'm glad to see that it got released . so it 's very thing .
A: wish we had someone here working on adaptation because it would to be able to take that and adapt it to meeting setting .
C: but it may be it may be useful in
E: how do you mean do you mean mechanical adaptation or
A: to adapt the speech recognition .
C: what was thinking is it may be useful in transcribing , if it 's far field , in doing , , some of our first automatic speech recognition models , it may be useful to have that data because that 's very different than any data that we have so far .
A: that 's true .
E: and and their recording conditions are really clean . 've 've heard 've listened to the data .
A: that 's not good , right ?
C: that 's that 's not great .
E: but what is that ,
D: but far field means great distance ? not head mounted ? and so that 's why they 're getting away with just two channels , or are they using multiple dats ?
E: and 't ans answer it .
A: we can look into it .
C: no , and their web their web page didn't answer it either . so 'm , , was thinking that we should contact them . so it 's that 's beside - the - point .
A: so we can get that just with , , media costs , is that right ?
C: we get it for free cuz they 're distributing it through the ldc .
A: so that would be , that would be something to look into .
C: so , actually arrange for it to arrive in short order if we 're
E: the other thing too is from
A: it 's silly to do unless we 're gonna have someone to work on it , so maybe we need to think about it little bit .
E: the other thing too is that their jus their transcription format is really and simple in the discourse domain . but they also mentioned that they have it time aligned . saw that write - up .
C: maybe we should maybe we should get copy of it just to see what they did so that we can we can compare .
E: it 's very .
A: why don't you go ahead and do that then eric ?
C: alright , 'll do that . 't remember the name of the corpus . it 's corps -
E: corpus of spoken american english . sp 've been was really pleased to see that . knew that they had some funding problems in completing it this is clever .
C: this was like phase one
E: got it through the ldc .
C: and the there 's still more that they 're gonna do like that unless they have funding issues and then it ma they may not do phase two but from all the web documentation it looked like , "" , this is phase one "" , whatever that means .
E: that , they 're really respected in the linguistics side too and the discourse area , so this is very good corpus .
C: but , it it would also maybe help be helpful for liz , if she wanted to start working on some discourse issues , , looking at some of this data and then , so when she gets here maybe that might be good thing for her .
A: actually , that 's another thing was thinking about is that maybe jane should talk to liz , to see if there are any transcription issues related to discourse that she needs to get marked .
C: maybe we should have big meeting .
D: that would be meeting ?
A: this is the meeting about the meeting .
C: but maybe we should , find some day that liz , liz and andreas seem to be around more often . so maybe we should find day when they 're gonna be here and morgan 's gonna be here , and we can meet , at least this subgroup . not necessarily have the - dub people down .
A: was even thinking that maybe we need to at least ping the - dub to see
C: we need we need to talk to them some more .
A: say "" this is what we 're thinking about for our transcription "" , if nothing else . so , shall we move on and talk little bit about transcription then ? so since that 's what we 're talking about . what we 're using right now is tool , , from this french group , called "" transcriber "" that seems to work very . so it has , , useful tcl - tk user interface
D: thi - this is the process of converting audio to text ? and this requires humans just like the stp .
A: right , right . so we 're we 're at this point only looking for word level . so all so what you have to do is just identify segment of speech in time , and then write down what was said within it , and identify the speaker . and so the things we that we know that want are the text , the start and end , and the speaker . but other people are interested in stress marking . and so jane is doing primary stress , , stress marks as . and then things like repairs , and false starts , and , filled pauses , and all that other , we have to decide how much of that we wanna do .
E: did include glo , certain first pass . my my view on it was when you have repair then , it seems we saw , there was this presentation in the one of the speech group meetings about how and liz has done some too on that , that it , that you get it bracketed in terms of like if it 's parenthetical , which know that liz has worked on , then you 'll have different prosodic aspects . and then also if it 's if it 's repair where they 're like what did , then it 's to have sense of the continuity of the utterance , the start to be to the finish . and , , it 's little bit deceptive if you include the repai the pre - repair part and sometimes or of it 's in the middle . anyway , so what was doing was bracketing them to indicate that they were repairs which isn't , very time - consuming .
D: is there already some plan in place for how this gonna be staffed or done ? or is it real is that what we 're talking about here ?
A: that 's part of the thing we 're talking about . so what we wanted to do was have jane do one meeting 's worth , forty minutes to an hour ,
E: as pilot study .
D: it this is like five times real time or ten times real time
E: as pilot study .
A: ten times about , is and so one of the things was to get an estimate of how long it would take , and then also what tools we would use . and so the next decision which has to be made actually pretty soon is how are we gonna do it ?
D: and so you make jane do the first one so then she can decide , , we don't need all this , just the words are fine .
E: that 's right , that 's right .
B: that 's right .
E: wanna hear about these , we have you were continuing with the transcription conventions for
A: so one option is to get linguistics grad students and undergrads to do it . and that 's happened in the past . and that 's probably the right way to do it . it will require post pass , people will have to look at it more than once to make that it 's been done correctly , but can't imagine that we 're gonna get anything that much better from commercial one . and the commercial ones 'm will be much more expensive .
D: can't we get joy to do it all ?
E: no , that 's
A: we will just get joy and jane to do everything .
D: is tha wasn't that what she was doing before ? that 's right .
A: but , , that 's what we 're talking about is getting some slaves who need money
E: object to that characterization !
A: and so again , have to say "" are we recording "" and then say , , morgan has consistently resisted telling me how much money we have .
D: the answer is zero . there 's reason why he 's resisted .
A: if it 's zero then we can't do any transcription . cuz we 're we
B: have such hard name .
A: 't imagine us doing it ourselves .
D: we already we already we already have plan in place for the first meeting .
E: th there is als there is also the other possibility which is if you can provide not money but instructional experience or some other perks , you can you could get people to , to do it in exchange .
D: but , , morgan 's in bind over this and thing to do is just the field of dreams theory , which is we go ahead as though there will be money at the time that we need the money . and that 's that 's the best we can do . to not do anything until we get money is ridiculous . we 're not gonna do any get anything done if we do that .
A: so at any rate , jane was looking into the possibility of getting students , at is that right ? talking to people about that ?
E: 'm afraid haven't made any progress in that front yet . should 've sent email and haven't yet .
D: do so until you actually have little experience with what this french thing does we don't even have
A: she 's already done quite bit .
E: have bunch of hours ,
D: so that 's where you came up with the the ten number ? or is that really just ?
E: actually that 's the one people usually use , ten .
C: how fast are you ?
E: and haven't really calculated how fast am ? see , 've been at the same time doing boot strapping in deciding on the transcription conventions that are , and like , , how much there 's some interesting human factors problems like , , what span of time is it useful to segment the thing into in order to , transcribe it the most quickly . cuz then , , you get like if you get span of five words , that 's easy . but then you have to take the time to mark it . and then there 's the issue of it 's easier to hear it th right the first time if you 've marked it at boundary instead of somewhere in the middle , cuz then the word 's bisected or whatever so , 've been playing with , , different ways of mar cuz 'm thinking , , , if you could get optimal instructions you could cut back on the number of hours it would take .
D: does this tool you 're using is strictly it doesn't do any speech recognition does it ?
E: no , it doesn't but what super tool . it 's great environment .
D: but but is there anyway to wire speech recognizer up to it and actually run it through
E: that 's an interesting idea .
A: we 've we 've thought about doing that but the recognition quality is gonna be horrendous .
D: first of all the time marking you 'd get you could get by tool .
B: that 's true .
D: and so if the if the issue really
E: that 's interesting .
D: 'm think about the close caption that you see running by on live news casts .
A: most of those are done by person .
D: no , understand . and in lot of them you see typos and things like that , but it but it occurs to me that it may be lot easier to correct things than it is to do things from scratch , no matter how wonderful the tool is . but if there was way to merge the two
C: , but sometimes it 's easier to type out something instead of going through and figuring out which is the right
A: we 've talked about it
E: that 'd be fun .
C: it depends on the error rate ,
D: but again the timing is for fr should be for free . the timing should be
C: but we don't care about the timing of the words .
D: you just that 's said that was critical issue .
A: we don't care about the timing of the words , just of the utterances .
B: we don't we , actually . we haven't decided which time we care about , and that 's one of the things that you 're saying , is like you have the option to put in more or less timing data and , , be in the absence of more specific instructions , we 're trying to figure out what the most convenient thing to do is .
A: so what she 's done so far , is more or less breath not breath groups , phrases , continuous phrases . and so , , that 's because you separate when you do an extract , you get little silence on either end . so that seems to work really .
E: that 's ideal . although was , the alternative , which was experimenting with before ran out of time , recently was , that , , ev if it were like an arbitrary segment of time pre - marked cuz it does take time to put those markings in . it 's really the the interface is wonderful because , , the time it takes is you listen to it , and then you press the return key . but then , , it 's like , , you press the tab key to stop the flow and , , the return key to to put in marking of the boundary . but , , there 's lag between when you hear it and when you can press the return key so it 's slightly delayed , so then you listen to it second time and move it over to here . so that takes time . now if it could all be pre - marked at some , , good
D: are are those delays adjustable ? those delays adjustable ? see lot of people who actually build with human computer interfaces understand that delay , and so when you by the time you click it 'll be right on because it 'll go back in time to put the
B: it could do that
E: not in this case .
A: we could program that pretty easily , couldn't we dan ? mis mister tcl ?
B: would have thought so ,
E: ! interesting point . that would make difference . it 's not bad
A: but , if we tried to do automatic speaker id .
E: but it does take twice .
A: cuz primarily the markings are at speaker change . but that would be
B: but we 've got we 've got the most channel data . we 'd have to do it from your signal . we 've we 've got lot of data .
A: the question is how much time will it really save us versus the time to write all the tools to do it .
E: we 've got volume .
B: but the chances are if we 're talking about collecting ten or hundred hours , which is going to take hundred or thousand hours to transcribe
D: if we can go from ten to five we 're doing big
A: we 're gonna need we 're gonna need ten to hundred hours to train the tools , and validate the tools the do the to do all this anyway .
B: if we 're just doing silence detection
E: but but it op
A: knew you were gonna do that . just saw it coming .
E: wish you had told me wish you 'd told me .
D: put put it on your sweater .
E: at what part ?
B: it 's it 's maybe like week 's work to get to do something like this . so forty or fifty hours .
E: could you get it so that with so it would it would detect volume on channel and insert marker ? and the format 's really transparent . it 's just matter of very clear it 's xml , isn't it ? it 's very , looked at the file format and it 's just it has time time indication and then something or other , and then an end time or other .
C: maybe we could try the following experiment . take the data that you 've already transcribed
D: is this already in the past or already in the future ?
C: already in the past .
D: you 've already you 've already done some ?
A: she 's she 's done about half meeting .
C: she she 's done one she 's one
D: - , see .
E: 'm not if it 's that 's much but anyway , enough to work with .
C: and throw out the words , but keep the time markings . and then go through , and go through and try and re - transcribe it , given that we had perfect boundary detection . and see if it see if it feels easier to you .
D: and forgetting all the words because you 've been thr
E: that 's what was thinking . 'd 'd be cheating little bit with familiarity effect .
C: , that 's part of the problem is , is that what we really need is somebody else to come along .
B: no , you should do it you should do it do it again from scratch and then do it again at the boundaries . so you do the whole thing three times and then we get
E: now , there 's plan .
D: and then since we need some statistics do it three more . and so you 'll get you 'll get down to one point two by the time you get done .
E: 'll do that tomorrow . should have it finished by the end of the day .
D: no , but the fact that she 's she 's did it before just might give lower bound . that 's all . which is fine . and if the lower bound is nine then it 's waste of time .
E: but there 's an extra problem which is that didn't really keep accurate it wasn't pure task the first time , so , it 's gonna be an upper bound in that case . and it 's not really strictly comparable . so though it 's good proposal to be used on new new batch of text that haven't yet done yet in the same meeting . could use it on the next segment of the text .
B: the point we where do we get the the oracle boundaries from ? or the boundaries .
A: one person would have to assign the boundaries and the and the other person would have to
E: but couldn't do it for the next
B: we we could get fake
A: that 's easy enough .
E: see what you mean .
A: could do that .
E: but the oracle boundaries would come from volume on partic specific channel wouldn't they ?
A: no , no .
B: that would be the automatic boundaries .
C: no , no , no . you wanna know given given perfect human segmentation , , you wanna know how the question is , is it worth giving you the segmentation ?
E: see what you mean .
A: that 's easy enough . could generate the segmentation and you could do the words , and time yourself on it .
D: little double - blind - ear thing .
A: so it that might be worth doing .
E: that 's good .
A: that would at least tell us whether it 's worth spending week or two trying to get tool , that will compute the segmentations .
D: and the thing to keep in mind too about this tool , guys is that , you can do the computation for what we 're gonna do in the future but if uw 's talking about doing two , or three , or five times as much and they can use the same tool , then there 's real multiplier there .
E: and the other thing too is with speaker identification , if that could handle speaker identification that 's big deal .
D: that 's why we bought the expensive microphones .
E: , that 's feature . that 's major that 's like , one of the two things that
C: there 's gonna there 's gonna be in the meeting , like the reading group meeting that we had the other day , that 's it 's gonna be bit of problem because , like , wasn't wearing microphone and there were other people that weren't wearing microphones .
D: but you didn't say anything worth while anyway , right ?
A: it might save ninety percent of the work though .
C: but , yes .
B: so need to we need to look at what the final output is but it seems like we it doesn't it seems like it 's not really not that hard to have an automatic tool to generate the phrase marks , and the speaker , and speaker identity without putting in the words .
A: 've already become pretty familiar with the format ,
E: that 'd be so great .
A: it would be easy . if you 'd tell me where it is , ?
E: we didn't finish the part of work already completed on this , you talked little bit about the transcription conventions , and , you 've mentioned in your progress report , or status report , that you had written script to convert it into so , when the it 's quickest for me in terms of the transcription part to say something like , , if adam spoke to , to just say , "" colon "" , like who could be , , at the beginning of the line . and colon instead of entering the interface for speaker identification and clicking on the thing , , indicating the speaker id . so , and then he has script that will convert it into the thing that , , would indicate speaker id .
A: it 's pretty cute .
E: if that 's clear .
A: but at any rate .
E: it 's perl script .
A: so so the at ten seems to be pretty standard . everyone more or less everyone you talk to says about ten times for hard technical transcription .
D: using wh using stone age using stone age tools .
E: that 's right .
A: using using stone age tools . looked at cyber transcriber
E: that 's true ,
A: which is service that you send an audio file , they do first - pass speech recognition . and then they do clean up . but it 's gonna be horrible . they 're never gonna be able to do meeting like this .
E: what approximately , what did you find out in terms of price or whatever ?
A: for cyber transcriber they don't quote price . they want you to call and talk . so for other services , , they were about thirty dollars an hour .
E: of of tape ? or of action ?
A: for thirty dollars an hour for of their work . so so if it 's ten times it 's three hundred dollars an hour .
C: so that 's three that 's three hours .
D: did you talk to anybody that does closed captioning for , tv ? cuz they usually at the end of the show they 'll tell what the name of the company is , the captioning company that 's doing it .
A: so my search was pretty cursory . it was just net search . and , , so it was only people who have web pages and are doing through that .
D: , the thing the thing about this is thinking , maybe little more globally than should here but that really this could be big contribution we could make . , we 've been through the stp thing , we it what it 's like to manage the manage the process , and admittedly they might have been looking for more detail than what we 're looking for here but it was big hassle , , , they constantly could 've reminding people and going over it . and clearly some new needs to be done here . and it 's it 's only our time , where "" our "" includes dan , dan and you guys . it doesn't include me .
B: if we 'd be able to do any thing to help stp type problems . but certainly for this problem we can do lot better than
D: because they wanted lot more detail ?
B: because they had because they only had two speakers , right ? the segmentation problem is
D: only had two .
A: they had two speakers over the telephone .
D: so what took them so long ?
A: mostly because they were doing much lower level time . so they were doing phone and syllable transcription , as as , , word transcription . and so we 're we decided early on that we were not gonna do that .
D: but there 's still the same issue of managing the process , of reviewing and keeping the files straight , and all this , that which is clearly hassle .
A: and so what 'm saying is that if we hire an external service we can expect three hundred dollars an hour . that 's the ball park . there were several different companies that and the range was very tight for technical documents . twenty - eight to thirty - two dollars an hour .
C: who knows if they 're gonna be able to manage multal multiple channel data ?
B: they they 'll refuse to do it .
A: we 'll have to mix them .
B: no , but , they they won't they will refuse to transcribe this material .
E: and then there 's the problem also that
B: that 's not what they 're quoting for , right ?
A: yes , it is .
D: they might they might quote it
B: for quoting meetings ?
A: sev - several of them say that they 'll do meetings , and conferences , and and so on . none of them specifically said that they would do speaker id , or speaker change mark . they all just said transcription .
D: th - th the th there may be just multiplier for five people costs twice as much and for ten people co something like that .
A: the way it worked is it was scaled . so what they had is , if it 's an easy task it costs twenty - four dollars an hour and it will take maybe five or six times real time . and what they said is for the hardest tasks , bad acoustics , meeting settings , it 's thirty - two dollars an hour and it takes about ten times real time . so that we can count on that being about what they would do . it would probably be little more because we 're gonna want them to do speaker marking .
D: lot of companies 've worked for the , the person leading the meeting , the executive or whatever , would go around the room and mentally calculate how many dollars per hour this meeting was costing , in university atmosphere you get little different thing . it 's lot like , "" he 's worth fifty an hour , he 's worth "" and so he so here we 're thinking , "" let 's see , if the meeting goes another hour it 's going to be another thousand dollars . ""
A: we have to have short meeting .
D: so ch so every everybody ta talk really fast .
E: that 's very interesting .
D: let 's get it over with .
E: talk slowly but with few words .
B: that 's right .
D: only talk when you 're pointed to .
E: there you go .
A: content words only .
E: we could have some telegraphic meetings . that might be interesting .
B: it 'd be cheap . cheap to transcribe .
A: but at any rate , so we have ballpark on how much it would cost if we send it out .
D: and we 're talking about do doing how many hours worth of meetings ?
A: thirty or forty .
D: so thirty or forty thousand dollars .
B: for ten thousand dollars .
D: what , it was thirty times
A: three hundred dollars an hour .
D: got an extra factor of three there .
C: so it 's thirty dollars an hour , essentially , right ? but we can pay graduate student seven dollars an hour . and the question is what 's the difference
B: how how much lower are they ?
C: or ei eight dollars . what do what the going rate is ? it 's it 's on the order of eight to ten .
E: that would give us good estimate .
C: but 'm not .
E: was gonna say eight you 'd say ten ?
C: let 's say ten .
B: give them break .
C: cuz it 's easier .
D: the - these are not for engineering graduate students , right ?
A: these are linguistics grad students .
C: what the what the standard
D: that 's right .
C: but there is standard pay scale what it is .
E: that 's right . that 's right .
C: so that means that even if it takes them thirty times real time it 's cheaper to do graduate students .
E: and there 's another aspect too .
A: that 's why said originally , that couldn't imagine sending it out 's gonna be cheaper .
B: no , it isn't .
E: the other thing too is that , , if they were linguistics they 'd be , in terms of like the post editing , tu content wise they might be easier to handle cuz they might get it more right the first time .
A: and also we would have control of , we could give them feedback . whereas if we do service it 's gonna be limited amount . we can't tell them , , "" for this meeting we really wanna mark stress and for this meeting we want "" and and they 're not gonna provide they 're not gonna provide stress , they 're not gonna re provide repairs , they 're not gonna provide they may or may not provide speaker id . so that we would have to do our own tools to do that .
D: just hypoth hypothetically assuming that we go ahead and ended up using graduate students . who 's the person in charge ? who 's gonna be the steve here ?
A: hope it 's jane . is that alright ?
E: now would this involve some manner of , monetary compensation or would be the voluntary , , coordinator of multiple transcribers for checking ?
A: would imagine there would be some monetary involved but we 'd have to talk to morgan about it .
B: out of out of adam 's pocket .
D: it just means you have to stop working for dave . that 's why dave should have been here .
E: don't wanna stop working for dave .
D: to pr protect his people .
A: would like you to do it because you have lot more experience than do , but if that 's not feasible , will do it with you as an advisor .
D: we 'd like you to do it and we 'd like to pay you .
E: we 'll see .
D: not being morgan though , it 's
B: we 'd like to .
A: six dollars an hour .
E: boy , if wanted to increase my income could start doing the transcribing again .
B: that 's right .
D: an and be and say , would you like fries with that when you 're thinking about your pay scale .
E: no , that would be interested in that in becoming involved in the project in some aspect like that
A: any more on transcript we wanna talk about ?
B: what so what are you so you 've done some portion of the first meeting . and what 's your plan ? to carry on doing it ?
E: what , what was right now we have so gave him the proposal for the transcription conventions . he made his , , suggestion of improvement . the the it 's good suggestion . so as far as 'm concerned those transcription conventions are fixed right now . and so my next plan would be
B: what what do they cover ?
E: they 're very minimal . so , it would be good to just to summarize that . so , , one of them is the idea of how to indicate speaker change , and this is way which meshes with , , making it so that , , , on the at the boy , it 's such interface . when you when you get the , you get the speech signal you also get down beneath it , an indication of , , if you have two speakers overlapping in in single segment , you see them one displayed one above each other . and then at the same time the top part of the screen is the actual verbatim thing . you can clip click on individual utterances and it 'll take you immediately to that part of the speech signal , and play it for you . and you can , you can work pretty between those two these two things .
D: is there limit to the number of speakers ?
A: the user interface only allows two . and so if you 're using their interface to specify overlapping speakers you can only do two . but my script can handle any . and their save format can handle any . and so , , using this the convention that jane and have discussed , you can have as many overlapping speakers as you want .
D: do is this , , university project ? th - this is the french software , right ?
A: and they 're they 've been quite responsive . 've been exchanging emails on various issues .
D: did you ask them to change the interface for more speakers ?
A: and they said that 's on in the works for the next version .
C: so multi multichannels .
A: they said they wanted to do it but that the code is really very organized around single channels . so that 's unlikely to ha happen .
D: do - do what they 're using it for ? why 'd they develop it ?
A: for this exact task ?
D: are they linguists ? but , are they are they linguists or are they speech recognition people ?
A: they 're linguists .
C: they 're they have some connection to the ldc cuz the ldc has been advising them on this process , the linguistic data consortium . but apart from that .
A: it 's also all the source is available . if you if you speak tcltk . and they have they 've actually asked if we are willing to do any development and said , , maybe . so if we want if we did something like programmed in delay , which actually is great idea , , 'm they would want that incorporated back in .
D: their pre - lay .
B: pre - lay .
E: pre - lay . and they 've thought about things . , they do have so you have when you play it back , , it 's it is useful to have , , break mark to se segment it . but it wouldn't be strictly necessary cuz you can use the , the tabbed key to toggle the sound on and off . it 'll stop the speech if you press tab . that 's feature . and then also once you 've put break in then you have the option of cycling through the unit . you could do it like multiply until you get crazy and decide to stop cycling through that unit .
D: yo - you , there 's al also the user interface that 's missing . it 's missing from all of our offices , and that is some analog input like this . it 's what audio people actually use . it 's something that wh when you move your hand further , the sound goes faster past it , like fast forward . or , you could wire mouse or trackball to do something like that .
E: why , that 's that 's not something wanted to have happen .
D: no , but 'm saying if this is what professionals who actually do this thing for for video or for audio where you need to do this , and so you get very good at jostling back and forth , rather than hitting tab , and backspace , and carriage return , and enter , and things like that .
A: we talked about things like foot pedals and other analog so , tho those are things we could do how much it 's worth doing . we 're just gonna have
E: they they have several options . so , , , mentioned the looping option . another option is it 'll pause when it reaches the end of the boundary . and then to get to the next boundary you just press tab and it goes on to the next unit . it 's very nicely thought out . and also it 'll go around the the , , but 'm not if that 's the right thing . anyway , you can so they thought about different ways of having windows that you work within , and but so in terms of the con the conventions , then , , , , it 's strictly orthographic which means with some provisions for , , , colloquial forms . so if person said , "" cuz "" instead of "" because "" then put an apostrophe at the beginning of the word and then in double ang angle brackets what the full lexical item would be . and this could be something that was handled by table but to have convention marking it as non - standard or wha don't mean standard but non , ortho orthographic , , whatever .
A: non - canonical .
E: "" gonna "" or "" wanna "" , the same thing . and and there would be limits to how much refinement you want in indicating something as non - standard pres pronunciation .
C: how are you handling backchannels ?
E: in my view , when when you 've got it densely overlapping , , didn't worry about didn't worry about specific start times .
C: what do you mean by du
E: that this is not gonna be easily processed anyway and maybe shouldn't spend too much time getting exactly when the person said "" no "" , or , , , "" immediate "" . and instead just rendered "" within this time slot , there were two people speaking during part of it and if you want more detail , figure it out for yourself "" ,
A: what what eric was talking about was channels other than the direct speech ,
E: was the way felt @ @
C: what is wh , when somebody says "" - "" in the middle of , , @ @
E: that happened very seldom .
C: cuz was was listening to dan was agreeing lot to things that you were saying as you were talking .
E: if it if there was word like "" right "" , , then wou would indicate that it happened within the same tem time frame
A: there 's an overlapping mark .
E: but wouldn't say exactly when it happened .
D: 'll be right back .
B: transcribed minute of this and there was lot of overlapping .
E: lot of overlapping , .
A: there 's lot of overlapping at the beginning and end .
B: it was at the beginning .
A: when no one when we 're not actually in the meeting , and we 're all separated , and doing things . but even during the meeting there 's lot of overlap but it 's marked pretty clearly . some of the backchannel jane had some comments and but lot of them were because you were at the meeting . and so that often you can't tell .
E: that 's true . that 's another issue .
A: jane had comments like , to who the person was speaking to .
E: only when it was otherwise gonna be puzzling because he was in the other room talking .
A: but someone who , , was just the transcriber wouldn't have known that . or when dan said , "" wa wasn't talking to you "" .
E: that 's true .
D: so you take bathroom break in the middle and keep your head mount
A: you have to turn off your mike .
B: you don't have to .
E: so he was checking the meter levels and we were handling things while he was labeling the whatever it was , and and so he was in you were talking so was saying , like "" and could label this one left . and he and he said , "" don't see anything "" . and he said he said , "" wasn't talking to you "" . or it wasn't it didn't sound quite that rude . but really , no , in the context if he can't hear what he 's saying
A: but when you when you listen to it
D: it was lot funnier if you were there though .
A: what it what happens is if you 're transcriber listening to it sounds like dan is just being total impolite .
E: you 'll see . you can listen to it . it was you who was . no , , but you were you were asking off the wall questions .
A: but but if you knew that wasn't actually in the room , and that dan wasn't talking to me , it became .
E: and that 's that 's where added comments . the rest of the time didn't bother with who was talking to who but this was unusual circum circumstance .
D: so this is this is gonna go on the meeting transcriber bloopers tape , right ?
E: and part of it was funny , reason was because it was mixed signal so you couldn't get any clues from volume that , , he was really far away from this conversation . you couldn't do that symmetrically in any case .
A: should rewrite the mix tool to put half the people in one channel and half in the other . have auto - gain - mixer tool that mixes all the head mounted microphones into one signal
E: that 's good idea .
A: and that seems to work really for the transcribers .
E: but it would be , didn't wanna add more contextual comments than were needed but that , it seemed to me , clarified that the con what was going on .
C: was just gonna ask , , so wanted to finish off the question had about backchannels , if that 's , which was , so say somebody 's talking for while and somebody goes "" - "" in the middle of it , and and what not , does the conversation come out from the or the person who 's speaking for the long time as one segment and then there 's this little tiny segment of this other speaker or does it does the fact that there 's backchannel split the it in two .
E: my focus was to try and maintain conten con content continuity and , , to keep it within what he was saying . like wouldn't say breath groups but prosodic or intonational groups as much as possible . so if someone said "" - "" in the middle of of someone 's , , intonational contour , indicated it as , like what you just did . then indicated it as segment which contained @ @ this utterance plus an overlap .
B: but that 's but there 's only one there 's only one time boundary for both speakers ,
E: that 's right . and , it could be made more precise than that
D: whenever we use these speech words we should always do the thing like you 're talking about , accent ,
E: see what you mean . and then "" hesitation "" . and so then , , in terms of like words like "" "" and "" "" wrote them because figured there 's limited number , and keep them to , limited set because it didn't matter if it was "" mmm "" or "" "" , , versus "" "" . so always wrote it as . and "" - "" , , "" . "" , like set of like five . but in any case didn't mark those .
B: "" - "" is "" . ""
E: 'd be happy with that . that 'd be fine . it 'd be good to have that in the in the conventions , what 's to be used .
A: did notice that there were some segments that had pauses on the beginning and end . we should probably mark areas that have no speakers as no speaker . then , so question mark colon is fine for that .
E: that 's fine idea . that 's fine idea .
A: just say silence .
D: what 's that mean ?
A: no one 's talking .
D: silence all around .
B: we have to mark those ? don't they can't we just leave them unmarked ?
E: you see , that 's possible too .
A: wanna leave the marked don't want them to be part of another utterance . so you just you need to have the boundary at the start and the end .
E: now that 's refinement that , , maybe it could be handled by part of the part of the script more
B: it seems like the , , tran the transcription problem would be very different if we had these automatic speaker detection turn placing things . actually it sounds like there might be problem putting it into the software if the software only handles two parallel channels . but assuming we can get around that somehow .
E: you were saying , it can read
A: it can read and write as many as you want , it 's just that it
B: but what if you wanna edit it ? we 're gonna generate this transcript with five tracks in it , but with no words . someone 's gonna have to go in and type in the words . and if there are five people speaking at once ,
A: right , it 's didn't explain it . if we use the little the conventions that jane has established , have script that will convert from that convention to their saved convention .
E: which allows five . and it can be edited after the fact , can't it also ? but their but their format , if you wanted to in indicate the speakers right there instead of doing it through this indirect route , then they window comes up and it only allows you to enter two speakers .
D: but you 're saying that by the time you call it back in to from their saved format it opens up window with five speakers ?
A: it 's just user interface .
D: they didn't quite go the whole they didn't go the whole route ,
A: the the whole saved form the saved format and the internal format , all that , handles multiple speakers . it 's just there 's no user interface for specifying multiple any more than two .
D: so your script solves doesn't it solve all our problems , cuz we 're always gonna wanna go through this preprocessing assuming it works .
E: and that works nicely cuz this so quick to enter . so wouldn't wanna do it through the interface anyway adding which worry who the speaker was . and then , , let 's see what else . in terms of like the continuity of thought for transcriptions , it 's it isn't just words coming out , it 's like there 's some purpose for an utterance . and sometimes someone will do backchannel in the middle of it but you wanna show that it 's continued at later point . so have have convention of putting like dash arrow just to indicate that this person 's utterance continues . and then when it , catches back up again then there 's an arrow dash , and then you have the opposite direction to indicate continuation of ones own utterance versus , sometimes we had the situation which is , which you which you get in conversations , of someone continuing someone else 's utterance , and in that case did tilde arrow versus arrow tilde , to indicate that it was continuation did equal arrow for the for the own for yourself things cuz it 's the speakers the same . and then tilde arrow if it was different if different speaker , , con continuation . but just , , the arrows showing continuation of thought . and then you could track whether it was the same speaker or not by knowing at the end of this unit you 'd happened later . and that was like this person continued and you 'd be able to look for the continuation .
B: but the only time that becomes ambiguous is if you have two speakers . like , if you if you only have one person , if you only have one thought that 's continuing across particular time boundary , you just need one arrow at each end , and if it 's picked up by different speaker , it 's picked up by different speaker . the time it becomes ambiguous if you have more than one speaker and that and they swap . if you have more than one thread going , then you then you need to know whether they were swapped or not .
C: how often does that happen do you think ?
B: hopefully not very much .
E: didn't use it very often .
A: especially for meetings . if if you were just recording someone 's day , it would be impossible . , if you were trying to do remembrance agent . but for meetings it 's probably alright . but , lot of these issues , that for , from my point of view , where wanna do speech recognition and information retrieval , it doesn't really matter . but other people have other interests .
B: but it does feel it does feel like it 's really in there . did this did this transcription and marked that , marked it with ellipsis because it seemed like there was difference . it 's something you wanted to indicate that it that this was the end of the phrase , this was the end of that particular transcript , but it was continued later . and picked up with an ellipsis . didn't have the equal , not equal thing .
E: that 's , that 's why didn't didn't do it that 's why about it , and re - ev and it didn't do didn't do it in ten times the time .
A: so anyway , are we interested then in writing tools to try to generate any of this automatically ? is that something you want to do , dan ?
B: but it 's something @ @ that feel we definitely ought to do .
E: also wanted to ask you if you have time estimate on the part that you transcribed . do you have sense of how long
B: it took me half an hour to transcribe minute , but didn't have any didn't even have was trying to get transcriber to run but couldn't . so was doing it by typ typing into text file and trying to fit it was horrible .
D: so thirty to one 's what you got ? so that 's new upper limit ?
E: , that 's that 's because you didn't have the segmentation help and all the other
A: but for first try that 's about right .
C: so so if we hired who if we hired whole bunch of dan 's
D: that 's right .
B: it was actually it was quite it was
A: if we hire an infinite number of dan 's
E: and there 's always warm up thing of
A: are we gonna run out of disk space ?
D: doesn't it beep in the other room when you 're out of disk space ?
C: maybe we should consider also , , starting to build up web site around all of these things .
B: that 's great !
A: dan 's already started .
B: we could have like business - to - business - commerce as !
C: that 's right . no , but 'm it would be interesting it would be interesting to see
A: can we sell banner ads ?
D: get get paid for click - throughs ?
A: what good idea , that 's how we could pay for the transcription .
C: want to introduce the word "" snot - head "" into the conversation at this point .
D: you wanna word that won't be recognized ?
C: you see , cuz , cuz
A: hey , what about me ?
E: you 're the one who raised the issue .
C: see here 's here 's my thought behind it which is that , , the that you 've been describing , jane , gu one has to , indicate , , is very interesting , 'd like to be able to pore through , , the types of tr conventions that you 've come up with and like that . so would like to see that on the web .
E: now , the alternative to web site would be to put it in doctor speech . cuz cuz what have is soft link to my transcription that have on my account
C: either 's fine .
E: but it doesn't matter .
A: we can do it all .
B: we can do it all !
E: web site 's . then you have to you have to do an ht access .
D: web site 's what ?
B: we could actually maybe we could use the tcl plug - in .
E: he 's committed himself to something .
C: see he said the word tcl and that 's
D: but he does such good job of it . he should be allowed to , , do it .
E: know , know .
B: but that but , but should be allowed to
D: if you just did crappy job , no nobody would want you to do it .
B: sh shouldn't be allowed to by by my own by my according to my own priorities . let 's look at it anyway . so definitely we should we should have some access to the data .
A: and we have we have quite disparate number of web and other sorts of documents on this project spread around . and dan has few ,
C: so we can add in links and like that to other things .
A: try try to consolidate . who wants to do that though ?
B: the other side is , .
A: no one wants to do that .
B: that 's the problem .
C: we could put we could put disorganized group gestalt
D: what what 's the issue ?
B: no one owns the project .
D: no one what ?
B: no one owns the project .
A: but don't wanna do it .
B: no one wants to own the project .
A: it 's mine !
B: then you have to do the web site .
A: "" wah - hah - hah - hah . ""
B: it 's like , it 's that simple .
D: but but what are you what are you talking about for web site hacking ? you 're talking about writing html , right ?
A: 'm talking about putting together all the data in form that is legible , and pleasant to read , and up to date , and et cetera , et cetera .
D: but , is it against the law to actually use tool to help your job go easier ?
A: it 's it 's against the law to use tool . haven't found any tools that like . it 's just as easy to use to edit the raw html as anything else .
B: that 's not true ,
A: it 's not true .
D: no , it it 's true that he hasn't found any he likes .
B: that 's true .
D: the question is what is what 's he looked at .
E: which one do you use jim ?
D: use something called trellix .
E: that 's right . which produces also site maps .
A: now , if were if were doing more powerful excuse me more complex web sites might want to .
D: it 's - it 's very powerful .
A: most of the web sites do aren't that complex .
E: would this be to document it also for outside people or mainly for in house use ?
A: mostly in house .
B: that 's right .
D: but what does internal mean ?
B: no , both .
D: you 're leaving . people at uw wanna look at it . it 's it 's internal until
C: internal to the project .
E: we could do an ht access which would accommodate those things .
A: send me pointers , rather , and 'll put it together .
B: 'm not how important that distinction is . don't think we should say , "" , it 's internal therefore we don't have to make it very good "" . you can say "" , it 's internal therefore we can put data in it that we don't we don't have to worry about releasing "" . but to try and be coherent and make it presentation .
E: it is true , that is it benefits to
D: cuz you 're gonna have to wor do the work sooner or later .
E: that 's right . it 's the early on .
D: even if it 's just writing things up .
E: it 's great idea .
A: let 's move on to electronics .
D: we out of tape out of disk ?
B: we 're doing we 're doing great .
D: was looking for the actual box plan to use , but all could couldn't find it at the local store . but this is the technology . it 's actually little bit thinner than this . and it 's two by two , by one , and it would fit right under the right under th the the lip ,
A: does everyone know about the lip on the table ? it 's great .
D: there 's lip in these tables . and , it oc especially brought the bottom along to try and generate some frequencies that you may not already have recorded . let 's see what it does to the but this was the just to review , and also brought this along rather than the projector so we can put these on the table , and push them around .
A: and and crinkle them and
E: and th "" that "" being diagram .
D: that that 's the six tables that we 're looking at . these six tables here , with little boxes , , in the middle here . the boxes are out of the way anyway . 'll - 'll show you the cro this is the table cross section . if people realize what they 're looking at .
B: you trying to screw up the the microphones ?
D: cuz this is what 's gonna happen . you got plenty of data . won't come to your next meeting . and you so this is the box 's
A: get your paper off my pda !
E: let the record show that this is exhibit two .
D: that 's right . "" or not to be "" . the box , there 's half inch lip here . the box is an inch thick so it hangs down half an inch . and so the two head set jacks would be in the front and then the little led to indicate that box is live . the the important issue about the led is the fact that we 're talking about eight of these total , which would be sixteen channels . and , , even though we have sixteen channels back at the capture , they 're not all gonna be used for this . so there 'd be subset of them used for just use the ones at this end for this many . you 'd like way to tell whether your box is live , so the led wouldn't be on .
B: all the lights .
D: so if you 're plugged in it doesn't work and the led is off that 's that 's tip off . and then the , would wire the all of the cables in in bundle come through here and collect these cables at the same time .
E: that 's good .
D: so this notion of putting down the ms and taking them away would somehow have to be turned into leaving them on the table
A: we wanna do that definitely .
D: and so the you we just epoxy them down . big screw into the table . and even though there 's eight cables they 're not really very big around so my model is to get piece of that that people put with the little you slip the wires into that 's shaped like that cross section .
A: not just sleeve them all ?
D: 'm 'm 'm going up and then 'm going down .
A: and leave them loose ?
E: that looks like semi - circle .
B: it 's like it 's sleeping policeman .
A: "" sleeping policeman "" !
D: it 's like speed bum an
E: that 's good .
D: and they 're ac they 're actually ext extruded from plastic . they sorta look like this .
C: what does that mean ?
B: that 's the that 's british for speed bump ,
C: is it speed bump ?
D: so that the wires go through here .
E: is that right ? never heard that .
A: that 's really cruel .
D: so it would go on the diagonal here .
C: it could go either way .
A: so why do we have sixteen channels instead of like some fewer number ?
B: how else are you gonna distribute them around the tables ?
D: because they 're there .
A: let me rephrase that . why two each ?
B: because then you don't have to just have one each . so that if if you have two people sitting next to each other they can actually go into the same box .
D: and to see , thi this is really the way people sit on this table . dot , dot .
E: which means two at each station .
D: that 's the way people sit . that 's how many chairs are in the room .
E: 'm just saying that for the recording .
D: and certainly you could do thing where all sixteen were plugged in .
A: but then none of these .
D: if you ha if you had nothing else .
A: none of these and no ms then .
B: only if you had it depends on this box , right ?
D: and actually , at the my plan is to only bring eight wires out of this box . thi - thi this box is one off deal .
E: that being the wiring box .
D: and , , it 's function is to to , , essentially wire converter to go from these little blue wires to these black wires , plus supply power to the microphones cuz the he the , , cheap head mounteds all require low voltage .
A: so so you 'd imagine some in some patch panel on top to figure out what the mapping was between each of these two and each of those one or what ?
D: the simplest thing could imagine , which is really , really simple is to quite literally that these things plug in . and there 's there 's plug on the end of each of these , , ei eight cables .
E: each of the blue wires ?
B: but there are only four .
D: an - and there 's only there 's only four slots that are , in the first version or the version we 're planning to build . so that was the whole issue with the led , that you plug it in , the led comes on , and and you 're live .
A: then it comes on . see , see .
D: now the the subtle issue here is that tha haven't really figured out solution for this . so , we it 'll have to be convention . what happens if somebody unplugs this because they plug in more of something else ? the there 's no clever way to let the up stream guys know that you 're really not being powered . th there will be certain amount of looking at cables has to be done if people , , rewire things .
B: , we had that last time . but there are actually that , there 's an extra there 's mix out on the radio receiver ? so there are actually six xlr outs on the back of the radio receiver and only five cables going in , had the wrong five , so ended up not recording one of the channels and recording the mix .
D: did you do any recognition on the mix out ? wonder whether it works any
B: but subtracted the four that did have from the mix and got pretty good approximation of the @ @ .
D: got the fifth ?
A: and did it work ? did it sound good ?
B: it 's not bad . it 's not bad ,
D: ain't science wonderful ?
E: that 's amazing .
A: so what 's the schedule on these things ?
B: but , you always
D: was wrestling with th with literally the number of connectors in the cable and the , , powering system . and was gonna do this very clever phantom power and decided couple days ago not to do it . so 'm ready to build it . which is to say , , the neighborhood of week to get the circuit board done .
A: so the other thing 'd like to do is , do something about the set up so that it 's little more presentable and organized . and 'm 'm just not what that is .
D: the the difficulty for this project is the intellectual capital to design the cabinet . in other words , to figure out ex exactly what the right thing is . that cabinet can go away . we can use that for kindling . but if you can imagine what the right form factor is . dan - dan and have gone around on this , and we were thinking about something that opened up in the top to allow access to the mixer . but there 's these things sticking out of the mixer which are pain , so you end up with this thing that if you stuck the mixer up here and the top opened , it 'd be it 'd be fine . you understand what 'm the you can start sketching it out , and certainly build it out of oak would it , arb , arbitrarily amount of
A: need desk at home too , alright ? is that gonna be better solution than just going out and buy one ?
D: the as we found out with the thing that , , jeff bought long time ago to hold our stereo system the you buy is total crap . and this is something you buy .
A: and it 's total crap .
D: it 's total crap . it 's useless for this function . works fine for holding kleenex ,
A: kleenex and telephones . so , it 's just question , is that something you wanna spend your time on ?
D: 'm paid for . have no problem . no , but certainly one of the issues is the , is security . we 've been been lax and lucky . really lucky with these things . but they 're not ours , the , the flat panels .
A: 'm telling you , 'm just gonna cart one of them away if they stay there much longer .
D: let the record show at at four thirty - five adam janin says
B: we 'll know we 'll know to come after .
A: then the other question is do we wanna try to do user interface that 's available out here ?
D: slipped almost slipped it by dan .
E: use - user interface
A: do we wanna try to get monitor ? or just something . and how do we want to do that ?
E: you mean like see meter readings , from while sitting here .
A: just so we see something .
D: how about use the thing that aciri 's doing . which is to say just laptop with wireless .
B: which we 'll borrow from them , when we need it .
D: what 's wrong with yours ? if we bought you
B: you could use my machine .
A: have an iram machine 've borrowed and we can use it .
D: 'm 'm serious . does does the wireless thing work on your
A: isn't that an ethernet connection or is that phone ?
B: that 's an ethernet connection . it 's going next door .
D: no 'm ain't joking here . 'm serious , that it
B: no , no , that 's the right way to do it . to have it , just
D: it 's very convenient especially if dan happens to be sitting at that end of the table to not have to run down here and look in the thing every so often ,
B: and given that we 've got wireless that we 've got we got the field .
D: but just have the it 's right there . the antenna 's right there , we need need to clear this with aciri how tough can that be ? there it you 'd all you need 's web access , isn't it ?
B: we don't need access
D: in in theory .
B: but that 's fine . that 's that 's what it does ,
A: right , so it 's just question of getting laptop and wireless modem .
D: and he had , reque @ @ my proposal is you have laptop . if if we bought you the thing would you mind using it with the
B: but 'm not if my laptop is compatible with the wave lan thing they 're using . apple has their own thing , right ?
D: your new one ?
B: apple has their own thing .
D: it just came through serial or an ethernet port .
B: you it just plug plugs in pc card , so you could probably make it run with that ,
A: the question is , is there an apple driver ?
B: imagine there is . there are there are abs there are bunch of machines at icsi that have those cards and so if if it doesn't we should be able to find machine that does that . doesn't don't the important people have those little blue vaios that
D: , that to me that 's whole nother . that 's whole nother issue . the the idea of con convincing them that we should use their network is fairly straight forward . the idea of being able to walk into their office and say , "" , can borrow your machine for while "" , is is non - starter . that don't think that 's gonna work . so , , either we figure out how to use machine somebody already in the group already owns , and the idea is that if it 's it perk , , it 's an advantage not disadvan or else we literally buy machine exactly for that purpose . certainly it solves lot of the problems with leaving monitor out here all the time . 'm not big fan of doing things to the room that make the room less attractive for other people , which is part of the reason for getting all this out of the way and , so monitor sitting here all the time people are gonna walk up to it and go , "" how come 't get , , pong on this "" or , whatev
A: 've 've borrowed the iram vaio sony thingy , and don't think they 're ever gonna want it back .
B: you 're kidding !
D: the next conference they will .
A: but that does mean so we can use that as .
D: , the certainly , you should give it shot first see whether you can get compatible . ask them what it costs . ask them if they have an extra one . who knows , they might have an extra hardware
B: 'd trade them flat panel display for it .
C: what is the , , projector supposed to be hooked up to ?
D: the , tsk . it 's gonna be hooked up to all sorts of junk . there 's gonna be actually plug at the front that 'll connect to people 's laptops so you can walk in and plug it in . and it 's gonna be con connected to the machine at the back . so we certainly could use that as constant reminder of what the vu meters are doing .
B: huge vu meters .
D: so people sitting here are going "" testing , one , two , three "" !
C: but , that 's another that 's another possibility that , , solves
B: that 's an end
D: but but the idea of having control panel it 's that 's there in front of you is really .
B: and , having it on wireless is the neatest way neatest way to do it .
D: as long as you as as long as you 're not tempted to sit there and keep fiddling with the volume controls going , "" can you talk bit louder ? ""
A: had actually earlier asked if could borrow one of the cards to do wireless and they said , "" , whenever you want "" . so it won't be problem .
D: and and it 's pcmcia card , right ? so you can have slot , in your new machine ?
C: it 's it really come down to the driver .
A: right , , and if and if his doesn't work , as said , we can use the pc .
D: it 'll it 'll work it 'll work the first time . trust steve jobs .
B: that sounds like good solution one way or the other .
A: so jim is gonna be doing wiring and you 're gonna give some thought to cabinets ?
D: we we need to figure out what we want . hey , what are those green lights doing ?
A: they 're flashing !
B: does that it means it 's gonna explode .
D: cut the red wire , the red wire !
A: when people talk , it they go on and off .
B: so again , washington wants to equip system . our system , we spent ten thousand dollars on equipment not including the pc . however , seven and half thousand of that was the wireless mikes .
D: and it and the the five thousand for the wires , so if 'm gonna do it 's joke .
B: but we haven't spent that , right ? but once we once we 've done the intellectual part of these , , we can just knock them out , right ? we can start we you can make hundred of them .
D: of the of the boards ?
B: and then we could washington could have system that didn't have any wireless but would had what 's based on these and it would cost
A: pc and peanuts .
B: pc and two thousand dollars for the - to - . and that 's about cuz you wouldn't even need the mixer if you didn't have the ms cost lot . but anyway you 'd save , on the seven or eight thousand for the for the wireless system . so actually that might be attractive . move my thumb now .
E: that 's great idea . it 's it 's to be thinking toward that .
D: like if we talked softer the disk lasts longer .
A: there 's speech compression program that works great on things like this , cuz if the dynamic range is low it encodes it with fewer bits . and so most of the time no one 's talking so it shortens it dramatically . but if you talk quieter , the dynamic range is lower and it will compress better .
D: it also helps if you talk in monotone . constant volume all the time .
E: and shorter words .
C: now , shorter words wouldn't would induce more dynamics , you want to have
B: but if the words are more predictable .
A: how about if you just go "" "" ?
E: that 's long word !
A: how do you spell that ? can you do one more round of digits ? are we done talking ?
D: it 's choice if we get choice , let 's keep talking .
A: do we have more to talk about ? are you done ?
C: but he 's not gonna say anything .
D: but you there 's problem structural problem with this though . you really need an incentive at the end if you 're gonna do digits again . like , , candy bars ,
A: 'll 'll remember to bring and 's next time .
D: or or little , , toothbrushes like they give you at the dentist . eric , you and win . we didn't make any mistakes .
A: it 's harder at the end than at the beginning .
E: we that for ,
A: should have mentioned that , to pause between lines but
D: no , know . 'm just giving you hard time .
A: it 's it 's only hard time for the transcriber not for the speech recognizer .
E: also think you said channel four and you meant microphone four . and that 's mistake .
D: so eric , you win . but the other thing is that there 's there 's colon for transcripts . and there shouldn't be colon . because see , everything else is you fill in .
B: that 's been filled in for you . but they 're in order ! they start , six , seven , eight , nine , zero , one , two , three , four , five , six , eight , nine .
D: where 'd they come from ?
B: and they 're in order because they 're sorted lexically by the file names , which are have the numbers in digits . and so they 're actually this is like all the all utterances that were generated by speaker mpj . and then within mpj they 're sorted by what he actually said .
A: didn't know that . should have randomized it .
B: it doesn't matter ! it 's like cuz you said "" six , seven , eight "" .
D: we doesn't matter .
B: we doesn't matter .
D: but the real question have is that , why bother with these ? why don't you just ask people to repeat numbers they already know ? like phone numbers , social security numbers .
B: cuz we have these writt written down , right ?
A: if we have it ,
E: social security numbers .
A: we don't have to transcribe .
B: you can you can generate
E: bank account numbers .
D: credit card numbers ,
A: we don't have to tran
B: that 's great idea .
D: so you just say your credit card numbers , say your phone numbers , say your mother 's maiden name .
A: bet we could do it .
E: password to your account .
D: people off the street .
A: actually , this got this directly from another training set , from aurora . we can compare directly .
B: looks like there were no errors .
E: was the reason made my mistake was wa - was this ?
B: there were no there were no direct driver errors , by the look of it , which is good .
A: the mike 's off .
B: so 'm gonna stop it .
D: mony on the mike .
","The Berkeley Meeting Recorder group discussed the aims , methods , timing , and outsourcing issues concerning transcription of the Meeting Recorder corpus.
The Transcriber software tool was introduced , along with a set of transcription conventions for coding different speech events.
The prospect of sending the data to an external transcription service was weighed against that of hiring a graduate student transcriber pool.
It was tentatively decided that the latter option would be less costly and allow BMR to maintain greater control over the transcription process.
Methods for distributing the data were briefly discussed , along with an initiative for creating a BMR project website.
The group received an update on the meeting room recording setup and electronics.
The group will obtain a copy of the Corpus of Spoken American English ( CSAE ) from the LDC to compare the methods and conventions used by UC Santa Barbara with those being considered for the Meeting Recorder project.
Speakers fe008 and me011 will experiment with pre-segmentation procedures in hopes of facilitating the transcription process.
Speaker fe008 will perform the transcription for one meeting ( 40-60 minutes of data ) as a pilot project.
A tentative decision was made to put speaker fe008 in charge of the in-house transcription effort.
Modifications to the Transcriber source code , e.g . adjusting the delay between the audio play function and the inputting of time boundaries , may be undertaken by the BMR group.
An initiative for creating an internal BMR project website was discussed , along with ideas for providing web access to external organizations , such as the University of Washington.
A cabinet will be built to house wires and other electronic equipment used in the recording setup.
A laptop and wireless modem will be avaiable to participants for monitoring the recording progress.
How should transcripts and corresponding audio files be formatted and distributed?
External transcription services are expensive , difficult to monitor , and are unlikely to be able to handle multi-channel data.
It is unclear which levels of transcription should be encoded.
What size of segment is most useful for doing transcriptions?
Which level of segmentation is most suitable for the aims of the project?
Transcriber's interface only allows the user to view two overlapping speakers.
Decisions must be made regarding the security of electronic recording equipment.
Efforts are in progress to collect and transcribe 30-40 hours of Meeting Recorder data.
The Transcriber tool is being used to do word-level transcriptions , and was reported to work well , when used with supplementary scripts , for specifying multiple speakers.
Other levels of transcription being considered include marking stress , repairs , and false starts.
A set of transcription conventions have been formulated for marking colloquial forms , the continuity of utterances , etc.
A cost assessment was made for sending Meeting Recorder data to an external transcription service.
It was agreed that hiring linguistics graduate students would be cheaper and allow the group to maintain greater control over the transcription process.
Tentative pre-segmentation efforts will enable the automatic generation of phrase boundaries and speaker identity coding , and will be extendable for use at UW.
Perl and XWaves scripts are available for extracting and aligning digits data.
Other suggestions for future work included performing multi-channel speech/non-speech detection , and linking an ASR system to the Transcriber tool.
The recording room electronics setup has been diagrammed and will take approximately one week to configure.
It was suggested that such efforts will enable researchers at UW and other collaborating institutions to create their own recording setups more cheaply.
"
ami_abstractive_summary,Bmr014.txt,"C: are we going ?
E: it is , must be february fifteenth .
C: the date 's written in there , . and actually if everyone could cross out the - nine next to "" session "" , and write mr eleven .
E: we didn't have front - end meeting today .
C: and let 's remember also to make that one 's gets marked as unread , unused .
F: that sounds like spy code .
C: there 's lots of clicking 'm as 'm trying to get this to work correctly .
E: any agenda items today ?
C: wanna talk little bit about getting how we 're gonna to get people to edit bleeps , parts of the meeting that they don't want to include . what 've done so far , and wanna get some opinions on , how to how to finish it up .
F: wanna ask about , some aud audio monitoring on some of the some of the equipment . in particular , the that 's just what wanna ask .
E: audio monitoring , jane .
F: ba - based on some of the tran in listening to some of these meetings that have already been recorded there are sometimes big spikes on particular things , and in pact this one 'm talking on is one of the ones that showed up in one of the meetings ,
B: "" spikes "" , you mean like , instantaneous click type spikes , or ?
F: and what the electronics is but .
C: it could be number of things . it could be touching and fiddling , and the other thing is that it could the fact that it 's on wired mike is suspicious . it might be connector .
F: then we don't really have to talk about that as an
B: you could try an experiment and say "" , 'm about to test for spikes "" ,
F: take that off the agenda .
B: and then wiggle the thing there , and then go and when they go to transcribe it , it could , ask them to come and get you . "" come get me when you transcribe this and see if there 's spikes . ""
E: were this professional audio recording , what we would do what you would do is in testing it is , you would actually do all this wiggling and make that that things are not giving that performance . and if they are , then they can't be used . let 's see . would like to have discussion about where we are on , recording , transcription where we are on the corpus . and then , the other thing which would like to talk about which is real meta - quest , , deal is , , agendas . so maybe 'll 'll start with that actually . . andreas brought up the fact that he would kinda like to know , if possible , what we were gonna be talking about because he 's peripherally involved to this point , and if there 's gonna be topic about discussion about something that he strongly cares about then he would come and and part of part of his motivation with this is that he 's trying to help us out , in the because of the fact that the meetings are tending to become reasonably large now on days when everybody shows up and so , he figures he could help that out by not showing and 'm help out his own time . by not showing up if it 's meeting that he 's he 's so , in order 'd that this is wish on his part . it 's actually gonna be hard because it seems like lot of times things come up that are unanticipated but , we could try anyway , do another try at coming up with the agenda , at some point before the meeting , say the day before .
C: maybe it would be good idea for one of us to like on wednesday , or tuesday send out reminder for people to send in agenda items .
E: you you wanna volunteer to do that ? alright so we 'll send out agenda request .
C: 'll put that on my spare brain or it will not get done .
B: that 'll help lot , actually .
E: have to tell you for the for the admin meeting that we have , lila does that every time before an admin meeting . and , she ends up getting the agenda requests , ten minutes before the meeting . but but but . but we can try . maybe it 'll work .
C: weirder things have happened .
F: 'm wondering if he were to just , , specify particular topics , maybe we 'd be able to meet that request of his little more .
B: would would also that as we get more into processing the data and things like that there 'll be more things of interest to him .
E: this this maybe brings up another topic which is so we 're done with that topic . the other topic was thinking of was the sta status on microphones and channels , and all that .
C: actually was going to say we need to talk about that too .
E: why why don't we do that .
C: the new microphones , the two new ones are in . and they are being assembled as we speak , hope . and didn't bring my car today so 'm gonna pick them up tomorrow . and then the other question was thinking about is , couple things . first of all , if the other headsets are lot more comfortable , we should probably just go ahead and get them . so we 'll have to evaluate that when they come in , and get people 's opinions on what they think of them . then the other question had is maybe we should get another wireless . another wireless setup . it 's expensive , but it does seem to be better than the wired .
E: so how many channels do you get to have in wireless setup ?
C: , 'm pretty that you can daisy - chain them together so what we would do is replace the wired mikes with wireless . so we currently have one base station with six wireless mike , possibility of six wireless receivers , and you can chain those together . and so we could replace our wired mikes with wireless if we bought another base station and more wireless mikes . so , it 's still , it 's fifteen minus six .
E: so let 's see we
C: so we could have up to nine .
E: and right now we can have up to six .
C: and we have five , we 're getting one more . and it 's , about nine hundred dollars for the base station , and then eight hundred per channel .
E: so so the only beyond the mike the cost of the mikes the only thing is the base station that 's nine hundred dollars . we should do it .
C: so 'll look into how you daisy - chain them and then just go ahead and order them .
B: don't quite understand how that how that works , . so we 're not increasing the number of channels .
C: no , we 're just replacing the wired the two wired that are still working , along with couple of the wired that aren't working , one of the wired that 's not working , with wireless .
B: three wireds work ,
C: three wireds work , .
E: but we 've had more problems with that . and that bypasses the whole the whole jimbox thing and all that . and so , we seem to have , reliable way of getting the data in , which is through the ra sony radio mikes , as long as we 're conscious about the batteries . that seems to be the key issue .
C: everyone 's battery ?
B: checked them this morning , they should be .
E: that 's the only thing with them . but the quality seems really good heard from uw that they 're they 're very close to getting their , setup purchased . they 're they 're buying something that you can just buy off the shelf .
C: we should talk to them about it because know that sri is also in the process of looking at , and so , , what we should try to keep everyone on the same page with that . they got sa apparent maybe this needs to be bleeped out ? have no clue . how much of it 's public .
E: probably we shouldn't probably we shouldn't talk about funding . but anyway there 's there 's , other activities that are going on there and and nist and uw . but but thin that at least the message we can tell other people is that our experience is quite positive with the sony , radio - mikes . now the one thing that you have said that actually concerns me little is you 're talking about changing the headsets meaning changing the connector , which means some hand - soldering ,
C: we 're having the them do it . so it 's so hand - soldering it , but 'm not doing it . so , they charge
E: nothing against you and your hand - soldering
C: you 've never seen my hand - soldering . but , as said they 're coming in .
E: , so that 's being done professionally
C: as professionally as you can get it done .
E: if they do lot of it , it 's
C: it 's just their repair shop . their maintenance people .
E: we 'll see what it 's like . that tha that can be quite good . so let 's go with that .
C: and , we 'll see , tomorrow , , what it looks like .
E: so , , , dave isn't here but he was going to start working on some things with the digits . so he 'll be interested in what 's going on with that . was the decision last time was that the transcribers were going to be doing with the digits as ? has that started , or is that ?
F: it would be to use his interface and was going to meet with him today about that .
C: right , so , the decision was that jane did not want the transcribers to be doing any of the paperwork . so did the all that last week . so all the all the forms are now on the computer . and , then have bunch of scripts that we 'll read those and let the transcribers use different tools . and want to talk to jane about how we transition to using those .
F: so he has set up that they it it will be efficient for them to do that .
C: don't 'll take too long . so , , just , matter of few days suspect .
E: so anyway we have at least one , user for the digits once they get done , which will be dave .
C: 've already done five or six sets . so if he wanted to , , just have few to start with , he could . and also have bunch of scripts that will , like , generate - files and run recognition on them also .
E: he might he might be asking if dave is on the list , if he 's invited to these meetings , if he knows .
F: don't tend to get an invitation myself for them even .
A: no , no .
C: we don't have active one but 'll make he 's on the list .
F: should we call him ? is he is he definitely not available today ? should call his office and see ?
A: he was in .
C: he 's still taking classes , so , he may have conflicts .
F: he wasn't there at cof
E: so this might be conflict for him .
C: didn't he say his signal - processing class was like tuesdays and thursdays ?
A: he has class .
B: he might have .
D: you talking about david gelbart ? he 's taking two twenty - five which is now .
E: so , that 's why we 're not seeing him . transcriptions , , beyond the digits , where we are , and so on . and the and the recordings also , just where we are .
F: so , should we don't wan wanna do the recording status first , or ?
C: we have about thirty - two hours as of , week and half ago , so we probably now have about thirty - five hours .
E: and and that 's that 's how much of that is digits ? that 's including digits ,
C: that 's including digits . haven't separated it out so have no clue how much of that is digits .
E: so anyway there 's at least probably thirty hours , there 's got to be more than thirty hour
C: of of non - digits ?
E: of of non - digits .
C: the digits don't take up that much time .
F: , don't have the exact numbers , but it would come to about eleven hours that are finished , transcribing from them right now . the next step is to that 'm working on is to insure that the data are clean first , and then channelized . what by clean is that they 're spell - checked , that the mark - up is consistent all the way throughout , and also that we now incorporate these additional conventions that , liz requested in terms of , in terms of having systematic handling of numbers , and acronyms which hadn't been specific about . , they 'll say "" ninety - two "" . and , so how you could so if you just say "" nine two "" , the there are many ways that could have been expressed . an - and had them certain number of them did put the words down , but now we have convention which also involves having it followed by , , gloss th and things .
B: and you may already be doing this , but 've noticed in the past that when 've gone through transcriptions and in order to build lexicons and things , if you , just take all the transcriptions and separate them into words and then alphabetize them , lot of times just scanning down that list you 'll find lot of inconsistencies and mis
F: you 're talking about the type token frequency listings , and use those too . you mean just on each line there 's one word it 's one token from the from the corpus . those are extremely efficient and agree that 's very good use of it .
B: so you already have that ,
F: that 's that 's way that 's the spell - check does that yes , that 's that 's exactly the strategy wanna do in terms of locating these things which are colloquial spoken forms which aren't in the lexicon .
B: cuz lot of times they 'll appear next to each other , and ,
F: and then you ca then you can do
B: in alphabetized lists , they 'll appear next to each other and so it makes it easier .
F: that 's very good that 's very good , suggestion . and that was that 's my strategy for handling lot of these things , in terms of things that need to be glossed . didn't get to that point so there are numbers , then there are acronyms , and then , there 's he she wants the , actually an explicit marker of what type of comment this is , so curly inside the curly brackets 'm gonna put either "" voc "" for vocalized , like cough or like laugh or whatever , "" nonvoc "" for door - slam , and "" gloss "" for things that have to do with if they said spoken form with this this pronunciation error . already had that convention
B: that 's great .
F: but haven't been asking these people to do it systematically cuz it most ha most efficiently handled by by filter . that was what was always planing on . so that , you get whole long list exactly what you 're saying , you get whole list of things that say "" curly bracket laugh curly bracket "" , then it 's it 's you you risk less error if you handle it by filter , than if you have this transcriber ch laboriously typing in voc space , so man so many ways that error prone . so , , 'm 'm going to convert that via filter , into these tagged , subcategorized comments , and same thing with , we see you get subset when you do what you 're saying , you end up with with , you 're collapsing across frequency you just have the tokens and you can , have filter which more efficiently makes those changes . but the numbers and acronyms have to be handled by hand , because , , jus
C: you what they could be .
F: now timit 's clear and plp is clear but there are things that are not so known , in or have variant uses like the numbers you can say "" nine two "" or you can say "" ninety - two "" ,
C: so how are you doing the
F: 'd handle the numbers individually .
C: how are you doing the , acronyms so if say pzm what would it appear on the transcript ?
F: it would be separate the letters would be separated in space and potentially they 'll have curly bracket thing afterwards but 'm not if that 's necessary , clarifying what it is , so gloss of whatever . if that 's really necessary to do that . maybe it 's thing to do because of it then indicating this is , step away from indicating that it really is intentional that those spaces are there , and indicating why they 're there to indicate that it 's the , enumerated , or it 's not good way of saying but it 's it 's the specific way of stating these letters .
C: so it sounds good .
F: and so anyway , the clean those are those things and then channelized is to then , get it into this multichannel format . and at that point then it 's ready for use by liz and don . but that 's been my top priority beyond getting it tanel channelized , the next step is to work on tightening up the boundaries of the time bins . and , thilo had breakthrough with this last week in terms of getting the channel - based speech - nonspeech segmentation , up and running and haven't haven't been able to use that yet this is my top priority get the data clean , and channelized .
C: have you also been doing spot checks , jane ?
F: you see that 's part of the cleaning process . actually have segment of ten minutes that was transcribed by two of our transcribers , and went through it last night , it 's it 's almost spooky how similar these are , word for word . and there are some differences in commas cuz commas left them discretion at commas . because it 's not part of our st of our ne needed conventions . and so they 'll be difference in commas , but it 's word - by - word the same , in huge patches of the data . and have ten minute stretch where where show that . and and sometimes it turns out that one of these transcribers has better ear for technical jargon , and the other one has better ear for colloquial speech . so , the one the colloquial speech person picked up "" gobbledy - gook "" . and the other one didn't . and on this side , this one 's picking up things like "" neural nets "" and the one that 's good on the sp on th the vocabulary on the colloquial didn't .
B: for the person who missed "" gobbledy - gook "" what did they put ?
F: it was an interesting approximation , put in parentheses , cuz have this convention that , if they 're not what it was , they put it in parentheses . so they tried to approximate it , but it was it was spelled gabbl
B: how it sounds .
F: more of an attempt to it was very clear to her that these the this was sound these are the sounds ,
C: it was technical term that she didn't recognize ,
F: but she knew that she didn't . maybe it was technical ter but she even though her technical perception is just really you 've 'm tempted to ask her if she 's taken any courses in this area or if she 's taken cognitive science courses then cuz "" neural nets "" and she has some things that are "" downsampled "" , she got that right . and some of these are rather unexpected . but ch ten solid ch chunk of ten solid minutes where they both coded the same data .
E: and the main track that you 're working with is elev eleven hours ? is that right ?
F: and that 's part of this
E: is that is that including digits ?
F: yes it is .
E: so let 's say roughly ten hours or so of it 's probably more than that but with of non - digits .
F: it 'd be more than that because my recollection is the minutes that da digits don't take more than half minute . per person . but the total set that gave them is twelve hours of tape , but they haven't gotten to the end of that yet . so they 're still working some of them are two of them are still working on completing that .
B: boy , they 're moving right along .
F: - . they 're very efficient . there 're some who have more hours that they devote to it than others .
E: so what what 's the deal with your
A: the channel thing ? it 's just , ran the recognizer , the speech - nonspeech detector on different channels and , it 's just in in this new multi - channel format and output , and gave one meeting to liz who wanted to try it for the recognizer as , the recognizer had problems with those long chunks of speech , which took too much memory or whatever , and so she will try that 'm 'm working on it .
C: is this anything different than the system you were using before ?
A: mmm , use some different features but not the basic thing is this base .
C: so there 's still no knowledge using different channels at the same time .
A: there is some , as the energy is normalized across channels
C: across all of them .
A: but that 's one of the main changes .
E: what are some of the other features ? besides the energy ? you said you 're trying some different features , .
A: mmm , use our loudness - based things before there were they were some in the log domain and changed this to the to the
E: cu - cube root ?
A: no , changed this to the to the loudness thingy with the with the how do you call it ? 'm not about the term . 'll look it up . and say it to you . that 's that 's the the thing . and and tried to normalize the features , there 's loudness and modified loudness , , within one channel , because they 're , to be able to distinguish between foreground and background speech . and it works quite . but , not always .
E: let 's see . were were you done with the transcription part ? so the next thing is this bleep editing .
C: so the the idea is that we need to have we need to provide the transcripts to every participant of every meeting to give them an opportunity to bleep out sections they don't want . so 've written bunch of tools that will generate web pages , with the transcription in it so that they can click on them and piece pieces and they can scroll through and read them , and then they can check on each one if they want it excluded . and then , it 's form , html form , so they can submit it and it will end up sending me email with the times that they want excluded . and so , , some of the questions on this is what do we do about the privacy issue . and so about this little bit and the best way to do it is every participant will have password , each person will have single password , user name and password . and then each meeting , we 'll only allow the participants who were at that meeting to look at it . and that way each person only has to remember one password .
E: 't help but wonder if this is maybe little more elaborate than is needed . for me would actually want to have some pieces of paper that had the transcription and would flip through it . and then if it was , 'd say "" it 's "" . it depends how this really ends up working out , but my thought was that the occasion of somebody wondering whether something was or not and needing to listen to it was gonna be extremely rare .
C: right , so th the fact that you could listen to it over the web is minor thing that had already done for other reasons . and so that 's minor part of it , wanted some web interface so that people you didn't actually have to send everyone the text . so what my intention to do is that as the transcripts become ready , would take them , and generate the web pages and send email to every participant or contact them using the contact method they wanted , and just , tell them , "" here 's the web page "" , "" you need password "" . so th question number one is how do we distribute the passwords , and question number two is how else do we wanna provide this information if they want it .
E: what was saying is that if you just say "" here is here is "" this maybe it sounds paleolithic but thought if you handed them some sheets of paper , that said , , "" here 's what was said in this transcription is it with you ? and if it is , here 's this other sheet of paper that you sign that says that it 's "" .
C: that there are subset of people who will want printouts that we can certainly provide .
E: and then they 'd hand it back to you .
C: but certainly wouldn't want printout . these are big , and would much rather be ha be able to just sit and leaf through it .
E: you find it easier to go through large how do you read books ?
C: certainly read books by hand . but like this , it 's easier to do it on the web . cuz you 're gonna get , , if 'm 'm in bunch of meetings and don't wanna get stack of these . wanna just be able to go to go to the web site and visit it as want .
E: going to web site is easy , but flipping through hundred pounds hundred pages of is not easy on the web .
C: don't 's that much harder than , paper .
F: have one question . so are you thinking that the person would have transcript and go strictly from the transcript ? because do think that there 's benefit to being able to hear the tone of voice and the
E: so here 's the way was imagining it , and maybe 'm wrong , but the way imagined it was that , the largest set of people is gonna go "" , didn't say anything funny in that meeting just go ahead , where 's the where 's the release ? "" and then there 'll be subset of people , think of who it is we 've been recording mostly . there 'll be subset of people , who , will say "" , , really would like to see that . "" and for them , the easiest way to flip through , if it 's really large document , unless you 're searching . searching , , should be electronic , but if you 're not so if you provide some search mechanism you go to every place they said something like that , but see then we 're getting more elaborate with this thing . if you don't have search mechanisms you just have this really , really long document , whenever 've had really , really long document that it was sitting on the web , 've always ended up printing it out . so it 's it 's you 're you 're not necessarily gonna be sitting at the desk all the time , you wanna figure you have train ride , and there 's all these situations where this is how was imagining it , anyway . and then figured , that out of that group , there would be subset who would go "" 'm really not about this section here , "" and then that group would need it if 'm right in that , it seems like you 're setting it up for the most infrequent case , rather than for the most frequent case . so that , now we have to worry about privacy ,
C: no fre for the most
E: we have to worry about all these passwords , for different people
C: for the most frequent case they just say "" it 's "" and then they 're done . and almost everyone would rather do that by email than any other method .
F: the other thing too is it seems like
E: , that 's true .
C: cuz you don't have to visit the web page if you don't want to .
E: we don't need their signature . an email is alright .
C: that was another thing had assumed that we didn't need their signature , that it that an email approval was sufficient . but don't actually know .
B: are are people going to be allowed to bleep out sections of meeting where they weren't speaking ?
C: if someone feels strongly enough about it , then they should be allowed to do that .
B: so that means other people are editing what you say ? if like that .
C: the only other choice is that the person would say "" no , don't distribute this meeting "" , and would rather they were able to edit out other people then just say "" don't distribute it "" .
E: but th what they signed in the consent form , was something that said you can use my voice .
C: but if someone is having conversation , and you only bleep out one side of it , that 's not sufficient .
E: but that 's our decision then .
C: because if object to the conversation . if say "" we were having conversation , and consider that conversation private , "" and consider that your side of it is enough for other people to infer , wanna be able to bleep out your side .
F: agree that the consent forms were , cons agree with what adam 's saying , that , the consent form did leave open this possibility that they could edit things which they found offensive whe whether they said them or didn't say them .
E: , if that 's what it said .
F: and the other thing is from the standpoint of the 'm not law lawyer , but it strikes me that , we wouldn't want someone to say "" yes , was little concerned about it but it was too hard to access "" . so it 's to have this facility to listen to it . now in terms of like editing it by hand , it 's some people would find that easier to specify the bleep part by having document they edited . but but it seems to me that sometimes , if person had bad day , and they had tone in their voice that they didn't really like , it 's it 's to be able to listen to it and be that was .
C: certainly provide printable version if people want it .
E: it 's also mixture of people , some people are do their work primarily by sitting at the computer , flipping around the web , and others do not . others would consider it this set of skills that they would have to gain .
C: most of the people in the meetings are the former .
E: it depends on what meetings .
F: that 's true .
E: in the meetings so far , . but we 're trying to expand this , so actually think that paper is the more universal thing .
C: but if they want to print it out that 's alright . everyone in the meeting can access the web .
E: no , we have to be able to print it out . it 's not just if they want to print it out .
C: so does that mean that 't use email ?
F: cuz you could send it through email you 're thinking .
C: don't think we can send the text through email because of the privacy issues . so giving them , you think web site to say , "" if you wanna print it out here it is "" , is not sufficient ?
E: certainly for everybody who 's been in the meetings so far it would be sufficient .
C: 'm just thinking for people that 's not sufficient for , what the only sufficient thing would be for me to walk up to them and hand it to them .
E: 'm just wondering about
F: you could mail it to them . get an mailing address . but it 's easier to drop in the box .
A: just put the button on the web page which say "" send me the scripts "" .
C: that 's right .
F: that 's interesting .
B: when you display it on the web page , what are what are you showing them ? and so can they bleep within an utterance ?
C: whole utterances only . and that was just convenience for my sake , that it 's , it would end up being fairly difficult to edit the transcripts if we would do it at the sub - utterance level . because this way just delete an entire line out of transcript file rather than have to do it by hand .
E: there 's another aspect to this which maybe is part of why this is bothering me . you 're really trying very hard to make this as convenient as possible for people to do this .
C: that 's why did the web form , because for me that would be my most convenient .
B: know where you 're going .
E: that 's the bad idea . see because you 're gon you 're you 're gonna end up with all these little patchy things , whereas really what we want to do is have the the bias towards letting it go . one or twi once or twice , in the re in the meetings we 've heard , where somebody said something that they might be embarrassed by , but overall people are talking about technical topics . nobody 's gonna get hurt . nobody 's being libeled . this is this we 're covering we 're playing the lawyer 's game , and we 're playing we 're we 're looking for the extreme case . if we really orient it towards that extreme case , make it really easy , we 're gonna end up encouraging headache . 'm psyching myself out here ,
C: don't see having few phrases here and there in meeting being that mu much of headache , bleeped out .
B: what morgan 's saying is the easier it is , the more is gonna be bleeped .
E: and and it really depends on what research you 're doing . some researchers who are gonna be working with this corpus years from now are really gonna be cursing the fact that there 's bunch of in there that 's missing from the dialogue . it depends on the research they 're doing , but it might be , it might be really pain . and , where it 's really gonna hurt somebody , in some way the one who said it or someone who is being spoken about , we definitely want to allow the option of it being bleeped out . but really think we wanna make it the rare incidence . and and , am just little worried about making it so easy for people to do , and so much fun ! that they 're gonna go through and bleep out .
F: so much fun .
E: and they can bleep out they don't like too , from somebody else , as you say , so "" didn't like what he said . ""
C: don't see any way of avoiding that . we have to provi we have promised that we would provide them the transcript and that they can remove parts that they don't like .
E: no , no , don't
C: the only question is
E: you - you 've talked me into that , but think that we should make it harder to do .
C: the problem is if it 's harder for them it 's also harder for me . whereas this web interface , get email , it 's all formatted , it 's all ready to go and just insert it .
E: so maybe you don't give them access to the web interface unless they really need it . so so maybe this is way out of it . you 've provided something that 's useful for you to do handle , and useful for someone else if they need it . but the issue of privacy and ease and should be that , they get access to this if they really need it .
B: so you 're saying the sequence would be more like first adam goes to the contact lists , contacts them via whatever their preferred method is , to see if they want to review the meeting . and then if they don't , you 're done . if they do , then he provides them access to the web site .
C: to some extent have to do that anyway because as said we have to distribute passwords .
B: or printed - out form .
E: but you don't necessarily have to distribute passwords is what 'm saying .
B: only if they want it .
C: what 'm saying is that 't just email them the password because that 's not secure . so they have to call me and ask .
E: no , no . but you aren't necessarily giving them but we don't even necessarily need to end up distributing passwords .
C: we do because of privacy . we can't just make it openly available on the web .
E: no , no . you 're missing the point . we 're we 're trying we 're trying to make it less of an obvious just fall off log , to do this .
F: not everyone gets password , unless they ask for it .
E: so th so what would see , is that first you contact them and ask them if they would like to review it for to check for the not just for fun , but to check this for things that they 're worried about having said or if they 're willing to just send an approval of it , at from their memory . and , , and we should think carefully actually we should review go through how that 's worded , then , if someone wants to review it , , and know you don't like this , but 'm offering this as suggestion , is that is that we then give them print out . and then if they say that "" have potential problem with these things , "" then , you say "" you might wanna hear this in context to you need that , "" you issue them password , in the
C: but the problem with what you 're suggesting is it 's not just inconvenient for them , it 's inconvenient for me . because that means multiple contacts every time for every single meeting every time anyone wants anything . would much prefer to have all be automatic , they visit the web site if they want to . they don't have to .
E: know you 'd prefer it , but the proble
C: so you 're thinking people are going to arbitrarily start bleeping and don't think that 's gonna happen .
E: there 's problem with it .
F: 'm also concerned about the spirit of the of the informed consent thing . cuz if they feel that , it 's th th if it turns out that something gets published in this corpus that someone really should have eliminated and didn't detect , then it could have been because of their own negligence that they didn't pursue that next level and get the password and do that , but they might be able to argue "" it was cumbersome , and was busy and it was gonna take me too much time to trace it down "" . so it could that the burden would come back onto us . so 'm little bit worried about , making it harder for them , from the legal standpoint .
E: you can go too far in that direction , and you need to find somewhere between ,
C: it seems to me that sending them email , saying "" if you have an - reply to this email and say , if you have problem with it contact me and 'll give you password "" , seems like is perfectly , reasonable compromise . and if they want printout they can print it out themselves .
F: or we could print it up for them , we could offer that but there 's , another aspect to that and that is that in the informed consent form , , my impression is that they that we offered them at the very least that they definitely would have access to the transcript . that there 's chance of really skipping that stage . maybe misinterpreted what you said but it 's
E: having access to it doesn't necessarily mean , that having it
F: giving it to them .
E: it just means they have the right to have it .
C: the consent form is right in there if anyone wants to look at it , you want me to grab one ? but you 're wired
F: that is true .
E: , don't wanna fool them , meant that every ev any time you say anything to anyone there is bias that is presented ,
C: "" if you agree to participate you 'll have the opportunity to have anything ex anything excised , which you would prefer not to have included in the data set . ""
F: that 's true .
C: "" once transcript is available we will ask your permission to include the data in the corpus for the larger research community . there again you will be allowed to indicate any sections that you 'd prefer to have excised from the database , and they will be removed both from the transcript and the recording . ""
F: that 's more open than realized .
C: the one question is definitely clear with anything as opposed to just what you said .
E: no that it tha
F: tha - that 's true . that 's more severe , but the next one says the transcript will be around .
E: that 's right .
F: and it doesn't really say we 'll send it to you , or wi it 'll be available for you on the web , or anything .
B: it probably leaves it open how we get it to them .
F: at least it more often . it means also we don't have to to give it to them . like morgan was saying they
C: they just have to make that it is available to them .
F: it 's available to them if they ask for it .
E: so . wh have an idea that may be sat may satisfy both you and me in this which is , , it 's it we just go over carefully how these notes to people are worded . so want it to be worded in such way where it gives the strong impre it gives very , nothing hidden , very strongly the bias that we would really like to use all of these data . that that we really would rather it wasn't patchwork of things tossed out , that it would be better for , , our , , field if that is the case . but if you really mething is gonna and don't think there 's anything in the legal aspects that is hurt by our expressing that bias .
F: great , great .
E: and then my concern about which you might be right , it may be it was just paranoia on my part , but people just see 'm @ @ worried about this interface so much fun that people start bleeping out just as just because they can .
C: it 's just check box next to the text , it 's not any fun .
E: had fun when you played me something that was bleeped out .
C: but they won't get that feedback . no because it doesn't automatically bleep it at the time . it just sends me
E: so you haven't made it so much fun .
C: it just sends me the time intervals . and then at some point 'll incorporate them all and put bleeps . don't wanna have ha do that yet until we actually release the data because , then we have to have two copies of every meeting and we 're already short on disk space . so wanna keep the times until we actually wanna release the data and then we bleep it .
E: so if we have if again let 's , circulate the wording on each of these things and get it right ,
C: since you seem to feel heart , strongest about it , would you like to do the first pass ?
E: turn about is fair play ,
F: al - also it ther there is this other question , the legal question that adam 's raised , about whether we need concrete signature , or email suffices or whatever and how that works . there 's something down there about "" if you agree to ""
E: 'm 'm about it with one of my background processes and it 's , it 's fine to do the email .
C: because thi th they 're signing here that they 're agreeing to the paragraph which says "" you 'll be given an opportunity . "" and so don't think they need another signature .
E: it 's now fairly routine in lot of arrangements that do with people on contracts and that if it 's if it 's that thing where you 're saying "" agree , we want eighty hours of this person at such - and - such amount , and agree that 's , "" if it 's follow up to some other agreement where there was signature it 's often done in email now so it 's it 's .
C: so probably should at the minimum , think about how to present it in printed form . 'm not really what 's best with that . the problem is lot of them are really short , and so don't necessarily wanna do one per line . but how else to do it .
F: it 's you have it , viewab her hearable on the on the web for those who might wonder about , the non nonverbal side , agree that our bias should be as expressed here , and but it 's that person could check . cuz sometimes you the words on on the page , come out soun sounding different in terms of the social dynamics if they hear it . and realize we shouldn't emphasize that people , shouldn't borrow trouble . what it comes down to but
C: my opinion probably is that the only time someone will need to listen to it is if the transcript is not good . if there are lots of mumbles and parentheses and things like that .
F: , or what if there was an error in the transcript that didn't get detected and there was whole segment against some personal th
C: that was all mumbled ?
F: or or even or even there was line about how "" - mmm bill gates duh - duh - duh . "" but it was all the words were all visible , but they didn't end up some there was slip in the transcript .
C: they 're gonna hate this meeting .
F: that 's true .
C: actually liz will like it .
E: liz will like it . we had pretty strong disagreement going there .
C: , that 's right .
F: we 're assuming that the transcript is close enough approximation and that my double checking will be so close to perfect that it that nothing will slip by .
E: some something might sometime , and they if it 's something that they said , they might you might be very accurate in putting down what they actually said , but , when they hear it , themselves , they may hear something different because they they meant .
F: how to notate that . that 's right .
B: how do you how do you indicate sarcasm ?
F: that 's right .
E: no , 'm serious . so the so the so we might we might get some feedback from people that such - and - such was , , not really what said .
C: that would be good to get , definitely . just for corrections . so , in terms of password distribution , phone is really the only way to do it , phone and in person . or mail , physical mail .
F: leave it on their voice mail .
B: any sub - word level thing .
C: any sub - wor you could do it with pgp or things like that but it 's too complex .
F: realized something , which is of th this question about the the possible mismatch of and actually also the lawyer saying that , we shouldn't really have them have the people believing that they will be cleared by our checks . so it 's like in way it 's it 's to have the responsibility still on them to listen to the tape and hear the transcript , to have that be the
E: but you can't dep most people will not wanna take the time to do that , though .
F: , fair enough . and they 're they 're absorbing the responsibility themselves .
E: and they have to
F: so it 's not it 's not
E: but if you were at meeting , and you don't think , at least , that you said anything funny and the meeting was about , , some funny thing about semantics , or
C: you probably won't listen to it .
F: it is true that tec that the content is technical , and so and we 're not having these discussions which when listen to these things , don't find things that are questionable , in other people 's speech or in my own .
E: you would would be rare ,
F: it should be very rare .
E: we 're not talking about the energy crisis , people have
C: how about them energy crises .
E: actually , was gonna di - did you have anything that 's going on , or
D: my project is going along but , 'm really just here to fill the project the overall progress . don't really have anything specific to talk about .
E: that 's fine . didn't wanna go by you , if you had something . you don't have anything to say . transcribers , he was rattling the marbles in his brain back and forth just then this
C: shall we do digits ? we should count out how many more digits to forms do we have back there ?
B: there were quite few .
C: that 's what . was going through them all and found actually lot filed in with them , that were blanks , that no one had actually read . and so we still have more than we did . so , we have few more digits before we 're done .
B: having this headset reminds me of like working at burger king .
F: did you do that ?
C: 'd like burger with that ,
B: no never did .
C: do you want fries with that ?
B: but feel like could now .
","The Berkeley Meeting Recorder group discussed recording equipment issues , including the purchase of two additional headsets and the prospect of getting a new base station and a set of wireless microphones to replace those wired microphones currently in use.
Speaker fe008 presented the current status on transcriptions , and explained procedures for cleaning up transcripts and ensuring they conform with set conventions.
Speaker mn014 briefly described his efforts to normalize loudness levels across speech channels to distinguish between foreground and background speech.
Finally , the group discussed legal and procedural issues concerning the provision of transcripts to meeting participants for 'bleeping out' any sections of speech they want excluded from the Meeting Recorder database.
The consent form issued to subjects prior to meetings will be revised to make more explicit details concerning access to transcripts and the ability of subjects to mark sections of meetings for exclusion from the database.
The group decided to replace wired microphones with a wireless setup , i.e . a new base station and set of wireless microphones.
Efforts will be made to ensure that recording conventions are consistent across ICSI , the University of Washington , and SRI.
Some of the meeting recordings contain spikes.
It was surmised that such disturbances are probably due to the connectors attached to a set of wired microphones in use.
With respect to editing bleeps , should participants be allowed to edit out others' speech?
It was suggested that making transcripts available to all of the subjects involved might make it too easy for them to edit out sections of meetings , whereas the bias should be to ensure that editing bleeps occur only rarely in the database.
Two additional wireless headsets will soon be made available.
Approximately 32-35 hours of meeting data have been recorded , roughly 30 hours of which comprise non-digits recordings.
The transcribers have begun performing digit extraction ( see abstract for Bmr013 ) and should be finished within a few days.
Approximately 11 hours of speech have been transcribed.
Efforts by speaker fe008 are in progress to ensure that transcripts are clean ( i.e . spell checked ) , channelized , and conform to set conventions regarding the coding of numbers , acronyms , and explicit comments ( e.g . door slams , coughs , and laughter ).
Subsequent efforts by speaker fe008 will be to tighten up boundaries on the time bins.
Inter-annotator agreement was reported to be very good.
Speaker mn014's multi-channel speech/non-speech segmenter is in use.
The SRI recognizer will be fed with pre-segmented output to eliminate difficulties with processing overly long speech segments.
Efforts by speaker mn014 to normalize loudness and distinguish between foreground and background speech have been largely successful.
The group discussed procedural issues concerning the provision of transcripts to meeting participants for 'bleeping out' any sections of speech they want excluded from the Meeting Recorder database.
"
ami_abstractive_summary,Bed002.txt,"A: we 're on . so just make that th your wireless mike is on , if you 're wearing wireless . and you should be able to see which one which one you 're on by , , watching the little bars change .
B: so , which is my bar ?
A: so , actually , if you guys wanna go ahead and read digits now , as long as you 've signed the consent form , that 's alright .
E: are we supposed to read digits at the same time ?
A: we 're talking about doing all at the same time but cognitively that would be really difficult . to try to read them while everyone else is .
E: everyone would need extreme focus .
A: so , when you 're reading the digit strings , the first thing to do is just say which transcript you 're on .
C: we we may wind up with ver we we may need versions of all this garbage .
A: so the first thing you 'd wanna do is just say which transcript you 're on . you can see the transcript ? there 's two large number strings on the digits ? so you would just read that one . and then you read each line with small pause between the lines . and the pause is just so the person transcribing it can tell where one line ends and the other begins . and 'll give 'll read the digit strings first , so can see how that goes . again , 'm not how much should talk about before everyone 's here .
C: we have one more coming .
A: why don't go ahead and read digit strings and then we can go on from there .
C: we can start doing it .
A: so , , just also note on wearing the microphones . all of you look like you 're doing it reasonably correctly , but you want it about two thumb widths away from your mouth , and then , at the corner . and that 's so that you minimize breath sounds , so that when you 're breathing , you don't breathe into the mike . that 's good . so , everyone needs to fill out , only once , the speaker form and the consent form . and the short form you should read the consent form , but , the thing to notice is that we will give you an opportunity to edit all the transcripts . so , if you say things and you don't want them to be released to the general public , which , these will be available at some point to anyone who wants them , , you 'll be given an opportunity by email , , to bleep out any portions you don't like . on the speaker form just fill out as much of the information as you can . if you 're not exactly about the region , we 're not exactly either . so , don't worry too much about it . the it 's just self rating . and that 's about it . should do you want me to talk about why we 're doing this and what this project is ?
C: no . there was there was let 's see .
E: does nancy know that we 're meeting in here ?
B: sent an email .
C: she got an emai she was notified . whether she knows is another question . so are the people going to be identified by name ?
A: what we 're gonna we 'll anonymize it in the transcript . but not in the audio .
C: so , then in terms of people worrying about , , excising things from the transcript , it 's unlikely . since it does isn't attributed . but the but the but the
A: right , so if said , "" , hi jerry , how are you ? "" , we 're not gonna go through and cancel out the "" jerry ""s . so we will go through and , in the speaker id tags there 'll be , , - one seven , - one eight . good way of doing it on the audio , and still have people who are doing discourse research be able to use the data .
C: no , wasn't complaining , wanted to understand .
B: we can make up aliases for each of us .
A: , whatever you wanna do is fine , but we find that we want the meeting to be as natural as possible . so , we 're trying to do real meetings . and so we don't wanna have to do aliases and we don't want people to be editing what they say . so that it 's better just as pro post - process to edit out every time you bash microsoft .
C: . so why don't you tell us briefly your give your normal schpiel .
A: so this is the project is called meeting recorder and there are lots of different aspects of the project . so my particular interest is in the pda of the future . this is mock - up of one . yes , we do believe the pda of the future will be made of wood . the idea is that you 'd be able to put pda at the table at an impromptu meeting , and record it , and then be able to do querying and retrieval later on , on the meeting . so that 's my particular interest , is portable device to do , information retrieval on meetings . other people are interested in other aspects of meetings . so the first step on that , in any of these , is to collect some data . and so what we wanted is room that 's instrumented with both the table top microphones , and these are very high quality pressure zone mikes , as as the close talking mikes . what the close talk ng talking mikes gives us is some ground truth , gives us , , high quality audio , especially for people who aren't interested in the acoustic parts of this corpus . so , for people who are more interested in language , we didn't want to penalize them by having only the far field mikes available . and then also , , it 's very , very hard task in terms of speech recognition . and so , , on the far field mikes we can expect very low recognition results . so we wanted the near field mikes to at least isolate the difference between the two . so that 's why we 're recording in parallel with the close talking and the far field at the same time . and then , all these channels are recorded simultaneously and framed synchronously so that you can also do things like , , beam - forming on all the microphones and do research like that . our intention is to release this data to the public , , probably through through body like the ldc . and , , just make it as generally available corpus . there 's other work going on in meeting recording . so , we 're we 're working with sri , nist has started an effort which will include video . we 're not including video , . and and then also , , small amount of assistance from ibm . is also involved . , and the digit strings , this is just more constrained task . so because the general environment is so challenging , we decided to do at least one set of digit strings to give ourselves something easier . and it 's exactly the same digit strings as in ti - digits , which is common connected digits corpus . so we 'll have some , , comparison to be able to be made . so when the last person comes in , just have them wear wireless . it should be on already . either one of those . and , read the digit strings and fill out the forms . so , the most important form is the consent form , so just be be everyone signs that , if they consent .
B: 'm it 's pretty usual for meetings that people come late , so you will have to leave what you set .
A: and , just give me call , which , my number 's up there when your meeting is over . and 'm going to leave the mike here but it 's {nonvocalsound} , but 'm not gonna be on so don't have them use this one . it 'll just be sitting here .
B: there we go .
C: adam , we will be using the , , screen as . so you guys who got email about this , friday about what we 're up to .
E: what was the nature of the email ?
C: this was about , inferring intentions from features in context , and the words , like "" go to see "" , or "" visit "" , or some you didn't get it ? these have got better filters . cuz sent it to everybody . you just blew it off .
B: it 's really simple though . so this is the idea . we could pursue , , if we thought it 's it 's worth it but , , we will agree on that , , to come up with with very , very first crude prototype , and do some implementation work , and do some research , and some modeling . so the idea is if you want to go somewhere , focus on that object down actually walk with this . that 's the powder - tower . now , , we found in our , , data and from experiments , that there 's three things you can do . you can walk this way , and come really , really close to it . and touch it . but you cannot enter or do anything else . unless you 're interested in rock climbing , it won't do you no good standing there . it 's just dark alley . but you can touch it . if you want to actually go up or into the tower , you have to go this way , and then through some buildings and up some stairs and . if you actually want to see the tower , and that 's what actually most people want to do , is just have good look of it , take picture for the family , you have to go this way , and go up here . and there you have vre really view it exploded , the during the thirty years - war . really , interesting sight . and , these these lines are , , paths , or so that 's ab er , the street network of our geographic information system . and you can tell that we deliberately cut out this part . because otherwise we couldn't get our gis system to take to lead people this way . it would always use the closest point to the object , and then the tourists would be faced , , in front of wall , but it would do them no good . so , what we found interesting is , first of all , intentions differ . maybe you want to enter building . maybe you want to see it , take picture of it . or maybe you actually want to come as close as possible to the building . for whatever reason that may be .
E: what 's it what 's it made out of ? so maybe you would wanna touch it .
B: maybe you would want to touch it . this , these intentions , we we could , if we want to , call it the vista mode , where we just want to get the overview or look at it , the enter mode , and the , , tango mode . always come up with silly names . so this "" tango "" means , literally translated , "" to touch "" . so but sometimes the tango mode is really relevant in the in the sense that , , if you want to , if you don't have the intention of entering your building , but that something is really close to it , and you just want to approach it , or get to that building . consider , , the post office in chicago , building so large that it has its own zip code . so the entrance could be miles away from the closest point . so sometimes it makes sense maybe to to distinguish there . so , , 've looked , , through twenty some didn't look through all the data . and there 's , lot more different ways in people , the ways people phrase how to get if they want to get to certain place . and sometimes here it 's it 's little bit more obvious maybe should go back couple of steps and go through the
C: no , come in , sit down . if you grab yourself microphone .
B: you need to sign some and read some digits .
C: you can sign afterwards .
E: you have to al also have to read some digits .
D: . afterwards is fine .
B: they are uncomfortable . but that was our idea .
C: and it it also has to be switched on , nance .
E: no , that one 's already on , he said .
C: it 's on ?
D: it 's on .
B: that was the idea . people , when they when they want to go to building , sometimes they just want to look at it . sometimes they want to enter it . and sometimes they want to get really close to it . that 's something we found . it 's just truism . and the places where you will lead them for these intentions are sometimes ex in incredibly different . gave an example where the point where you end up if you want to look at it is completely different from where if you want to enter it . so , this is how people may , may phrase those requests to mock - up system at least that 's the way they did it . and we get tons of these "" how do get to "" , "" want to go to "" , but also , "" give me directions to "" , and "" would like to see "" . and , what we can do , if we look closer closer at the data that was the wrong one . we can look at some factors that may make difference . first of all , and , that 've completely forgot that when we talked . this is crucial factor , "" what type of object is it ? "" so , some buildings you just don't want to take pictures of . or very rarely . but you usually want to enter them . some objects are more picturesque , and you more more highly photographed . then the actual phrases may give us some idea of what the person wants . sometimes found in the , looking at the data , in superficial way , found some modifiers that may also give us hint , "" 'm trying to get to "" "" need to get to "" . hints to the fact that you 're not really sightseeing and just there for pleasure and and so on . and this leads us straight to the context which also should be considered . that whatever it is you 're doing at the moment may also inter influence the interpretation of phrase . so , this is , , really my suggestion is really simple . we start with , now , let me , , say one more thing . what we do know , is that the parser we use in the smartkom system will never differentiate between any of these . so , all of these things will result in the same xml - three - structure . action "" go "" , and then an object . so it 's it 's way too crude to capture those differences in intentions . so , , "" mmm ! maybe for deep understanding task , that 's playground or first little thing . "" where we can start it and look "" , we need , we gonna get those - three - structures . the crude , undifferentiated parse . we may need additional part of speech , or maybe just some information on the verb , and modifiers , auxiliaries . we 'll see . and will try to come up with list of factors that we need to get out of there , and maybe we want to get switch for the context . so this is not something which we can actually monitor , now , but just is something we can set . and then you can all imagine constrained satisfaction program , depending on what , , comes out . we want to have an structure resulting if we feed it through belief - net along those lines . we 'd get an inferred intention , we produce structure that differentiates between the vista , the enter , and the , , tango mode . which we maybe want to ignore . but . that 's my idea . it 's up for discussion . we can change all of it , any bit of it . throw it all away .
F: now @ @ this email that you sent , actually . now remember the email .
E: still , have no recollection whatsoever of the email . 'll have to go back and check .
C: so , what is important is that we understand what the proposed task is . and , the , robert and talked about this some on friday . and we 's - formed . so we 's - formed , , starter task for this , , deeper understanding in the tourist domain .
F: so , where exactly is the , , deeper understanding being done ? like , is it before the bayes - net ?
C: it 's the it 's always all of it . so , in general it 's always going to be , the answer is , everywhere . so the notion is that , , this isn't real deep . but it 's deep enough that you can distinguish between these th three quite different kinds of , , going to see some tourist thing . and , so that 's that 's the quote "" deep "" that we 're trying to get at . and , robert 's point is that the current front - end doesn't give you any way to not only doesn't it do it , but it also doesn't give you enough information to do it . it isn't like , if you just took what the front - end gives you , and used some clever inference algorithm on it , you would be able to figure out which of these is going on . and this is bu - in general it 's gonna be true of any deep understanding , there 's gonna be contextual things , there 're gonna be linguistic things , there 're gonna be discourse things , and they gotta be combined . and , my idea on how to combine them is with belief - net , although it may turn out that some different thing is gonna work better . the idea would be that you , , take your you 're editing your slide ?
B: as , as get ideas , so , discourse about that . that needs to go in there .
C: so . this is minutes taking minutes as we go , in his in his own way . anyway . so , , naively speaking , you 've you 've got for this little task , belief - net , which is going to have as output , the conditional pr probability of one of three things , that the person wants to , to view it , to enter it , or to tango with it . so that the output of the belief - net is pretty formed . and , then the inputs are going to be these kinds of things . and , then the question is there are two questions is , , one , where do you get this information from , and two , what 's the structure of the belief - net ? so what are the conditional probabilities of this , that , and the other , given these things ? and you probably need intermediate nodes . we what they are yet . so it may be that , , , that , , knowing whether another thing you want is some information abou , about the time of day . now , they may wanna call that part of context . but the time of day matters lot . and , if things are closed , then , you
B: people won't want to enter it .
C: pe - people don't wanna enter them . and , if it 's not obvious , you may want to actually , point out to people that it 's closed , what they 're going to is closed and they don't have the option of entering it . so another thing that can come up , and will come up as soon as you get serious about this is , that another option is to have more of dialogue . so if someone says something you could ask them . and now , one thing you could do is always ask them , but that 's boring . and it also it also be pain for the person using it . so one thing you could do is build little system that , said , "" whenever you got question like that 've got one of three answers . ask them which one you want . "" but that 's , , not what we 're gonna do .
B: but maybe that 's false state of the system , that it 's too close to call .
C: you want the you want the ability to you want the ability to ask , but what you don't wanna do is onl build system that always asks every time , that 's not getting at the scientific problem , in general you 're , it 's gonna be much more complex than that . this is purposely really simple case .
B: have one more point to bhaskara 's question . also the the deep understanding part of it is going to be in there to the extent that we , want it in terms of our modeling . we can start , , basic from human beings , going , walking , seeing , we can mem model all of that and then compose whatever inferences we make out of these really conceptual primitives . that will be extremely deep in the in my understanding .
C: so the way that might come up , if you wanna suppose you wanted to do that , you might say , "" , as an intermediate step in your belief - net , is there source - path - goal schema involved ? "" and if so , , is there focus on the goal ? or is there focus on the path ? and that could be , , one of the conditiona th the in some piece of the belief - net , that could be the appropriate thing to enter .
F: so , where would we extract that information from ? from the - three - ?
C: no . see , the - three - is not gonna give th what he was saying is , the - three - does not have any of that . all it has is some really crude saying , "" person wants to go to place . ""
E: the - three - is the old smartkom output ?
C: - three , - three - itself refers to multimedia mark - up language .
E: it 's just language .
C: so we have th we have to have better way of referring to
B: the parser output ? "" analyzed speech "" it 's what they call it , th no , actually , intention lattices is what we 're gonna get .
C: is - but they they call it intention lattice ,
B: in - in intention lattice hypothesis . they call it intention hypotheses .
C: so , th they 're gonna give us some cr or we can assume that you get this crude information . and that 's all they 're going to provide . and they don't give you the object , they don't give you any discourse history , if you want to keep that you have to keep it somewhere else .
B: they keep it . we have to request it . but it 's not in there .
C: they kee they keep it by their lights . it may it may or may not be what we want .
E: so , if someone says , "" wanna touch the side of the powder - tower "" , that would , we need to pop up tango mode and the and the directions ?
C: if if , if it got as simple as that , . but it wouldn't .
E: but that doesn't necessarily but we 'd have to infer source - path - goal to some degree for touching the side , right ?
B: th the there is point there if understand you . correct ? because , sometimes people just say things this you find very often . "" where is the city hall ? "" and this do they don't wanna sh see it on map , or they don't wanna 's five hundred yards away from you , or that it 's to the your north . they wanna go there . that 's what they say , is , "" where is it ? "" . where is that damn thing ?
E: and the parser would output
B: that 's question mark . lot of parsers , , that 's way beyond their scope , is of interpreting that . still outcome the outcome will be some form of structure , with the town hall and maybe saying it 's wh focus on the town hall . but to interpret it , somebody else has to do that job later .
E: 'm just trying to figure out what the smartkom system would output , depending on these things .
B: it will probably tell you how far away it is , at least that 's that 's even what deep map does . it tells you how far away it is , and shows it to you on map . because we can not differentiate , at the moment , between , , the intention of wanting to go there or the intention of just know wanting to know where it is .
D: people no might not be able to infer that either , right ? like the fact like , could imagine if someone came up to me and asked , "" where 's the city hall ? "" , might say , ar "" are you trying to get there ? "" because how describe , its location , probably depend on whether should give them , , directions now , or say , , whatever , "" it 's half mile away "" like that .
B: it 's granularity factor , because where people ask you , "" where is new york ? "" , you will tell them it 's on the east coast . you won't tell them how to get there , ft , take that bus to the airport and blah - blah . but if it 's the post office , you will tell them how to get there . so th they have done some interesting experiments on that in hamburg as .
C: go go back to the , th
B: so this is "" onto "" is knowledge about buildings , their opening times , and then coupled with time of day , , this should
D: so that context was like , , their presumed purpose context , like business or travel , as as the utterance context , like , "" 'm now standing at this place at this time "" .
C: we ought to as we have all along , we we 've been distu distinguishing between situational context , which is what you have as context , and discourse context , which you have as dh , what the means . so we can work out terminology later . so , they 're they 're quite distinct . you need them both , but they 're quite distinct . and , so what we were talking about doing , as first shot , is not doing any of the linguistics . except to find out what seems to be useful . so , the the reason the belief - net is in blue , is the notion would be this may be bad dis bad idea , but the idea is to take as first goal , see if we could actually build belief - net that would make this three way distinction , in plausible way , these we have all these transcripts and we 're able to , by hand , extract the features to put in the belief - net . saying , "" aha ! here 're the things which , if you get them out of out of the language and discourse , and put them into the belief - net , it would tell you which of these three , intentions is most likely . "" and if to actually do that , build it , , run it run it on the data where you hand - transcribe the parameters . and see how that goes . if that goes , then we can start worrying about how we would extract them . so where would you get this information ? and , expand it to other things like this . but if we can't do that , then we 're in trouble . th if you can't do this task ,
B: we need different , , engine .
C: it if it if it 's the belief - nets , we 'll switch to , logic or some terrible thing , but don't think that 's gonna be the case . that , , if we can get the information , belief - net is perfectly good way of doing the inferential combination of it . the real issue is , do what are the factors involved in determining this ? hold on hold on second . so , know . , is it clear what 's going on here ?
D: missed the beginning , could you back to the slide , the previous one ? so , is it that it 's , these are all factors that , these are the ones that you said that we are going to ignore now ? or that we want to take into account ?
C: take them into account . but but you don't worry about
D: take the linguistic factors too . how to extract these features .
C: how to extract them . so , let 's find out which ones we need first ,
D: and and it 's clear from the data , , like , sorta the correct answer in each case .
C: let 's go back to th let 's go back to the the slide of data .
D: that 's that 's the thing 'm curious ab like do we know from the data wh which
B: not from that data . but , , since we are designing an , compared to this , even bigger data collection effort , , we will definitely take care to put it in there , in some shape , way , form over the other , to see whether we can , then , get empirically validated data . from this , we can sometimes , an and that 's that but that isn't that what we need for belief - net anyhow ? sometimes when people want to just see it , they phrase it more like this ? but it doesn't exclude anybody from phrasing it differently , even if they still but then other factors may come into play that change the outcome of their belief - net . so , , this is exactly what because you can never be . and 'm even the most , , deliberate data collection experiment will never give you data that say , "" , if it 's phrased like that , the intention is this . "" because then , , you
D: the only way you could get that is if you were to give th the subjects task . where you have where your , , current goal is to
B: that 's what we 're doing . but but we will still get the phrasing all over the place .
D: so that 's what you want ? so you will know . the no , that 's fine . it 's just knowing the intention from the experimental subject .
C: from that task , . so , , you all know this , but we are going to actually use this little room and start recording subjects probably within month . so , this is not any lo any of you guys ' worry , except that we may want to push that effort to get information we need . so our job is to figure out how to solve these problems . if it turns out that we need data of certain sort , then the data collection branch can be , , asked to do that . and one of the reasons why we 're recording the meeting for these guys is cuz we want their help when we we start doing , recording of subjects . so , you 're right , though . no , you will not have , and there it is ,
D: and the other concern that has come up before , too , is if it 's if this was collected what situation this data was collected in . was it is it the one that you showed in your talk ?
B: no , no .
D: so was this , like , someone actually mobile , like using device ?
B: no , no not but not with real wizard system . so there were never answers .
D: but , is it the situation of collecting th the data of , like here you could imagine them being walking around the city . as like one situation . and then you have all sorts of other situational context factors that would influence how to interpret , like you said , the scope and things like that . if they 're doing it in "" 'm sitting here with map and asking questions "" , would imagine that the data would be really different . so it 's just
B: but it was never th the goal of that data collection to serve for sat for such purpose . so that 's why the tasks were not differentiated by intentionality , there was there was no label , intention , intention , intention . or task , , . 'm we can produce some if we need it , that will help us along those lines . but , , you gotta leave something for other people to model . so , to finding out what , , situational con what the contextual factors of the situation really are , is an interesting interesting thing . 'm , at the moment , curious and 'm want to approach it from the end where we can start with this toy system that we can play around with , so that we get clearer notion of what input we need for that , what suffices and what doesn't . and then we can start worrying about where to get this input , what do we need , ultimately once we are all experts in changing that parser , , maybe , there 's just couple three things we need to do and then we get more whatever , part of speech and more construction - type - like out of it . it 's pragmatic approach , , at the moment .
E: how exactly does the data collection work ? do they have map , and then you give them scenario of some sort ?
B: imagine you 're the subject . you 're gonna be in here , and and you see , , either th the three - model , or , quicktime animation of standing in square in heidelberg . so you actually see that . first thing is you have to read text about heidelberg . so , just off textbook , , tourist guide , to familiarize , , yourself with that odd - sounding german street names , like fischergasse and . so that 's part one . part two is , you 're told that this huge new , wonderful computer system exists , that can tell you everything you want to know , and it understands you completely . and so you 're gonna pick up that phone , and you get certain amount of tasks that you have to solve . first you have to know find out how to get to that place , maybe with the intention of buying stamps in there . maybe so , the next task is to get to certain place and take picture for your grandchild . the third one is to get information on the history of an object . and then the system breaks down .
D: at the third ?
B: after the third task . or after the fourth . some find @ @ forget that for now . and then , human operator comes on , and exp apologizes that the system has crashed , but , , urges you to continue , ? now with human operator . and so , you have the same tasks again , just with different objects , and you go through it again , and that was it . and one little bit and , the computer you are you are being told the computer system knows exactly where you are , via gps . when the human operator comes on , , that person does not know . so the gps is crashed as . so the person first has to ask you "" where are you ? "" . and so you have to do some tell the person where you are , depending on what you see there . this is bit that don't think we did we discuss that bit ? squeezed that in now . but it 's something , , that would provide some very interesting data for some people know .
D: so , in the display you can , you said that you cou you might have display that shows , like , the
B: additionally , you have map type display .
D: your perspective ? ? and so , as you so as you move through it that 's - they just track it on the for themselves
B: but don't think you really move , that would be an an enormous technical effort , we can show it walks to , . we can have movies of walking , you walking through heidelberg , and ultimately arriving there . maybe we wanna do that .
D: was just trying to figure out how ambitious the system is .
B: the map was intended to you want to go to that place . and it 's there . and you see the label of the name so we get those names , pronunciation , and , and we can change that .
D: so your tasks don't require you to yo you 're told so when your task is , , "" go buy stamps "" like that ? so , do you have to respond ? what are you ste what are you supposed to be telling the system ? what you 're doing now ?
B: we 'll see what people do .
D: so it 's just like , "" let 's figure out what they would say under the circumstances "" .
B: and we will record both sides . we will record the wi - the wizard in both cases it 's gonna be human , in the computer , and in the operator case . and we will re there will be some dialogue , ? so , you first have to do this , and that , see wh what they say . we can ins instruct the , , wizard in how expressive and talkative he should be . maybe the maybe what you 're suggesting is what you 're suggesting that it might be too poor , the data , if we limit it to this ping pong one , task results in question and then there 's an answer and that 's the end of the task ? you wanna have it more steps , ?
D: how much direction is given to the subject about what their interaction th they 're unfamiliar with interacting with the system . all they it 's this great system that could do .
C: but to some extent this is different discussion . so . , we have to have this discussion of th the experiment , and the data collection , and all that sorta and we do have , , student who is candidate for wizard . she 's gonna get in touch with me . it 's student of eve 's . do you do you sh - is sh
D: she started taking the class last year and then didn't , , didn't continue .
C: she 's graduated .
D: is she an undergradua she is graduate , . know her very , very briefly . know she was inter , interested in aspect and like that .
C: so , anyway , she 's looking for some more part time work while she 's waiting actually for graduate school . and she 'll be in touch . so we may have someone , , to do this , and she 's got , some background in all this . and is linguist st so . that 's so , nancy , we 'll have an at some point we 'll have another discussion on exactly wha , how that 's gonna go . and , jane , but also , , liz have offered to help us do this , , data collection and design and . so , when we get to that we 'll have some people doing it that they 're doing .
D: the reason was asking about the the de the details of this thing is that , , it 's one thing to collect data for , , speech recognition or various other tasks that have pretty clear correct answers , but with intention , , as you point out , there 's lot of di other factors and 'm not really , , how the question of how to make it appropriate toy version of that , it 's ju it 's just hard . so , , it 's
E: , actually that was my question . is the intention implicit in the scenario that 's given ? like , do the
D: it is , if they have these tasks that they 're supposed to
E: wasn't to what level of detail the task was .
B: no one is , at the moment .
C: so , we that 's part of what we 'll have to figure out . the the problem that was tr gonna try to focus on today was , let 's suppose by magic you could collect dialogues in which , one way or the other , you were able to , , figure out both the intention , and set the context , and language was used . so let 's suppose that we can get that data . the issue is , can we find way to , , featurize it so that we get some discrete number of features so that , , when we know the values to all those features , or as many as possible , we can come up with the best estimate of which of the , in this case three little intentions , are most likely .
D: what are the three intentions ? is it to go there , to see it , and
B: to come as close as possible to it .
C: th - the terminology we 're using is to
D: it 's @ @ .
C: to view it . to enter it . now those it seems to me those are cl you you have no trouble with those being distinct . "" take picture of it "" you might want to be really rather different place than entering it . and , for an object that 's big , , getting to the nearest part of it , could be quite different than either of those .
D: so now understand the referent of tango mode . didn't get that before .
E: see , would have thought it was more of waltz .
B: to "" waltz "" it ?
D: like , how close are you gonna be ? like , tango 's really close .
F: so , like , the question is how what features can like , do you wanna try to extract from , say , the parse or whatever ? like , the presence of word or the presence of certain , stem , or certain construction or whatever .
C: is there construction , or the object , or , anything else that 's in the si it 's either in the in the the discourse itself or in the context . so if it turns out that , whatever it is , you want to know whether the person 's , tourist or not , ? that becomes feature . now , how you determine that is another issue . but fo for the current problem , it would just be , "" , if you can be that it 's tourist , versus businessman , versus native , "" , , that would give you lot of discriminatory power and then just have little section in your belief - net that said , "" pppt ! "" though sin in the short run , you 'd set them , and see ho how it worked , and then in the longer run , you would figure out how you could derive them . from previous discourse or any anything else you knew .
F: so , how should what 's the , plan ? like , how should we go about figuring out these
C: so , first of all is , do either of you guys , you got favorite belief - net that you 've , , played with ?
F: no , not really .
C: anyway . get one . ? so so one of th one of the things we wanna do is actually , , pick package , doesn't matter which one , presumably one that 's got good interactive abilities , cuz lot of what we 're gonna be we don't need the one that 'll solve massive , , belief - nets quickly . these are not gonna get big in the foreseeable future . but we do want one in which it 's easy to interact with and , , modify . because that 's lot of what it 's gonna be , is , , playing with this . and probably one in which it 's easy to have , , what amounts to transcript files . so that if we have all these cases so we make up cases that have these features , and then you 'd like to be able to say , "" , here 's bunch of cases "" there 're even ones tha that you can do learning ? so you have all their cases and their results and you have algorithms to go through and run around trying to set the probabilities for you . probably that 's not worth it . my is we aren't gonna have enough data that 's good enough to make the these data fitting ones worth it , so would say you guy the first task for you two guys is to , pick package . and you wanna it , the standard things you want it stable , you want it and , as soon as we have one , we can start trying to , , make first cut at what 's going on .
B: an - nuh .
C: but it what like about it is it 's very concrete . ? we we have we the outcomes are gonna be , and we have some data that 's loose , we can use our own intuition , and see how hard it is , and , importantly , what intermediate nodes we think we need . so it if it turns out that just , thinking about the problem , you come up with things you really need to , this is the thing that is , , an intermediate little piece in your belief - net . that 'd be really interesting .
B: and it and it may serve as platform for person , maybe me , or whoever , who is interested in doing some linguistic analysis . we have the for - framenet group here , and we can see what they have found out about those concepts already , that are contained in the data , , to come up with little set of features and , maybe even means of , extracting them . and and that altogether could also be , become paper that 's going to be published somewhere , if we sit down and write it . when you said javabayes belief - net you were talking about ones that run on coffee ? or that are in the program language java ?
C: no , th it turns out that there is , the new end of java libraries . and it turns out one called which is one that fair people around here use fair amount . have no idea whether that 's the obvious advantage of that is that you can then , relatively easily , get all the other java packages for guis or whatever else you might want to do . so that that 's why lot of people doing research use that . but it may not be have no idea whether that 's the best choice an and there 're plenty of people around , students in the department who , , live and breathe bayes - nets .
D: there 's the tool kit that , kevin murphy has developed , which might be useful too .
C: so , , kevin would be good person to start with .
D: and it 's available matlab code .
C: nancy knows him . whether you guys have met kevin yet or not ,
B: but since we all probably are pretty that , , the this th the dialogue history is , producing xml documents . - three - is xml . and the ontology that , the student is constructing for me back in eml is in oil and that 's also in xml . and so that 's where lot of knowledge about bakeries , about hotels , about castles and is gonna come from . so , if it has that io capability and if it 's java package , it will definitely be able we can couple .
C: so , , we 're {nonvocalsound} committed to xml as the , , interchange . but that 's , , not big deal . so , in terms of interchanging in and out of any module we build , it 'll be xml . and if you 're going off to queries to the ontology , , you 'll have to deal with its interface . but that 's that 's fine all of these things have been built with much bigger projects than this in mind . so they have worked very hard . it 's blackboards and multi - wave blackboards and ways of interchanging and registering your that don't even worth us worrying about just yet . if we can get the core of the thing to work , in way that we 're comfortable with , then we ca we can get in and out of it with , , xml , , little descriptors .
B: , like , , the what you said about the getting input from just files about where you where you have the data , have specified the features and . that 's , , easy also to do with , , xml .
C: you could have an , you could make and xml format for that . . feature value xml format is probably as good way as any . so it 's als , it 's also worth , , while you 're poking around , poke around for xml packages that , do things you 'd like .
F: doesn't does smartkom system have such packages ?
B: the the lib - three - library does that .
C: and the question is , you you 'll have to we 'll have to that should be ay we should be able to look at that
B: what what came to my mind is was the notion of an idea that if there are nets that can actually lear try to set their own , , probability factors based on on input which is in file format , if we , , get really wild on this , we may actually want to use some corpora that other people made and , , if they are in mate , then we get documents with discourse annotations , from the discourse act down to the phonetic level . michael has project where , recognizing discourse acts and he does it all in mate , and so they 're actually annotating data and data . so if we if we 's worth it one of these days , not with this first prototype but maybe with second , and we have the possibility of taking input that 's generated elsewhere and learn from that , that 'd be .
C: it 'd be , but do don't wanna count on it . you can't you can't run your project based on the speculation that the data will come ,
B: no , no , , just for
C: and you don't have to actually design the nets .
B: just back door that we should devote
C: so in terms of the , the what the smartkom gives us for - three - packages , it could be that they 're fine , or it could be eeh . you don't , you don't really like it . so we 're not we 're not abs we 're not required to use their packages . we are required at the end to give them in their format , it doesn't control what you do in , internally .
E: what 's the time frame for this ?
B: two , three days ?
C: bu 'd like that this , this week , to ha to to have guys , , , pick the , belief - net package and tell us what it is , and give us pointer so we can play with it . and , then as soon as we have it , we should start trying to populate it for this problem . make first cut at , , what 's going on , and probably the ea easiest way to do that is some on - line way . you can figure out whether you wanna make it web site
B: was actually more joking . with the two or three days . so this was usual jo it will take as long as yo you guys need for that . but , maybe it might be interesting if the two of you can agree on who 's gonna be the speaker next monday , to tell us something about the net you picked , and what it does , and how it does that .
C: , or both of them speak .
B: or you can split it up .
C: we don't care .
B: so that will be the assignment for next week , is to for slides and whatever net you picked and what it can do and how far you 've gotten .
C: 'd like to also , though , , ha have first cut at what the belief - net looks like . even if it 's really crude . so , , here here are
E: so we 're supposed to @ @ about features and whatnot ,
C: and , as said , what 'd like to do is , what would be really great is you bring it in if if we could , , in the meeting , say , , "" here 's the package , here 's the current one we have , "" , "" what other ideas do you have ? "" and then we can think about this idea of making up the data file . , get tentative format for it , let 's say xml , that says , , "" these are the various scenarios we 've experienced . "" we can just add to that and there 'll be this file of them and when you think you 've got better belief - net , you just run it against this , this data file .
F: so we 'll be like , hand , , doing all the probabilities .
C: , unt until we know more .
E: and what 's the relation to this with changing the table so that the system works in english ?
B: so this is whi - while you were doing this , received two lovely emails . the the full nt and the full linux version are there . 've downloaded them both , and started to unpack the linux one the nt one worked fine . and started unta pack the linux one , it told me that 't really unpack it because it contains future date . so this is the time difference between germany . had to until one ' clock this afternoon before was able to unpack it . now , then it will be my job to get this whole thing running both on swede and on this machine . and so that we have it . and then hopefully that hoping that my urgent message will now come through to ralph and tilman that it will send some more documentation along , maybe that 's what will do next monday is show the state and show the system and show that .
C: so the answer , johno , is that these are , at the moment , separate . what one hopes is that when we understand how the analyzer works , we can both worry about converting it to english and worry about how it could ex extract the parameters we need for the belief - net .
E: my question was more about time frame . so we 're gonna do belief - nets this week ,
C: none of this is neither of these projects has got real tight time - line , in the sense that over the next month there 's there 's deliverable . so , it 's opportu in that sense it 's opportunistic . if if , if we don't get any information for these guys for several weeks then we aren't gonna sit around , , wasting time , trying to do the problem or what they go on and do other things .
B: but but the this point is really very , very valid that ultimately we hope that both will merge into harmonious and , , wonderful , , state where we can not only do the bare necessities , ie , changing the table so it does exactly in english what it does in german , but also that we can have the system where we can say , "" , this is what it usually does , and now we add this little thing to it "" , johno 's and bhaskara 's great belief - net , and we plug it in , and then for these certain tasks , and we know that navigational tasks are gonna be core domain of the new system , it all of sudden it does much better . because it can produce better answers , tell the person , as showed you on this map , produce either , red line that goes to the vista point or red line that goes to the tango point or red line that goes to the door , which would be great . so not only can you show that something sensible but ultimately , if you produce system like this , it takes the person where it wants to go . rather than taking him always to the geometric center of building , which is what they do now . and we even had to take out bit . nancy , you missed that part . we had to take out bit of the road work . so that it doesn't take you to the wall every time . so this was actually an actual problem that we encountered , which nobody have has because car navigation systems don't really care . they get you to the beginning of the street , some now do the house number . but even that is problematic . if you go if you wanna drive to the sap in waldorf , 'm the same is true of microsoft , it takes you to the address , whatever , street number blah - blah , you are miles away from the entrance . because the postal address is maybe mailbox somewhere . but the entrance where you actually wanna go is somewhere completely different . so unless you 're mail person you really don't wanna go there .
C: probably not then , cuz you probably can't drop the mail there anyway .
B: probably neither not even that .
E: the powder - tower is made of red limestone .
B: do you wanna see picture ? have to reboot for that though .
D: so , you two , who 'll be working on this , li are you gl will you be doing , are you supposed to just do it by thinking about the situation ? can you use the sample data ?
C: they use the sample data .
D: , ho is there more than is there lot of sample data that is beyond what you what you have there ?
B: there there 's more than showed , but , this is , in part my job to look at that and to see whether there are features in there that can be extracted , and to come up with some features that are not , empirically based on real experiment or on on reality but on your intuition of , "" aha ! this is maybe sign for that , and this is maybe sign for this . ""
F: so , . later this week we should get together , and start thinking about that , hopefully .
C: we can end the meeting and call adam , and then we wanna look at some filthy pictures of heidelberg . we can do that as .
B: they had they used the ammunition they stored the ammunition in that tower . and that 's why , when it was hit by , cannon ball , it exploded .
E: that 's why they call it the powder - tower . first thought it had something to do with the material that it that 's why asked .
D: that 's right , .
","The initial task of the EDU group is to work on inferring intentions through context.
In the navigational paradigm used for the task , these intentions are to ""see"" to ""enter"" or to ""get to the closest point of"" a building.
There will be purpose-designed experiments carried out.
However , the starting point is , through the use of existing data , to determine possible linguistic , discourse or situation features that define intentionality.
These may include the type of building , time of day , particular phrases used or whether the user is a tourist or a native.
Initially , these features will be hand-coded , but the goal is to find ways of extracting them automatically from the XML data.
Consequently , they will be fed into a belief-net -implemented on a software package like JavaBayes- and the conditional probability of each intention calculated.
A prototype system will be put together to test hypotheses regarding both the exact nature of the features and how intentions are derived from them.
Inferring intentions in a navigational context is an appropriate task both in project and real-world terms.
Its goals are clearly defined and contributre to a smarter system.
Although there are some preliminary data to work on , task-specific experiments and recordings will take place.
The XML format is going to be used has not been defined , although the SmartKom data can be used as a foundation.
In the first instance , the group will have to decide on the software package to be used for the creation and manipulation of the belief-nets.
Stability and ease-of-use -in addition to ability to handle XML- of the package are the focus at this stage , instead of the ability to handle large amounts of data.
Experts in Bayes nets within ICSI can be consulted on the matter.
The decision will be presented in the next meeting along with a first schema of the belief-nets themselves.
Possible intermediate nodes can be added to the nets after this.
The hypothesis that a set of features from which intentions can be derived exists has to be assessed , before moving on to how to extract these features from the data automatically.
Curent navigation systems do not provide for the user's particular intentions when asking for directions.
They always compute the shortest path between source and destination.
The SmartKom parser , for example , does not mark up data with features adequate for the inference of these intentions.
Although it is understandable that language , discourse and situation features will play a role in how they are weighed , the exact nature of those features is unclear.
Also hard to evaluate at this stage , is how the assumed features will combine in a belief-net , in order to provide the conditional probabilities of the users' intentions.
Even if these problems are solved , extracting the features from the data may prove to be a bottleneck.
The existing data are appropriate only for preliminary work , as they don't include intention-related information.
On the other hand , the details of the experiments that will have to be designed to get more appropriate data are not clearcut and are yet to be settled.
When asking for directions , a user of a navigational device may wish to either view , enter or simply approach a building.
This was identified as an initial problem to be tackled through ""deep understanding""-type inferences.
There is a set of data to start work on from previous work.
Similarly , the SmartKom data-format and an ontology developed for the tourist domain ( both in XML-standard formats ) can be used as groundwork for defining the features , which indicate the user's intentions.
For the creation and management of the belief-nets necessary for the task , there are readily available packages -such as JavaBayes- and tools that can provide the infrastructure for a prototype system.
"
ami_abstractive_summary,Bro026.txt,"B: so we we had meeting with , with hynek , , in which , , sunil and stephane , summarized where they were and , , talked about where we were gonna go . so that happened mid - week .
E: did you guys get your code pushed together ?
D: it 's it 's it was updated yesterday ,
A: you probably received the mail .
E: right , saw saw the note .
B: what was the update ?
A: what was the update ? so there is th then the all the new features that go in . the , , noise suppression , the re - synthesis of speech after suppression .
E: is the , the cvs mechanism working ? are are people , , up at ogi grabbing code , via that ?
A: if they use it ,
D: don't think anybody up there is like working on it right now .
B: it more likely that what it means is that when sunil is up there he will grab it .
D: so right now nobody 's working on aurora there .
B: they 're working on different task . but what 'll happen is he 'll go back up there and , , pratibha will come back from , , the east coast . and , and actually , , after eurospeech for little bit , , he 'll go up there too . so , actually everybody who 's working on it will be up there for at least little while . so they 'll remotely access it from there .
E: so has has anybody tried remotely accessing the cvs using , , ssh ?
A: if hari did that or you
D: today . , just log into
E: have you tried it yet ?
D: no , didn't . so 'll try it today .
A: actually tried wh while when installed the repository , tried from belgium . logged in there and tried to import
E: it worked good ?
A: but it 's so , right now it 's the mechanism with ssh . don't didn't set up you can also set up cvs server on new port . it 's like , main server , or you can do cvs server .
E: then that 's using the cvs password mechanism and all that ,
A: but didn't do that because was not about security problems .
E: so when you came in from belgian belgium , using ssh , , was it asking you for your own password into icsi ? so if yo you can only do that if you have an account at icsi ? cuz there is an way to set up anonymous cvs
A: you ha in this way you ca you have to set up cvs server but then , , you can access it . you can set up priorities .
E: so the anonymous mechanism
A: you can access them and mostly if you if the set the server is set up like this .
E: because lot of the open source works with anonymous cvs and 'm just wondering , , for our transcripts we may want to do that .
B: for this don't think we 're quite up to that . we 're still so much in development . we want to have just the insiders .
E: wasn't suggesting for this . 'm thinking of the meeting recorder what 's new ?
B: , maybe the thing to me might be me 'm you 've just been working on , , details of that since the meeting ,
A: mmm , since the meeting , 've been 've been train training new vad and new feature net .
B: that was that was tuesday .
A: so they should be ready .
B: but maybe the thing since you weren't yo you guys weren't at that meeting , might be just to , , recap , , the conclusions of the meeting .
E: you 're talking about the meeting with hynek ?
B: cuz that was , we 'd been working up to that , , he would come here this week and we would since he 's going out of town like now , and 'm going out town in couple weeks , , and time is marching , , given all the mu many wonderful things we could be working on , what will we actually focus on ? and , and what do we freeze ? and , , what do we ? this software that these guys created was certainly key part . so then there 's something central and there aren't at least bunch of different versions going off in ways that differ trivially . , and , ,
E: that 's that 's .
B: and then within that , the idea was to freeze certain set of options for now , to run it , , particular way , and decide on what things are gonna be experimented with , as opposed to just experimenting with everything . so keep certain set of things constant . maybe describe roughly what we are keeping constant for now ,
A: so we 've been working like six weeks on the noise compensation and we end up with something that seems reasonable .
E: are you gonna use which of the two techniques ?
A: so finally it 's it 's , , wiener filtering on fft bins . and it uses , , two steps , smoothing of the transfer function , the first step , that 's along time , which use recursion . and after this step there is further smoothing along frequency , which use sliding window of twenty fft bins .
E: so this is on the , before any mel scaling has been done ?
B: this this smoothing is done on the estimate , , of what you 're going to subtract ? or on the thing that has already had something subtracted ?
A: it 's on the transfer function .
B: it 's on the transfer function for the wiener filter .
A: so we tried different configuration within this idea . we tried applying this on mel bands , having spectral subtraction instead of wiener filtering . finally we end up with this configuration that works , , quite . so we are going to fix this for the moment and work on the other aspects of the whole system .
B: actually , let me int , dave isn't here to talk about it , but let me just interject . this module , in principle , , you would know whether it 's true , is somewhat independent from the rest of it . because you re - synthesize speech , you don't you don't re - synthesize speech , but you could
A: we we do not fo
B: but you could .
A: we do , but we don't don't re - synthesize . in in the program we don't re - synthesize and then re - analyze once again . we just use the clean fft bins .
B: but you have re - synthesized thing that you that 's an option here .
A: this is an option that then you can
B: gu my point is that , , in some of the work he 's doing in reverberation , one of the things that we 're finding is that , , it 's for the for an artificial situation , we can just deal with the reverberation and his techniques work really . but for the real situation , problem is , is that you don't just have reverberation , you have reverberation in noise . and if you don't include that in the model , it doesn't work very . so it might be very thing to do , to just take the noise removal part of it and put that in front of what he 's looking at . and , , generate new files or whatever , and , and then do the reverberation part .
E: so dave hasn't tried that yet ?
B: no , no . he 's ,
E: he 's busy with
B: prelims , right .
C: pre - prelim hell .
B: but , , that 'll it 's clear that we , we are not with the real case that we 're looking at , we can't just look at reverberation in isolation because the interaction between that and noise is considerable . and that 's , in the past we 've looked at , , and this is hard enough , the interaction between channel effects and , and additive noise , , so convolutional effects and additive effects . and that 's hard enough . don't think we really we 're trying to deal with that . in sense that 's what we 're trying to deal with in this aurora task . and we have , , the , , lda that in principle is doing something about convolutional effects . and we have the noise suppression that 's doing something about noise . even that 's hard enough . and and the on - line normalization as , in that category . there 's all these interactions between these two and that 's part of why these guys had to work so hard on juggling everything around . but now when you throw in the reverberation , it 's even worse , because not only do you have these effects , but you also have some long time effects . and , , so dave has something which , , is doing some things under some conditions with long time effects but when it 's when there 's noise there too , it 's it 's pretty hard . so we have to start since any almost any real situation is gonna have , where you have the microphone distant , is going to have both things , we actually have to think about both at the same time . so there 's this noise suppression thing , which is worked out and then , , maybe you should just continue telling what else is in the form we have .
A: , the , , the other parts of the system are the blocks that were already present before and that we did not modify lot .
B: so that 's again , that 's the wiener filtering , followed by , , that 's done at the fft level .
A: th then the mel filter bank , then the log operation ,
B: the the filtering is done in the frequency domain ? and then the mel and then the log , and then the
A: then the lda filter , mmm , then the downsampling , then , , on - line normalization ,
B: on - line norm ,
A: followed by upsampling . then finally , we compute delta and we put the neural network also .
B: right , and then in parallel with an neural net . and then following neural net , some probably some orthogonalization .
A: and finally frame dropping , which , would be neural network also , used for estimated silence probabilities . and the input of this neural network would be somewhere between log mel bands or one of the earlier stages of the processing .
B: so that 's most of this is , is operating parallel with this other . so the things that we , , , there 's there 's some , , neat ideas for so , , in there 's like there 's bunch of tuning things to improve . there 's questions about various places where there 's an exponent , if it 's the right exponent , or ways that we 're estimating noise , that we can improve estimating noise . and there 's gonna be host of those . but structurally it seemed like the things the main things that we brought up that , , are gonna need to get worked on are , , significantly better vad , , putting the neural net on , , which , , we haven't been doing anything with , the , , neural net at the end there , and , , the , , opening up the second front .
E: the other half of the channel ?
B: , , cuz we have we have , , half the , , data rate that they allow .
E: that what you mean ?
B: and , , so the initial thing which came from , , the meeting that we had down south was , , that , , we 'll initially just put in mel spectrum as the second one . it 's , , cheap , easy . there 's question about exactly how we do it . we probably will go to something better later , but the initial thing is that cepstra and spectra behave differently , tony robinson used to do was saying this before . he used to do mel , , spectra and mel cepstra . he used them as alternate features . put them together .
E: so if you took the system the way it is now , the way it 's fro you 're gonna freeze it , and it ran it on the last evaluation , where it would it be ? in terms of ranking ?
A: ri - right now it 's second .
B: although , you haven't tested it actually on the german and danish ,
A: no , we didn't .
E: so on the ones that you did test it on it would have been second ?
B: when you 're saying second , you 're comparing to the numbers that the , that the best system before got on , also without german and danish ?
D: and th the ranking actually didn't change after the german and danish .
B: ranking didn't before , but 'm just asking where this is to where theirs was without the german and danish ,
E: where where were we actually on the last test ?
B: we were also esp essentially second , although there were , we had couple systems and they had couple systems . and so , by that we were third , but , there were two systems that were pretty close , that came from the same place . so institutionally we were we were second , with , , the third system .
E: we 're so this second that you 're saying now is system - wide second ?
B: no it 's also institutional ,
E: still institutionally second ?
B: both of their systems probably
A: we are between their two systems . it is triumph .
D: their their first system is fifty - four point something . and , , we are fifty - three point something .
A: but everything is within the range of one percent .
D: and their second system is also fifty - three point something .
B: so they 're all they 're all pretty close .
E: that 's very close .
B: and and , , , in some sense we 're all doing fairly similar things . , one could argue about the lda and but , , in lot of ways we 're doing very similar things .
E: so how did they fill up this all these bits ?
B: why are we using half ? so you could you
E: or how are they using more than half , maybe is what
B: so , you guys are closer to it than me , so correct me if 'm wrong , but that what 's going on is that in both cases , some normalization is done to deal with convola convolutional effects . they have some cepstral modification , in our case we have couple things . we have the on - line normalization and then we have the lda rasta . and they seem to comple complement each other enough and be different enough that they both seem to help us . but in any event , they 're both doing the same thing . but there 's one difference . the lda rasta , , throws away high modulation frequencies . and they 're not doing that . so that if you throw away high modulation frequencies , then you can downsample .
E: so what if you didn't so do you explicitly downsample then ? do we explicitly downsample ? and what if we didn't do that ? would we get worse performance ?
A: not better , not worse .
B: it doesn't affect it , so , since we 're not evidently throwing away useful information , let 's try to put in some useful information . and , , so , we 've found in lot of ways for quite while that having second stream , helps lot . so that 's that 's put in , and , it may even end up with mel spectrum even though 'm saying we could do much better , just because it 's simple . and , in the long run having something everybody will look at and say , "" , , understand "" , is very helpful .
E: so you would you 're you 're thinking to put the , , mel spectrum in before any of the noise removal ? or after ?
B: that 's question . we were talking about that . it looks like it 'd be straightforward to , , remove the noise ,
E: cuz that happens before the mel conversion ,
B: so , , to do it after the mel conversion , after the noise removal , after the mel conversion . there 's even question in my mind anyhow of whether th you should take the log or not .
A: what about norm normalizing also ?
B: but normalizing spectra instead of cepstra ? some kind would be good .
D: it so it actually makes it dependent on the overall energy of the , the frame .
B: if you do or don't normalize ?
D: if yo if you don't normalize and if you don't normalize .
B: yes , so , one would think that you would want to normalize . my thought is , , particularly if you take the log , try it . and then if normalization helps , then you have something to compare against , and say , "" , this much effect "" , you don't want to change six things and then see what happens . you want to change them one at time . so adding this other stream in , that 's simple in some way . and then saying , particularly because we 've found in the past there 's all these these different results you get with slight modifications of how you do normalization . normalization 's very tricky , sensitive thing and you learn lot . so , would think you would wanna have some baseline that says , "" , we don't normalize , this is what we get "" , when we do this normalization , when we do that normalization . but but the other question is so ultimately we 'll wind up doing some normalization .
E: so this second stream , will it add latency to the system
B: no , it 's in parallel . we 're not talking about computation time here . we 're ta we 're pretty far out . so it 's just in terms of what data it 's depending on . it 's depending on the same data as the other . so it 's in parallel .
C: so with this , , new stream would you train up vad on both features , somehow ?
D: no , the vad has its own set of features . which could be this one of these streams , or it can be something derived from these streams .
A: and there is also the idea of using traps , maybe , for the vad , pratibha showed , when , she was at ibm , that it 's good idea .
C: would would that fit on the handset ,
A: have no idea .
D: it has the th
A: it would have to fit
D: if it has to fit the delays and all this .
B: there 's the delays and the storage , but don't think the storage is so big for that . th the biggest we 've run into for storage is the neural net . and so the issue there is , are we are we using neural - net - based traps , and how big are they ? so that 'll that 'll be , , an issue . maybe they can be little ones . mini - traps .
C: cuz she also does the , the correlation - based , , traps , with without the neural net , just looking at the correlation between
B: and maybe for vad they would be . that 's true . or simple neural net , , if you 're doing correlation , you 're just doing simple , dot product , , with some weights which you happened to learn from this learn from the data . putting nonlinearity on it is , , not that big deal . it certainly doesn't take much space . so , , the question is , how complex function do you need ? do you need to have an added layer ? in which case , , potentially , , it could be big . so what 's next ? maybe remind us .
E: so the meeting with hynek that you guys just had was to decide exactly what you were gonna freeze in this system ? or was there ? were you talking about what new ,
B: what to freeze and then what to do after we froze . and like was saying , the , the basic directions are , , there 's lots of little things , such as improve the noise estimator but the bigger things are adding on the neural net and , , the second stream . and then , , improving the vad .
D: so , 'll , 'll actually after the meeting 'll add the second stream to the vad and maybe 'll start with the feature net in that case . it 's like , you 're looking at the vad ,
A: 've new feature net ready also .
D: for the vad ?
A: no , . two network , one vad and one feature net .
D: you already have it ? so just figure how to take the features from the final
A: but , , there are plenty of issues to work on for the feature net @ @ .
E: what about the , , the new part of the evaluation , the , , wall street journal part ?
B: have you ever ? very good question . have you ever worked with the mississippi state , software ? you may be called upon to help , , on account of , , all the work in this here has been , , with small vocabulary .
E: so what how is the , , interaction supposed to happen ? remember the last time we talked about this , it was up in the air whether they were going to be taking , , people 's features and then running them or they were gonna give the system out or so they 're gonna just deliver system .
B: do we already have it ?
D: th it 's almost ready . so they have released their , , document , describing the system .
B: maybe you could , , point it at chuck ,
E: so we 'll have to grab this over cvs ?
D: it - no , it 's just downloadable from their from their web site .
E: is that how they do it ?
B: cuz one of the things that might be helpful , if you 've if you 've got time in all of this is , is if these guys are really focusing on improving , , all the digit , , maybe and you got the front - end from them , maybe you could do the runs for the and , , iron out hassles that you have to , , tweak joe about or whatever , because you 're more experienced with running the large vocabulary .
D: so 'll point you to the web site and the mails corresponding .
E: and it but it 's not ready yet , the system ?
D: they are still , , tuning something on that . so they 're like , they 're varying different parameters like the insertion penalty and other , and then seeing what 's the performance .
E: are those going to be parameters that are frozen , nobody can change ?
D: there is , , time during which people are gonna make suggestions .
E: but everybody 's gonna have to use the same values .
D: so these sugges these this , , period during which people are gonna make suggestions is to know whether it is actually biased towards any set of features or
B: so th certainly the thing that would want to know about is whether we get really hurt , , on in insertion penalty , language model , scaling , sorts of things .
E: using our features .
B: in which case , , hari or hynek will need to , , push the case more about this .
E: and we may be able to revisit this idea about , , somehow modifying our features to work with
B: yes . in this case , that 's right . that 's right . some of that may be , , last minute rush thing because if the if our features are changing the other thing is that even though it 's months away , , it 's starting to seem to me now like november fifteenth is right around the corner . and , , if they haven't decided things like this , like what the parameters are gonna be for this , , when "" deciding "" is not just somebody deciding . , there should be some understanding behind the , , deciding , which means some experiments and . it it seems pretty tight to me .
E: so wha what 's the significance of november fifteenth ?
B: that 's when the evaluation is . so , , so after but , , they may even decide in the end to push it off . it wouldn't , , entirely surprise me . but , , due to other reasons , like some people are going away , 'm 'm hoping it 's not pushed off for long while . that would be , put us in an awkward position . that 'll be helpful . there 's there 's not anybody ogi currently who 's who 's , , working with this
E: is is this part of the evaluation just small part , or ho how important is this to the overall ?
B: it 's it 's , it depends how badly you do . that it is .
E: this is one of those things that will be debated afterwards ?
B: , it 's conceptually , it my impression , again , you guys correct me if 'm wrong , but my impression is that , , they want it as double check . that you haven't come across you haven't invented features which are actually gonna do badly for significantly different task , particularly one with larger vocabulary . and , , but it 's not the main emphasis . the truth is , most of the applications they 're looking at are pretty small vocabulary . so it 's it 's double check . so they 'll probably assign it some low weight .
E: seems to me that if it 's double check , they should give you one or zero . you passed the threshold or you didn't pass the threshold , and they shouldn't even care about what the score is .
B: but , , we 'll we 'll see what they come up with . but in the current thing , , where you have this - matched , moderately - matched , and mis highly - mismatched , , the emphasis is somewhat on the on the - matched , but it 's only marginal , it 's like forty , thirty - five , twenty - five , like that . so you still if you were way , way off on the highly - mismatched , it would have big effect . and , , it wouldn't surprise me if they did something like that with this . so again , if you 're if you get if it doesn't help you much , , for noisy versions of this of large vocabulary data , then , , , it may not hurt you that much . but if it if you don't if it doesn't help you much , , or to put it another way , if it helps some people lot more than it helps other people , , if their strategies do , then
E: so is this , ? guenter was putting bunch of wall street journal data on our disks .
B: that 's it .
E: so that 's the data that we 'll be running on ?
B: so we have the data , just not the recognizer .
E: so this test may take quite while to run , then . may - judging by the amount of data that he was putting on .
B: there 's training and test , no , , if it 's like the other things , there 's there 's data for training the ms and data for testing it . so , training the recognizer , but it 's trained on clean and is it trained on clean and test on ?
D: the wall street ?
A: it 's training on range between ten and twenty db , , and testing between five and fifteen . that 's what got on
D: it 's , it 's like medium - mismatch condition , .
A: and so the noise is there is range of different noises also which are selected randomly and added randomly , , to the files . and there are noises that are different from the noises used on ti - digits .
B: , wouldn't imagine that the amount of testing data was that huge . they probably put training , almost certain they put training data there too . that 's that . anybody have anything else ?
E: one last question on that . when did they estimate that they would have that system available for download ?
D: one some preliminary version is already there .
E: so there 's something you can download to just learn ?
D: it 's already there . but they 're actually parallel - doing some modifications also , . so the final system will be frozen by middle of , like , one more week maybe .
B: that 's pretty soon .
D: that 's just one more .
C: is this their , , svm recognizer ?
D: no , it 's just straightforward .
B: their they have lot of options in their recognizer and the svm is one of the things they 've done with it , but it 's not their more standard thing . for the most part it 's it 's gaussian mixtures .
D: it 's just , gaussian mixture model .
B: the svm thing was an also . it was just it was like hybrid , like
E: so , just so that understand , they 're providing scripts and everything so that , , you push button and it does training , and then it does test , and everything ? is that the idea ?
D: something like that . it 's like as painless as possible , is what do they provide all the scripts , everything , and then just ,
E: somehow yo there 's hooks to put your features in and
D: ju , th .
B: , if you look into it little bit , it might be reasonable just to ask him about the issue of , , different features having different kinds of , , scaling characteristics and so on . so that , , possibly having entirely different optimal values for the usual twiddle factors and what 's what 's the plan about that ?
D: so sh shall we , like , add chuck also to the mailing lists ? it may be better , , in that case if he 's going to because there 's mailing list for this .
E: that 'd be great .
D: maybe hari or hynek , one of them , has to send mail to joe . or maybe if you
E: could send him an email .
D: , to add or maybe wh
E: know him really .
D: so that 's just fine .
E: was just talking with him on email the other day actually .
B: , and just , , se maybe see .
E: about other things ,
B: do you have hari 's , ? so maybe just cc hari and say that you 've just been asked to handle the large vocabulary part here , and , , ,
E: would it be better if asked hari to ask joe ?
B: why don't you just ask joe but cc hari , and then in the note say , "" hari , hopefully this is with you "" . and then if joe feels like he needs confirmation , har answer it . that way you can get started asking joe quickly while he 's while he 's maybe still , , putting in nails and screws and
D: and there is an , , archive of all the mails that has been gon that has gone , , between these people among these people . so just you can see all this mails in the isip web site mississippi web site .
E: is that password controlled ?
D: it 's password protected . so , like , it 's , like
B: have you thought about how long would be , most useful for you to go up to ogi ?
A: we can for september , we can set up work schedule and we can maybe work independently . and then at some point it maybe be better to work together again .
B: so you 're you 're imagining more that you would come back here first for while and then and then go up there ? it 's to you . ju you guys are anyway , you don't have to decide this second but th about it about what you would think would be the best way to work it . 'll support it either way , so . got anything to tell us ?
C: 've been reading some literature about clustering of data . just , , , let me put it in context . so we 're talking about discovering intermediate categories to , to classify . and , , was looking at some of the work that , , sangita was doing on these traps things . so she has , she has temporal patterns for , , certain set of phonemes , from timit , the most common phonemes . and each one of them has pattern over time , one second window . and it has these patterns . so she has , trap for each one of the phonemes , , times fifteen , for each of the fifteen critical bands . and , , she does this agglomerative hierarchical clustering which , , is clustering algorithm that , , starts with many , many different points many different clusters , corresponding to the number of data , , patterns that you have in the data . and then you have this distance mej metric which , , measures how closely related they are . and you start , by merging the patterns that are most closely related .
E: and you create tree . and then you can pick , , values anywhere along that tree to fix your set of clusters .
C: right , usually it 's when , when the sol similarity measures , , don't go down as much . and so , so you stop at that point . and what she found was , sh , was there were five broad , broad categories , , corresponding to , , things like , , fricatives and , , vocalic , , and , , stops . and , , one for silence and another one for schwa sounds . and , , was thinking about ways to generalize this because you 're it 's like it 's not completely automatic way of clustering , because yo beforehand you have these traps and you 're saying that these frames correspond to this particular phoneme . and that 's that 's constraining your clustering to the set of phonemes that you already have . whereas maybe we want to just take look at , , arbitrary windows in time , , of varying length , , and cluster those . and 'm thinking if we if we do that , then we would probably , , at some point in the clustering algorithm find that we 've clustered things like , , thi this is transition , , this is relatively stable point . and 'm hoping to find other things of similarity and maybe use these things as the intermediate , intermediate categories that , , , 'll later classify .
B: are you looking at these in narrow bands ? cuz that 's what you 're gonna be using ,
C: haven't exactly figured out , , the exact details for that but , , the representation of the data that was thinking of , was using , , critical band , , energies , , over different lengths of time .
B: , it seems somehow that needs th , there 's couple things that wonder about with this . so one is , again , looking at the same representation , if you 're going for this thing where you have , little detectors that are looking at narrow bands , then what you 're going to be looking for should be some category that you can find with the narrow bands . that that seems to be fundamental to it . and then the other thing , , is that wonder about with it , and don't take this in the wrong way , like 'm doing or anything , but , . , just wondering really . the standard answer about this thing is that if you 're trying to find the right system in some sense , whether you 're trying by categories or parameters , and your goal is discrimination , then having choices based on discrimination as opposed to , , unsupervised nearness of things , , is actually better . and if that , since you 're dealing with issues of robustness , , maybe this isn't right , but it 'd be something 'd be concerned about . because , , you can imagine , , if you remember from , from your quals , john ohala saying that , , "" buh "" and "" puh "" differed , , not really cuz of voicing but because of aspiration . in as far as wha what 's really there in the acoustics . so , , if you looked if you were doing some coarse clustering , you probably would put those two sounds together . and yet , would gue would that many of your recognition errors were coming from , , , pfft , screwing up on this distinction . so , , it 's little hard because recognizers , to first order , work . and the reasons we 're doing the things we 're doing is because they don't work as as we 'd like . and since they work , , it means that they are already doing if you go and take any recognizer that 's already out there and you say , "" how is it distinguishing between schwas and stops ? "" boy , bet they 're all doing nearly perfectly on this , so these big categories that differ in huge obvious ways , we already know how to do . so , what are we bringing to the party ? what we wanna do is have something that , particularly in the presence of noise , , is better at distinguishing between , , categories that are actually close to one another , and hence , would probably be clustered together . so that 's th that 's the hard thing . understand that there 's this other constraint that you 're considering , is that you wanna have categories that , that would be straightforward for , say , human being to mark if you had manual annotation . and it 's something that you really think you can pick up . but it 's also essential that you wanna look at what are the confusions that you 're making and how can you come up with , , categories that , , can clarify these confusions . so , , the standard way of doing that is take look at the algorithms you 're looking at , but then throw in some discriminative aspect to it . this is more like , , how does lda differ from pca ? they 're the same thing . they 're both orthogonalizing . and , , this is little harder because you 're not just trying to find parameters . you 're actually trying to find the the categories themselves . so little more like brain surgery , anyway . that 's my thought . you 've been thinking about this problem for long time actually . actually , you stopped thinking about it for long time , but you used to think about it lot . and you 've been thinking about it more now ,
E: don't , it 's not clear to me how to reconcile , , what you 're saying , which is right , with the way 've been looking at it . that it 's it 's all not very clear to me . but it seems to me that the desire the desirable feature to have is something that , , is bottom - up . however we do that . and and so what don't understand is how to do that and still be discriminative , because to be discriminative you have to have categories and the only categories that we know of to use are these human sig significant categories that are significant to humans , like phonemes , things like that . but that 's what you want to avoid . and so that feels how to get out of this .
B: here 's here 's , here 's generic and possibly useless thought , which is , , what do you really , in sense the only systems that make sense , , are ones that have something from top - down in th in them . because if even the smallest organism that 's trying to learn to do anything , if it doesn't have any reward for doing or penal penalty for doing anything , then it 's just going to behave randomly . so whether you 're talking about something being learned through evolution or being learned through experience , it 's gotta have something come down to it that gives its reward or , , at least some reinforcement learning ,
E: so the question is , how far down ? we could stop at words , but we don't , we go all the way down to phonemes .
B: right , but me that maybe in some ways part of the difficulty is trying to deal with the with these phonemes . and and it 's almost like you want categories if our if our , , , metric of goodness , , if our correction if our metric of badness is word error rate then , , maybe we should be looking at words . for for very , , reasons we 've looked for while at syllables , and they have lot of good properties , but if you go all the way to words , , that 's really , in many applications you wanna go further . you wanna go to concepts , or have have concepts , actions , this thing .
E: but words would be
B: words aren't bad , .
E: so the common right , the common wisdom is you can't do words because there 's too many of them , so you have to have some smaller set that you can use , and so everybody goes to phonemes . but the problem is that we build models of words in terms of phonemes and these models are really cartoon - ish , so when you look at conversational speech , , you don't see the phonemes that you that you have in your word models .
B: but but we 're not trying for models of words here . see , so her here 's maybe where if the issue is that we 're trying to come up with , , some intermediate categories which will then be useful for later , , then maybe it doesn't matter that we can't have enough what you wanna do is build up these categories that are that are best for word recognition . and and somehow if that 's built into the loop of what the categories we do this every day in this very gross way of running thousand experiments because we have fast computers and picking the thing that has the best word error rate . in some way , we derive th the time . in some ways it 's really not bad thing to do because it tells you how your adjustments at the very low level affect the final goal . so maybe there 's way to even put that in much more automatic way , where you take , , something about the error at the level of the word or some other it could be syllable but in some large unit , and , you may not have word models , you have phone models , whatever , but you don't worry about that , and just somehow feed it back through . so that 's , , wh what called useless comments because 'm not really telling you how to do it . but , it 's it 's it 's , it
E: no , but the important part in there is that , , if you want to be discriminative , you have to have , , categories . and this the important categories are the words , and not the phones . if you can put the words in to the loop somehow for determining goodness of your sets of clusters
B: now , that being said , that if you have something that is , once you start dealing with spontaneous speech , all the things you 're saying are really true . if you have read speech that 's been manually annotated , like timit , then , , you the phones are gonna be right , actually , for the most part . so so , , it doesn't really hurt them to do that , to put in discrimination at that level . if you go to spontaneous speech then it 's it 's trickier and and , , the phones are , it 's gonna be based on bad pronunciation models that you have of and , and it won't allow for the overlapping phenomenon
E: so it 's almost like there 's this mechanism that we have that , , when we 're hearing read speech and all the phonemes are there , we deal with that , but when we go to conversational , and then all of sudden not all the phonemes are there , it doesn't really matter that much to us as humans because we have some mechanism thows for these word models , whatever those models are , to be munged , , and it doesn't really hurt , 'm not how to build that in .
B: the other thing is to think of little bit we when when you start looking at these results it usually is pretty intuitive , but start looking at , what are the kinds of confusions that you do make , , , between words if you want or or , , even phones in in read speech , say , , when there is noise . so is it more across place or more across manner ? or is it cor , is it ? know one thing that happens is that you you , , you lose the , , , low energy phones . if there 's added noise then low energy phones sometimes don't get heard . and if that if that is if it , if that turns it into another word or different , or another pair of words , then it 's more likely to happen . but , , , would would that you 'd anyway , that 's
E: part of the difficulty is that lot of the robustness that we have is probably coming from much higher level . we understand the context of the situation when we 're having conversation . and so if there 's noise in there , , our brain fills in and imagines what should be there .
C: we 're we 're doing some prediction of what
B: , that 's really big . but , even if you do , , diagnostic rhyme test things , , where there really isn't an any information like that , , people are still better in noise than they than they are in , , than the machines are . so , , that 's right . we can't we can't get it without any language models . language models are there and important if we 're not working on that then we should work on something else and improve it , but especially if it looks like the potential is there . should we do some digits ? since we 're here ?
E: go ahead , morgan .
B: that 's all folks .
","ICSI's Meeting Recorder Group at Berkeley met mainly to discuss work on their main project , the Aurora task , but also talked about the work of one of their student members.
Some members of the group met recently with research partners to settle on the current state of their software , and decide on the future work they would investigate , and these decisions were relayed to the rest of the group.
Of the three areas for the future , they touched mostly upon the use of a second , parallel , data stream.
The group also discussed a new part to the evaluation , the use of a chunk of the Wall Street Journal.
Speaker me006 is working on data clustering , and discussion of related issues led to more general acoustic matters.
After the meeting , mn052 volunteered to get the second data stream up and running in the current software.
Since he has been asked to assist in a particular aspect of the work , me018 has to contact the relevant persons in order to be added to the according mailing list.
There is a new system coming from OGI for dealing with the Wall Street Journal data , and me013 wanted everyone to pay attention to areas where the groups might get hurt because of their features.
The group's code has been updated , and in it's frozen state , runs at the second best level in the project.
The CVS allowing access to the code is up and running , but now one at OGI is actually working on it yet.
Speaker me006 has been reading literature on data clustering , with particular attention to a previous work , and is contemplating how to generalise it.
"
ami_abstractive_summary,Bmr018.txt,"E: we 're recording .
C: alright , and no crash .
E: pre - crashed it .
F: pre - crashed !
D: it never crashes on me . what is what is that ?
E: it depends on if the temp files are there or not , that at least that 's my current working hypothesis , that what happens is it tries to clear the temp files and if they 're too big , it crashes .
B: when the power went out the other day and restarted it , it crashed the first time .
E: that 's right .
B: after the power out
D: so then there would be no temp files .
E: no , it doesn't it doesn't clear those necessarily ,
D: it doesn't clear them ,
E: it 's they 're called temp files , but they 're not actually in the temp directory they 're in the scratch , they 're not backed up , but they 're not erased either on power failure .
D: but that 's usually the meeting that recorded , and it neve it doesn't crash on me .
B: this wasn't actually , this wasn't before your meeting , this was , , tuesday afternoon when , , , robert just wanted to do little recording , and the power had gone out earlier in the day .
C: when would be good excuse for it , but can't to be giving talk and and use the example from last week with everybody doing the digits at once .
A: that was fun .
C: 'd love to play somebody that .
A: that was fun .
D: it was quick .
C: it was really efficient .
B: talk about good noise shield . you wanted to pe keep people from listening in , you could like have that playing outside the room . nobody could listen in .
D: had this idea we could make our whole meeting faster that way .
C: everybody give the reports about what they were doing at exactly the same time ,
D: and we 'll just all leave ,
B: and then we 'll we 'll go back later and review the individual channels ,
E: and then everyone can listen to it later .
C: actually isn't that what we have been doing ?
E: it 's what it sounds like .
B: with all the overlaps .
C: what are we doing ?
E: since 've been gone all week , didn't send out reminder for an agenda , do we have anything to talk about or should we just read digits and go ?
B: wouldn't mind hearing how the conference was .
D: had one question about
E: it 's all blur .
D: aren't the uw folks coming this weekend ?
F: no . the next ,
E: next weekend , week from
C: that is right . the next weekend .
D: not not the days coming up , but
F: it 's like the
E: week from saturday .
C: that 's when they 're coming .
D: within ten days .
C: that 's correct .
D: so , are we do we have like an agenda or anything that we should be
C: no , but that would be good idea .
F: so so the deal is that , , , be available after , , like ten thirty . how how early you wanted to
C: they 're not even gonna be here until eleven or so .
E: that 's good .
C: cuz they 're flying up that day .
D: this is on sunday ?
E: eurospeech is due on friday and then 'm going down to san , san jose friday night , so , if , if we start and late saturday that 's good thing .
C: no , , they 're flying up from down from seattle .
E: they 're flying from somewhere to somewhere ,
C: and they 'll end up here . so and also brian kingsbury is actually flying from , , the east coast on that morning . so , will be , he 's taking very early flight and we do have the time work difference running the right way , but still think that there 's no way we could start before eleven . it might end up really being twelve . so when we get closer we 'll find people 's plane schedules , and let everybody know . so . that 's good .
E: but , , maybe an agenda , or at least some things to talk about would be good idea .
C: we can start gathering those ideas , but then we should firm it up by next thursday 's meeting .
A: will we have time to , , to prepare something that we in the format we were planning for the ibm transcribers by then ,
E: so have you heard back from brian about that ,
B: he 's 'm , should have forwarded that along . mentioned at the last meeting , he said that , , he talked to them and it was fine with the beeps they would be that 's easy for them to do .
E: so , , , though thi - thilo isn't here , have the program to insert the beeps . what don't have is something to parse the output of the channelized transcripts to find out where to put the beeps , but that should be really easy to do . so do we have meeting that 's been done with ,
A: he 's he 's
E: that we 've tightened it up to the point where we can actually give it to ibm and have them try it out ?
A: he generated , , channel - wise presegmented version of meeting , but it was robustness rather than edu so depends on whether we 're willing to use robustness ?
B: for this experiment we can use pre anything . this experiment of just
E: we had we had talked about doing maybe edu as good choice , though . whatever we have .
B: we 've talked about that as being the next ones we wanted to transcribe . but for the purpose of sending him sample one to
E: maybe it doesn't matter .
A: 'll 'll , , get make that available .
E: and has it been corrected ? hand - checked ? cuz that was one of the processes we were talking about as .
B: right , so we need to run thilo 's thing on it ,
A: that 's right .
B: and then we go in and adjust the boundaries .
A: that 's right . we haven't done that . could set someone on that tomorrow .
E: and time how long it takes .
B: and we probably don't have to do necessarily whole meeting for that if we just wanna send them sample to try .
A: what would be good number of minutes ?
B: maybe we can figure out how long it 'll take @ @ to do .
E: it seems to me we probably should go ahead and do whole meeting because we 'll have to transcribe the whole meeting anyway sometime .
C: except that if they had if there was choice between having fifteen minutes that was fully the way you wanted it , and having whole meeting that didn't get at what you wanted for them it 's just dependent of how much
E: like if we have to do it again anyway ,
B: the only thing 'm not about is , , how quickly can the transcribers scan over and fix the boundaries , is it pretty easy ?
E: it 's gonna be one or two times real time at excuse me , two or more times real time , cuz they have to at least listen to it .
C: can we pipeline it so that say there 's , , the transcriber gets done with quarter of the meeting and then we you run it through this other ?
E: 'm just thinking that from data keeping - track - of - the - data point of view , it may be best to send them whole meetings at time and not try to send them bits and pieces .
C: that 's right . so the first thing is the automatic thing , and then it 's then it 's the transcribers tightening up , and then it 's ibm .
A: - , - .
C: so you might as ha run the automatic thing over the entire meeting , and then and then , , you would give ibm whatever was fixed .
A: and have them fix it over the entire meeting too ?
C: , but start from the beginning and go to the end , so if they were only half way through then that 's what you 'd give ibm .
B: as of what point ? the the question on my mind is do we for the transcribers to adjust the marks for the whole meeting before we give anything to ibm , or do we go ahead and send them sample ?
C: why wouldn't we @ @ if they were going sequentially through it , why wouldn't we give them are we trying to get something done by the time brian comes ?
E: that was the question . though .
C: so if we if we were , then it seems like giving them something , whatever they had gotten up to , would be better than nothing .
E: they typically work for what , four hours , something like that ? the they should be able to get through whole meeting in one sitting . unless it 's lot harder than we is , which it could be , certainly .
A: if it 's got like for speakers then if
B: we 're just doing the individual channels ,
E: or seven or eight .
B: so it 's gonna be , depending on the number of people in the meeting ,
A: there is this issue of , , if the segmenter thought there was no speech on particular stretch , on particular channel , and there really was , then , if it didn't show up in mixed signal to verify , then it might be overlooked , so , , the question is "" should transcriber listen to the entire thing or can it can it be based on the mixed signal ? "" and th so far as 'm concerned it 's fine to base it on the mixed signal at this point ,
E: that 's what it seems to me too , in that if they need to , just like in the other cases , they can listen to the individual , if they need to .
A: and that cuts down the time .
E: but they don't have to for most of it .
A: that 's good . good , good .
B: don't see how that will work , though .
A: what what aspect ?
C: so you 're talking about tightening up time boundaries ? so how do you
E: so , they have the normal channeltrans interface where they have each individual speaker has their own line , but you 're listening to the mixed signal and you 're tightening the boundaries , correcting the boundaries . you shouldn't have to tighten them too much because thilo 's program does that .
A: should be pretty good ,
D: except for it doesn't do on short things , remember .
E: right , so you 'll have to
D: it will miss them . it will miss most of the really short things .
A: but those would be those would be
D: it will it will miss you have to say "" - "" more slowly to get no , 'm 'm actually serious .
E: 'll work on that .
D: so it will miss like that which
E: so that 's something that the transcribers will have to have to do .
A: but presumably , most of those they should be able to hear from the mixed signal unless they 're embedded in the heavil heavy overlap section when in which case they 'd be listening to the channels anyway .
B: that 's that 's what 'm 'm concerned about the part .
D: and that 's what 'm not about .
A: and it 's an empirical question .
B: can't we couldn't we just have , , maybe this just doesn't fit with the software , but if didn't know anything about transcriber and was gonna make something to let them adjust boundaries , would just show them one channel at time , with the marks , and let them adju
E: but then they have to do but then they for this meeting they would have to do seven times real time , and it would probably be more than that .
A: that 's it .
E: because they 'd have to at least listen to each channel all the way through .
B: but but it 's very quick , you scan , if you have display of the waveform .
E: you 're talking about visually .
A: the other problem is the breaths cuz you also see the breaths on the waveform . 've 've looked at the int , 've tried to do that with single channel , and you do see all sorts of other besides just the voice .
E: and that they 're going much more on acoustics than they are on visuals .
A: that 'm not . what you the digital what the digital task that you had your interface ? know for fact that one of those sh she could really she could judge what th what the number was based on the on the waveform .
E: that 's actually true . you 're right . you 're right . found the same thing that when was scanning through the wave form could see when someone started to read digits just by the shapes .
A: she could tell which one was seven .
C: 'm 'm now entirely confused about what they do . so , they 're they 're looking at mixed signal , or they 're looking what are they looking at visually ?
A: they have choice . they could choose any signal to look at . 've tried lookin but usually they look at the mixed . but 've 've tried looking at the single signal and in order to judge when it when it was speech and when it wasn't , but the problem is then you have breaths which show up on the signal .
C: but the procedure that you 're imagining , , people vary from this , is that they have the mixed signal wave form in front of them , and they have multiple , , let 's see , there isn't we don't have transcription yet . so but there 's markers of some sort that have been happening automatically , and those show up on the mixed signal ? there 's @ @ clicks ?
A: they show up on the separate ribbons . so you have separate ribbon for each channel ,
C: there 're separate ribbons .
A: and it 'll be because it 's being segmented as channel at time with his with thilo 's new procedure , then you don't have the correspondence of the times across the bins across the ribbons
C: and is there line moving across the waveform as it goes ? so the way you 're imaging is they play it , and they see this happened , then and if it 's about right , they just let it slide , and if it there 's question on something , they stop and maybe look at the individual wave form .
A: not "" look "" .
E: they wouldn't look at it at this point . they would just listen .
C: they they might look at it ,
E: the problem is that the interface doesn't really allow you to switch visuals .
A: not very quickly .
E: the problem is that the tcl - tk interface with the visuals , it 's very slow to load waveforms .
A: you can but it takes time . that 's it .
E: and so when tried that was the first thing tried when first started it ,
A: you can you can switch quickly between the audio , but you just can't get the visual display to show quickly . so you have to it takes , , three , four minutes to , it takes it takes long enough
D: it 's very slow to do that .
A: it takes long enough cuz it has to reload the exactly what it 's doing frankly cuz but it it takes long enough that it 's just not practical alternative .
E: it does some shape pre - computation so that it can then scroll it quickly ,
G: but you can cancel that .
E: but then you can't change the resolution or scroll quickly .
A: now you could set up multiple windows , each one with different signal showing , and then look between the windows . maybe that 's the solution .
E: we could do different interfaces ,
G: what if you preload them all ?
E: so we could use like waves instead of transcriber , and it loads faster , certainly .
G: what if you were to preload all the channels or initially
E: that 's what tried originally . so actually before , , dave gelbart did this , did an interface which showed each waveform and ea ribbon for each waveform , but the problem with it is even with just three waveforms it was just painfully slow to scroll . so you just scroll screen and it would , go "" kur - chunk ! "" and so it just was not doable with the current interface .
A: am thinking if we have meeting with only four speakers and , , you could fire up transcriber interface for , , in different windows , multiple ones , one for each channel . and it 's hack but it would be one way of seeing the visual form .
E: that if we decide that we need that they need to see the visuals , we need to change the interface so that they can do that .
D: that 's actually what of , loading the chopped up waveforms , , , that would make it faster
E: the chopped up waveforms .
B: the problem is if anything 's cut off , you can't expand it from the chopped up
D: right , but if you
E: and wouldn't that be the same as the mixed signal ?
D: no , the individual channels that were chopped up that it 'd be to be able to go back and forth between those short segments . cuz you don't really nee like nine tenths of the time you 're throwing most of them out , but what you need are tho that particular channel , or that particular location , might be , cuz we save those out already , , to be able to do that . but it won't work for ibm , it only works here cuz they 're not saving out the individual channels .
A: do think that this will be doable procedure , and have them starting with mixed and , , then when they get into overlaps , just have them systematically check all the channels to be that there isn't something hidden from audio view .
E: the mixed signal , the overlaps are pretty audible because it is volume equalized . so they should be able to hear . the only problem is , , counting how many and if they 're really correct or not .
D: that you can locate them very from the mixed signal ,
E: right but once that they happen , you can at least listen to the close talking ,
D: but you would know that they were there , and then you would switch . and then you would switch into the other
C: but right now , to do this limitation , the switching is going to be switching of the audio ? is what she 's saying . so they 're using their ears to do these markings anyway .
E: did dave did dave do that change where you can actually just click rather than having to go up to the menu to listen to the individual channels ? had suggested it before . whether he did it or not .
A: 'm not what click on the ribbon ? you can get that get you can get the , you can get it to switch audio ? not last tried , but , , maybe he 's changed it again .
E: we should get him to do that because , , that would be much , much faster than going to the menu .
A: there 's reason disagree , and that is that , , you it 's very good to have dissociation between the visual and the audio . there 're times when wanna hear the mixed signal , bu but want to transcribe on the single channel .
E: then maybe just buttons down at the bottom next to it .
A: maybe , don't don't see that it 's
E: just something so that it 's not in the menu option so that you can do it much faster .
A: , that 's the that might be personal style thing . find it really convenient the way the way it 's set up right now .
E: it just seems to me that if you wanna quickly "" was that jane , no , was that chuck , no , was that morgan "" , right now , you have to go up to the menu , and each time , go up to the menu , select it , listen to that channel then click below , and then go back to the menu , select the next one , and then click below .
A: that 's fine . it 's true .
E: so you can definitely streamline that with the with the interface .
A: it could be faster , but , , , th in the ideal world no agree that 'd be .
C: so , , done with that ? does any forget , does anybody , , working on any eurospeech submission related to this ?
E: would like to try to do something on digits but if we have time . it 's due next friday so we have to do the experiments and write the paper . so , 'm gonna try , we 'll just have to see . so actually wanna get together with both andreas and , , stephane with their respective systems .
C: there was that we that 's right , we had that one conversation about , , what what did it mean for , , one of those speakers to be pathological ,
E: and haven't had chance to sit down and listen .
F: haven't haven't listened to them either ,
E: was going to do that this afternoon .
F: but there must be something wrong ,
E: morgan and were having debate about that . whereas it 's probably something pathologic and actually stephane 's results , confirm that . he he did the aurora system also got very lousy average error , like fifteen or , , fifteen to twenty percent average ? but then he ran it just on the lapel , and got about five or six percent word error ? so that means to me that somewhere in the other recordings there are some pathological cases . but , , we th that may not be true . it may be just some of the segments they 're just doing lousy job on . so 'll 'll listen to it and find out since you 'd actually split it up by segment . so actually listen to it .
B: did you run the andreas the sri recognizer on the digits ?
E: he had sent that around to everyone , did you just sent that to me ?
F: no , didn't . since considered those preliminary , didn't . but , , if you take
E: it was bimodal .
F: it 's actually , , it it was trimodal , actually
E: was it trimodal , .
C: there 's zero , little bit , and lot .
F: there were there was there was one one bump at ze around zero , which were the native speakers ,
B: zero percent error ?
F: the non - pathological native speakers . then there was another bump at , , , like fifteen .
B: this is error you 're talking about ?
C: was it fifteen ?
F: those were the non - natives . and then there was another distinct bump at , like , hundred , which must have been some problem .
G: what is patho what do you mean by pathological ?
E: just just something really wrong with bug is what , so that it 's like
F: and there was this one meeting , forget which one it was , where like , , six out of the eight channels were all , like had hundred percent error .
E: which probably means like there was th the recording interface crashed , or there was short , someone was jiggling with cord or , , extracted it incorrectly , it was transcribed incorrectly , something really bad happened , and haven't listened to it yet to find out what it was .
F: so , if excluded the pathological ones , by definition , those that had like over ninety - five percent error rate , and the non - natives , then the average error rate was like one point four ,
C: what we 're calling .
F: which seemed reasonable given that , , the models weren't tuned for it . and the grammar wasn't tuned either .
B: and it didn't matter whether it was the lapel or whether it was the
F: it was just @ @ . haven't split it up that way ,
D: but there 's no overlap during the digit readings , so it shouldn't really matter .
F: but it would be
C: no , but there 's little difference ,
E: there 's lot .
C: and we haven't looked at it for digits ,
B: so was curious about that .
C: cuz because what he was what was saying when looked at those things is it was almost gonna call it quadrimodal because there was whole lot of cases where it was zero percent . they just plain got it all right . and then there and then there was another bunch that were couple percent .
F: but if you if you actually histogrammed it , and it was , , it was zero was the most of them , but then there were the others were decaying from there . and then there was the bump for the non - natives and then the pathological ones ,
E: cuz some of our non - natives are pretty non - native .
A: you did you have , , something in the report about , , about , , for , forced alignment ? have you have you started on that ?
F: , , so 've been struggling with the forced alignments . so the scheme that drew on the board last time where we tried to , allow reject models for the speech from other speakers , most of the time it doesn't work very . so , , and the haven't done , the only way to check this right now was for me to actually load these into waves and , , plus the alignments , and play them and see where the and it looks and so looked of the utterances from you , chuck , in that one conversation , which you probably know which one , it 's where you were on the lapel and morgan was sitting next to you and we can hear everything morgan says . but and some of what you , you also appear quite bit in that cross - talk . so , actually went through all of those , there were fifty - five segments , , in waves , and did crude check , and more often than not , it gets it wrong . so there 's either the beginning , mostly the beginning word , where th you , , , chuck talks somewhere into the segment , but the first , , word of what he says , often "" "" but it 's very reduced "" , "" that 's just aligned to the beginning of someone else 's speech , in that segment , which is cross - talk . so , , 'm still tinkering with it , but it might be that we can't get clean alignments out of this out of those , , channels ,
C: unless maybe we do this , , , cancellation business .
D: right , but that 's , that was our plan , but it 's clear from dan that this is not something you can do in short amount of time .
C: the short amount of time thing , right .
D: so we , we had spent lot of time , , writing up the hlt paper and we wanted to use that , , analysis , but the hlt paper has , , it 's very crude measure of overlap . it 's not really something you could scientifically say is overlap , it 's just whether or not the , , the segments that were all synchronized , whether there was some overlap somewhere . and , , that pointed out some differences , so he thought if we can do something quick and dirty because dan said the cross - cancellation , it 's not straight - forward . if it were straight - forward then we would try it , so , it 's good to hear that it was not straight - forward , thinking if we can get decent forced alignments , then at least we can do overall report of what happens with actual overlap in time ,
B: didn't think that his message said it wasn't straight - forward .
E: if we 'd just
B: he 's just saying you have to look over longer time window when you do it .
D: and the but there are some issues of this timing , , in the recordings
B: so you just have to look over longer time when you 're trying to align the things , you can't you can't just look
E: are you talking about the fact that the recording software doesn't do time - synchronous ? is that what you 're referring to ? that seems to me you can do that over the entire file and get very accurate
F: don't thi don't think that was the issue .
D: that was side issue .
F: the issue was that you have to you have you first have to have pretty good speech detection on the individual channels .
D: and it 's dynamic , so it was more dynamic than some simple models would be able to so there are some things available , and too much about this area where if people aren't moving around much than you could apply them , and it should work pretty if you took care of this recording time difference .
E: right , which should be pretty straight forward .
D: which at least is defined , but then if you add the dynamic aspect of adapting distances , then it wasn't it just wasn't something that he could do quickly and not in time for us to be able to do something by two weeks from now , less than week . so , so what we can do if anything , that 's worth , , eurospeech paper at this point .
B: andreas , how did it work on the non - lapel ?
E: that 's what was gonna say .
F: haven't checked those yet . it 's very tedious to check these . we would really need , ideally , transcriber to time mark the , the be at least the beginning and ends of contiguous speech . and , , then with the time marks , you can do an automatic comparison of your of your forced alignments .
B: because really the at least in terms of how we were gonna use this in our system was to get an ideal an idea , , for each channel about the start and end boundaries . we don't really care about like intermediate word boundaries ,
F: no , that 's how 've been looking at it . don't care that the individual words are aligned correctly , but you don't wanna , , infer from the alignment that someone spoke who didn't .
B: right , exactly . so that 's why was wondering if it maybe if it doesn't work for lapel , we can just not use that
F: haven't ha just haven't had the time to , , do the same procedure on one of the so would need would need channel that has speaker whose who has lot of overlap but , is non - lapel mike . and , , where preferably , also there 's someone sitting next to them who talks lot .
E: so meeting with me in it .
F: maybe someone can help me find good candidate and then would be willing to
B: maybe the best way to find that would be to look through these . cuz you can see the seat numbers , and then you can see what type of mike they were using . and so we just look for , , somebody sitting next to adam at one of the meetings
D: actually we can tell from the data that we have ,
F: from the insertions , maybe ?
D: , there 's way to tell . it might not be single person who 's always overlapping that person but any number of people , and , , if you align the two hypothesis files across the channels , , just word alignment , you 'd be able to find that . so so that 's last ther there 're few things we could do . one is just do like non - lapels if we can get good enough alignments . another one was to try to get somehow align thilo 's energy segmentations with what we have . but then you have the problem of not knowing where the words are because these meetings were done before that segmentation . but maybe there 's something that could be done .
B: what what is why do you need the , , the forced alignment for the hlt for the eurospeech paper ?
D: wanted to just do something not on recognition experiments because that 's ju way too early , but to be able to report , , actual numbers . like if we if we had hand - transcribed pe good alignments or hand - checked alignments , then we could do this paper . it 's not that we need it to be automatic . but without knowing where the real words are , in time
B: so it was to get it was to get more data and better to squeeze the boundaries in .
D: to to an overlap really if it 's really an overlap , or if it 's just segment correlated with an overlap , and that 's the difference to me between like real paper and , promissory paper . so , , if we it might be possible to take thilo 's output and like if you have , , like right now these meetings are all ,
E: forgot the digital camera again .
D: they 're time - aligned , so if these are two different channels and somebody 's talking here and somebody else is talking here , just that word , if thilo can tell us that there 're boundaries here , we should be able to figure that out because the only thing transcribed in this channel is this word . but , , , if there are things if you have two and they 're at the edges , it 's like here and here , and there 's speech here , then it doesn't really help you ,
B: thilo 's won't put down two separate marks in that case
D: it it would , but , , we exactly where the words are because the transcriber gave us two words in this time bin
E: thilo 's will . but .
D: and we don't really know ,
A: it 's merging problem . if you had if you had if you had script which would 've thought about this , and 've discussed 've discussed it with thilo ,
D: if you have any ideas .
A: the , , in principle could imagine writing script which would approximate it to some degree , but there is this problem of slippage ,
E: maybe maybe that will get enough of the cases to be useful .
D: that would be really helpful . that was another possibility .
E: cuz it seemed like most of the cases are the single word sorts , or at least single phrase
A: they can be stretched .
E: in most of the bins .
A: wouldn't make that generalization cuz sometimes people will say , "" and then "" and there 's long pause and finish the sentence and sometimes it looks coherent and the it 's it 's not simple problem . but it 's really and then it 's coupled with the problem that sometimes , , with fricative you might get the beginning of the word cut off and so it 's coupled with the problem that thilo 's isn't perfect either . we 've th it 's like you have merging problem plus so merging plus this problem of , , not if the speech - nonspeech were perfect to begin with , the detector , that would already be an improvement , but that 's impossible , , that 's too much to ask . and so and may , , it 's that there always th there would have to be some hand - tweaking , but it 's possible that script could be written to merge those two types of things . 've 've discussed it with thilo and in terms of not him doing it , but we discussed some of the parameters of that and how hard it would be to in principle to write something that would do that .
D: in the future it won't be as much as an issue if transcribers are using the tightened boundaries to start with , then we have good idea of where the forced alignment is constrained to .
A: it 's just , , matter of we had the revolution we had the revolution of improved , , interface , , one month too late ,
D: so 'm no if this
A: but it 's like , , it 's wonderful to have the revolution ,
D: it 's it 's
A: so it 's just matter of , , from now on we 'll be able to have things channelized to begin with .
E: and we 'll just have to see how hard that is .
A: that 's right .
E: so so whether the corrections take too much time .
A: that 's right .
E: was just thinking about the fact that if thilo 's missed these short segments , that might be quite time - consuming for them to insert them .
D: but he also can adjust this minimum time duration constraint and then what you get is noises mostly , but that might be ,
E: it might be easier to delete something that 's wrong than to insert something that 's missing .
D: and you can also see in the waveform
E: what do you think , jane ?
C: if you can feel confident that what the , that there 's actually something that you 're not gonna miss something ,
E: cuz then you just delete it , and you don't have to pick time .
A: the problem is it 's really good question , and really find it pain in the neck to delete things because you have to get the mouse up there on the on the text line and and otherwise you just use an arrow to get down it depends on how lar th there 's so many extra things that would make it one of them harder than the other , or vice versa . it 's not simple question . but , , , in principle , like , , if one of them is easier then to bias it towards whichever one 's easier .
E: the semantics aren't clear when you delete segment , because you would say you would have to determine what the surroundings were .
D: you could just say it 's noise , though , and write , , post - processor will just all you have to do is just
E: if it 's really noise .
D: or just say it 's just put "" , "" , like "" not speech "" ,
A: it 's easier to add than delete , frankly ,
D: and then you can get
A: because you have to , , maneuver around on the on both windows then .
E: to add or to delete ? that maybe that 's an interface issue that might be addressable .
A: it 's possible .
E: but it 's the semantics that are that are questionable to me , that you delete something so let 's say someone is talking to here , and then you have little segment here . is that part of the speech ? is it part of the nonspeech ? what do you embed it in ?
D: there 's something , though , about keeping , and this is probably another discussion , keeping the that thilo 's detector detected as possible speech and just marking it as not speech than deleting it . because then when you align it , then the alignment can you can put reject model or whatever ,
E: so then they could just like put that 's what you meant by just put an "" "" there .
D: and you 're consistent with th the automatic system ,
E: that 's an interesting idea .
D: whereas if you delete it
E: so so all they so th they would have to do is put like an "" "" there .
D: or some , , dummy reject mod
E: so blank for blank for silence , "" "" "" "" for speech , "" "" "" "" else .
D: that 's actually better way to do it cuz the the forced alignment will probably be more consistent than
A: like , there 's complication which is that you can have speech and noise in
D: if it 's just as easy ,
A: , on the same channel , the same speaker , so now sometimes you get ni microphone pop and , , , there 're these fuzzy hybrid cases , and then the problem with the boundaries that have to be shifted around . it 's not simple not simple problem .
D: anyway , quick question , though , at high level do people think , let 's just say that we 're moving to this new era of like using the , , pre - segmented , non - synchronous conversations , does it make sense to try to take what we have now , which are the ones that , , we have recognition on which are synchronous and not time - tightened , and try to get something out of those for purposes of illustrating the structure and the nature of the meetings , or is it better to just , , forget that and tr
E: we 'll have to , eventually . and my hope was that we would be able to use the forced alignment to get it .
D: that was everybody 's hope .
E: but if we can't
D: and maybe we can for the non - lapel , but
E: but if we can't , then maybe we just have to
D: if we can't then we can fake it even if we 're we report , , we 're wrong twenty percent of the time or ten percent of the time .
E: are you talking about for paper , or are talking about for the corpus .
D: that 's good question actually .
E: cuz for the corpus it would be if everything were
D: actually that 's good question because we 'd have to completely redo those meetings , and we have like ten of them now .
E: we wouldn't have to re - do them , we would just have to edit them .
A: and also , , still haven't still haven't given up on forced alignment .
D: no , you 're right ,
A: that when brian comes , this 'll be an interesting aspect to ask him as when brian kingsbury comes .
E: you you said ryan . and it 's like , "" who 's ryan ? ""
A: ryan could come .
D: no , that 's good point , though , because for feature extraction like for prosody , , the meetings we have now , it 's good chunk of data we need to get decent
A: that 's what my hope has been ,
D: so we should at least try it even if we can't ,
A: and that 's what , ever since the february meeting that transcribed from last year , forced alignment has been on the on the table as way of cleaning them up later .
E: on the table ,
A: and and so 'm hopeful that 's possible . know that there 's complication in the overlap sections and with the lapel mikes ,
D: we might be able , at the very worst , we can get transcribers to correct the cases where you have good estimate where these places are because the recognition 's so poor .
B: we were never just gonna go with these as the final alignments .
D: and so you 're
B: we were always gonna run them past somebody .
D: so we need some way to push these first chunk of meetings into state where we get good alignments .
F: 'm probably going to spend another day or so trying to improve things by , , by using , , acoustic adaptation . the right now 'm using the unadapted models for the forced alignments , and it 's possible that you get considerably better results if you , , manage to adapt the , , phone models to the speaker and the reject model to the to all the other speech .
B: could you could you at the same time adapt the reject model to the speech from all the other channels ?
C: that 's what he just said .
E: that 's what he was saying .
F: that 's what said .
B: not just the speech from that of the other people from that channel , but the speech from the actual other channels .
E: don't think that would work , lot of it 's dominated by channel properties .
D: but what you do wanna do is take the , even if it 's klugey , take the segments the synchronous segments , the ones from the hlt paper , where only that speaker was talking .
F: so you want to
D: use those for adaptation , cuz if you if you use everything , then you get all the cross - talk in the adaptation , and it 's just blurred .
F: that 's good point .
D: and that we know , , we have that . and it 's about roughly two - thirds , , very roughly averaged . that 's not completely negligible . like third of it is bad for adaptation or so .
E: it was higher than that , that 's pr
D: it really it depends lot . this is just an overall
C: we 're not turning in to eurospeech , redo of the hlt paper . that don't wanna do that ,
E: 'm doing that for avios .
D: but we 're , morgan 's talk went very , .
E: "" bleep "" .
D: morgan 's talk went very it woke it was really presented and got people laughing
F: some good jokes in it ?
E: especially the batteried meter popping up , that was hilarious . right when you were talking about that .
C: that wa that was the battery meter saying that it was fully charged ,
E: it 's full .
A: you said , "" speaking about energy "" , .
E: but that was funny .
A: that was very .
E: he he was onto the bullet points about talking about the the little hand - held , and trying to get lower power and so on ,
F: po - low power
E: and microsoft pops up little window saying "" your batteries are now fully charged . ""
A: that 's great .
E: 'm thinking about scripting that for my talk , , put little script in there to say "" your batteries are low "" right when 'm saying that .
C: no , in your case , , you were joking about it , but , , your case the fact that your talking about similar things at couple of conferences , it 's not these are conferences that have really different emphases . whereas hlt and eurospeech , pretty pretty similar , so 't see really just putting in the same thing ,
E: are too close ,
D: no , don't think that paper is really the hlt paper is really more of introduction - to - the - project paper , and ,
E: for eurospeech we want some results if we can get them .
D: , it 's probably wouldn't make sense ,
C: or some or some would see eurospeech if we have some eurospeech papers , these will be paper , submissions . these will be things that are particular things , aspects of it that we 're looking at , rather than , , attempt at global paper about it .
D: right , right .
A: did go through one of these meetings . had , , one of the transcribers go through and tighten up the bins on one of the , , nsa meetings , and then went through afterwards and double - checked it so that one is really very accurate . men mentioned the link . sent that one ?
G: the which one ?
A: 'm trying to remember don't remember the number off hand . it 's one of the nsa 's . sent email before the conference , before last week . bef - what is wednesday , thursday .
D: that might have been the one of the ones that we did .
A: 'm that one 's accurate , 've been through it myself .
D: so that might actually be useful but they 're all non - native speakers .
F: so we could compare before and after
E: that 's what was gonna say . the problem with those , they 're all german .
G: that 's the problem with the nsa speakers .
D: and and extremely hard to follow , like word - wise , bet the transcri , have no idea what they 're talking about ,
A: corrected it for number of the words . 'm that , , they 're they 're accurate now .
F: actually have to go .
D: this is tough for language model probably but that might be useful just for speech .
E: andreas is leaving the building .
C: don't think we 'll go much longer .
E: , before you go it 's alright for you to talk little without the mike noticed you adjusting the mike lot , did it not fit you ?
A: won noticed when you turned your head , it would it would tilt .
E: maybe it wasn't just tightened enough , or
D: maybe the , the thing that you have tightened @ @ ,
B: actually if you have larger head , that mike 's gotta go farther away which means the balance is gonna make it wanna tip down .
E: cuz , 'm just thinking , , we were we 're we 've been talking about changing the mikes , , for while , and if these aren't acoustically they seem really good , but if they 're not comfortable , we have the same problems we have with these stupid things .
A: this is the first time 've worn this , find it very comfortable .
E: find it very comfortable too , but , , it looked like andreas was having problems , and morgan was saying it
C: but had it on had it on this morning and it was fine .
B: can see that ?
E: you did wear it this morning ? it 's off , so you can put it on .
B: don't want it on , want to , , say what is problem with this . if you are wearing this over your ears and you 've got it all the way out here , then the balance is gonna want to pull it this way . where as if somebody with smaller head has it back here ,
E: it 's more balanced .
B: then it then it falls back this way so it 's
D: so we have to
E: wh what it 's supposed to do is the backstrap is supposed to be under your crown , and so that should be should be if it 's right against your head there , which is what it 's supposed to be , that balances it so it doesn't slide up .
B: so this is supposed to be under that little protuberance .
E: if you feel the back of your head , you feel little lump , and so it 's supposed to be right under that .
B: so it 's really supposed to go more like this than like this .
E: yes , exactly .
B: but then isn't that going to you can control that .
E: that that tilts , in lots and lots of different ways .
D: so 'm not saying anything about bias towards small headsize , but does seem ,
B: it would be an advantage .
A: wonder if it 's if he was wearing it over his hair instead of under his hair .
C: we should we shou we should work on compressing the heads , and
E: it probably just wasn't tight enough to the back of his head . so the directions do talk about bending it to your size , which is not really what we want .
B: the other thing that would do it would be to hang five pound weight off the back .
C: that 's good !
A: what did you say ?
C: hang five pound weight off the off the back .
B: hang five pound weight off the back .
E: we at boeing used was doing augmented reality so they had head - mounts on , and we had little jury - rigged one with welder 's helmet ,
B: counter - balance .
E: and we had just bag with bunch of marbles in it as counter - balance .
C: or maybe this could be helpful just for evening the conversation between people . if people those who talk lot have to wear heavier weights , so , , what was gonna say ? , was gonna say , , had these , , conversations with nist folks also while was there and , , , so they have their plan for room , , with , , mikes in the middle of the table , and , , close - mounted mikes , and they 're talking about close - mounted and lapels , just cuz and the array .
D: which is the interesting
C: and , like multiple video cameras coverin covering every everybody every place in the room ,
D: and video , right .
C: the the mikes in the middle , the head - mounted mikes , the lapel mikes , the array , , with there 's some discussion of fifty - nine ,
E: fifty - nine elements .
C: they might go down to fifty - seven because , , there is , , some pressure from couple people at the meeting for them to use kemar head . forget what kemar , , stands for , but what it is it 's dummy head that is very specially designed ,
E: that 's right .
C: and and , so what they 're actually doing is they 're really there 's really two recording systems .
D: that 's great idea .
C: so they may not be precisely synchronous , but the but there 's two recording systems , one with , , twenty - four channels , and one with sixty - four channels . and the sixty - four channel one is for the array , but they 've got some empty channels there , and anyway they like they 're saying they may give up couple if for the kemar head if they go with that .
E: it is good idea . , jonathan fiscus did say that , , they have lots of software for doing calibration for skew and offset between channels and that they 've found that 's just not big deal .
C: 'm not too worried about that .
D: but they 're still planning to do like fake
E: scenario - based .
D: they have to do something like that ,
E: their their legal issues won't allow them to do otherwise . but it sounded like they were pretty thought out
D: th that 's true .
E: and they 're they 're gonna be real meetings , it 's just that they 're with str with people who would not be meeting otherwise .
B: did did they give talk on this or was this informal ?
C: no , we just had some discussions , various discussions with them .
E: it 's just informal . also sat and chatted with several of the nist folks . they seemed like good group .
B: what was the , the paper by , , lori lamel that you mentioned ?
C: , we sh we should just have you have you read it , but , mea ba , we 've all got these little proceedings , but , , , it was about , , , going to new task where you have insufficient data and using data from something else , and adapting , and how that works . so it was pretty related to what liz and andreas did , , except that this was not with meeting , it was with like they didn't they start off with broadcast news system ? and then they went to
E: the - their broadcast news was their acoustic models and then all the other tasks were much simpler . so they were command and control and that thing .
C: ti - digits was one of them , and , , wall street journal .
B: what was their rough what was their conclusion ?
E: read wall street journal .
D: it 's it 's good paper ,
E: that was one of the ones that liked . that it not only works , in some cases it was better , which was pretty interesting , but that 's cuz they didn't control for parameters . the broadcast news nets were not nets ,
B: did they ever try going the other direction from simpler task to more complicated tasks ,
E: acoustic models were lot more complex . not in that paper .
C: that might be hard .
E: , one of the big problems with that is often the simpler task isn't fully doesn't have all the phones in it , and that makes it very hard . but 've done the same thing . 've been using broadcast news nets for digits , like for the spr speech proxy thing that did ? that 's what did . so . it works .
C: and they have they have better adaptation than we had than that system ,
E: you mean they have some .
C: we should probably what would actually what we should do , , haven't said anything about this , but probably the five of us should pick out paper or two that , , , got our interest , and we should go around the room at one of the tuesday lunch meetings and say , , what was good about the conference ,
E: do trip report .
D: the summarization was interesting , anything about that field , but for this proposal on meeting summarization , , it 's far cry because they weren't working with meeting type data , but he got an overview on some of the different approaches ,
B: do you remember who the groups were that we 're doing ?
D: this was the last day ,
E: lot of different ones .
D: but , , there 's that 's huge field and probably the groups there may not be representative of the field , exactly that everyone submits to this particular conference ,
B: was were there folks from bbn presenting ?
D: yet there was , let 's see , this was on the last day , mitre , bbn , and , , prager
E: mitre , bbn , ibm .
C: columbia have anything ?
E: wasn't who who did the order one ?
D: this was wednesday morning . the sentence ordering one , was that barselou , and these guys ?
E: ugh ! 'm just so bad at that .
D: anyway , it 's in the program , should have read it to remind myself , but that 's useful and like when mari and katrin and jeff are here it 'd be good to figure out some kinds of things that we can start doing maybe just on the transcripts cuz we already have
E: we do have word transcripts .
A: like the idea that adam had of , , maybe generating minutes based on some of these things that we have because it would be easy to to do that it has to be , though , someone from this group because of the technical nature of the thing .
E: someone who actually does take notes , 'm very bad at note - taking .
D: but what 's interesting is there 's all these different evaluations , like just , , how do you evaluate whether the summary is good or not ,
E: always write down the wrong things .
A: do take notes .
D: and that 's what 's was interesting to me is that there 's different ways to do it ,
B: was sra one of the groups talking about summarization , no ?
D: hm - umm .
A: it was an interesting session .
E: and as said , like the microsoft talk on scaling issues in , , word sense disambiguation , that was interesting .
C: that was an interesting discussion ,
E: it it was the only one it was the only one that had any real disagreement about .
D: the data issue comes up all the ti
C: didn't have as much disagreement as would have liked , but didn't wanna wouldn didn't wanna get into it because , , , it was the application was one didn't know anything about , it just would have been , , me getting up to be argumentative , so what they were saying it 's one of these things is , all you need is more data , but mea wh it @ @ that 's that 's dissing it , , improperly , it was study . they were doing this it wasn't word - sense disambiguation , it was was it was it word - sense ?
E: but it was it was very simple case of "" to "" versus "" too "" versus "" two "" and "" there "" , "" their "" , "" they 're ""
D: and there and their and and that you could do better with more data , , that 's clearly statistically
C: and so , what they did was they had these different kinds of learning machines , and they had different amounts of data , and so they did like , , eight different methods that everybody , , , argues about , "" my learning machine is better than your learning machine . "" and , , they were started off with million words that they used , which was evidently number that lot of people doing that particular task had been using . so they went up , being microsoft , they went up to billion . and then they had this log scale showing and naturally everything gets
E: them being beep , they went off to billion .
C: it 's big company , didn't didn't mean it as ne anything negative ,
D: you mean the bigger the company the more words they use for training ?
E: the reason they can do that , is that they assumed that text that they get off the web , like from wall street journal , is correct , and edit it . so that 's what they used as training data . it 's just saying if it 's in this corpus it 's correct .
C: but , , yes . there was the effect that , , one would expect that that you got better and better performance with more and more data . but the real point was that the different learning machines are all over the place , and by going up significantly in data you can have much bigger effect then by switching learning machines and furthermore which learning machine was on top depended on where you were in this picture ,
B: this was my concern about the recognizer in aurora . that the differences we 're seeing in the front - end is once you get real recognizer at the back - end .
D: if you add more data ?
C: so so , , that was that was , , it 's good point , but the problem had with it was that the implications out of this was that , , the choices you make about learning machines were therefore irrelevant which is not at as for as tasks 'm more familiar with @ @ is not true . what what is true is that different learning machines have different properties , and you wanna those properties are . and someone else implied that we , all the study of learning machine we still what those properties are . we them perfectly , but we know that some kinds use more memory and some other kinds use more computation and some are hav have limited discrimination , but are just easy to use , and others are
B: but doesn't their conclusion just you could have guessed that before they even started ? because if you assume that these learning things get better and better , then as you approach there 's point where you can't get any better , you get everything right .
D: it 's just no
B: so they 're all approaching .
E: no , but there was still spread . they weren't all up they weren't converging .
B: but what 'm saying is that th they have to , as they all get better , they have to get closer together .
E: they were all still spread . right , right . but they hadn't even come close to that point . all the tasks were still improving when they hit billion .
B: but they 're all going the same way , so you have to get closer .
E: but they didn't get closer . they just switched position .
C: that 's getting cl the spread was still pretty wide that 's th that 's true , but , , it would be irntu intu intuition that this would be the case , but , , to really see it and to have the intuition is quite different , somebody let 's see who was talking about earlier that the effect of having lot more data is quite different in switchboard than it is in broadcast news ,
D: it 's different for different tasks .
E: it was liz .
D: so it depends lot on whether , , it disambiguation is exactly the case where more data is better , you 're you can assume similar distributions , but if you wanted to do disambiguation on different type of , , test data then your training data , then that extra data wouldn't generalize ,
E: but , one of their they they had couple points . one of them was that "" , maybe simpler algorithms and more data are is better "" . because their simplest , most brain - dead algorithm did pretty darn when you got gave it lot more data . and then also they were saying , "" , you have access to lot more data . why are you sticking with million words ? "" their point was that this million - word corpus that everyone uses is ten or fifteen years old . and everyone is still using it ,
C: but anyway , it 's it 's just the it 's it 's not really the conclusion they came to so much , as the conclusion that some of the , , commenters in the crowd came up with
E: but we could talk about this , this would be fun to do .
C: that , , , this therefore is further evidence that , , more data is really all you should care about , and that was just going too far the other way ,
E: machine - learning .
C: and the , , one person ga got up and made brief defense , but it was different grounds , it was that , , the reason people were not using so much data before was not because they were stupid or didn't realize data was important , but th they didn't have it available . but the other point to make again is that , , machine learning still does matter , but it matters more in some situations than in others , and it and also there 's there 's not just mattering or not mattering , but there 's mattering in different ways . you might be in some situation where you care how much memory you 're using , or you care , , what recall time is , or you care , , and
E: or you only have million words for your some new task .
D: or done another language , or you so there 's papers on portability and rapid prototyping and blah - blah , and then there 's people saying , "" , just add more data . ""
C: and there 's cost !
D: these are like two different religions , .
C: there 's just plain cost ,
E: that 's big one .
C: so these , th the in the speech side , the thing that @ @ always occurs to me is that if you one person has system that requires ten thousand hours to train on , and the other only requires hundred , and they both do about the same because the hundred hour one was smarter , that 's that 's gonna be better . because people , , there isn't gonna be just one system that people train on and then that 's it for the for all of time . people are gonna be doing other different things , and so it these things matters matter .
A: that 's it .
E: so that 's one of the slides they put up .
A: so , , this was very provocative slide . she put this up , and it was like this is this people kept saying , "" can see that slide again ? "" and then they 'd make comment , and one person said , - known person said , , , "" before you dismiss forty - five years including my work ""
E: forty - five years of research .
D: but th , the same thing has happened in computational linguistics , you look at the acl papers coming out , and now there 's turn back towards , we 've learned statistic we 're getting what we expect out of some statistical methods , the there 's arguments on both sides ,
E: the matters is the thing that was misleading .
A: that was very offending ,
E: is th of them are based on all the others , just , you can't say
B: maybe they should have said "" focus "" .
E: and 'm saying the same thing happened with speech recognition , for long time people were hand - coding linguistic rules and then they discovered machine - learning worked better . and now they 're throwing more and more data and worrying perhaps worrying less and less about , , the exact details of the algorithms .
D: and and then you hit this
E: except when they have eurospeech paper .
C: tea is tea is , , starting .
E: shall we read some digits ? are we gonna do one at time ? or should we read them all agai at once again .
C: let 's do it all at once .
A: that 's good .
C: we @ @ let 's try that again .
D: so , and maybe we won't laugh this time also .
E: so remember to read the transcript number so that , , everyone knows that what it is . three , two , one .
C: boy , is that ever efficient .
E: that 's really fast .
","The Berkeley Meeting Recorder group discussed the preparation of a data sample for IBM , the manual adjustment of time bins by transcribers , recognition results for a test set of digits data , and forced alignments.
Participants also talked about Eurospeech 2001 submissions , and exchanged comments on the proceedings of the recently attended Human Language Technologies conference ( HLT'01 ).
Preliminary recognition results were presented for a subset of digits data.
Efforts to deal with cross-talk and improve forced alignments for non-digits data were also discussed.
Subsequent manual adjustment of speech and non-speech boundaries will be delegated to the transcriber pool.
A subset of Meeting Recorder data will be prepared ( i.e . pre-segmented and manually adjusted ) for delivery to IBM.
The Transcriber interface may require modifications if it becomes necessary for transcribers to quickly switch among waveform displays.
Transcribers risk overlooking speech that is deeply embedded in the mixed signal.
Should transcriptions be derived from each of the close-talking channels or from the mixed signal alone?
The pre-segmentation tool does not perform well on short utterances , e.g . backchannels.
The Transcriber interface does not allow the user to quickly switch among visual displays , i.e . multi-channel waveforms.
Forced alignments were problematic for non-digits data due to cross-talk.
This problem was reported to be particularly bad for cross-talk featuring more than one word.
Echo cancellation was considered as a means of improving forced alignments , but was ultimately deemed to be too time-consuming given the dynamic aspect of adapting distances between speakers.
Comparing error rates in terms of the recording device used , i.e . lapel versus wireless microphones , is tedious.
Deleting segments of the recordings is expected to be very time-consuming for transcribers.
More results are needed for generating adequate submissions for Eurospeech'01.
Participants have complained that the head-mounted microphone is uncomfortable.
One meeting recording has been channelized and pre-segmented for delivery to IBM.
A sample of digits data is being prepared for IBM.
Preliminary recognition results were obtained for a subset of digits data.
The error rate distribution was multimodal , reflecting differences in performance for native versus non-native speakers , and also possible pre-processing errors.
Future efforts will involve an attempt to get good forced alignments on digits data and generate a report for Eurospeech'01.
A program has been developed for replacing sections of recorded speech with editing bleeps.
The tightening of time bins for one NSA meeting was checked and judged to be highly accurate.
Efforts are ongoing to improve forced alignments for a subset of non-digits data , including acoustic adaptation manipulations.
"
ami_abstractive_summary,Bed003.txt,"D: is that good ?
C: 've have never handled them .
B: goats eat cans , to my understanding .
D: did we need to do these things ?
B: could hit - seven to do that ? the remote will do it cuz 'm already up there ?
A: in control here .
B: you are in control .
D: we 're all so high tech here . yet another powerpoint presentation .
B: it makes it easier to do so , we were
C: johno , where are you ?
B: so , let 's see . which one of these buttons will do this for me ?
C: should you go back to the first one ?
B: do wanna go back to the first one ?
C: , "" the search for the middle layer "" . it 's talks about it just refers to the fact that one of main things we had to do was to decide what the intermediate nodes were ,
A: but if you really want to find out what it 's about you have to click on the little light bulb .
B: although 've 've never what the light bulb is for . didn't install that into my powerpoint presentation .
A: it opens the assistant that tells you that the font type is too small . do you wanna try ?
B: 'd prefer not to .
D: it 's needless good idea . is that the idea ?
A: why are you doing this in this mode and not in the presentation mode ?
B: because 'm gonna switch to the javabayes program and then if do that it 'll mess everything up .
C: can you maximize the window ?
B: you want me to what do you want me to do ?
C: can you maximize the window so all that on the side isn't doesn't appear ?
A: no , it 's . it 's it 'll work .
B: but then have to end the presentation in the middle so go back to open up here , let 's see if is that better ? 'll also get rid of this "" click to add notes "" . so then the features we decided or we decided we were talked about , the prosody , the discourse , verb choice . we had list of things like "" to go "" and "" to visit "" and what not . the "" landmark - iness "" of knew you 'd like that . of of building . and this we actually have separate feature but decided to put it on the same line for space . "" walls "" which we can look up because if you 're gonna get real close to building in the tango mode , there 's gotta be reason for it . and it 's either because you 're in route to something else or you wanna look at the walls . the context , which in this case we 've limited to "" business person "" , "" tourist "" , or "" unknown "" , the time of day , and "" open to suggestions "" , isn't actually feature . it 's "" we are open to suggestions . ""
D: can ask the walls part of it is that , in this particular domain you said be it could be on two different lines but are you saying that in this particular domain it happens the that landmark - iness cor is correlated with
B: they 're separate things . either could put "" walls "" on its own line or "" open to suggestions "" off the slide .
C: like you could have
D: by "" "" you mean
C: you like you could have post office with , murals .
B: or one time was at this
D: so "" walls "" is stand in for like architecturally it , significant
B: but see , if it 's
C: architecturally appealing from the outside .
B: but if it 's architecturally significant you might be able to see it from like you might be able to "" vista "" it , and be able to versus , like , was at this place in europe where they had little carvings of , like , dead people on the walls . it was long time ago .
D: there 's lot of those .
B: but if you looked at it real close , you could see the in intricacy of the of the walls .
D: so that count as counts as wall . something you want to inspect at close range because it 's interesting .
A: there is term that 's often used . that 's "" saliency "" , or the "" salience "" of an object . and was just wondering whether that 's the same as what you describe as "" landmark - iness "" . but it 's really not . an object can be very salient but not landmark .
D: there 's landmark for , touristic reasons and landmark for
C: we meant , , touristic reasons .
D: but you can imagine maybe wanting the oth both kinds of things there for different , goals .
B: tourist - landmarks also happen to be wouldn't couldn't they also be they 're not exclusive groups , like non - tourist - landmarks and
A: or it can be als
D: they 're not mutually exclusive ?
B: so our initial idea was not very satisfying , because our initial idea was all the features pointing to the output node .
D: so , big flat structure .
B: and , so we reasons being , , it 'd be pain to set up all the probabilities for that . if we moved onto the next step and did learning of some sort , according bhaskara we 'd be handicapped . belief - nets very .
C: usually , , , if you have features , then it 's two to the or exponential in .
B: and they wouldn't look pretty .
C: they 'd all be like pointing to the one node .
B: so then our next idea was to add middle layer , so the thinking behind that was we have the features that we 've drawn from the communication of some like , the someone the person at the screen is trying to communicate some abstract idea , like "" 'm "" the abstract idea being "" am tourist want to go to this place . "" so we 're gonna set up features along the lines of where they want to go and what they 've said previously and whatnot . and then we have the means that they should use . but the middle thing , we were thinking along the lines of maybe trying to figure out , like , the concept of whether they 're tourist or whether they 're running an errand like that along those lines . yes , we could things we couldn't extract the from the data , the hidden variables . so then the hidden variables hair variables we came up with were whether someone was on tour , running an errand , or whether they were in hurry , because we were thinking , if they were in hurry there 'd be less likely to like or th
C: want to do vista , because if you want to view things you wouldn't be in hurry .
B: or they might be more likely to be using the place that they want to go to as like navigational point to go to another place . whether the destination was their final destination , whether the destination was closed . and then "" let 's look at the belief - net "" . so that means that should switch to the other program . right now it 's still in toy version of it , because we didn't know the probabilities of or 'll talk about it when get the picture up .
A: no one knows it .
B: so this right what we let 's see . what happens if maximize this ? there we go . so . the mode has three different outputs . the probability whether the probability of vista , tango , or enter . the "" context "" , we simplified . it 's just the businessman , the tourist , unknown . "" verb used "" is actually personally amusing mainly because it 's it 's just whether the verb is tango verb , an enter verb , or vista verb .
C: that one needs lot of
D: and are those mutually exclusive sets ?
C: that 's that needs lot of work . but that would 've made the probably significantly be more complicated to enter , so we decided that for the purposes of this it 'd be simpler to just have three verbs .
D: stab at it .
B: why don't you mention things about this , bhaskara , that am not that are not coming to my mind right now .
C: so , so note the four nodes down there , the , the things that are not directly extracted . actually , the five things . the "" closed "" is also not directly extracted ,
D: from the utterance ?
B: it 's so it is
C: actually , no ,
B: because it 's because have the time of day
C: "" closed "" is .
B: it just had the er and what time it closed .
C: but the other ones , the final destination , the whether they 're doing business , whether they 're in hurry , and whether they 're tourists , that thing is all probabilistically depends on the other things .
D: inferred from the other ones ?
C: and the mode , , depends on all those things only .
B: the actual parse is somewhere up around in here .
C: so we haven't , managed like we don't have nodes for "" discourse "" and "" parse "" , although like in some sense they are parts of this belief - net . but the idea is that we just extract those features from them , so we don't actually have node for the entire parse , because we 'd never do inference on it anyway ,
D: so some of the top row of things what 's what 's "" disc admission fee "" ?
C: whether they discuss the admission fees . so we looked at the data and in lot of data people were saying things like "" can get to this place ? "" "" what is the admission fee ? "" . so that 's like huge clue that they 're trying to enter the place rather than to tango or vista ,
B: there were there 'd be other things besides just the admission fee , but , we didn't have
C: that was like our example .
B: that was the initial one that we found .
D: so there are certain cues that are very strong either lexical or topic - based , concept cues
B: from the discourse that
D: for one of those . and then in that second row or whatever that row of time of day through that so all of those some of them come from the utterance and some of them are either world knowledge or situational things . so that you have no distinction between those and
B: one , . , anything else you want to say bhaskara ?
D: "" unmark @ @ time of day ""
A: they 're they 're are couple of more things . would actually suggest we go through this one more time so we all , agree on what the meaning of these things is at the moment and maybe what changes we
B: so one thing 'm unsure about , is how we have the discus the "" admission fee "" thing set up . so one thing that we were thinking was by doing the layers like this , we kept things from directly affecting the mode beyond the concept , but you could see perhaps discus the "" admission fee "" going directly to the mode pointing at "" enter "" , versus pointing to just at "" tourist "" , but we just decided to keep all the things we extracted to point at the middle and then down .
A: why is the landmark the landmark is facing to the tourists . that 's because we 're talking about landmarks as touristic landmarks
B: that would be whatever building they referred to .
C: so let 's see . disc - "" admission fee "" is binary thing , "" time of day "" is like morning , afternoon , night . is that the deal ?
B: that 's how we have it currently set up , but it could be , , based upon hour or dis we could discrete it des descret - ize it .
C: normally context will include huge amount of information , but , we are just using the particular part of the context which consists of the switch that they flick to indicate whether they 're tourist or not , .
D: so that 's given in their input .
C: so it 's not really all of context . similarly prosody is not all of prosody but simply for our purposes whether or not they appear tense or relaxed .
A: that 's very , the the so the context is switch between tourist or non - tourist ? or also unknown ?
B: or un unknown ,
D: so it seems like that would really help you for doing business versus tourist ,
C: which is th which one ?
D: so the context being , if that question 's in general , "" are you "" do they allow business people to be doing non - business things at the moment ? so then you just have some probabilities over
C: everything is probablistic , and there 's always
D: over which of those it is .
C: so then landmark is "" verb used "" is like , right now we only have three values , but in general they would be probability distribution over all verbs . let me rephrase that . it it can take values in the set of all verbs , that they could possibly use . "" walls "" is binary , "" closed "" is binary "" final destination "" , again all those are binary . and "" mode "" is one of three things .
A: so , the middle layer is also binary ?
C: anything with question mark after it in that picture is binary node .
A: but all those things without question marks are also binary .
C: "" walls "" is something that we extract from our world knowledge . . it is binary .
B: but it doesn't have question mark because it 's extracted .
C: that 's true . see your point . similarly "" closed "" , .
A: so we can either be in hurry or not , but we cannot be in medium hurry at the moment ?
C: to do that we would add another value for that . and that would require updating the probability distribution for "" mode "" as . because it would now have to like take that possibility into account .
D: so , this will happen when we think more about the kinds of verbs that are used in each cases but you can imagine that it 's verb plus various other things that are also not in the bottom layer that would that would help you like it 's conjunction of , the verb used and some other that would determine
C: other syntactic information you mean ?
A: the the landmark is the object the argument in sense ?
D: if that 's always the case haven't looked at the data as much as you guys have .
A: that 's always warping on something some entity , and maybe at this stage we will we do want to get modifiers in there because they may also tell us whether the person is in hurry or not
B: want to get to the church quickly ,
D: that would be cue .
A: what 's the fastest way
B: do we have anything else to say about this ?
C: we can do little demo .
B: but the demo doesn't work very .
A: then it wouldn't be demo
C: we can do demo in the sense that we can , just ob observe the fact that this will , do inference . so we can , , set some of the nodes and then try to find the probability of other nodes .
B: dat - dat - dah . what should observe ?
C: just se set few of them . you don't have to do the whole thing that we did last time . just like , maybe the fact that they use certain verb actually forget the verb . say they discussed the admission fee and the place has walls
B: 'm big fan .
C: and it 's night .
D: it 's starting to grow on me
B: and the time of day is night ?
C: it 's not really consistent . they don't discuss the admission fee . make that false . and it 's night . that didn't work .
D: 'd like to do that again .
B: one thing that bugs me about javabayes is you have to click that and do this . th you want ? so let 's see . want to query ,
C: "" go "" and , right , "" query "" .
B: and then on here so let 's see .
C: so that is the probability that they 're entering , vista - ing or tango - ing .
D: so slightly biased toward "" tango "" ing
B: if it 's night time , they have not discussed admission fee , and the walls are . that makes sense . the reason say the demo doesn't work very is yesterday we observed everything in favor of taking tour , and it came up as "" tango "" , over and over again . we couldn't we couldn't figure out how to turn it off of "" tango "" .
C: it loves the tango . that 's just to do with our probabilities . like , we hand - tuned the probabilities , we were like "" , if the person does this and this , let 's say forty percent for this , fifty per "" like , . so that 's gonna happen .
D: maybe the bias toward "" tango "" ing was yours , then ?
B: that 's that 's at
C: it 's so we have to like fit the probabilities .
B: spent my youth practicing the tango de la muerte .
D: so , the real case ?
A: however , it the purpose was not really , at this stage , to come up with meaningful probabilities but to get thinking about that hidden middle layer .
B: once we look at the data more we 'll get more hidden nodes , but 'd like to see more . not because it would expedite the probabilities , cuz it wouldn't . it would actually slow that down tremendously .
C: not that much though . only little early .
B: we should have exponentially more middle nodes than features we 've extracted . 'm ju 'm just jo
D: so . are "" doing business "" versus "" tourist "" they refer to your current task . like like current thing you want to do at this moment .
C: that 's that 's an interesting point . whether you 're it 's whether it 's not it 's more like "" are you are tourist ? are you in ham - like heidelberg for ""
D: so , that was directly given by the context switch .
C: that 's different thing . what if the context , which is not set , but still they say things like , "" want to go , see the the castle and , et cetera . ""
B: the of "" doing business "" as more of running an errand type thing .
C: business on the other hand is , , definitely what you 're doing .
A: so if you run out of cash as tourist , and and you need to go to the at
D: you may have task . wh you have to go get money and so you are doing business at that stage .
A: "" how do get to the bank ? ""
C: and that 'll affect whether you want to enter or you if you
D: so the "" tourists "" node should be , very consistent with the context node . if you say that 's more their in general what their background is .
C: this context node is bit of do we wanna have
D: are you assuming that or not ? like is that to be if that 's accurate then that would determine tourist node .
C: if the context were to set one way or another , that like strongly , says something about whether or not they 're tourists . so what 's interesting is when it 's not when it 's set to "" unknown "" .
A: we - what set the they set the context to "" unknown "" ?
C: right now we haven't observed it , so it 's averaging over all those three possibilities . you can set it to un "" unknown "" .
A: and if we now do leave everything else as is the results should be the same ,
C: because we th - the way we set the probabilities might not have it 's it 's an issue , so the issue is that in belief - nets , it 's not common to do what we did of like having , , bunch of values and then "" unknown "" as an actual value . what 's common is you just like don't observe the variable , and then just marginalizes but we didn't do this because we felt that there 'd we were thinking in terms of switch that actually but what the right thing is to do for that . 'm not if am happy with the way it is .
A: how long would it take to add another node on the observatory and , , play around with it ?
C: another node on what ?
B: it depends on how many things it 's linked to .
A: let 's just say make it really simple . if we create something that would be so th some things can be landmarks in your sense but they can never be entered ? so maybe we wanna have "" landmark "" meaning now "" enterable landmark "" versus , something that 's simply just vista point , .
B: that 's true .
C: so it 's addressing variable that 's "" enterable or not "" . so like an "" enterable , question mark "" .
B: also , didn't we have size as one ? the size of the landmark . cuz if it 's
C: not when we were doing this , but at some point we did .
B: for some reason had that , that was thought that had at one point but then went away .
C: so you want to have node for like whether or not it can be entered ?
A: , if we include that , "" is it can it be entered ? "" then , this is binary as . and then , there 's also the question whether it may be entered . in the sense that , , if it 's tom the house of tom cruise , , it 's enterable but you may not enter it . you 're not allowed to . unless you are , whatever , his divorce lawyer . and and these are very observable from the from the ontology things .
B: does it actually help to distinguish between those two cases though ? whether it 's practically speaking enterable , or actually physically enterable or not ?
A: if you 're running an errand you maybe more likely to be able to enter places that are usually not al you 're not usually not allowed to
D: it seems like it would for , determining whether they wanna go into it or not .
A: let 's get this clearer . so it 's matrix between if it 's not enterable ,
B: whether it 's whether it 's public building , and whether it 's actually has door . so tom cruise 's house is not public building but it has door . explain to me why it 's necessary to distinguish between whether something has door and is not public . or , if something it seems like it 's equivalent to say that it doesn't have door and it or "" not public "" and "" not door "" are equivalent things , it seems like in practice .
A: so we would have what does it mean , then , that we have to we have an object type statue . that really is an object type . so there is there 's gonna be bunch of statues . and then we have , , an object type , , that 's hotel . how about hotels ? so , the most famous building in heidelberg is actually hotel . it 's the hotel zum ritter , which is the only renaissance building in heidelberg that was left after the big destruction and for the thirty years war , blah - blah .
B: does it have walls ?
A: it has wonderful walls . - and lots of detail , and carvings , engravings and , but , , it 's still an unlikely candidate for the tango mode must say . but . . so so if you are it 's very tricky . so your question is so far have no really arg no real argument why to differentiate between statues as statues and houses of celebrities , from that point of view . can we add , just so see how it 's done , , "" has door "" property
C: what would it , , connect to ? like , what would , , it affect ?
A: , , it might affect actually it 's it wouldn't affect any of our nodes ,
C: what was thinking was if you had like
A: it 's it affects th the "" doing business "" is certainly not .
B: you could affect theoretically you could affect "" doing business "" with "" has door "" .
A: it should , , inhibit that ,
B: let 's see .
C: if javabayes is about that . it might be that if you add new thing pointing to variable , you just like it just overwrites everything . but you can check .
B: we have it saved . so . we can rel open it up again .
C: it 's true .
B: the safety net .
D: you could just add it .
C: that 's fine , but we have to see the function now . has it become all point fives or not ?
B: let 's see . so this is "" has door "" true , false . that 's acceptable . and want to edit the function going to that ,
C: this is fine ,
B: it was fine . added this one .
C: what would be if it is if it just like kept the old function for either value didn't do it .
B: that 's not good .
C: that 's annoying .
A: so just dis dismiss everything . close it and load up the old state so it doesn't screw that up .
B: let 's see .
A: maybe you can read in ?
C: ha - so have you used javabayes lot ?
D: really ha 've haven't used it lot and haven't used it in the last many months , we can ask someone .
C: it might be worth asking around . like , we looked at page that had like bunch of he 'd be the person .
D: srini 's the one to ask would say . he might know .
C: in way this is lot of good features in java it 's cra has gui and it 's those are the main two things . it does learning ,
B: no it doesn't , actually . didn't did learning . maybe it did little bit of learning ,
C: maybe you 're right . but it 's free .
B: which is quite positive ,
C: maybe another thing that but its interface is not the greatest .
B: but actually it had an interface . lot of them were like , .
A: what is the code ? can can we see that ? how do you write the code or do you actually never have to write any code there ?
C: there is actually text file that you can edit . you don't have to do that .
B: there 's like an xml format for bayes - nets .
C: is it xml ?
B: the - there is one . if this uses it .
C: no this doesn't use it . you can look at the text file . but do you have it here ?
B: yes do actually .
C: maybe you don't .
B: let me see .
C: like , there 's the
B: didn't is there an ampersand in dos ?
C: just start up new dos .
B: we - that 's alright . probably double cli click on it . let 's see . let 's see ,
C: it 'll ask you what you what it wants what you want to open it with and see what bat , .
B: one of these days , it should open this ,
A: go right mouse .
B: there we go . maybe it was just it was dead . to the world .
A: through the old notepad . that 's my favorite editor .
B: like like word pad because it has the the returns , the carriage returns on some of them . how they get "" auto - fills "" , or whatever you call it .
C: anyway , there it is .
A: so this is lisp - ?
B: it just looks like it just specifies bunch of
C: that 's how actual probability tables are specified . as , like , lists of numbers . so theoretically you could edit that .
B: it just that it 's
C: but they 're not very friendly .
B: the ordering isn't very clear on
C: so you 'd have to like figure out like you have to go and
D: the layout of the table .
B: actually we could write program that could generate this . we were doing it
C: we can maybe write an interface th for entering probability distributions easily , something like little script . that might be worth it .
A: and that might do .
D: actually seem to recall srini complaining about something to do with entering probability so this is probably
C: the other thing is it is in java
B: we could manipulate the source itself ?
A: do you have the true source files or just the class ?
C: saw directory called "" source "" , go up one ?
B: yes , good . "" source "" . that 's that 's quite .
C: if it actually manipulate the source , though . that might be bit complicated . it might it might be simpler to just have script that , it 's , like , friendly ,
D: the the data tables .
C: it allows you enter things .
A: but if th if there is an xml file that or format that it can also read it just reads this , when it starts .
B: know there is an was looking on the we web page and he 's updated it for an xml version of bayes - nets . there 's bayes - net spec for in xml .
C: he 's like this guy has ? the javabayes guy ? so but , he doesn't use it . so in what sense has he updated it ?
B: th you can either you ca or you can read both . to my understanding .
C: that would be awesome .
B: could have misread the web page , have habit of doing that ,
A: so you got more slides ?
B: do have more slides ? "" future work "" . every presentation have should have "" future work "" slide . we already talked about all this ,
C: the additional thing is learning the probabilities , also . that 's maybe ,
B: that 's future work . and if you have presentation that doesn't have something that doesn't work , then you have "" what learned "" , as slide .
D: can't you have both ?
B: my first approach failed . so that our presentation 's finished . like about these meetings is one person will nod , and then the next person will nod , and then it just goes all the way around the room .
D: missed my turn .
B: no earlier went {nonvocalsound} and bhaskara went {nonvocalsound} and you did it . you did it .
A: it 's like yawning .
D: it 's like yawning .
A: and this announcement was in stereo .
B: should pull up the net again ?
D: could you put the , net up again ?
B: there we go . cuz got wireless mike on .
D: so more general thing than "" discussed admission fee "" , could be 'm just wondering whether the context , the background context of the discourse might be if there 's way to define it or maybe generalize it some way there might be other cues that , say , , in the last few utterances there has been something that has strongly associated with say one of the particular modes if that might be and into that node would be various things that could have specifically come up .
A: this is this is excellent because it gets you thinking along these terms is that maybe we ob we could observe couple of discourse phenomena such as the admission fee , and something else and something else , that happened in the discourse before . and let 's make those four . and maybe there are two so maybe this could be separate region of the net , which has two has it 's own middle layer . maybe this , , has some , funky thing that di and this may influence these hidden nodes of the discourse which is maybe something that is , more general version of the actual phenomenon that you can observe . so things that point towards
B: so instead of single node , for like , if they said the word "" admission fee "" "" admission fee "" , or maybe , , "" how much to enter ""
D: opening hours like that .
B: that would all funnel into one node that would constitute entrance requirements like that .
A: so "" pay visit ""
D: it get into plan recognition kinds of things in the discourse . that 's like the bigger , version of it .
A: and then maybe there are some discourse acts if they happened before , it 's more for cue that the person actually wants to get somewhere else and that you are in in route proceeding past these things , so this would be just something that where you want to pass it . is that it ? however these are then the nodes , the observed nodes , for your middle layer . so this again points to "" final destination "" , "" doing business "" , "" tourist hurry "" and . and so then we can say , "" . we have whole region "" in
D: that 's whole set of discourse related cues to your middle layer .
A: and this is just then just one . so because at the end the more we add , , the more spider - web - ish it 's going to become in the middle and the more of hand editing . it 's going to get very ugly . but with this way we could say "" , these are the discourse phenomena . they ra may have there own hidden layer that points to some of the real hidden layer , or the general hidden layer . and the same we will be able to do for syntactic information , the verbs used , the object types used , modifiers . and maybe there 's hidden layer for that . then we have context .
C: so essentially lot of those nodes can be expanded into little bayes - nets of their own .
B: one thing that 's been bugging me when more look at this is that the the fact that the there 's complete separation between the observed features and in the output . it makes it cleaner , but then .
C: that 's true .
B: if the discourse does
D: what do you mean by that ?
B: the "" discourse admission fee "" node seems like it should point directly to the or increase the probability of "" enter directly "" versus "" going there via tourist "" .
C: or we could like add more , , middle nodes . like we could add node like do they want to enter it , which is affected by admission fee and by whether it 's closed and by whether it has door . so it 's like there are those are the two options . either like make an arrow directly or put new node .
B: that makes sense .
A: and if it if you do it if you could connect it too hard you may get such phenomenon that like "" so how much has it cost to enter ? "" and the answer is two hundred fifty dollars , and then the persons says "" want to see it . "" meaning "" it 's way out of my budget ""
B: there are places in germany where it costs two hundred fifty dollars to enter ?
A: nothing comes to mind . without thinking too hard . or or any good old pink floyd concert .
B: if you want to see "" the magic flute "" .
D: or maybe , famous restaurant . there are various things that you might not want to eat meal there but your own table .
B: the spagos of heidelberg .
A: that the nothing beats the admission charge prices in japan . so there , two hundred dollars is moderate for getting into discotheque . then again , everything else is free then once you 're ins in there . food and drink and . but , we can something somebody can have discussed the admission fee and the answer is if we , still , based on that result is never going to enter that building . because it 's just too expensive .
B: so the discourse refers to "" admission fee "" but it just turns out that they change their mind in the middle of the discourse .
D: you have to have some notion of not just there 's there 's change across several turns of discourse so how if any of this was discussed but how if it all this is going to interact with whatever general , other discourse processing that might be happen .
B: what discourse processing is are the how much is built into smartkom and
A: it works like this . the first thing we get is that already the intention is they tried to figure out the intention , simply by parsing it . and this won't differentiate between all modes , but at least it 'll tell us "" here we have something that somebody that wants to go someplace , now it 's up for us to figure out what going there is is happening , and , if the discourse takes couple of turns before everything all the information is needed , what happens is the parser parses it and then it 's handed on to the discourse history which is , one of the most elaborate modules . it 's it 's actually the whole memory of the entire system , that knows what wh who said what , which was what was presented . it helps an anaphora resolution and it and it fills in all the structures that are omitted , because you say "" , how can get to the castle ? "" , how much is it ? "" and "" would like to let 's do it "" and . so even without an ana anaphora somebody has to make that information we had earlier on is still here . because not every module keeps memory of everything that happened . so whenever the , person is not actually rejecting what happened before , so as in "" no really don't want to see that movie . 'd rather stay home and watch tv "" what movie was selected in what cinema in what town is going to be added into the disc into the representations every di at each dialogue step , by the discourse model discourse model , that 's what it 's called . and , , it does some help in the anaphora resolution and it also helps in coordinating the gesture screen issues . so person pointing to something on the screen , , the discourse model actually stores what was presented at what location on the on the screen so it 's it 's rather huge thing it has very clear interface . we can query it whether admission fees were discussed in the last turn and the turn before that or how deep we want to search which is question . how deep do we want to sear , but we should try to keep in mind that , , we 're doing this for research , so we should find limit that 's reasonable and not go , , all the way back to adam and eve . did that person ever discuss admissions fee fees in his entire life ? and the dialogues are pretty concise
D: so one thing that might be helpful which is implicit in the use of "" admission fee discussion "" as cue for entry , is thinking about the plans that various people might have . like all the different general schemas that they might be following this person is , finding out information about this thing in order to go in as tourist or finding out how to get to this place in order to do business . because then anything that 's cue for one of the steps would be slight evidence for that overall plan . they 're in non in more traditional ai kinds of plan recognition things you have , some idea at each turn of agent doing something , "" , wha what plans is this consistent with ? "" and then get some more information and then you see "" here 's sequence that this roughly fits into "" . it it might be useful here too . you 'd have to figure out what knowl what knowledge representation would work for that .
A: it 's in the these plan schemas . there are some of them are extremely elaborate , "" what do you need to buy ticket ? "" and it 's fifty steps , just for buying ticket at ticket counter , and maybe that 's helpful to look at it to look at those . it 's amazing what human beings can do . when we talked we had the example , , of you being person on ticket counter working at railway station and somebody runs up to you with suitcase in his hands , says new york and you say track seven , and it 's because that person actually is following , you execute whole plan of going through hundred and fifty steps , , without any information other than "" new york "" , inferring everything from the context . so , works . even though there is probably no train from here to new york ,
B: you 'd probably have to transfer in chicago .
A: but it 's possible . no you probably have to transfer also somewhere else . is that san francisco , chicago ? is that possible ?
B: one time saw report on trains , there was line that went from somewhere , maybe it was sacramento to chicago , but there was like california to chicago line of some sort . could be wrong though . it was while ago .
D: the transcontinental railroad , doesn't that ring bell ?
B: but if it 's still
D: it has to exist somewhere .
B: they might have blown it up .
A: it never went all the way , you always had to change trains at omaha ,
D: most of the way .
A: one track ended there and the other one started at five meters away from that
D: you seem to know better than we do so .
A: has anybody ever been on an amtrak ?
D: but not transcontinentally .
B: 'm frightened by amtrak myself . they seem to have lot of accidents on the amtrak .
A: their reputation is very bad . it 's not maybe reality .
D: it 's not like german trains . like german trains are really great
A: but , whether it 's which ones are safer , , statistically .
D: but they 're faster .
C: and there 's much more of them . they 're , it 's way better
A: used amtrak quite bit on the east coast and was surprised . it was actually . on boston new york , new york rhode island ,
C: 've done that thing .
A: that 's different issue .
B: this is going to be an interesting transcript .
C: want to see what it does with "" landmark - iness "" .
D: let 's all say it few more times .
B: it 'd help it figure it out .
D: so tha that structure that robert drew on the board was like more , cue - type - based , here 's like we 're gonna segment off bit of that comes from discourse and then some of the things we 're talking about here are more we mentioned maybe if they talk about , entering or som like they might be more task - based . so if there there 's some more than one way of organizing the variables into something
A: that what you guys did is really nicely sketching out different tasks , and maybe some of their conditions . one task is more likely you 're in hurry when you do that doing business , and less in hurry when you 're tourist tourists may have never have final destinations , because they are eternally traveling around so maybe what what happened what might happen is that we do get this task - based middle layer , and then we 'll get these sub - middle layers , that are more cue - based .
D: that feed into those ?
A: might be might be dichotomy of the world . so , suggest to for to proceed with this in the sense that maybe throughout this week the three of us will talk some more about maybe segmenting off different regions , and we make up some toy observable "" nodes "" is that what th
B: refined re just refine the
A: what 's the technical term ? for the nodes that are observable ? the "" outer layer "" ?
C: just observable nodes ,
A: feature ma make up some features for those identify four regions , maybe make up some features for each region and and , and middle layer for those . and then these should then connect somehow to the more plan - based deep space
B: just refine some of the more general nodes .
A: the - they will be aud ad - hoc for for some time to come .
C: the probabilities and all are completely ad - hoc . we need to look of them . but , they 're even like like , close to the end we were like , , we were like really ad - hoc .
D: it 's even distribution .
C: cuz if it 's like , if it 's four things coming in , and , say , some of them have like three possibilities and all that . so you 're thinking like hundred and forty four possible things numbers to enter ,
D: that 's terrible .
B: some of them are completely absurd too , like they want to enter , but it 's closed , it 's night time , there are tourists and all this weird happens at the line up and you 're like
C: the only like possible interpretation is that they are like come here just to rob the museum to that effect .
D: in which case you 're supposed to alert the authorities , and see appropriate action .
C: another thing to do , , is also to , to ask around people about other bayes - net packages . is srini gonna be at the meeting tomorrow ,
A: the day after tomorrow .
C: day after tomorrow .
B: who 's talking on wednesday ?
C: maybe we can ask him about it .
B: haven't jerry never sent out sent out an email , did he , ever ?
C: but he mentioned at the last meeting that someone was going to be talking ,
A: ben , then ,
D: it 's ben actually , giving his job talk . was just reading the screen .
A: that will be one thing we could do . actually , have , also we can , start looking at the smartkom tables actually wanted to show that to you guys now
B: do you want to trade ?
A: actually made mistake because it fell asleep and when linux falls asleep on my machine it 's it doesn't wake up ever , so had to reboot and if reboot without network , will not be able to start smartkom , because need to have network . so we 'll do that maybe
C: but once you start sart start smartkom you can be on you don't have to be on network anymore . is that the deal ?
B: why does smartkom need network ?
A: it looks up some that , , is that is in the written by the operating system only if it if you get dhcp request , so it , my computer does not ts ip address , unless it boots up with networking .
B: it 's plugged in .
A: and don't have an ip address , they can't look up they who localhost is , and and . but it 's , , simple solution . we can just , go downstairs and and look at this , but maybe not today . the other thing will have to report , data collection . we interviewed fey , she 's willing to do it , meaning be the wizard for the data collection , also maybe transcribe little bit , if she has to , but also recruiting subjects , organizing them , and . so that looks good . jerry however suggested that we should have trial run with her , see whether she can actually do all the spontaneous , eloquent and creativeness that we expect of the wizard . and talked to liz about this and it looks as if friday afternoon will be the time when we have first trial run for the data .
C: so who would be the subject of this trial run ? who will there be is one is you one of you gonna be the subject ?
A: liz also volunteered to be the first subject , which might be even better than us guys .
B: one of us ,
A: if we do need her for the technical , then one of you has to jump in .
B: like how we 've you guys have successfully narrowed it down . "" is one of you going to be the subject ? "" is one of you
D: haven't done it yet .
C: figured it has to be someone who 's , , familiar enough with the data to problems for the wizard , so we can , , see if they 're good .
D: plants ? someone who can plant difficult things .
C: that 's what we wanna check ,
D: in this case it 's it 's testing of the wizard rather than of the subject .
C: isn't that what it is ?
A: yes we would like to test the wizard , but , if we take subject that is completely unfamiliar with the task , or any of the set up , we get more realistic
C: that would be reasonable .
B: that 's probably good enough test of
C: having an actively antagonistic ,
D: that might be little unfair . 'm if we , you think there 's chance we might need liz for , whatever , the technical side of things ? 'm we can get other people around who anything , if we want another subject . like drag ben into it . although he might problems so , is it experimental setup for the , data collection ready determined ?
B: "" test the wizard . "" want that on - shirt .
A: it 's it 's experimental setup on the technical issue except we st we still need recording device for the wizard , just tape recorder that 's running in room . but in terms of specifying the scenario , we 've gotten little further but we wanted to until we know who is the wizard , and have the wizard partake in the ultimate definition probe . so so if on friday it turns out that she really likes it and we really like her , then nothing should stop us from sitting down next week and getting all the details completely figured out .
D: so the ideal task , will have whatever how much the structure of the evolving bayes - net will af affect like we wanna we wanna be able to collect as much of the variables that are needed for that ,
A: mmm - yea - some .
D: in the course of the task ? not all of them
A: bu - 'm even this this tango , enter , vista is , itself , an ad - hoc scenario . the the basic idea behind the data collection was the following . the data we get from munich is very command line , hardly anything complicated . no metaphors whatsoever . not rich language . so we wanted just to collect data , to get that elicits more , , that elicits richer language . and we actually did not want to constrain it too much , just see what people say . and then maybe we 'll discover the phenomenon the phenomena that we want to solve , , with whatever engine we come up with . so this this is parallel track , there they hopefully meet ,
D: so in other words this data collection is more general . it could it could be used for not just this task .
A: it should tell us , , what phenomenon could occur , it should tell us also maybe something about the difference between people who think they speak to computer versus people who think they speak to human being and the differences there . so it may get us some more information on the human - machine pragmatics , , that no one knows anything about , as of yesterday . and nothing has changed since then , and secondly , now that we have started to lick blood with this , and especially since johno can't stop tango - ing , we may actually include , , those intentions . so now we should maybe have at least one navigational task with explicit not ex it 's implicit that the person wants to enter , and maybe some task where it 's more or less explicit that the person wants to take picture , or see it . so that we can label it . that 's how we get corpus that we can label . whereas , , if we 'd just get data we 'd never they actually wanted , we 'd get no cues . that was that .
B: so is this the official end of the meeting now ?
D: looks like it .
C: so what 's "" economics , the fallacy "" ?
B: randomly label things . so that has nothing to do with economics or anything .
A: maybe we ought to switch off these things before we continue .
","The group discussed the first version of the Bayes-net used to work out a user's intentions when asking for directions from a navigation device.
Three intentions were identified: Vista ( to view ) , Enter ( to visit ) and Tango ( to approach ).
The structure of the belief-net comprises , firstly , a feature layer , which includes linguistic , discourse and world knowledge information that can be gleaned from the data.
It is possible for these variables to form thematic clusters(  eg ""entrance"" , ""type of object"" , ""verb"" ) , each one with a separate middle layer.
These feed , in turn , into the main middle layer , that defines more general hidden variables , such as the tourist/business status of the user.
The feature layer can end up being cue-based , while the middle layers task-based.
The latter determine the final probability of each intention in the output layer.
This first model of the belief-net was built in JavaBayes , since it is a free package , has a graphical interface , and it can take XML files as input.
At this stage , all the actual probabilities are ad-hoc and hand-coded.
However , there has been progress in the design and organisation of experiments , that will eventually provide data more useful and appropriate for this task.
It is necessary for the belief-net to have at least one layer of nodes between the features and the final output.
This makes the structure more flexible in terms of coding feature-layer probabilities.
Another technique to systematise the work is the thematic clustering of the features , each cluster forming a Bayes-net of each own: for example features like ""admission fee"" and ""opening hours"" can feed into an intermediate ""entrance"" node connecting to the main middle layer.
The next stage is to refine the set of feature nodes and identify possible clusters.
Although , in theory , traditional AI plan recognition techniques could also be helpful for inferring intentions , the schemas involved are too elaborate for this task.
Further work also includes discussing the possible advantages of Bayes-net packages , other than JavaBayes , with experts at ICSI.
If they continue using JavaBayes , a script to help with the inputting of probabilities in the nodes is needed , as the in-built method is cumbersome.
Finally , it was decided that at least some of the experiments designed for the new data collection initiative will factor in the intentions studied in the current task.
The set of cues that form the feature nodes is not well-defined yet.
Especially with lexical cues ( verbs , modifiers etc ) , no one offered specific intuitions as to how they might contribute to the inference of intentions.
Other features , like ""admission fee"" , may be intuitively linked with one of the outputs ( Enter ) , however , any probabilities are coded in an ad-hoc fashion and are by no means realistic.
Cases like this , where feature and output seem to be linked directly , bring the necessity of a middle layer in the belief-net to question.
Nevertheless , not having a middle layer would not allow for shifts in the discourse and would make the setting of probabilities and manipulation of the belief-net clumsy.
Some issues with the use of JavaBayes also arose: the addition of new variables in an existing node overwrites all previous settings , and the native text file where the probability tables are set is not easy to read; this makes adding and changing variables and nodes problematic.
Finally , it is unclear how much learning can be done on the created nets.
There was a demonstration of the structure and the function of a toy version of the belief-net for the intentionality task.
The features nodes include things like prosody , discourse , verb choice , ""landmark-iness"" of a building , time of day and whether the admission fee was discussed.
The values these nodes take feed into the middle layer nodes identified as hidden variables of the user/device interaction , such as whether the user is on tour , running an errand or in a hurry.
These , in turn , help infer whether the user wants to see , enter or simply approach a building.
The set of features nodes is derived from linguistic cues , world knowledge and discourse history.
SmartKom , although it does not code for intentions as specified in this task , provides a model of the discourse , which can be useful for the detection of features through querying and anaphora resolution.
Experiments for the collection of new data will start soon , since someone who will recruit subjects and help run the experiments has already been hired and the designing of the experiments has also progressed significantly.
"
ami_abstractive_summary,Bed014.txt,"B: mental mental palm pilot . hence no problem .
F: let 's see . so . what ? 'm supposed to be on channel five ? her . nope . doesn't seem to be ,
B: hello 'm channel one .
E: what does your thing say on the back ?
F: nnn , five . alright , 'm five .
D: sibilance . three , three . see , that matches the seat up there .
F: , it 's coming up then , or
D: cuz it 's that starts counting from zero and these start counting from one . ergo , the classic off - by - one error .
B: but mine is correct . it 's one .
D: your mike number is what we 're
E: look at the back .
D: 've bested you again , nancy .
B: no , but the paper 's correct .
D: the paper is correct .
B: look at the paper .
D: didn't det was saying the microphone , not the paper .
C: it 's always offset . .
B: yes , you 've bested me again . that 's how of our continuing interaction .
D: so is keith showing up ? he 's talking with george right now . is he gonna get rip rip himself away from that ?
B: he 'll probably come later .
C: he - he 's probably not , is my .
D: then it 's just gonna be the five of us ?
E: he was very affirmative in his way of saying he will be here at four . but , that was before he knew about that george lecture probably .
C: this this is not it 's not bad for the project if keith is talking to george . so my suggestion is we just forge ahead , .
B: are you in charge ?
E: had informal talks with most of you . so , eva just reported she 's really happy about the cbt 's being in the same order in the xml as in the be java declaration format so you don't have to do too much in the style sheet transversion . the , java the embedded bayes wants to take input , bayes - net in some java notation and eva is using the xalan style sheet processor to convert the xml that 's output by the java bayes for the into the , , bayes input .
F: actually , maybe could try , like , emailing the guy and see if he has any something already . that 'd be weird , that he has both the java bayes and the embedded bayes in
D: but that 's some conversion program ?
F: and put them into different formats .
D: you should demand things from him .
F: he could do that , too .
C: he charges so much . right . no , it 's good idea that you may as ask . .
E: and , , pretty mu on on the top of my list , would have asked keith how the "" where is ? "" hand parse is standing . but we 'll skip that . there 's good news from johno . the generation templates are done .
D: so the trees for the xml trees for the for the gene for the synthesizer are written . so need to do the , write new set of tree combining rules . but those 'll be pretty similar to the old ones .
C: you were gonna send me note about hiring didn't finish the sentence but he understood it .
D: he 's talking about .
C: but nancy doesn't .
E: so natural language generation produces not just surface string that is fed into text - to - speech but , surface string with syntax tree that 's fed into concept - to - speech . now and this concept - to - speech module has certain rules on how if you get the following syntactic structure , how to map this onto prosodic rules . and fey has foolheartedly to rewrite , the german concept syntax - to - prosody rules
B: didn't know she spoke german .
E: no , she doesn't . but she speaks english .
B: rewrite the german ones into english .
E: and therefore the , if it 's that we give her couple of more hours per week , then she 'll do that .
D: what language is that written is that scheme thing that you showed me ?
E: that 's the lisp - type scheme .
D: she knows how to program in scheme ?
E: my is asked for commented version of that file ? if we get that , then it 's doable , even without getting into it , even though the scheme li , is really documented in the festival .
D: if you 're not used to functional programming , scheme can be completely incomprehensible . cuz , there 's no like there 's lots of unnamed functions
C: anyway , it we 'll sort this out . but anyway , send me the note and then 'll - 'll check with , , morgan on the money . don't anticipate any problem but we have to ask . so this was {nonvocalsound} , on the generation thing , if sh she 's really going to do that , then we should be able to get prosody as . so it 'll say it 's nonsense with perfect intonation .
D: are we gonna can we change the voice of the of the thing , because right now the voice sounds like murderer .
E: we ha we have to change the voice .
B: wh - which one ?
D: the the little smarticus smarticus sounds like murderer .
A: that 's good to know .
D: "" have your reservations . ""
A: but will not give them to you unless you come into my lair .
E: it is , we have the choice between the , , usual festival voices , which already told the smartkom people we aren't gonna use because they 're really bad .
C: it 's the name of some program ,
B: . got it . .
A: the usual party voices .
B: that doesn't sound , exactly right either .
E: ogi has , , crafted couple of diphone type voices that are really and we 're going to use that . we can still , , agree on gender , if we want . so we still have male or female .
B: let 's just pick whatever sounds best . whatever sounds best . unfortunately , probably male voices , bit more research on .
D: does ogi stand for ? original german institute ?
C: oregon @ @ graduate institute it turns out there 's the long - standing links with these guys in the speech group . there 's this guy who 's got joint appointment , he 's - spends fair amount of time here . won't be problem .
E: and it 's probably also uninteresting for all of you to , learn that as of twenty minutes ago , david and , per accident , managed to get the whole smartkom system running on the , icsi linux machines with the icsi nt machines thereby increasing the number of running smartkom systems in this house from one on my laptop to three .
B: mmm , that 's good .
D: how was this by accident ?
B: tha - that 's the part didn't understand .
E: suggested to try something that was really even though against better knowledge shouldn't have worked , but it worked .
B: will it work again ,
E: maybe maybe bit for the ai intuition thing . and , , we 'll never found out why . it - it 's just like why the generation ma the presentation manager is now working ?
A: this is something you ha you get used to as programmer , right ? and it 's , it works out that way .
E: so , the people at saarbruecken and decided not to touch it ever again . that would work . was gonna ask you where something is and what we know about that .
B: where the "" where is "" construction is .
A: what what thing is this ?
E: but by , we can ask , , did you get to read all four hundred words ?
D: wa was looking at it . it doesn't follow logically . it doesn't the first paragraph doesn't seem to have any link to the second paragraph .
A: and so on .
D: each paragraph is good , though .
C: , it 's fine .
A: it was written by committee .
C: but the meeting looks like it 's , it 's gonna be good .
B: didn't know about it until robert told me , like ,
C: ra ran across it in don't even know where , some just some weird place . and , , , 'm surprised didn't know about it
B: , . was like , why didn't dan tell me ?
C: since we know all the invited speakers , right , or some so but anyway , so did see that . wha . before we get started on this st so also had email correspondence with daphne kohler , who said yes she would love to work with us on the , , , using these structured belief - nets and but starting in august , that she 's also got new student working on this and that we should get in touch with them again in august and then we 'll figure out way for you you to get connected with , their group . that 's , looks pretty good . 'll say it now . and it looks to me like we 're now at good point to do something start working on something really hard . we 've been so far working on things that are easy . which is mental spaces and and - or
B: it 's hard . it 's hard .
C: it 's hard puzzle . but the other part of it is the way they connect to these , , probabilistic relational models . so there 's all the problems that the linguists know about , about mental spaces , and the cognitive linguists know about , but then there 's this problem of the belief - net people have only done moderately good job of dealing with temporal belief - nets . which they call dynamic they incorrectly call dynamic belief - nets . so there 's term "" dynamic belief - net "" , doesn't mean that . it means time slices . and srini used those and people use them . one of the things would like to do over the next , , month , it may take more , is to st understand to what extent we can not only figure out the constructions for them for multiple worlds what the formalism will look like and where the slots and fillers will be , but also what that would translate into in terms of belief - net and the inferences . so the story is that if you have these probabilistic relational models , they 're set up , in principle , so that you can make new instances and instances connect to each other , and all that , so it should be feasible to set them up in such way that if you 've got the past tense and the present tense and each of those is separate , belief structure that they do their inferences with just the couplings that are appropriate . but that 's that 's , as far as tell , it 's it 's putting together two real hard problems . one is the linguistic part of what are the couplings and when you have certain , , construction , that implies certain couplings and other couplings , between let 's say between the past and the present , or any other one of these things and then we have this inference problem of exactly technically how does the belief - net work if it 's got , let 's say one in , , different tenses or my beliefs and your beliefs , or any of these other ones of multiple models . in the long run we need to solve both of those and my suggestion is that we start digging into them both , , in way we that , , th hopefully turns out to be consistent , and sometimes it 's actually easier to solve two hard problems than one because they constrain each other . if you 've got huge ra huge range of possible choices we 'll see . but anyway , so that 's ,
A: like , solved the problem of we were talking about how do you various issues of how come plural noun gets to quote "" count as noun phrase "" , occur as an argument of higher construction , but bare singular stem doesn't get to act that way . and it would take really long time to explain it now , but 'm about to write it up this evening . solved that at the same time as "" how do we keep adjectives from floating to the left of determiners and how do we keep all of that from floating outside the noun phrase "" to get something like "" the kicked dog "" . did it did it at once .
C: that 's great .
A: so maybe it 'll be similar thing .
C: no , know , th that is gonna be the key to this wh to th the big project of the summer of getting the constructions right is that people do manage to do this so there probably are some , , relatively clean rules , they 're just not context - free trees . and if we if the formalism is good , then we should be able to have , , moderate scale thing . and that is , keith , what encouraged george to be talking with you about . not the formalism yet but the phenomena . there was this , thing that nancy to in in weak moment this morning that
B: was really strong .
C: . in in friendly moment . anyway , , that we were that we 're gonna try to get , first cut at the revised formalism by the end of next week . probably skipping the mental spaces part .
A: right . do .
C: just trying to write up essentially what you guys have worked out so that everybody has something to look at . we 've talked about it , but only the innermost inner group currently , ,
B: and not even all of them really do .
A: there 's the group as whole knows but no individual member kno
C: that th there 's one of the advantages of document , right ? , is that it actually transfers from head to head . communication , documentation and . anyway , so , , with little luck let 's , let 's have that as goal anyway .
A: so , , what was the date there ? it 's friday .
C: no , no . no , we 're talking about week fr end of next week .
A: end of next week .
B: but , , but the two of us will probably talk to you at before th
A: you said beginning of
B: anyway , let 's talk separately about how
A: but after that , gung - ho .
C: , so someti sometime next week . now if it turns out that effort leads us into some big hole that 's fine . if you say we 're we 're dump dump . there 's really hard problem we haven't solved yet that , that 's just fine .
A: but at least try and work out what the state of the art is right now .
C: right , if to the extent that we have it , let 's write it and to the extent we don't , let 's find out what we need to do .
E: can we ? is it worth thinking of an example out of our tourism thing domain , that involves decent mental space shift or setting up
C: but but interrupted before keith got to tell us what happened with "" where is the powder - tower ? "" or whatever
A: , what was supposed to happen ? 've been actually caught up in some other ones , so , , , don't have write - up of or haven't elaborated on the ideas that we were already talking about
E: . we already came to the conclusion that we have two alternative paths that we two alternative ways of representing it .
A: it 's gone . the question of whether the polysemy is like in the construction or pragmatic .
B: one of them was th
E: is resolved later .
A: it has to be the second case . so ' you is it clear what we 're talking about here ? the question is whether the construction is semantic or like ambiguous between asking for location and asking for path .
B: so you might be , and asking for directions .
A: or whether the construction semantically , , is clearly only asking for location but pragmatically that 's construed as meaning "" tell me how to get there "" .
E: so assume these are two , , nodes we can observe in the bayes - net . so these are either true or false and it 's also just true or false . if we encounter phrase such as "" where is ? "" , should that set this to true and this to true , and the bayes - net figures out which under the situation in general is more likely ? or should it just activate this , have this be false , and the bayes - net figures out whether this actually now means ?
C: so that 's that 's separate issue . so th agree with you that , , it 's disaster to try to make separate constructions for every , pragmatic reading , although there are some that will need to be there . there 's some that
B: or have every construction list all the possible pragmatic implications of the same one .
C: you can't do that either . but , , almost certainly "" can you pass the salt "" is construction worth noting that there is this th this
A: so right , this one is maybe in the gray area . is it is it like that or is it just obvious from world knowledge that no one you wouldn't want to know the location without wanting to know how to get there or whatever .
E: or in some cases , it 's it 's quite definitely so that you just know wanna know where it is .
A: the question is , is this conventional or conversational implicature ?
B: might be , .
C: and , see , the more important thing at this stage is that we should be able to know how we would handle it in ei in the short run it 's more important to know how we would treat technically what we would do if we decided and what we would do if we decided , than it is to decide or right now .
A: which of that is . ,
B: which one it is . cuz there will be other examples that are one way or the other . right .
C: we know for that we have to be able to do both . so in the short run , let 's let 's be real clear on what the two alternatives would be .
E: and then the we had another idea floating around , which we wanted to , , get your input on , and that concerns the but we would have person that would like to work on it , and that 's ir - irina gurevich from eml who is going to be visiting us , , the week before , , august and little bit into august . and she would like to apply the ontology that is , being crafted at eml . that 's not the one sent you . the one sent you was from gmd , out of european crumpet .
C: it was terrible .
E: and one of the reas one of the those ideas was , back to the old johno observation that if if you have dialogue history and it said the word "" admission fee "" was , mentioned , it 's more likely that the person actually wants to enter than just take picture of it from the outside . now what could imagine to , , have list for each construction of things that one should look up in the discourse history , ? that 's the really stupid way . then there is the really clever way that was suggested by keith and then there is the , , middle way that 'm suggesting and that is you get , which is whatever , the ontology will tell us that castles have opening hours , that they have admission fees , they have whatever . and then , this is we go via thesaurus and look up certain linguistic surface structures that are related to these concepts and feed those through the dialogue history for each entity . we look it up check whether any of these were mentioned and then activate the corresponding nodes on the discourse side . but keith suggested that much cleaner way would be is , , to keep track of the discourse in such way that you if that something like that ha has been mentioned before , this just continues to add up ,
A: so if someone mentions admission fees , that activates an enter schema which sticks around for little while in your rep in the representation of what 's being talked about . and then when someone asks "" where is ? "" you 've already got the enter schema activated and you 're able to conclude on it .
C: so that 's certainly more realistic .
D: , is it doesn't it seem like if you just managed the dialogue history with thread , that , kept track of ho of the activity of cuz it would the thread would nodes like , needed to be activated , so it could just keep track of how long it 's been since something 's been mentioned , and automatically load it in .
C: you could do that . but here 's here 's way in th in the bl bayes - net you could you could think about it this way , that if at the time "" admissions fee "" was mentioned you could increase the probability that someone wanted to enter .
B: turn prior on .
D: we - th that 's what wa wasn't was wasn't thinking in terms of enter schemas .
C: fair enough , , but , in terms of the the current implementation
B: it would already be higher in the context .
C: th that th the the conditional probability that someone so at the time you mentioned it this is this is essentially the bayes - net equivalent of the spreading activation . it 's in some ways it 's not as good but it 's the implementation we got . we don't have connectionist implementation . now my is that it 's not question of time but it is question of whether another intervening object has been mentioned . we could look at dialo the other thing we ha we do is , is we have this data coming which probably will blow all our theories , so but my is what 'll probably will happen , here 's here 's proposed design . is that there 're certain constructions which , , for our purposes do change the probabilities of eva decisions and various other kinds th that the , , standard way that the these contexts work is stack - like or whatever , but that 's the most recent thing . and so it could be that when another , en tourist entity gets mentioned , you re essentially re - initiali , re - essentially re - initialize the state . and if we had fancier one with multiple worlds you could have , you could keep track of what someone was saying about this and that . "" wanna go in the morning
A: "" here 's my plan for today . here 's my plan for tomorrow . ""
C: or , in the morning 'm planning to go shopping , in the afternoon to the powder - tower tal so 'm talking about shopping and then you say , , , , "" what 's it cost ? "" . so one could imagine , but not yet . but do th think that the it 'll turn out that it 's gonna be depend on whether there 's been an override .
E: , if you ask "" how much does train ride and cinema around the vineyards cost ? "" and then somebody tells you it 's sixty dollars and then you say "" how much is , would like to visit the "" whatever , something completely different , "" then go to , , point reyes "" , it 's not more likely that you want to enter anything , but it 's , , complete rejection of entering by doing that .
B: so when you admit have admission fee and it changes something , it 's only for that particular it 's relational , right ? it 's only for that particular object .
C: and and the simple idea is that it 's on it 's only for for the current , tourist entity of instre interest .
E: so , has the current object been mentioned in with question about concerning its
C: no , no . it 's it it goes the other it goes in the other direction . when th when the this is mentioned , the probability of , let 's say , entering changes
B: of that object .
D: you could just hav , just , ob it it observes an er , it sets the node for "" entered "" or "" true "" ,
C: now , but ro - robert 's right , that to determine that , ? you may want to go through th thesaurus
D: "" discourse enter "" .
C: so , if the issue is , if so now th this construction has been matched and you say "" . does this actually have any implications for our decisions ? "" then there 's another piece of code that presumably does that computation .
B: so , forward chaining in way , rather than backward .
C: but but what 's robert 's saying is , and he 's right , is you don't want to try to build into the construction itself all the synonyms and all , all the wo 'll have to think about that . it th th of arguments in either direction on that . but somehow you want to do it .
E: it 's just another , , construction side is how to get at the possible inferences we can draw from the discourse history or changing of the probabilities , and - or
B: it 's like the other thing is , whether you have user model that has , , whatever , current plan , whatever , plans that had been discussed ,
D: what , what 's the argument for putting it in the construction ? is it just that the synonym selection is better , or ?
C: wel , the ar the the argument is that you 're gonna have the if you 've recognized the word , you 've recognized the word , which means you have lexical construction for it , so you could just as tag the lexical construction with the fact that it 's , , thirty percent increase in probability of entering . you so you could you could invert the whole thing , so you you tag that information on to the lexicon since you had to recognize it anyway . that that 's the argument in the other direction .
E: even though the lexical construction itself out of context , , won't do it . you have to keep track whether the person says "" but but 'm not interested in the opening times "" is more type .
C: there 's , ther there 's that as .
E: but , we 'll we have time to this is just sidetrack , it 's also something that people have not done before , is , abuse an ontology for these kinds of , , inferences , on whether anything relevant to the current something has been , has crept up in the dialogue history already , or not . have the , if we wanted to have that function in the dialogue hi dialogue module of smartkom , have the written consent of jan to put it in there .
C: , this is highly relevant to someone 's thesis .
E: that 's , 'm 'm keeping on good terms with jan .
C: you 've noticed that . so , it 's very likely that robert 's thesis is going to be along these lines , and the local rules are if it 's your thesis , you get to decide how it 's done . so if , if this is , if this becomes part of your thesis , you can say , hey we 're gonna do it this way , that 's the way it 's done .
B: yay , it 's not me . it 's always me when it 's someone 's thesis .
C: no , no ! no , no . we 've got lot we 've got lot of theses going .
A: there 's few of us around now .
B: now it 's not . yay !
E: let 's let 's talk after friday the twenty - ninth . then we 'll see how
C: right . so he 's got th he 's got meet meeting in germany with his thesis advisor .
B: he said he 's gonna finish his thesis by then .
E: should try to finish it by then . .
C: so , that 's the other thing . this is this is , speaking of hard problems , this is very good time , to start trying to make explicit where construal comes in and , where where the construction per - se ends and where construal comes in ,
B: we 've we 've done quite bit of that .
C: cuz this is clearly part of th
B: we 've been doing quite bit of that .
C: said . but that 's part of what the
B: we have many jobs for you , ro - robert .
C: , he 's gonna need this .
A: it seems to always land in your category . you 're lucky .
C: right . so . right . so thing that 's part of why we want the formalism , is because th it is gonna have implicit in it
E: was ? in the room ?
B: no , you weren't there on purpose .
A: made it much easier to make these decisions .
C: right . that 's tentative .
A: right , right .
C: they aren't decisions , they 're ju they 're just proposals .
A: yes . excuse me .
B: no , they 're decisions .
C: that that 's the point , is th
E: let 's call them constraints , around which one has to
B: there 's problem with that word , too , though .
C: anyway . but so that 's
D: but it he the decisions made wer had to do with my thesis . so consequently don't get to decide then that it 's robert 's job ?
B: 'll just pick piece of the problem and then just push the hard into the center and say it 's robert 's .
E: 've always been completely in favor of consensus decisions , so we 'll we 'll find way .
C: we we will ,
E: it it might even be interesting then to say that should be forced to , pull some of the ideas that have been floating in my head out of the , out of the top hat that metaphor is not going anywhere , .
C: ri - no . . so , , wh you had you ha you had done one draft .
E: yes , and , , it 's ha - none of that is still around ,
A: that 's normal .
B: it 's good didn't read it .
C: this is 'm shocked . this is the first time 've seen thesis proposal change . right . anyway , . so . but , , second that would be great . so , , sec you 're gonna need it anyway .
E: and would like to discuss it and , , get you guys 's input and make it bomb - proof . bullet - proof . that 's the word was looking for .
B: good luck . really .
C: so that , so th thi this , so this is the point , is we 're going to have to cycle through this , but th the draft of the proposal on the constructions is going to tell us lot about what we think needs to be done by construal . and , , we oughta be doing it .
E: we need we need some then we need to make some dates . meeting regular meeting time for the summer , we really haven't found one . we did thursdays one for while . talked to ami . it 's - it 's coincidence that he can't do couldn't do it today here .
B: usually , he can .
E: usually he has no real constraints .
C: and the ntl meeting moved to wednesday ,
E: it was just an exception .
C: you weren't here , but , and so , if that 's with you ,
A: it 's is it staying at the wednesday noon ? it was th off this week ,
B: always thought it was staying . it was just this week that we were changing it .
E: and , . how do we feel about doing it wednesdays ? because it seems to me that this is time where when we have things to discuss with other people , there they seem to be tons of people around .
C: the only disadvantage is that it may interfere with other no , you , people in this group connecting with
B: those people who happen to be around .
C: those people who might not be around so much .
A: to tell you the truth , 'd rath 'd , 'd would like to avoid more than one icsi meeting per day , if possible .
C: no , that 's fine .
E: the 'd like to have them all in one day , so package them up and then
C: people differ in their tastes in this matter .
B: 'm always here anyway ,
E: it 's , that
B: it doesn't matter .
C: @ @ that 's me too . 'm 'm here .
E: if one thing is , this room is taken at after three - thirty pr every day by the data collection . so we have subjects anyway except for this week , we have subjects in here . that 's why it was one . so we just knew
B: so did you just say that am't make one '
E: no , he can . so let 's say thursday one . but for next week , this is bit late . so would suggest that we need to talk about the the th
B: could we do thursday at one - thirty ? would that be horrible ?
E: because , , this room is again taken at two - thirty by morgan .
B: . you didn't tell me that . that 's fine .
E: and the meeting recorder meeting recording on meeting meetings
C: so you 're proposing that we meet tuesday .
E: how about that ?
B: we 're meeting tuesday . we usually meet tuesday or like , linguists , at two .
A: that 's right .
B: do you want to meet again here bef
D: is the speech - gen meeting still at on tuesdays ?
E: actually we we did scrap our monday time just because bhaskara couldn't come monday .
B: hhh . maybe do need palm pilot .
E: so there 's nothing 's impeding monday anymore either .
A: that doesn't apply to
D: although you wanted to go camping on monday er , take off mondays lot so you could go camping .
E: that 's another thing . . but , . , there are also usually then holidays anyways . like sometimes it works out that way .
B: , the linguists ' meeting happens to be at two , but that 's .
A: that should be relatively flexible be
B: pretty flexible , .
A: there 's just the two to four of us . and , , nancy and are just always talking anyway and sometimes we do it in that room . so , , .
E: so forget about the the camping thing . so let 's , any other problems ? but , suggested monday . if that 's problem for me then shouldn't suggest it .
D: ha - ha .
A: all of the proposed times sound fine with me .
C: whate what robert 's saying is that
A: earlier in the week
C: at least for next week , there 's lot of we want to get done , so why don't we plan to meet monday and we 'll see if we want to meet any more than that .
B: at one , two , three ?
E: one , two , three ? three 's too late .
C: , actually two is the earliest meet on monday .
E: two - thirty ?
C: here 'm blissfully agreeing to things and realizing that actually do have some scheduled on monday .
A: so that 's the eighteenth .
B: you guys will still remind me , right ? you 'll come and take all the headph the good headphones first and then remind me .
E: why do you ?
B: why do have this unless 'm gonna write ?
E: do get to see th , your formalism before that ?
B: would you like to ? was actually gonna work on it for tomorrow like this weekend .
E: wo would like would get notion of what you guys have in store for me .
C: @ @ , maybe mond - maybe we can put this is part of what we can do monday , if we want .
B: so there was like , , in my head the goal to have like an intermediate version , like , everything know . and then , would talk to you and figure out everything , that , see if they 're consistent .
A: why don't maybe you and should meet more or less first thing monday morning and then we can work on this .
B: that 's fine with me . you said you 're busy over th until the weekend , right ?
A: because kate has photography show .
B: that 's fine . so we might continue our email thing and that might be fine , too . so , maybe 'll send you some
A: if you have time after this 'll show you the noun phrase thing .
B: that would be . and we 'll you wanna
E: so the idea is on monday at two we 'll we 'll see an intermediate version of the formalism for the constructions ,
B: so that 's for you
E: and do an on - line merging with my construal ideas . so it won't be , like , for semi - formal presentation of my proposal . it 'll be more like towards finalizing that proposal .
B: cuz then you 'll find out more of what we 're making you do .
E: that 's fine .
A: oy , deadlines .
B: we 'll make presentation of your propo of your proposal .
E: perfect . can you also write it up ?
B: it 's like , "" this is what we 're doing . and the complement is robert . ""
E: 'll 'll send you 'll 'll send you style file , right ?
B: already sent you my fi my bib file .
A: someday we also have to we should probably talk about the other side of the "" where is "" construction , which is the issue of , , how do you simulate questions ? what does the simspec look like for question ? because it 's little different . we had to we had an idea for this which seemed like it would probably work .
C: simspec may need we may need to re - name that . ? so let 's think of name for whatever the this intermediate structure is . we talked about semspec , for "" semantic spec specification ""
A: it 's more general
C: so it 's minimal change .
B: only have to change one vowel . that 's great . all the old like graphs , just change the just , like , mark out the
C: right , little substi that 's what text substitution macros are for .
A: it 's good for you .
C: anyway , , so let 's let 's for the moment call it that until we think of something better . and , , we need to find part of what was missing were markings of all sorts that weren't in there , incl including the questions we didn't we never did figure out how we were gonna do emphasis in , the semspec .
B: we 've talked little bit about that , too , it 's hard for me to figure out with our general linguistic issues , how they map onto this particular one ,
C: but that 's part of the formalism is got to be , how things like that get marked .
B: do you have data , like the you have preliminary data ? cuz know , , we 've been using this one easy sentence and 'm you guys have , maybe you are the one who 've been looking at the rest of it it 'd it 'd be useful for me , if we want to have it little bit more data oriented .
A: to tell you the truth , what 've been looking at has not been the data so far , said "" alright let 's see if get noun phrases and , , major verb co , constructions out of the way first . "" and have not gotten them out of the way yet . so , have not really approached lot of the data , but like these the question one , since we have this idea about the indefinite pronoun thing and all that , , ca can try and , run with that , try and do some of the sentence constructions now . it would make sense .
E: do you wanna run the indefinite pronoun idea past jerry ?
A: the basic idea is that let 's see if formulate this .
E: so mary fixed the car with wrench . so you perform the mental sum and then , , "" who fixed the car with wrench ? "" you are told , to do this in the in analogously to the way you would do "" someone fixed the car with wrench "" . and then you hand it back to your hippocampus and find out what that , , and then come up with that so who that someone was .
A: the wh question has this as extra thing which says "" and when you 're done , tell me who fills that slot "" or . and , , this is way to do it , the idea of saying that you treat from the simulation point of view or whatever you treat , , wh constructions similarly to , indefinite pronouns like "" someone fixed the car "" because lots of languages , , have wh questions with an indefinite pronoun in situ or whatever ,
B: use actually the same one .
A: and you just get intonation to tell you that it 's question . so it makes sense
C: alright , which is in in logic , it 's it 's @ @ it 's actual ?
B: right . let 's put skolem constant in ,
C: that - that 's not that 's not saying it 's bad ,
A: right . no . .
C: it 's just that that the logicians have ,
A: that 's right . it makes sense from that point of view , too , which is actually better .
E: come up with this
A: anyway , but just that thing and we 'll figure out exactly how to write that up and so on , no , all the focus . we just dropped that cuz it was too weird and we didn't even know , like , what we were talking about exactly , what the object of study was .
C: , if , part of what the exercise is , by the end of next week , is to say what are the things that we just don't have answers for yet . that 's fine .
E: if you if you do wanna discuss focus background and then get me into that because , wo scientifically worked on that for almost two years .
A: then certainly we will .
B: you should definitely , be on that maybe by after monday we 'll you can see what things we are and aren't
A: we should figure out what our questions are , , to ask you .
C: wel - then hans . has haven't seen hans boas ?
B: he 's been around . just maybe not today .
C: so has he been involved with this ,
B: would say that tha that those discussions have been primarily , , keith and keith and me , like in th the meeting , he thin like the last meeting we had , we were all very much part of it
A: sometimes hans has been coming in there as like devil 's advocate type role , like "" this make , 'm going to pretend 'm linguist who has nothing to do with this . this makes no sense . "" and he 'll just go off on parts of it which definitely need fixing but aren't where we 're at right now ,
B: like like what you call certain things , which we decided long ago we don't care that much right now . but in sense , it 's good to know that he of all people like maybe lot of people would have much stronger reactions , so , , he 's like relatively friendly linguist and yet word like "" constraint "" causes lot of problems . and , so . right . so .
C: this is consistent with the role had suggested that he play , which was that one of the things would like to see happen is paper that was tentatively called "" towards formal cognitive semantics "" which was addressed to these linguists who haven't been following this . so it could be that he 's actually , at some level , thinking about how am going to communicate this story so , internally , we should just do whatever works , cuz it 's hard enough . but if he if he turns is really gonna turn around and help to write this version that does connect with as many as possible of the other linguists in the world then it becomes important to use terminology that doesn't make it hard it 's gonna be plenty hard for people to understand it as it is , but you don't want to make it worse .
A: no , right . , tha that role is , , indispensable but that 's not where our heads were at in these meetings . it was little strange .
C: . no , that 's fine . have to catch up with him , and wanted to get feeling for that . .
A: so what his take will be on these meetings exactly , . cuz sometimes he sounds like we 're talking bunch of goobledy - gook from his point of view .
B: it 's good when we 're when we 're into data and looking at the some specific linguistic phenomenon in english or in german , in particular , whatever , that 's great , and ben and hans are , if anything , more , they have more to say than , let 's say , would about some of these things . but when it 's like , , how do we capture these things , , it 's definitely been keith and who have , who have worried more about the
C: that 's good . that 's that should be the core group
B: which is fine .
C: that 's , , very close to the maximum number of people working together that can get something done .
B: we actually have we have been making progress , and its surprising .
C: definitely get that impression . . that 's great .
B: so anyone else would like ruin the balance of
C: but . but th then then we have to come back to the bigger group . great . and then we 're gon we 're gonna because of this other big thing we haven't talked about is actually implementing this ? so that the three of us are gonna connect tomorrow about that .
B: we could talk tomorrow . was just gonna say , though , that , , there was , out of meeting with johno came the suggestion that "" , could it be that the meaning constraints really aren't used for selection ? "" which has been implicit in the parsing strategy we talked about . in which case we we can just say that they 're the effects or the bindings . which , so far , in terms of like putting up all the constraints as , , pushing them into type constraints , the when 've , , propo then proposed it to linguists who haven't yet given me , we haven't yet thought of reason that wouldn't work . right ? as long as we allow our type constraints to be reasonably complex . so anyway , to be to talk about later .
C: it has to in the sense that you 're gonna use them eventu it 's , it 's , , generate and test thing ,
B: - . - .
C: and if you over - generate then you 'll have to do more . if there are some constraints that you hold back and don't use , in your initial matching then you 'll match some things
B: - . - .
C: don't think there 's any way that it could completely fail . it it could be that , you wind up the original bad idea of purely context - free grammars died because there were just vastly too many parses . exponentially num many parses . and so th the concern might be that not that it would fail , but that
B: that it would still generate too many . right ? so by just having semantic even bringing semantics in for matching just in the form of semantic types , right ?
C: it would still genera
B: like "" conceptually these have to be construed as this , and this "" might still give us quite few possibilities that , and and it certainly helps lot . le let 's put it that way .
C: no question . . and it 's it 's perfectly fine place to start . and say , let 's see how far we can go this way .
B: - . - .
D: it definitely makes the problem easier .
C: 'm 'm in favor of that . cuz it 's as , it 's real hard and if if we
B: so . , that 's tuesday . like th that 's the conclusion . .
E: so , you your dance card is completely filled now ?
B: and have nothing to do this weekend but work . no , that 's not really true ,
D: what about what about ddr ?
B: it 's almost true . don't have it this weekend , so , tsk don't have to worry about that .
C: ddr , he asked ?
B: speaking of dance , it 's it 's like game , but it 's for , like , dancing . hard to it 's like karaoke , but for dancing , and they tell you what it 's amazing . it 's so much fun . it 's so good . my friend has home version and he brought it over , and we are so into it . it 's so amazing . it 's one of your hobbies ? it 's great exercise , must say . 't to hear this . definitely . they have , like , places instead of like , instead of karaoke bars now that have , like , ddr , , didn't until started hanging out with this friend , who 's like "" , , bring over the ddr if you want . "" , dance revolution . he actually brought clone called stepping selection , but it 's just as good .
","Minor technical issues,such as format conversions for XML and JavaBayes and the full translation of the SmartKom generation module in English , are currently being resolved.
The voice synthesiser will also be replaced by better technology.
An important research issue to be investigated is how the concept of mental spaces and probabilistic relational models can be integrated into the belief-net.
Mental space interdependencies are based on relatively clean rules , since people seem to manage them easily.
A step towards this goal is the construction formalism being put together.
This module will eventually have to include ways to simulate questions , do emphasis and focus.
The constructions could be built assuming either conventional or conversational implicature.
At this stage both routes need to be examined.
The formalism will also serve as a starting point for the definition of construal mechanisms.
Similarly , issues like time plans and discourse stacks are dependent on how the ontology and discourse history are going to be structured and linked.
One suggestion was to use the spreading activation as a paradigm for activating nodes in the belief-net.
Finally , using type constraints in the construction analysis should work , as long as they are complex enough not to generate too many parses.
It is necessary to ask the JavaBayes programmer whether he already has XML conversion programs.
For the SmartKom generation module , all the syntax-to-prosody rules are going to be re-written for English.
Additionally , OGI can offer a range of synthesiser voices to choose from.
The focus of the next meeting , whose time was rescheduled , will be the discussion of the revised construction formalism.
The presentation will unify the existing ideas and help identify the areas in need of further work , such as how it can deal with time and tense use and how they affect inferences in belief-nets.
The ambiguity in a ""where is X?"" construction can be coded in the formalism as a semantic feature or pushed forward to the belief-net where pragmatic features will disambiguate it: in terms of system design , both options need to be investigated at this stage.
As the translation of the german SmartKom into English moves on , the generation rules may prove difficult to tackle for someone without experience in functional programming , as they are written in LISP.
As far as the construction analysis is concerned , the two problems that will need to be solved are to identify the couplings between constructions in different mental spaces and to define how inferences will work in the belief-net from a technical point of view.
Additionally , in the example ""Where is X?"" construction , the ambiguity ( Location or Path ) could be coded either in the semantics of the construction or as if determined by context.
The former could mean creating a different construction for every slight pragmatic variation.
On the other hand , some of the belief-net probabilities could be instantiated in the lexicon.
Specifying which approach to take when linking the ontology and the discourse history has also proven not to be straightforward.
Finally , it is still undecided where construal comes in , which would help delimit the constructions as well.
Several technical matters are being resolved: a conversion program is being written for data to be translated between XML and the Java Embedded-Bayes notation; the language generation templates are now available for the english version of the SmartKom system; SmartKom now works on three different machines at ICSI.
On the other hand , future collaboration on belief-nets has already been agreed with another research group.
The construction analysis and formalism are also progressing.
Several issues that have been dealt with were mentioned during the meeting: indefinite pronouns and wh-questions , noun-phrase structure , etc.
This analysis is being done with the help of a linguist , who often provides different perspectives to methods and terminology.
"
ami_abstractive_summary,Bed017.txt,"A: no , cuz she already told me it , before she told you .
E: no , she told me long time ago . she told me she told me like two weeks ago .
A: , it doesn't matter what time .
B: how to toggle the display width function
A: maybe she hadn't just started transcribing me yet .
D: what is it ?
E: let me explain something to you . my laugh is better than yours .
A: beg to differ . but you have to say something genuinely funny before you 'll get an example .
D: how to get to the next page . here .
E: you should be at least be self - satisfied enough to laugh at your own jokes .
A: no , it 's different laugh .
E: ! holy mackerel .
D: wasn't even doing anything . .
E: eva 's got laptop , she 's trying to show it off .
D: that was actually robert 's idea . but anyhow .
F: so , here we are . so we haven't had meeting for while , and probably won't have one next week , number of people are gone . so robert , why don't you bring us up to date on where we are with edu ?
B: in in smaller group we had , talked and decided about continuation of the data collection . so fey 's time with us is almost officially over , and she brought us some thirty subjects and , collected the data , and ten dialogues have been transcribed and can be looked at . if you 're interested in that , talk to me . and we found another , cogsci student who 's interested in playing wizard for us . here we 're gonna make it little bit more complicated for the subjects , this round . she 's actually suggested to look , at the psychology department students , because they have to partake in two experiments in order to fulfill some requirements . so they have to be subjected , before they can actually graduate . we want to design it so that they really have to think about having some time , two days , , to plan certain things and figure out which can be done at what time , package the whole thing in in re in few more complicated , structure . that 's for the data collection . as for smartkom , 'm the last smartkom meeting mentioned that we have some problems with the synthesis , which as of this morning should be resolved . and , so , "" should be "" means they aren't yet , but have the info now that need . plus , johno and are meeting tomorrow , so maybe , when tomorrow is over , we 're done . and ha hav we 'll never have to look at it again maybe it 'll take some more time , to be realistic , but at least we 're we 're seeing the end of the tunnel there . that was that . don't think we need to discuss the formalism that 'll be done officially once we 're done . something happened , in on eva 's side with the prm that we 're gonna look at today , we have visitor from bruchsal from the international university . andreas , you 've met everyone except nancy .
A: hi . hi .
B: hi . hi .
A: so when you said "" andreas "" you were talking about stolcke . now know that we aren't ,
B: andy , you actually go by andy ,
C: cuz there is another andreas around , so , to avoid some confusion .
B: that will be reuter ? so my scientific director of the eml is also the dean of the international university , one of his many occupations that just contributes to the fact that he is very occupied . he @ @ might tell us little bit about what he 's actually doing , and why it is somewhat related , and by using maybe some of the same technologies that we are using . and . was that enough of an update ? in what order shall we proceed ? maybe you have your on - line
D: so , 've be just been looking at , , what are you doing ? 've been looking at the prm . so , this is , like the latest thing have on it , sorta constructed couple of classes . like , user class , site class , and , time , route , and then and query class . and tried to simplify it down little bit , so that actually , look at it more . it 's the same paper that gave to jerry last time . so took out lot of , lot of the decision nodes , and then tried to the red lines on the , , graph are the , relations between the different , classes . like , user has like , query , and then , also has , , reference slots to its preferences , the special needs and , , money , and the user interest . this is more or less similar to the flat bayes - net that have , , with the input nodes and all that . so tried to construct the dependency models , lot of these got from the flat bayes - net , and what they depend on , and it turns out , , the cpt 's are really big , if do that , so tried to see how do , put in the computational nodes in between . and what that would look like in prm . and so ended up making several classes actually , , class of with different attributes that are the intermediate nodes , and one of them is like , time affordability money affordability , site availability , and the travel compatibility . and so some of these classes are some of these attributes only depend on from , say , the user , or just from , , like the site . like , , these here , it 's only like , user , but , if you look at travel compatibility for each of these factors , you need to look at pair of , , what the , preference of the user is versus , , what type of an event it is , or , which form of transportation the user has and whether , , the onsite parking matters to the user , in that case . and that makes the scenario little different in prm , because , , then you have one - user objects and potentially you can have many different sites in mind . for each of the site you 'll come up with this rating , of travel compatibility . and , they all depend on the same users , but different sites , 'm tr wa have been trying to see whether the prm would make it more efficient if we do inferencing like that . you end up having fewer number of nodes than in flat bayes - net , cuz otherwise you would it 's probably the same . no , you would definitely have be able to re - use , like , , all the user , and not having to recompute lot of the , because it 's all from the user side . so if you changed sites , you can , , save some work on that . in the case where , it depends on both the user and the site , then 'm still having hard time trying to see how , using the prm will help . so anyhow , using those intermediate nodes then , this would be the class that represent the intermediate nodes . and that would it 's just another class in the model , with , , references to the user and the site and the time . and then , after you group them together this no the dependencies would of the queries would be reduced to this . and so , , it 's easier to specify the cpt and all . so that 's about as far as 've gone on the prm .
F: so you didn't yet tell us what the output is . so what decisions does this make ?
D: so it only makes two decisions , in this model . and one is how desirable site is meaning , , how good it matches the needs of user . and the other is the mode of the visit , whether th it 's the eva decision . so , instead of , doing lot of , , computation about , , which one site it wants of the user wants to visit , 'll come , try to come up with like , list of sites . and for each site , , where how it fits , and rating of how it fits and what to do with it . anything else missed ?
F: so that was pretty quick . she 's ac eva 's got little write - up on it that , probably gives the details to anybody who needs them . the you you didn't look yet to see if there 's anybody has implementation .
D: no , not yet ,
F: so one so one of the questions , , about these ms is we aren't gonna build our own interpreter , so if we can't find one , then we , go off and do something else and until one appears . so one of the things that eva 's gonna do over the next few weeks is see if we can track that down . the people at stanford write papers as if they had one , but , , we 'll see . so anyway . so that 's major open issue . if there is an interpreter , it looks like , what eva 's got should run and we should be able to actually , try to solve , , the problems , to actually take the data , and do it . and we 'll see . actually is cleaner , and the ability to instantiate , , instance of people and sites and , , will help in the expression . whether the inference gets any faster or not . it wouldn't surprise me if it if it doesn't . it 's the same information . there are things that you can express this way which you can't express in normal belief - net , without going to some incredible hacking of rebuilding it on the fly . the notion of instantiating your el elements from the ontology and fits this very nicely and doesn't fit very into the extended belief - net . so that was one of the main reasons for doing it . so , , people who have thought about the problem , like robert it looked to me like if eva were able to come up with , value for each of number of , sites plus its eva thing , that travel planner should be able to take it from there . and , with some other information about how much time the person has and whatever , and then plan route .
B: - , , , first of all , great looks , mu much cleaner , nnn , nnn , certain certain beauty in it , so , , if beauty is truth , then , we 're in good shape . as , , mentioned before we probably should look at the details . so if you have write - up then , 'd love to read it you go all the way back to the very top ? these @ @ these when these are instantiated they take on the same values ? that we had before ?
D: 't really see the whole thing .
B: or are they have they changed , in sense ?
D: leave them to similar things . some of the things might that might be different , maybe like are that the hours for the site . and , eventually that to mean whether they 're open at this hour or not . and status would be , , more or less like , whether they 're under construction , and or like that .
B: and the , , other question would have is that presumably , from the way the stanford people talk about it , you can put the probabilities also on the relations .
D: which is the structural uncertainty ?
F: that was actually in the previous the ubenth . don't remember whether they carried that over to this or not ,
B: it 's in the definition or in the in daphne 's definition of prm is that classes and relations , and you 're gonna have cpt 's over the classes and their relations . more uncertainty , or
D: remember them learning when , , you the structure for , but don't remember reading how you specify
B: that would be exactly my question .
D: wh to start with .
F: so , , the plan is when daphne gets back , we 'll get in touch and supposedly , , we 'll actually get deep connected to their work somebody 'll , if it 's group meeting once week probably someone 'll go down and , whatever . so , we 'll actually figure all this out .
B: then the long term perspective is pretty clear . we get rocking and rolling on this again , once we get package , if , when , and how , then this becomes foregrounded focused , again . until then we 'll come up with something that 's @ @ that 's way more complicated for you . because this was laughingly easy ,
D: actually had to take out lot of the complicated , cuz made it really complicated in the beginning , and jerry was like , "" this is just too much "" .
F: you could , from this , go on and say suppose there 's group of people traveling together and you wanted to plan something that somehow , with some pareto optimal , , thing for
A: that 's good . that 's definitely job for artificial intelligence . except for humans can't really solve it either , so .
B: that 's not even something humans
F: that 's the that would be , you could sell it , as you don't have to fight about this , just give your preferences to the
A: and then you can blame the computer .
B: but what does it would pote potential result be to split up and never talk to each other again ?
A: that should be one of them .
E: that 'd be .
F: so . so there there are some , , , elaborations of this that you could try to put in to this structure , but don't 's worth it now . because we 're gonna see what else what else we 're gonna do . it 's good , and there were couple other ideas of , things for eva to look at in the interim .
B: good . then , we can move on and see what andreas has got out his sleeve . or andy , for that matter ?
C: so , , for having me here , first of all . so maybe just little background on my visit . so , , 'm not really involved in any project , that 's that 's relevant to you , at the moment , the reason is really for me , to have an opportunity to talk to some other researchers in the field . and and so 'll just give you real quick introduction to what 'm working on , and , hope that you have some comments or , maybe you 're interested in it to find out more , and so 'll be , happy to talk to you and , 'd also like to find out some more and maybe 'll just walk around the office and then and ask some questions , , in couple days . so 'll be here for , tomorrow and then , the remainder of , next week . so , , what started looking at , , to begin with is just , content management systems , in general . what 's the state of the art there is to you have bunch of documents or learning units or learning objects , and you store meta - data , associate to them . so there 's some international standards like the - triple - , there 's an - triple - , lon standard , and , these fields are pretty straightforward , you have author information , you have , size information , format information and so on . but they 're two fields that are , more interesting . one is you store keywords associated with the with the document , and one is , you have , , what is the document about ? so it 's some taxonomic , ordering of the of the units . now , if you put on your semantic glasses , you say , that 's not all that easy , because there 's an implicit , , assumption behind that is that , all the users of this system share the same interpretation of the keyword and the same interpretation of , whichever taxonomy is used , that 's that 's very that 's key point of these systems and they always brush over this real quickly without really elaborating much of that and , the only thing that really works out so far are library ordering codes , which are very , very coarse grain , so you have some like , science , biology , and then but that 's really all that we have at the moment . so there 's huge , , need for improvement there . now , what this standard like this would give us is we could , with search engine just query , different repositories all over the world . but we can't really so what 'm what try to do is , to have , so . so the scenario is the following , you 're working on some project and you encounter certain problem . now , what we have at our university quite bit is that , students , try to program certain assignment , , they always run into the same problems , and they always come running to us , and they 'll say why 's it not it 's not working , and we always give out the same answer , so we thought , , it 'd be to have system that could take care of this , and so , what want to build is smart system . now , what you need to do here is you need to provide some context information which is more elaborate than "" 'm looking for this and this keyword . "" and that don't need to tell you this . 'm 'm you have the same when somebody utters sentence in certain , , context it , and the same sentence in another context makes huge difference . so , want to be able to model information like , , so in the in the context of developing distributed systems , of at computer science school , what software is the person using , which homework assignment is he or she working on at the moment , maybe what 's the background of that student 's which error message was encountered . so this information should be transmitted , , when certain document is retrieved . so we somehow need to have formalized , way of writing this down , and that 's where the shared interpretation of certain terms and keywords comes in again . and , using this and some , knowledge about the domain you can do some simple inferences . like that when somebody 's working about , working on servlets , he 's using java , cuz servlets are used are written in java . so some inferences like that , now , , using this you can infer more information , and you could then match this to the meta - data of off the documents you 're you 're searching against . so , what wanna do is have some given these inputs , and then compute how many documents match , and use this as metric in the search . now , what plan to do is want to do try to improve the quality of the search results , and want to do this by having depth , steepest descent approach . so if knew which operating system the person was working on , would this improve my search result ? and and having , symbolic formalized model of this could simply compute that , and find out which which questions are worth , asking . and that 's what then propagate back to the user , and try to optimize the search in this way . now , the big problem that 'm facing right now is , it 's fairly easy to hack up system quickly , that works in the small domain , but the problem is the scalability . and , so robert was mentioning , earlier today is that , microsoft with their printer set up program has bayesian network , which does exactly this , but there you face problem that these are very hard to extend . and so , what 'm what try to do is try to model this , in way that you could really combine , knowledge from very different sources , and , looking into some of the ideas that the semantic web community , came up with . trying to have , an approach how to integrate certain representation of certain concepts and also some computational rules , what you can do with those . what 'm also looking into is probabilistic approach into this because document retrievals is very fuzzy procedure , so it 's probably not that easy to simply have symbolic , computational model . that that probably isn't expressive enough . so . so that 's another thing , which you 're also , looking into right now . and then , as an add - on to this whole idea , , that would be now , depending on what the search engine or the content repository depending on which , , which , rules and which ontologies it uses , or its view of the world , you can get very different results . so it might ma make lot of sense to actually query lot of different search engines . and there you could have an idea where you actually have peer to peer approach , where we 're all carrying around our individual bookshelves , and , if you have question about homework , it 's probably makes sense to ask somebody who 's in your class with you , the guru in the certain area , rather than going to some yahoo - like , search engine . so these are some of the just in nutshell , some of the ideas . and lot of the even though it 's it 's very different domain , but lot of the , , issues are fairly similar .
A: and so some of the how much about the larger heidelberg project ,
C: know , know abou about it .
A: so it seems like lot of some of the issues are the same . it 's like , , , the context - based factors that influence how you interpret ,
C: - . - .
A: how to interpret . in in this case , infer in knowing wanting to kinds of things to ask . we - we 've talked about that , but we haven't worried too much about that end of the discourse . but maybe you guys had that in the previous models .
B: in in one one mmm , small difference in in way , is that he doesn't have to come up with an answer , but he wants to point to the places
A: documents that have the answers .
C: so . so 'm 'm not building an expert want to build smart librarian , that can point you to the right reference . don't wanna compute the answer , so it 's little bit easier for me .
B: , you have to still understand what the content says about itself , and then match it to what you think the informational needs
A: so you also don't have to figure out what the content is . you 're just taking the keywords as topic text ,
C: assume that the there will be learning systems that tag their content . @ @ and what what envision is that you rather than just supplying bunch of keywords you could for an faq you could state like logic condition , when this document applies . so "" this document explains how to set up your , mail account on linux "" like this . so . so something very specific that you can then but the that the key point with these , learning systems is that , learning system is only as good as the amount of content it carries . you can have the best learning system with the best search interface , if there 's no content inside of it , it 's not very useful . so ultimately because , developing these rules and these inference inferences is very costly , so , you must be able to reuse some existing , domain information , or or ontologies that other people wrote and then try to integrate them , and then also search the entire web , rather than just the small , content management system . so that 's that 's crucial for the success of or @ @
A: so , you 're not 'm trying to figure out how it maps to the kinds of things that we 've talked about in this group , and , actually associated groups , cuz some of us do pretty detailed linguistic analyses , and 'm guessing that you won't be doing that ? so , you take the query , and
F: on the other hand , , framenet could be useful . so do the framenet story ?
C: not too much ,
F: th - that 's another thing you might wanna look into while you 're here .
C: have rough overview .
F: because , , , the standard story is that keyworks keywords evoke frames , and the frames may give you additional keywords or , if that that bunch of keywords , indicate frame , then you can find documents that actually have the whole frame , rather th than just , individual
C: mmm . mmm .
F: so there 's lot of , and people are looking at that . most of the work here is just trying to get the frames right . there 's linguists and and there 's lot of it and they 're they 're busily working away . but there are some application efforts trying to exploit it . and this looks it seems to be that this is place where you might be able to do that .
C: 'm could learn lot about , , just how to how to come up with these structures , cuz it 's it 's very easy to whip up something quickly , but it maybe then makes sense to me , but not to anybody else , and if we want to share and integrate things , they must , they must be designed really .
B: remember the , prashant story ? the no linguistic background person that the iu sent over here . and andreas and tried to come up wi or we had come up actually with with him working on an interface for framenet , as it was back then , that would do some of the work for this machine , which , never got done because prashant found happy occupation
F: know , it he he did what he did was much more sensible for him .
B: but so 'm just saying , the , we had that idea
F: the idea was there . , .
B: to exploit framenet there as .
F: actually you guys never
B: and srini 's doing information extraction also , with that framenet base .
F: so you guys never sent anybody else from .
C: except except prashant ?
F: this was supposedly an exchange program , and we , it 's fine . we don't care , but it just 'm little surprised that , andreas didn't come up with anyone else he wanted to send . had forgotten to be honest with you , 'd forgotten we had program .
B: it 's in the program ?
C: it 's it 's really the lack of students , at iu at the moment .
F: no , no . there was whole co there was little contract signed .
C: . it 's ju it 's more the lack of students , really , and we have all these sponsors that are always eager to get some teams . if were student , 'd love to come here , rather than work for some german {nonvocalsound} company , or
B: you are being recorded right now , so beware .
C: didn't say anybody to anything to offend except for the sponsors maybe ,
F: right . so thi tha that 's that 's one of the things that might be worth looking into while you 're here . unfortunately , srini , who is heavily involved in daml and all this is himself out of town .
C: 'll go to the , semantic web workshop , , in two weeks .
F: for some reason he 's not doing that .
A: he had other things to do .
F: why he @ @ , who knows ? anyway , , you 'll see you 'll certainly see lot of the people there .
A: the other person of is dan gildea ? because he did some work on topic spotting
F: st - statistical . that would be very good idea .
A: which is , , you . don't depending on how you wanna integrate with that end , like , taking the data and fig you said the learning systems that figure out we there 's someone in icsi who actually has been working on has worked on that kinda , and he 's worked with frame net , so you could talk to him about , , both of those things at once .
C: - . - .
A: and he just finished writing draft of his thesis . dan gildea , gildea .
C: so , , who is that again ?
A: and , he 's in one of the rooms on the fifth floor and ,
B: take you to his office . it 's just around the corner .
A: if you fal solve the problem , hope you can do one for us too .
F: alright , was there anything else for this ? one of these times soon we 're gonna hear about construal .
B: have it was november two thousand three or some no . wh - had something in my calendar .
E: that 's long way away .
B: maybe bribe my way out of this . so did some double checking and it seems like spring break in two thousand one .
A: talk about changing the topic .
F: no , but he 's he 's as you said , he 's , like the state legislature , he 's trying to offer us bribes .
A: at least this is private meeting . right , exactly , that 's the link .
B: this , they refused the budget again ? is it so about citris ?
F: we 're , , involved in literally three hundred million dollar , program . with the state of california . and , the state of california is now month and half behind its legis its legally required date to approve budget . so the budget has not been approved . and two days ago there 's two , so , two branches of legislature . one branch approved it , yesterdayday there was this that the other branch would just approve it , but now there 's actually little back sliding to people who approved it got flak from there , ! have to tell you wonderful story about this , and then we 'll go . so , it turns out wound up having lunch today with guy named tom kalil . and , , he now works at berkeley . he 's hired to run lot of citris , even though we don't have the money they so they 've been hiring people right and left , so , , they think the money 's coming . so and he was , , the chief staffer to clinton on technology matters . he was in the white house , don't remember what he was saying . anyway , like that . and , is now doing all the politics for citris , but also , has , lot of interest in , actually doing things for society , so digital divide and like that . so that 's interesting to me but maybe not to you . but the really interesting thing was , he st he said something about , 'm interested in things that have high social multiplier , something that is of great social value . he said , "" "" , this was his only example , "" if you had adult literacy program that was as good as an individual tutor , and as compelling as video game , then that would have huge social impact "" . said , "" great ! that 's good problem to work on . "" anyway . so it was that , he 's got this view , of , that 's what you should try to do , and , , language would be good way to do it .
A: mmm . definitely .
F: so anyway , that 's the end of the story .
A: but for adults and not for the children .
F: didn't push him on the ch on the child thing , again , if you if you and this was this was literacy , which actually is somewhat different problem . so this is reading , rather than teaching another project we started on , and didn't get funded for was , , to try to build an automatic tutoring program , for kids whose first language wasn't english . which is like half the school population in california . something like that , enormous problem in california , and the idea was if we 're so smart about language understanding and speech understanding , couldn't we build , programs that would be tutors for the kids . we think we could . anyway . so so but this is slightly different problem , know none of us have the spare time to look at it right now , but it it 's it 's interesting and may , talk to him some more about is somebody already doing this , and like that . so anyway , that was that was today 's little story .
B: so did manage to get pull my head out of the sling by sidetracking into citris ,
F: no , no .
B: but or temporarily putting it out of the sling but , 'll volunteer to put it right back in by stating that am among some other things in the process of writing up that we have been discussing at our daily meetings , and also revising , for all the comments , the the original construal proposal . and , if put one and one together , may end up with number that 's greater than one and that potentially present once you get back .
A: greater than two ?
F: you 're good .
B: nnn . sometimes , the sum is not less than the
F: anyway . , so , so that 'd be great , but 'd it 's it 's time again ,
B: but , and hopefully all sidetracking , other things will have disappeared , soon .
","The first phase of the data collection has finished.
There is a new wizard for phase two , during which subjects will be given more complex scenarios.
Also finished are the modifications on SmartKom: the remaining glitches will take no more than a day to iron out.
A big part of the meeting was covered by the presentation of the PRM of the proposed system.
An alternative representation of the Bayes-net , it depicts context features as classes , and dependencies as relations between them.
The current outputs show the desirability of a site , as well as its EVA mode.
The fact that this model allows for instantiations of classes fits the research purposes much better than the extended belief-net.
Following this , a visiting researcher presented an overview of a parallel project at the International University.
It attempts to build a smart tutoring system for a computer science course.
The assumption is that document searches can give more personalised results , if they take into account contextual parameters ( user , situation ).
Although no detailed linguistic analysis takes place , it was suggested that the use of FrameNet could be a useful approach.
There were also further suggestions for meetings with ICSI researchers.
As the data collection is going into its second phase , more complex scenarios will be used to generate more intricate dialogues.
Subjects can be recruited from within the Psychology department students , since such participation in experiments is compulsory in their syllabus.
As the work on creating a PRM for the system has progressed , it is now necessary to find an implementation that can work as a PRM interpreter.
There are no plans to build one from scratch , but it seems that other research groups at Stanford may already have one.
Moreover , closer collaboration with the local PRM group will be pursued with additional participation in their meetings.
An early version of the PRM of the system presented the same problem as a flat Bayes-net: the CPT's become too large.
Another PRM issue that arose and remained unclear was how the probabilities are specified ( instead of learnt ) on the actual relations between the classes.
Furthermore , the lack of a PRM interpreter is an open issue.
It is not within the remit of the project to build one from scratch , therefore , an existing implementation has to be found.
On the other hand , the discussion about the smart tutoring system being built at the International University showed the importance of finding out  which context parameters are influential in a given domain.
It is easy to hack up a system for a small domain , but making it scalable is much more difficult.
Finally , there was a passing mention of problems encountered with the speech synthesis module of SmartKom.
The first phase of the data collection has been completed.
Thirty subjects were recorded in total.
Of those dialogues , ten have been transcribed.
A new wizard will carry out the second phase.
On top of this , a presentation of a PRM of the proposed system took place.
The PRM comprises a set of classes , such as ""user"" , ""site"" , ""route"" , ""time"" and ""query"" with relations between them.
Another class incorporates a number of attributes ( ""money affordability"" , ""travel compatibility"" etc ) modelling the intermediate nodes of the Bayes-net , as well as references to the other classes in the model.
This model is much cleaner , and it also makes it easier to specify the CPT's.
At this stage , the model makes two decisions ( outputs ): how much a site fits a user's needs and what the user intention is in EVA terms.
"
ami_abstractive_summary,Bmr013.txt,"F: so wanted to discuss digits briefly , but that won't take too long .
C: we have digits , what else we got ?
A: new version of the presegmentation .
C: new version of presegmentation .
B: do we wanna say something about the , an update of the , , transcript ?
G: why don't you summarize the
C: update on transcripts .
G: and that includes some the filtering for the , the asi refs , too .
C: filtering for what ?
G: for the references that we need to go from the fancy transcripts to the {nonvocalsound} brain - dead .
B: it 'll it 'll be it 'll be re - cap of meeting that we had jointly this morning .
G: with don , as .
C: anything else more pressing than those things ? so , why don't we just do those . you said yours was brief , so
F: the , as you can see from the numbers on the digits we 're almost done . the digits goes up to about four thousand . and so , , we probably will be done with the ti - digits in , , another couple weeks . , depending on how many we read each time . so there were bunch that we skipped . someone fills out the form and then they 're not at the meeting and so it 's blank . but those are almost all filled in as . and so , once we 're it 's done it would be very to train up recognizer and actually start working with this data .
D: so we 'll have corpus that 's the size of ti - digits ?
F: one particular test set of ti - digits .
D: test set , .
F: so , extracted , ther - there was file sitting around which people have used here as test set . it had been randomized and so on and that 's just what used to generate the order . of these particular ones .
C: so , 'm impressed by what we could do , is take the standard training set for ti - digits , train up with whatever , , great features we think we have , , and then test on this test set . and presumably it should do reasonably on that , and then , presumably , we should go to the distant mike , and it should do poorly . and then we should get really smart over the next year or two , and it that should get better .
F: and inc increase it by one or two percent , . but , in order to do that we need to extract out the actual digits . so that the reason it 's not just transcript is that there 're false starts , and misreads , and miscues and things like that . and so have set of scripts and waves where you just select the portion , hit , it tells you what the next one should be , and you just look for that . so it 'll put on the screen , "" the next set is six nine , nine two "" . and you find that , and , hit the key and it records it in file in particular format . and so the question is , should we have the transcribers do that or should we just do it ? some of us . 've been do 've done , eight meetings , something like that , just by hand . just myself , rather . so it will not take long .
C: what do you think ?
B: my feeling is that we discussed this right before coffee and it 's it 's fine idea partly because , , it 's not un unrelated to their present skill set , but it will add , for them , an extra dimension , it might be an interesting break for them . and also it is contributing to the , , composition of the transcript cuz we can incorporate those numbers directly and it 'll be more complete transcript . so 'm it 's fine , that part .
F: there is there is
C: so you 's fine to have the transcribers do it ?
F: there 's one other small bit , which is just entering the information which at which is at the top of this form , onto the computer , to go along with the where the digits are recorded automatically . and so it 's just , , typing in name , times time , date , and so on . which again either they can do , but it is , , firing up an editor , or , again , do . or someone else can do .
B: and , that , , 'm not , that one 'm not so if it 's into the , things that , , wanted to use the hours for , because the , the time that they 'd be spending doing that they wouldn't be able to be putting more words on . but that 's really your choice , it 's your
D: so are these two separate tasks that can happen ? or do they have to happen at the same time before
F: no they don't have this you have to enter the data before , you do the second task , but they don't have to happen at the same time . so it 's it 's just have file whi which has this information on it , and then when you start using my scripts , for extracting the times , it adds the times at the bottom of the file . and so , , , it 's easy to create the files and leave them blank , and so actually we could do it in either order . it 's it 's to have the same person do it just as double - check , to make you 're entering for the right person . but , either way .
C: just by way of , , order of magnitude , , , we 've been working with this aurora , data set . and , , the best score , on the , nicest part of the data , that is , where you 've got training and test set that are the same kinds of noise and , , is about , the best score was something like five percent , , error , per digit . you 're right . so if you were doing ten digit , , recognition , you would really be in trouble . so the the point there , and this is car noise , things , but real situation , "" real "" , the there 's one microphone that 's close , that they have as this thing , close versus distant . but in car , instead of instead of having projector noise it 's it 's car noise . but it wasn't artificially added to get some artificial signal - to - noise ratio . it was just people driving around in car . so , that 's that 's an indication , that was with , many sites competing , and this was the very best score and , so . more typical numbers like
D: although the models weren't , that good , the models are pretty crappy ?
C: you 're right . that we could have done better on the models , but that we got this is the typical number , for all of the , , things in this task , all of the , , languages . and so we 'd probably the models would be better in some than in others . so , . anyway , just an indication once you get into this realm even if you 're looking at connected digits it can be pretty hard .
B: it 's gonna be fun to see how we , compare at this . very exciting . @ @ .
D: how did we do on the ti - digits ?
F: the prosodics are so much different it 's gonna be , strange . the prosodics are not the same as ti - digits , . so 'm 'm not how much of effect that will have .
G: what do you mean , the prosodics ?
F: just what we were talking about with grouping . that with these , the grouping , there 's no grouping , and so it 's just the only discontinuity you have is at the beginning and the end .
G: so what are they doing in aurora , are they reading actual phone numbers ,
F: what they do in aurora .
G: or , digit at time , or ?
C: no , no it 's connected it 's connected , , digits ,
G: so there 's also the not just the prosody but the cross the cross - word modeling is probably quite different .
F: but in ti - digits , they 're reading things like zip codes and phone numbers and things like that ,
D: do we do on ti - digits ?
F: so it 's gonna be different .
C: we were in the .
F: one and half percent , two percent , something like that ?
C: th no we got under percent , but it was but it 's but . the very best system that saw in the literature was point two five percent that somebody had at bell labs , or . , but . but , , pulling out all the stops .
B: @ @ . it strikes me that there are more each of them is more informative because it 's so , random ,
C: but lot of systems get half percent , or three - quarters percent , and we 're we 're in there somewhere .
F: but that it 's really it 's close - talking mikes , no noise , clean signal , just digits , , every everything is good .
G: it 's the beginning of time in speech recognition .
F: yes , exactly . and we 've only recently got it to anywhere near human .
G: it 's like the , single cell , , it 's the beginning of life ,
D: pre - prehistory .
F: and it 's still like an order of magnitude worse than what humans do .
C: when they 're wide awake , . after coffee , you 're right . not after lunch .
F: so , , what 'll do then is 'll go ahead and enter , this data . and then , hand off to jane , and the transcribers to do the actual extraction of the digits .
C: one question have that , we wouldn't know the answer to now but might , do some guessing , but was talking before about doing some model modeling of arti , marking of articulatory , features , with overlap and so on . and , and , , on some subset . one thought might be to do this , on the digits , or some piece of the digits . it 'd be easier , , and . the only thing is 'm little concerned that maybe the phenomena , in the reason for doing it is because the argument is that certainly with conversational speech , the that we 've looked at here before , , just doing the simple mapping , from , , the phone , to the corresponding features that you could look up in book , , isn't right . it isn't actually right . there 's these overlapping processes where some voicing some up and then some , , some nasality is comes in here , and . and you do this gross thing saying "" it 's this phone starting there "" . so , , that 's the reasoning . but , it could be that when we 're reading digits , because it 's it 's for such limited set , that maybe that phenomenon doesn't occur as much . di - an anybody ? do you have any ? anybody have any opinion about that ,
B: and that people might articulate more , and you that might end up with more closer correspondence .
F: that 's agree . that it 's just it 's would , this corpus really be the right one to even try that on ?
G: it 's definitely true that , when people are , reading , even if they 're - reading what , they had said spontaneously , that they have very different patterns . mitch showed that , and some , dissertations have shown that . so the fact that they 're reading , first of all , whether they 're reading in room of , people , or rea , just the fact that they 're reading will make difference . and , depends what you 're interested in .
C: so , may maybe the thing will be do to take some very small subset , not have big , program , but take small set , , subset of the conversational speech and small subset of the digits , and look and just get feeling for it . just take look . really .
B: that could be an interesting design , too , cuz then you 'd have the com the comparison of the , , predictable speech versus the less predictable speech
C: cuz don't think anybody is , at least , , of anybody , , , the answers .
B: and maybe you 'd find that it worked in , in the , case of the pr of the , , non - predictable .
D: hafta think about , the particular acoustic features to mark , too , because , , some things , they wouldn't be able to mark , like , , , , tense lax . some things are really difficult .
F: we can get ohala in to , give us some advice on that .
B: also you were thinking of much more restricted set of features , that
C: but was , like he said , was gonna bring john in and ask john what he thought . but you want you want it be restrictive but you also want it to to have coverage . you should . it should be such that if you , , if you had , all of the features , determined that you that you were ch have chosen , that would tell you , , in the steady - state case , , the phone .
F: even , with vowels that would be pretty hard , to identify actually , , which one it is ?
B: it would seem to me that the points of articulation would be more , that 's about articulatory features , about , points of articulation , which means , , rather than vowels .
D: points of articulation ? what do you mean ?
B: so , is it , , bilabial or dental or is it , , palatal . which which are all like where your tongue comes to rest .
C: place , place .
D: place of ar place of articulation .
B: what whatev whatever said , that 's really meant place .
C: we got our jargon then , .
G: it 's also , there 's , really difference between , the pronunciation models in the dictionary , and , the pronunciations that people produce . and , so , you get , some of that information from steve 's work on the on the labeling and it really , actually think that data should be used more . that maybe , although the meeting context is great , that he has transcriptions that give you the actual phone sequence . and you can go from not from that to the articulatory features , but that would be better starting point for marking , the gestural features , then , data where you don't have that , because , we you wanna know , both about the way that they 're producing certain sound , and what kinds of , what kinds of , phonemic , differences you get between these , transcribed , sequences and the dictionary ones .
C: you might be right that mi might be the way at getting at , what was talking about , but the particular reason why was interested in doing that was because remember , when that happened , and , john ohala was over here and he was looking at the spectrograms of the more difficult ones . he didn't to say , about , what is the sequence of phones there . they came up with some compromise . because that really wasn't what it look like . it didn't look like sequence of phones it look like this blending thing happening here and here .
F: so you have this feature here , and , overlap , .
D: there was no name for that .
G: but it still is there 's there are two steps . one , one is going from dictionary pronunciation of something , like , "" gonna see you tomorrow "" ,
F: and or "" gonta "" .
G: it could be "" going to "" or "" gonna "" or "" gonta "" . "" gonna see you tomorrow "" , , "" guh see you tomorrow "" . and , that it would be to have these , intermediate , or these some these reduced pronunciations that those transcribers had marked or to have people mark those as . because , it 's not , , that easy to go from the , dictionary , word pronuncia the dictionary phone pronunciation , to the gestural one without this intermediate or syllable level , representation .
F: don't think morgan 's suggesting that we do that , though .
C: do you mean , , 'm jus at the moment we 're just talking about what , to provide as tool for people to do research who have different ideas about how to do it . so , you might have someone who just has wor has words with states , and has , comes from articulatory gestures to that . and someone else , might actually want some phonetic intermediate thing . so it would be best to have all of it if we could .
F: but what 'm imagining is score - like notation , where each line is particular feature . so you would say , , it 's voiced through here , and so you have label here , and you have nas nasal here , and , they could be overlapping in all sorts of bizarre ways that don't correspond to the timing on phones .
C: this is the reason why remember when at one of the switchboard , workshops , that when we talked about doing the transcription project , dave talkin said , "" can't be done "" . he was he was , what he meant was that this isn't , , sequence of phones , and when you actually look at switchboard that 's , not what you see , and , . and . it ,
F: and the inter - annotator agreement was not that good , on the harder ones ?
G: it depends how you look at it , and understand what you 're saying about this , transcription exactly , because 've seen , where does the voicing bar start and . all 'm saying is that , it is useful to have that the transcription of what was really said , and which syllables were reduced . if you 're gonna add the features it 's also useful to have some level of representation which is , is reduced it 's pronunciation variant , that currently the dictionaries don't give you because if you add them to the dictionary and you run recognition , you add confusion . so people purposely don't add them . so it 's useful to know which variant was produced , at least at the phone level .
D: so it would be it would be great if we had , either these , labelings on , the same portion of switchboard that steve marked , or , steve 's type markings on this data , with these .
G: that 's all , .
C: no don't disagree with that .
G: and steve 's type is fairly it 's not that slow , exactly what the , timing was , but .
C: don't disagree with it the on the only thing is that , what you actually will end en end up with is something , it 's all compromised , so , the string that you end up with isn't , actually , what happened . but it 's it 's the best compromise that group of people scratching their heads could come up with to describe what happened .
D: and it 's more accurate than , phone labels .
C: but . and it 's more accurate than the than the dictionary or , if you 've got pronunciation lexicon that has three or four , this might be have been the fifth one that you tr that you pruned or whatever ,
D: so it 's like continuum . it 's you 're going all the way down ,
G: that 's what is an and in some places it would fill in , so the kinds of gestural features are not everywhere . so there are some things that you don't have access to either from your ear or the spectrogram , but what phone it was and that 's about all you can all you can say . and then there are other cases where , nasality , voicing
D: it 's just having , multiple levels of , information and marking , on the signal .
F: the other difference is that the features , are not synchronous , they overlap each other in weird ways . so it 's not strictly one - dimensional signal . so that 's sorta qualitatively different .
G: you can add the features in , , but it 'll be underspecified . th - there 'll be no way for you to actually mark what was said completely by features .
F: not with our current system but you could imagine designing system , that the states were features , rather than phones .
G: and if you 're we 've probably have separate , , discussion of , of whether you can do that .
B: that 's , isn't that that was , but that wasn't that kinda the direction ?
C: so , what where this is , , want would like to have something that 's useful to people other than those who are doing the specific research have in mind , so it should be something broader . but , the but where 'm coming from is , , we 're coming off of that larry saul did with , , , john dalan and muzim rahim in which , , they , , have , , multi - band system that is , , trained through combination of gradient learning an and , to , estimate , , the , , value for for particular feature . and this is part of larger , image that john dalan has about how the human brain does it in which he 's imagining that , individual frequency channels are coming up with their own estimate , of these , these kinds of something like this . might not be , , exact features that , jakobson thought of . but some , something like that . some low - level features , which are not , fully , , phone classification . and the th this particular image , of how thi how it 's done , is that , then given all of these estimates at that level , there 's level above it , then which is making , some sound unit classification such as , , phone and , . you could argue what , what sound unit should be , and . but that 's what was imagining doing , and but it 's still open within that whether you would have an intermediate level in which it was actually phones , or not . you wouldn't necessarily have to . but , again , wouldn't wanna , wouldn't want what we produced to be so , know , local in perspective that it was matched , what we were thinking of doing one week , and and , , what you 're saying is right . that , that if we , can we should put in , , another level of , of description there if we 're gonna get into some of this low - level .
D: , if we 're talking about , having the , annotators annotate these kinds of features , it seems like , the the question is , do they do that on , meeting data ? or do they do that on , switchboard ?
F: that 's what was saying ,
B: it seems like you could do both .
F: maybe meeting data isn't the right corpus .
B: was thinking that it would be interesting , to do it with respect to , parts of switchboard anyway , in terms of , partly to see , if you could , generate first guesses at what the articulatory feature would be , based on the phone representation at that lower level . it might be time gain . but also in terms of comparability of , ,
D: cuz the , and then also , if you did it on switchboard , you would have , the full continuum of transcriptions . you 'd have it , from the lowest level , the ac acoustic features , then you 'd have the , , the phonetic level that steve did ,
G: that 's all was thinking about .
B: and you could tell that
G: it is telephone band , so , the bandwidth might be
D: it 'd be complete , set then .
B: and you get the relative gain up ahead .
C: it 's so it 's little different . so we 'll see wha how much we can , , get the people to do , and how much money we 'll have and all this thing ,
D: but it might be good to do what jane was saying , , seed it , with , guesses about what we think the features are , based on , , the phone or steve 's transcriptions . to make it quicker .
C: might be do both .
F: alright , so based on the phone transcripts they would all be synchronous , but then you could imagine , nudging them here and there .
D: scoot the voicing over little , because
C: what 'm 'm little behind in what they 're doing , now , and , , the they 're doing on switchboard now . but that , steve and the gang are doing , something with an automatic system first and then doing some adjustment . as re as recall . so that 's probably the right way to go anyway , is to is to start off with an automatic system with pretty rich pronunciation dictionary that , , , tries , to label it all . and then , people go through and fix it .
B: so in our case you 'd think about us starting with maybe the regular dictionary entry ,
C: regular dictionary , , this is pretty rich dictionary . it 's got , got fair number of pronunciations in it
D: or you could start from the if we were gonna , do the same set , of sentences that steve had , done , we could start with those transcriptions .
G: that 's actually what was thinking , is tha the problem is when you run , , if you run regular dictionary , , even if you have variants , in there , which most people don't , you don't always get , out , the actual pronunciations , so that 's why the human transcriber 's giving you the that pronunciation ,
C: actually maybe they 're using phone recognizers .
G: they that they were
C: is that what they 're doing ?
G: we should catch up on what steve is , that would be good good idea .
C: so that we also don't have , , we 've got good start on it , but we don't have really good , meeting , recorder or recognizer or transcriber or anything yet , so , another way to look at this is to , , do some on switchboard which has all this other , to it . and then , , as we get , further down the road and we can do more things ahead of time , we can , do some of the same things to the meeting data .
B: and 'm and these people might they are , most of them are trained with ipa . they 'd be able to do phonetic - level coding , or articulatory .
D: are they busy for the next couple years , or ?
B: , they , they 're interested in continuing working with us , so , and this would be up their alley , so , we could when the when you meet with , with john ohala and find , what taxonomy you want to apply , then , they 'd be , good to train onto it .
C: anyway , this is , not an urgent thing , just it came up .
D: it 'd be very interesting though , to have that data .
B: so , too .
F: wonder , how would you do forced alignment ? to to , you 'd wanna iterate , somehow . it 's interesting thing to think about . you 'd you 'd want models for spreading .
G: was thinking it might be
D: of the acoustic features ?
G: it might be neat to do some , phonetic , features on these , nonword words . are are these kinds of words that people never the "" ""s and the "" ""s and the "" "" and the these no , 'm serious . there are all these kinds of functional , , elements . what you call them . but not just fill pauses but all kinds of ways of interrupting and . and some of them are , , "" - ""s , and "" ""s , and , "" ! "" "" "" "" "" , "" "" grunts , that might be interesting .
B: he 's got lip lipsmacks .
G: in the meetings .
C: we should move on . new version of , , presegmentation ?
A: , , worked little bit on the on the presegmentation to get another version which does channel - specific , , speech - nonspeech detection . and , what did is used some normalized features which , , look in into the which is normalized energy , , energy normalized by the mean over the channels and by the , minimum over the , other . within each channel . and to , , to , , to normalize also loudness and modified loudness and things and that those special features actually are in my feature vector . and , and , therefore to be able to , , somewhat distinguish between foreground and background speech in the different in each channel . and , , tested it on three or four meetings and it seems to work , , fairly , would say . there are some problems with the lapel mike .
F: that 's great . so understand that 's what you were saying about your problem with , minimum .
A: and had had , , specific problems with .
F: so new use ninetieth quartile , rather than , minimum .
A: then did some some things like that , as there are some problems in , when , in the channel , there they the speaker doesn't doesn't talk much or doesn't talk . then , the , , there are there are some problems with with with normalization , and , then , , there the system doesn't work . so , 'm 'm glad that there is the digit part , where everybody is forced to say something , so , that 's that 's great for my purpose . and , , then the evaluation of the system is little bit hard , as don't have any references .
F: we did the hand the one by hand .
A: that 's the one wh where do the training on so 't do the evaluation on so , can the transcribers perhaps do some , some meetings in terms of speech - nonspeech in the specific channels ?
D: won't you have that from their transcriptions ?
B: , so , now we need
F: no , cuz we need is really tight .
B: might have done what you 're requesting , though did it in the service of different thing . have thirty minutes that 've more tightly transcribed with reference to individual channels .
A: that 's great . for me . , so .
F: hopefully that 's not the same meeting that we did .
B: no , actually it 's different meeting . so , , so the , , we have the , th they transcribe as if it 's one channel with these with the slashes to separate the overlapping parts . and then we run it through then it then 'm gonna edit it and 'm gonna run it through channelize which takes it into dave gelbart 's form format . and then you have , all these things split across according to channel , and then that means that , if person contributed more than once in given , overlap during that time bend that two parts of the utterance end up together , it 's the same channel , and then took his tool , and last night for the first thirty minutes of one of these transcripts , , tightened up the , , boundaries on individual speakers ' channels , cuz his interface allows me to have total flexibility in the time tags across the channels . and , so .
A: so , , that that 's great , but what would be to have some more meetings , not just one meeting to be that , there is system ,
D: so , current this week .
B: might not be what you need .
F: so if we could get couple meetings done with that level of precision that would be good idea .
B: time so the meetings vary in length , what are we talking about in terms of the number of minutes you 'd like to have as your as your training set ?
A: it seems to me that it would be good to have , few minutes from different meetings , but 'm not about how much .
B: now you 're saying different meetings because of different speakers or because of different audio quality or both or ?
A: different different number of speakers , different conditions .
C: we don't have that much variety in meetings yet , we have this meeting and the feature meeting and we have couple others that we have , couple examples of . but but , ,
E: even probably with the gains differently will affect it , you mean
C: poten - potentially .
A: because of the normalization , .
E: cuz you use the normalization ?
G: we can try running we haven't done this yet because , , , andreas an is gonna move over the sri recognizer . ran out of machines at sri , cuz we 're running the evals and don't have machine time there . but , once that 's moved over , , hopefully in couple days , then , we can take , , what jane just told us about as , the presegmented , {nonvocalsound} the segmentations that you did , at level eight or som at some , threshold that jane , tha right , and try doing , forced alignment . , on the word strings .
A: with the recognizer ?
G: and if it 's good , then that will that may give you good boundary . if it 's good , we don't then we 're we 're fine , but , yet whether these , segments that contain lot of pauses around the words , will work or not .
A: would quite like to have some manually transcribed references for the system , as 'm not if it 's really good to compare with some other automatic , found boundaries .
B: no , if we were to start with this and then tweak it manually , would that would be ?
G: they might be . it it really depends on lot of things , but , would have maybe transciber , , look at the result of forced alignment and then adjust those .
A: to adjust them , or ,
G: that might save some time . if they 're horrible it won't help , but they might not be horrible . so but 'll let when we , , have that .
B: how many minutes would you want from we could easily , get section , , like say minute or so , from every meeting that we have so from the newer ones that we 're working on , everyone that we have . should provide this .
A: if it 's not the first minute of the meeting , that 's with me , but , in the first minute , , often there are some strange things going on which aren't really , , for , which aren't re really good . so . what what 'd quite like , perhaps , is , to have , some five minutes of of different meetings ,
B: somewhere not in the very beginning , five minutes , . and , then wanted to ask you just for my inter information , then , would you , be trai cuz don't quite unders so , would you be training then , , the segmenter so that , it could , on the basis of that , segment the rest of the meeting ? so , if give you like five minutes is the idea that this would then be applied to , , to , providing tighter time bands ?
A: could do retraining with that , . that 's but hope that don't need to do it . so , it can be do in an unsupervised way . 'm 'm not , but , for for those three meetings whi which which did , it seems to be , quite , but , there are some as said some problems with the lapel mike , but , perhaps we can do something with cross - correlations to , to get rid of the of those . that 's that 's what that 's my future work . what want to do is to look into cross - correlations for removing those , false overlaps .
G: are the , , wireless , different than the wired , mikes , ? have you noticed any difference ?
A: 'm 'm not , , if there are any wired mikes in those meetings , or , , have to loo have look at them but , 'm there 's no difference between ,
G: so it 's just the lapel versus everything else ?
B: so then , if that 's five minutes per meeting we 've got like twelve minutes , twelve meetings , roughly , that 'm that 've been working with , then
C: of of the meetings that you 're working with , how many of them are different , tha are there any of them that are different than , these two meetings ?
B: wa in terms of the speakers or the conditions or the ? we have different combinations of speakers . just from what 've seen , , there are some where , , you 're present or not present , and , then you have the difference between the networks group and this group
A: know , some of the nsa meetings , .
C: so didn't the group you had if you had so you have the networks meeting ? do you have any of jerry 's meetings in your , pack , er ,
B: you recorded one last week or so . could get that new one in this week get that new one in .
G: we 're gonna be recording them every monday ,
C: cuz he really needs variety , and having as much variety for speaker certainly would be big part of that .
B: then , , if were to include all together samples from twelve meetings that would only take an hour and could get the transcribers to do that what is , that would be an hour sampled , and then they 'd transcribe those that hour , that 's what should do ?
A: that 's that 's .
C: ye - but you 're
B: so they get it into the multi - channel format and then adjust the timebands so it 's precise .
C: so that should be faster than the ten times thing ,
B: did did , , , so , last night did , , last night , did about half an hour in , three hours , which is not , terrific , anyway , it 's an hour and half per
C: that 's probably .
B: 't calculate on my , on my feet .
A: do the transcribers actually start wi with , , transcribing new meetings , or are they ?
B: they 're still working they still have enough to finish that haven't assigned new meeting , but the next , was about to need to assign new meeting and was going to take it from one of the new ones , and could easily give them jerry feldman 's meeting ,
G: so they 're really running out of , data , prett that 's good .
B: that first set .
C: they 're running out of data unless we make the decision that we should go over and start , , transcribing the other set . there the first half .
B: and so was in the process of like editing them but this is wonderful news . we funded the experiment with , also we were thinking maybe applying that to getting the , that 'll be , very useful to getting the overlaps to be more precise all the way through .
C: so this , blends nicely into the update on transcripts .
B: yes , it does . so , , , liz , and don , and met this morning , in the barco room , with the lecture hall ,
G: and this afternoon .
B: and this afternoon , it drifted into the afternoon , , concerning this issue of , , the , there 's the issue of the interplay between the transcript format and the processing that , they need to do for , the sri recognizer . and , , , so , mentioned the process that 'm going through with the data , so , , get the data back from the transcri , , metaphorically , get the data back from the transcriber , and then , check for simple things like spelling errors and things like that . and , , 'm going to be doing more thorough editing , with respect to consistency of the conventions . but they 're they 're generally very good . and , then , run it through , , the channelize program to get it into the multi - channel format , . and the , what we discussed this morning , would summarize as saying that , , these units that result , in particular channel and particular timeband , at that level , , vary in length . and , , {nonvocalsound} their recognizer would prefer that the units not be overly long . but it 's really an empirical question , whether the units we get at this point through , just that process described might be sufficient for them . so , as first pass through , first chance without having to do lot of hand - editing , what we 're gonna do , is , 'll run it through channelize , give them those data after 've done the editing process and be it 's clean . and do that , pretty quickly , with just , that minimal editing , without having to hand - break things . and then we 'll see if the units that we 're getting , , with the at that level , are sufficient . and maybe they don't need to be further broken down . and if they do need to be further broken down then maybe it just be piece - wise , maybe it won't be the whole thing . so , that 's that 's what we were discussing , this morning as far as among also we discussed some adaptational things , so it 's like , hadn't , , incorporated , convention explicitly to handle acronyms , , but if someone says , pzm it would be to have that be directly interpretable from , the transcript what they said , or pi - tcl tcl . it 's and so , , 've 've incorporated also convention , with that but that 's easy to handle at the post editing phase , and 'll mention it to , transcribers for the next phase but that 's . and then , similar conv , convention for numbers . so if they say one - eighty - three versus one eight three . and also 'll be , , encoding , as do my post - editing , the , things that are in curly brackets , which are clarificational material . and to incorporate , , keyword , at the beginning . so , it 's gonna be either gloss or it 's gonna be vocal sound like , laugh or cough , or , . or non - vocal sound like doors door - slam , and that can be easily done with , , just one little additional thing in the , in the general format .
G: we we just needed way to , strip , , all the comments , all the things th the that linguist wants but the recognizer can't do anything with . but to keep things that we mapped to like reject models , or , , , mouth noise , or , cough . and then there 's this interesting issue jane brought up which hadn't thought about before but was , realizing as went through the transcripts , that there are some noises like , the good example was an inbreath , where transcriber working from , the mixed , signal , doesn't know whose breath it is , and they 've been assigning it to someone that may or may not be correct . and what we do is , if it 's breath sound , , sound from the speaker , we map it , to , noise model , like mouth - noise model in the recognizer , and , , it probably doesn't hurt that much once in while to have these , but , if they 're in the wrong channel , that 's , not good idea . and then there 's also , things like door - slams that 's really in no one 's channel , they 're like it 's in the room . and , jane had this , , idea of having , like an extra , couple tiers ,
F: an extra channel .
B: 've been 've been adding that to the ones 've been editing .
G: and we were thinking , that is useful also when there 's uncertainties . so if they hear breath and they who breath it is it 's better to put it in that channel than to put it in the speaker 's channel because maybe it was someone else 's breath , so that 's good you can always clean that up , post - processing . so lot of little details , but we 're , coming to some kinda closure , on that . so the idea is then , , don can take , , jane 's post - processed channelized version , and , with some scripts , , convert that to reference for the recognizer and we can , can run these . so when that 's , ready , as soon as that 's ready , and as soon as the recognizer is here we can get , twelve hours of force - aligned and recognized data . and , , start , working on it , so we 're , coup week or two away would say from , if that process is automatic once we get your post - process , transcript .
B: and that doesn't the amount of editing that it would require is not very much either . 'm just hoping that the units that are provided in that way , {nonvocalsound} will be sufficient cuz would save lot of , , time , dividing things .
G: some of them are quite long . you did one ?
E: saw couple , around twenty seconds , and that was just without looking too hard for it , so , would imagine that there might be some that are longer .
B: would that be single speaker or is that multiple speakers overlapping ?
E: no . no , but if we 're gonna segment it , like if there 's one speaker in there , that says "" "" , right in the middle , it 's gonna have lot of dead time around it ,
G: right . it 's not the it 's not the fact that we can't process twenty second segment , it 's the fact that , there 's twenty seconds in which to place one word in the wrong place
E: so it 's not
G: if someone has very short utterance there , and that 's where , we , might wanna have this individual , , ha have your pre - process input .
B: that 's very important .
A: that perhaps the transcribers could start then from the those mult multi - channel , , speech - nonspeech detections , if they would like to .
G: have to run it .
B: in in doing the hand - marking ? that 's what was thinking , too .
G: so that 's probably what will happen , but we 'll try it this way and see . it 's probably good enough for force - alignment . if it 's not then we 're really then we def definitely but for free recognition 'm it 'll probably not be good enough . we 'll probably get lots of errors because of the cross - talk , and , noises and things .
C: that 's probably our agenda , or starting up there .
B: wanted to ask one thing , the microphones the new microphones , when do we get , ?
F: they said it would take about week .
D: you ordered them already ?
G: so what happens to our old microphones ?
C: they go where old microphones go .
G: do we give them to someone ,
F: the only thing we 're gonna have extra , for now ,
G: we don't have more receivers ,
F: right , we don so the only thing we 'll have extra now is just the lapel . not not the , bodypack , just the lapel .
G: just the lapel itself .
F: and then one of the one of those . since , what decided to do , on morgan 's suggestion , was just get two , new microphones , , and try them out . and then , if we like them we 'll get more . since they 're they 're like two hundred bucks piece , we won't , , at least try them out .
D: so it 's replacement for this headset mike ?
F: and they 're gonna do the wiring for us .
D: what 's the , , style of the headset ?
F: it 's , , it 's by crown , and it 's one of these mount around the ear thingies , and , , when when mentioned that we thought it was uncomfortable he said it was common problem with the sony . and this is how lot of people are getting around it . and checked on the web , and every site went to , raved about this particular mike . it 's comfortable and stays on the head , so we 'll see if it 's any good . but , , it 's promising .
B: you said it was used by aerobics instructors ?
F: , so it was it was advertised for performers
B: that says lot .
C: for the recor for the record adam is not paid employee or consultant of crown . said "" for the record adam is not paid consultant or employee of crown "" .
F: that 's right .
G: however , he may be solicited after these meetings are distributed .
F: we 're using the crown
G: don't worry about finishing your dissertation .
F: the ms are crown ,
C: you bet . you bet .
F: and they work very .
C: so if we go to workshop about all this it 's gonna be meeting about meetings .
F: and then it we have to go to the planning session for that workshop .
C: , what which 'll be the meeting about the meeting .
F: cuz then it would be meeting about the meeting about meetings .
C: just start saying "" four "" .
F: to the fourth .
C: should we do the digits ?
F: go for it . pause between the lines , remember ?
","The Berkeley Meeting Recorder group discussed the collection status for a set of connected digits recordings that are nearly complete and ready to be trained on a recognizer.
Anticipated results were discussed in reference to results obtained for other digits corpora , i.e . Aurora and TI-digits.
The group also considered the prospect of performing fine-grained acoustic-phonetic analyses on a subset of Meeting Recorder digits or Switchboard data.
Pre-segmentation manipulations that allow for the segmentation of channel-specific speech/non-speech portions of the signal and the distinction of foreground versus background speech were discussed.
Finally , speaker fe008 and fe016 reported on new efforts to adapt transcriptions to the needs of the SRI recognizer , including conventions for encoding acronyms , numbers , ambient noise , and unidentified inbreaths.
The group decided to delegate the extraction of digits to the transcriber pool.
A tentative decision was also made to delegate transcribers with the task of labelling a subset of digits or Switchboard data for fine-grained acoustic-phonetic features.
Speaker fe008 will run selected Meeting Recorder data through channelize and determine whether the resulting units are of a sufficient length.
With respect to encoding more fine-grained acoustic information in transcriptions , the question was posed: which features should be marked?
Speaker mn014 reported problems pre-segmenting speech recorded via the lapel microphones.
Normalization of the energy measured across and within channels is problematic when performed for speakers who say little or nothing during meetings.
The evaluation of pre-segmented data is difficult without tightly transcribed time references to the individual channels from which the speech was derived.
The SRI recognizer requires that multi-channel format units not be too large , indicating that some additional pre-processing of unit lengths may be necessary.
A test set of Meeting Recorder digits is nearly complete.
Future work will include training this data on a recognizer , and feeding the recognizer with corresponding far-field microphone data.
It was noted that the results of experiments testing similar digits corpora have yielded high error rates , indicating that similar problems may be expected for the set of Meeting Recoreder digits.
The group discussed the prospect of performing fine-grained acoustic-phonetic analyses on a subset of digits or Switchboard data.
It was suggested that prior to the use of data-driven methods , knowledge-driven approaches should be used to 'seed' the data with sub-phonemic features , either manually , or using a rich pronunciation dictionary.
A new version of the pre-segmentation tool that segments channel-specific speech/non-speech portions of the signal has been developed and tested.
Future pre-segmentation work will include normalizing other features , such as loudness , enabling the distinction of foreground versus background speech.
Speaker mn014 will also look at cross-correlations for removing false overlaps.
New efforts were reported to adapt transcriptions to the needs of the SRI recognizer , including conventions for encoding acronyms , numbers , ambient noise , and unidentified inbreaths.
With the arrival of the SRI recognizer , 12 hours of forced aligned , recognized data can be expected.
"
ami_abstractive_summary,Bro024.txt,"F: and we 're on .
D: might wanna close the door so that , stephane will
F: 'll get it . could you go ahead and turn on , , stephane 's
D: so that 's the virtual stephane over there .
G: do you use pc for recording ?
F: it 's got , , like sixteen channels going into it .
G: the quality is quite good ?
F: so far , it 's been pretty good .
D: the suggestion was to have these guys start to
F: why don't you go ahead , dave ?
C: so , , the this past week 've been main mainly occupied with , , getting some results , from the sri system trained on this short hub - five training set for the mean subtraction method . ran some tests last night . the results are suspicious . it 's , , cuz they 're the baseline results are worse than , , andreas than results andreas got previously . and it could have something to do with ,
F: that 's on digits ?
C: that 's on digits . it it could it could have something to do with , , downsampling . that 's that 's worth looking into . ap apart from that , the main thing have ta have to talk is , , where 'm planning to go over the next week . so 've been working on integrating this mean subtraction approach into the smartkom system . and there 's this question of , , so , , in my tests before with htk found it worked it worked the best with about twelve seconds of data used to estimate the mean , but , we 'll often have less in the smartkom system . so we 'll use as much data as we have at particular time , and we 'll we 'll concatenate utterances together , , to get as much data as we possibly can from the user . but , , there 's question of how to set up the models . so , we could train the models . if we think twelve seconds is ideal we could train the models using twelve seconds to calculate the mean , to mean subtract the training data . or we could , , use some other amount . so like did an experiment where , , was using six seconds in test , but , for tried twelve seconds in train . and tried , , the same in train 'm tried six seconds in train . and six seconds in train was about point three percent better . and , it 's not clear to me yet whether that 's something significant . so wanna do some tests and , , actually make some plots of , for particular amount of data and test what happens if you vary the amount of data in train .
D: guenter , if you followed this but this is , , , long - term long - term window he you talked about it .
G: we spoke about it already ,
D: so what he 's doing .
C: so was actually ran the experiments mostly and was was hoping to have the plots with me today . didn't get to it . wou would be curious about people 's feedback on this cuz 'm @ @ there are some it 's it 's like bit of tricky engineering problem . 'm trying to figure out what 's the optimal way to set this up . so , , 'll try to make the plots and then put some postscript up on my on my web page . and 'll mention it in my status report if people wanna take look .
D: you could clarify something for me . you 're saying point three percent , you take point three percent hit , when the training and testing links are don't match ? is that what it is ?
C: don't 's just for any mismatch you take hit . in some cases it might be better to have mismatch . like saw something like if you only have two seconds in test , or , , maybe it was something like four seconds , you actually do little better if you , , train on six seconds than if you train on four seconds . but the case , with the point three percent hit was using six seconds in test , , comparing train on twelve seconds versus train on six seconds .
D: and which was worse ?
C: the train on twelve seconds .
D: but point three percent , , from what to what ? that 's point three percent
C: on the the accuracies went from it was something vaguely like ninety - five point six accuracy , , improved to ninety - five point nine wh when
D: so four point four to four point one . so about about an eight percent , , seven or eight percent relative ? in , if you were going for an evaluation system you 'd care . but if you were doing live system that people were actually using nobody would notice . it 's , to get something that 's practical , that you could really use .
C: that 's that 's interesting . alright , the , see your point . was thinking of it as , , an interesting research problem . the how to was thinking that for the asru paper we could have section saying , "" for smartkom , we in we tried this approach in , , interactive system "" , which don't think has been done before . and and then there was two research questions from that . and one is the does it still work if you just use the past history ? and the other was this question of , what was just talking about now . so that 's why it was interesting .
D: short - time fft short - time cepstrum calculation , , mean mean calculation work that people have in commercial systems , they do this all the time . they the they calculate it from previous utterances and then use it , . but but , , as you say , there hasn't been that much with this long - time , , spectra work .
C: so that 's that 's standard .
D: no , it is interesting . and the other thing is , , there 's two sides to these really small , , gradations in performance . , on the one hand in practical system if something is , , four point four percent error , four point one percent error , people won't really tell be able to tell the difference . on the other hand , when you 're doing , , research , you may , you might find that the way that you build up change from ninety - five percent accurate system to ninety - eight percent accurate system is through ten or twelve little things that you do that each are point three percent . so so the they it 's don't mean to say that they 're they 're irrelevant . they are relevant . but , , for demo , you won't see it .
C: let 's let 's see . and then there 's , another thing wanna start looking at , , wi is , , the choice of the analysis window length . so 've just been using two seconds just because that 's what carlos did before . wrote to him asking about he chose the two seconds . and it seemed like he chose it bit informally . with the with the htk set - up should be able to do some experiments , on just varying that length , say between one and three seconds , in few different reverberation conditions , say this room and also few of the artificial impulse responses we have for reverberation , just , , making some plots and seeing how they look . with the sampling rate was using , one second or two seconds or four seconds is at power of two , number of samples and , , 'll 'll jus for the ones in between 'll just zero - pad .
D: one thing that might also be an issue , , cuz part of what you 're doing is you 're getting spectrum over bunch of different kinds of speech sounds . and so it might matter how fast someone was talking . if you if there 's lot of phones in one second maybe you 'll get really good sampling of all these different things , and , , on the other hand if someone 's talking slowly maybe you 'd need more . if you have some samples of faster or slower speech but it might make difference .
C: don't don't think the ti - digits data that have , , is would be appropriate for that . but what do you what about if fed it through some , , speech processing algorithm that changed the speech rate ?
D: but then you 'll have the degradation of , , whatever you do , added onto that . maybe if you get something that sounds that 's does pretty job at that .
C: , just if you 's worth looking into .
D: you could imagine that .
C: it is getting little away from reverberation .
D: it 's just that you 're making choice was thinking more from the system aspect , if you 're making choice for smartkom , that that it might be that it 's it the optimal number could be different , depending on
C: and and th the third thing , , , is , , barry explained lda filtering to me yesterday . and so , , mike shire in his thesis , did series of experiments , , training lda filters in on different conditions . and you were interested in having me repeat this for for this mean subtraction approach ? is is that right ? or for these long analysis windows , , is the right way to put it .
D: the the issue was the general issue was bringing up was that if you 're have moving window , , wa set of weights times things that , , move along , shift along in time , that you have linear time invariant filter . and you just happened to have picked particular one by setting all the weights to be equal . and so the issue is what are some other filters that you could use , , in that sense of "" filter "" ? as was saying , the simplest thing to do is not to train anything , but just to do some , , hamming or hanning , , window , thing , just to de - emphasize the jarring . so that would be the first thing to do . but then , , the lda , is interesting because it would say , suppose you actually trained this up to do the best you could by some criterion , what would the filter look like then ? that 's what we 're doing in this aur - aurora . it 's still not clear to me in the long run whether the best thing to do would be to do that or to have some stylized version of the filter that looks like these things you 've trained up , because you always have the problem that it 's trained up for one condition and it isn't quite right for another . that 's why that 's why rasta filter has actually ended up lasting long time , people still using it quite bit , because you don't change it . doesn't get any worse .
C: actually was just thinking about what was asking about earlier , wi which is about having less than say twelve seconds in the smartkom system to do the mean subtraction . you said in systems where you use cepstral mean subtraction , they concatenate utterances and , do how they address this issue of , , testing versus training ?
G: what they do is they do it always on - line , that you just take what you have from the past , that you calculate the mean of this and subtract the mean . and then you can , you can increase your window whi while you get while you are getting more samples .
C: and , , so in tha in that case , wh what do they do when they 're , performing the cepstral mean subtraction on the training data ? so because you 'd have hours and hours of training data . so do they cut it off and start over ?
G: so do you have , you mean you have files which are hours of hours long ? usually you have in the training set you have similar conditions , file lengths are , the same order or in the same size as for test data , or
C: so if someone 's interacting with the system , though , , morgan , morgan said that you would tend to , , chain utterances together
D: what was what was saying was that , , at any given point you are gonna start off with what you had from before . and so if you 're splitting things up into utterances so , , in dialogue system , where you 're gonna be asking , , , th for some information , there 's some initial th something . and , , the first time out you might have some general average . but you you don't have very much information yet . but at after they 've given one utterance you 've got something . you can compute your mean cepstra from that , and then can use it for the next thing that they say , so that , , the performance should be better that second time . and the heuristics of exactly how people handle that and how they handle their training 'm vary from place to place . but the ideally , it seems to me anyway , that you would wanna do the same thing in training as you do in test . but that 's that 's just , , prejudice . and anybody working on this with some particular task would experiment .
C: the question had was , , amount of data was the amount of data that you 'd give it to , update this estimate . because say you if you have say five thousand utterances in your training set , , and you keep the mean from the last utterance , by the time it gets to the five thousandth utterance
D: no , but those are all different people with different , in so , in the in telephone task , these are different phone calls . so you don't wanna @ @ chain it together from from different phone call .
C: so so they would
D: so it 's within speaker , within phone call , if it 's dialogue system , it 's within whatever this characteristic you 're trying to get rid of is expected to be consistent over ,
C: so you 'd you and so in training you would start over at every new phone call or at every new speaker .
D: now , , maybe you 'd use something from the others just because at the beginning of call you anything , and so you might have some general thing that 's your best to start with . lot of these things are proprietary so we 're doing little bit of guesswork here . what do comp what do people do who really face these problems in the field ? and they don't tell other people exactly what they do . but but , when you the hints that you get from what they when they talk about it are that they do they all do something like this .
C: bec - because so this smartkom task first off , it 's this tv and movie information system .
D: but you might have somebody who 's using it and then later you might have somebody else who 's using it . and so you 'd wanna set some
C: was was about to say . so if you ask it "" what what movies are on tv tonight ? "" , if look at my wristwatch when say that it 's about two seconds . the way currently have the mean subtraction , , set up , the analysis window is two seconds . so what you just said , about what do you start with , raises question of what do start with then ?
D: so in that situation , though , th maybe what 's little different there , is you 're talking about there 's only one it it also depends we 're getting little off track here . there 's been some discussion about whether the work we 're doing in that project is gonna be for the kiosk or for the mobile or for both . and for this discussion it matters . if it 's in the kiosk , then the physical situation is the same . it 's gonna , the exact interaction of the microphone 's gonna differ depending on the person and . but at least the basic acoustics are gonna be the same . so if it 's really in one kiosk , then that you could just chain together and , as much as much speech as possible to because what you 're really trying to get at is the is the reverberation characteristic . but in the case of the mobile , , presumably the acoustic 's changing all over the place . and in that case you probably don't wanna have it be endless because you wanna have some it 's not question of how long do you 's you can get an approximation to stationary something , given that it 's not really stationary .
C: and just started thinking of another question , which is , for the very first frame , what do do if 'm if take if use that frame to calculate the mean , then 'm just gonna get nothing . so should probably have some default mean for the first couple of frames ?
D: or subtract nothing .
C: or subtract nothing . and and that 's that 's something that 's people have figured out how to deal with in cepstral mean subtraction as ?
D: people do something . they they , , they have some , , in cepstral mean subtraction , for short - term window analysis windows , as is usually done , you 're trying to get rid of some very general characteristic . and so , , if you have any other information about what general characteristic would be , then you can do it there .
F: you can also reflect the data . so you take , 'm not how many frames you need . but you take that many from the front and flip it around to as the negative value . so you can always
D: the other thing is that and remember doing this , is that if you have multi - pass system , , if the first pass ta it takes most of the computation , the second and the third pass could be very , very quick , just looking at relatively small small , , space of hypotheses . then you can do your first pass without any subtraction . and then your second pass , , eliminates those most of those hypotheses by , by having an improved version of the analysis .
C: so that was all had , for now .
F: do you wanna go , barry ?
A: so for the past , , week an or two , 've been just writing my , , formal thesis proposal . so 'm taking this qualifier exam that 's coming up in two weeks . and finish writing proposal and submit it to the committee . and , should should explain , , more about what 'm proposing to do , and and ?
D: yes , briefly .
A: so briefly , 'm proposing to do new approach to speech recognition using , combination of , , multi - band ideas and ideas , , about the , acoustic phonec phonetic approach to speech recognition . so will be using these graphical models that , that implement the multi - band approach to recognize set of intermediate categories that might involve , , things like phonetic features or other feature things that are more closely related to the acoustic signal itself . and the hope in all of this is that by going multi - band and by going into these , intermediate classifications , that we can get system that 's more robust to unseen noises , and situations like that . some of the research issues involved in this are , , one , what intermediate categories do we need to classify ? another one is , what other types of structures in these multi - band graphical models should we consider in order to , combine evidence from the sub - bands ? and , , the third one is how do we how do we merge all the , , information from the individual , multi - band classifiers to come up with word recognition or phone recognition things . so that 's that 's what 've been doing .
F: so you 've got two weeks , ?
A: got two weeks to brush up on , presentation
D: you were finishing your thesis in two weeks .
F: are you gonna do any dry runs for your thing , or are you just gonna
A: 'm gonna do some . would you be interested ? to help out ?
F: is that it ?
A: that 's it .
F: let 's see . so we 've got forty minutes left , and it seems like there 's lot of material . an - any suggestions about where we where we should go next ?
B: mmm , @ @ .
F: do you wanna go , sunil ? maybe we 'll just start with you .
B: but actually stuck most of this in our last meeting with guenter . so the last week , , showed some results with only speechdat - car which was like some fifty - six percent . and , , didn't found that the results wasn't getting that results on the ti - digit . so was like looking into "" why , what is wrong with the ti - digits ? "" . why why was not getting it . and found that , the noise estimation is reason for the ti - digits to perform worse than the baseline . so , , actually , picked th the first thing did was scaled the noise estimate by factor which is less than one to see if that because found there are lot of zeros in the spectrogram for the ti - digits when used this approach . so the first thing did was scaled the noise estimate . so the results that 've shown here are the complete results using the new the the new technique is nothing but the noise estimate scaled by factor of point five . so it 's just an ad - hoc some intermediate result , because it 's not optimized for anything . so the results the trend the only trend could see from those results was like the the current noise estimation or the , , noise composition scheme is working good for like the car noise type of thing . because 've the only very good result in the ti - digits is the noise car noise condition for their test - , which is like the best could see that for any non - stationary noise like "" babble "" or "" subway "" or any "" street "" , some "" restaurant "" noise , it 's like it 's not performing very . the so that 's the first thing , could make out from this .
G: what is important to see is that there is big difference between the training modes . if you have clean training , you get also fifty percent improvement . but if you have muddy condition training you get only twenty percent .
B: and in that twenty percent @ @ it 's very inconsistent across different noise conditions . so have like forty - five percent for "" car noise "" and then there 's minus five percent for the "" babble "" , and there 's this thirty - three for the "" station "" . and so it 's not it 's not actually very consistent across . the only correlation between the speechdat - car and this performance is the stationarity of the noise that is there in these conditions and the speechdat - car . so the overall result is like in the last page , which is like forty - seven , which is still very imbalanced because there are like fifty - six percent on the speechdat - car and thirty - five percent on the ti - digits . ps the fifty - six percent is like comparable to what the french telecom gets , but the thirty - five percent is way off .
D: 'm looking on the second page , and it says "" fifty percent "" looking in the lower right - hand corner , "" fifty percent relative performance "" .
G: for the clean training . and if you if you look
D: is that fifty percent improvement ?
B: for that 's for the clean training and the noisy testing for the ti - digits .
D: so it 's improvement over the baseline mel cepstrum ? but the baseline mel cepstrum under those training doesn't do as 'm 'm trying to understand why it 's it 's eighty percent that 's an accuracy number , , so that 's not as good as the one up above . but the fifty is better than the one up above , so 'm confused .
B: actually the noise compensation whatever , , we are put in it works very for the high mismatch condition . it 's consistent in the speechdat - car and in the clean training also it gives it but this fifty percent is that the high mismatch performance equivalent to the high mismatch performance in the speech .
F: so so since the high mismatch performance is much worse to begin with , it 's easier to get better relative improvement .
B: so by putting this noise
E: if we look at the figures on the right , we see that the reference system is very bad .
B: the reference drops like very fast
E: like for clean training condition .
D: this is this is ti digits we 're looking at ? this whole page is ti - digits or this is ?
B: it 's not written anywhere . it 's ti - digits . the first spreadsheet is ti - digits .
D: how does clean training do for the , , "" car ""
B: the "" car "" ? still it still , that 's still consistent . get the best performance in the case of "" car "" , which is the third column in the condition .
D: this is added noise . this is ti - digits . in the , , multi - language , , finnish and
G: this is next page .
B: that 's the next spreadsheet , is so that is the performance for italian , finnish and spanish .
D: "" training condition "" so "" clean "" corresponds to "" high mismatch "" . and "" increase "" ,
B: that 's "" percentage increase "" is the percentage improvement over the baseline .
G: it 's it 's
D: which means decrease in word error rate ? so "" percentage increase "" means decrease ?
G: the the there was very long discussion about this on the on the , , amsterdam meeting . how to how to calculate it then .
B: there 's there 's
G: you are using finally this the scheme which they
B: which is there in the spreadsheet . 'm not changing anything in there . so all the hi numbers are very good , in the sense , they are better than what the french telecom gets . but the only number that 's still , which stephane also got in his result was that medium mismatch of the finnish , which is very which is very strange situation where we used the we changed the proto for initializing the this is because it gets stuck in some local minimum in the training . that seventy - five point seven nine in the finnish mismatch which is that the eleven point nine six what we see .
D: so we have to jiggle it somehow ?
B: so we start with that different proto and it becomes eighty - eight , which is like some fifty percent improvement .
D: start with different what ?
B: which is like different initialization for the , , transition probabilities . it 's just that right now , the initialization is to stay more in the current state , which is point four point six , right ? and if it changes to point five , which is equal @ @ for transition and self loop where it becomes eighty - eight percent .
F: but that involves mucking with the back - end ,
B: we can't do it .
F: which is not allowed .
G: it , like , it is known , this medium match condition of the finnish data has some strange effects .
B: it has very few at , actually , , tran , words also . it 's very , very small set , actually .
G: there is there is lot of , there are lot of utterances with music in with music in the background .
B: it has some music also . very horrible music like
D: so maybe for that one you need much smarter vad ? if it 's music .
B: that 's the that 's about the results . the summary is like so there are the other thing what tried was , which explained in the last meeting , is using the channel zero for , , for both dropping and estimating the noise . and that 's like just to get feel of how good it is . the fifty - six percent improvement in the speechdat - car becomes like sixty - seven percent . like ten percent better . but that 's that 's not that 's cheating experiment .
G: but the but the , , forty - seven point nine percent which you have now , that 's already remarkable improvement in comparison to the first proposal .
B: so we had forty - four percent in the first proposal . we have big im so the major improvement that we got was in all the high mismatch cases , because all those numbers were in sixties and seventies because we never had any noise compensations . so that 's where the biggest improvement came up . not much in the match and the medium match and ti - digits also right now . so this is still at three or four percent improvement over the first proposal .
D: so that 's good . then if we can improve the noise estimation , then it should get better .
G: started thinking about also , discovered the same problem when started working on , on this aurora task almost two years ago , that you have the problem with this mulit at the beginning we had only this multi condition training of the ti - digits . and , , found the same problem . just taking , what we were used to use , , , some type of spectral subtraction , you get even worse results than the basis tried to find an explanation for it ,
B: stephane also has the same experience of using the spectral subtraction right ? so here , found that it 's if changed the noise estimate could get an improvement . so that 's so it 's something which actually pursue , is the noise estimate .
G: what you do is in when you have the this multi - condition training mode , then you have then you can train models for the speech , for the words , as as for the pauses where you really have all information about the noise available . at the beginning it was not surprising to me that you get really the best results on doing it this way , in comparison to any type of training on clean data and any type of processing . it seems to be the best what wh what we can do in this moment is multi - condition training . and every when we now start introducing some noise reduction technique we introduce also somehow artificial distortions . and these artificial distortions , have the feeling that they are the reason why we have the problems in this multi - condition training . that means the ms we trained , they are they are based on gaussians , and on modeling gaussians . can move little bit with this ? and if we introduce now this spectral subtraction , or wiener filtering so , usually what you have is maybe , 'm 'm showing now an envelope maybe you 'll for this time . so usually you have maybe in clean condition you have something which looks like this . and if it is noisy it is somewhere here . and then you try to subtract it or wiener filter or whatever . and what you get is you have always these problems , that you have this these zeros in there . and you have to do something if you get these negative values . this is your noise estimate and you somehow subtract it or do whatever . and then you have and then what you do is you introduce some artificial distribution in this in the models . you train it also this way but , somehow there is there is no longer gaussian distribution . it is somehow strange distribution which we introduce with these artificial distortions . and and was thinking that might be the reason why you get these problems in the especially in the multi - condition training mode .
B: th - that 's true . the the models are not complex enough to absorb that additional variability that you 're introducing .
E: also have the feeling that , the reason ye why it doesn't work is , that the models are much are , not complex enough . because actually als always had good experience with spectral subtraction , just straight spectral subtraction algorithm when was using neural networks , big neural networks , which maybe are more able to model strange distributions then tried the same exactly the same spectral subtraction algorithm on these aurora tasks and it simply doesn't work . it 's even it , , hurts even .
D: we probably should at some point here try the tandem the system - two with this , with the spectral subtraction for that reason . cuz again , it should do transformation to domain where it maybe looks more gaussian .
G: just yesterday when was thinking about it what we could try to do , or do about it if you if you get at this in this situation that you get this negative values and you simply set it to zero or to constant or whatever if we would use there somehow , random generator which has certain distribution , not certain , special distribution we should see we have to think about it . and that we , so , introduce again some natural behavior in this trajectory .
B: very different from speech . still , , it shouldn't confuse the
G: , similar to what you see really in the real noisy situation . or in the clean situation . but but somehow natural distribution .
D: but isn't that again the idea of the additive thing , if it as we had in the ? if you have random data , , in the time domain , then when you look at the spectrum it 's gonna be pretty flat . so just add something everywhere rather than just in those places . it 's just constant , right ?
G: it 's it 's just especially in these segments , you introduce , , very artificial behavior .
D: see if you add something everywhere , it has almost no effect up up on top . and it and it has significant effect down there . that was , the idea .
B: the that 's true . that those regions are the for this @ @ those negative values or whatever you get .
G: we could trit , we could think how what we could try . it was just an idea .
D: when it 's noisy people should just speak up .
E: if we look at the france telecom proposal , they use some noise addition . they have random number generator , right ? and they add noise on the trajectory of , , the log energy only , right ?
B: - - zero and log energy also ,
E: but how much effect it this have , but they do that .
G: so it it is somehow similar to what
E: because they have th log energy , and then just generate random number . they have some mean and variance , and they add this number to the log energy simply .
B: the log energy , the after the clean cleaning up . so they add random noise to it .
D: to the just the energy , or to the mel , to the mel filter ?
B: on - only to the log energy .
D: so it cuz , this is most interesting for the mel filters . one or the other .
G: but but they do not apply filtering of the log energy or what
B: no their filter is not domain . so they did filter their time signal and then what @ @
G: and then they calculate from this , the log energy
B: then after that it is almost the same as the baseline prop system . and then the final log energy that they that they get , that to the to that they add some random noise .
D: but again , that 's just log energy as opposed to filter bank energy .
B: so it 's not the mel . it 's not the mel filter bank output . these are log energy computed from the time domain signal , not from the mel filter banks .
E: maybe it 's just way to decrease the importance of this particular parameter in the in the world feature vector cu if you add noise to one of the parameters , you widen the distributions
B: the variance , , reduces ,
E: eee - sss - .
D: so it could reduce the dependence on the amplitude and so on .
F: so is , is that about it ?
B: so the other thing is the 'm just looking at little bit on the delay issue where the delay of the system is like hundred and eighty millisecond . so tried another sk system , another filter which 've like shown at the end . which is very similar to the existing , filter . only , only thing is that the phase is like nonlinear phase because it 's it 's not symmetric filter anymore .
F: this is for the lda ?
B: so this is like so this makes the delay like zero for lda because it 's completely causal . so got actually just the results for the italian for that and that 's like so the fifty - one point nine has become forty - eight point six , which is like three percent relative degradation . so have like the fifty - one point nine it fares for the other conditions . so it 's just like it 's like three percent relative degradation ,
G: but but is there is there problem with the one hundred eighty milliseconds ?
D: th - , this is
G: , talked to , ta , talked , , about it with hynek .
D: so , our position is that , , we shouldn't be unduly constraining the latency at this point because we 're all still experimenting with trying to make the performance better in the presence of noise . there is minority in that group who is arguing who are arguing for , , having further constraining of the latency . so we 're just continuing to keep aware of what the trade - offs are and , , what do we gain from having longer or shorter latencies ? but since we always seem to at least get something out of longer latencies not being so constrained , we 're tending to go with that if we 're not told we can't do it .
F: what where was the , the smallest latency of all the systems last time ?
B: the french telecom .
D: france telecom was was very short latency and they had very good result .
F: what what was it ?
D: it was thirty - five .
G: it was in the order of thirty milliseconds
B: thirty - four .
D: so it 's possible to get very short latency . but , again , we 're the approaches that we 're using are ones that take advantage of
F: was just curious about where we are compared to , , the shortest that people have done .
G: but but this thirty milliseconds they did it did not include the delta calculation . and this is included now ,
B: so if they include the delta , it will be an additional forty millisecond .
G: th they were not using the htk delta ?
B: no , they 're using nine - point window , which is like four on either side ,
G: nine - point .
B: they didn't include that .
E: where does the comprish compression in decoding delay comes from ?
B: that 's the way the the frames are packed , like you have to for one more frame to pack . because it 's the crc is computed for two frames always .
D: that the they would need that forty milliseconds also .
B: they actually changed the compression scheme altogether . so they have their own compression and decoding scheme and they what they have . but they have coded zero delay for that . because they ch know they changed it , they have their own crc , their own error correction mechanism . so they don't have to more than one more frame to know whether the current frame is in error . so they changed the whole thing so that there 's no delay for that compression and part also . even you have reported actually zero delay for the compression . maybe you also have some different
G: no , used this scheme as it was before .
F: we 've got twenty minutes so we should probably try to move along . did you wanna go next , stephane ?
E: we have to take so you have one sheet ? this one is you don't need it , so you have to take the whole the five . there should be five sheets .
D: because left one with dave because was dropping one off and passing the others on . so , no , we 're not .
H: give me one .
D: we need one more over here .
E: maybe there 's not enough for everybody .
F: share with barry .
E: can we look at this ? there are two figures showing actually the , mmm , , performance of the current vad . so it 's neural network based on plp parameters , which estimate silence probabilities , and then put median filtering on this to smooth the probabilities , right ? didn't use the scheme that 's currently in the proposal because don't want to in the system we want to add like speech frame before every word and little bit of , , couple of frames after also . but to estimate the performance of the vad , we don't want to do that , because it would artificially increase the the false alarm rate of speech detection . there is normally figure for the finnish and one for italian . and maybe someone has two for the italian because 'm missing one figure here . so one surprising thing that we can notice first is that the speech miss rate is , higher than the false alarm rate .
G: so so what is the lower curve and the upper curve ?
E: there are two curves . one curve 's for the close - talking microphone , which is the lower curve . and the other one is for the distant microphone which has more noise it 's logical that it performs worse . so as was saying , the miss rate is quite important which means that we tend to label speech as silence . didn't analyze further yet , but it 's it may be due to the fricative sounds which may be in noisy condition maybe label labelled as silence . and it may also be due to the alignment the reference alignment . because right now use an alignment obtained from system trained on channel zero . checked it little bit but there might be alignment errors . like the fact that the models tend to align their first state on silence and their last state on silence also . so the reference alignment would label as speech some silence frame before speech and after speech . this is something that we already noticed before so this cus this could also explain , , the high miss rate maybe .
G: and and this curves are the average over the whole database ,
E: and the different points of the curves are for five , thresholds on the probability from point three to point seven .
B: so the detection threshold is very
E: there first , threshold on the probability @ @ that puts all the values to zero or one . and then the median filtering .
B: so the median filtering is fixed . you just change the threshold ?
E: it 's fixed , so , going from channel zero to channel one , , almost double the error rate . so it 's reference performance that we can , if we want to work on the vad , we can work on this basis
A: is this is this vad mlp ? how how big is it ?
E: it 's very big one .
B: so three hundred and fifty inputs , six thousand hidden nodes and two outputs .
D: middle - sized one .
E: you have questions about that , or suggestions ? it seems the performance seems worse in finnish ,
B: it 's not trained on finnish .
H: it 's worse .
E: it 's not trained on finnish ,
D: what 's it trained on ?
B: the mlp 's not trained on finnish .
D: what 's it trained on ?
B: it 's italian ti - digits .
D: it 's trained on italian ?
B: that 's right .
E: and also there are like funny noises on finnish more than on italian .
B: the , it 's true .
E: we were looking at this . but for most of the noises , noises are if we want to talk about that . the "" car "" noises are below like five hundred hertz . and we were looking at the "" music "" utterances and in this case the noise is more about two thousand hertz . the music energy 's very low . from zero to two thousand hertz . so maybe just looking at this frequency range for from five hundred to two thousand would improve somewhat the vad
B: so there are like some some parameters you wanted to use ?
E: it 's there .
G: so is the is the training is the training based on these labels files which you take as reference here ? wh - when you train the neural net you
E: it 's not . it 's it was trained on some alignment obtained for the italian data , we trained the neural network on with embedded training . so re - estimation of the alignment using the neural network , . that 's right ?
B: we actually trained , , the on the italian training part . we we had another system with
E: so it was phonetic classification system for the italian aurora data .
B: it must be somewhere .
E: for the aurora data that it was trained on , it was different . like , for ti - digits you used previous system that you had , .
B: that 's true .
E: so the alignments from the different database that are used for training came from different system . then we put them tog together . you put them together and trained the vad on them . but did you use channel did you align channel one also ?
B: took their entire italian training part . so it was both channel zero plus channel one .
E: so the alignments might be wrong then on channel one , right ? so we might ,
B: we can do realignment . that 's true .
E: at least want to retrain on these alignments , which should be better because they come from close - talking microphone .
G: the that was my idea . if it ha if it is not the same labeling which is taking the spaces .
B: so the vad was trained on maybe different set of labels for channel zero and channel one was the alignments were were different for certainly different because they were independently trained . we didn't copy the channel zero alignments to channel one . but for the new alignments what you generated , you just copied the channel zero to channel one , right ?
E: actually when we look at the vad , for some utterances it 's almost perfect , it just dropped one frame , the first frame of speech so there are some utterances where it 's almost one hundred percent vad performance . so the next thing is , have the spreadsheet for three different system . but for this you only have to look right now on the speechdat - car performance so didn't test the spectral subtraction on ti - digits yet . so you have three she sheets . one is the proposal - one system . actually , it 's not exe exactly proposal - one . it 's the system that sunil just described . but with , wiener filtering from , france telecom included . so this gives like fifty - seven point seven percent , , , error rate reduction on the speechdat - car data . and then have two sheets where it 's for system where so it 's again the same system . but in this case we have spectral subtraction with maximum overestimation factor of two point five . there is smoothing of the gain trajectory with some , low - pass filter , which has forty milliseconds latency . and then , after subtraction , add constant to the energies and have two cases where the first case is where the constant is twenty - five db below the mean speech energy and the other is thirty db below . and for these two system we have like fifty - five point , , five - percent improvement , and fifty - eight point one . so again , it 's around fifty - six , fifty - seven .
D: cuz notice the ti - digits number is exactly the same for these last two ?
E: for the france telecom , spectral subtraction included in the our system , the ti - digits number are the right one , but not for the other system because didn't test it yet this system , including with spectral subtraction on the ti - digits data . tested it on speechdat - car .
D: so so that means the only thing
G: so so these numbers are simply
E: this , we have to
B: but this number .
D: so you so you just should look at that fifty - eight perc point nine percent and so on .
B: so by , by reducing the noise decent threshold like minus thirty db , it 's like , you are like reducing the floor of the noisy regions , right ?
E: the floor is lower .
D: so when you say minus twenty - five or minus thirty db , with respect to what ?
E: to the average , speech energy which is estimated on the world database .
D: so you 're creating signal - to - noise ratio of twenty - five or thirty db ?
E: but it 's not
G: what you do is this . when when you have this , after you subtracted it , , then you get something with this , , where you set the values to zero and then you simply add an additive constant again . so you shift it somehow . this this whole curve is shifted again .
D: but did you do that before the thresholding to zero ,
E: but , it 's after the thresholding .
D: so you 'd really want to do it before ,
E: maybe we might do it before ,
D: because then the then you would have less of that phenomenon .
E: but still , when you do this and you take the log after that , it reduce the variance .
D: that will reduce the variance . that 'll help . but maybe if you does do it before you get less of these funny - looking things he 's drawing .
B: so before it 's like adding this , col to the exi original
D: right at the point where you 've done the subtraction . essentially you 're adding constant into everything .
G: but the way stephane did it , it is exactly the way have implemented in the phone ,
D: better do it different , then . just you just ta you just set it for particular signal - to - noise ratio that you want ?
G: made similar investigations like stephane did here , just , adding this constant and looking how dependent is it on the value of the constant and then , must choose them somehow to give on average the best results for certain range of the signal - to - noise ratios .
E: it 's clear . should have gi given other results . also it 's clear when you don't add noise , it 's much worse . like , around five percent worse . and if you add too much noise it get worse also . and it seems that right now this is constant that does not depend on anything that you can learn from the utterance . it 's just constant noise addition .
D: then then 'm confused . you 're saying it doesn't depend on the utterance but you were adding an amount that was twenty - five db down from the signal energy .
E: so the way did that , measured the average speech energy of the all the italian data . and then have used this as mean speech energy .
D: it 's just constant amount over all .
E: wha what observed is that for italian and spanish , when you go to thirty and twenty - five db , it 's good . it stays in this range , it 's , , the the performance of the this algorithm is quite good . but for finnish , you have degradation already when you go from thirty - five to thirty and then from thirty to twenty - five . and have the feeling that maybe it 's because just finnish has mean energy that 's lower than the other databases . and due to this the thresholds should be the the noise addition should be lower
D: but in , in the real thing you 're not gonna be able to measure what people are doing over half an hour or an hour , or anything , right ? so you have to come up with this number from something else .
G: but you are not doing it now language dependent ?
E: it 's not . it 's just something that 's fixed .
G: it 's overall .
D: but what he is doing language dependent is measuring what that number reference is that he comes down twenty - five down from .
E: because did it started working on italian . obtained this average energy and then used this one .
B: for all the languages .
D: so it 's arbitrary .
E: so the next thing is to use this as maybe initialization and then use something on - line .
D: something more adaptive ,
E: but and expect improvement at least in finnish because the way for italian and spanish it 's th this value works good but not necessarily for finnish . but unfortunately there is , like , this forty millisecond latency so would try to somewhat reduce this @ @ . already know that if completely remove this latency , so . , it there is three percent hit on italian .
G: your your smoothing was @ @ , over this so to say , the factor of the wiener . and then it 's , what was it ? this smoothing , it was over the subtraction factor , so to say .
E: it 's smoothing over the gain of the subtraction algorithm .
G: and and you are looking into the future , into the past .
E: so , to smooth this thing .
G: and did you try simply to smooth to smooth the to smooth stronger the envelope ? because , it should have similar effect if you you have now several stages of smoothing , so to say . you start up . as far as remember you smooth somehow the envelope , you smooth somehow the noise estimate , and later on you smooth also this subtraction factor .
E: it 's it 's just the gain that 's smoothed actually
B: actually do all the smoothing .
E: but it 's smoothed
G: it it was you .
E: no , in this case it 's just the gain . but the way it 's done is that , for low gain , there is this non nonlinear smoothing actually . for low gains , use the smoothed sm , smoothed version but for high gain @ @ it 's don't smooth .
G: it experience shows you , if you do the the best is to do the smoo smoothing as early as possible . so when you start up . you start up with the somehow with the noisy envelope . and , best is to smooth this somehow .
E: could try this .
B: so , before estimating the snr , @ @ smooth the envelope .
E: then would need to find way to like smooth less also when there is high energy . cuz noticed that it helps little bit to like smooth more during low energy portions and less during speech , because if you smooth then you distort the speech .
G: you could do it in this way that you say , if you if 'm you have somehow noise estimate , and , if you say 'm with my envelope 'm close to this noise estimate , then you have bad signal - to - noise ratio and then you would like to have stronger smoothing . so you could you could base it on your estimation of the signal - to - noise ratio on your actual
B: or some silence probability from the vad if you have
E: but don't trust the current vad .
B: so not right now maybe .
D: the vad later will be much better .
F: so is that it ?
E: fff that 's it .
G: so to summarize the performance of these , speechdat - car results is similar than yours so to say .
B: so the fifty - eight is like the be some fifty - six point
G: you have you have fifty - six point four
B: that 's true .
G: and and dependent on this additive constant , it is better or worse .
E: the condition where it 's better than your approach , it 's it just because maybe it 's better on matched and that the weight on matched is bigger ,
B: you caught up . that 's true .
E: if you don't weigh differently the different condition , you can see that your , the win the two - stage wiener filtering is maybe better it 's better for high mismatch , right ?
B: it 's better for high mismatch .
E: but little bit worse for matched .
B: so over all it gets , , worse for the matched condition ,
F: so we need to combine these two .
B: that 's that 's the best thing , is like the french telecom system is optimized for the matched condition . so they know that the weighting is good for the matched , and so there 's everywhere the matched 's performance is very good for the french telecom . we are we may also have to do something similar @ @ .
D: our tradition here has always been to focus on the mismatched . cuz it 's more interesting .
G: mu - my mine was it too , . before started working on this aurora .
H: only say that the this is , summary of the of all the vts experiments and say that the result in the last , for italian the last experiment for italian , are bad . make mistake when write . up at copy one of the bad result . there . , this . if we put everything , we improve lot the spectral use of the vts but the final result are not still mmm , good like the wiener filter . maybe it 's @ @ it 's possible to have the same result . because have , mmm , worse result in medium mismatch and high mismatch .
B: you you have better you have some results that are good for the high mismatch .
H: someti are more or less similar but are worse . still don't have the result for ti - digits . the program is training . maybe for this weekend will have result ti - digits and complete that like this . one thing that note are not here in this result but are speak are spoken before with sunil improve my result using clean lda filter . if use , , the lda filter that are training with the noisy speech , that hurts the res my results .
D: so what are these numbers here ? are these with the clean or with the noisy ?
H: this is with the clean . with the noise have worse result , that if doesn't use it . but that may be because with this technique we are using really clean speech . the speech the representation that go to the htk is really clean speech because it 's from the dictionary , and maybe from that . because that you did some experiments using the two the two lda filter , clean and noi and noise , and it doesn't matter too much .
E: but it doesn't matter on speechdat - car , but , it matters , , lot on ti - digits .
B: using the clean filter .
H: it 's better to use clean .
E: it 's much better when you we used the clean derived lda filter .
H: maybe you can do also this . to use clean speech .
E: sunil in your result it 's
B: 'll try the cle no , my result is with the noisy lda .
E: it 's with the noisy one .
B: it 's with the noisy . it 's it 's not the clean lda . it 's in in the front sheet , have like the summary .
D: and and your result is with the
E: it 's with the clean lda .
B: this is your results are all with the clean lda result ?
H: with the clean lda .
E: and in your case it 's all noisy ,
H: is that the reason ?
E: but observe my case it 's in , , at least on speechdat - car it doesn't matter but ti - digits it 's like two or three percent absolute , , better .
B: on ti - digits this matters .
D: so you really might wanna try the clean .
B: will have to look at it . that 's true .
D: that could be sizeable right there .
H: and this is everything .
G: maybe you are leaving in about two weeks carmen . so , if if would put it put on the head of project mana manager would say , , there is not so much time left now .
D: be my guest .
G: what would do is would pick @ @ the best consolation , which you think , and create all the results for the whole database that you get to the final number as sunil did it
H: and prepare at the
G: and maybe also to write somehow document where you describe your approach , and what you have done .
H: was thinking to do that next week .
D: 'll 'll borrow the head back and agree .
H: wi will do that next week .
D: that 's that 's actually the , the spanish government , , requires that anyway . they want some report from everybody who 's in the program . and 'd we 'd like to see it too .
F: what 's do you think we , , should do the digits or skip it ? or what are what do you think ?
D: we have them now ? why don why don't we do it ? just just take minute .
F: would you pass those down ? so 'll go ahead .
E: is it the channel , or the mike ? it 's the mike ? it 's not four .
H: this is date and time . on the channel , channel .
G: what is this ?
F: if you could just leave , , your mike on top of your , , digit form fill in any information that 's missing . didn't get chance to fill them out ahead of time . we 're gonna have to fix that . let 's see , it starts with one here , and then goes around and ends with nine here .
A: so 'm eight ,
F: so he 's eight ,
A: you 're seven .
F: you 're seven ,
","Another weekly meeting on ICSI's Meeting Recorder Group at Berkeley , though the members are joined by a visiting researcher.
The groups regulars reported progress on their work on mean subtraction , noise estimation , voice activity detection and the Vector Taylor Series.
While on these topics , related areas discussed included recognition window length , training versus test set sizes , artificial distortion and latency concerns.
Speaker fn002 is soon to be leaving the group , and so she will choose her best setup , run a complete set of experiments , and write up her work , procedure and results for next week.
New filters introduced to reduce latency by mn052  , performed slightly worse than those they replaced.
Whereas mn007 has added some latency to the process which he feels he can reduce.
Speaker me026 has been working on mean subtraction , his most recent results are suspiciously poor , and he is attempting to integrate the method into the SmartKom system.
Speaker mn052 has been looking at noise estimation , because he was getting better results with one data set than another.
Speaker mn007 has been looking at VAD performance , and getting some good results , though nothing that hasn't been produced before.
Speaker fn002 has been running VTS experiments , but her results aren't particularly impressive.
Speaker me006 has been working on the proposal for his thesis and outlined his idea.
"
ami_abstractive_summary,Bmr006.txt,"F: that 's looks strange .
B: now we 're on and it seems to be working .
E: there we go .
C: one two three four five six
A: that is weird .
E: this looks good .
A: it 's like when it 's been sitting for long time .
B: what it is . but all that it seems like every time am up here after meeting , and start it , it works fine . and if 'm up here and start it and we 're all sitting here waiting to have meeting , it gives me that error message and have not yet sat down with been able to get that error message in point where sit down and find out where it 's occurring in the code .
A: next time you get it maybe we should write it down .
B: one of these days .
E: was it pause , or ? was it on "" pause "" ?
D: so so the , the new procedural change that just got suggested , which is good idea is that , we do the digit recordings at the end . and that way , if we 're recording somebody else 's meeting , and number of the participants have to run off to some other meeting and don't have the time , , then they can run off . it 'll mean we 'll get somewhat fewer , sets of digits , but , that way we 'll cut into people 's time , , if someone 's on strict time , less . so , th we should start doing that . so , , let 's see , we were having discussion the other day , maybe we should bring that up , about , the nature of the data that we are collecting . @ @ that , we should have fair amount of data that is , collected for the same meeting , so that we can , wh - what were some of the points again about that ?
F: , , 'll back up . at the previous at last week 's meeting , this meeting was griping about wanting to get more data and talked about this with jane and adam , and was thinking of this mostly just so that we could do research on this data , since we 'll have new this new student di does wanna work with us , th the guy that was at the last meeting . and he 's already funded part - time , so we 'll only be paying him for for half of the normal part - time ,
B: and what 's he interested in , specifically ?
F: he 's comes from signal - processing background , but liked him lot cuz he 's very interested in higher level things , like language , and disfluencies and all kinds of eb maybe prosody , so he 's just getting his feet wet in that . anyway , , maybe we should have enough data so that if he starts he 'd be starting in january , next semester that we 'd have , , enough data to work with . but , , jane and adam brought up lot of good points that just posting note to berkeley people to have them come down here has some problems in that you you need to make that the speakers are who you want and that the meeting type is what you want , and . so , about that and it 's still possible , but 'd rather try to get more regular meetings of types that we know about , and hear , then mish - mosh of bunch of one - time just because it would be very hard to process the data in all senses , both to get the , to figure out what type of meeting it is and to do any higher level work on it , like , was talking to morgan about things like summarization , or what 's this meeting about . it 's very different if you have group that 's just giving report on what they did that week , versus coming to decision and . so . then was , talking to morgan about some new proposed work in this area , separate issue from what the student would be working on where was thinking of doing some summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to hot spots in the meeting , or things where is going on that might be important for someone who didn't attend to listen to . and in that , regard , we definitely will need it 'd it 'd be for us to have bunch of data from few different domains , or few different kinds of meetings . so this meeting is one of them , although 'm not participate if would feel very strange being part of meeting that you were then analysing later for things like summarization . and then there are some others that menti that morgan mentioned , like the front - end meeting and maybe networking group meeting .
B: we 're we 're hoping that they 'll let us start recording regularly .
F: so if that were the case then we 'd have enough . but , for anything where you 're trying to get summarization of some meeting meaning out of the meeting , , it would be too hard to have fifty different kinds of meetings where we didn't really have good grasp on what does it mean to summarize , but rather we should have different meetings by the same group but hopefully that have different summaries . and then we need couple that of we don't wanna just have one group because that might be specific to that particular group , but @ @ three or four different kinds .
B: we have lot of overlap between this meeting and the morning meeting .
F: see , 've never listened to the data for the front - end meeting .
B: we 've only had three .
F: but maybe that 's enough . so , in general , was thinking more data but also data where we hold some parameters constant or fairly similar , like meeting about of people doing certain work where at least half the participants each time are the same .
D: now , let let me just give you the other side to that cuz ca because don't disagree with that , but there is complimentary piece to it too . for other kinds of research , particularly the acoustic oriented research , actually feel the opposite need . 'd like to have lots of different people . as many people here and talking about the thing that you were just talking about it would have too few people from my point of view . 'd like to have many different speakers . so , would also very much like us to have fair amount of really random scattered meetings , of somebody coming down from campus , and , , if we can get more from them , fine , but if we only get one or two from each group , that still could be useful acoustically just because we 'd have close and distant microphones with different people .
F: definitely agree with that .
E: can say about that the issues that adam and raised were more matter of advertising so that you get more native speakers . because if you just say an and in particular , my suggestion was to advertise to linguistics grad students because there you 'd have so people who 'd have proficiency enough in english that , it would be useful for purposes . but , 've been 've gathered data from undergrads at on campus and if you just post randomly to undergrads you 'd get such mixed bag that it would be hard to know how much conversation you 'd have . and and the english you 'd have the language models would be really hard to build because it would not really be it would be an interlanguage rather than
D: , , first place , don't think we 'd just want to have random people come down and talk to one another , there should be meeting that has some goal and point cuz that 's what we 're investigating ,
F: it has to be pre - existing meeting , like meeting that would otherwise happen anyway .
D: so was was thinking more in terms of talking to professors , and and , senior , and , doctoral students who are leading projects and offering to them that they have their hold their meeting down here .
F: that 's what we and agree with .
D: that 's the first point . the second point is that for some time now , going back through berp that we have had speakers that we 've worked with who had non - native accents and th that
E: . 'm not saying accents . the accent 's not the problem . no , it 's more matter of , proficiency , just simply fluency . deal with people on campus who sometimes people , undergraduates in computer science , have language skills that make , that their fluency and writing skills are not so strong .
D: you 're not talking about foreign language .
B: , just talking about .
D: you 're just talking about
B: we all had the same thought .
E: but , it 's like when you get into the graduate level , , no problem . 'm not saying accents .
D: then we 're completely gone .
E: 'm say 'm saying fluency .
D: it 's the the habits are already burnt in .
E: 'm just saying fluency .
B: that , that the only thing we should say in the advertisement is that the meeting should be held in english . and and if it 's pre - existing meeting and it 's held in english , it 's probably if few of the people don't have , particularly good english skills .
E: now can say the other aspect of this from my perspective which is that , there 's there 's this issue , you have corpus out there , it should be used for multiple things cuz it 's so expensive to put together . and if people want to approach the idea of computational linguistics and probabilistic grammars and all may not be the focus of this group , but the idea of language models , which are fund generally speaking , , terms of like the amount of benefit per dollar spent or an hour invested in preparing the data , if you have choice between people who are pr more proficient in {nonvocalsound} , more fluent , more close to being academic english , then it would seem to me to be good thing . because otherwise you don't have the ability to have so if you have bunch of idiolects that 's the worst possible case . if you have people who are using english as as an interlanguage because they don't , they can't speak in their native languages and but their interlanguage isn't really match to any existing , , language model , this is the worst case scenario .
D: that 's what you 're going to have in the networking group . because they most the network group is almost entirely germans and spaniards .
E: but , that these people are of high enough level in their in their language proficiency that and 'm not objecting to accents . 'm 'm just thinking that we have to think at at higher level view , could we have language model , grammar grammar , , that , wo would be possibility . so so if you wanted to bring in model like dan jurafsky 's model , an and do some top - down , it to help th the bottom - up and merge the things or whatever , , it seems like , don't see that there 's an argument 'm what is that why not have the corpus , since it 's so expensive to put together , , useful for the widest range of central corp things that people generally use corpora for and which are , , used in computational linguistics . that 's that 's my point . which which includes both top - down and bottom - up .
C: it 's difficult .
D: , let 's let 's see what we can get . it that if we 're aiming at , groups of graduate students and professors and who are talking about things together , and it 's from the berkeley campus , probably most of it will be ,
E: yes , that 's fine . that 's fine . and my point in in my note to liz was that undergrads are an iff iffy population .
F: definitely agree with that , , for this purpose .
B: not to mention the fact that would be hesitant certainly to take anyone under eighteen , probably even an anyone under twenty - one .
E: grads and professors , fine .
D: you age - ist !
B: what 's that ? age - ist . the "" eighteen "" is because of the consent form .
E: age - ist .
B: we 'd hafta get find their parent to sign for them .
C: "" age - ist "" .
E: that 's true .
F: have , , question . morgan , you were mentioning that mari may not use the equipment from ibm if they found something else , cuz there 's
D: they 're they 're , they 're they 're assessing whether they should do that or do something else , hopefully over the next few weeks .
F: cuz , one remote possibility is that if we st if we inherited that equipment , if she weren't using it , could we set up room in the linguistics department ? and and , there may be lot more or in psych , or in comp wherever , in another building where we could , record people there . we 'd have better chance
B: we 'd need real motivated partner to do that . we 'd need to find someone on campus who was interested in this .
F: but if there were such it 's remote possibility , then , , one of us could , go up there and record the meeting rather than bring all of them down here . so it 's just thought if they end up not using the hardware .
D: the other thing , the other thing that was hoping to do in the first place was to turn it into some portable thing so you could wheel it around . but . , and
B: know that space is really scarce on at least in cs . to actually find room that we could use regularly might actually be very difficult .
F: but you may not need separate room , ,
B: that 's true .
F: the idea is , if they have meeting room and they can guarantee that the equipment will be safe and , and if one of us is up there once week to record the meeting
D: maybe john would let us put it into the phonology lab .
F: it 's not out of the question .
B: it would be interesting because then we could regularly get another meeting . another type of meeting .
C: but you need , , another portable thing another portable equipment to do , , more easier the recording process , , out from icsi . and probably . . if you want to record , , seminar or class , , in the university , you need it - it would be very difficult to put , , lot of , , head phones in different people when you have to record only with , , this , , device .
B: if we if we wanna just record with the tabletop microphones , that 's easy . that 's very easy ,
C: ye - , .
B: but that 's not the corpus that we 're collecting .
D: actually , that 's int that raises an interesting point that came up in our discussion that 's maybe worth repeating . we realized that , , when we were talking about this that , , there 's these different things that we want to do with it . so , , it 's true that we wanna be selective in some ways , , the way that you were speaking about with , , not having an interlingua and , these other issues . but on the other hand , it 's not necessarily true that we need all of the corpus to satisfy all of it . so , as per the example that we wanna have fair amount that 's done with small recorded with small , , typ number of types of meetings but we can also have another part that 's , , just one or two meetings of each of of range of them and that 's too . we realized in discussion that the other thing is , what about this business of distant and close microphones ? we really wanna have substantial amount recorded this way , that 's why we did it . but what about for th for these issues of summarization , lot of these higher level things you don't really need the distant microphone .
B: and you don't really need the close microphone , you mean .
D: you actually don't .
F: yea - , you actually don't really even need any fancy microphone .
E: which one did you mean ?
D: you you don't ne it doesn't you just need some microphone , somewhere .
B: ye - . .
F: you can use found data . you you can .
D: you need some microphone ,
F: use , but that any data that we spend lot of effort {nonvocalsound} to collect , each person who 's interested in , we have cou we have bunch of different , , slants and perspectives on what it 's useful for , , they need to be taking charge of making they 're getting enough of the data that they want . and so in my case , , there there is enough data for some kinds of projects and not enough for others .
B: not enough for others , right .
F: and so {nonvocalsound} 'm looking and thinking , "" 'd be glad to walk over and record people and so {nonvocalsound} forth if it 's to help th in my interest . "" and other people need to do that for themselves , , or at least discuss it so that we can find some optimal
D: right . so that but that 'm raising that cuz it 's relevant exactly for this idea up there that if you think about , "" , gee , we have this really complicated setup to do , "" maybe you don't .
B: for some of it .
D: maybe if if really all you want is to have recording that 's good enough to get , transcription from later , you just need to grab tape recorder and go up and make recording . we could have fairly we could just get dat machine and
F: agree with {nonvocalsound} jane , though , on the other hand that so that might be true , you may say , summarization , that sounds very language oriented . you may say , "" , you just do that from transcripts of radio show . "" you don't even need the speech signal . but what you what was thinking is long term what would be neat is to be able to pick up on suppose you just had distant microphone there and you really wanted to be able to determine this . there 's lots of cues you 're not gonna have . so do think that long term you should always try to satisfy the greatest number of interests and have this parallel information , which is really what makes this corpus powerful . otherwise , , lots of other sites can propose individual studies , so
D: but that the we can't really underestimate the difficulty shouldn't really underestimate the difficulty of getting setup like this up . and so , it took quite while to get that together and to say , "" , we 'll just do it up there , "" if you 're talking about something simple , where you throw away lot of these dimensions , then you can do that right away . talking about something that has all of these different facets that we have here , it won't happen quickly , it won't be easy , and there 's all sorts of issues about th keeping the equipment safe , or else hauling it around , and all sorts of
F: so then maybe we should {nonvocalsound} try to bring people here .
D: the first priority should be to pry to get try to get people to come here .
F: that 's that 's
D: we 're set up for it . the room is really , , underused .
E: the free lunch idea was great idea .
D: free lunch is good .
F: and we can get people to come here , that but the issue is you definitely wanna make that the group you 're getting is the right group so that you don't waste lot of your time {nonvocalsound} and the overhead in bringing people down .
A: no crunchy food .
F: so , it would be lunch afterwards .
B: was thinking , lunch after .
F: and they 'd have to do their digits or they don't get dessert .
D: they have to do their digits or they don't get they don't get their food .
B: had spoke with some people up at haas business school who volunteered . should pursue that ? they they originally they 've decided not to do go into speech . so 'm not whether they 'll still be so willing to volunteer , but 'll send an email and ask .
D: tell them about the free lunch .
B: 'll tell them about the free lunch . and they 'll say there 's no such thing .
F: 'd love to get people that are not linguists or engineers , cuz these are both weird
D: the the the oth the other
F: know , shouldn't say that .
B: that 's alright . no , the they 're very weird .
F: we need wider sampling .
A: "" beep . ""
B: the problem with engineers is "" beep . ""
D: they make funny sounds . the the other the other thing is , , that we talked about is give to them , burn an extra cd - rom .
B: let them have their meeting .
D: and give them so if they want {nonvocalsound} and audio record of their
F: that was he meant , "" give them music cd , "" like they then he said cd of the of their speech and it depends of what audience you 're talking to , but , personally {nonvocalsound} would not want {nonvocalsound} cd of my meeting ,
B: mmm . of the meeting ?
F: but maybe , maybe you 're
D: if you 're having some planning meeting of some sort and you 'd like
F: right . right . right .
A: that 's good idea .
B: it 'd be fun . it would just be fun , , if nothing else , . it 's novelty item .
D: but it als it it also builds up towards the goal . we 're saying , "" look , , you 're gonna get this . is - is isn't that neat . then you 're gonna go home with it . it 's actually it 's probably gonna be pretty useless to you , but you 'll ge appreciate , , where it 's useful and where it 's useless , and then , we 're gonna move this technology , so it 'll become useful . ""
F: no , that 's great idea , actually .
A: what if you could tell them that you 'll give them the transcripts when they come back ?
F: but we might need little more to incentivize them , that 's all .
B: anyone can have the transcripts . so . we could point that out .
F: that 's interesting .
E: hav have to raise little eensy - weensy concern about doing th giving them the cd immediately , because of these issues of , , this , where maybe ?
D: that 's very good point . so we can so we can
E: we could burn it after it 's been cleared with the transcript stage . and then they get cd , but just not the same day .
B: that 's right .
F: if it should be the same cd - rom that we distribute publically ,
B: that 's good point . right , it can't be the internal one .
F: otherwise they 're not allowed to play it for anyone .
E: there we go .
B: that 's right .
E: put . put . so , after the transcript screening phase .
B: that 's true .
E: things have been weeded out .
F: otherwise we 'd need two lawyer stages .
E: that 's right , say "" , , got this cd , and , your honor , ""
F: that 's good point .
D: so that 's so let 's start with haas , and .
F: to have to {nonvocalsound} have to leave .
D: that 's fine .
F: will be here full - time next week .
D: that 's alright . so , let 's see . so that was that topic , and then , another topic would be where are we in the whole disk resources question
B: we are slowly getting to the point where we have enough sp room to record meetings . so did bunch of archiving , and still doing bunch of archiving , 'm in the midst of doing the - files from , broadcast news . and it took eleven hours to do to copy it . and it 'll take another eleven to do the clone .
A: where did you copy it to ?
B: it 's abbott . it 's abbott , so it just but it 's it 's lot of data .
D: sk - it 's copying from one place on abbott to another place on abbott ?
A: on the tape .
B: did an archive . so 'm archiving it , and then 'm gonna delete the files . so that will give us ten gigabytes of free space .
E: the archiving program does take long time .
B: and so one that that will be done , like , in about two hours . and so , at that point we 'll be able to record five more meetings .
E: one thing the good news about that is that once it 's archived , it 's pretty quick to get back . it the other direction is fast , but this direction is really slow .
B: especially because 'm generating clone , also . so . and that takes while .
E: that 's good point .
B: one offsite , one onsite .
E: now , what will is the plan to to so will be saved , it 's just that you 're relocating it ? so we 're gonna get more disk space ?
B: no , the these are the - files from broadcast news , which are regeneratable if we really need to , but we had lot of them . and for the full , , hundred forty hour sets . and so they were two gigabytes per file and we had six of them .
D: we are getting more space . we are getting , , another disk rack and four thirty - six gigabyte disks . so but that 's not gonna happen instantaneously .
B: or maybe six .
D: or maybe six ?
B: the sun , ha , takes more disks than the andatico one did . the sun rack takes th - one took four and one took six , or maybe it was eight and twelve . whatever it was , it was , , fifty percent more .
A: is there difference in price ?
B: what happened is that we bought all our racks and disks from andatico for years , according to dave , and andatico got bought by another company and doubled their prices . and so , , we 're looking into other vendors . "" we "" by "" we "" dave .
A: 've been looking at the , , aurora data and , , first look at it , there were three directories on there that could be moved . one was called aurora , one was spanish , which was carmen 's spanish , and the other one was , , spine . and so , , wrote to dan and he was very concerned that the spine was moving to non - backed - up disk . so , , realized that , probably not all of that should be moved , just the cd - rom type data , the static data . so moved that , and then , asked him to check out and see if it was . before actually deleted the old , , but haven't heard back yet . told him he could delete it if he wanted to , haven't checked today to see if he 's deleted it or not . and then carmen 's , realized that when had copied all of her to xa , had copied there that was dynamic data . and so , had to redo that one and just copy over the static data . and so need to get with her now and delete the old off the disk . and then lo haven't done any of the aurora . have to meet with , , stephane to do that .
D: so , but , you 're figuring you can record another five meetings with the space that you 're clearing up from the broadcast news , but , we have some other disks , some of which you 're using for aurora , but are we do we have some other space now ?
B: so , so , , we have space on the current disk right now , where meeting recorder is , and that 's probably enough for about four meetings .
A: is that the one that has is that dc ?
B: no , no , it 's wherever the meeting recorder currently is . it 's di .
A: but the 'm moving from aurora is on the dc disk that we
B: th - it 's dc - it 's whatever that one is . don't remember , it might be dc . and that has enough for about four more meetings right now . we were at hundred percent and then we dropped down to eighty - six for reasons don't understand . someone deleted something somewhere . and so we have some room again . and then with broadcast news , that 's five or six more meetings , so , , we have couple weeks . so , , we 're , until we get the new disk .
A: so should , one question had for you was , , we need we sh probably should move the aurora an and all that other off of the meeting recorder disk . is there another backed - up disk that of that would ?
B: we should put it onto the broadcast news one . that 's probably the best thing to do . and that way we consolidate meeting recorder onto one disk rather than spreading them out .
A: do what happen to disk that is off ?
B: tell you , off the top of my head .
A: alright , 'll find out from you .
B: but , so we could ' jus just do that at the end of today , once the archive is complete , and 've verified it . cuz that 'll give us plenty of disk .
D: , @ @ so , , then th the last thing 'd had on my agenda was just to hear an update on what jose has been doing ,
C: have , , the result of my work during the last days . for your information because read . , and the last , , days , , work , , in my house , , in lot of ways and thinking , reading , different things about the meeting recording project . and have , , some ideas . this information is very useful . because you have the the distribution , now .
E: 'm glad to hear it . glad to hear it .
C: but for me , is interesting because , , here 's is the demonstration of the overlap , , problem .
B: 've seen it already .
C: it 's real problem , frequently problem , because you have overlapping zones , , all the time .
B: throughout the meeting .
C: by moment have , , nnn , the , , did mark of all the overlapped zones in the meeting recording , with , exact mark .
B: you did that by hand ?
C: heh ? that 's , yet , by by hand by hand because , , "" why . ""
B: can see that ? can get copy ?
C: my my idea is to work do don't @ @ , , if , , it will be possible because haven't lot , enough time to to work . , only just , six months , as , but , , my idea is , , is very interesting to work in the line of , , automatic segmenter . but , in my opinion , we need , reference session to to evaluate the the tool .
B: and so are you planning to do that or have you done that already ?
C: and no , no , with
B: have you done that or are you planning to do that ?
C: no , plan to do that . plan plan , but , the idea is the following . now , , need ehm , to detect all the overlapping zones exactly . will will , talk about , in the in the blackboard about the my ideas . , this information , with , exactly time marks , for the overlapping zones overlapping zone , and , speaker pure speech , speaker zone . zones of speech of , one speaker without any , noise , any acoustic event that , , is not , speech , real speech . and , need true , silence for that , because my idea is to study the nnn the set of parameters , what , , are more more discriminant to , classify . the overlapping zones in cooperation with the speech zones . the idea is to to use , 'm not to yet , but my idea is to use cluster algorithm or , nnn , person strong in neural net algorithm to to study what is the , , the property of the different feat feature , , to classify speech and overlapping speech . and my idea is , it would be interesting to have , control set . and my control set , will be the , silence without , any noise .
E: which means that we 'd still you 'd hear the
C: acoustic with this . with with , , the background .
E: that 's interesting . this is like ground level , with it 's not it 's not total silence .
C: , noise , claps , tape clips , , the difference , event , which , , has , , hard effect of distorti spectral distortion in the in the speech .
B: so so you intend to hand - mark those and exclude them ?
C: have mark in in that not in all in all the file , only , nnn , mmm , have , ehm don't remind what is the the quantity , but , have marked enough speech on over and all the overlapping zones . have , , two hundred and thirty , more or less , overlapping zones , and is similar to this information ,
E: great . great .
C: because with the program , cross the information of , of jane with , my segmentation by hand . and is , mor more similar .
E: glad to hear it .
C: and the idea is , , will use , , want my idea is , , to {nonvocalsound} to classify .
B: should 've got the digital camera .
C: need , the exact , mark of the different , , zones because want to put , , for , each frame label indicating . it 's sup supervised and , , hierarchical clustering process . put , , for each frame {nonvocalsound} label indicating what is th the type , what is the class , , which it belong . , the class you will {nonvocalsound} overlapping speech "" overlapping "" is class , , "" speech "" {nonvocalsound} @ @ the class that 's
A: these will be assigned by hand ?
C: ha put the mark by hand , because , , my idea is , , in the first session , need , , need , , to be that the information , that , , will cluster , is right . because , , if not , , will will , , return to the speech file to analyze , what is the problems ,
B: training , and validation . .
C: and 'd prefer would prefer , the to have , , this labeled automatically , but , , fro th need truth .
A: you need truth . .
B: but this is what you 're starting with .
E: 've gotta ask you . so , , the difference between the top two , so so start at the bottom , so "" silence "" is clear . by "" speech "" do you mean speech by one sp by one person only ? so this is un , and then the top includes people speaking at the same time , or speaker and breath overlapping , someone else 's breath , or clicking , overlapping with speech so , that 's all those possibilities in the top one .
B: one or two or more .
C: one , two , three . no , by th by the moment . . in the first moment , because , , have information , , of the overlapping zones , , information about if the , , overlapping zone is , , from speech , clear speech , from one to two speaker , or three speaker , or is the zone where the breath of speaker , overlaps , onto , speech , another , especially speech .
E: so it 's basi it 's speech wi som with something overlapping , which could be speech but doesn't need to be .
C: no , no , es especially , overlapping speech from , , different , speaker .
D: no , but there 's but , she 's saying "" where do you in these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? "" which category do you put that in ?
E: that 's right . that 's my question .
C: he here put speech from , from , , one speaker without , , any any events more .
D: right , so where do you put speech from one speaker that does have nonspeech event at the same time ?
C: where ? where what is the class ?
D: which catege which category ?
C: no . by the moment , no .
B: , that 's what he was saying before .
C: for for the by the @ @ no , @ @ because want to limit the nnn , the study .
D: so you not marked .
E: so you don't it 's not in that
D: fine . so so
A: so you 're not using all of the data .
B: so that 's what he was saying before , is that he excluded those .
C: the all exactly .
E: so you 're ignoring overlapping events unless they 're speech with speech .
D: that 's fine .
C: what 's the reason ? "" because it 's the first study .
D: no , it 's perfectly sensible way to go . we just wondered trying to understand what you were doing .
E: cuz you 've talked about other overlapping events in the past . so , this is subset .
C: in the in the future , the idea is to extend the class , to consider all the all the information , you mentioned before
D: , don't think we were asking for that .
C: but , the first idea because , what hap what will happen with the study .
D: we were jus just trying to understand
E: we just wanted to the category was here .
A: is your silence category pure silence , or ? what if there was door - slam ?
C: no , no , it 's pure silence . it 's the control set . it 's the control set . it 's pure si pure silence with the machine on the on the roof .
D: what you what you mean is that it 's nonspeech segments that don't have impulsive noises .
B: with the fan .
D: cuz you 're calling what you 're calling "" event "" is somebody coughing or clicking , or rustling paper , or hitting something , which are impulsive noises . but steady - state noises are part of the background . which , are being , included in that .
C: here yet , yet , , there are that some noises that , , don't don't wanted to be in that , , in that control set .
E: so it 's like signal - noise situation .
C: but prefer , prefer at the first , , the silence with , this this the of of noise .
D: right , it 's , it 's "" background "" might be might be better word than "" silence "" . it 's just that the background acoustic
B: right . so fine . go on .
C: and , , with this information the idea is , nnn , have label for each , , frame and , with cluster algorithm and
E: we needed to get the categories , .
C: and am going to prepare test bed , , , , set of feature structure , models . and my idea is
B: "" tone "" , whatever .
C: so on because have pitch extractor yet . have to test , but
A: you have your own ?
C: ha have prepare . is modified version of of pitch tracker , , from , , standar - stanford university from , , , cambridge university .
A: what 's it written in ?
C: , don't remember what is the name of the of the author , because have several have , , , library tools , from , festival and of from edinburgh , from cambridge , , and from our department .
D: - . - .
C: and have to because , in general the pitch tracker , doesn't work very and
B: but , , as feature , it might be . so , we .
C: this this is and th the idea is to , , to obtain , , , , diff , different , no , great number of fec , , , twenty - five , , thirty parameters , , for each one . and in first , nnn , step in the investi in the research in , my idea is try to , , to prove , what is the performance of the difference parameter , to classify the different , , what is the the front - end approach to classify , the different , , frames of each class and what is the , nnn , nnn , , what is the , the error , of the data this is the , first idea and the second is try to , to use some ideas , similar to the linear discriminant analysis . similar , because the idea is to study what is the contribution of , each parameter to the process of classify correctly the different the different parameters .
B: what classifier ar ?
C: the the classifier is nnn by the moment is is , similar , nnn , that the classifier used , in quantifier vectorial quantifier is , used to , some distance to put , vector , in class different . is ? with model , is only to cluster using , @ @ or similarity .
B: so is it just one cluster per
C: another possibility it to use netw neural network . but what 's the what is my idea ? what 's the problem see in in if you use the neural network ? if when this , mmm , cluster , clustering algorithm to can test , to can observe what happened you can't you can't , put up with your hand in the different parameter ,
B: right , you can't analyse it .
C: but if you use neural net is good idea , but you what happened in the interior of the neural net .
D: actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are . it 's hard to what you it 's hard to tell on neural net is what 's going on internally . but it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized .
B: using something simpler first is probably fine .
D: this isn't tru if if you really wonder what different if then decision tree is really good , but here he 's he 's not like he has one , bunch of very distinct variables , like pitch and this he 's talking about , like , all these cepstral coefficients , and , in which case any reasonable classifier is gonna be mess , and it 's gonna be hard to figure out what
C: will include too the the differential de derivates too .
D: the other thing that one , this is , good thing to do , to look at these things at least see what 'd let me tell you what would do . would take just few features . instead of taking all the mfcc 's , or all the plp 's or whatever , would just take couple . like like - one , - two , something like that , so that you can visualize it . and look at these different examples and look at scatter plots . so before you do build up any fancy classifiers , just take look in two dimensions , at how these things are split apart . that will give you lot of insight of what is likely to be useful feature when you put it into more complicated classifier . and the second thing is , once you actually get to the point of building these classifiers , @ @ what this lacks so far is the temporal properties . so if you 're just looking at frame and time , you anything about , , the structure of it over time , and so you may wanna build @ @ build markov model of some sort , or else have features that really are based on on some bigger chunk of time . but this is good place to start . but don't anyway , this is my suggestion , is don't just , , throw in twenty features at it , the deltas , and the delta del and all that into some classifier , even if it 's - nearest - neighbors , you still won't know what it 's doing , even it 's to it 's to have better feeling for what it 's look at som some picture that shows you , "" here 's these things , are offer some separation . "" and , , in lpc , , the thing to particularly look at is , is something like , , the residual
E: it strikes me that there 's another piece of information , that might be useful and that 's simply the transition . so , if you go from transition of silence to overlap versus transition from silence to speech , there 's gonna be big informative area there , it seems to me .
C: . but is my my own vision , of the of the project . the meeting recorder project , for me , has , two , has several parts , several objective because it 's great project . but , at the first , in the acoustic , , parts of the project , you we have two main objective . one one of these is to to detect the change , the acoustic change . and for that , if you don't use , , , speech recognizer , broad class , or not broad class to try to to label the different frames , the ike criterion or bic criterion will be enough to detect the change . and probably . would like to prove . probably . when you have , the transition of speech or silence to overlap zone , this criterion is enough with probably with , , this , the the more use used normal , regular parameter mf - mfcc . you have to to find you can find the mark . you can find the nnn , the acoustic change . but understand that you your objective is to classify , to know that that zone not is only new zone in the in the file , that you have , but you have to to know that this is overlap zone . because in the future you will try to process that zone with non - regular speech recognizer model , suppose . you will pretend to process the overlapping zone with another algorithm because it 's very difficult to to obtain the transcription from using regular , normal speech recognizer . that , , is the idea . and so the , nnn the {nonvocalsound} the system will have two models . model to detect more acc the mor most accurately possible that is , will be possible the , the mark , the change and another model will @ @ or several models , to try but several model robust models , sample models to try to classify the difference class .
B: 'm 'm , didn't understand you what you said . what what model ?
C: the classifiers of the to detect the different class to the different zones before try to recognize , with to transcribe , with speech recognizer . and my idea is to use , , neural net with the information we obtain from this this study of the parameter with the selected parameter to try to to put the class of each frame . for the difference zone you , have obtained in the first , step with the , bic , criterion compare model
D: but , in any event we 're that the first step is because what we had before for , speaker change detection did not include these overlaps . so the first thing is for you to build up something that will detect the overlaps . so again , the first thing to do to detect the overlaps is to look at these , in in again , the things you 've written up there are way too way too big . ? if you 're talking about , say , twelfth - order mfcc 's like that it 's just way too much . you won't be able to look at it . all you 'll be able to do is put it into classifier and see how it does . whereas if you have things if you pick one or two dimensional things , or three of you have some very fancy display , , and look at how the different classes separate themselves out , you 'll have much more insight about what 's going on .
C: it will be enough .
D: you 'll you 'll get feeling for what 's happening , , so if you look at suppose you look at first and second - order cepstral coefficients for some one of these kinds of things and you find that the first - order is much more effective than the second , and then you look at the third and there 's not and not too much there , you may just take first and second - order cepstral coefficients , and with lpc , lpc per se isn't gonna tell you much more than than the other , maybe . and on the other hand , the lpc residual , the energy in the lpc residual , will say how , the low - order lpc model 's fitting it , which should be pretty poorly for two or more people speaking at the same time , and it should be pretty , for for one . and so again , if you take few of these things that are prob promising features and look at them in pairs , , you 'll have much more of sense of "" , now have , doing bunch of these analyses , now have ten likely candidates . "" and then you can do decision trees or whatever to see how they combine .
A: 've got question .
C: but , it is the first way to do that and would like to , your opinion . all this study in the in the first moment , will pretend to do with equalizes speech . the the equalizes speech , the speech , the mixes of speech .
B: right . mixed .
C: the mix , mixed speech .
E: "" mixed "" . .
C: because the spectral distortion is more lot clearer , very much clearer if we compare with the pda . pda speech file is it will be difficult .
E: so it 's messier . the the pda is messier .
C: fff ! because the the noise to sp the signal - to - noise relation is is low .
B: that 's good way to start .
C: that the result of the of the study with with this this speech , the mix speech will work exactly with the pda files .
B: it would be interesting in itself to see . that would be an interesting result .
C: what , , what is the effect of the low ' signal to to noise relation , , with
D: it 's not it 's not unreasonable . it makes sense to start with the simpler signal because if you have features which don't aren't even helpful in the high signal - to - noise ratio , then there 's no point in putting them into the low signal ratio , one would think , anyway . and so , if you can get @ @ again , my prescription would be that you would , with mixed signal , you would take collection of possible , features look at them , look at how these different classes that you 've marked , separate themselves , and then collect , in pairs , and then collect ten of them , and then proceed with bigger classifier . and then if you can get that to work , then you go to the other signal . and then , and , they won't work as , but how , how much and then you can re - optimize , and so on .
B: but it it would be interesting to try couple with both . because it it would be interesting to see if some features work with close mixed , and and don't
D: that 's , the it it 's true that it also , it could be useful to do this exploratory analysis where you 're looking at scatter plots and so on in both cases . .
C: that the parameter we found , worked with both , speech file ,
E: that 's good .
C: but what is the the relation of of the performance when you use the , speech file the pda speech files . but it it will be important . because people , different groups has experience with this problem . is is not easy to solve , because if you have seen the the speech file from pda , and some parts is very difficult because you don't see the spectrum the spectrogram .
B: they 're hidden .
C: is very difficult to apply , parameter to detect change when you don't see .
D: that that 's another reason why very simple features , things like energy , and things like harmonicity , and residual energy are , are better to use than very complex ones because they 'll be more reliable .
B: are probably better , .
C: will put the energy here .
D: ch - chuck was gonna ask something .
C: you have question .
A: maybe this is dumb question , but it would be it would be easier if you used pda because can't you , couldn't you like use beam - forming to detect speaker overlaps ?
B: if you used the array , rather than the signal from just one .
D: no , you 're you 're right that , if we made use of the fact that there are two microphones , you do have some location information . which we don't have with the one and so that 's
A: is that not allowed with this project ?
D: , no , , we don't have any rules , really .
A: but didn't mean given given the goal .
D: it 's it 's it 's an additional interesting question .
A: is that violation of the
D: you wanna know whether you can do it with one , because it 's not necessarily true that every device that you 're trying to do this with will have two . if , on the other hand , we show that there 's huge advantage with two , then that could be real point . but , we don't even know yet what the effect of detecting having the ability to detect overlaps is . maybe it doesn't matter too much . so , this is all pretty early stages . but no , you 're right . that 's good thing to consider .
E: there there is complication though , and that is if person turns their back to the to the pda , then some of the positional information goes away ?
D: it it does , it it does , but the the issue is that
A: no , it 's not it 's not that so much as
E: and then , and if they 're on the access on the axis of it , that was the other thing was thinking . he you mentioned this last time , that if you 're straight down the midline , then the the left - right 's gonna be different ,
B: we hav need to put it on little turntable ,
E: and and in his case , , he 's closer to it anyway . it seems to me that it 's not , , it 's this the topograph the topology of it is little bit complicated .
B: but it 's another source of information .
C: because the distance between the two microph , microphone , , in the pda is very near . but it 's from my opinion , it 's an interesting idea to try to study the binaural problem , with information , because found difference between the speech from each micro , in the pda .
D: it 's timing difference . it - it 's not amplitude ,
E: ! agree ! and we use it ourselves . know that 's very important cue . but 'm just 'm just saying that the way we 're seated around table , is not the same with respect to each to each person with respect to the pda ,
C: no , no .
E: so we 're gonna have lot of differences with ref respect to the speaker .
D: that 's that 's fine .
A: but th don't think that matters , though .
D: that 's so so @ @ the issue is , "" is there clean signal coming from only one direction ? "" if it 's not coming from just one direction , if it if th if there 's broader pattern , it means that it 's more likely there 's multiple people speaking , wherever they are .
A: so it 's like how confused is it about where the beam is .
D: is it is it is there narrow is there narrow beam pattern or is it distributed beam pattern ? so if there 's distributed beam pattern , then it looks more like it 's it 's , multiple people . wherever you are , even if he moves around .
E: , it just it just seemed to me that , that this isn't the ideal type of separation . it 's see the value
D: ideal would be to have the wall filled with them , but but just having two mikes if you looked at that thing on dan 's page , it was when when there were two people speaking , and it looked really different .
A: what looked different ?
D: , basic he was looking at correlation .
B: cross - co cross - correlation .
D: just cross - correlation between two sides .
A: did - , 'm not what dan 's page is that you mean . he was looking at the two
D: so cross - correlation is pretty sensitive .
E: his web page .
D: you take the signal from the two microphones and you cros and you cross - correlate them with different lags .
B: and you find they get peaks .
D: so when one person is speaking , then wherever they happen to be at the point when they 're speaking , then there 's pretty big maximum right around that point in the in the lag . so if at whatever angle you are , at some lag corresponding to the time difference between the two there , you get this boost in the in the cross - correlation value function .
A: so so if there 's two
B: and if there are multiple people talking , you 'll see two peaks .
D: it 's spread out .
E: let me ask you , if both people were over there , it would be less effective than if one was there and one was across , catty - corner ?
D: the - the , 'm , if they 're right next to one another ?
A: if was if was here and morgan was there and we were both talking , it wouldn't work .
E: next next one over over on this side of the pda . there we go . good example , the same one 'm asking . versus you versus , and we 're catty - corner across the table , and 'm farther away from this one and you 're farther away from that one .
B: or or even if , like , if people were sitting right across from each other , you couldn't tell the difference either .
E: it seems like that would be pretty strong . across the same axis , you don't have as much to differentiate .
D: we , we don't have third dimension there . , so it 's
E: and so my point was just that it 's it 's gonna be differentially varia valuable . it 's not to say , certainly 's extremely val and we humans depend on , these binaural cues .
D: but it 's almost but it 's almost what you 're talking about there 's two things .
B: must do . .
D: there 's sensitivity issue , and then there 's pathological error issue . so th the one where someone is just right directly in line is pathological error . if someone just happens to be sitting right there then we won't get good information from it .
E: and and if there so it and if it 's the two of you guys on the same side
D: if they 're if they 're close , it 's just question of the sensitivity . so if the sensitivity is good enough and we just we just don't have enough , , experience with it to know how
E: 'm not 'm not trying to argue against using it , by any means . wanted to point out that weakness , that it 's topo topologically impossible to get it perfect for everybody .
B: and dan is still working on it . so . he actually he wrote me about it little bit ,
E: no , don't mean to discourage that .
D: the other thing you can do , if , we 're assuming that it would be big deal just to get somebody convince somebody to put two microphones in the pda . but if you put third in , you could put in the other axis . and then then you 're , then you could cover
A: once you got two what about just doing it from these mikes ?
C: it will be more interesting to study the pzm because the the separation
D: @ @ but - but that 's , we can we 'll be all of this is there for us to study .
B: then they 're much broader . we can do whatever we want .
D: but but , , one of the at least one of the things was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has pda .
B: whatever you 're interested in .
A: that 's what was asking about , what are the constraints ?
D: that 's that 's the constraint of one question that both adam and were were interested in . but if you can instrument room , this is really minor league compared with what some people are doing , right ? some people at , , at brown and at and at cape ,
B: big micro @ @ arrays .
A: didn't they have something at cape ?
D: they both have these , , big arrays on the wall . and , if you could do that , you 've got microphones all over the place tens of microphones ,
A: ! saw demo .
C: right , , .
D: and if you do that then you can really get very selectivity
B: saw one that was like hundred microphones , ten by ten array .
A: and you could in noisy room , they could have all kinds of noises and you can zoom right in on somebody .
B: and they had very precision .
C: very complex , .
D: ye - . .
B: it was all in software and they and you could pick out an individual beam and listen to it . it was , it was interesting .
D: but , the reason why haven't focused on that as the fir my first concern is because , 'm interested in what happens for people , random people out in some random place where they 're having an impromptu discussion . and you can't just always go , "" , let 's go to this heavily instrumented room that we spent tens of thousands of dollars to se to set up "" .
A: no , what you need to do is you 'd have little fabric thing that you unroll and hang on wall . it has all these mikes and it has plug - in jack to the pda .
D: the other thing actually , that gets at this little bit of something else 'd like to do , is what happens if you have two and they communicate with each other ? and then , they 're in random positions , the likelihood that , there wouldn't be any likely to be any nulls , if you even had two . if you had three or four it 's .
B: that 's on my web pages . all sorts of interesting things you can do with that , not only can you do microphone arrays , but you can do all sorts of multi - band as . so it 's it would be neat .
A: still like my rug on the wall idea , so if anybody patents that , then
E: you could have strips that you stick to your clothing .
B: in terms of the research th research , it 's really it 's whatever the person who is doing the research wants to do . so if jose is interested in that , that 's great . but if he 's not , that 's great too .
D: would actually like us to wind it down , see if we can still get to the end of the , , birthdays thing there .
B: catch some tea ? had couple things that did wanna bring out . one is , do we need to sign new these again ?
E: it 's slightly different . so would say it would be good idea .
A: are they new ?
E: cuz it 's slightly different .
D: this morning we didn't sign anything cuz we said that if anybody had signed it already , we didn't have to .
B: should 've checked with jane first , but the ch the form has changed .
E: it 's slightly different .
B: so we may wanna have everyone sign the new form . had some things wanted to talk about with the thresholding 'm doing .
E: had to make one
B: but , if we 're in hurry , we can put that off . and then also anonymity , how we want to anonymize the data .
E: should have some results to present , but we won't have time to do that this time . but it seems like the anonymization is , is also something that we might wanna discuss in greater length . if if we 're about to wind down , what would prefer is that we , delay the anonymization thing till next week , and would like to present the results that have on the overlaps .
A: we still have to do this , too , right ?
B: no - , we don't have to do digits .
D: so @ @ . @ @ it sounds like , there were there were couple technical things people would like to talk about . why don't we just take couple minutes to briefly do them , and then and then and then we
B: go ahead , jane .
E: 'd , 'd prefer to have more time for my results . could do that next week maybe ? that 's what 'm asking . and the anonymization , if if you want to proceed with that now , think that 's that 's discussion which also really deserves lo , more that just minute . really do think that , because you raised couple of possibilities yourself , you and have discussed it previously , and there are different ways that people approach it , and we should
B: we 're we 're just we 're getting enough data now that 'd like to do it now , before get overwhelmed with once we decide how to do it going and dealing with it .
E: . 'll give you the short version , but do 's an issue that we can't resolve in five minutes . so the short thing is , we have , tape recording , , digitized recor recordings . those we won't be able to change . if someone says "" hey , roger so - and - so "" . so that 's gonna stay that person 's name . now , in terms of like the transcript , the question becomes what symbol are you gonna put in there for everybody 's name , and whether you 're gonna put it in the text where he says "" hey roger "" or are we gonna put that person 's anonymized name in instead ?
B: no , because then that would give you mapping , and you don't wanna have mapping .
E: so first decision is , we 're gonna anonymize the same name for the speaker identifier and also in the text whenever the speaker 's name is mentioned .
B: because that would give you mapping between the speaker 's real name and the tag we 're using , and we don't want
E: don't think you understood what what said . so , so in within the context of an utterance , someone says "" so , roger , what do you think ? "" then , , it seems to me that , maybe it seems to me that if you change the name , the transcript 's gonna disagree with the audio , and you won't be able to use that .
A: right , you don't wanna do that .
B: we don't we wanna we ha we want the transcript to be "" roger "" . because if we made the transcript be the tag that we 're using for roger , someone who had the transcript and the audio would then have mapping between the anonymized name and the real name , and we wanna avoid that .
E: , but then there 's this issue of if we 're gonna use this for discourse type of thing , then and , , liz was mentioning in previous meeting about gaze direction and who 's who 's the addressee and all , then to have "" roger "" be the thing in the utterance and then actually have the speaker identifier who was "" roger "" be "" frank "" , that 's going to be really confusing and make it useless for discourse analysis .
B: that 's good point .
E: now , if you want to , , , in some cases , know that susan ervin - tripp in some of hers , , actually did do , , filter of the signal where the person 's name was mentioned , except
D: once you get to the publication you can certainly do that .
E: and and cer and so , , the question then becomes one level back . how important is it for person to be identified by first name versus full name ? on the one hand , , it 's not full identity , we 're taking all these precautions , and they 'll be taking precautions , which are probably even the more important ones , to they 'll be reviewing the transcripts , to see if there 's something they don't like . so , maybe , , maybe that 's enough protection . on the other hand , this is small this is small pool , and people who say things about topic who are researchers and - known in the field , they 'll be identifiable and simply from the from the first name . however , taking one step further back , they 'd be identifiable anyway , even if we changed all the names . so , is it really , ? now , in terms of like so did some results , which 'll report on next time , which do mention individual speakers by name . now , there , the human subjects committee is very precise . you don't wanna mention subjects by name in published reports . now , it would be very possible for me to take those data put them in in study , and just change everybody 's name for the purpose of the publication . and someone who looked
D: you can go , , , "" "" , . , , , it doesn't , 'm not knowledgeable about this , but it certainly doesn't bother me to have someone 's first name in the in the transcript .
E: that 's the same thing you saw .
D: you don't wanna have their full name to be , listed .
E: and in the form that they sign , it does say "" your first name may arise in the course of the meetings "" .
D: so again , th the issue is if you 're tracking discourse things , , if someone says , , "" frank said this "" and then you wanna connect it to something later , you 've gotta have this part where that 's "" frank colon "" .
E: or "" your name "" . and , even more , immediate than that just being able to , , it just seems like to track from one utterance to the next utterance who 's speaking and who 's speaking to whom , cuz that can be important . "" you raised the point , so - and - so "" , it 's be to be able to know who "" you "" was .
B: 'm thinking too much .
E: and ac and actually you remember furthermore , you remember last time we had this discussion of how , was avoiding mentioning people 's names ,
D: was too . .
E: and it was and we made the decision that was artificial . , if we 're going to step in after the fact and change people 's names in the transcript , we 've done something one step worse .
B: would sug don't wanna change the names in the transcript , but that 's because 'm focused so much on the acoustics instead of on the discourse , and so that 's really good point . you 're right , this is going to require more thought .
D: let me just back up this to make brief comment about the , , what we 're covering in the meeting . realize when you 're doing this that , didn't realize that you had bunch of things that you wanted to talk about . and so , and so was proceeding some somewhat at random , frankly . so what would be helpful would be , and 'll 'll mention this to liz and andreas too , that , before the meeting if anybody could send me , any , , agenda items that they were interested in and 'll 'll take the role of organizing them , into the agenda , but 'd be very pleased to have everyone else completely make up the agenda . 've no desire to make it up , but if no one 's told me things , then 'm just proceeding from my guesses , and , and ye , 'm it ended up with your out your time to , 'm just always asking jose what he 's doing , , and so it 's there 's , there 's other things going on .
E: it 's not problem . not problem . . couldn't do it in two minutes .
B: how will we how would the person who 's doing the transcript even know who they 're talking about ? do what 'm saying ?
A: "" the person who 's doing the transcript "" the ibm people ?
B: so how is that information gonna get labeled anyway ?
E: how do you mean , who what they 're who they 're talking about ?
B: so if 'm saying in meeting , "" and bob , , wanted to do so - and - so "" ,
E: how do you mean ?
A: they 're just gonna write "" bob "" on it or do @ @
B: if you 're doing @ @ they 're just gonna write "" bob "" . and so . if you 're if you 're doing discourse analysis ,
E: they won't be able to change it themselves .
D: what ar how are they gonna do any of this ?
E: 'm betting we 're gonna have huge chunks that are just un untranscribable by them .
D: they 're gonna say speaker - one , or speaker - two or speaker
A: they can't do that .
B: the current one they don't do speaker identity . because in naturallyspeaking , or , excuse me , in viavoice , it 's only one person . and so in their current conventions there are no multiple speaker conventions .
D: so it may just be one long transcript of bunch of words .
E: that my understanding from yen is it yen - ching ? is that how you pronounce her name ?
D: yu - ching , yu - ching . .
E: yu - ching ? yu - ching ?
B: yu - ching .
E: was that , they will that they will adopt the part of the conventions that we discussed , where they put speaker identifier down . but , , they won't know these people , so it 's , they 'll they 'll adopt some convention but we haven't specified to them so they 'll do something like speaker - one , speaker - two , is what bet , but 'm betting there 'll be huge variations in the accuracy of their labeling the speakers . we 'll have to review the transcripts in any case .
D: and it and it may very be , since they 're not going to sit there and and worry ab about , , it being the same speaker , they may very go the the first se the first time it changes to another speaker , that 'll be speaker - two . and the next time it 'll be speaker - three even if it 's actually speaker - one .
E: that would be very practical solution on their part .
C: it 's good idea .
E: and and but then we would need to label it .
B: we can probably regenerate it pretty easily from the close - talking mikes .
E: and that 's . yes , was thinking , the temp the time values of when it changes .
B: so . but that doesn't this doesn't answer the question .
E: that 'd be very efficient .
B: the it 's good point , "" which what do you do for discourse tracking ? ""
C: because you to know , you don't need to what is the iden identification of the of the speakers . you only want to know
B: for for acoustics you don't but for discourse you do .
C: for discourse , . .
D: if if someone says , , "" what is jose doing ? "" and then jose says something , you need to know that was jose responding .
B: ugh , that 's problem .
E: unless we adopt different set of norms which is to not id to make point of not identifying people by name , which then leads you to be more contextually ex explicit .
A: that would be hard .
E: people are very flexible . ? , so when we did this las last week , felt that , now , andreas may , , @ @ , he sometimes people think of something else at the same time and they miss sentence , and because he missed something , then he missed the the initial introduction of who we were talking about , and was unable to do the tracking . but felt like most of us were doing the tracking and knew who we were talking about and we just weren't mentioning the name . so , people are really flexible .
A: but , , like , at the beginning of this meeting or , you said , , or liz , said something about , , "" is mari gonna use the equipment ? "" how would you say that ? you have to really think , , about what you 're saying bef
B: if you wanted to anonymize .
D: "" is who up in where ? "" right ? use the
A: it would be really hard if we made policy where we didn't say names , plus we 'd have to tell everybody else .
B: what was gonna say is that the other option is that we could bleep out the names . but then , again that kills your discourse analysis .
A: the , my own two cents worth is that you don't do anything about what 's in the recordings , you only anonymize to the extent you can , the speakers have signed the forms and all .
E: that 's that 's the issue .
B: but that but that as said , that that works great for the acoustics , but it hurts you lot for trying to do discourse . because you don't have map of who 's talking versus their name that they 're being referred to .
A: we were gonna get it labelled speaker - one , speaker - two
B: but , then you have to know that jose is speaker - one and
A: why do you have to know his name ?
D: so suppose someone says , "" if really heard what , what jose said . "" and then , jose responds . and part of your learning about the dialogue is jose responding to it . but it doesn't say "" jose "" , it says "" speaker - five "" .
A: see , you wanna associated the word "" jose "" in the dialogue with the fact that then he responded .
B: someone who 's doing discourse would wanna do that .
D: and so , if we pass out the data to someone else , and it says "" speaker - five "" there , we also have to pass them this little guide that says that speaker - five is jose ,
B: and that violates our privacy .
D: and if were gonna do that we might as give them "" jose "" say it was "" jose "" .
B: and that violates our privacy issue .
E: now , that we have these two phases in the in the data , which is the one which is our use , university of washington 's use , ibm , sri . and within that , it may be that it 's sufficient to not change the to not incorporate anonymization yet , but always , always in the publications we have to . and also , when we take it that next step and distribute it to the world , we have to . but but don that 's that 's long way from now and it 's matter of between now and then of of deciding how
B: making some decisions ?
E: it , it may be that we 'll need to do something like actually out that part of the the audio , and just put in brackets "" speaker - one "" .
B: for the public one . what we could do also is have more than one version of release . one that 's public and one that requires licensing . and so the licensed one would we could it would be sticky limitation . we can talk about that later .
E: that 's risky . that the public should be the same . that when we do that world release , it should be the same .
D: agree with jane .
E: for bunch of reasons , legal .
D: that we have need to have consistent licensing policy of some sort , and
E: but also think consistent licensing policy is important .
A: one thing to take into consideration is are there any , the people who are funding this work , they want this work to get out and be useful for discourse . if we all of sudden do this and then release it to the public and it 's not longer useful for discourse ,
B: depending on how much editing we do , you might be able to still have it useful . because for discourse you don't need the audio . so you could bleep out the names in the audio . and use the anonymized one through the transcript .
A: but if you release both
E: excuse me . we we do need audio for discourse .
B: but , excuse me , but you could bleep out just the names .
D: no , but she 's saying , from the argument before , she wants to be able to say if someone said "" jose "" in their in their thing , and then connect to so to what he said later , then you need it .
B: but in the transcript , you could say , everywhere they said "" jose "" that you could replace it with "" speaker - seven "" .
E: but also wanna say that people
B: and then it wouldn't meet match the audio anymore . but it would be still useful for the
A: but if both of those are publically available
E: that 's good .
D: and th and the other thing is if if liz were here , what she might say is that she wants to look if things that cut across between the audio and the dialogue ,
E: you see ? so , it 's complicated .
D: and so , ,
E: we have to think about @ @ how . that this can't be decided today .
B: , good point .
E: but it 's but it was good to introduce the thing and we can do it next time .
B: didn't think when wrote you that email wasn't thinking it was big can of worms , but it is .
D: lot of these things are .
E: it discourse , also wanted to make the point that discourse is gonna be more than just looking at transcript . it 's gonna be looking at , and prosod prosodic is involved , and that means you 're going to be listening to the audio , and then you come directly into this confronting this problem .
A: maybe we should just not allow anybody to do research on discourse , and then , we wouldn't have to worry about it .
E: we should just market it to non - english speaking countries .
D: maybe we should only have meetings between people who one another and who are also amnesiacs who their own name .
B: did you read the paper on eurospeech ?
E: we could have little labels . wanna introduce my reservoir dogs solution again , which is everyone has like "" mister white "" , "" mister pink "" , "" mister blue "" .
B: did you read the paper few years ago where they were reversing the syllables ? they were di they had the utterances . and they would extract out the syllables and they would play them backwards .
A: but so , the syllables were in the same order , with respect to each other , but the acous
B: everything was in the same order , but they were the individual syll syllables were played backwards . and you could listen to it , and it would sound the same .
A: what did it sound like ?
B: people had no difficulty in interpreting it . so what we need is something that 's the reverse , that speech recognizer works exactly the same on it but people can't understand it .
D: that 's there 's an easy way to do that . jus - jus just play it all backwards .
B: right . the speech recognizer 's symmetric , isn't it .
D: what , what does the speech recognizer care ?
E: do we do digits ? or ? what do we do ?
B: we 'll quickly do digits .
D: let 's do digits . we we already missed the party .
E: or do we just quit ?
B: go off here .
A: it would be fun sometime to read them with different intonations . like as if you were talking like , "" nine eight six eight seven ? ""
E: , in the in the one transcribed , did find couple instances found one instance of contrastive stress , where it was like the string had li so it was like "" nine eight two four , nine two four "" .
A: so they were like looking ahead ,
E: at that session did feel like they did it more as sentences . but , , sometimes people do it as phone numbers . , 've am interested in and sometimes , , and never know . when do it , ask myself what 'm doing each time .
A: was thinking that it must get boring for the people who are gonna have to transcribe this they may as throw in some interesting intonations .
E: like your question intonation . that 's very funny . haven't heard that one .
B: we have the transcript . we have the actual numbers they 're reading , so we 're not necessarily depending on that . 'm gonna go off .
","The Berkeley Meeting Recorder group discussed research aims and corresponding concerns for future data collection.
It was agreed that a substantial amount of meeting data is required from different domains , and comprising several speakers , to perform the types of discourse and acoustic analyses desired.
Ongoing efforts by speaker mn005 to automatically  detect regions of speaker overlap were considered.
It was suggested that speaker mn005 focus on a small set of acoustic parameters , e.g . energy and harmonics-related features , to distinguish regions of overlap from those containing the speech of just one speaker.
Disk space issues were discussed.
And , finally , the problem of speaker anonymization was explored.
Recordings must be of existing meetings that are conducted in English.
Participants should ideally consist of professors and doctoral students , but no undergraduate students , who are willing to record their meetings at ICSI.
The Meeting Recorder corpus should comprise data from a large number of speakers representing different domains.
Attempts should also be made to optimize the speaker population for generating good language models.
Speaker me011 will pursue volunteers from the Haas Business School to record their weekly meetings at ICSI.
A tentative decision was made to offer participants a recorded version of their meeting on a cd rom once the transcript screening phase is complete for that meeting.
Non-native speakers with a low proficiency in English are problematic for language modelling.
The prospect of creating another recording setup requires the elimination certain more complicated dimensions of the existing setup , e.g . the use of close-talking and far-field microphones.
Speaker anonymization poses problems for the transcription proccess , and also discourse analysis , as it makes it more difficult to track who is speaking and to whom a particular utterance is being addressed.
As the current version of transcriptions does not include speaker identification labels , no multiple speaker transcription conventions are in use.
Research aims and corresponding concerns for future data collection were discussed.
A student researcher will be working with speaker fe016 to investigate different strategies for automatically summarizing meetings , and identifying discussional 'hotspots'.
Efforts by speaker mn005 are ongoing to detect regions of speaker overlap in the signal.
A total of 230 regions of overlapping speech have been manually transcribed for a subset of meeting data.
Supervised clustering and neural networks are being considered as means for classifying overlap.
It was suggested that speaker mn005 focus on a small set of acoustic parameters , e.g . energy and harmonics-related features , to use the mixed signal to distinguish regions of overlap from those containing the speech of just one speaker.
Future work may also involve focussing on additional signals , and using a Markov model to analyze acoustic parameters over larger time frames.
Beam-forming was suggested as an alternate method of detecting overlapping speech.
Efforts are ongoing to select an optimal method for anonymizing speakers.
More disk space is gradually being made available for the storage of new Meeting Recorder data.
"
ami_abstractive_summary,Bro025.txt,"A: alright . we 're on .
B: test , . test , test . that 's me . there 's two sheets of paper in front of us .
A: what are these ?
B: this is the arm wrestling ?
C: , we formed coalition actually . we already made it into one .
B: that 's the best thing . so , tell me about it .
E: so it 's , it 's spectral subtraction or wiener filtering , depending on if we put if we square the transfer function or not . and then with over - estimation of the noise , depending on the , the snr , with smoothing along time , smoothing along frequency . it 's very simple , smoothing things . and , , the best result is when we apply this procedure on fft bins , , with wiener filter . and there is no noise addition after that . so it 's good because it 's difficult when we have to add noise to to find the right level .
A: are you looking at one in particular of these two ?
E: so the sh it 's the sheet that gives fifty - three point sixty - six . the second sheet is abo , about the same . it 's the same , , idea but it 's working on mel bands , and it 's spectral subtraction instead of wiener filter , and there is also noise addition after , , cleaning up the mel bins . the results are similar .
B: , it 's it 's actually , , very similar . if you look at databases , the , , one that has the smallest smaller overall number is actually better on the finnish and spanish , but it is , , worse on the , , aurora
E: it 's worse on
B: on the , , ti - digits ,
E: on the multi - condition in ti - digits . .
B: so , it probably doesn't matter that much either way . but , , when you say , unified do you mean , , it 's one piece of software now ,
E: so now we are , , setting up the software . it should be ready , , very soon .
A: so what 's what 's happened ? 've missed something .
B: maybe you weren't around when when hynek and guenther and ?
C: hynek was here .
B: . so , let 's summarize . and then if summarize somebody can tell me if 'm wrong , which will also be possibly helpful . what did press here ? hope this is still working . we , we looked at , {nonvocalsound} anyway we after coming back from qualcomm we had , , very strong feedback and , , it was hynek and guenter 's and my opinion also that , , , we spread out to look at number of different ways of doing noise suppression . but given the limited time , , it was time to choose one . and so , , th the vector taylor series hadn't really worked out that much . the subspace , , had not been worked with so much . so it came down to spectral subtraction versus wiener filtering . we had long discussion about how they were the same and how they were , completely different . and , , , fundamentally they 're the same thing but the math is little different so that there 's there 's an exponent difference in the index what 's the ideal filtering , and depending on how you construct the problem . and , , it 's sort , after that meeting it made more sense to me because , if you 're dealing with power spectra then how are you gonna choose your error ? and typically you 'll do choose something like variance . and so that means it 'll be something like the square of the power spectra . whereas when you 're when you 're doing the , , , looking at it the other way , you 're gonna be dealing with signals and you 're gonna end up looking at power , noise power that you 're trying to reduce . and so , so there should be difference of , conceptually of , , factor of two in the exponent . but there 're so many different little factors that you adjust in terms of , , , over - subtraction and and , that arguably , you 're and and the choice of do you do you operate on the mel bands or do you operate on the fft beforehand . there 're so many other choices to make that are almost , if not independent , certainly in addition to the choice of whether you , , do spectral subtraction or wiener filtering , that , , @ @ again we felt the gang should just figure out which it is they wanna do and then let 's pick it , go forward with it . so that 's that was last week . and and , , we said , , take week , go arm wrestle , figure it out . and th the joke there was that each of them had specialized in one of them . and and so they so instead they went to yosemite and bonded , and they came out with single piece of software . so it 's another victory for international collaboration .
A: so so you guys have combined or you 're going to be combining the software ?
C: the piece of software has , like , plenty of options , like you can parse command - line arguments . so depending on that , it becomes either spectral subtraction or wiener filtering .
A: they 're close enough .
B: that 's fine , but the important thing is that there is piece of software that you that we all will be using now .
C: there 's just one piece of software .
E: need to allow it to do everything and even more than this . if we want to , like , optimize different parameters of we can do it later . but , still so , there will be piece of software with , , will give this system , the fifty - three point sixty - six , by default
A: how how is how good is that ? don't have sense of
E: it 's just one percent off of the best proposal . it 's between we are second actually if we take this system .
A: compared to the last evaluation numbers ? .
B: which we were before but we were considerably far behind . and , this doesn't have neural net in yet . so it so , , it 's it 's not using our full bal bag of tricks , if you will . and , , and it is , , very close in performance to the best thing that was there before . but , , looking at it another way , maybe more importantly , , we didn't have any explicit noise , , handling we didn't explicitly have anything to deal with stationary noise . and now we do .
A: so will the neural net operate on the output from either the wiener filtering or the spectral subtraction ? or will it operate on the original ?
B: so so argu arguably , , what we should do gather you have it sounds like you have few more days of nailing things down with the software and so on . but and then but , , arguably what we should do is , even though the software can do many things , we should for now pick set of things , th these things would , and not change that . and then focus on everything that 's left . and , , that our goal should be by next week , when hynek comes back , , to , really just to have firm path , , for the , for the time he 's gone , of , , what things will be attacked . but would would thought think that what we would wanna do is not futz with this for while because what 'll happen is we 'll change many other things in the system , and then we 'll probably wanna come back to this and possibly make some other choices .
A: but just conceptually , where does the neural net go ? do do you wanna run it on the output of the spectrally subtracted ?
B: depending on its size one question is , is it on the , , server side or is it on the terminal side ? if it 's on the server side , it you probably don't have to worry too much about size . so that 's an argument for that . we do still , however , have to consider its latency . so the issue is , , , could we have neural net that only looked at the past ? what we 've done in in the past is to use the neural net , , to transform , , all of the features that we use . so this is done early on . this is essentially , , it 's it 's more or less like spee speech enhancement technique here where we 're just creating new if not new speech at least new fft 's that have , which could be turned into speech that have some of the noise removed . after that we still do mess of other things to produce bunch of features . and then those features are not now currently transformed by the neural net . and then the way that we had it in our proposal - two before , we had the neural net transformed features and we had the untransformed features , which you actually did linearly transform with the klt , but , to orthogonalize them but they were not , , processed through neural net . and stephane 's idea with that , as recall , was that you 'd have one part of the feature vector that was very discriminant and another part that wasn't , which would smooth things bit for those occasions when , , the testing set was quite different than what you 'd trained your discriminant features for . so , , all of that is , still seems like good idea . now we know some other constraints . we can't have unlimited amounts of latency . , that 's still being debated by the by people in europe but , , no matter how they end up there , it 's not going to be unlimited amounts , so we have to be little conscious of that . so there 's the neural net issue . there 's the vad issue . and , , there 's the second stream thing . and those that we last time we that those are the three things that have to get , , focused on .
A: what was the issue with the vad ?
B: better ones are good .
A: and so the the default , , boundaries that they provide are they 're , but they 're not all that great ?
B: they still allow two hundred milliseconds on either side or some ? is that what the deal is ?
E: so th , they keep two hundred milliseconds at the beginning and end of speech . and they keep all the
A: outside the beginnings and end .
E: and all the speech pauses , which is sometimes on the speechdat - car you have pauses that are more than one or two seconds . more than one second for . and , , it seems to us that this way of just dropping the beginning and end is not we cou we can do better , , because , , with this way of dropping the frames they improve over the baseline by fourteen percent and sunil already showed that with our current vad we can improve by more than twenty percent .
A: on top of the vad that they provide ?
E: just using either their vad or our current vad . so , our current vad is more than twenty percent , while their is fourteen .
A: theirs is fourteen ?
E: and another thing that we did also is that we have all this training data for let 's say , for speechdat - car . we have channel zero which is clean , channel one which is far - field microphone . if we just take only the , , vad probabilities computed on the clean signal and apply them on the far - field , , test utterances , then results are much better . in some cases it divides the error rate by two . so it means that there are stim still
A: how how much latency does the , does our vad add ?
E: if if we can have good vad , , it would be great .
A: is it significant ,
E: right now it 's , , neural net with nine frames . so it 's forty milliseconds plus , , the rank ordering , which , , should be
C: like another ten frames .
E: so , right now it 's one hundred and forty milliseconds .
B: with the rank ordering ?
C: the the smoothing the the filtering of the probabilities .
E: it 's not median filtering . it 's just we don't take the median value . we take something so we have eleven , , frames .
B: this is for the vad .
E: for the vad , and we take th the third .
B: so , was just noticing on this that it makes reference to delay . so what 's the ? if you ignore the vad is in parallel , isn't isn't it , with the ? , it isn't additive with the , , lda and the wiener filtering , and .
C: so so what happened right now , we removed the delay of the lda . so we , if so if we if so which is like if we reduce the delay of va so , the the final delay 's now ba is determined by the delay of the vad , because the lda doesn't have any delay . so if we re if we reduce the delay of the vad , , it 's like effectively reducing the delay .
A: how how much , , delay was there on the lda ?
C: so the lda and the vad both had hundred millisecond delay . so and they were in parallel , so which means you pick either one of them the biggest , whatever . so , right now the lda delays are more .
B: and there didn't seem to be any , , penalty for that ? there didn't seem to be any penalty for making it causal ?
C: no . it actually made it , like , point one percent better , actually .
B: may as , then . and he says wiener filter is forty milliseconds delay . so is it ?
C: so that 's the one which stephane was discussing , like the you smooth it and then delay the decision by
B: so that 's that 's really not bad . so we may we 'll see what they decide . we may have , , the , , latency time available for to have neural net . sounds like we probably will . that 'd be good . cuz cuz it certainly always helped us before .
A: what amount of latency are you thinking about when you say that ?
B: they 're , they 're disputing it . they 're saying , one group is saying hundred and thirty milliseconds and another group is saying two hundred and fifty milliseconds . two hundred and fifty is what it was before actually . some people are lobbying to make it shorter .
A: were you thinking of the two - fifty or the one - thirty when you said we should have enough for the neural net ?
B: it just it when we find that out it might change exactly how we do it , is all . how much effort do we put into making it causal ? the neural net will probably do better if it looks at little bit of the future . but , , it will probably work to some extent to look only at the past . and we ha , limited machine and human time , and effort . and , , how much time should we put into that ? so it 'd be helpful if we find out from the standards folks whether , , they 're gonna restrict that or not . but , , at this point our major concern is making the performance better and , , if , , something has to take little longer in latency in order to do it that 's , secondary issue . but if we get told otherwise then , , we may have to clamp down bit more .
C: so , the one one difference is that was there is like we tried computing the delta and then doing the frame - dropping . the earlier system was do the frame - dropping and then compute the delta on the
A: which could be funny delta .
B: so that 's fixed in this . we talked about that .
C: so we have no delta . and then so the frame - dropping is the last thing that we do . so , , what we do is we compute the silence probability , convert it to that binary flag , and then in the end you up upsample it to match the final features number of
A: did that help then ?
C: it seems to be helping on the - matched condition . so that 's why this improvement got from the last result . so . and it actually reduced little bit on the high mismatch , so in the final weightage it 's better because the - matched is still weighted more than
B: so , @ @ , you were doing lot of changes . did you happen to notice how much , , the change was due to just this frame - dropping problem ? what about this ?
C: you had something on it .
E: just the frame - dropping problem . but it 's it 's difficult . sometime we change two things together and but it 's around maybe it 's less than one percent .
B: but like we 're saying , if there 's four or five things like that then pretty sho soon you 're talking real improvement .
E: and then we have to be careful with that also with the neural net because in the proposal the neural net was also , , working on after frame - dropping .
B: that 's real good point .
E: so . , we 'll have to be to do the same correction .
B: it might be hard if it 's at the server side .
E: mmm . , we can do the frame - dropping on the server side or we can just be careful at the terminal side to send couple of more frames before and after ,
A: maybe don't quite understand how this works , but , , couldn't you just send all of the frames , but mark the ones that are supposed to be dropped ? cuz you have bunch more bandwidth .
B: , it always seemed to us that it would be to in addition to , , reducing insertions , actually use up less bandwidth . but nobody seems to have cared about that in this evaluation .
A: and that way the net could use if the net 's on the server side then it could use all of the frames .
C: yes , it could be . it 's , like , you mean you just transferred everything and then finally drop the frames after the neural net . that 's that 's one thing which
A: but you could even mark them , before they get to the server .
C: right now we are right now what wha what we did is , like , we just mark we just have this additional bit which goes around the features , saying it 's currently it 's speech or nonspeech . so there is no frame - dropping till the final features , like , including the deltas are computed . and after the deltas are computed , you just pick up the ones that are marked silence and then drop them .
B: so it would be more or less the same thing with the neural net , , actually .
C: so . , that 's what that 's what , , this is doing right now .
B: what 's , ? that 's that 's good set of work that ,
C: just one more thing . like , should we do something more for the noise estimation , because we still ?
B: was wondering about that . that was had written that down there .
E: so , we , actually did the first experiment . this is with just fifteen frames . we take the first fifteen frame of each utterance to it , and average their power spectra . tried just plugging the , , , guenter noise estimation on this system , and it , it got worse . but didn't play with it . didn't do much more for noise estimation . tried this ,
B: . , it 's not surprising it 'd be worse the first time . it does seem like , , some compromise between always depending on the first fifteen frames and always depending on pause is is good idea . maybe you have to weight the estimate from the first - teen fifteen frames more heavily than was done in your first attempt . do you have any way of assessing how or how poorly the noise estimation is currently doing ?
E: mmm . no , we don't . we don't have nothing that
C: is there was there any experiment with ? did the only experiment where tried was used the channel zero vad for the noise estimation and frame - dropping . so don't have don't have split , like which one helped more . so . it it was the best result could get . so , that 's the
B: so that 's something you could do with , , this final system . just do this everything that is in this final system except , , use the channel zero .
C: for the noise estimation . we can try something .
B: and then see how much better it gets . if it 's , , essentially not better , then it 's probably not worth
C: but the guenter 's argument is slightly different . it 's , like , ev even if use channel zero vad , 'm just averaging the power spectrum . but the guenter 's argument is , like , if it is non - stationary segment , then he doesn't update the noise spectrum . so he 's , like he tries to capture only the stationary part in it . so the averaging is , like , different from updating the noise spectrum only during stationary segments . so , th the guenter was arguing that , , even if you have very good vad , averaging it , like , over the whole thing is not good idea . because you 're averaging the stationary and the non - stationary , and finally you end up getting something which is not really the because , you anyway , you can't remove the stationary part fr , non - stationary part from the signal .
B: not using these methods anyway . .
C: so you just update only doing or update only the stationary components . so , that 's so that 's still slight difference from what guenter is trying
B: . and and also there 's just the fact that , , , although we 're trying to do very on this evaluation , , we actually would like to have something that worked in general . and , , relying on having fifteen frames at the front is pretty you might not . it 'd certainly be more robust to different kinds of input if you had at least some updates . what what do you , what do you guys see as being what you would be doing in the next week , given wha what 's happened ?
C: cure the vad ?
A: what was that ?
E: so , should we keep the same ? we might try to keep the same idea of having neural network , but training it on more data and adding better features , , but because the current network is just plp features . it 's trained on noisy plp
C: just the cepstra .
E: plp features computed on noisy speech . but there is no nothing particularly robust in these features . there 's no rasta , no
A: so , , don't remember what you said the answer to my , , question earlier . will you will you train the net on after you 've done the spectral subtraction or the wiener filtering ?
B: this is different net .
C: so we have vad which is like neur that 's neural net .
A: you 're talking about the vad net .
C: so that vad was trained on the noisy features . so , right now we have , like , we have the cleaned - up features , so we can have better vad by training the net on the cleaned - up speech .
A: see . see .
C: but we need vad for noise estimation also . so it 's , like , where do we want to put the vad ?
A: can you use the same net to do both , can you use the same net that you that was talking about to do the vad ?
C: it actually comes at at the very end . so the net the final net , which is the feature net so that actually comes after chain of , like , lda plus everything . so it 's , like , it takes long time to get decision out of it . and and you can actually do it for final frame - dropping , but not for the va - noise estimation .
B: you see , the idea is that the , , initial decision to that you 're in silence or speech happens pretty quickly .
A: cuz that 's used by some of these other ?
B: and that 's fed forward , and you say "" , flush everything , it 's not speech anymore "" .
A: that was only used for doing frame - dropping later on .
B: it is used , it 's only used , it 's used for frame - dropping . it 's used for end of utterance because , , there 's if you have more than five hundred milliseconds of of nonspeech then you figure it 's end of utterance like that .
E: and it seems important for , like , the on - line normalization . we don't want to update the mean and variance during silen long silence portions . so it has to be done before this mean and variance normalization .
B: so probably the vad and maybe testing out the noise estimation little bit . keeping the same method but , , seeing if you cou but , noise estimation could be improved . those are related issues . it probably makes sense to move from there . and then , , later on in the month we wanna start including the neural net at the end .
E: the half dome was great .
B: you didn't didn't fall . that 's good . our our effort would have been devastated if you guys had run into problems .
A: so , hynek is coming back next week , you said ?
B: that 's the plan . the week after he 'll be , , going back to europe , and so we wanna
A: is he in europe right now or is he up at ?
B: no , no . he 's he 's dropped into the us . . the idea was that , , we 'd we 'd sort out where we were going next with this with this work before he , , left on this next trip . good . , barry , you just got through your quals , so if you have much to say .
D: no , just , , looking into some of the things that , , , john ohala and hynek , , gave as feedback , as starting point for the project . in in my proposal , was thinking about starting from set of , , phonological features , or subset of them . but that might not be necessarily good idea according to , , john . he said , , , these phonological features are figments of imagination also .
B: in conversational speech in particular . you can you can put them in pretty reliably in synthetic speech . but we don't have too much trouble recognizing synthetic speech since we create it in the first place . so , it 's
D: so , , better way would be something more data - driven , just looking at the data and seeing what 's similar and what 's not similar . so , 'm 'm , , taking look at some of , , sangita 's work on traps . she did something where , where the traps learn she clustered the temporal patterns of , , certain phonemes in averaged over many , many contexts . and , , some things tended to cluster . right ? , like stop consonants clustered really . silence was by its own self . and , , , vocalic was clustered . and , , so , those are interesting things to
A: so you 're now you 're looking to try to gather set of these types of features ?
D: just to see where could start off from , set of small features and continue to iterate and find , , better set .
B: , short meeting . so next week hopefully we 'll can get hynek here to join us
A: should we do digits ?
B: digits , digits .
A: go ahead , morgan . you can start .
B: alright . let me get my glasses on so see them .
A: and we 're off .
","ICSI's Meeting Recorder Group have returned from a meeting with some important decisions to make.
They have developed a piece of software which allows them to implement their two main approaches to dealing with noise.
The base rate is currently set at the second best rate as of the last project evaluation , and it does not yet include everything the group have been working on.
With this in mind , they have decided to set most things , and concentrate on studying only a few key aspects , the neural network , the voice activity detector , and the noise estimation.
By the time a senior member of their research partners OGI returns , they want to have a firm plan of what they will be doing.
System latency is still an issue , but limits have still not been set by the project heads.
The group have encountered problems with frame-dropping , and will need to bear that in mind since their neural network would come after that stage.
While deciding which of two approaches to finally adopt , the group put together one piece of software for all to use that implements both spectral subtraction and wiener filtering.
Speaker me026 has done his quals , and is looking at some of the feedback he received.
"
ami_abstractive_summary,Bmr020.txt,"A: we 're recording .
F: we can say the word "" zero "" all we want ,
B: that 's not allowed , .
C: cur - curly brackets .
E: is that voiced or unvoiced ?
F: correction for transcribers .
G: mmm ! gar - darn !
A: do we use square brackets for anything ?
E: these poor transcribers .
C: not ri not right now .
D: there 's gonna be some zeros from this morning 's meeting because noticed that barry , maybe you turned your mike off before the digits were was it during digits ? so it doesn't matter .
A: it 's still not good idea .
B: so it 's not it 's not that bad if it 's at the end , but it 's in the beginning , it 's bad .
A: you wanna you wanna keep them on so you get good noise through the whole meeting .
C: that 's interesting .
F: probably just should have left it on . did have to run ,
E: is there any way to change that in the software ?
A: change what in the software ?
E: where like you just don't like if you if it starts catching zeros , like in the driver in the card , or somewhere in the hardware where if you start seeing zeros on across one channel , you just add some random , @ @ noise floor like small noise floor .
A: certainly we could do that , but don't think that 's good idea . we can do that in post - processing if the application needs it .
B: manual post - processing .
F: actually what the default is anymore as to how we 're using the front - end but for when we use the icsi front - end ,
A: as an argument .
F: there is an there is an an option in rasta , in when first put it in , , back in the days when actually wrote things , , did actually put in random bit or so that was in it , but then realized that putting in random bit was equivalent to adding adding flat spectrum , and it was lot faster to just add constant to the to the spectrum . so then started doing that instead of calling "" rand "" , so it it does that . gee ! here we all are !
A: so the only agenda items were jane was jane wanted to talk about some of the ibm transcription process .
F: there 's an agenda ?
A: condensed the three things you said into that . and then just only have like , this afternoon and maybe tomorrow morning to get anything done before go to japan for ten days . so if there 's anything that , desperately needs to be done , you should let me know now .
F: and you just sent off eurospeech paper ,
G: hope they accept it . both actu as submission and , as paper .
A: you sent it in late .
F: you first you have to do the first one ,
G: we actually exceeded the delayed deadline by another day ,
F: they had some extension that they announced ?
G: liz had sent them note saying "" could we have another "" , "" three days "" , and they said yes .
D: and then she said "" did say three ?
A: that was the other thing dave gelbart sent me email , he sent it to you too , that , there 's special topic , section in si in eurospeech on new , corp corpors corpora . and it 's not due until like may fifteenth .
F: this isn't the aurora one ? it 's another one ?
A: it 's different one .
B: got this mail from
A: forwarded it to jane as being the most relevant person . so , it was highly relevant have you did you look at the url ?
C: haven't gotten over to there yet , but what our discussion yesterday , really wanna submit one .
B: was this smartkom message ? christoph draxler sent this ,
C: and , you offered to join me , if you want me to .
A: but 't , really do , most of it ,
C: that 's right .
G: several people sent this ,
A: but any help you need certainly provide .
F: that 's that 's great idea .
G: there were some interesting results in this paper , though . that morgan , accounted for fifty - six percent of the robustness meetings in terms of number of words .
C: in in terms of what ?
G: number of words .
A: that 's just cuz he talks really fast .
C: do you mean , is it partly , , correctly identified words ? or just overall volume ?
G: no . , according to the transcripts .
A: but re regardless . it 's he 's in all of them ,
G: we didn't mention morgan by name
A: and he talks lot .
F: we have now ,
G: we we something about
A: did you identify him as senior member ?
G: we as identify him as the person dominating the conversation .
F: get these aarp things , but 'm not se really senior yet , but , other than that delightful result , what was the rest of the paper about ?
G: it was about it had three sections
F: you sent it to me but haven't seen it yet .
G: three kinds of results , if you will . the one was that the just the amount of overlap
A: the good , the bad , and the ugly .
G: in terms of in terms of number of words and also we computed something called "" spurt "" , which is essentially stretch of speech with , no pauses exceeding five hundred milliseconds . and we computed how many overlapped spurts there were and how many overlapped words there were . , for four different corpora , the meeting recorder meetings , and , found and compared the numbers . and found that the , as you might expect the meeting recorder meetings had the most overlap but next were switchboard and callhome , which both had roughly the same , and the robustness meetings were had the least , one unexpected result there is that two - party telephone conversations have about the same amount of overlap , in gen order of magnitude - wise as , as face - to - face meetings with multiple
A: have had better start changing all my slides !
G: also , in the levinson , the pragmatics book , in , , textbook , there 's found this great quote where he says , how people it talks about how how people are so good at turn taking , and so they 're so good that generally , the overlapped speech does not is less than five percent .
C: that 's interesting .
G: this is way more than five percent .
E: did he mean face like face - to - face ?
G: in real conversations , it 's what these conversation analysts have been studying for years and years there .
C: , no , it doesn't necessarily go against what he said , cuz he said "" generally speaking "" . in order to go against that claim you 'd have to big canvassing .
F: we have pretty limited sample here .
B: five percent of time or five percent of what ?
A: was gonna ask that too .
G: it 's time .
C: it 's it 's not against his conclusion , it just says that it 's bi bell curve , and that , you have something that has range , in your sampling .
G: so there are slight there are differences in how you measure it , but still it 's , the difference between between that number and what we have in meetings , which is more like , , close to in meetings like these , , close to twenty percent .
F: but what was it like , say , in the robustness meeting , ?
G: it was about half of the so , in terms of number of words , it 's like seventeen or eigh eighteen percent for the meeting recorder meetings and about half that for , , the robustness .
F: maybe ten percent ?
A: but if that 's really fair way of comparing between , multi - party , conversations and two - party conversations .
B: then then you have to
A: that 's just something
D: wonder if you have to normalize by the numbers of speakers .
B: then , then normalize by something like that ,
C: that 's good point .
G: we didn't get to look at that , but this obvious thing to see if there 's dependence on the number of participants .
A: bet there 's weak dependence . 'm it 's it 's not real strong one .
D: cuz not everybody talks .
A: you have lot of lot of two - party , subsets within the meeting . it 's an interesting result regardless .
C: yes , that 's right .
G: and and then and we also computed this both with and without backchannels , so you might think that backchannels have special status because they 're essentially just
A: so , did we all said "" - "" and nodded at the same time ,
G: but , even if you take out all the backchannels so you treat backchannels as nonspeech , as pauses , you still have significant overlap . it goes down from maybe for switchboard it goes down from fourteen percent of the words to maybe , eleven percent it 's it 's not dramatic change , that was that was one set of results , and then the second one was just the we had in the in the hlt paper on how overlaps effect the recognition performance . and we rescored things , little bit more carefully . we also fixed the transcripts in numerous ways . but mostly we added one number , which was what if you , score ignoring all so so the conjecture from the hlt results was that most of the added recognition error is from insertions due to background speech . so , we scored all the recognition results , , in such way that the
A: who 's on channel four ? you 're getting lot of breath .
B: was just wondering .
E: that 's me .
G: don 's been working hard .
E: that 's right .
G: so if you have the foreground speaker speaking here , and then there 's some background speech , may be overlapping it somehow , and this is the time bin that we used , then you 're gonna get insertion errors here and here . so we scored everything , and must say the nist scoring tools are pretty for this , where you just ignore everything outside of the , , region that was deemed to be foreground speech . and where that was we had to use the forced alignment , , results from for that 's somewhat that 's somewhat subject to error , but still we , don did some ha hand - checking and we think that based on that , we think that the results are , valid , although , some error is gonna be in there . but what we found is after we take out these regions so we only score the regions that were certified as foreground speech , the recognition error went down to almost , the level of the non - overlapped speech . so that means that even if you do have background speech , if you can somehow separate out or find where it is , , the recognizer does good job ,
A: that 's great .
G: even though there is this back
A: that doesn't surprise me , because , with the close - talking mikes , the signal will be so much stronger . what what normalization do you do ?
G: , we just @ @ we do , vit
A: in you recognizer , in the sri recognizer .
G: we do , vtl vocal tract length normalization , and we , we , make all the features have zero mean and unit variance .
A: over an entire utterance ?
G: over over the entire over the entire channel . now we didn't re - align the recognizer for this . we just took the old so this is actually sub - optimal way of doing it , so we took the old recognition output and we just scored it differently . so the recognizer didn't have the benefit of knowing where the foreground speech start
F: were you including the lapel in this ? and did the did the la did the problems with the lapel go away also ? fray for insertions ?
G: it not per , not completely , so we have to should bring the should bring the table with results . maybe we can look at it monday .
F: would presume that you still would have somewhat higher error with the lapel for insertions than
G: it 's it 's
F: cuz again , looking forward to the non - close miked case , that we still
A: 'm not looking forward to it .
F: it 's the high signal - to - noise ratio here that helps you .
G: so that was number that was the second set of , the second section . and then , the third thing was , we looked at , , what we call "" interrupts "" , although that 's that may be misnomer , but we looked at cases where so we used the punctuation from the original transcripts and we inferred the beginnings and ends of sentences .
C: di - did you use upper - lower case also , or not ? upper lower case or no ?
G: we only used , , periods , , question marks and exclamation . and we know that there 's th that 's not very we miss lot of them ,
C: comma also or not ?
G: and then we looked at locations where , if you have overlapping speech and someone else starts sentence , , where do these where do other people start their turns not turns really , but , sentences , so we only looked at cases where there was foreground speaker and then at the to at the so the foreground speaker started into their sentence and then someone else started later .
B: somewhere in between the start and the end ? somewhere in between the start and the end of the foreground ?
G: so that such that there was overlap between the two sentences . so , the question was how can we what can we say about the places where the second or actually , several second speakers , start their "" interrupts "" , as we call them .
D: three words from the end .
A: at pause boundaries .
G: and we looked at this in terms of
A: on - closures , only .
G: so so we had we had to for the purposes of this analysis , we tagged the word sequences , and we time - aligned them . and we considered it interrupt if it occurred in the middle of word , we , considered that to be interrupt as if it were at the beginning of the word . so that , if any part of the word was overlapped , it was considered an interrupted word . and then we looked at the locatio the , , , the features that the tags because we had tagged these word strings , , that occurred right before these , interrupt locations . and the tags we looked at are the spurt tag , end of spurt . so whether there was pause essentially here , because spurts are defined as being , five hundred milliseconds or longer pauses , and then we had things like discourse markers , so disfluen the 's are for , , the interruption points of disfluency , so , where you hesitate , or where you start the repair there . what else do we had . repeated , repeated words is another of that disfluencies and . so we had both the beginnings and ends of these so , the end of filled pause and the end of discourse marker . and we just eyeballed we didn't really hand - tag all of these things . we just looked at the distribution of words , and so every "" so "" , and "" "" , , and "" - "" were the were deemed to be backchannels and "" "" and "" so "" and "" right "" , were not "" right "" . "" right "" is backchannel . but so , we just based on the lexical , identity of the words , we tagged them as one of these things . and the the interruption points we got from the original transcripts . and then we looked at the disti so we looked at the distribution of these different kinds of tags , overall and and particularly at the interruption points . and , we found that there is marked difference so at the end after discourse marker or after backchannel or after filled pause , you 're much more likely to be interrupted than before . and also after spurt ends , which means in inside pauses . so pauses are always an opportunity for so we have this little histogram which shows these distributions it 's it 's not no big surprises , but it is interesting from
A: it 's to actually measure it though .
D: wonder about the and effect there . in other words if you weren't going to pause you will because you 're being interrupted .
G: there 's no statement about and effect .
D: no , no .
G: this is just statistical correlation ,
F: but he , he 's he 's right , you weren't intending to pause , but you were intending to stop for fifty - seven milliseconds , but then chuck came in and so you paused for second
G: anyway . so , and that was it . and and we so we wrote this and then , we found we were at six pages , and then we started cutting furiously and threw out half of the material again , and played with the latex
A: made the font smaller and the narrows longer .
G: and until it fi no , no . you couldn't really make everything smaller
B: put the abstract end .
G: but we we put
A: took out white space .
G: the gap between the two columns is like ten millimeters , so shrunk it to eight millimeters and that helped some . and like that .
D: wasn't there wasn't there some result , andreas maybe liz presented this at some conference while ago about , backchannels and that they tend to happen when the pitch drops . you get falling pitch . and so that 's when people tend to backchannel . - do you rem
G: we didn't talk about , , prosodic , , properties ,
D: right . right .
G: although that 's take it that 's something that don will look at
E: we 're gonna be looking at that .
G: now that we have the data and we have the alignment , this is purely based on the words
C: have reference for that though .
D: so am recalling correctly ?
G: anyway , so .
C: didn't know about liz 's finding on that , but know of another paper that talks about something
E: 'd like to see that reference too .
D: it made me think about little device that could be built to handle those people that call you on the phone and just like to talk and talk . and you just have this little detector that listens for these drops in pitch and gives them the backchannel . and so then you hook that to the phone and go off and do the do whatever you wanna do , while that thing keeps them busy .
G: there 's actually there 's this former student of here from berkeley , he did system , in he lives in japan now , and he did this backchanneling , automatic backchanneling system . so , exactly what you describe , but for japanese . and it 's for japa - in japanese it 's really important that you backchannel . it 's really impolite if you don't ,
F: actually for lot of these people you could just backchannel continuously and it would be fine .
D: it wouldn't matter ?
E: that 's that 's what do .
A: there was there was monty python sketch with that . where the barber who was afraid of scissors was playing tape of clipping sounds , and saying "" - "" , "" how about them sports teams ? ""
G: so the paper 's on - line cc ' ed message to meeting recorder with the url so you can get it .
A: printed it out , haven't read it yet .
G: one more thing . so 'm actually about to send brian kingbury an email saying where he can find the the the material he wanted for the for the speech recognition experiment , but haven't sent it out yet because actually my desktop locked up , like 't type anything . so if there 's any suggestions you have for that was just gonna send him the
D: is it the same directory that you had suggested ?
C: he still has his unix account here , . and he and he 's
G: but but he has to
C: 'd hafta add him to meeting recorder , ,
G: he prefe he said he would prefer ftp and also , , the other person that wants it there is one person at sri who wants to look at the , , the the data we have so far , and so figured that ftp is the best approach . so what did is @ @ made new directory after chuck said that would that was gonna be good thing . so it 's "" ftp pub what is it again ?
A: ask dan ellis .
G: the same the same as the mailing list ,
F: the no vowels .
G: and then under there actually and this directory , is not readable . it 's only , accessible . so , in other words , to access anything under there , you have to be told what the name is . so that 's quick and dirty way of doing access control . and the directory for this call it "" asr zero point one "" because it 's meant for recognition .
F: so anyone who hears this meeting now knows the
G: and then in there have file that lists all the other files , so that someone can get that file and then know the file names and therefore download them . if you the file names you can't
F: is that dash or dot in there ?
A: don't don't say .
G: so all all was gonna do there was stick the transcripts after we the way that we munged them for scoring , because that 's what he cares about , and also and then the waveforms that don segmented . just tar them all up for each meeting tar them all into one tar file and - zip them and stick them there .
A: put digits in my own home directory home ftp directory , but 'll probably move them there as .
D: so we could point mari to this also for her march - one request ?
G: march - one .
D: you remember she was
G: she wanted that also ?
D: she was saying that it would be if we had they had or was she talking she was saying it would be if they had the same set , so that when they did experiments they could compare .
G: but they don't have recognizer even . we can send cc mari on this so that she knows
D: so , for the thing that
C: that 's good .
D: we need to give brian the beeps file , so was gonna probably put it
A: we can put it in the same place . just put in another directory .
D: 'll make another directory .
G: make ano make another directory .
E: and , andreas , , sampled ? so either we should regenerate the original versions , or , we should just make note of it .
G: because in one directory there 's two versions .
E: that 's the first meeting cut both versions . just to check which if there is significant difference .
G: so but for the other meetings it 's the downsampled version that you have .
E: they 're all downsampled ,
G: that 's th important to know , we should probably give them the non - downsampled versions . alright , then 'll hold off on that and 'll for you
E: 'll send you an email .
G: definitely they should have the full bandwidth version ,
E: because liz decided to go ahead with the downsampled versions cuz we can there was no like , significant difference .
G: it takes it takes up less disk space , for one thing .
E: it does take up less disk space , and it did even better than the original versions , which , is just , probably random .
G: it was small difference
E: but , they probably want the originals .
G: it 's good thing that
A: we 're losing , don and andreas at three - thirty ,
E: hey mon hafta booga .
F: that 's why it was good to have andreas , say these things so , we should probably talk about the ibm transcription process that
C: so , that adam created , script to generate the beep file ? to then create something to send to ibm . you should probably talk about that . but but you were gonna to use the originally transcribed file because tightened the time bins and that 's also the one that they had already in trying to debug the first stage of this . my understanding was that , haven't haven't listened to it yet , but it sounded very good and understand that you guys were going to have meeting today , before this meeting .
A: it was just to talk about how to generate it . just so that while 'm gone , you can regenerate it if you decide to do it different way . so , chuck and thilo should , now more or less know how to generate the file and , the other thing chuck pointed out is that , , since this one is hand - marked , there are discourse boundaries . so so when one person is speaking , there 's breaks . whereas thilo 's won't have that . so what we 're probably gonna do is just write script , that if two , chunks are very close to each other on the same channel we 'll just merge them . so , , and that will get around the problem of , the , "" one word beep , one word beep , one word beep "" .
D: after our meeting , this morning thilo came in and said that , there could be other differences between the already transcribed meeting with the beeps in it and one that has just been run through his process .
C: and that 's the purpose .
D: so tomorrow , when we go to make the , chunked file for ibm , we 're going to actually compare the two . so he 's gonna run his process on that same meeting , and then we 're gonna do the beep - ify on both , and listen to them and see if we notice any real differences .
G: beep - ify !
C: now one thing that prevented us from apply you from applying so that is the training meeting .
D: and we know that . wel - we just wanna if there 're any major differences between doing it on the hand
G: so this training meeting , un is that some data where we have very , , accurate time marks ? for
C: went back and hand - marked the ba the bins , ment mentioned that last week .
D: but the but there 's , but there is this one issue with them in that there 're there are time boundaries in there that occur in the middle of speech . like when we went to when was listening to the original file that adam had , it 's like you hear word then you hear beep and then you hear the continuation of what is the same sentence .
A: that 's on the other channel . that 's because of channel overlap .
D: and so the th so there are these chunks that look like that have
A: that 's not gonna be true of the foreground speaker . that 'll only be if it 's the background speaker .
D: so you 'll you 'll have chunk of , , channel which starts at zero and ends at ten , and then the same channel starting at eleven , ending at fifteen , and then again , starting at sixteen , ending at twenty . so that 's three chunks where actually we can just make one chunk out of that which is , zero , twenty .
A: that 's what said ,
D: so wanted to make that it was clear . so if you were to use these , you have to be careful not to pull out these individual
G: what would was interested in is having se having time marks for the beginnings and ends of speech by each speaker .
A: that 's definitely problem .
G: because we could use that to fine tune our alignment process to make it more accurate . it don't care that , there 's actually abutting segments that we have to join together . that 's fine . but what we do care about is that the beginnings and ends are actually close to the speech inside of that
D: jane tightened these up by hand .
G: so what is the how tight are they ?
F: it looks much better .
C: they were , , reasonably tight , but not excruciatingly tight . that would 've taken more time . wanted to get it so tha so that if you have like "" "" in swimming in big bin , then it 's
G: no , no !
A: let me make note on yours .
G: because we don't want to th that 's perfectly fine . it 's good . you always want to have little bit of pause or nonspeech around the speech , say for recognition purposes . but just get an id wanted to have an idea of the of how much extra you allowed so that interpret the numbers if compared that with forced alignment segmentation .
C: 't answer that , but my main goal was , in these areas where you have three - way overlap and one of the overlaps involves "" "" , and it 's swimming in this huge bin , wanted to get it so that it was clo more closely localized .
G: but are we talking about , , tenth of second ? how how much extra would you allow at most
C: wanted it to be able to he be heard normally , so that if you if you play back that bin and have it in the mode where it stops at the boundary , it sounds like normal word . it doesn't sound like the person it sounds normal . it 's as if the person could 've stopped there . and it wouldn't have been an awkward place to stop . now sometimes , it 's these are involved in places where there was no time . and so , there wouldn't be gap afterwards because some cases , there 're some people , who have very long segments of discourse where , , they 'll they 'll breath and then put break . but other than that , it 's really pretty continuous and this includes things like going from one sentence into the one utterance into the next , one sentence into the next , without really stopping . in writing you have this two spaces and big gap but but some people are planning and , , , lot we always are planning what we 're going to say next . but , in which case , the gap between these two complete syntactic units , , which spoken things are not always complete syntactically , but it would be shorter shorter break than maybe you might like . but the goal there was to not have the text be so crudely parsed in time bin . because from discourse purpose it 's it 's more useful to be able to see and also , from speech recognition purpose my impression is that if you have too long unit , it 's it doesn't help you very much either , cuz of the memory .
G: that 's fine .
C: so , that means that the amount of time after something is variable depending partly on context , but my general goal when there was sufficient space , room , pause after it to have it be natural feeling gap . which what it would be quantified as . wally chafe says that , in producing narratives , the spurts that people use tend to be , , that the what would be pause might be something like two seconds . and , that would be , one speaker . the discourse the people who look at turn taking often do use was interested that you chose , , the that you use cuz that 's unit that would be more consistent with sociolinguistics .
G: we chose , , half second because if you go much larger , you have , your statement about how much overlap there is becomes less , , precise , because you include more of actual pause time into what you consider overlap speech . it 's compromise ,
B: , also used something around zero point five seconds for the speech - nonspeech detector
G: and it 's also based liz suggested that value based on the distribution of pause times that you see in switchboard and other corpora .
B: for the minimum silence length .
C: in any case , this , meeting that hand hand - adjusted two of them and sent sent email ,
G: so so at some point we will try to fine - tune our forced alignment
C: and sent the path .
G: maybe using those as references because , what you would do is you would play with different parameters . and to get an object you need an objective measure of how closely you can align the models to the actual speech . and that 's where your data would be very important to have .
B: and hopefully the new meetings which will start from the channelized version will have better time boundaries and alignments .
C: but like this idea of , for our purposes for the for the ibm preparation , , having these joined together , it makes lot of sense . and in terms of transcription , it would be easy to do it that way . the way that they have with the longer units , not having to fuss with adding these units at this time .
B: whi - which could have one drawback . if there is backchannel in between those three things , the the backchannel will occur at the end of those three . and and in the in the previous version where in the which is used now , there , the backchannel would be in - between there somewhere , that would be more natural
C: that 's that 's right , but , thi this brings me to the other stage of this which discussed with you earlier today , which is the second stage is , what to do in terms of the transcribers adjustment of these data . discussed this with you too . so the idea initially was , we would get , for the new meetings , so the edu meetings , that thilo ha has now presegmented all of them for us , on channel by channel basis . so , 've assigned 've assigned them to our transcribers so far 've discussed it with one , and had about an hour discussion with her about this yesterday , we went through edu - one , at some extent . and it occurred to me that that what we have in this format is you could consider it as staggered mixed file , we had some discussion over the weekend about at this other meeting that we were all at about whether the tran the ibm transcribers should hear single channel audio , or mixed channel audio . and , in way , by having this chunk and then the backchannel after it , it 's like stagal staggered mixed channel . and , it occurred to me in my discussion with her yesterday that , the the maximal gain , it 's from the ibm people , may be in long stretches of connected speech . so it 's whole bunch of words which they can really do , because of the continuity within that person 's turn . so , what 'm thinking , and it may be that not all meetings will be good for this , but what 'm thinking is that in the edu meetings , they tend to be driven by couple of dominant speakers . and , if the chunked files focused on the dominant speakers , then , when it got patched together when it comes back from ibm , we can add the backchannels . it seems to me that , , the backchannels per - se wouldn't be so hard , but then there 's this question of the time @ @ , marking , and whether the beeps would be and 'm not exactly how that how that would work with the with the backchannels . and certainly things that are intrusions of multiple words , taken out of context and displaced in time from where they occurred , that would be hard . so , my thought is 'm having this transcriber go through the edu - one meeting , and indicate start time {nonvocalsound} for each dominant speaker , endpoi end time for each dominant speaker , and the idea that these units would be generated for the dominant speakers , and maybe not for the other channels .
A: the only , , disadvantage of that is , then it 's hard to use an automatic method to do that . the advantage is that it 's probably faster to do that than it is to use the automated method and correct it . we 'll just have to see .
C: , the original plan was that the transcriber would adjust the the boundaries , and all that for all the channels but , , that is so time - consuming , and since we have bottleneck here , we want to get ibm things that are usable as soon as possible , then this seemed to me it 'd be way of gett to get them flood of data , which would be useful when it comes back to us . also , at the same time she when she goes through this , she 'll be if there 's anything that was encoded as pause , but really has something transcribable in it , then she 's going to , make mark so , so that bin would be marked as it as double dots and she 'll just add an . and in the other in the other case , if it 's marked as speech , and really there 's nothing transcribable in it , then she 's going to put dash , and 'll go through and it and , , with with substitution command , get it so that it 's clear that those are the other category . 'll just , , recode them . but , , the transcribable events that , 'm considering in this , , continue to be laugh , as as speech , and cough and things like that , so 'm not stripping out anything , just , being very lenient in what 's considered speech .
D: in terms of the this new procedure you 're suggesting , , what is the
A: it 's not that different .
D: so 'm little confused , because how do we know where to put beeps ? is it is it
A: transcriber will do it .
C: so what it what it involves is really , , the original pr procedure , but only applied to , certain strategically chosen aspect of the data .
A: we pick the easy parts of the data , and transcriber marks it by hand .
C: you got it .
D: but after we 've done thilo 's thing .
A: didn't didn't understand that .
B: 'm @ @ now 'm confused .
C: we start with your presegmented version
G: and 'm leaving .
E: have to go as .
A: leave the mikes on , and just put them on the table .
C: we start with the presegmented version
A: let me mark you as no digits .
B: you start with the presegmentation ,
C: and then , the transcriber , instead of going painstakingly through all the channels and moving the boundaries around , and deciding if it 's speech or not , but not transcribing anything . instead of doing that , which was our original plan , the tra they focus on the dominant speaker
D: they just do that on the main channels .
C: so what they do is they identify who 's the di dominant speaker , and when the speaker starts . so , you 're still gonna it 's based on your se presegmentation , that 's the basic thing .
B: and you just use the the segments of the dominant speaker then ? for for sending to ibm
D: so , now jane , my question is when they 're all done adjusting the time boundaries for the dominant speaker , have they then also erased the time boundaries for the other ones ?
C: no . no , no .
D: so how will we know who
C: that 's that 's why she 's notating the start and end points of the dominant speakers . so , on , so in edu - one , as far as listened to it , you start off with section by jerry . so jerry starts at minute so - and - so , and goes until minute so - and - so . and then mark paskin comes in . and he starts at minute such - and - such , and goes on till minute so - and - so . and then meanwhile , she 's listening to both of these guys ' channels , determining if there 're any cases of misclassification of speech as nothing , and nothing as speech , and and adding tag if that happens .
D: so she does the adjustments on those guys ?
C: but , wanted to say , his segmentation is so good , that , the part that listened to with her yesterday didn't need any adjustments of the bins .
B: on that meeting .
C: so far we haven't . so this is not gonna be major part of the process , at least not in not on ones that really
D: so if you don't have to adjust the bins , why not just do what it for all the channels ? why not just throw all the channels to ibm ?
C: there 's the question of whether she it 's question of how much time we want our transcriber to invest here when she 's gonna have to invest that when it comes back from ibm anyway . so if it 's only inserting "" - ""s here and there , then , wouldn't that be something that would be just as efficient to do at this end , instead of having it go through , then be patched together , then be double checked here .
B: but then we could just use the output of the detector , and do the beeping on it , and send it to
D: without having her check anything .
A: we just we just have to listen to it and see how good they are .
B: for some meetings , 'm 'm it
C: 'm 'm open to that ,
F: if it 's working ,
B: that 's and some on some meetings it 's good .
F: that sounds like good idea since as you say you have to do with the other end anyway .
C: the detector , this
D: we have to fix it when it comes back anyhow .
C: now , you were saying that they differ in how they work depending on channel sys systems and .
B: so we should perhaps just select meetings on which the speech - nonspeech detection works ,
C: but edu is great .
B: and just use , those meetings to to send to ibm and , do the other ones .
A: release to begin with .
F: what 's the problem the forget . is the problem the lapel ,
B: it really depends . my my impression is that it 's better for meetings with fewer speakers , and it 's better for meetings where nobody is breathing .
F: the dead meetings .
B: that 's it .
D: so this might suggest an alternative hybrid between these two things .
A: no , the undead meeting ,
D: so the one suggestion is we run thilo 's thing and then we have somebody go and adjust all the time boundaries and we send it to ibm . the other one is we just run his thing and send it to ibm . there 's another possibility if we find that there are some problems , and that is if we go ahead and we just run his , and we generate the beeps file , then we have somebody listen beeps file . and they listen to each section and say "" yes , no "" whether that section is intelligible or not . and it just , there 's little interface which will for all the "" yes "" - es it then that will be the final beep file .
C: that 's interesting ! cuz that 's that 's directly related to the end task .
D: it wouldn't be that much fun for transcriber to sit there , hear it , beep , yes or no . but it would be quick .
F: it would be quick but they 're still listening to everything .
D: but there 's no adjusting . and that 's what 's slow . there 's no adjusting of time boundaries .
C: , listening does take time too .
F: 'm 'm really tending towards
A: one and half times real time .
F: what 's the worst that happens ? as long as th on the other end they can say there 's there 's something conventions so that they say "" ? "" and then we can flag those later .
D: that 's true . we can just catch it at the catch everything at this side . maybe that 's the best way to go ,
A: it just depends on how
C: so was gonna say , edu - one is good enough , maybe we could include it in this in this set of , this we send .
B: there 's there are some meetings where it would it 's possible like this .
A: we won't know until we generate bunch of beep files automatically , listen to them and see how bad they are .
D: we won't be able to include it with this first thing , because there 's part of the process of the beep file which requires knowing the normalization coefficients .
A: that 's not hard to do . just it takes , it just takes five minutes rather than , taking second . so . hand hard - coded it .
D: except don't think that the the instructions for doing that was in that directory , didn't see where you had gener
A: no , but it 's easy enough to do .
B: doing the gain ? it 's no problem . adjusting the gain ?
D: no , getting the coefficients , for each channel .
B: that 's no problem .
D: so we just run that one
A: there are lots of ways to do it .
B: we can do that .
A: have one program that 'll do it . you can find other programs .
D: we just run that - sound - stat ? .
A: minus , capital .
F: but have another suggestion on that , which is , since , really what this is , is is trying to in the large , send the right thing to them and there is gonna be this post - processing step , why don't we check through bunch of things by sampling it ? in other words , rather than , , , saying we 're gonna listen to everything
A: didn't mean listen to everything , just see if they 're any good .
F: so you do bunch of meetings , you listen to little bit here and there , if it sounds like it 's almost always right and there 's not any big problem you send it to them .
D: send it to them .
F: and , , then they 'll send us back what we what they send back to us ,
C: that 'd be great .
F: and we 'll we 'll fix things up and some meetings will cost more time to fix up than others .
A: and we should just double - check with brian on few simple conventions on how they should mark things .
D: when they when there 's either no speech in there , they don't understand , things like that .
A: cuz @ @ what had originally said to brian was they 'll have to mark , when they can't distinguish between the foreground and background , because that was gonna be the most prevalent . but if we send them without editing , then we 're also gonna hafta have , notations for words that are cut off , and other sorts of , , acoustic problems .
C: they do already .
D: and they may just at what those cut - off words are , but we 're gonna adjust everything when we come back
A: but what we would like them to do is be conservative so that they should only write down the transcript if they 're . and otherwise they should mark it so that we can check .
C: we have the unintelligibility convention . and actually they have one also ,
F: maybe have an order of it 's probably in your paper that haven't looked at lately , an order of magnitude notion of how on good meeting , how often , do you get segments that come in the middle of words and , and in bad meeting how often ?
C: was is it in what is the
F: he 's saying , , that the edu meeting was good meeting ,
C: in good meeting ,
F: and so so it was almost it was almost always doing the right thing . so wanted to get some sense of what almost always meant . and then , in bad meeting , or some meetings where he said he 's had some problems , what does that mean ? so does one of the does it mean one percent and ten percent ? or does it mean five percent and fifty percent ? or maybe percentage isn't the right word , but how many how many per minute ,
B: the problem is that , nnn , the numbers ian gave in the paper is just , some frame error rate . so that 's that 's not really what will be effective for the transcribers , is they have to , in they have to insure that 's real spurt . and but , the numbers let me think . so the speech the amount of speech that is missed by the detector , for good meeting , th is around or under one percent , would say . but there can be but there can be more there 's there 's more amount speech the detector says there is speech , but there is none . so that can be lot when it 's really breathy channel .
F: but that 's less of problem . they 'll just listen . it 's just wasted time . and th and that 's for good meeting . now what about in meeting that you said we 've you 've had some more trouble with ?
B: 't really hhh , tsk . don't have really representative numbers , . did this on four meetings and only five minutes of every meet of these meetings so , it 's not that representative , it 's perhaps , it 's perhaps then it 's perhaps five percent of something , which the frames speech frames which are which are missed , but , 't can't really tell .
F: so so sometime , we might wanna go back and look at it more in terms of how many times is there spurt that 's that 's , interrupted ? something like that ?
C: the other problem is , that when it when it on the breathy ones , where you get breathing , , inti indicated as speech . and we could just indicate to the transcribers not to encode that if they we could still do the beep file .
F: again that is probably less of problem because if you 're if there 's if if word is split , then they might have to listen to it few times to really understand that they can't quite get it . whereas if they listen {nonvocalsound} to it and there 's don't hear any speech they 'd probably just listen to it once . so there 'd you 'd think there 'd be factor of three or four in , , cost function ,
B: so but that 's that really doesn't happen very often that that word is cut in the middle . that 's that 's really not normal .
F: so so what you 're saying is that nearly always what happens when there 's problem is that is that , there 's some , nonspeech that that is interpreted as speech .
B: that is marked as speech .
F: then , we really should just send the .
C: that would be great .
F: because that doesn't do any harm . if they hear , dog bark and they say what was the word ,
B: also thought of there are really some channels where it is almost , only bre breathing in it . and to re - run 's . . 've got - method with loops into the cross - correlation with the pzm mike , and then to reject everything which seems to be breath . so , could run this on those breathy channels , and perhaps throw out
A: that 's good idea .
C: that 's great idea .
F: but th again , that that would be good , and what that 'll do is just cut the time little further . but none of this is that really needs somebody doing these , explicit markings .
C: 'd be delighted with that , was very impressed with the with the result .
F: cuz the other thing that was concerning me about it was that it seemed specialized to the edu meeting , and that then when you get meeting like this , and you have bunch of different dominant speakers how are you gonna handle it . whereas this sounds like more general solution
C: pr much prefer this , was just trying to find way cuz don't think the staggered mixed channel is awfully good as way of handling overlaps .
D: that that really simplifies thing then . and we can just , , get the meeting , put the beeps file , send it off to ibm . with very little work on our side .
B: hear into it . listen to it ,
A: or at least sample it .
F: would just use some samples , make you don't send them three hours of "" bzzz "" .
B: that won't be good .
D: that would be very good . and then we can that 'll oughta be good way to get the pipeline going .
C: 'd be delighted .
B: and there 's there 's one point which , which we covered when when listened to one of the edu meetings , and that 's that somebody is playing sound from his laptop . and the speech - nonspeech detector just assigns randomly the speech to one of the channels , - haven't - didn't think of of this before ,
A: what can you do ?
B: but what shall we do about things like this ?
C: you were suggesting you suggested maybe just not sending that part of the meeting .
B: sometimes the the laptop is in the background and some somebody is talking , and , that 's really little bit confusing ,
A: it 's little bit confusing .
F: that 's life .
A: what 're we gonna do ? even hand - transcription would hand - transcriber would have trouble with that .
B: that 's that 's second question , "" what will different transcribers do with the laptop sound ? ""
F: what was the what was the laptop sound ? was it speech ,
B: it 's speech .
C: so my standard approach has been if it 's not someone close - miked , then , they don't end up on one of the close - miked channels . they end up on different channel . and we have any number of channels available , it 's an infinite number of channels . so just put them on some other channel .
B: when thi when this is sent to the - , transcribers , if they can tell that 's really
C: that 's right .
A: cuz there will be no channel on which it is foreground .
C: they have convention , in their own procedures , which is for background sound .
A: right , but , , in general don't think we want them transcribing the background , cuz that would be too much work . because in the overlap sections , then they 'll
D: don't think jane 's saying they 're gonna transcribe it , but they 'll just mark it as being there 's some background there ,
A: but that 's gonna be all over the place . how how will they tell the difference between that background and the dormal normal background of two people talking at once ?
C: it 'd be easy to say "" background laptop "" .
A: how would they know that ?
D: why would they treat them differently ?
C: because one of them
A: because otherwise it 's gonna be too much work for them to mark it . they 'll be marking it all over the place .
C: background laptop or , background lt wouldn't take any time .
A: but how are they gonna tell bet the difference between that and two people just talking at the same time ?
C: you can tell . acoustically , can't you tell ?
B: it 's really good sound ,
F: isn't there category something like , "" sounds for someone for whom there is no close mike "" ?
B: that would be very important ,
A: but how do we how do we do that for the folks ? how can they tell that ?
D: we may just have to do it when it gets back here .
A: that 's my opinion as . so we don't do anything for it with it .
C: that sounds good .
A: and they 'll just mark it however they mark it ,
C: that sounds good .
A: and we 'll correct it when it comes back .
B: there was category for @ @ speech .
A: no , not default .
C: as it comes back , we have when we can use the channelized interface for encoding it , then it 'll be easy for us to handle . but but if out of context , they can't tell if it 's channeled speak , , close - miked speaker or not , then that would be confusing to them . either way would be fine with me , don't really care .
F: shall we , do digits and get out of here ?
C: have have one question . do you think we should send the that whole meeting to them and not worry about pre - processing it ? what is we should leave the part with the audio in the , beep file that we send to ibm for that one , or should we start after the that part of the meeting is over in what we send . so , the part where they 're using sounds from their from their laptops .
B: with the laptop sound ,
C: if we have speech from the laptop should we just , excise that from what we send to ibm , or should we give it to them and let them do with it what they can ?
D: it 's gonna be too much work if we hafta worry about that .
C: that 'd be to have uniform procedure .
D: if we just send it all to them .
A: worry about it when we get back .
C: and see how they do .
D: worry about it when we get back in .
C: and give them freedom to indicate if it 's just not workable .
F: cuz , wouldn't don't think we would mind having that transcribed , if they did it .
A: as say , we 'll just have to listen to it and see how horrible it is . sample it , rather .
B: that will be little bit of problem
C: that 's great .
B: as it really switches around between two different channels , .
A: and they 're very it 's very audible ? on the close - talking channels ? it 's the same problem as the lapel mike .
F: let 's do digits .
C: so we read the transcript number first ,
A: are we gonna do it altogether or separately ?
B: what time is it ?
F: why don't we do it together ,
C: quarter to four .
F: that 's that 's fast way to do it . one , two , three ,
C: it 's interesting if there 're any more errors in these , than we had the first set .
A: there probably will be .
D: do you guys plug your ears when you do it ?
C: didn't this time .
D: how can you do that ?
B: perhaps there are lots of errors in it
A: total concentration . are you guys ready ?
D: you hate to have your ears plugged ?
","The main topics of the agenda were a paper submitted to Eurospeech and the organising of the recording transcriptions to be done by IBM.
The results presented in the former show a significant percentage of overlapping speech even without counting in backchanneling.
Additionally , the high error rate in the recognition of such overlapping speech by the SRI recogniser was minimised simply by changing the scoring method used.
Finally , a strong correlation between pauses and interruptions was confirmed.
All these measurements were based on the sample of available transcripts.
Other features , like prosody , will be studied in the near future.
An FTP directory containing such experimental data is being set up for the benefit of other researchers.
Regarding the transcriptions to be carried out by IBM , the discussion mainly concerned the format of the recordings that should be sent to them.
Suggestions included sending only the channels with the dominant speakers for transcription , but it was finally agreed on sending the original files with minimal modifications , as there will be extensive in-house post-processing.
Within this discussion , the rationale behind the coding of the time bins according to the flow of discourse was also explained.
The files made available in the FTP directory will be the original ones ( before down-sampling ) , as these seem to be wanted by other parties.
Moreover , as files may have been modified through different processing , tests will be carried out in order to ensure the generation of beep files in a consistent way.
Also towards this goal , some of the time bins will need to be merged.
On the other hand , the two meetings where time bins have been hand-coded in detail will be used to fine-tune the forced alignments.
Recordings will be sent to IBM for transcription.
Before that , the files will be automatically pre-segmented into speech/non-speech bins and the beeps will be inserted.
In order to make things easier for the transcribers , breathy channels , which are erroneously marked as speech , will be re-classified correctly with other methods.
All this pre-processing will have to be evaluated first by checking a sample of the output files.
Other issues , like whether and how synthesised speech off a laptop needs be transcribed , will be resolved during the in-house post-processing of the transcriptions.
There is a slight worry about the acceptance of the paper submitted to Eurospeech as the deadline was exceeded.
As to the content of the paper , the overlap statistics have not been normalised against the number of participants in the conversation , although the dependency is probably going to be a weak one.
Additionally , the correlation between pauses in speech and interruptions does not provide a cause-and-effect link for these phenomena.
The preparation of files for transcription by IBM is facing some minor difficulties , as some features ( hand-coded time boundaries , multiplicity of channels etc ) may complicate the generation of beep files.
Besides this , the automatic pre-segmentation has been deemed to be good , but there are still no specific measurements to verify this.
The pre-segmentation tool also classifies synthesised speech used in a recording as ""normal speech"" and assigns a random channel to it.
The transcribers at IBM may not be able to differentiate between the two.
A paper has been submitted to Eurospeech , which also includes a section on new corpora.
The statistics in the paper are based on the transcripts of two meeting and two telephone conversation corpora.
In the first two , the overlapped words vary between 9% and 18%.
The telephone conversation results were in-between and very similar to each other.
On the other hand , the automatic recognition errors affected by overlaps were reduced dramatically by focusing on regions with the foreground speech.
Furthermore , it was shown that after spurts , backchannels , disfluencies and discourse markers , the likelihood of interruption by other speakers was much higher.
Files with the recordings , as well as some experimental data will be available for other researchers in an FTP directory that is being set up.
Parts of the recordings will have to be beeped out by a script that has already been developed.
Finally , EDU meetings already recorded have now been pre-segmented and assigned to the transcribers at ICSI.
"
ami_abstractive_summary,Bed006.txt,"G: are you fey ?
B: what day is today ?
G: we 've met before , like , remember talking to you about aspect like that at some point or other .
F: it 's the twenty nineteenth .
D: that 's right , and you were my gsi briefly , until dropped the class .
B: right , right .
G: that 's right .
C: some in some introductions are in order .
G: getting ahead of myself .
C: everyone knows me , this is great . apart from that , the old gang , johno and bhaskara have been with us from day one and they 're engaged in various activities , some of which you will hear about today . ami is our counselor and spiritual guidance and also interested in problems concerning reference of the more complex type , and he sits in as interested participant and helper . is that good characterization ?
A: that 's pretty good , .
C: keith is not technically one of us yet , ha - ha . but it 's too late for him now .
G: "" one of us . ""
E: 've got the headset on after all .
C: officially he will be joining us in the summer . and hopefully it is by means of keith that we will be able to get better formal and better semantic idea of what construction is and how we can make it work for us . additionally his interest surpasses english because it also entails german , an extra capability of speaking and writing and understanding and reading that language . and , is there anyone who doesn't know nancy ? do you do nancy ?
B: made that joke already , nancy , sadly . the "" myself "" joke . before you came in .
G: about me or you ?
A: you could do it about you .
G: didn't mean to be humor copying , yes , know myself .
C: and fey is with us as of six days ago officially ? but in reality already much longer and next to some more or less bureaucratic with the data collection she 's also the wizard in the data collection
D: it 's very exciting .
C: we 're sticking with the term "" wizard "" ,
G: not witch - like . didn't take vote ?
C: , why don't we get started on that subject anyways . so we 're about to collect data and the the following things have happened since we last met . when will we three meet again ?
G: more than three of us .
C: what happened is that , "" "" , there was some confusion between you and jerry with the that leading to your talking to catherine snow , and he was he completely that some something confusing happened . his idea was to get the the lists of mayors of the department , it it 's exactly how you interpreted it ,
E: the list of majors in the department ?
C: ma - majors , majors . "" mayors "" .
G: the department has many mayors .
C: and just sending the little write - up that we did on to those email lists
D: so it was really carol snow who was confused , not me and not jerry .
C: so , that is
D: that 's good . so should still do that . and using the thing that you wrote up .
C: and we have little description of asking peop subjects to contact fey for recruiting them for our thing and there was some confusion as to the consent form , which is that what you just signed and since we have one already
G: did jerry talk to you about maybe using our class ? the students in the undergrad class that he 's teaching ?
C: he said we definitely "" yes "" , however there is always more people in in facul in department than are just taking his class or anybody else 's class at the moment and one should reach out and try and get them all .
G: but th it 's that people in his class cover different set is the cogsci department that you were talking about ? reaching out to ?
D: that 's what suggested to him , that people like jerry and george and et cetera just
G: cuz we have people from other areas advertise in their classes as .
D: or even could could do the actual
G: cuz know how to contact our students ,
D: that 's generally the way it 's done .
G: so if there 's something that you 're sending out you can also send me copy , me or bhaskara could either of us could post it to if it 's general solicitation that is just contact you then we can pro post it to the news group so you 'll send it
D: 'll send it ,
G: you can send it to me . we this doesn't concern you anymore , robert .
C: how however suggest that if you if you look at your email carefully you may think you may find that you already have it .
G: it 's fine .
C: we 'll see .
G: don't remember getting anything .
C: also we will talk about linguistics and computer science . and then , secondly , we had , you may remember , the problem with the re - phrasing , that subject always re - phrase the task that we gave them , and so we had meeting on friday talking about how to avoid that , and it proved finally fruitful in the sense that we came up with new scenario for how to get the subject to really have intentions and to act upon those , there the idea is now that next actually we need to hire one more person to actually do that job because it 's getting more complicated . so if anyone interested in what 'm about to describe , tell that person to write mail to me or jerry soon , the idea now is to come up with high level of abstract tasks "" go shopping "" "" take in batch of art "" do some sightseeing "" blah - blah - blah , analogous to what fey has started in in compiling here and already she has already gone to the trouble of anchoring it with specific entities and real world places you will find in heidelberg . so out of these these high level categories the subject can pick couple , such as if there is cop category in emptying your roll of film , the person can then decide "" , wanna do that at this place "" , make up their own itinerary and tasks and the person is not allowed to take this high level category list with them , the person is able to take notes on map that we will give him and the map will be tourist 's schematic representation with symbols for the objects . and so , the person can maybe make mental note that "" wanted to go shopping here "" and "" wanted to maybe take picture of that "" and "" maybe eat here "" and then goes in and solves the task with the system , and we 're gonna try out that
G: so you 'll have those say somewhere what their intention was so you still have the thing about having data where what the actual intention was ? there 's nothing that says "" these are the things you want to do "" so they 'll say "" these are the things want to do "" so they 'll have little bit more natural interaction ?
F: so they 'll be given this map , which means that they won't have to like ask the system for in for like high level information about where things are ?
C: it 's schematic tourist map . so it 'll be it 'll still require the that information
G: it it doesn't have like streets on it that would allow them to figure out their way
C: not not really the street network .
E: so you 're just saying like what part of town the things are in or whatever ?
C: the map is more means for them to have the buildings and their names and maybe some ma major streets and their names and we want to maybe ask them , if you have get it isolated street the , whatever , "" river street "" , and they know that they have decided that , yes , that 's where they want to do this action that they have it with them and they can actually read them or have the label for the object because it 's too hard to memorize all these st strange german names . and then we 're going to have another we 're gonna have another trial run ie the first with that new setup tomorrow at two and we have real interesting subject which is ron for who those who know him , he 's the founder of ici . so he 'll he 's around seven seventy years old , .
G: didn't know he was the founder .
C: and he also approached me and he offered to help our project and he was more thinking about some high level thinking tasks and said "" we need help you can come in as subject "" and he said "" "" . so that 's what 's gonna happen , tomorrow ,
G: using this new plan ,
C: new new set up . which 'll hopefully scrape together but , to fey , we already have blueprint and work with that . comments on that ? if not , we can move on . no more questions ?
E: 'm not understand this
G: so what 's the this is what you made , fey ?
E: 'm not understand everything that 's being talked about
G: like so so it 's just based on like the materials you had about heidelberg .
C: are you familiar with the with the very rough setup of the data ?
E: but imagine 'll just catch on .
D: based on the web site ,
G: there 's web site and then you could like figure out what the cate
D: it 's tourist information web site ,
E: this is where they 're supposed to
C: talk to machine and it breaks down and then the human comes on . the question is just how do we get the tasks in their head that they have an intention of doing something and have need to ask the system without giving them clear wording or phrasing of the task . because what will happen then is that people repeat , or as much as they can , of that phrasing .
G: are you worried about being able to identify the goals that we 've you guys have been talking about are this these identifying which of three modes their question concerns . so it 's like the enter versus view
C: we we will get protocol of the prior interaction , that 's where the instructor , the person we are going to hire , and the subjects sit down together with these high level things th the first question for the subject is , "" so these are things , , we thought tourist can do . is there anything that interests you ? "" and the person can say "" , sh this is something would do . would go shopping "" . and then we can this instructor can say "" , then you may want to find out how to get over here because this is where the shopping district is "" .
G: so the interaction beforehand will give them hints about how specific or how whatever though the kinds of questions that are going to ask during the actual session ?
C: just , what what would you like to buy and then there you wanna buy whatever cuckoos clocks and the there is store there . so the task then for that person is finding out how to get there , that 's what 's left . and we know that the intention is to enter because we know that the person wants to buy cuckoos clock .
G: so like those tasks are all gonna be unambiguous about which of the three modes .
A: so the idea is to try to get the actual phrasing that they might use and try to interfere as little as possible with their choice of words .
G: that they 'll be here ?
C: yes . in sense that 's exactly the the idea , which is never possible in in in lab situation ,
A: the one experiment th that that 've read somewhere , it was they used pictures . so to actually specify the tasks .
C: we had exactly that on our list of possible way things so we even made silly thing how that could work , how you control you are here you want to know how to get someplace , and this is the place and it 's museum and you want to do some and and there 's person looking at pictures . so , , this is exactly getting someplace with the intention of entering and looking at pictures . however , not only was the common census were among all participants of friday 's meeting was it 's gonna be very laborious to make these drawings for each different things , all the different actions , if possible , and also people will get caught up in the pictures . so all of sudden we 'll get descriptions of pictures in there . and people talking about pictures and pictorial representations would would still be willing to try it .
A: 'm 'm not saying it 's necessary but you might be able to combine text and some picture and also it will be good idea to show them the text and chew the task and then take the test away the the text away so that they are not guided by what you wrote , but can come up with their with their own
C: they will have no more linguistic matter in front of them when they enter this room . then suggest we move on to the to we have the edu project , let me make one more general remark , has two side actions , its action items that we 're do dealing with , one is modifying the smartkom parser and the other one is modifying the smartkom natural language generation module . and this is not too complicated but 'm just mentioning it put it in the framework because this is something we will talk about now . have some news from the generation , do you have news from the parser ?
F: yes , , would really it would be better if talked about it on friday . if that 's .
C: did you run into problems or did you run into not having time ?
F: but not any time part .
C: so that 's good . that 's better than running into problems . and do have some good news for the natural language generation however . and the good news is it 's done . meaning that tilman becker , who does the german one , actually took out some time and already did it in english for us . and so the version he 's sending us is already producing the english that 's needed to get by in version one point one .
F: so take it that was similar to the what we did for the parsing ?
C: it even though the generator is little bit more complex and it would have been , not changing one hundred words but maybe four hundred words , but it would have been but this is good news , and the the time do have it here ? the time is now fixed . it 's the last week of april until the fourth of may so it 's twenty - sixth through fourth . that they 'll be here . so it 's it 's extremely important that the two of you are also present in this town during that time .
B: what are the days ? april twenty - sixth to the may fourth ?
C: something like that .
B: 'll probably be here .
E: you will be here .
C: isn't finals coming up then after that ?
F: finals was that .
G: it doesn't really have much meaning to grad students but final projects might .
F: actually , that 's true .
C: anyway , so this is
B: 'll be here working on something . it 's just will be here , , in 'll be here too actually
C: no it 's just they 're coming for us so that we can bug them and ask them more questions and sit down together and write sensible code and they can give some talks and .
B: but it 's not like we need to be with them twenty - four hours day for the seven days that they 're here .
C: not not unless you really want to .
E: they 're very dependent
C: not unless you really want to . and they 're both guys so you may want to . that much from the parser and generator side , unless there are more questions on that .
G: so , no sample generator output yet ?
C: it just mail that , , he 's sending me the the soon
G: this is being sent ,
C: and was completely flabbergasted here and and that 's also it 's it 's going to produce the concept - to - speech blah - blah information for necessary for one point one in english based on the english , was like "" ,
E: we 're done .
C: we 're done ! ""
G: so that was like one of the first , the first task was getting it working for english . so that 's over now . is that right ? so the basic requirement fulfilled .
C: the basic requirement is fulfilled almost . when andreas stolcke and his gang , when they have changed the language model of the recognizer and the dictionary , then we can actually put it all together
G: so the speech recognizer also works .
C: you can speak into it and ask for tv and movie information if something actually happens and some answers come out , then we 're done .
G: if and they 're correct .
E: so it 's not done .
G: and they are correct .
E: perhaps if the answers have something to do with the questions .
G: it 's not just like anything . and they 're mostly in english . are they is it using the database ? the german tv movie . so all the actual data might be german names ? or are they all like american tv programs ?
E: want to see "" die dukes von hazard ""
C: so you how the german dialogue the german the demo dialogue actually works . the first thing is what 's , , showing on tv , and then the person is presented with what 's running on tv in germany on that day , on that evening and so you take one look at it and then you say "" that 's really nothing there 's nothing for me there "" "" what 's running in the cinemas ? "" so maybe there 's something better happening there . and then you get you 're shown what movies play which films , and it 's gonna be all the heidelberg movies and what films they are actually showing . and most of them are going to be hollywood movies . so , "" american beauty "" is "" american beauty "" ,
G: but they 're shown like on screen . it 's so would the generator , like the english language sentence of it is "" these are the follow the following films are being shown "" like that ?
C: but it in that sense it doesn't make in that case it doesn't really make sense to read them out loud . if you 're displaying them .
G: so it 'll just display
C: but it 'll tell you that this is what 's showing in heidelberg and there you go .
G: so we don't have to worry about
C: and the presentation agent will go "" hhh ! "" nuh ? like that the avatar . and then you pick movie and and it show shows you the times and you pick time and you pick seats and all of this . but it 's so this time we are at an advantage because it was problem for the german system to incorporate all these english movie titles . but in english , that 's not really problem , unless we get some topical german movies that have just come out and that are in their database . so the person may select "" huehner rennen "" or whatever .
E: "" chicken run "" .
C: then on to the modeling . there it is .
E: what 's the next thing ?
C: this is very rough but this is what johno and managed to come up with . the idea here is that
B: this is the the schema of the xml here , not an example like that .
C: this is not an xml this is towards an schema , the idea is , so , imagine we have library of schema such as the source - path - goal and then we have forced motion , we have cost action , we have whole library of schemas . and they 're gonna be , , fleshed out in their real ugly detail , source - path - goal , and there 's gonna be lot of on the goal and blah - blah , that goal can be and . and all the names could should be taken "" cum grano salis "" . the fact that we 're calling this "" action schema "" right now should not entail that we are going to continue calling this "" action schema "" . but what that means is we have here first of all on the in the first iteration stupid list of source - path - goal actions
B: actions that can be categorized with or that are related to source - path - goal .
C: and we will have forced motion and cost action actions .
B: and then those actions can be in multiple categories at the same time if necessary .
C: so push may be in in both push in this or this
G: forced motion and caused action ,
C: also , these things may or may not get their own structure in the future . so this is something that , , may also be res as result of your work in the future , we may find out that , , there 're really these subtle differences between even within the domain of entering in the light of source - path - goal schema , that we need to put in fill in additional structure up there . but it gives us handle . so with this we can slaughter the cow any anyway we want . it it is it was it gave us some headache , how do we avoid writing down that we have the enter source - path - goal that this but this gets the job done in that respect and maybe it is even conceptually somewhat adequate in sense that we 're talking about two different things . we 're talking more on the intention level , up there , and more on the this is the your basic bone schema , down there .
B: one question , robert . when you point at the screen is it your shadow that 'm supposed to look at ?
G: it 's the shadow .
B: whereas keep looking where your hand is ,
C: that wouldn't have helped you .
B: what this is that there 's an interface between what we are doing and the action planner
E: spit right here .
B: and right now the way the interface is "" action go "" and then they have the what the person claimed was the source and the person claimed as the goal passed on . and the problem is , is that the current system does not distinguish between goes of type "" going into "" , goes of type "" want to go to place where take picture of "" , et cetera .
C: so this is what it looks like now , some simple "" go "" action from it from an object named "" peter 's kirche "" of the type "" church "" to an object named "" powder - tower "" of the type "" tower "" .
G: this is the what the action planner uses ?
B: right . currently .
G: and is that and tha that 's changeable ? like are we adapting to it ?
C: we this is the output , , of the natural language understanding , the input into the action planning , as it is now . and what we are going to do , and you can see here , for johno focus the shadow , here you have the action and the domain object
G: what did you think he was doing ?
E: laser pointer would be most appropriate here .
B: robert likes to be abstract and that 's what thought he was doing .
G: you look up here .
C: between here and here , so as you can see this is on one level and we are going to add another "" struct "" , if you want , ie rich action description on that level . so in the future
G: so it 's just an additional information
C: in the future though , the content of hypothesis will not only be an object and an action and domain object but an action , domain object , and rich action description ,
G: that doesn't hurt the current way .
B: which which we 're abbreviating as "" rad "" .
F: so you had like an action schema and source - path - goal schema , so how does this source - path - goal schema fit into the action schema ? like is it one of the tags there ?
G: can you go back to that one ?
B: so the source - path - goal schema in this case , 've if understand how we described we set this up , cuz we 've been arguing about it all week , but we 'll hold the in this case it will hold the the features . 'm not it 's hard for me to exactly so that will store the object that is the source will store the object that we 're going from , the goal will store the
G: so the fillers of the role source .
B: we 'll fill those in fill those roles in , the action - schemas have extra see we so those are schemas exist because in case we need extra information instead of just making it an attribute and which is just one thing we decided to make it 's own entity so that we could explode it out later on in case there is some structure that we need to exploit .
G: this is just xml mo notational but the fact that it 's action schema and then slash action schema that 's whole entit
B: that 's block ,
G: that 's block , whereas source is just an attribute ?
C: no , no . source is just not spelled out here . source meaning source will be will have name , type , maybe dimensionality ,
G: - , - . could it could also be blocked out then as
C: source it will be , we know lot about sources so we 'll put all of that in source . but it 's independent whether we are using the spg schema in an enter , view , or approach mode , this is just properties of the spg schema . we can talk about paths being the fastest , the quickest , the nicest and , or and the trajector should be coming in there as . and then the same about goals .
G: so the question is when you actually fill one of these out , it 'll be under action schema ? it 's gonna be one you 'll pick one of those for these are this is just layout of the possible that could go play that role .
B: right , so the the roles will be filled in with the schema and then what actual action is chosen is will be in the in the action schema section .
G: so one question . this was in this case it 's all clear , obvious , but you can think of the enter , view and approach as each having their roles , the it 's it 's implicit that the person that 's moving is doing entering viewing and approaching , but the usual thing is we have bindings between they 're like action specific roles and the more general source - path - goal specific roles . so are we worrying about that or not for now ?
C: yes , yes . since you bring it up now , we will worry about it . tell us more about it . what do you what do you
G: what 's that ? may be just reading this and interpreting it into my head in the way that 've always viewed things and that may or may not be what you guys intended . but if it is , then the top block is like , you have to list exactly what - schema or in this action schema , there 'll be certain one , that has its own structure and maybe it has about that specific to entering or viewing or approaching , but those could include roles like the thing that you 're viewing , the thing that you 're entering , the thing that you 're
E: so very specific role names are "" viewed thing "" , "" entered thing ""
G: think of enter , view and approach as frames and they have frame - specific parameters and roles and you can also describe them in general way as source - path - goal schema and maybe there 's other image schemas that you could add after this that , how do they work in terms of force dynamics
C: - , - .
G: or how do they work in terms of other things . so all of those have either specific frame specific roles or more general frame specific roles that might have binding . so the question is are how to represent when things are linked in certain way . so we know for enter that there 's container potentially involved and it 's not if you wanna have in the same level as the action schema spg schema it 's somewhere in there that you need to represent that there is some container and the interior of it corresponds to some part of the source - path - goal goal goal in this case . so is there an easy way in this notation to show when there 's identity between things and di if that 's something we need to invent
B: wa wasn't there supposed to be link in the if this answers your question , was just staring at this while you were talking , link between the action schema , field in the in the schema for the image schemas that would link us to which action schema we were supposed to use
C: that 's that 's one thing is that we can link up , think also that we can have one or as many as we want links from the schema up to the action description of it . but the notion got from nancy 's idea was that we may find concepts floating around in the action description of the action "" enter "" frame up there that are , when you talk about the real world , actually identical to the goal of the source - path - goal schema ,
G: right , right .
C: and do we have means of telling it within that and the answer is . the way we have those means that are even part of the - three - api , meaning we can reference .
G: that 's exactly what is necessary .
C: this referencing thing however is of temporary nature because sooner or later the - three - will be finished with their - path , , , specification and then it 's going to be even much nicer . then we have real means of pointing at an individual instantiation of one of our elements here and link it to another one , and this not only within document but also via documents , and all in very easy homogenous framework .
G: so happen to know how what "" sooner or later "" means like in practice ?
C: but it 's soon . so it 's it 's the spec is there and it 's gonna part of the - three - ap api filed by the end of this year so that this means we can start using it now . but this is technical detail .
G: so pointer way to really say pointers .
B: references from the roles in the schema the bottom schemas to the action schemas is wha 'm assuming .
C: personally , 'm looking even more forward to the day when we 're going to have forms , which is form of notation where it allows you to say that if the spg action up there is enter , then the goal type can never be statue .
G: so you have constraints that are dependent on the actual specific filler , , of some attribute .
C: this , , does not make sense in light of the statue of liberty , however it is these things are imaginable .
F: so , like are you gonna have similar schemas for fm
G: or the gateway arch in st .
F: like forced motion and caused action and like you have for spg ? and if so like can are you able to enforce that if it 's if it 's spg action then you have that schema , if it 's forced motion then you have the other schema present in the
C: we have no means of enforcing that , so it would be considered valid if we have an spg action "" enter "" and no spg schema , but forced action schema .
G: whi - which is not bad , because , that there 's multiple sens that particular case , there 's mult there 's forced side of that verb as .
C: it maybe it means we had nothing to say about the source - path - goal . what 's also , and for for me in my mind it 's it 's crucially necessary , is that we can have multiple schemas and multiple action schemas in parallel . and we started thinking about going through our bakery questions , so when say "" is there bakery here ? "" do ultimately want our module to be able to first of all tell the rest of the system "" hey this person actually wants to go there "" and "" "" , that person actually wants to buy something to eat there . and if these are two different schemas , ie the source - path - goal schema of getting there and then the buying snacks schema ,
G: would they both be listed here in under so under action schema there 's list that can include both things .
C: ye , they would both schemas would appear , so what is the is there "" buying snacks "" schema ?
G: that 's interesting .
C: what is the have the buying snack schema ?
D: buying buying his food
E: 'm there 's commercial event schema in there somewhere .
C: "" commercial event "" . so so we would we would instantiate the spg schema with source - path - goal blah - blah and the buying event at which however that looks like , the place thing to buy .
G: would you say that the like you could have flat structure and just say these are two independent things , but there 's also this like causal , so one is really facilitating the other and it 's part of compound action of some kind , which has structure .
C: now it 's technically possible that you can fit schema within schema , and schema within schemata
G: that 's nicer for lot of reasons but might be pain
C: for me it seems that
G: there are truly times when you have two independent goals that they might express at once , but in this case it 's really like there 's purpo means that for achieving some other purpose .
C: if 'm if 'm recipient of such message and get source - path - goal where the goal is bakery and then get commercial action which takes place in bakery , and and they are , via identifiers , identified to be the same thing here .
G: see that bothers me that they 're the same thing .
C: no , no , just the
G: because they 're two different things one of which is you could think of one sub pru whatever pre - condition for the second . so there 's like levels of granularity . so there 's there 's single event of which they are both part . and they 're independently they are events which have very different characters as far as source - path - goal whatever . so when you identify source - path - goal and whatever , there 's gonna to be desire , whatever , eating , hunger , whatever other frames you have involved , they have to match up in ways . so it seems like each of them has its own internal structure and mapping to these schemas but that 's just that 's just me .
C: we 're gonna hit lot of interesting problems and as prefaced it this is the result of one week of arguing about it
E: still am not entirely that really fully grasp the syntax of this .
B: it 's not it 's not actually very actually , it doesn't actually
C: it occur it occurs to me that ne
E: or the intended interpretation of this .
C: should have we should have added an ano an xml example , or some xml examples
G: that would be that would be .
C: and this is on on my list of things until next week . it 's also question of the recursiveness and hier hierarchy in there . do we want the schemas just blump ? it 's if we can actually get it so that we can , out of one utterance , activate more than one schema , , then we 're already pretty good ,
A: you have to be careful with that thing because many actions presuppose some almost infinitely many other actions . so if you go to bakery you have general intention of not being hungry . you have specific intentions to cross the traffic light to get there . you have further specific intentions to left to lift your right foot and so you really have to focus on on and decide the level of abstraction that you aim at it zero in on that , and more or less ignore the rest , unless there is some implications that you want to constant draw from sub - tasks that are relevant but very difficult .
G: the other thing that thought of is that you could want to go to the bakery because you 're supposed to meet your friend there or som so you like being able to infer the second thing is very useful and probably often right .
B: the the utterance was "" is there bakery around here ? "" ,
G: but having them separate
B: not "" want to go to bakery . ""
G: maybe their friend said they were going to meet them in bakery around the area . and 'm , 'm inventing contexts which are maybe unlikely , but it 's still the case that you could you could override that default by giving extra information which is to me reason why you would keep the inference of that separate from the knowledge of "" they really want to there 's bakery around here "" , which is direct .
C: there there should never be hard coded shortcut from the bakery question to the double schema thing , and , , when have traveled with my friends we make these exactly these kinds of appointments .
G: it 's met someone at the bakery in the victoria station train station london before ,
A: have question about the slot of the spg action . so the enter - view - approach the the eva , those are fixed slots in this particular action . every action of this kind will have choice . or or will it just
E: every spg every spg action either is an enter or view or an approach ,
A: right , right . so so for each particular action that you may want to characterize you would have some number of slots that define in some way what this action is all about . it can be either , or . so is it fixed number or do you leave it open it could be between one and fifteen it 's it 's flexible .
C: it depends on if you actually write down the schema then you have to say it 's either one of them or it can be none , or it can be any of them . however the it seems to be sensible to me to to view them as mutually exclusive maybe even not .
G: do you mean within the source - path - goal actions ?
C: and how where is the end ?
A: no , no . there actually by my question is simpler than that , so you have an spg action and it has three different aspects because you can either enter building or view it or approach it and touch it . now you define another action , it 's it 's called - one
C: forced action or forced motion .
A: different action . and this action - two would have various variable possibilities of interpreting what you would like to do . and in way similar to either enter - view - approach you may want to send letter , read letter , or dictate letter , let 's say .
B: if 'm gonna answer your question or not with this , but the categories inside of action schemas , so , spg action is category . although what we 're specifying here is this is category where the actions "" enter , view and approach "" would fall into because they have related source - path - goal schema in our tourist domain . cuz viewing in tourist domain is going up to it and or actually going from one place to another to take picture , in this in
A: so it 's automatic derived fr from the structure that is built elsewhere .
E: this is cate this category structure here , what are some types of action schemas ? one of the types of action schemas is source - path - goal action . and what are some types of that ? and an enter , view , an approach . those are all source - path - goal actions .
B: inside of enter there will be roles that can be filled . so if want to go from outside to inside then you 'd have the roles that need to filled , where you 'd have source - path - goal set of roles . so you 'd the source would be outside and path is to the door or whatever , so if you wanted to have new type of action you 'd create new type of category . then this category would we would put it we would put new action in the in the categories that in which it has the every action has set of related schemas like source - path - goal or force , whatever , so we would put "" write letter "" in the categories that in which it had it had schemas
E: there could be communication event action like that
B: schemas that of that type .
E: and you could write it .
B: and then later , , there the we have communication event action where we 'd define it down there as
G: so there 's bit redundancy , in which the things that go into particular you have categories at the top under action schema and the things that go under particular category are supposed to have corresponding schema definition for that type . so what 's the function of having it up there too ? 'm wondering whether you could just have under action schema you could just say whatever it 's gonna be enter , view or approach or whatever number of things and pos partly because you need to know somewhere that those things fall into some categories . and it may be multiple categories as you say which is the reason why it gets little messy but if it has if it 's supposed to be categorized in category then the corresponding schema will be among the structures that follow .
B: this is one of things we were arguing about .
C: th this is this this is this is more this is probably the way that th that 's the way that seemed more intuitive to johno
G: you didn't tell me to
C: also for while for
G: but now you guys have seen the light .
C: no , no . we have not we have not seen the light .
B: the the reason one reason we 're doing it this way is in case there 's extra structure that 's in the enter action that 's not captured by the schemas ,
G: it 's easy to go back and forth which is why would think you would say enter and then just say all the things that are relevant specifically to enter . and then the things that are abstract will be in the abstract things as . and that 's why the bindings become useful .
E: ri - you 'd like so you 're saying you could practically turn this structure inside out ?
G: ye - see what you mean by that , but don't if would would need to have have that .
C: get get rid of the spg slash something or the sub - actions category , because what does that tell us ? and agree that this is something we need to discuss ,
G: what you could say is for enter , you could say "" here , list all the kinds of schemas that on the category that
E: list all the parent categories .
G: list all the parent categories "" . it 's just like frame hierarchy , like you have these blended frames . so you would say enter and you 'd say my parent frames are such - and - such , and then those are the ones that actually you then actually define and say how the roles bind to your specific roles which will probably be richer and fuller and have other in there .
E: this sounds like paper 've read around here recently in terms of
G: it could be not coincidence . like said , 'm 'm just hitting everything with hammer that developed , 'm just telling you what , you just hit the button and it 's like
E: but there 's good question here . like , do you when do you need damn this headset ! when you this , that 's all recorded .
G: "" damn this project . "" no just kidding .
E: how do how do come at this question ? don't see why you would who uses this this data structure ? ? like , do you say "" alright 'm going to do an spg action "" . and then somebody ne either the computer or the user says "" alright , , want to do source - path - goal action so what are my choices among that ? "" and "" , , so do an enter - view - approach "" . it 's not like that , it 's more like you say "" want to , want to do an enter . "" and then you 're more interested in knowing what the parent categories are of that . so that the the representation that you were just talking about seems more relevant to the kinds of things you would have to do ?
B: 'm not if understand your question . only one of those things are gonna be lit up when we pass this on . so only enter will be if we if our module decided that enter is the case , view and approach will not be there .
C: it 's it came into my mind that sometimes even two could be on , and would be interesting .
E: mayb - maybe 'm not understanding where this comes from and where this goes to .
B: in that case , we can't we can't if
C: let 's let 's not
B: if that 's the case we our don't think our system can handle that currently .
E: what are we doing with this ?
C: no , not .
G: "" approach and then enter . ""
C: the the in some sense we ex get the task done extremely because this is exactly the discussion we need . no more qualifiers than that .
G: no , this is the useful ,
C: and and th hope let 's make sharper claim . we will not end this discussion anytime soon . and it 's gonna get more and more complex the complexer and larger our domains get . and we will have all of our points in writing pretty soon . so this is about being recorded also .
D: that 's true .
B: the the in terms of why is it 's laid out like this versus some other that 's contentious point between the two of us but this is one wa so this is way to link the way these roles are filled out to the action .
E: in my view .
B: because if we know that enter is is an spg action , we know to look for an spg schema and put the appropriate fill in the appropriate roles later on .
G: and you could have also indicated that by saying "" enter , what are the kinds of action am ? "" so there 's just like reverse organization , so like unless @ @ are there reasons why one is better than the other that come from other sources ?
C: yes because nobod no the modules don't this is this is schema that defines xml messages that are passed from one module to another , mainly meaning from the natural language understanding , or from the deep language understanding to the action planner . now the reason for not using this approach is because you always will have to go back , each module will try have to go back to look up which entity can have which , , entity can have which parents , so you always need the whole body of your model to figure out what belongs to what . or you always send it along with it , so you always send up "" here am am this person , and have these parents "" in every message .
G: so it 's just like pain to have to send it .
C: it may or may not be just pain it 's it 's 'm completely willing to to throw all of this away and completely redo it , and and it after some iterations we may just do that .
E: would just like to ask like , if it could happen for next time , just beca cuz 'm new and don't really just what to make of this and what this is for , and like that , , so if someone could make an example of what would actually be in it , like first of all what modules are talking to each other using this ,
C: we will promise for the next time to have fleshed out xml examples for run through and see how this then translates , and how this can come about , including the "" miracle occurs here "" part . is there more to be said ? in principle what that this approach does , and whether or not we take the enter - view and we all throw up the ladder wha how do how does professor peter call that ? the hhh , silence su sublimination ? throwing somebody up the stairs ? have you never read the peter 's principle
F: people reach their level of max their level of at which they 're incompetent or whatever .
A: right , right .
C: and then you can throw them up the stairs so we can promote enter - view all up bit and get rid of the blah - - blah asterisk sub - action item altogether . no no problem with that and we we will play around with all of them but the principal distinction between having the pure schema and their instantiations on the one hand , and adding some whatever , more intention oriented specification on parallel to that this approach seems to be workable to me . if you all share that opinion then that made my day much happier .
B: this is simple way to link roles to actions .
G: . that 's fine .
B: that 's the that was the intent of it , .
G: that 's true .
B: so do 'm 'm not
C: 'm 'm never happy when he uses the word "" roles "" ,
E: you meant pastries , then ?
B: pastries is what 'm talking about .
G: ba the bak bakery example .
E: this is the bakery example . got it . alright .
G: 'll agree to that , then .
C: that 's all have for today . there 's one more issue . bhaskara brought that one up . meeting time rescheduling .
G: didn't you say something about friday ,
C: so it looks like you have not been partaking , the monday at three ' clock time has turned out to be not good anymore . so people have been thinking about an alternative time and the one we came up with is friday two - thirty ? what was it ?
B: you have class until two , so if we don't want him if we don't want him to run over here
C: two - th two - thirty - ish or three or friday at three around that time .
B: two thirty - ish or three is
G: that would be good .
A: that 's fine .
C: and know that you have until three you 're busy ?
G: so three is sounds good ? 'll be free by then .
E: could do that . earlier on friday is better but three if it were three or three thirty time then would take the three or whatever , but three is fine .
C: and you can always make it shortly after three probably .
D: and don't need to be here particularly deeply .
C: no , but , you are more than welcome if you think that this discussion gets you anywhere in your life then you 're free to
D: it 's fascinating .
G: "" that 's the right answer . ""
D: 'm just glad that don't have to work it out 'm just glad that don't have to work it out myself , that 'm not involved in the working out of it
C: but you 're linguist .
D: that 's why 'm glad that 'm not involved in working it out .
A: so it 's at friday at three ?
E: so already again this week ,
C: how diligent do we feel ? do feel that we have done our chores for this week
F: so clearly there 's talk about the the parser changes on friday at least ,
C: bhaskara will do the big show on friday .
G: and you guys will argue some more ?
B: and between now and then .
E: between now and then .
G: and have some ? and we 'll get the summary like , this the , short version ,
A: an - and would like to second keith 's request . an example wo would be to have detailed example .
C: yes . 've 've 'm on record for promising that now .
G: like have it we 'll have it in writing . or , better , speech .
B: the other good thing about it is jerry can be on here on friday and he can weigh in as .
C: and if you can get that binding point also maybe with example that would be helpful for johno and me .
G: let 's they 're
E: you 've got one on hand ,
G: have several in my head , always thinking about binding .
C: the the binding is technically no problem but it 's it for me it seems to be conceptually important that we find out if we can if there if there are things in there that are general nature , we should distill them out and put them where the schemas are . if there are things that are intention - specific , then we should put them up somewhere ,
G: so , in general they 'll be bindings across both intentions and the actions .
C: that 's wonderful .
G: so it 's gen it 's general across all of these things it 's like shastri would say binding is like an essential cognitive process . so don't will be isolated to one or the two , but you can definitely figure out where sometimes things belong and so actually 'm not would be curious to see how separate the intention part and the action part are in the system . like know the whole thing is like intention lattice , like that , so is the ri right now are the ideas the rich the rad or whatever is one potential block inside intention . it 's still it 's still mainly intention hypothesis and then that 's just one way to describe the action part of it .
B: it 's an attempt to refine it .
C: it 's an it 's
G: not just that you want to go from here to here , it 's that the action is what you intend and this action consists of all com complicated modules and image schemas and whatever .
C: and and there will be relatively high level of redundancy in the sense that ultimately one so th so that if we want to get really cocky we will say "" if you really look at it , you just need our rad . "" you can throw the rest away , because you 're not gonna get anymore information out of the action as you find it there in the domain object . but then again in this case , the domain object may contain information that we don't really care about either . but we 'll see that then , and how it evolves . if people really like our rad , what might happen is that they will get rid of that action thing completely , and leave it up for us to get the parser input
G: mmm . we know the things that make use of this thing so that we can just change them so that they make use of rad .
D: you don't have to use the acronym .
G: 't believe we 're using this term . so 'm like rad ! like every time say it , it 's horrible . see what you mean .
B: rad 's great term .
G: but what is the "" why "" ?
E: it 's rad , even ! it happened to be what it stands for .
B: it just happened to be the acronym .
G: that 's doesn't make it great term . it 's just like those jokes where you have to work on both levels .
D: just think of it as "" wheel "" in german .
C: but if you if you work in th in that xml community it is great acronym
G: do you see what ?
C: because it evokes whatever rdf rdf is the biggest thing that 's the rich "" resource description framework ""
E: "" rich de ""
C: so , description , having the word term "" description "" in there is wonderful , "" rich "" is also great ,
B: who doesn't like to be
E: everybody likes action . plus it 's hip . the kids 'll like it .
G: but what if it 's not an action ?
C: it 's it 's rad ,
D: all the kids 'll love it .
G: and intentions will be "" rid "" ? are the are the sample data that you guys showed sometime ago maybe you 're gonna run trial tomorrow . 'm just wondering whether the ac some the actual sentences from this domain will be available . cuz it 'd be for me to like look if 'm thinking about examples 'm mostly looking at child language which will have some overlap but not total with the kinds of things that you guys are getting . so you showed some in this here before and maybe you 've posted it before but where would look if want to see ?
C: you want audio ? or do you want transcript ?
G: no just transcript .
C: just transcript is just not available because nobody has transcribed it yet . 'll transcribe it though .
G: take that back then .
C: it 's no problem .
G: don't don't make it high priority if you just tell me like like two examples the the representational problems are 'm , will be there , like enough for me to think about .
C: whoever wants and comes , and can . the big parser show . now you can all turn off your
","The data collection script has been slightly modified , so that it encourages more natural dialogue between the subjects and the ""wizard"".
Another trial run will take place , while a call to recruit subjects is being emailed to students.
Meanwhile , the translation of the TV and cinema information system to english is almost complete.
This was the basic requirement of the project.
On the other hand , there was a presentation of the model that offers more elaborate action planning for SmartKom , of which Enter/View/Approach ( EVA ) modes are a part.
These modes will form categories of complete XML schemas with information filled in from the language understanding in a more elaborate way than the current Object-""Go Action""-Object model.
These categories will , in turn , be linked with action schemas , one of which is Source-Path-Goal ( SPG ).
Categories and action schemas can have -in theory- any number of blocks depending on the expansion of the domain.
The notation provides for linking and referencing between different schemas.
The model also allows for multiple action schemas to be triggered in parallel.
However , the structure of the model is open for discussion , since its use was to elicit discussion and highlight issues.
As the data collection is about to start , a call for the recruitment of subjects is going to be sent out.
The main pool of subjects is going to be the student community in the institute.
Along with the ""wizard"" , who is going to be an integral part of the experiments , another person needs to be hired as the instructor for the tasks involved in them.
Meetings were rescheduled and are now going to take place on Fridays.
For the next meeting , there is going to be a presentation of the modifications in the parser module of the basic system.
Additionally , the proposed XML model will be put to the test with concrete data.
Similarly , such examples will clarify issues relating to the binding and redundancy of features with common characteristics amongst the shcemas ( eg ""Container"" for Enter and ""Goal"" for SPG ).
Subjects in the trial runs of the experiment were given detailed descriptions of the tasks , which led to the subsequent dialogue being a re-iteration or re-phrasing of the instructions.
Using pictures instead would be one way to deal with the problem , however , it was deemed too laborious and it would divert the focus of the experiment.
As the original action planner of the SmartKom system only included a generic SPG schema , a new module was presented that allows for variety in the user intentions to be included.
This being only a model , there are several issues that will need to be clarified in the future.
How the model deals with redundancy of information among categories and action schemas , and whether a flat or a hierarchical model would be preferable are two of them.
What is also clear is that as the domain of research broadens beyond the study of EVA modes , the complexity of the model will also increase.
Another trial run of the data collection experiment is to take place , while subjects are being recruited.
There have been some adjustments in the script.
The prior description of tasks the subjects are going to be given is now going to be more schematic , although the intentions are still going to be clear.
The lack of detailed , written explanation will hopefully encourage more natural and varied dialogue between subjects and ""wizard"".
On the other hand , the generator module of the system has been translated from german.
Eventually , a user is going to be able to request and receive TV- and cinema-related information in english.
This will satisfy the basic project requirements.
The model of a new module for SmartKom was presented.
It is an interface between the language understanding and the action planning modules.
One layer of XML schemas creates a richer representation of the linguistic analysis , which is subsequently used to trigger one or more action schemas.
The model keeps the concept of XML messages being sent between the modules of the system , although it is open-ended as to the number of schemas involved.
"
ami_abstractive_summary,Bed011.txt,"C: now can you give me the remote ?
D: so eva , co could you read your numbers ?
A: go ahead and read .
D: let 's get started . hopefully nancy will come , if not , she won't .
B: robert , do you have any way to turn off your screensaver on there so that it 's not going off every , it seems to have about at two minute
C: 've it 's not that didn't try . and told it to stay on forever and ever , but if it 's not plugged in it just doesn't obey my commands . it has mind . but , keep on wiggling .
E: wants to conserve .
C: but we 'll just be working on it at intensity so it doesn't happen . we 'll see . should we plunge right into it ? so , would you like to so what 've tried to do here is list all the decision nodes that we have identified on this side . commented and what they 're about and the properties we may give them . and here are the tasks to be implemented via our data collection . so all of these tasks the reading is out of these tasks more or less imply that the user wants to go there , sometime or the other . and analogously , here we have our eva intention . and these are the data tasks where we can assume the person would like to enter , view or just approach the thing . analogously the same on the object information we can see that , , we have created these tasks before we came up with our decision nodes so there 's lot of things where we have no analogous tasks , and that may or may not be problem . we can change the tasks slightly if we feel that we should have data for for every decision node so trying to im implant the intention of going to place now , going to place later on the same tour , or trying to plant the intention of going sometime on the next tour , or the next day or whenever .
D: right , right .
C: but that might be overdoing it little .
D: so let me pop up level . and make that we 're all oriented the same . so what we 're gonna do today is two related things . one of them is to work on the semantics of the belief - net which is going to be the main inference engine for thi the system making decisions . and decisions are going to turn out to be parameter choices for calls on other modules . so the natural language understanding thing is , we think gonna only have to choose parameters , but , fairly large set of parameters . so to do that , we need to do two things . one of which is figure out wh the choices are , which we 've done fair amount . then we need to figure out what influences its choices and finally we have to do some technical work on the actual belief relations and presumably estimates of the probabilities and . but we aren't gonna do the probability today . technical we 'll do another day . probably next week . but we are gonna worry about all the decisions and the things that pert that contribute to them . and we 're also , in the same process , going to work with fey on what there should be in the dialogues . so one of the steps that 's coming up real soon is to actually get subjects in here , and have them actually record like this . record dialogues more or less . and depending on what fey provokes them to say , we 'll get information on different things .
C: how people phrase different intentions more or less ,
D: fo - people with the phrase them and so for , , keith and people worrying about what constructions people use , we have some we have some ways to affect that the dialogues go . so what robert kindly did , is to lay out table of the kinds of things that might come up , and , the kinds of decisions . so the on the left are decision nodes , and discreet values . so if we 're right , you can get by with just this middle column worth of decisions , and it 's not all that many , and it 's perfectly feasible technically to build belief - nets that will do that . and he has handout .
C: maybe it was too fast plunging in there , because we have two updates . you can look at this if you want , these are what our subject 's going to have to fill out . any comments still be made and the changes will be put in correspondingly . let me summarize in two sentences , mainly for eva 's benefit , who probably has not heard about the data collection , . or have you heard about it ? we were gonna put this in front of people . they give us some information on themselves . then then they will read task where lots of german words are thrown in between . and and they have to read isolated proper names no , this is not the release form . this is the speaker information form . the release form is over there in that box .
D: alright , fair enough .
C: and and then they gonna have to choose from one of these tasks , which are listed here . they they pick couple , say three six . six different things they think they would do if they were in heidelberg or traveling someplace and and they have map . very sketchy , simplified map . and they can take notes on that map . and then they call this computer system that works perfectly , and understands everything .
B: this is fictional system ,
C: the comp , the computer system sits right in front of you , that 's fey .
E: 've understand everything .
D: and she does know everything .
C: and she has way of making this machine talk . so she can copy sentences into window , or type really fast and this machine will use speech synthesis to produce that . so if you ask "" how do get to the castle "" then several seconds later it 'll come out of here "" in order to get to the castle you do "" and and then after three tasks the system breaks down . and fey comes on the phone as human operator . and says "" the system broke down but let 's continue . "" and we get the idea what people do when they think they speak to machine and what people say when they think they speak to human , or know , or assume they speak to human . that 's the data collection . and and fey has some thirty subjects lined up ? and and they 're ready to roll .
E: and more and more every day .
C: and we 're gonna start tomorrow at three ?
E: because we whether that person is coming or not ,
C: around four - ish . and we 're still looking for room on the sixth floor because they stole away that conference room . behind our backs .
D: see , we have to it 's tricky . we 'll let 's let we 'll do that off - line , .
C: but it 's happening . david and jane and lila are working on that as we speak . that was the the data collection in nutshell . and report so did this but also tried to do this so if click on here , isn't this wonderful ? we get to the belief - net just focusing on the go - there node . analogously this would be the reason node and the timing node and . and what what happened is that design - wise 'd noticed that we can we still get lot of errors from lot of points to one of these sub go - there user go - there situation nodes . so came up with couple of additional nodes here where whether the user is thrifty or not , and what his budget is currently like , is going to result in some financial state of the user . how much will he is he willing to spend ? or can spend . being the same at this just the money available , which may influence us , whether he wants to go there if it is charging tons of dollars for admission or its gonna cost lot of twenty - two million to fly to international space station , . just not all people can do that . so , and this actually turned out to be pretty key , because having specified these this intermediate level and noticing that everything that happens here let 's go to our favorite endpoint one is again more or less we have then the situation nodes contributing to the endpoint situation node , which contributes to the endpoint and . now draw straight lines from these to here , meaning it goes where the sub - everything that comes from situation , everything that comes from user goes with the sub - , and whatever we specify for the so - called "" keith node "" , or the discourse , what comes from the parser , construction parser , will contribute to the and the ontology to the sub - node . and one just has to watch which also final decision node so it doesn't make sense to figure out whether he wants to enter , view or approach an object if he never wants to go there in the first place . but this makes the design thing fairly simple . and now all that 's left to do then is the cpg 's , the conditional probabilities , for the likelihood of person having enough money , actually wanting to go place if it costs , this or that . and once bhaskara has finished his classwork that 's where we 're gonna end up doing . you get involved in that process too . and and for now the question is "" how much of these decisions do we want to build in explicitly into our data collection ? "" so , one could think of we could call the see or , people who visit the zoo we could call it "" visit the zoo tomorrow "" , so we have an intention of seeing something , but not now but later .
D: so let 's see th that from one point of view , , , all these places are the same , so that that , in terms of the linguistics and , there may be few different kinds of places , so th it seems to me that we ought to decide , what things are are actually going to matter to us . and , so the zoo , and the university and the castle , et cetera . are all big - ish things that have different parts to them , and one of them might be fine .
C: the the reason why we did it that way , as as reminder , is no person is gonna do all of them . they 're just gonna select , according to their preferences . "" , , usually visit zoos , or usually visit castles , or usually "" and then you pick that one .
D: right , no , but th point is to to build system that 's got everything in it that might happen you do one thing .
E: they 're redundant .
D: to build system that had the most data on relatively confined set of things , you do something else . and the speech people , , are gonna do better if they if things come up repeatedly . now , , if everybody says exactly the same thing then it 's not interesting . so , all 'm saying is th there 's there 's question of what we 're trying to accomplish . and my temptation for the data gathering would be to , and each person is only gonna do it once , so you don't have to worry about them being bored , so if it 's one service , one luxury item , , one big - ish place , and and so on , then my is that the data is going to be easier to handle . now you have this possible danger that somehow there 're certain constructions that people use when talking about museum that they wouldn't talk about with university and , but 'm my temptation is to go for simpler . but what other people think about this in terms of
B: so don't exactly understand like we 're trying to limit the detail of our ontology or types of places that someone could go , but who is it that has to care about this , or what component of the system ?
D: th there are two places where it comes up . one is in the th these people who are gonna take this and try to do speech with it . lots of pronunciations of th of the same thing are going to give you better data than , few pronunciations of lots more things . that 's one .
B: so we would rather just ask have bunch of people talk about the zoo , and assume that will that the constructions that they use there will give us everything we need to know about these zoo , castle , whatever type things , these bigger places .
D: thi this is question for
B: and that way you get the speech data of people saying "" zoo "" over and over again or whatever too .
D: so this is question for you , and , , if we if we do , and we probably will , actually try to build prototype , probably we could get by with the prototype only handling few of them anyway .
C: the this was these are all different activities . but got the point and like it . we can do put them in more hierarchical fashion . so , "" go to place "" and then give them choice , either they 're the symphony type or opera type or the tourist site guide type or the nightclub disco type person and they say "" this is on that "" go to big - ish place "" , this is what would do . "" and then we have the "" fix "" thing , and then maybe "" do something the other day "" thing , so . my question is to some extent , we should we just have to try it out and see if it works . it would be challenging , in sense , to try to make it so complex that they even really should schedule , or to plan it , , more complex thing in terms of they should get the feeling that there are these six things they have to do and they sh can be done maybe in two days . so they make these decisions , "" can go there tomorrow ? ""
D: it 's easy enough to set that up if that 's your expectation . so , the system could say , "" , we 'd like to set up your program for two days in heidelberg , let 's first think about all the things you might like to do . so there th in in th 'm that if that 's what you did then they would start telling you about that , and then you could get into various things about ordering , if you wanted .
C: but this is part of the instructor 's job . and that can be done , to say , "" now we 've picked these six tasks . "" "" now you have you can call the system and you have two days . ""
D: no , we have to help we have to decide . fey will carry out whatever we decide . but we have to decide , what is the appropriate scenario . that 's what we 're gonna talk about .
F: but these are two different scenarios entirely . one is planner the other , it give you instructions on the spot
C: but th the don't 'm not really interested in "" phase planning "" capabilities . but it 's more the how do people phrase these planning requests ? so are we gonna masquerade the system as this as you said simple response system , "" have one question get one response "" , or should we allow for certain level of complexity . and think the data would be nicer if we get temporal references .
D: so keith , what do you think ?
B: off the top of my head it kinda seems like you would probably just want , , richer data , more complex going on , people trying to do more complex sets of things . if our goal is to really be able to handle whole bunch of different , then throwing harder situations at people will get them to do more linguistic more interesting linguistic . but 'm not really because don't fully understand like what our choices are of ways to do this here yet .
C: we have tested this and have you heard listen to the first two or th the second person is is was faced with exactly this setup .
B: started to listen to one and it was just like , , , depressing . 'd just listen to the beginning part and the person was just reading off her script .
C: that was the first subject .
D: first one wasn't very good .
C: it is already with this it got pretty with this setup and that particular subject it got pretty complex . maybe suggest we make some fine tuning of these , get run through ten or so subjects and then take breather , and see whether we wanna make it more complex or not , depending on what results we 're getting .
B: it , , am just today , next couple days gonna start really diving into this data . 've looked at one of the files you gave me those dozens of files and looked at one of them which was about ten sentences , found fifteen , twenty different construction types that we would have to look for and so on and like , "" alright , , let 's start here . "" so haven't really gone into the , looked of the that 's going on . right , , once start doing that 'll have more to say about this thing .
D: but th but you did say something important , which is that you can probably keep yourself fairly occupied with the simple cases for quite while . although , th so that sa does suggest that now , have looked the data , and it 's pre it 's actually at least to an amateur , quite redundant . that that it was it was very stylized , and quite lot of people said more or less the same thing .
B: did scan it at first and noticed that , and then looked in detail at one of them . but , noticed that , too .
D: so , we we wanna do more than that .
C: and with this we 're getting more . do we wanna get going beyond more , which is the
D: , so let 's let 's take let 's your suggestion is good , which is we 'll do batch . fey , how long is it gonna be till you have ten subjects ? or thr week ? or don't have feel for th
E: can probably schedule ten people , , whenever .
D: it 's it 's up to you , we don't have any huge time pressure . it 's just when you have
E: how long will it be ? would say maybe two weeks .
D: so let 's do this . let 's plan next monday , , to have review of what we have so far .
C: this means audio , but
D: no , we won't have the transcriptions , but what we should be able to do and if , fey , if you will have time to do this , but it would be great if you could , , not transcribe it all , but pick out , some . we could lis just sit here and listen to it all . are you gonna have the audio on the web site ?
C: until we reach the gigabyte thing and david johnson ki kills me . and we 're gonna put it on the web site . .
D: you can buy another disk for two hundred dollars , it 's it 's not like so , we 'll take care of david johnson .
C: no , he , he has been solving all our problems or is wonderful ,
E: take care of him .
D: so we 'll buy disk . but anyway , so , , if you if you can think of way to , point us to th to interesting things , as you 're doing this make your make notes that this is , , something worth looking at . and other than that , we 'll just have to , listen although it 's only ten minutes each ,
E: 'm not how long it 's actually going to take .
C: the reading task is lot shorter . that was cut by fifty percent . and the reading , nobody 's interested in that except for the speech people .
D: no , we don't care about that .
C: it 's actually like five minutes dialogue .
D: my is it 's gonna be ten .
C: ten minutes is long .
E: it feels like long time
C: it feels like forever when you 're doing it , but then it turns out to be three minutes and forty five seconds .
D: was thinking people would , , hesitate and whatever . whatever it is we 'll we 'll deal with it .
C: and it 's fun .
D: so that 'll be on the web page . that 's great . but anyway , so it 's good idea to start with the relatively straight forward res just response system . and then if we want to get them to start doing multiple step planning with whole bunch of things and then organize them tell them which things are near each other any of that . "" which things would you like to do tuesday morning ? "" so th that seems pretty straight forward .
E: but were you saying that
C: need those back .
D: 'm , fey , what ?
E: that maybe one thing we should do is go through this list and select things that are categories and then offer only one member of that category ?
D: that 's what was suggesting for the first round , .
B: so rather than having zoo and castle .
E: and then , , they could be alternate versions of the same if you wanted data on different constructions .
D: they could , but tha they
E: like one person gets the version with the zoo as choice , and the other person gets the
D: but but in the short run ,
C: no , th the per the person don't get it . this is why we did it , because when we gave them just three tasks for part - and three tasks for part -
E: no , they could still choose . they just wouldn't be able to choose both zoo and say , touring the castle .
C: this is limiting the choices , but . but this approach will very work , but the person was able to look at it and say "" , this is what would actually do . ""
E: he was vicious .
C: we gotta we gotta disallow traveling to zoos and castles at the same time ,
E: there they are significantly different , but .
C: but no , they 're they 're this is where tour becomes tourists maybe bit different and , , these are just places where you enter , much like here .
D: if if you use the right verb for each in common , like at , "" attend theater , symphony or opera "" is group , and "" tour the university , castle or zoo "" , all of these do have this "" tour "" aspect about the way you would go to them . and , the movie theater is probably also is "" attend "" et cetera . so it may turn out to be not so many different kinds of things , and then , what one would expect is that the sentence types would their responses would tend to be grouped according to the activity , you would expect .
F: but it seem that there is difference between going to see something , and things like "" exchange money "" or "" dine out "" @ @ function , .
C: th the function is definitely different and the getting information or . but this is open . so since people gonna still pick something , we 're not gonna get any significant amount of redundancy . and for reasons , we don't want it , really , in that sense . and we would be ultimately more interested in getting all the possible ways of people asking , , for different things with or with computer . and so if you can think of any other high level tasks tourist may do just always just mail them to us and we 'll sneak them into the collection . we 're not gonna do much statistical with it .
D: we don't have enough .
C: but it seems like since we since we are getting towards subject fifty subjects and if we can keep it up to five four - ish per week rate , we may even reach the one hundred before fey takes off to chicago .
E: that means that one hundred people have to be interested .
D: , these are all people off campus from campus so far , so we we how many we can get next door at the shelter . for ten bucks , probably quite few .
B: that 's right .
D: so , alright , so let 's go let 's go back then , to the chart with all the decisions and , and see how we 're doing . do do people think that , this is gonna cover what we need , or should we be thinking about more ?
C: in terms of decision nodes ? go - there is yes or no . 'm also interested in th in this "" property "" line here , so if you look at , look at that timing was have these three . do we need final differentiation there ? now , later on the same tour , sometimes on the next tour .
B: what 's this idea of "" next tour "" ?
C: it 's next day , so you 're doing something now and you have planned to do these three four things , and you can do something immediately , you could tag it on to that tour or you can say this is something would do wanna do sometime in my life , .
B: so so this tour is just like th the idea of current round of touristness or whatever ,
D: probably between stops back at the hotel . if you if you wanted precise about it , , and that 's the way tourists do organize their lives . "" , we 'll go back to the hotel and then we 'll go off
F: so all tours tour happens only within one day ? so the next tour will be tomorrow ?
B: just to be clear .
C: my visit to prague there were some nights where never went back to the hotel , so whether that counts as two - day tour or not we 'll have to think .
B: you just spend the whole time at fleku ,
D: we will we will not ask you more .
E: that 's enough .
C: what is the the english co cognate if you want , for "" sankt nimmerlandstag "" ? "" we 'll do it on when you say on that day it means it 'll never happen . do you have an expression ?
B: not that know of actually .
C: when hell , we 'll do it when hell freezes over . so maybe that should be another property in there . the reason why do we go there in the first place ie it 's either for sightseeing , for meeting people , for running errands , or doing business . entertainment is good one in there , .
B: so , business is supposed to , be it like professional type ,
C: this this is an old johno thing . he had it in there . "" who is the tour is the person ? "" so it might be tourist , it might be business man who 's using the system , who wants to go to some
B: like my father is about to travel to prague . he 'll be there for two weeks . he is going to he 's there to teach course at the business school but he also is touring around and so he may have some mixture of these things .
F: what ab what do you have in mind in terms of socializing ?
C: just meeting people , . "" want to meet someone somewhere "" , which be puts very heavy constraint on the "" eva "" because then if you 're meeting somebody at the town hall , you 're not entering it usually , you 're just want to approach it .
B: so , does this capture , like , where do you put "" exchange money "" is an errand , so , like "" go to movie "" is now entertainment , "" dine out "" is
D: let , we 'll put it somewhere , would say that if "" dine out "" is special if you 're doing it for that purpose then it 's entertainment . and we 'll also as as you 'll further along we 'll get into business about "" , you 're this is going over meal time , do you wanna stop for meal or pick up food ? "" and that 's different . that 's that 's part of th that 's not destination reason , that 's "" en passant , "" right .
C: that goes with the "" energy depletion "" function , blech . "" endpoint "" .
B: "" tourist needs food , badly ""
C: "" endpoint "" is pretty clear . "" mode "" , have found three , "" drive there "" , "" walk there "" or "" be driven "" , which means bus , taxi , bart .
D: taxis are very different than buses , but on the other hand the system doesn't have any public transport this the planner system doesn't have any public transport in it yet .
C: so this granularity would suffice , if we say the person probably , based on the utterance we on the situation we can conclude wants to drive there , walk there , or use some other form of transportation .
B: how much of heidelberg can you get around by public transport ? in terms of the interesting bits . there 's lots of bits where you don't really 've only ev was there ten years ago , for day , so don't remember , but . like the the tourist - bits
D: you can't get to the philosophers ' way very , there are hikes that you can't get to , but other things you can , if remember right .
A: so is like "" biking there "" part of like "" driving there "" ,
C: we actually biking should be should be separate point because we have very strong bicycle planning component .
E: mmm that 's good .
D: put it in .
C: bicycles should be in there , will we have bic is this realistic ?
D: we can leave it out , .
C: we can we can , drive
B: would would lump it with "" walk "" because hills matter . things like that .
C: "" length "" is , you wanna get this over with as fast as possible , you wanna use some part of what of the time you have . but we should just make decision whether we feel that they want to use some substantial or some fraction of their time . they wanna do it so badly that they are willing to spend the necessary and plus time . and , if we feel that they wanna do nothing but that thing then , , we should point out that to the planner , that they probably want to use all the time they have . so , stretch out that visit for that .
B: it seems like this would be really hard to . on the part of the system . it seems like it you 're you 're talking about rather than having the user decide this you 're supposed we 're supposed to figure it out ?
C: th - the user can always say it , but it 's just we hand over these parameters if we make if we have feeling that they are important . and that we can actually infer them to significant de degree , or we ask .
D: and par , and part of the system design is that if it looks to be important and you can't figure it out , then you ask . but hopefully you don't ask , all these things all the time . or so , but there 's th but definitely back - off position to asking .
C: and if no part of the system ever comes up with the idea that this could be important , no planner is ever gonna ask for it . so and like the idea that , , jerry pushed this idea from the very beginning , that it 's part of the understanding business to make good question of what 's important in this general picture , what you need if you wanna simulate it , , what parameters would you need for the simulation ? and , timing , , length would definitely be part of it , "" costs "" , "" little money , some money , lots of money "" ? actually , maybe so ,
B: you could say "" some "" in there .
F: must say that thi this one looks bit strange to me . maybe it seems like appropriate if go to las vegas . but decide how much money 'm willing to lose . but as tourist , 'll just paying what 's what 's more or less is required .
D: there are there 're different things where you have ch choice , this interacts with "" do am do are you willing to take taxi ? "" or , , if you 're going to the opera are you gonna look for the best seats or the peanut gallery
F: the best seat or right .
D: so there are variety of things in which tour - tourists really do have different styles eating .
F: right , that 's true .
C: the what my sentiment is they 're once had to write charter , carter for student organization . and they had wanted me to define what the quorum is going to be . and looked at the other ones and they always said ten percent of the student body has to be present at their general meeting otherwise it 's not and wrote in there "" en - enough "" people have to be there . and it was hotly debated , but people with me that everybody probably has good feeling whether it was farce , joke , or whether there were enough people . and if you go to turkey , you will find when people go shopping , they will say "" how much cheese do you want ? "" and they say "" , enough . "" and the and the this used all over the place . because the person selling the cheese knows , , that person has two kids and , husband that dislikes cheese , so this is enough . and so the middle part is always the golden way , so you can you can be really make it as cheap as possible , or you can say "" want , er , , don't care ""
B: money is no object .
C: money is no object , or you say "" want to spend enough "" . or the sufficient , or the appropriate amount . but , then again , this may turn out to be insufficient for our purposes . but , this is my first , in much the same way as how should the route be ? should it be the easiest route , even if it 's little bit longer ? no steep inclinations ? go the normal way ? whatever that again means , er or do you does the person wanna rough it ?
B: th so there 's couple of different ways you can interpret these things "" want to go there and don't care if it 's really hard . "" or if you 're an extreme sport person , . "" wanna go there and insist on it being the hard way . "" so assume we 're going for the first interpretation , it 's different from thing to
D: no , he was going for the second one ar actually . anyway , we 'll sort th , we 'll sort that out .
C: this is all , top of my head . no no research behind that . "" object information "" , "" do do wanna know anything about that object ? "" is either true or false . and . if care about it being open , accessible or not , don't think there 's any middle ground there . either wanna know where it is or not , wanna know about it 's history or not , or , wanna know about what it 's good for or not . maybe one could put scales in there , too . so wanna know lot about it .
D: what were you gonna say ?
C: one could put scales in there . so wanna know lot about the history ,
D: so "" object "" becomes "" entity "" ,
C: that 's true .
D: but we don't have to do it now .
C: that was the wrong shortcut anyhow .
D: and we think that 's it , interestingly enough , that , , th or very close to it is going to be going to be enough . alright , so so the order of things is that , robert will clean this up little bit , although it looks pretty good .
C: this is the part that this is the part that needs the work .
D: so so , in parallel , three things are going to happen . robert and eva and bhaskara are gonna actually build belief - net that , , has cpt 's and , , tries to infer this from various kinds of information . and fey is going to start collecting data , and we 're gonna start thinking about what constructions we want to elicit . and then go it may iterate on , further data collection to elicit
B: do you mean do you mean eliciting particular constructions ? or do you mean like what kinds of things we want to get people talking about ? semantically speaking , ?
D: and though for us , constructions are primarily semantic ,
B: from my point of view 'm 'm trying to care about the syntax , so
D: but if th if we in if we , make that we get them talking about temporal order . that would be great and if th if they use prepositional phrases or subordinate clauses or whatever , whatever form they use is fine . but that probably we 're gonna try to look at it as , what semantic constructions do we do we want them to do direc , "" caused motion "" , something like that . but , - this is actually conversation you and have to have about your thesis fantasies , and how all this fits into that .
C: will tell you the german tourist data . because have not been able to dig out all the out of the ta thirty
B: is that roughly the equivalent of what 've seen in english or is it
C: no , not . wizard of oz .
B: like what what have got now ? have what 'm loo what those files that you sent me are the user side of some interaction with fey ?
C: little bit of data ,
B: is that what it is ? or ? just talking into box and not hearing anything back .
D: no , no .
C: some data collected in couple weeks for training recognizers and email way back when . nothing to write home about . see this ontology node is probably something that will try to expand . once we have the full ontology api , what can we expect to get from the ontology ? and hopefully you can also try to find out , , sooner or later in the course of the summer what we can expect to get from the discourse that might , or the not the discourse , the utterance as it were , ,
D: right , but we 're not expecting keith to actually build parser .
B: right , right .
C: no , no , no .
D: we are expecting johno to build parser ,
C: this is yes .
B: by the end of the summer , too .
D: he 's he 's hoping to do this for his masters ' thesis by year from now .
C: but it 's it 's
B: still , pretty formidable actually .
D: , the idea is , the hope is that the parser itself is , , pretty robust . but it 's not popular it 's only only
B: right , right . existence proof , . set up the infrastructure ,
D: it 's only popula
B: sometime , have to talk to some subset of the people in this group , at least about what constructions 'm looking for . like just again , looking at this one thing , , saw things from as general as argument structure constructions . , have to do verb phrase . have to do unbounded dependencies , which have variety of constructions in on the other hand have to have , , there 's particular , fixed expressions , or semi - fixed expressions like "" get "" plus path expression for , , "" how ho how do get there ? "" , "" how do get in ? "" , "" how do get away ? "" and all that . so there 's variety of different sorts of constructions and it it 's it 's like anything goes .
D: so this is we 're gonna mainly work on with george . let me th say what is so the idea is first of all misspoke when said we thought you should do the constructions . for linguist that means to do completely and perfectly . so what , , so what was "" do first cut at "" .
B: er that 's what
D: because we do wanna get them perfectly but we 're gonna have to do first cut at lot of them to see how they interact .
B: right , exactly . now it we talked about this before , and me it would be completely out of the question to really do more than , say , like , , ten , over the summer , but , but we need to get general view of what things look like ,
D: so the idea is going to be to do like nancy did in some of the er these papers where you do enough of them so you can go from top to bottom so you can do , have complete story ov of of some piece of dialogue . and that 's gonna be much more useful than having all of the clausal constructions and nothing else , or like that . so that the trick is going to be to take this and pick some lattice of constructions , so some lexical and some phrasal , and , , whatever you need in order to , be able to then , , by hand , , explain , some fraction of the utterances . and so , exactly which ones will partly depend on your research interests and bunch of other things .
B: but in terms of the th level of of analysis , these don't necessarily have to be more complex than like the "" out of "" construction in the bcp paper where it 's just like , , half page on each one .
D: half page is what we 'd like . and if there 's something that really requires lot more than that then it does and we have to do it ,
B: for the first cut , that should be fine , .
C: we could sit down and think of the ideal speaker utterances , and two or three that follow each other , so , where we can also , once we have everything up and running , show the tremendous , insane inferencing capabilities of our system . so , , as the smartkom people have . this is their standard demo dialogue , which is , , what the system survives and nothing but that . we could also sor have the analogen of our sample sentences , the ideal sentences where we have complete construction coverage and , , they match nicely . so the "" how do get to ? "" , that 's definitely gonna be , major one .
B: that 's about six times in this little one here , so , .
C: "" where is ? "" might be another one which is not too complicated . and "" tell me something about . "" and hey , that 's that 's already covering eighty percent of the system 's functionality .
D: ye - right , but it 's not covering eighty percent of the intellectual interest .
C: no , we can throw in an "" out of film "" construction if you want to ,
D: no , no . the th there 's lot that needs to be done to get this right .
C: have one bit of news . the action planner guy has wrote has written lengthy proposal on how he wants to do the action planning . and responded to him , also rather lengthy , how he should do the action planning .
D: "" action planning "" meaning "" discourse modeling "" ?
C: and tacked on little paragraph about the fact that the whole world calls that module dis disc dialogue manager , and wouldn't it make sense to do this here too ? and also rainer malaka is going to be visiting us shortly , most likely in the beginning of june .
D: 'll be gone .
C: he - he 's just in conference somewhere and he is just swinging through town . and making me incapable of going to naacl , for which had funding . but . no , no pittsburg this year . when is the santa barbara ? who is going to ? should lot of people . that 's something will would enjoy .
D: probably should go . that was that 's one you should probably go to .
B: how much does it cost ? haven't planned to go .
D: probably we can pay for it . student rate shouldn't be very high . so , if we all decide it 's good idea for you to go then you 'll we 'll pay for it .
E: then you can go .
D: don't have feeling one way or the other at the moment , but it probably is .
","The main focus of the meeting was firstly on the structure of the belief-net , its decision nodes and the parameters that influence them , and secondly , on the design of the data collection tasks.
For the latter , there are already 30 subjects lined up and more are expected to be recruited off campus.
It was agreed that making subjects select from categories of tasks , such as ""big place"" , ""service"" , etc . could provide a better range of data.
The duration of each dialogue will probably be no more than 10 minutes.
On the other hand , the organisation of the intermediate nodes of the belief-net and their properties is almost complete , although no conditional probabilities have been inserted yet.
These nodes represent decisions that will function as parameters to action calls in the system.
Their values will either be inferred from the user-system interaction , or -as a last resort- requested directly from the user.
Finally , as to the semantic and syntactic constructions , work will start with more general and brief descriptions , before moving to exhaustive analysis of at least a subset.
Similarly , the construction parser that is to be built within a year is expected to be relatively basic , yet robust.
As the data collection is ready to start , it was agreed that for the first ten subjects the interaction with the system/instructor will be along the lines of a basic response system.
Tasks will be divided in categories ( ""tour"" , ""attend"" etc ) and subjects are going to be asked to choose no more than one task out of each category .
This first run will probably take a couple of weeks , but the first results ( audio files and selected highlights ) will be discussed shortly , in order to decide whether more detail ( complex spatial relationships , temporal planning etc ) should be included in the design or particular constructions be elicited.
Regarding the completion of the belief-net , the remaining details , mainly the properties of the ontology and discourse nodes , should be added.
After building in the conditional probability tables , a working prototype of the net will be ready.
Finally , the initial work on constructions should focus on a general overview of the dialogues with brief descriptions.
Further analysis will follow from there in a top-down fashion.
Although there is an effort to include some of the key features of the belief-net in the design of the data gathering , not all of them can be built in.
The tasks that the subjects will have to carry out will be categorised in ways that will indicate EVA intentions , however , this approach may limit the variety of possible constructions used within a single category of entities.
On the other hand , generating more diverse dialogues may have an adverse effect from a speech recognition perspective.
A minor problem has arisen with the laboratory where recordings are supposed to take place , but this is currently being sorted out.
As regards the completion of the belief-net , no work has been done on the CPT's yet.
Finally , it was noted that although a general overview of the pertinent constructions is attainable , no more than ten of them can be analysed in detail with the summer months.
A detailed diagram of the EVA belief-net was presented and some of the intermediate nodes and their properties were discussed in depth.
Some of the key features and properties are: ""Go-there"" , which is binary , and defined by the user , situation , ontology and discourse models; ""timing"" ( current/next tour ); ""reason"" ( business , sight-seeing , socialising ); ""transport""; ""length of tour""; ""costs""; ""entity"" ( open , accessible ) etc.
The data collection that will provide relevant dialogues is moving along , with thirty subjects already lined up.
They will be given a reading task , which will include some german proper names , and a series of tasks from the tourist domain to choose from.
In order to get directions , they will then communicate with a computer system and a human operator , using a sketchy map as an aid.
A different set of data are already available from the SmartKom system and similar sources.
A preliminary study using this data has shown that a large number of syntactic and semantic constructions can be derived from a small sample.
"
ami_abstractive_summary,Bed005.txt,"A: got my mike on . let 's see .
B: ami , do yours then we 'll open it and it 'll be enough .
A: mmm doesn't , it should be the other way . now it 's on .
B: so , we all switched on ?
A: we are all switched on , .
B: anyway . so , , before we get started with the , , technical part , want to review what is happening with the our data collection .
F: we are all switched on .
B: so , probably after today , that shouldn't come up in this meeting . th - this is should be im it isn't there 's another thing going on of gathering data , and that 's independent of this . but , , want to make we 're all together on this . what we gonna happen is that , , in parallel starting about now we 're gonna get fey to , where you 're working with me and robert , draft note that we 're gonna send out to various cogsci and other classes saying , "" here 's an opportunity to be subject . contact fey . "" and then there 'll be certain number of , hours during the week which she will be available and we 'll bring in people . roughly how many , robert ? we do we know ?
C: fifty was our our first
B: so , we 're looking for total of fifty people , not necessarily by any means all students but we 'll we 'll start with that . in parallel with that , we 're gonna need to actually do the script . and , so , there 's plan to have meeting friday afternoon , with , jane , and maybe liz and whoever , on actually getting the script worked out . but what 'd like to do , if it 's , is to to , as say , start the recruiting in parallel and possibly start running subjects next week . the week after that 's spring break , and maybe we 'll look for them some subjects next door
C: also , fey will not be here during spring break .
B: , then we won't do it . so that 's easy . so , is is that make sense to everybody ?
C: also , , both fey and will , , do something of which may , kindly ask you to do the same thing , which is we gonna check out our social infrastructures for possible subjects . meaning , , kid children 's gymnastic classes , pre - school parents and . they also sometimes have flexible schedules . so , if you happen to be in non - student social setting , and people who may be interested in being subjects we also considered using the berkeley high school and their teachers , maybe , and get them interested in .
B: that 's good idea .
C: so that 's as far as our brainstorming was concerned .
B: . the high school 's great idea .
C: but will just make first draft of the , , note , the "" write - up "" note , send it to you and fey
B: and why don't you also copy jane on it ?
C: are we have we concurred that , , these forms are sufficient for us , and necessary ?
B: th they 're necessary . this the permission form . there has to be one , and we 're just gonna use it as it is ,
C: you happy with that ?
B: there 's one tricky part about , they have the right the last paragraph "" if you agree to participate you have the opportunity to have anything excised which you would prefer not to have included in the data set . "" now that , we had to be included for this other one which might have , , meetings , , about something . in this case , it doesn't really make sense . so what 'd like to do is also have our subjects sign waiver saying "" don't want to see the final transcript "" . and if they don't if they say "" no , 'm not willing to sign that "" , then we 'll show them the final transcript . so we might actually , jane may say that , "" , you can't do this "" , "" on the same form , we need separate form . "" but anyway . 'd 'd like to , , add an little thi thing for them to initial , saying "" nah , do don't want to see the final transcript . "" but other than that , that 's one 's been approved , this really is the same project , so we just go with it .
C: so much for the data , except that with munich everything is fine now . they 're gonna transcribe . they 're also gonna translate the , , german data from the tv and cinema for andreas . they 're they all seem to be happy now , with that . sh should we move on to the technical sides ? the good news of last week was the parser . bhaskara and started working on the parser . then bhaskara went to class and once he came back , , it was finished . it , didn't measure it , but it was about an hour and ten minutes . and , and now it 's we have complete english parser that does everything the german parser does .
D: something like that .
B: which is not lot .
D: that 's the , , point .
C: the , that 's not lot .
E: what did you end up having to do ? wha was there anything interesting about it ?
D: we 'll show you .
B: we can show us ,
E: or are we gonna see that ?
C: we the first we did is we tried to do change the "" laufen "" into "" run "" , or "" running "" , or "" runs "" . and we noticed that whatever we tried to do , it no effect . and we were puzzled . and , , the reason was that the parser completely ignores the verb . so this sentence is parses the the same output ,
E: interesting parser property .
C: even if you leave out , , all of this . so it 's feature film and tv . that 's what you need . if if you 'd add today and evening , it 'll add time or not .
E: and the and the time , right ?
C: so it it does look at that . but all the rest is simply frosting on the cake , and it 's optional for that parser .
B: so , you can sho you you are are you gonna show us the little templates ?
C: we ar we can sh er show you the templates . also have it running here ,
E: the former end ""
C: so if do this now , , you can see that it parsed the wonderful english sentence , "" which films are on the cinema today evening ? "" do don't worry about it . it could be "" this evening , which films are on the cinema "" , or "" running in the cinema , "" today evening "" , "" is anything happening in the cinema this evening ? ""
E: key words , .
C: ge - elaborate , or , more or less ,
B: actually , it 's little tricky , in that there 's some allowable german orders which aren't allowable english orders and . and it is order - based . so it doe it these these optional elements , it 's it 's actually set ,
C: we were was afraid that ,
E: so it really is key word matching , .
C: , these sentences are just silly . , these were not the ones we actually did it . what 's an idiomatic of phrasing this ? which films are showing ?
D: are pl playing at the cinema ? changed that file , actually , where it 's on my account .
E: this this evening ?
F: actually , you would say , "" which films are on tonight ? ""
D: you want to get it ? or is di was it easy to get it ?
C: have no net here . so . wonderful parse , except that we we don't have this , , time information here now , this are the reserve . anyways . so . these are the the ten different sentence types that the the parser was able to do . and it still is , now in english . you have already to make it little bit more elaborate , right ?
D: changed those sentences to make it , , more , , idiomatic . and , , you can have many variations in those sentences , they will still parse fine . so , in sense it 's pretty broad .
C: so , if you want to look at the templates , they 're conveniently located in file , "" template "" . and this is what had to do . had to change , @ @ "" spielfilm "" to "" film "" , "" film "" to "" movie "" , cinem "" kino "" to "" cinema "" to "" today "" heu "" heute "" to "" today "" , evening "" abend "" to "" evening ""
D: one thing was wondering , was , those functions there , are those things that modify the - three - ?
C: and that 's that 's the next step , but we 'll get to that in second . and so this means , , "" this "" and "" see "" are not optional . "" want like "" is all maybe in there , but may also not be in there .
B: so so , , if it says "" this "" and "" see "" , it also will work in "" see "" and "" this "" ? in the other order ? with those two key words ?
C: should we try it ?
B: "" this is the one want to see ""
C: "" action watch "" , nothing was specialfi specified . except that it has some references to audio - visual media here . where it gets that from it 's correct , but where it gets it from .
D: "" see "" .
C: "" see "" . and "" see this "" is exactly the same thing .
B: so it is set - based .
D: one thing was wondering was , those percentage signs , right ? so , , why do we even have them ? because if you didn't have them
C: 'll tell you why . because it gives you score . and the value of the score is , assume , , the more of these optional things that are actually in there , the higher the score it is .
D: so that 's the main purpose . alright .
E: it 's match .
C: so we shouldn't belittle it too much . it 's doing something , and it 's very flexible . 've just tried to
B: no , no . , flexible it is .
C: , let 's hope that the generation will not be more difficult , even though the generator is little bit more complex . that means we may need two hours and twenty minutes rather than an hour ten minutes , and the next thing would like to be able to do , and it seems like this would not be too difficult either , is to say , "" let 's now pretend we actually wanted to not only change the mapping of , , words to the - three - but we also wanted to change add new sentence type and make up some new - three - ""
B: that 'd be great . it would be good exercise to just see whether one can get that to run .
D: so , that 's
C: that 's shouldn't be too tough .
D: so where are those those functions "" action "" , "" goodbye "" , and so on , right ? are they actually , , are they going to be called ? are they present in the code for the parser ?
C: what it does , it it does something fancy . it has these style sheets and also the , , schemata . so what it probably does , is it takes the , is this where it is ? this is already the xml ? this is where it takes its own , , syntax , and converts it somehow .
D: what are you looking for ?
C: where it actually produces the xml out of the , , parsed . no , this is not it . 't find it now . you mean , where the where the act how the action "" goodbye "" maps into something
A: where are those constructors defined ?
D: no , that 's not it .
C: this is what happens . this is what you would need to change to get the , , xml changed . so when it encounts encounters "" day "" , it will , , activate those classes in the in the xml saw those actions , the "" goodbye "" somewhere .
A: grep for it ?
C: let 's do that .
D: - three - dot dtd ? that 's just specification for the xml format .
C: we 'll find that out . so whatever this does this is , , looks to me like function call , right ? so , whenever it encounters "" goodbye "" , which we can make it do in second , here
A: that function automatically generates an initialized xml structure ?
D: each of those functions act on the current xml structure , and change it in some way , , by adding field to it , .
B: they also seem to affect state , there were other actions , that seemed to step state variables somewhere , like the "" discourse status confirm "" . so that 's going to be call on the discourse and confirm that it 's
D: you mean that 's not going to actually modify the tree ,
B: that 's right .
D: but it 's going to change the event .
B: it 's actually that looks like it 's state modification .
C: there is feature called "" discourse - status "" ,
D: when there 's feature .
C: and so whenever say , "" write "" , it will it will put this in here .
B: so it always just is it so it go back , then , cuz it may be th those th things , while they look like function calls , are just way of adding exactly that to the xml . 'm not 'm not .
C: we 'll see , when we say , let 's test something , "" goodbye "" , causes it to to create an "" action goodbye - end - action "" . which is means of telling the system to shut down . now , if we know that "" write "" produces "" feature discourse - status confirm discourse - status "" . so if now say "" write , goodbye , "" it should do that . it sho it creates this , "" confirm goodbye "" .
D: but there is some function call , because how does it know to put goodbye in content , but , , confirm in features ?
C: it it that 's because
D: so , it 's not just that it 's adding that field .
B: it 's it 's the it 's under what sub - type you 're doing it .
A: it 's mystery functions .
C: sometimes it sometimes ,
D: they 're defined somewhere , presumably .
B: so that 's funny . you bury the the state in the function
A: it just automatically initializes things that are common , right ? so it 's just shorthand .
C: this is german . so , now , this , it cannot do anymore . nothing comes out of here .
A: "" not number "" is value . awesome .
C: so , it doesn't speak german anymore , but it does speak english . and there is , here , reference so , this tells us that whatever is has the id "" zero "" is referenced here by @ @ the restriction seed and this is exa "" want "" what was the sentence ?
B: "" want two seats here . ""
C: "" need two seats here . "" nuh . "" and where is it playing ? "" there should also be reference to something , maybe . our this is re here , we change and so , we here we add something to the discourse - status , that the user wants to change something that was done before and that , whatever is being changed has something to do with the cinema .
A: so then , whatever takes this - three - is what actually changes the state ,
B: no , right , the discourse maintainer , and it and it runs around looking for discourse status tags , and doing whatever it does with them . and other people ignore those tags . so , . definitely 's it 's worth the exercise of trying to actually add something that isn't there .
C: get complete understanding of the whole thing .
B: kid understanding what 's going on . then the next thing we talked about is actually , , figuring out how to add our own tags , and like that .
C: point number two . got the , , - three - for the routes today . so got some more . it 's just going up , it 's not going back down . so , this is , what got today is the new - three - for , the maps , and with some examples so , this is the xml and this is what it will look like later on , even though it you can't see it on this resolution . and this is what it is the structure of map requests , also not very interesting , and here is the more interesting for us , is the routes , and , again , as we thought it 's really simple . this is the , , , parameters . we have @ @ simple "" from objects "" and "" to objects "" and , points of interest along the way asked them whether or not we could , first of all , was little bit it seemed to me that this way of doing it is stack step backwards from the way we 've done it before . it seems to me that some notions were missing . so these are these are
B: so these are these are your friends back at eml .
C: who are doing this .
B: so this is not complicated negotiation . there 's there 's not seven committees , or anything , right ?
C: no , this is very straightforward .
B: so this is just trying to it 's design thing , not political thing . once we 've we can just agree on what oughta be done .
C: however , the , so that you understand , it is really simple . you you have route , and you cut it up in different pieces . and every element of that of that every segment we call "" route element "" . and so , from to we cut up in three different steps , and every step has "" from object "" where you start , "" to object "" where where you end , and some points of interest along the way . what was missing here , and , maybe it was just me being too stupid , is , didn't get the notion of the global goal of the whole route . really , was not straightforward visibly for me . and some other . and suggested that they should be , kind enough to do two things for us , is one , , also allocating , , some tags for our action schema enter - vista - approach , and also , , since you had suggested that , , we figure out if we ever , for demo reason , wanted to shortcut directly to the gis and the planner , of how we can do it . now , what 's the state of the art of getting to entrances , what 's the syntax for that , how get getting to vista points and calculating those on the spot . and the approach mode , anyhow , is the default . that 's all they do it these days . wherever you 'll find route planner it does nothing but get to the closest point where the street network is at minimal distance to the geometric center .
B: so , , let now , this is important . let , want again , outside of almost managerial point , you 're in the midst of this , but it seems to me it 's probably good idea to li minimize the number of , change requests we make of them . so it seemed to me , what we ought to do is get our story together . and think about it some , internally , before asking them to make changes . does this does this make sense to you guys ? it you 're you 're doing the interaction but it seemed to me that what we ought to do is come up with , something where you , and who 's mok working most closely on it . take what they have , send it to everybody saying "" this is what they have , this is what we think we should add "" , and then have an iteration within our group saying "" , "" and get our best idea of what we should add . and then go back to them . does this make sense to you ?
C: especially if we want what my feeling was we reserved something that has an label . that 's th that was my th first step . no matter how we want to call it , this is our playground . and if we get something in there that is structure elaborate and and complex enough to to maybe enable whole simulation , one of these days , that would be the perfect goal .
B: that 's right . the problem isn't the short ra range optimization . it 's the one or two year thing . what are the thl class of things we think we might try to do in year or two ? how how would we try to characterize those and what do we want to request now that 's leave enough space to do all that ? and that re that requires some thought . and so that sounds like great thing to do as the priority item as soon as we can do it . so so you guys will send to the rest of us version of , this , and the , description
A: with sugge , suggested improvements
B: so , the not everyone , reads german , so if you 'd tu , tur change the description to , , english then , with some sug suggestions about where do we go from here ? this and this , , was just the action end . at some point we 're going to have to worry about the language end . but for the moment just , for this class of things , we might want to try to encompass .
A: then the scope of this is beyond approach and vis - or vista .
B: this is this is everything that , , , we might want to do in the next couple years . we don't , that 's an issue . we what , entirely .
A: this xml here just has to do with source - path - goal type , in terms of traveling through heidelberg . or travel , specifically . so , but this is the domain greater than that ?
B: the the idea is that it 's beyond source - path - goal , but we don't need to get beyond it @ @ tourists in heidelberg . it seems to me we can get all the complexity we want in actions and in language without going outside of tourists in heidelberg . but , depending on what people are interested in , one could have , , tours , one could have , explanations of why something is , , why was this done , no there 's no end to the complexity you can build into the , what tourist in heidelberg might ask . so , at least unless somebody else wants to suggest otherwise the general domain we don't have to , broaden . that is , tourists in heidelberg . and if there 's something somebody comes up with that can't be done that way , then , . we 'll we 'll look at that , 'd be 'd be surprised at if there 's any important issue that if you want to , push us into reference problems , that would be great . so this is his specialty is reference , and , what are these things referring to ? not only anaphora , but , , more generally the , this whole issue of , , referring expressions , and , what is it that they 're actually dealing with in the world ? and , again , this is li in the databa this is also pretty formed because there is an ontology , and the database , and . so it isn't like , , , the evening star or like that . all the entities do have concrete reference . although th the to get at them from language may not be trivial . there aren't really deep mysteries about , what what things the system knows about .
F: and you have both proper names and descriptions
B: all those things .
F: and and you can ask for it .
B: you have proper names , and descriptions . and and lot and anaphora , and pronouns , and all those things .
C: now , we hav the whole unfortunately , the whole database is , , in german . we have just commissioned someone to translate some bits of it , ie the the shortest the more general descriptions of all the objects and , , persons and events . so , it 's relational database with persons , events , and , , objects . and it 's it 's quite , , there . but did there will be great because the reference problem really is not trivial , even if you have such - defined world . - he you are not , , throwing , carrying owls to athens .
A: could you give me an example of reference problem ? so make it more concrete ?
C: how do get to the powder - tower ? we think that our bit in this problem is interesting , but , just to get from powder - tower to an object id in database is also not really trivial .
F: or or if you take something even more scary , , "" how do get to the third building after the tower ? the ple - powder - tower ? "" you need some mechanism for
B: or , , the church across from city hall ,
A: or the re the restaurant where they wear lederhosen ?
B: that would be fine .
C: or tower , or this tower , or that building , or
B: or you can say "" how "" , "" how do get back ? "" and , again , it 's just question of which of these things , , people want to dive into . what , , 'm gonna try to do , and , pwww ! let 's say that by the end of spring break , 'll try to come up with some general story about , , construction grammar , and what constructions we 'd use and how all this might fit together . there 's this whole framework problem that 'm feeling really uncomfortable about . and haven't had chance to think about it . but want to want to do that early , rather than late . and you and will probably have to talk about this some .
C: that 's what strikes me , that we the de , small something , , maybe we should address one of these days , is to that most of the work people actually always do is look at some statements , and analyze those . whether it 's abstracts or newspapers and like this . but the whole is it is it really relevant that we are dealing mostly with , , questions ? and this is it seems to me that we should maybe at least spend session or brainstorm little bit about whether that this is special case in that sense . did we ever find metaphorical use in questions in that sense , really ? and how soon ,
B: , we could take all the standard metaphor examples and make question versions of them .
C: "" who got kicked out of france ? ""
B: or , . "" wh - why is he why is he pushing for promotion ? "" or , "" who 's pushing proof "" er , just pick any of them and just do the so don't don't think , , it 's difficult , to convert them to question forms that really exist and people say all the time , and we how to handle them , too . we how to handle the declarative forms , @ @ really , and , then , the interrogative forms , - . nancy , it looked like you were
E: it 's just that the goals are very different to cases so we had this problem last year when we first thought about this domain , actually , was that most of the things we talked about are our story understanding . we 're gonna have short discourse and the person talking is trying to , , give you statement and tell you something . and here , it 's th
C: help you create mental model , blah - blah .
E: yea - , so . and then here , you are , the person is getting information and they or may not be following some larger plan , , that we have to recognize or , , infer . and th the their discourse patterns probably {nonvocalsound} don't follo follow quite as many logical connec
B: right . no , that 's one of things that 's interesting , is in this over - arching story we worked it out for th as you say , this the storytelling scenario . and it 's really worth thinking through what it looks like . what is the simspec mean , et cetera .
E: right . cuz for while we were thinking , "" , how can we change the , , data to illicit tha illicit , , actions that are more like what we are used to ? "" but we would rather , , try to figure out what 's what 's ,
B: maybe that 's what we 'll do is we can do anything we want with it . once we have fulfilled these requirements , and the one for next , summer is just half done and then the other half is this , , "" generation thing "" which we sn't much different . so once that 's done , then all the rest of it is , , , , what we want to do for the research . and we can we can do all sorts of things that don't fit into their framework . th - there 's no reason why we 're we 're constrained to do that . if we can use all the , , execution engines , then we can , , really {nonvocalsound} try things that would be too much pain to do ourselves . but there 's no obligation on any of this . so , if we want to turn it into understan standing stories about heidelberg , we can do that . that would just be
C: or , , we need and if we ' take ten year perspective , we need to do that , assuming we have this , , we ta in that case we actually do have these wonderful stories , and historical anecdotes , and knights jumping out of windows , and - and tons of . so , th the database is huge , and if we want to answer question on that , we actually have to go one step before that , and understand that . in order to do sensible information extraction .
B: you might , .
C: this has been deep map research issue that was is part of the unresolved , and to - do 's , and something for the future , is how can we run our text , our content , through machine that will enable us , later , to retrieve or answer questions more sensibly ?
B: who 's going ?
F: so , so , , was just going to ask , what is the basic thing that you are , , obligated to do , , , by the summer before we can move
B: so , what happened is , there 's this , , the there 's two packages there 's , , quote parser , there 's particular piece of this big system , which , in german , , takes these sentence templates and produces xml structures . and one of our jobs was to make the english equivalent of that . that , these guys did in in day . the other thing is , at the other end , roughly at the same level , there 's something that takes , , structures , produces an output xml structure which is instructions for the generator . and then there 's language generator , and then after that synthesizer that goes from an xml structure to , , language generation , to actual specifications for synthesizer . but again , there 's one module in which there 's one piece that we have to convert to english . and that but as say , this is all along was viewed as minor thing , necessary , but not and much more interesting is the fact that , as part of doing this , we are , , inheriting this system that does all these other things .
F: that 's great !
B: not precisely what we want , and that 's that 's wh where it gets difficult . and don't pretend to understand yet what we really ought to do .
C: so , enough of that , but , , , the , johno and will take up that responsibility , and , , get first draft of that . now , we have just , two more short things . you guys started fighting , , on the bayes - net "" noisy - or "" front ?
D: should , , talk little bit about that , because that might be good , , architecture to have , in general for , , problems with , , multiple inputs to node .
B: and what 's the other one ? so that just we the agenda is ?
C: the wu paper ,
B: 've got couple new wu papers as . so 've been in contact with wu , so , probably let 's put that off till till understand better , , what he 's doing . it 's just little embarrassing all this was in his thesis and was on his thesis committee , and , so , really knew this at one time . but , it 's not only is part of what haven't figured out yet is how all this goes together . so 'll dig up some more from dekai . and so why don't we just do the ,
D: should is there white board here that use ? or shall use this ?
B: it 's probably just as easy .
A: you can put the microphone in your pocket . was envying you and your pocket don't have one .
E: it was quick one , ?
B: that 's why they invented "" pocket 's "" .
E: they have clips !
D: so , recall that , , we want to have this structure in our bayes - nets . namely , that , you have these nodes that have several bands , right ? the typical example is that , , these are all bunch of cues , and this is certain effect that we 'd like to conclude . like , let 's just look at the case when , , this is actually the final action , right ? so this is like , , , touch , - eva , right ? enter , view , approach , right ?
F: what was this ? it ehhh , ehhh .
B: wri - write it out for
D: so , this is so , , we 'd like to take all these various cues , right ?
F: like the army .
D: so this one might be , say , let me pick random one
E: haven't heard that before .
D: it could be , like this isn't the way it really is , but let me say that , suppose someone mentioned , , admission fees it takes too long . try let me just say "" landmark "" . if landmark , , then there 's another thing that says if if it 's closed or not , at the moment . alright , so you have nodes . and the , , problem that we were having was that , , given - nodes , there 's "" two to the "" given - nodes , and furthermore , the fact that there 's three things here , we need to specify "" three times "" , , "" two to the "" probabilities . that 's assuming these are all binary , which they may not be . they could be "" time of day "" , in which case we could , , say , , "" morning , afternoon , evening , night "" . so , this could be more so , it 's lot , anyway . and , that 's lot of probabilities to put here , which is pain . so noisy - ors are way to , , deal with this . where should put this ? so , the idea is that , , let 's call these , , - one , - two , - three , and - four , and , for and effect , . the idea is to have these intermediate nodes . actually , the idea , first of all , is that each of these things has quote - unquote distinguished state , which means that this is the state in which we don't really know anything about it . so , , if we don't really landmark or not , or , if that just doesn't seem relevant , then that would be th the disting - the distinguish state . it 's really , , if there is something for the person talking about the admission fee , if they didn't talk about it , that would be the distinguish state .
C: so , this is fanciful way of saying "" default "" ?
D: that 's just what they the word they used in that paper . so , the idea is that , , you have these intermediate nodes , right ? - one , - two , - three and - four ?
B: so , this is the heckerman paper you 're working with ?
D: so the idea is that , each of these ei is represents what this would be if all the other ones were in the distinguish state . right ? so , , suppose that the person , suppose the thing that they talked about is landmark . but none of the other cues really apply . then , this would be the this would just represent the probability distribution of this , assuming that this cue is turned on and the other ones just didn't apply ? so , , if it is landmark , and no none of the other things really ap applicable , then this would represent the probability distribution . so maybe in this case maybe we just maybe we decide that , if the thing 's landmark and we anything else , then we 're gonna conclude that , they want to view it with probability , , point four . they want to enter it with probability , with probability point five and they want to approach it probability point one , say so we come up with these little tables for each of those and the final thing is that , this is deterministic function of these , so we don't need to specify any probabilities . we just have to , , say what function this is , right ? so we can let this be , of - one comma - two . - three , - four . right ? and our example would be , , majority vote ?
B: , so th so the important point is not what the function is . the important point is that there is general idea of shortcutting the full cpt . th - the full conditional probability table with some function . which you choose appropriately for each case . so , depending on what your situation is , there are different functions which are most appropriate . so gave bhaskara copy of this , "" ninety - two "" paper . and you got one , robert . who else has seen it .
D: it 's heckerman and breese .
B: it 's short . it 's short . so , , yo you have you read it yet ?
D: you can , you should take look at it , .
B: so you should take look . nancy , 'm you read it at some point in life . and so , you other guys can decide how interested anyway . so the paper isn't th isn't real hard . one of the questions just come at bhaskara is , "" how much of this does javabayes support ? ""
D: it 's good question . {nonvocalsound} the so what we want , is javabayes to support deterministic , , functions . and , in sense it sup we can make it supported by , , manually , , entering , , probabilities that are one and zeros , right ?
B: right . so the little handout that the little thing that sent sent message saying , , here is way to take one thing you could do , which is in way , stupid , is take this deterministic function , and use it to build the cpt . so , if ba - javabayes won't do it for you , that you can convert all that into what the cpt would be . and , what sent out about week ago , was an idea of how to do that , for , , evidence combination . so one of one function that you could use as your "" function "" is an evidence - combining . so you just take the , if each of th if each of the ones has its own little table like that , then you could take the , , strength of each of those , times its little table , and you 'd add up the total evidence for "" "" , "" "" , and "" "" .
D: don't think you can do this , because is function from that to that . so there 's no numbers . there 's just quadruplets of , - duplets of , , vs .
B: no , no but 'm saying is there is if if you decide what 's what is appropriate , is probablistic evidence combination , you can write function that does it . it 's pui it 's actually one of the examples he 's got in there . but , anyway , skipping the question of exactly which functions now is it clear that you might like to be able to shortcut the whole conditional probability table .
C: in some it seems very plausible in some sense , where we will be likely to not be observe some of the . cuz we don't have the access to the information .
B: that 's one of the problems , is , is is , where would th where would it all come from ?
D: would not be ab able to observe
C: if it 's discar discourse initial phrase , we will have nothing in the discourse history . so , if we ever want to wonder what was mention
D: are you saying that we 'll not be able to observe certain nodes ? that 's fine . that is orthogonal thing .
B: so there 's there 's two separate things , robert . the the the bayes - nets in general are quite good at saying , "" if you have no current information about this variable just take the prior for that . "" ? th - that 's what they 're real good at . so , if you don't have any information about the discourse , you just use your priors of whatever the discourse whatever it 's probabilistically , whatever it would be . and it 's it 's not great estimate , but it 's the best one you have , so that , they 're good at . but the other problem is , how do you fill in all these numbers ? and that 's the one he was getting at .
D: so , specifically in this case you have to have this many numbers , whereas in this case you just have to have three for this , three for this . right ? so you have to have just three ? so , this is much smaller than that .
E: so , you don't need da data enough to cover , nearly as much .
A: so , really , what noisy - or seems to "" neural - net - acize "" these bayes - nets ?
B: no , no . so , "" noisy - or "" is funny way of referring to this , because the noisy - or is only one instance .
D: this isn't noisy - or anymore .
B: that one actually isn't noisy - or . so we 'll have to think of way
D: it 's noisy - arg - max or noisy - whatever .
A: my point was more that we just with the neural net , right , , things come in , you have function that combines them
B: it tha - that 's true . it is is also more neural - net - like , although , it isn't necessarily sum , , sum of weights or anything like that . you could have , like the noisy - or function , really is one that 's essentially says , , take the max .
D: the "" or "" . right . you 're right .
B: and , thi that 's the standard way people get around the there are couple other ones . there are ways of breaking this up into to subnets and like that . we definitely it 's great idea tha to pursue that .
C: wha - still leaves one question . it you can always see easily that 'm not grasping everything correctly , but what seemed attractive to me in im in the last discussion we had , was that we find out means of getting these point four , point five , point one , of - four , not because , , is landmark or not , but we we label this whatever object type , and if it 's garden , it 's point three , point four , point two . if it 's castle , it 's point eight , point one . if it 's , , town hall , it 's point two , point three , point five . and we don't want to write this down necessarily every time let 's see .
D: it 'll be students where else would it be stored ? that 's the question .
C: in the beginning , we 'll write up flat file . we know we have twenty object types and we 'll write it down in flat file .
B: let me say something , guys , cuz there 's not there 's pretty point about this we might as get in right now . which is the hierarchy that comes with the ontology is just what you want for this . so that , if about it let 's say , particular town hall that , it 's one that is monument , then , that would be stored there . if you don't , you look up the hierarchy , so , you you may or so , then you 'd have this little vector of , , , approach mode or eva mode . let 's , so we have the eva vector for various kinds of landmarks . if it for specific landmark you put it there . if you don't , you just go up the hierarchy to the first place you find one .
D: so , is the idea to put it in the ontology ?
B: or , link to but in any case view it logically as being in the ontology . it 's part of what about an object , is its eva vector . and , if yo as say , if about specific object , you put it there . this is part of what dekai was doing . so , when we get to wu , the - we 'll see what he says about that . and , then if you if it isn't there , it 's higher , and if you anything except that it 's it 's it 's building , then up at the highest thing , you have the pr what amounts to prior . if you anything else about building , , you just take whatever your crude approximation is up at that level , which might be equal , or whatever it is . so , that 's very pretty relationship between these local vectors and the ontology . and it seems to me the obvious thing to do , unless we find reason to do something different . does this make sense to you ?
D: so , we are but we 're not doing the ontology , so we have to get to whoever is doing the ultimately ,
B: so , that 's another thing we 're gonna need to do , is , to , either
D: we have to get them to
B: we 're gonna need some way to either get tag in the ontology , or add fields , or some way to associate or , it may be th we can do is , , some of our own hash tables that it th - the th , there 's always way to do that . it 's just question of
A: hash on object name to , , , the probabilities or whatever .
B: and , so ,
C: but it 's , , it strikes me as what for if we get the mechanism , that will be the wonderful part . and then , how to make it work is the second part , in the sense that , the guy who was doing the ontology , ap apologized that it will take him another through two to three days because they 're having really trouble getting the upper level straight , the reason is , given the craw bet , the the projects th carry their own taxonomy and , on all history , they 're really trying to build one top level ontology ft that covers all the eml projects , and that 's , , tough cookie , little bit tougher than they figured . could have told them so . but , nevertheless , it 's going to be there by by , , next monday and will show you what 's what some examples from that for towers , and . what don't ever going to be in the ontology , is , , the likelihood of , , people entering town halls , and looking at town halls , and approaching town halls , especially since we are dealing with case - based , not an instance - based ontology . so , there will be nothing on that town hall , or on the berkeley town hall , or on the heidelberg town hall , it 'll just be information on town halls .
B: they how ar what are they gonna do with instances ?
C: that 's that 's al different question . th the first , they had to make design question , "" do we take ontologies that have instances ? or just one that does not , that just has the types ? "" and , so , since the decision was on types , on simply type - based , we now have to hook it up to instances .
B: but what what is smartkom gonna do about that ? cuz , they have instances all the time .
C: but the ontology is really not smartkom thing , in and of itself . that 's more something that kicked loose in eml . so it 's completely eml thing .
B: but smartkom 's gonna need an ontology .
C: yes , lot of people are aware of that .
B: understand , but is anybody doing anything about it ? it 's political problem . we won't worry about it .
C: no , but th the th still think that there is enough information in there . so , th it will know about the twenty object types there are in the world . let 's assume there are only twenty object types in this world . and it will any of those have institutional meanings . so , in sense , "" "" used as institutions for some in some sense or the other . which makes them enterable . right ?
B: anyway . so we may have to this is with the whole thing , we may have to build another data stru conceptually , we should be done . when we see what people have done , it may turn out that the easiest thing to do is to build separate thing that just pools like , it may be , that , the instance that we have to build our own instance , , things , that , with their types ,
D: right , we can just assume
B: and then it goes off to the ontology once you have its type . so we build little data structure and so what we would do in that case , is , in our instance gadget have our and if we there isn't one we 'd get the type and then have the as for the type . so we 'd have our own little , , eva tree . and then , for other , , vectors that we need . so , we 'd have our own little things so that whenever we needed one , we 'd just use the ontology to get the type , and then would hash or whatever we do to say , "" ! if it 's that type of thing , and we want its eva vector , pppt - pppt ! it 's that . "" so , we can handle that . and then but , the combination functions , and whether we can put those in java bayes , and all that , is , is the bigger deal . that 's where we have to get technically clever .
A: we could just steal the classes in javabayes and then interface to them with our own code .
B: me ye {nonvocalsound} , , the
D: that requires understanding the classes in javabayes , . @ @ .
B: , it 's , , cute . you 've been around enough to there 's this huge package which may or may not be consistent but , , we could look at it . it 's an inter it it 's an interpreter and it expects its data structures to be in given form , and if you say , "" hey , we 're gonna make different data structure to stick in there ""
A: no , but that just means there 's protocol ,
B: it may or may not . that 's the question is "" to what extent does it allow us to put in these functions ? ""
A: no , but what the so you could have four different bayes - nets that you 're running , and then run your own write your own function that would take the output of those four , and make your own "" function "" , is what was saying .
B: if it 's if it comes only at the end . but suppose you want it embedded ?
A: then you 'd have to break all of your bayes - nets into smaller bayes - nets ,
B: that 's truly horrible way to do it . , , you bet . but , at that point you may say , "" hey , java bayes isn't the only package in town . let 's see if there 's another package that 's , , more civilized about this . "" now , srini is worth talking to on this , cuz he said that he actually did hack some combining functions into but he doesn't remember at least when talked to him , he didn't remember whether it was an an easy thing , natural thing , or whether he had to do some violence to it to make it work . but he did do it .
D: don't see why the , , combining functions have to be directly hacked into they 're used to create tables so we can just make our own little functions that create tables in xml .
B: say that 's one way to do it , is to just convert it int into into that you zip it 's blown up , and is it 's , it 's huge , but it doesn't require any data fitting or complication .
D: don't think , the fact that it blown blows up is huge issue in the sense that so say it blows up , right ? so there 's , like , the , ten , ten , fifteen , , things . it 's gonna be like , two to the that , which isn't so bad .
B: 'm just saying tha that that was wi that was my note . the little note sent said that . it said , "" here 's the way you 'd take the logical function and turn it into cpt . "" that the max - the evidence - combining function . so we could do that . and maybe that 's what we 'll do . so , will , before next week , , @ @ push some more on this that dekai wu did , and try to understand it . you 'll make couple of more copies of the heckerman paper to give to people ?
F: would like copy ,
C: and 'll 'll think through this , , getting eva vectors dynamically out of ontologies one more time because 'm not quite whether we all think of the same thing or not , here .
B: you and should talk about it . alright , great ! and , robert , for coming in under he he 's been sick ,
A: was thinking maybe we should just cough into the microphone and see if they can't th see if they can handle it .
","The data collection running in parallel with the project can start shortly with recruiting subjects.
Meanwhile , the german parser now works with english sentences.
The parser's output modifies the XML used by the system to initiate actions and generate responses.
The XML for Map requests also comprise a route , route elements and points of interest along the way.
It is at this level that Enter/Vista/Approach tags will be added as action modes.
As the project evolves , further enrichment of the ontology ( actions , linguistic features ) will be necessary.
Similarly , object representations will include an EVA vector.
This can be incorporated in the database entry for a particular building or inherited from the ontology of the building type.
These elements will constitute only a small part of the inputs of the Bayes-net that determines the action mode.
The actual number of the inputs can create a combinatorial explosion when setting the probabilities.
Noisy-OR's can help avoid this by simplifying the probability tables and applying a deterministic function to produce their complete version.
In any case , further to fulfilling the basic requirements ( translating the parser and the generator into english ) , the project is entirely open-ended in terms of focus of research.
As the data collection is about to begin , there are some minor changes to be done in the design of the experiment , the script and the permission forms.
Subjects can be recruited either from within the university or through other social circles.
As to the system design , the next step is the translation of the generator into english.
Moreover , it is important to test the system and its internal workings by adding new sentence types and modifying the parser.
All further research will use the existing domain ( ""tourists in Heidelberg"" ) , as this provides enough diversity for the purposes of the project.
The german partners for the project will realise all the necessary changes in the ontology.
It is therefore preferable for the group to exercise foresight and agree on the set of new tags they will need in the long run , so that they limit the number of change requests.
Finally , on a more technical note , Noisy-OR's were discussed and considered a sensible approach to deal with the potential problems with the setting the conditional probabilities of the Bayes-nets.
Although the parser has been modified to work with english , the details of its internal workings ( calling functions , setting discourse variables , generating actions ) are not yet clear.
Understanding the parsed data is helped by the database of objects , people and events accompanying the system , but the mapping of referring expressions to database objects can still be a hurdle.
On a different level , the Bayes-net used to generate the different action modes can easily become unmanageable as the number of features to be taken into account increases.
This can be tackled with the use of the Noisy-OR technique.
The deterministic functions this requires cannot be introduced directly into JavaBayes , although some runaround ways can be implemented.
A final , high-level issue , that has not been dealt with yet , is the definition of the constructions and the construction grammar framework analysis behind the whole enterprise.
The preparation for the data collection is almost finished and expected to start experiments within a couple of weeks.
There is some additional TV and cinema data currently being translated from german.
The german parser has been translated and it can now be used for a range of sentence types in english.
On the other hand , the translation of some parts of the relational database accompanying the system has also been commissioned.
EML have provided the structure for Map requests , the basic representation of the navigational goals upon which further action modes are going to be built.
The same people are also creating a general , top-level XML object ontology that will include all types of buildings.
"
ami_abstractive_summary,Bro027.txt,"A: we 're going .
C: eight , eight ?
D: this is three .
B: let 's see . move it bit . it 's alright . let 's see . barry 's not here and dave 's not here . say about just just quickly to get through it , that dave and submitted this asru . it 's it 's interesting . we 're dealing with rever reverberation , and , , when we deal with pure reverberation , the technique he 's using works really , really . and when they had the reverberation here , , we 'll measure the signal - to - noise ratio and it 's , , about nine db .
A: you mean , from the actual , , recordings ? it 's nine db ?
B: and actually it brought up question which may be relevant to the aurora too . know that when you figured out the filters that we 're using for the mel scale , there was some experimentation that went on at , at ogi . but one of the differences that we found between the two systems that we were using , the aurora htk system baseline system and the system that we were the , other system we were using , the , the sri system , was that the sri system had maybe , , hundred hertz high - pass . and the , , aurora htk , it was like twenty .
D: sixty - four . sixty - four .
B: sixty - four ?
D: if you 're using the baseline .
B: is that the ba band center ? the edge is really , , sixty - four ? for some reason , , dave thought it was twenty ,
D: so the , , center would be somewhere around like hundred and hundred and maybe it 's like fi hundred hertz .
B: but do , , how far down it would be at twenty hertz ? what the how much rejection would there be at twenty hertz , let 's say ?
D: at twenty hertz .
B: any idea what the curve looks like ?
D: it 's it 's zero at twenty hertz , right ?
C: yea - actually , the left edge of the first filter is at sixty - four .
D: sixt - sixty - four . so anything less than sixty - four is zero .
B: it 's actually set to zero ? what filter is that ? is this , from the from
C: this is the filter bank in the frequency domain that starts at sixty - four .
B: so you , so you really set it to zero , the fft ?
D: so it 's it 's weight on the ball spectrum .
B: so that 's that 's little different than dave thought , . still , it 's possible that we 're getting in some more noise . so wonder , is it @ @ was there their experimentation with , , say , throwing away that filter ?
D: throwing away the first ? we 've tried including the full bank . from zero to four . and that 's always worse than using sixty - four hertz .
B: but the question is , whether sixty - four hertz is , , too , , low .
D: make it hundred or so ? 've tried hundred and it was more or less the same , or slightly worse .
B: on what test set ?
D: on the same , , speechdat - car ,
B: it was on the speechdat - car .
D: so tried hundred to four .
B: and on and on the , , ti - digits also ?
D: no , no . tried it on speechdat - car .
B: that 'd be something to look at sometime because what , , , he was looking at was performance in this room . would that be more like you 'd think that 'd be more like speechdat - car , in terms of the noise . the speechdat - car is more , , roughly stationary , lot of it . and and ti - digits maybe is not so much as maybe it 's not big deal . anyway , that was just something we wondered about . certainly lot of the noise , , is , , below hundred hertz . the signal - to - noise ratio , , looks fair amount better if you if you high - pass filter it from this room . but it 's still pretty noisy . even even for hundred hertz up , it 's it 's still fairly noisy . the signal - to - noise ratio is is actually still pretty bad .
A: so that 's on th that 's on the the far field ones though , right ?
B: that 's on the far field . the near field 's pretty good .
A: so wha what is , what 's causing that ?
B: we got video projector in here , and , which we keep on during every session we record , which , , we were aware of but we thought it wasn't bad thing . that 's noise source . and there 's also the , , air conditioning . which , , , is pretty low frequency thing . so , those are those are major components , , for the stationary . maybe said this last week too but it it really became apparent to us that we need to take account of noise . so when he gets done with his prelim study one of the next things we 'd want to do is to take this , , noise , , processing and , , synthesize some speech from it .
A: when are his prelims ?
B: in about , , little less than two weeks . it might even be sooner . let 's see , this is the sixteenth , if he 's before it might even be in week .
A: ed that they were gonna do it some time during the semester
B: week and half .
A: but they 'll do it any time , ?
B: they seem to be the semester actually is starting up .
A: is it already ?
B: the semester 's late august they start here . so they do it right at the beginning of the semester . the overall results seemed to be first place in in the case of either , , artificial reverberation or modest sized training set . either way , , , it helped lot . and but if you had really big training set , recognizer , , system that was capable of taking advantage of really large training set that one thing with the htk is that is has the as we 're using the configuration we 're using is is being bound by the terms of aurora , we have all those parameters just set as they are . so even if we had hundred times as much data , we wouldn't go out to , , ten or or hundred times as many gaussians or anything . it 's hard to take advantage of of big chunks of data . whereas the other one does expand as you have more training data . it does it automatically , actually . that one really benefited from the larger set . and it was also diverse set with different noises and . that , that seemed to be so , if you have that better recognizer that can that can build up more parameters , and if you , , have the natural room , which in this case has pretty bad signal - to - noise ratio , then in that case , , the right thing to do is just do use speaker adaptation . and and not bother with this acoustic , , processing . but that would not be true if we did some explicit noise - processing as as , , the convolutional things we were doing . that 's what we found .
A: , started working on the mississippi state recognizer . so , got in touch with joe and , , from your email and things like that . and , , they added me to the list the mailing list . and he gave me all of the pointers and everything that needed . and so downloaded the , there were two things , , that they had to download . one was the , , the software . and another wad was , , like sample sample run . so downloaded the software and compiled all of that . and it compiled fine . and , , grabbed the sample but haven't , , compiled it .
D: that sample was released only yesterday or the day before , right ?
A: haven't grabbed that one yet . so there 's two .
D: there is another short sample set
A: there was another short one , and so haven't grabbed the latest one that he just , , put out yet . but , the software seemed to compile fine and everything ,
B: is there any word yet about the issues about , , adjustments for different feature sets or anything ?
A: you asked me to write to him and forgot to ask him about that . or if did ask him , he didn't reply . don't remember yet . 'll 'll 'll double check that and ask him again .
B: it 's like that could turn out to be an important issue for us .
D: cuz they have it
A: maybe 'll send it to the list .
D: cuz they have , , already frozen those in insertion penalties and all those is what feel . because they have this document explaining the recognizer . and they have these tables with , , various language model weights , insertion penalties .
A: haven't seen that one yet .
D: it 's th it 's there on that web . and , , on that , , they have run some experiments using various insertion penalties and all those
A: and so they 've picked the values .
D: they picked the values from
B: for what test set ?
D: the one that they have reported is nist evaluation , wall street journal .
B: but that has nothing to do with what we 're testing on , right ?
D: so they 're , like so they are actually trying to , , fix that those values using the clean , , training part of the wall street journal . aurora has clean subset . they want to train it and then this they 're going to run some evaluations .
B: so they 're set they 're setting it based on that ? so now , we may come back to the situation where we may be looking for modification of the features to account for the fact that we can't modify these parameters . but it 's still worth , , just since , just chatting with joe about the issue .
A: do you think that 's something should just send to him or do you should send it to this there 's an mailing list .
B: it 's not secret . we 're , , certainly willing to talk about it with everybody , but that , , it 's probably best to start talking with him just to @ @ , it 's dialogue between two of you about what , what does he think about this and what what could be done about it . if you get ten people in involved in it there 'll be lot of perspectives based on , , how but , , it all should come up eventually , but if if there is any , , way to move in way that would that would , , be more open to different kinds of features . but if , if there isn't , and it 's just shut down and then also there 's probably not worthwhile bringing it into larger forum where political issues will come in .
D: so this is now it 's compiled under solaris ? because he there was some mail saying that it 's may not be stable for linux and all those .
A: that was particular version . susi or whatever it was but we don't have that .
D: that 's fine .
A: it compiled fine actually . no no errors .
B: this is slightly off topic
D: that 's good .
B: noticed , just glancing at the , , hopkins workshop , , web site that , , one of the thing , we 'll see how much they accomplish , but one of the things that they were trying to do in the graphical models thing was to put together , , tool kit for doing , , arbitrary graphical models for , , speech recognition . so and jeff , the two jeffs were
A: who 's the second jeff ?
B: , do geoff zweig ? he , he was here for couple years and he , got his phd . and he 's , , been at ibm for the last couple years .
A: that would be neat .
B: so he did he did his phd on dynamic bayes - nets , for speech recognition . he had some continuity built into the model , presumably to handle some , , inertia in the in the production system ,
C: 've been playing with , first , the , , vad . so it 's exactly the same approach , but the features that the vad neural network use are , , mfcc after noise compensation . have the results .
B: what was it using before ?
C: before it was just
D: it was just the noisy features .
C: this is what we get after this so , actually , we , , here the features are noise compensated and there is also the lda filter . and then it 's pretty small neural network which use , , nine frames of six features from - zero to - fives , plus the first derivatives . and it has one hundred hidden units .
A: is that nine frames , centered around the current frame ? or
B: so , 'm 'm , there 's there 's how many how many inputs ?
C: so it 's twelve times nine .
B: twelve times nine inputs , and hundred , , hidden . so about eleven thousand parameters , which actually shouldn't be problem , even in small phones . .
A: so what is different between this and what you
C: it should be . so the previous syst it 's based on the system that has fifty - three point sixty - six percent improvement . it 's the same system . the only thing that changed is the es the estimation of the silence probabilities . which now is based on , , cleaned features .
B: and , it 's it 's lot better . that 's great .
C: so it 's it 's not bad , but the problem is still that the latency is too large .
B: what 's the latency ?
C: the latency of the vad is two hundred and twenty milliseconds . and , , the vad is used , for on - line normalization , and it 's used before the delta computation . so if you add these components it goes to hundred and seventy ,
B: you started off with two - twenty and you ended up with one - seventy ?
C: with two an two hundred and seventy .
B: two - seventy .
C: if you add the delta comp delta computation which is done afterwards .
B: so it 's two - twenty . the is this are these twenty - millisecond frames ? is that why ? is it after downsampling ?
C: the two - twenty is one hundred milliseconds for the no , it 's forty milliseconds for for the , , cleaning of the speech . then there is , , the neural network which use nine frames . so it adds forty milliseconds . after that , , you have the , filtering of the silence probabilities . which is million filter and it creates one hundred milliseconds delay .
D: plus there is delta at the input .
C: and there is the delta at the input
B: one hundred milliseconds for smoothing .
C: so it 's @ @
D: it 's like forty plus forty plus
C: this forty plus twenty , plus one hundred .
D: so it 's two hundred actually .
C: there are twenty that comes from there is ten that comes from the lda filters also . so it 's two hundred and ten ,
D: if you are using
C: plus the frame ,
D: if you are using three frames
C: so it 's two - twenty .
D: if you are phrasing using three frames , it is thirty here for delta .
C: it 's it 's five frames ,
D: so five frames , that 's twenty . so it 's who un two hundred and ten .
B: it 's forty for the for the cleaning of the speech , forty for the ann , hundred for the smoothing . but at ten ,
C: twenty for the delta .
B: twenty for delta .
D: at th {nonvocalsound} at the input . that 's at the input to the net .
B: delta at input to net ?
D: so it 's like five , six cepstrum plus delta at nine frames of
B: and then ten milliseconds for
D: fi - there 's an lda filter .
B: ten milliseconds for lda filter , and and ten another ten milliseconds you said for the frame ?
C: for the frame . computed two - twenty it 's for the fr the
B: and then there 's delta besides that ?
C: so this is the features that are used by our network and then afterwards , you have to compute the delta on the , , main feature stream , which is , delta and double - deltas , which is fifty milliseconds .
B: no , , the after the noise part , the forty the other hundred and eighty some of this is , is in parallel , isn't it ? you have the lda as part of the - , vad ?
C: the vad use , , lda filtered features also .
B: so in that case there isn't too much in parallel .
C: there is , , just downsampling , upsampling , and the lda .
B: so the delta at the end is how much ?
C: it 's fifty . but , we could probably put the delta , , before on - line normalization . it should not that make big difference ,
A: what if you used smaller window for the delta ? could that help little bit ? there 's lot of things you could do to
B: so if you if you put the delta before the , , ana on - line if then it could go in parallel . and then then you don't have that additive
C: cuz the time constant of the on - line normalization is pretty long compared to the delta window , it should not make
B: and you ought to be able to shove tw , sh pull off twenty milliseconds from somewhere else to get it under two hundred ,
A: is two hundred the
B: mill hundred milliseconds for smoothing is an arbitrary amount . it could be eighty and probably do @ @
A: wh - what 's the baseline you need to be under ?
B: they 're still arguing about it . if it 's two if it 's , if it 's two - fifty , then we could keep the delta where it is if we shaved off twenty . if it 's two hundred , if we shaved off twenty , we could we could , , meet it by moving the delta back .
A: so , how do that what you have is too much if they 're still deciding ?
B: but it 's just the main thing is that since that we got burned last time , and , by not worrying about it very much , we 're just staying conscious of it . and so , th if if week before we have to be done someone says , "" , you have to have fifty milliseconds less than you have now "" , it would be pretty frantic around here .
A: but still , that 's that 's pretty big , , win . and it doesn't seem like you 're in terms of your delay , you 're , , that
B: he added bit on , because before we were had were able to have the noise , , , , and the lva be in parallel . and now he 's he 's requiring it to be done first .
C: but the main thing , maybe , is the cleaning of the speech , which takes forty milliseconds or so .
B: let 's say ten milliseconds seconds for the lda .
C: and but the lda is , , pretty short right now .
B: and then forty for the other .
D: the lda we , is , like is it very crucial for the features , right ?
C: this is the first try . maybe the lda 's not very useful then .
B: so you could start pulling back , you have twenty for delta computation which now you 're doing twice , but yo were you doing that before ?
C: in the proposal , , the input of the vad network were just three frames , .
D: on the in the just the static , no delta .
B: so , what you have now is fort , forty for the noise , twenty for the delta , and ten for the lda . that 's seventy milliseconds of which was formerly in parallel , that 's that 's the difference as far as the timing , and you could experiment with cutting various pieces of these back bit , we 're we 're not we 're not in terrible shape .
A: that 's what it seems like to me . it 's pretty good .
B: it 's it 's not like it 's adding up to four hundred milliseconds .
A: where where is this fifty - seven point two in comparison to the last evaluation ?
B: it 's it 's better than anything , , anybody got .
A: is that right ?
C: the best was fifty - four point five . and our system was forty - nine , but with the neural network .
A: so this is almost ten percent .
B: with the with the neural net .
D: so this is this is like the first proposal . the proposal - one . it was forty - four , actually .
B: and we still don't have the neural net in . so so it 's we 're we 're doing better .
A: this is this is really good .
B: we 're getting better recognition . 'm other people working on this are not sitting still either , the important thing is that we learn how to do this better , so , our , you can see the numbers that we 're having , say , on speechdat - car which is hard task , cuz it 's really , it 's just reasonable numbers , starting to be . it 's still terri
C: even for - matched case it 's sixty percent error rate reduction , so actually , this is in between what we had with the previous vad and what sunil did with an idl vad . which gave sixty - two percent improvement , right ?
D: it 's almost that . it 's almost an average
A: what was that ? say that last part again ?
C: so , if you use , like , an idl vad , , for dropping the frames ,
D: or the best we can get .
C: the best that we can get that means that we estimate the silence probability on the clean version of the utterances . then you can go up to sixty - two percent error rate reduction , globally .
A: so that would be even that wouldn't change this number down here to sixty - two ?
B: so you were get
C: if you add good very good vad , that works as as vad working on clean speech , then you wou you would go
A: so that 's the best you could hope for .
B: so fi si fifty - three is what you were getting with the old vad . and sixty - two with the , , quote , unquote , cheating vad . and fifty - seven is what you got with the real vad . that 's great .
C: , the next thing is , started to play don't want to worry too much about the delay , maybe it 's better to from the committee . but started to play with the , , , tandem neural network . did the configuration that 's very similar to what we did for the february proposal . so . there is first feature stream that use straight mfcc features . these features actually . and the other stream is the output of neural network , using as input , also , these , , cleaned mfcc .
A: those are th those are th what is going into the tandem net ?
C: don't have the comp so there is just this feature stream , the fifteen mfcc plus delta and double - delta . so it 's makes forty - five features that are used as input to the htk . and then , there is there are more inputs that comes from the tandem mlp .
B: he likes to use them both , cuz then it has one part that 's discriminative , one part that 's not .
C: right now it seems that tested on speechdat - car while the experiment are running on your on ti - digits . it improves on the - matched and the mismatched conditions , but it get worse on the highly mismatched .
A: compared to these numbers ?
C: compared to these numbers , . like , on the - match and medium mismatch , the gain is around five percent relative , but it goes down lot more , like fifteen percent on the hm case .
B: you 're just using the full ninety features ? you have ninety features ?
C: from the networks , it 's twenty - eight .
B: and from the other side it 's forty - five .
C: so , it 's forty - five .
B: so it 's you have seventy - three features , and you 're just feeding them like that . there isn't any klt or anything ?
C: there 's klt after the neural network , as before .
A: that 's how you get down to twenty - eight ? why twenty - eight ?
C: it 's it 's because it 's what we did for the first proposal . we tested , , trying to go down
B: it 's multiple of seven .
C: wanted to do something very similar to the proposal as first try .
A: that makes sense .
C: but we have to for , we have to go down , because the limit is now sixty features . we have to find way to decrease the number of features .
A: so , it seems funny that , maybe don't quite understand everything , but that adding features if you 're keeping the back - end fixed . maybe that 's it . because it seems like just adding information shouldn't give worse results . but if you 're keeping the number of gaussians fixed in the recognizer , then
B: but , , just in general , adding information suppose the information you added , , was really terrible feature and all it brought in was noise . or or suppose it wasn't completely terrible , but it was completely equivalent to another one feature that you had , except it was noisier . in that case you wouldn't necessarily expect it to be better .
A: , wasn't necessarily saying it should be better . 'm just surprised that you 're getting fifteen percent relative worse on the wel
C: but it 's worse .
B: on the highly mismatched condition .
A: on the highly mismatch .
B: so , "" highly mismatched condition "" means that your training is bad estimate of your test . so having , , greater number of features , if they aren't maybe the right features that you use , certainly can can easily , , make things worse . you 're right . if you have if you have , , lots and lots of data , and you have and your your training is representative of your test , then getting more sources of information should just help . but but it 's it doesn't necessarily work that way . what 's your what 's your thought about what to do next with it ?
C: because expected the neural net to help more when there is more mismatch , as it was the case for the
D: so , was the training set same as the the february proposal ?
C: it 's the same training set , so it 's timit with the ti - digits ' , , noises , , added .
B: we might , we might have to experiment with , better training sets . the other thing is , , before you found that was the best configuration , but you might have to retest those things now that we have different the rest of it is different , what 's the effect of just putting the neural net on without the other path ? what the straight features do . that gives you this . what it does in combination .
A: what if you did the would it make sense to do the klt on the full set of combined features ? instead of just on the
C: the reason did it this ways is that in february , it we tested different things like that , so , having two klt , having just klt for network , or having global klt .
A: so you tried the global klt before and it didn't really
C: and , , th the differences between these configurations were not huge , but it was marginally better with this configuration .
B: but , , that 's another thing to try , since things are things are different . so all of these seventy - three features are going into , , the , the . and is are are any deltas being computed of tha of them ?
C: of the straight features , . but th the , , tandem features are used as they are . maybe we can add some context from these features also as dan did in his last work .
B: but the other thing was thinking was , now lost track of what was thinking .
A: you said there was limit of sixty features ? what 's the relation between that limit and the , , forty - eight , forty eight hundred bits per second ?
B: was gonna say .
C: not no relation .
A: so don't understand ,
C: the the forty - eight hundred bits is for transmission of some features .
A: if you 're only using
C: and generally , it allows you to transmit like , fifteen , , cepstrum .
B: the issue was that , , this is supposed to be standard that 's then gonna be fed to somebody 's recognizer somewhere which might be , , it might be concern how many parameters are use used and . they felt they wanted to set limit . so they chose sixty . some people wanted to use hundreds of parameters and that bothered some other people . they just chose that . it 's arbitrary too . but but that 's that 's what was chosen . remembered what was going to say . what was going to say is that , , maybe with the noise removal , , these things are now more correlated . so you have two sets of things that are uncorrelated , , within themselves , but they 're pretty correlated with one another . they 're being fed into these , , variants , only gaussians and , so maybe it would be better idea now than it was before to , , have , , one klt over everything , to de - correlate it .
D: what are the rs in the training set , timit ?
C: it 's , , ranging from zero to clean ? from zero to clean .
B: so we found this , this macrophone data , and , that we were using for these other experiments , to be pretty good . so that 's after you explore these other alternatives , that might be another way to start looking , is just improving the training set . we were getting , , lots better recognition using that , than you do have the problem that , , we are not able to increase the number of gaussians , , or anything to , , to match anything . so we 're only improving the training of our feature set , but that 's still probably something .
A: so you 're saying , add the macrophone data to the training of the neural net ? the tandem net ?
B: that 's the only place that we can train . we can't train the other with anything other than the standard amount ,
A: what what was it trained on again ? the one that you used ?
C: it 's timit with noise . so , , it 's rather small
B: how big is the net , ?
C: it 's , , five hundred hidden units .
B: you did experiments back then where you made it bigger and it and that was that was the threshold point . much less than that , it was worse , much more than that , it wasn't much better .
D: so is it is it though the performance , big relation in the high ma high mismatch has something to do with the , , cleaning up that you that is done on the timit after adding noise ? it 's all the noises are from the ti - digits , it 's like the high mismatch of the speechdat - car after cleaning up , maybe having more noise than the training set of timit after clean after you do the noise clean - up . earlier you never had any compensation , you just trained it straight away . so it had like all these different conditions of rs , actually in their training set of neural net . but after cleaning up you have now different set of rs , right ? for the training of the neural net . is it something to do with the mismatch that 's created after the cleaning up , like the high mismatch
C: you mean the most noisy occurrences on speechdat - car might be lot more noisy than
D: the snr after the noise compensation of the speechdat - car .
B: so the training the neural net is being trained with noise compensated . which makes sense , but , , you 're saying , the noisier ones are still going to be , even after our noise compensation , are still gonna be pretty noisy .
D: so now the after - noise compensation the neural net is seeing different set of rs than that was originally there in the training set . of timit . because in the timit it was zero to some clean . so the net saw all the snr @ @ conditions . now after cleaning up it 's different set of snr . and that snr may not be , like , com covering the whole set of rs that you 're getting in the speechdat - car .
B: but the speechdat - car data that you 're seeing is also reduced in noise by the noise compensation .
D: but , 'm saying , there could be some issues of
C: if the initial range of snr is different , we the problem was already there before .
B: , it depends on whether you believe that the noise compensation is equally reducing the noise on the test set and the training set .
D: on the test set , .
B: you 're saying there 's mismatch in noise that wasn't there before , but if they were both the same before , then if they were both reduic reduced equally , then , there would not be mismatch . heaven forbid , this noise compensation process may be imperfect , so maybe it 's treating some things differently .
D: that could be seen from the ti - digits , , testing condition because , , the noises are from the ti - digits , right ? so cleaning up the ti - digits and if the performance goes down in the ti - digits mismatch high mismatch like this
C: clean training , .
D: on clean training , or zero db testing .
C: we 'll so we 'll see .
D: then it 's something to do .
B: one of the things about the macrophone data , , , , it was recorded over many different telephones . so , there 's lots of different kinds of acoustic conditions . it 's not artificially added noise or anything . so it 's not the same . don't think there 's anybody recording over car from car , but it 's it 's varied enough that if doing this adjustments , , and playing around with it doesn't , , make it better , the most , it seems like the most obvious thing to do is to improve the training set . the condition it it gave us an enormous amount of improvement in what we were doing with meeting recorder digits , even though there , again , these macrophone digits were very , very different from , , what we were going on here . we weren't talking over telephone here . but it was just just having variation in acoustic conditions was just good thing .
C: actually to , what observed in the hm case is that the number of deletion dramatically increases . it it doubles .
B: number of deletions .
C: when added the num the neural network it doubles the number of deletions . so don't how to interpret that ,
A: and and did an other numbers stay the same ? insertion substitutions stay the same ?
C: they stayed the same , they maybe they are little bit , lower . they are little bit better .
B: did they increase the number of deletions even for the cases that got better ? say , for the , it
C: no , it doesn't .
B: so it 's only the highly mismatched ? and it remind me again , the "" highly mismatched "" means that the
C: it 's clean training close microphone training and distant microphone , , high speed , . the most noisy cases are the distant microphone for testing .
B: maybe the noise subtraction is subtracting off speech .
C: but without the neural network it 's , it 's better . it 's just when we add the neural networks . the feature are the same except that
B: that 's right .
A: that says that , , the , the models in , , the recognizer are really paying attention to the neural net features .
B: actually {nonvocalsound} the timit noises are range of noises and they 're not so much the stationary driving noises , right ? it 's it 's pretty different .
C: there is car noise . so there are just four noises . "" car "" , , "" babble "" ,
D: "" babble . ""
C: "" subway "" , right ?
D: "" street "" or "" airport "" .
C: and "" street "" isn't
D: or "" train station "" .
C: "" train station "" , . so it 's mostly , "" car "" is stationary , "" babble "" , it 's stationary background plus some voices , some speech over it . and the other two are rather stationary also .
B: that if you run it actually , you maybe you remember this . when you in the old experiments when you ran with the neural net only , and didn't have this side path , , , with the pure features as , did it make things better to have the neural net ? was it about the same ?
C: it was little bit worse . than just the features ,
B: until you put the second path in with the pure features , the neural net wasn't helping . that 's interesting .
C: it was helping , , if the features are were bad , just plain ps or as soon as we added lda on - line normalization , and all these things , then
B: they were doing similar enough things . still would be interesting to see what would happen if you just had the neural net without the side thing . and and the thing have in mind is , , maybe you 'll see that the results are not just little bit worse . maybe that they 're lot worse . but if on the ha other hand , , it 's , say , somewhere in between what you 're seeing now and and , , what you 'd have with just the pure features , then maybe there is some problem of of , , combination of these things , or correlation between them somehow . if it really is that the net is hurting you at the moment , then the issue is to focus on , , improving the net . so what 's the overall effe you haven't done all the experiments but you said it was somewhat better , say , five percent better , for the first two conditions , and fifteen percent worse for the other one ? but it 's but that one 's weighted lower , so wonder what the net effect is .
C: it 's it was one or two percent . that 's not that bad , but it was like two percent relative worse on speechdat - car . have to check that .
D: it will overall it will be still better even if it is fifteen percent worse , because the fifteen percent worse is given like twenty - five point two five eight .
B: so the so the worst it could be , if the others were exactly the same , is four , and , , since the others are somewhat better
D: so it 's four . so either it 'll get cancelled out , or you 'll get , like , almost the same .
C: it was it was slightly worse .
B: it should be pretty close to cancelled out .
A: 've been wondering about something . in the , lot of the , the hub - five systems , , recently have been using lda . and they , they run lda on the features right before they train the models . so there 's the lda is right there before the so , you guys are using lda but it seems like it 's pretty far back in the process .
D: this lda is different from the lda that you are talking about . the lda that you saying is , like , you take block of features , like nine frames , and then do an lda on it , and then reduce the dimensionality to something like twenty - four like that .
A: you you can .
D: and then feed it to .
A: it 's , you 're just
D: so this is like two two dimensional tile .
A: you 're shifting the feature space .
D: so this is two dimensional tile . and the lda that we are applying is only in time , high cost frequency . so it 's like more like filtering in time ,
A: so what what about , what if this is good idea or not , but what if you put ran the other lda , , on your features right before they go into the ?
C: no , actually , what do we do with the ann is something like that except that it 's not linear . but it 's it 's like nonlinear discriminant analysis .
A: it 's the it 's so it 's like the tandem is like nonlinear lda . but , but the other features that you have , , th the non - tandem ones ,
C: in the proposal , they were transformed using pca , it might be that lda could be better .
B: the the argument is in and it 's not like we really know , but the argument anyway is that , , , we always have the prob discriminative things are good . lda , neural nets , they 're good . they 're good because you you learn to distinguish between these categories that you want to be good at distinguishing between . and pca doesn't do that . it pac - pca low - order pca throws away pieces that are , maybe not gonna be helpful just because they 're small , . but , , the problem is , training sets aren't perfect and testing sets are different . so you you face the potential problem with discriminative , be it lda or neural nets , that you are training to discriminate between categories in one space but what you 're really gonna be getting is something else . and so , , stephane 's idea was , , let 's feed , , both this discriminatively trained thing and something that 's not . so you have good set of features that everybody 's worked really hard to make , and then , , you discriminately train it , but you also take the path that doesn't have that , and putting those in together . so it 's like combination of the , what , , dan has been calling , , feature , , feature combination versus posterior combination . it 's it 's , , you have the posterior combination but then you get the features from that and use them as feature combination with these other things . and that seemed , at least in the last one , as he was just saying , he when he only did discriminative , it actually was it didn't help in this particular case . there was enough of difference , , between the testing and training . but by having them both there the fact is some of the time , the discriminative is gonna help you . and some of the time it 's going to hurt you , and by combining two information sources if , if
A: so you wouldn't necessarily then want to do lda on the non - tandem features because now you 're doing something to them that
B: that 's counter to that idea . now , again , it 's we 're just trying these different things . we don't really 's gonna work best . but if that 's the hypothesis , at least it would be counter to that hypothesis to do that . and in principle you would think that the neural net would do better at the discriminant part than lda . though , maybe not .
A: we , we were getting ready to do the tandem , , for the hub - five system , and , , andreas and talked about it , and the idea the thought was , "" , , , that th the neural net should be better , but we should at least have , number , , to show that we did try the lda in place of the neural net , so that we can , show clear path . that you have it without it , then you have the lda , then you have the neural net , and you can see , theoretically .
B: that 's good idea . did did you do that or tha that 's
A: that 's what that 's what we 're gonna do next as soon as finish this other thing .
B: no , , that 's good idea .
A: we just want to show . it everybody believes it , but , we just
B: no , no , but it might not even be true . it 's it 's it 's great idea . one of the things that always disturbed me , , in the resurgence of neural nets that happened in the eighties was that , , lot of people because neural nets were pretty easy to use lot of people were just using them for all sorts of things without , , looking into the linear , , versions of them . and , , people were doing recurrent nets but not looking at iir filters , and , , , so , , it 's definitely good idea to try it .
A: and everybody 's putting that on their systems now , that 's what made me wonder about this ,
B: they 've been putting them in their systems off and on for ten years , but but , ,
A: what is it 's it 's like in the hub - five evaluations , , and you read the system descriptions and everybody 's got , , lda on their features .
B: and now they all have that .
C: it 's the transformation they 're estimating on they are trained on the same data as the final are .
A: so it 's different . cuz they don't have these , , mismatches that you guys have . so that 's why was wondering if maybe it 's not even good idea . enough about it ,
B: part of why you were getting into the klt you were describing to me at one point that you wanted to see if , , , getting good orthogonal features was and combining the different temporal ranges was the key thing that was happening or whether it was this discriminant thing , right ? so you were just trying this is it doesn't have the lda aspect but th as far as the orthogonalizing transformation , you were trying that at one point , right ? it doesn't work as .
D: 've been exploring parallel vad without neural network with , like , less latency using snr and energy , , after the cleaning up . so what 'd been trying was , , after the after the noise compensation , was trying to find feature based on the ratio of the energies , that is , cl after clean and before clean . so that if they are , like , pretty close to one , which means it 's speech . and if it is if it is close to zero , which is so it 's like scale @ @ probability value . so was trying , , with full band and multiple bands , ps separating them to different frequency bands and deriving separate decisions on each bands , and trying to combine them . the advantage being like it doesn't have the latency of the neural net if it if it can and it gave me like , , one point one more than one percent relative improvement . so , from fifty - three point six it went to fifty four point eight . so it 's , like , only slightly more than percent improvement , which means that it 's it 's doing slightly better job than the previous vad , at lower delay .
B: does it still have the median filter ?
D: it still has the median filter .
B: so it still has most of the delay ,
D: so with the delay , that 's gone is the input , which is the sixty millisecond . the forty plus twenty . at the input of the neural net you have this , , nine frames of context plus the delta .
B: plus the delta ,
D: so that delay , plus the lda . so the delay is only the forty millisecond of the noise cleaning , plus the hundred millisecond smoothing at the output . so the di the biggest the problem for me was to find consistent threshold that works across the different databases , because try to make it work on tr speechdat - car and it fails on ti - digits , or if try to make it work on that it 's just the italian , it doesn't work on the finnish . so there are there was , like , some problem in balancing the deletions and insertions when try different thresholds . 'm still trying to make it better by using some other features from the after the clean up maybe , some , , correlation auto - correlation or some additional features of to mainly the improvement of the vad . 've been trying .
B: now this this , , "" before and after clean "" , it sounds like you think that 's good feature . that that , it you th think that the , the it appears to be good feature , right ? what about using it in the neural net ?
C: eventually we could just
D: so that 's the so we 've been thinking about putting it into the neural net also . because they did that itself
C: then you don't have to worry about the thresholds and
D: so that 's ,
B: so if we if we can live with the latency or cut the latencies elsewhere , then that would be , , good thing . anybody has anybody you guys or naren , , somebody , tried the , , , second th second stream thing ?
D: put the second stream in place and , ran one experiment , but just like just to know that everything is fine . so it was like , , forty - five cepstrum plus twenty - three mel log mel . and and , just , like , it gave me the baseline performance of the aurora , which is like zero improvement . so tried it on italian just to know that everything is but didn't export anything out of it because it was , like , weird feature set .
B: what , , would be more what you 'd want to do is is , , put it into another neural net . we 're we 're not quite there yet . so we have to figure out the neural nets , .
D: the , other thing was wondering was , , if the neural net , , has any because of the different noise con unseen noise conditions for the neural net , where , like , you train it on those four noise conditions , while you are feeding it with , like , additional some four plus some few more conditions which it hasn't seen , actually , from the while testing . instead of just having , those cleaned up cepstrum , sh should we feed some additional information , like the the we have the vad flag . should we feed the vad flag , also , at the input so that it has some additional discriminating information at the input ?
B: wh - , the vad what ?
D: we have the vad information also available at the back - end . so if it is something the neural net is not able to discriminate the classes because most of it is sil we have dropped some silence we have dropped so silence frames ? no , we haven't dropped silence frames still . the biggest classification would be the speech and silence . so , by having an additional , , feature which says "" this is speech and this is nonspeech "" , , it certainly helps in some unseen noise conditions for the neural net .
A: do do you have that feature available for the test data ?
D: , we have we are transferring the vad to the back - end feature to the back - end . because we are dropping it at the back - end after everything all the features are computed . so that is coming from separate neural net or some vad . which is which is certainly giving
A: so you 're saying , feed that , also , into the neural net .
D: so it 's an additional discriminating information .
B: you could feed it into the neural net . the other thing you could do is just , , modify the , , output probabilities of the of the , , , neural net , tandem neural net , based on the fact that you have silence probability . so you have an independent estimator of what the silence probability is , and you could multiply the two things , and renormalize . , you 'd have to do the nonlinearity part and deal with that . , go backwards from what the nonlinearity would , would be .
D: through to the soft max .
C: maybe , , when
A: but in principle wouldn't it be better to feed it in ? and let the net do that ?
B: let 's put it this way . you have this complicated system with thousands and thousand parameters and you can tell it , , "" learn this thing . "" or you can say , "" it 's silence ! go away ! "" the second one sounds lot more direct .
A: so , what if you then , since this , what if you only use the neural net on the speech portions ? that 's the same . that 's similar .
B: you 'd have to actually run it continuously ,
A: but , train the net only on
B: but it 's @ @ you want to train on the nonspeech also , because that 's part of what you 're learning in it , to to generate , that it 's it has to distinguish between .
A: but , if you 're gonna if you 're going to multiply the output of the net by this other decision , , would then you don't care about whether the net makes that distinction , right ?
B: but this other thing isn't perfect . so that you bring in some information from the net itself .
A: that 's good point .
B: now the only thing that bothers me about all this is that the the fact it 's bothersome that you 're getting more deletions .
C: so might maybe look at , is it due to the fact that , the probability of the silence at the output of the network , is ,
B: is too high .
C: if it 's the case , then multiplying it again by by something ?
D: it may not be it it may be too it 's too high in sense , like , everything is more like , , flat probability .
C: - eee - hhh .
D: so , like , it 's not really doing any distinction between speech and nonspeech or , , different among classes .
A: be interesting to look at the wonder if you could do this . but if you look at the , , highly mism high mismat the output of the net on the high mismatch case and just look at , , the distribution versus the other ones , do you do you see more peaks ?
C: like the entropy of the output , it it seems that the vad network doesn't , it doesn't drop , , too many frames because the dele the number of deletion is reasonable . but it 's just when we add the tandem , the final mlp , and then
B: now the only problem is you don't want to ta for the output of the vad before you can put something into the other system , cuz that 'll shoot up the latency lot , am missing something here ? so that 's maybe problem with what was just saying .
A: but if you were gonna put it in as feature it means you already have it by the time you get to the tandem net ,
D: we we don't have it , actually , because it 's it has high rate energy
B: it 's done in some of the things are , not in parallel , but certainly , it would be in parallel with the with tandem net . so maybe , if that doesn't work , but it would be interesting to see if that was the problem , anyway . and and then another alternative would be to take the feature that you 're feeding into the vad , and feeding it into the other one as . and then maybe it would just learn it better . that 's an interesting thing to try to see , if what 's going on is that in the highly mismatched condition , it 's , , causing deletions by having this silence probability up too high , at some point where the vad is saying it 's actually speech . which is probably true . if the vad said since the vad is is right lot , we just started working with it . but these are these are some good ideas .
C: and the other thing there are other issues maybe for the tandem , like , , , do we want to , do we want to work on the targets ? or , like , instead of using phonemes , using more context dependent units ?
A: for the tandem net you mean ?
C: 'm thinking , also , about dan 's work where he trained network , not on phoneme targets but on the state targets . it was giving slightly better results .
B: problem is , if you are going to run this on different test sets , including large vocabulary ,
C: was just thinking maybe about , like , generalized diphones , and come up with reasonable , not too large , set of context dependent units , and then anyway we would have to reduce this with the klt .
B: but it it 's all worth looking at , but it sounds to me like , , looking at the relationship between this and the speech noise is is probably key thing . that and the correlation between .
A: if the , , high mismatch case had been more like the , , the other two cases in terms of giving you just better performance , how would this number have changed ?
C: around five percent better , .
B: we what 's it 's gonna be the ti - digits yet . he hasn't got the results back yet .
C: if you extrapolate the speechdat - car - matched and medium - mismatch , it 's around , , maybe five .
A: so this would be sixty - two ?
B: sixty - two .
C: sixty - two ,
D: somewhere around sixty , must be .
C: it 's around five percent , because it 's if everything is five percent .
A: all the other ones were five percent ,
C: have the speechdat - car right now , it shou we should have the results today during the afternoon ,
B: so won't be here for
A: when do you leave ?
B: 'm leaving next wednesday . may or may not be in the morning . leave in the afternoon .
A: you 're not gonna be around this afternoon ?
B: 'm talking about next week . 'm leaving next wednesday . for the meeting meeting ? that 's just cuz of something on campus . so next week won't , and the week after won't , cuz 'll be in finland . and the week after that won't . by that time you 'll be , you 'll both be gone from here . so there 'll be no definitely no meeting on september sixth .
A: what 's september sixth ?
B: that 's during eurospeech . so , , sunil will be in oregon . stephane and will be in denmark . so it 'll be few weeks , really , before we have meeting of the same cast of characters . you guys should probably meet . and maybe barry will be around . and then , we 'll start up again with dave and dave and barry and stephane and us on the , , twentieth .
A: you 're gonna be gone for the next three weeks ?
B: 'm gone for two and half weeks starting next wed - late next wednesday .
A: so that 's you won't be at the next three of these meetings . is that right ?
B: it 's probably four because of is it three ? let 's see , twenty - third , that 's right , and the third one won't probably won't be meeting , cuz , , su - sunil , stephane , and will all not be here . mmm . so it 's just , , the next two where there will be there , , may as be meetings , but won't be at them . and then starting up on the thirteenth , {nonvocalsound} , we 'll have meetings again but we 'll have to do without sunil here somehow .
A: when do you go back ?
D: thirty - first , august .
A: when is the evaluation ?
B: it was supposed to be november fifteenth . has anybody heard anything different ?
C: the meeting in is the five and six of december .
D: it 's like , it 's tentatively all full . that 's proposed date , .
C: so the evaluation should be on week before
B: but , no , this is good progress .
A: should we do digits ?
B: we 're done . it 's wrap .
","ICSI's Meeting Recorder Group at Berkeley meets to discuss , for the most part , progress on the Aurora Project.
The main areas being worked on were the voice activity detector and the tandem data streams.
The group discussed possible further investigations that arose from these areas , including better linking the two.
They also consider how aspects of an absent member's work might be applied to the current project.
The meeting closed with a discussion of upcoming absences , and how meetings would continue.
Speaker me018 must confirm what is needed to work with the new software in terms of adjustments with someone further up the project chain.
The system at it's current stage employs the neural networks and second stream , but the group leader would like the network investigated separately , incase it is hurting performance.
There are worries regarding the need to make adjustments so the new software can handle the group's different feature set.
The system , whilst improved , also has increased latency , and while the limit has not been set , the group need to reduce it.
Likewise the number of features the use in their system , since this has been set at an arbitrarily low value.
There has been an increase in the number of deletion in the errors , which is of some concern.
Speaker mn007 has been implementing a new voice activity detector on noise compensated data , and it performs much better.
He has also been working on the tandem neural network.
Speaker me013 , along with a student , submitted work on reverberation for a speech workshop.
Speaker me018 has downloaded and compiled the software he was asked to work with in the previous meeting.
"
ami_abstractive_summary,Bed010.txt,"D: how many batteries do you go through ?
C: so , let 's get started . nancy said she 's coming and that means she will be . my suggestion is that robert and johno give us report on last week 's adventures to start . so everybody knows there were these guys from heidelber - , actually from dfki , part of the german smartkom project , who were here for the week and , got lot done .
E: the we got to the point where we can now speak into the smartkom system , and it 'll go all the way through and then say something like "" roman numeral one , am smarticus . "" it actually says , "" roemisch einz , am smarticus , "" which means it 's just using german sythesis module for english sentences .
C: it doesn't know "" "" .
B: am spartacus . ""
D: "" am sm - am smarticus "" is what it 's saying .
E: the sythesis is just question of , hopefully it 's just question of exchanging couple of files , once we have them . and , , it 's not going to be problem because we decided to stick to the so - called concept to speech approach . so 'm 'm going backwards now , so "" synthesis "" is where you make this , make these sounds , and "" concept to speech "" is feeding into this synthesis module giving it what needs to be said , and the whole syntactic structure so it can pronounce things better , presumably . then , just with text to speech . and , , johno learned how to write xml tags . and did write the tree adjoining grammar for some sentences .
D: so . bu - , the way the , the dialogue manager works is it dumps out what it wants to know , or what it wants to tell the person , to er in xml and there 's conversion system for different , to go from xml to something else . and th so , the knowledge base for the system , that generates the syntasti syntactic structures for the ge generation is , in lisp - like the knowledge base is in lisp - like form . and then the thing that actually builds these syntactic structures is something based on prolog . so , you have , goal and it , , says "" , 'm gonna try to do the greet - the - person goal , so it just starts , it binds some variables and it just decides to , , do some subscold . it just means "" build the tree . "" and then it passes the tree onto , , the ge the generation module .
E: but that that out of the twelve possible utterances that the german system can do , we 've already written the syntax trees for three or four .
D: so , the syntax trees are very simple . it 's like most of the sentences in one tree , and instead of , , breaking down to , like , small units and building back up , they took the sentences , and cut them in half , or , into thirds like that , and made trees out of those . and so , tilman wrote little tool that you could take lisp notation and generate an xml , , tree . , what do ca structure from the from the lisp . and so you just say , , "" noun goes to "" , , er , nah , don't re 've never been good at those . so there 's like the vp goes to and those things in lisp , and it will generate for you .
E: and because we 're sticking to that structure , the synthesis module doesn't need to be changed . so all that fancy , and the texas speech version of it , which is actually the simpler version , is gonna be done in october which is much too late for us . this way we worked around that . the , the system , show you the system . actually want , at least , maybe , you should be able to start it on your own . if you wanna play around with it , in th in the future . right now it 's brittle and you need to ch start it up and then make ts twenty changes on on seventeen modules before they actually can stomach it , anything . and send in couple of side queries on some dummy center set - up program so that it actually works because it 's designed for this seevit thing , where you have the gestural recognition running with this siemens virtual touch screen , which we don't have here . and so we 're doing it via mouse , but the whole system was designed to work with this thing and it was it was lot of engineering . no science in there whatsoever , but it 's working now , and , that 's the good news . so everything else actually did prove to be language independent except for the parsing and the generation .
D: why had did need to chan generate different trees than the german ones , mainly because like , the gerund in german is automatically taken care of with just regular verb ,
E: you have to switch it on .
D: so 'd have to add "" am walking , "" or 'd have to add little stem for the "" am "" , when build the built the tree .
B: noticed that , that some of the examples they had , had , non - english word orders and so on , and then all that good .
C: so it might be worth , keith , you looking at this ,
B: still don't still don't really understand like still don't exactly understand the information flow in this thing , or what the modules are and so on . so , , like just that such - and - such module decides that it wants to achieve the goal of greeting the user , and then magically it how does it know which syntactic structure to pull out , and all that ?
C: so . it 's not worth going over in the group , but when you get free and you have the time either robert or johno or walk you through it . and you can ask all the questions about how this all fits together .
B: that 's fine .
C: it 's eee messy but once you understand it . it 's it 's there 's nothing really complicated about it .
B: and remember one thing that came up in the talk last wednesday . , was this , he talked about the idea of like , he was talking about these lexicalized , tree adjoining grammars where you for each word you ,
D: how to do it ?
B: for each lexical item , the lexical entry says wh the trees are that it can appear in . and , that 's not that 's the opposite of constructional . that 's , , that 's that 's hpsg or whatever .
C: now , we 're we 're not committed for our research to do any of those things . so we are committed for our funding .
B: make our fit to that .
C: no , to just get the dem get the demos they need . so between us all we have to get th the demos they need . if it turns out we can also give them lots more than that by , , tapping into other things we do , that 's great .
D: you should probably move the microphone closer to your face .
C: but it turns out not to be in an any of the contracts
D: there 's like little the twisty thing , you can move it with .
C: and , deliberately . so , the reason 'd like you to understand what 's going on in this demo system is not because it 's important to the research . it 's just for closure . so that if we come up with question of "" could we fit this deeper in there ? "" . what the hell we 're talking about fitting in . so it 's just , in the sam same actually with the rest of us we just need to really understand what 's there . is there anything we can make use of ? is there anything we can give back , beyond th the minimum requirements ? but none of that has short time fuse . so th the demo requirements for this fall are taken care of as of later this week . and then so , it 's probably fifteen months until there 's another serious demo requirement . that doesn't mean we don't think about it for fifteen months , but it means we can not think about it for six months . so . the plan for this summer , really is to step back from the applied project , keep the keep the context open , but actually go after the basic issues . so the idea is there 's this , other subgroup that 's worrying about formalizing the nota getting notation . but in parallel with that , , the hope is tha in particularly you will work on constructions in english ge - and german for this domain , but not worry about parsing them or fitting them into smartkom or any of the other anything lik any other constraints for the time being . it 's hard enough to get it semantically and syntactically right and then and get the constructions in their form and . and , don don't want you feeling that you have to somehow meet all these other constraints . and similarly with the parsing , we 're gonna worry about parsing , the general case construction parser for general constructions . and , if we need cut - down version , or whatever , we 'll worry about that later . so 'd like to , for the summer turn into science mode . and assume that 's also , , your plan as .
B: so , that like the meetings so far that 've been at have been been geared towards this demo , and then that 's going to go away pretty soon .
C: but but we 're swit
B: and then we 'll shift gears fairly substantially ,
E: it 's got . what what is good idea that show to anyone who 's interested , we can even make an internal demo , and show you what do , speak into it and you hear it talk , and walk through the information . so , this is like in half hour or forty - five minutes . and so you when somebody on the streets com comes up to you and asks you what is smartkom so you can , , give sensible answer .
C: so , sh we could set that up as actually an institute wide thing ? just give talk in the big room , and so peo people 's going on ? when you 're ready ? that 's the thing that 's the level at which we can just li invite everybody and say "" this is project that we 've been working on and here 's demo version of it "" and like that .
E: we do wanna have all the bugs out where you have to pipe in extra xml messages from left and right before you 're
C: but any so that it 's clear , then , . actually , roughly starting let 's say , nex next meeting , cuz this meeting we have one other thing to tie up besides the trip report . but starting next meeting we want to flip into this mode where there are lot of issues , what 's the ontology look like , what do the constructions look like , what 's the execution engine look like , mmm lots of things . but , more focused on an idealized version than just getting the demo out . now before we do that , let 's get back in but , it 's still , , useful for you to understand the demo version enough , so that you can see what it is that it might eventually get retro - fitted into . and johno 's already done that , , looked at the dem the looked at the smartkom .
D: what part of th the smartkom ?
C: the parser , and that . so , the trip the report on these the last we interrupted you guys telling us about what happened last week .
B: it 's alright .
E: it was just amazing to see how instable the whole thing is ,
C: maybe you 're done , then .
E: and if you just take the and got the feeling that we are the only ones right now who have running system . what the guys in kaiserslautern have running the version that is , the full version that 's on the server does not work . and you need to do lot of to make it work . and so it 's and even tilman and ralf said "" there never was really working version that did it without th all the shortcuts that they built in for the october @ @ version "" . so we 're actually maybe ahead of the system gruppe by now , the system the integration group . and it was , it was fun to some extent , but the the outcome that is scientific interest is that both ralf and tilman know that they enjoyed it here , and they they liked , , lot of the they saw here , what we have been thinking about , and they 're more than willing to , cooperate , by all means . and , part of my responsibility is to use our internal "" group - ware "" server at eml , make that open to all of us and them , so that whatever we discuss in terms of parsing and generating and constructions we put it in there and they put what they do in there and maybe we can even , get some overlap , get some synergy out of that . if find someone at in eml that is interested in that , may even think that we could look take constructions and generate from them because the tree adjoining grammars that tilman is using is as you said nothing but mathematical formalism . and you can just do anything with it , whether it 's syntactic trees , - like , or whether it 's construction . so if you ever get to the generation side of constructing things and there might be something of interest there , but in the moment we 're definitely focused on the understanding , , pipeline .
C: anyth - any other repo visit reports stories ? we so we now know , what the landscape is like . and so we just push on and , do what we need to do . and one of the things we need to do is the , and this is relatively tight tightly constrained , is to finish up this belief - net . and was going to switch to start talking about that unless there 're other more general questions . so here 's where we are on the belief - net as far as understand it . going back two weeks ago robert had laid out this belief - net , missing only the connections . that is so , he 'd put all th all the dots down , and we went through this , and , , more or less convinced ourselves that at least the vast majority of the nodes that we needed for the demo level we were thinking of , were in there . we may run across one or two more . but the connections weren't . so , bhaskara and went off and looked at some technical questions about were certain operations legitimate belief - net computations and was there some known problem with them or had someone already , solved how to do this and . and so bhaskara tracked that down . the answer seems to be , "" no , no one has done it , but yes it 's perfectly reasonable thing to do if that 's what you set out to do "" . and , so the current state of things is that , again , starting now , we 'd like to actually get running belief - net for this particular subdomain done in the next few weeks . so bhaskara is switching projects as of the first of june , and , he 's gonna leave us an inheritance , which is hopefully belief - net that does these things . and there 're two aspects to it , one of which is , , technical , getting the coding right , and making it run , and like that . and the other is the actual semantics . ? wh , what are the considerations and how and what are the ways in which they relate . so he doe he doesn't need help from this group on the technical aspects or if he does we 'll do that separately . but in terms of what are the decisions and like that , that 's something that we all have to work out . is is that right ? that 's that 's both you guys ' understanding of where we are ?
G: so , , is there like latest version of the belief - net of the proposed belief - net ?
E: , no , we didn't decide . we wanted to look into maybe getting it , the visualization , bit clearer , but if we do it , , paper version of all the nodes and then the connections between them , that should suffice .
G: that should be fine .
C: that 's separate problem . we do in the long run wanna do better visualization and all that . that 's separable ,
D: did look into that , in terms of , , exploding the nodes out and down ag javabayes does not support that . imagine way of hacking at the code to do that . it 'd probably take two weeks or so to actually go through and do it ,
C: not not at this point .
D: and went through all the other packages on murph - kevin murphy 's page , and couldn't find the necessary mix of free and with the gui and , with this thing that we want .
C: we can if it 's if we can pay if it 's paying thousand dollars we can do that . so so don't view free as absolute constraint .
D: so then 'll go back and look at the ones on the list that
C: and you can ask kevin .
G: the one that people seem to use is hugin or whatever ?
C: that 's free .
G: is it free ? because 've seen it advertised in places so it seems to
C: it may be free to academics . have co have copy that downloaded . so , at one point it was free . but yo noticed people do use hugin
D: how do you spell that ?
C: and bhaskara can give you pointer . so then , in any case , if if it 's probably for university , it 's it 's gonna be real cheap anyway . but , , if it 's fifty thousand dollars we aren't gonna do it . 'm mean , we have no need for that .
E: also would suggest not to spend two weeks in in changing the javabayes code .
C: he 's not gonna do that .
E: will send you pointer to java applet that does that , it 's fish - eye . you you have node , and you click on it , and it shows you all the connections , and then if you click on something else that moves away , that goes into the middle . and maybe there is an easy way of interfacing those two . if that doesn't work , it 's not problem we need to solve right now . what 'm what my job is , will , , give you the input in terms of the internal structure . maybe node by node , like this ? or should collect it all
G: just any like rough representation of the entire belief - net is probably best .
E: and you 're gonna be around ? again , always tuesdays and thursdays afternoon - ish ? as usual ? or will that change ?
G: this week , have lot of projects and but after that will generally be more free . so yes , might be around . and , generally if you email me also be around on other days .
C: and this is not crisis that , you do , everybody who 's student should , do their work , get their courses all in good shape and and then we 'll dig dig down on this .
E: no , that 's good . that means have spend this week doing it .
B: how do you go about this process of deciding what these connections are ? know that there 's an issue of how to weight the different things too , and . do you just and see if it
C: there there there 're two different things you do . one is you design and the other is you learn . so what we 're gonna do initially is do design , and , if you will , . that is use your best knowledge of the domain to , hypothesize what the dependencies are and . if it 's done right , and if you have data then , there are techniques for learning the numbers given the structure and there are even techniques for learning the structure , although that takes lot more data , and it 's not as @ @ and and so on . but for the limited amount of we have for this particular exercise we 'll just design it .
E: fo - hopefully as time passes we 'll get more and more data from heidelberg and from people actually using it and . so but this is the long run . but to solve our problems ag mediocre design will do in the beginning .
B: that 's right . , and , speaking of data , , are there could swore , could swear saw it sitting on someone 's desk at some point , but is there transcript of any of the , , initial interactions of people with the with the system ? cuz , 'm still itching to look at what look at the , and see what people are saying .
C: make yourself note . so and , keith would like the german as as the english , so whatever you guys can get . the your native language , you remember that one .
E: that 's important , .
C: so he 'll get you some data .
B: found the , the audio of some of those , and , it sounded like didn't want to trudge through that , . it was just strange ,
E: we probably will not get those to describe because they were trial runs . but that 's th but we have data in english and german already . will send you that .
C: so while we 're still at this top level , anything else that we oughta talk about today ?
E: ho - how was your thingy .
B: , wanted to , , like mention as an issue , , last meeting wasn't here because went to linguistics colloquium on the fictive motion , and that was pretty interesting seems to me that will fairly be of relevance to to what we 're doing here because people are likely to give descriptions like , "" what 's that thing right where you start to go up the hill , "" like that , meaning few feet up the hill or whatever from some reference point and all that so , 'm in terms of , people trying to state locations or , , all that , this is gonna be very relevant . now that was the talk was about english versus japanese , , which the japanese doesn't affect us directly , except that , , some of the construction he 'd what he talked about was that in english we say things like th , "" your bike is parked across the street "" and we use these prepositional phrases , , "" , if you were to move across the street you would be at the bike "" , but in japanese the more conventionalized tendency is to use description of "" where one has crossed to the river , there is tree "" . and , you can actually say things like , , "" there 's tree where one has crossed the river , but no one has ever crossed the river "" , like that . so the idea is that this really is that 's supposed show that 's it 's really fictive and so on . but that construction is also used in english , , like "" right where you start to go up the hill "" , or "" just when you get off the train "" , like that to , to indicate where something is . so we 'll have to think about
C: how much is that used in german ?
E: the wa was on on different sidetrack . the deep map project which is undergoing some renovation at the moment , but this is three language project : german , english , japanese . and , we have , have taken care that we have the japanese generation and . and so looked into spatial description . so we can generate spatial descriptions , how to get from to . and and information on objects , in german , english , and japanese . and there is huge project on spatial descriptions differences in spatial descriptions . if yo if you 're interested in that , it does go all the way down to the conceptual level to some extent .
C: so , where is this huge project ?
E: it 's kleist . it 's the bielefeld generation of spatial descriptions and whatever .
C: that may be another thing that keith wants to look at .
E: but , we should leave japanese constructions maybe outside of the scope for now , but definitely it 's interesting to look at cross the bordered there .
A: are are you going to pay any attention to the relative position of the direction relative to the speaker ? there are some differences between hebrew and english . we can say "" park in front of the car "" as you come beh you drive behind the car . in hebrew it means "" park behind the car "" , because to follow the car is defined as it faces you . while in english , front of the car is the absolute front of the car .
B: right , so the canonical direction of motion determines where the front is .
A: so , is german closer to , , to don't 's related to syntax , though , so it may be entirely different .
C: no , it 's not .
E: did you ever get to look at the rou paper that sent you on the on that problem in english and german ? carroll , ninety - three . there is study on the differences between english and german on exactly that problem . so it 's they actually say "" the monkey in front of the car , where 's the monkey ? "" and , , they found statistically very significant differences in english and german , it might be , since there are only finite number of ways of doing it , that german might be more like hebrew in that respect . the solution they proposed was that it was due to syntactic factors .
A: that but it wasn't was
E: that syntactic facto factors do play role there , wh whether you 're more likely , , to develop , choices that lead you towards using intrinsic versus extrinsic reference frames .
B: it seems to me that you can get both in english depending like , "" in front of the car "" could like , here 's the car sideways to me in between me and the car 's in front of the car , or whatever . could see that , but anyway , so , , this was this was very good talk on those kinds of issues and so on .
E: also give you , pointer to paper of mine which is the ultimate taxonomy of reference frames . 'm the only person in the world who actually knows how it works .
C: no , 've not seen that .
A: what do you mean . . "" reference frames "" ?
E: it 's it 's spatial reference frames . you actually have only if you wanna have should there should be an "" "" , though . actually you have only have two choices . you can either do two - point or three - point which is you you 're familiar with th with the "" origo "" ? where that 's the center "" origo "" is the center of the frame of reference . and then you have the reference object and the object to be localized . in some cases the origo is the same as the reference object .
C: so that would be "" origin "" in english ,
E: "" origo "" is terminus technikus . in that sense , that 's even used in the english literature . "" origo . ""
B: never heard it .
E: and , so , this video tape is in front of me . 'm the origo and 'm also the reference object . those are two - point . and three - point relations is if something has an intrinsic front side like this chair then your shoe is behind the chair . and , reference object and . no , from my point of view your shoe is left of the chair .
B: you you can actually say things like , , "" it 's behind the tree from me "" like that , , in in certain circumstances in english , as "" from where 'm standing it would appear that ""
F: looks little bit like reichenbach for time .
C: it sounds like it ,
F: it 's lot like it .
E: and then and then here you on this scale , you have it either be ego or allocentric . and that 's that 's it . so . egocentric two - point , egocentric three - point , or you can have allocentric . so , "" as seen from the church , the town hall is right of that , fire station "" . aa - it 's hardly ever used but it 's
A: 'd love to see it if you if you have copy .
C: see this is this is getting into ami 's thing . he 's he 's very interested in that . why don't you just put it on the web page ? there 's this edu
E: it 's or just
C: or link to it .
E: it 's also all on my home page at eml . it 's called "" an anatomy of spatial description "" . but 'll send that link .
C: maybe just put link on . there something that didn't know until about week ago or so , is , there are separate brain areas for things within reach , and things that are out of reach . so there 's there 's all this linguistic about , near and far , or yon and . so this is all this is there 's this linguistic facts . but , the . here 's the way the findings go . that , they do mri , and if you 're got something within reach then there 's one of your areas lights up , and if something 's out of reach different one . but here 's the amazing result , , they say . you get someone with with deficit so that they have perfectly normal ability at distance things . so the typical task is subdivision . so there 's line on the wall over there , and you give them laser pointer , and you say , "" where 's the midpoint ? "" and they do fine . if you give them the line , and they have to touch it , there 's just that part of the brain isn't functioning , so they can't do that . here 's the real experiment . the same thing on the wall , you give them laser , "" where is it ? "" , they do it . give them stick , long stick , and say "" do it "" , they can't do it . so there 's remapping of distant space into nearby space .
A: the end the end of this
F: because it 's within reach now ?
C: it 's not within reach and you use the within - reach , mechanism . so 'll 'll dig you up this reference . and so this doe this is , first of all , it explains something that 've always wondered about and 'll do this test on you guys as . how - have had an experience , not often , but certain number of times , when , , 'm working with tool , screwdriver , for long time , start feeling the tip directly . but you actually can feel the tip . and people who are accomplished violinists and like that , claim they also have this thing where you get direct sensation of , physical sensation , of the end affector .
B: what 's going on at the end of the tool ,
A: the ext the the extension ,
B: what 's going on at the end of the tool , or whatever .
A: the extension of your hand , right .
C: have you hav had this ?
A: it 's not exactly the th same thing , but it it 's getting close to that .
F: what does it feel like ?
C: it feels like your as if your neurons had extended themselves out to this tool , and you 're feeling forces on it and and you deal directly with it .
A: once was playing with those devices thow you to manipulate objects when it 's dangerous to get close ? so you can insert your hand something and there 's correspondence between so played with it . after while , you don't feel the difference anymore . very you stop back and suddenly it goes away and you have to work again to recapture it , but .
C: so anyway , so so this was the first actual experimental evidence 'd seen that was consistent with this anecdotal . and it makes lovely def story about why languages , make this distinction . there are behavioral differences too . things you can reach are really quite different than things you can't . but there seems to be an actu really deep embodied neural difference . and this is , so . in addition to the
E: this is more proximal - distal .
C: so in addition to ego and allocentric which appear all over the place , you also have this proximal - distal thing which is very deeply embedded .
E: he does the th the cognitive map world , down in santa barbara . and he always talks about these probably most likely without knowing this evidence is talking about these small scale spaces that you can manipulate versus large scale environmental spaces .
C: there 's there 's been lot of behavioral things on this , but that was the first neur neuro - physiological thing saw . anyway , so we 'll we 'll look at this . and . so , all of these issues now are now starting to come up . so , now we 're now done with demos . we 're starting to do science , and so these issues about , reference , and spatial reference , discourse reference , - - all this , , deixis which is part of what you were talking about , so , all of this is coming up essentially starting now . so we gotta do all this . so there 's that . and then there 's also set of system things that come up . so "" , we 're not using their system . that means we need our system . "" it it follows . and so , , in addition to the business about just getting the linguistics right , and the formalism and , we 're actually gonna build something and , johno is point person on the parser , analyzer , whatever that is , and we 're gonna start on that in parallel with the , the grammar . but to do that we 're gonna need to make some decisions like ontology , so , and so this is another thing where we 're gonna , , have to get involved and make relatively early , make some decisions on , "" is there an ontology api that "" there 's standard way of getting things from ontologies and we build the parser and around that , or is there particular ontology that we 're gonna standardize on , and if so , is there something that we can use there . does either the smartkom project or one of the projects at eml have something that we can just pull out , for that . so there are gonna be some some things like that , which are not science but system . but we aren't gonna ignore those cuz we 're we 're not only going the plan is not only to lay out this thing , but to actually build some of it . and how much we build , and . part of it , if it works right , is wh it looks like we 're now in position that the construction analyzer that we want for this applied project can be the same as the construction analyzer that nancy needs for the child language modeling . so . it 's always been out of phase but it now seems that , there 's good shot at that . so we 've talked about it , and the hope is that we can make these things the same thing , and it 's only in both cases it 's only one piece of bigger system . but it would be if that piece were exactly the same piece . it was just this construction analyzer . and so we think we think we have shot at that . so . the for to to come full circle on that , this formalization task , is trying to get the formalism into shape where it can actually
B: be of use to someone who 's trying to do this ,
C: where it actually is covers the whole range of things . and the the thing that got mark into the worst trouble is he had very ambitious thing he was trying to do , and he insisted on trying to do it with limited set of mechanisms . it turned out , inherently not to cover the space . and it just it was just terribly frustrating for him , and he seemed fully committed to both sides of this irreconcilable thing . johno is much more pragmatic .
B: good to know .
C: is this is true , is it not ? so there 's , , deep , really deep , emotional commitment to certain theory being , complete .
F: you don't have hidden purist streak ?
C: we - it hasn't it certainly hasn't been observed , in any case . now , you do , but that 's . so . for for
B: cuz don't have to implement anything .
F: have problem , then . it 's so . whether do depends on whether 'm talking to him or him probably .
C: why actually , , , you do but , th the thing you have to im implement is so small that .
F: which meeting 'm in . it 's to be purist within that context .
C: and , it 's and still , , , get something done . but to try to do something upscale and purist particularly if what you 're purist about doesn't actually work , is real hard . and then the other thing is while we 're doing this robert 's gonna pick piece of this space ,
A: it 's possible .
C: for his absentee thesis . you all know that you can just , in germany almost just send in your thesis .
B: just drive up . ca - chuk ! there you go .
E: the - th there there 's drive - in thesis sh joint over in saarbruecken .
B: drive through , .
C: it costs lot . the the amount you put in your credit card and as . so , , that 's , also gotta be worked out , hopefully over the next few weeks , so that it becomes clear , what piece , robert wants to jump into . and , while we 're at this level , , there 's at least one new doctoral student in computer science who will be joining the project , either next week or the first of august , depending on the blandishments of microsoft . so , de . and her name is eva . it really is . nobody believed th that
F: it had to be joke , of your part , like "" johno made it up ,
G: is this person someone who 's in first - year this year ,
C: no , first year coming . so , she 's she 's now out here she 's moved , and she 'll be student as of then . and probably she 'll pick up from you on the belief - net , so sh she 'll be chasing you down and like that . against all traditions . and actually talked today to undergraduate who wants to do an honors thesis on this .
F: someone from the class ? we always get these people who are not in the class , who
C: some of th some of them , .
F: it 's interesting .
C: but she 's another one of these ones with three point nine average and and so on . so , , 've give 've given her some things to read . so we 'll see how this goes . there 's yet another one of the incoming first incoming first - year graduate students who 's expressed interest , so we 'll see how that goes . so , as far as this group goes , , it 's certainly worth continuing for the next few weeks to get closure on the belief - net and the ideas that are involved in that , and what are th what are the concepts . we 'll see whether it 's gonna make sense to have this be separate from the other bigger effort with the formalization or not , it partly depends on what your thesis turns out to be and how that goes . so , we 'll see . and then , ami , you can decide , , how much time you wanna put into it and , it 's beginning to take shap shape , you will find that if you want to look technically at some of the your traditional questions in this light , keith , who 's buil building constructions , will be quite happy to see what , , you envision as the issues and the problems and , how they might get reflected in constructions . suspect that 's right .
A: may have to go to switzerland for in june or beginning of july for between two weeks and four weeks , but , after that or before that .
C: and , , if it 's useful we can probably arrange for you to drop by and visit either at heidelberg or at the german ai center , while you 're in the neighborhood .
A: actu actually 'm invited to do some consulting with bank in geneva which has an affiliation with research institute in geneva , which forgot the name of .
C: we 're connected to there 's there 's very significant connection between we 'll we 'll go through this , icsi and epfl , which is the , it 's the fr ge - germany 's got two big technical institutes . there 's one in zurich , and then there 's one , the french speaking one , in lausanne ,
B: so in switzerland .
C: so find out who they are associated with in geneva . probably we 're connected to them .
A: 'll send you email .
C: and so anyway we we can undoubtedly get ami to give talk at eml like that . while he 's in
E: the one you gave here couple of weeks ago would be of interest there , too .
C: lot of interest . actually , either place , dfki or so , and if there is book , that you 'll be building up some audience for it . and you 'll get feedback from these guys . cuz they 've actually these dfki guys have done as much as anyone over the last decade in trying to build them . so we 'll set that up . so , , unless we wanna start digging into the the belief - net and the decisions now , which would be fine , it 's probably
E: it 's probably better if come next week with the version point nine of the structure .
C: so , how about if you two guys between now and next week come up with something that is partially proposal , and partially questions , saying "" here 's what we think we understand , here are the things we think we don't understand "" . and that we as group will try to finish it . what 'd like to do is shoot for finishing all this next monday . "" these are the decisions "" don't think we 're gonna get lots more information . it 's design problem . and let 's come up with first cut at what this should look like . and then finish it up . does that so make sense ?
E: and , the sem semester will be over next week but then you have projects for one more week to come ?
G: no , 'll be done everything by this by the end of this week .
E: same with you ?
D: this , 've have projects , but then the my prof professor of one of my classes also wa has final that he 's giving us . and he 's giving us five days to do it which means it going to be hard .
C: is it take - home final ? who 's doing this ?
D: aikin , alex , .
C: that would have been my . but anyway , .
D: so , the seventeenth will definitely be the last day , like it or not for me .
C: so let 's do this , and then we there 's gonna be some separate co these guys are talking , we have group on the formalization , nancy and johno and are gonna talk about parsers . so there 're various kinds of nothing gets done even in meeting of seven people , so , , two or three people is the size in which actual work gets done . so we 'll do that . the other thing we wanna do is catch up with , ellen and see what she 's doing because the image schemas are going to be , an important pa
B: quite relevant , .
C: we we want those , and we want them formalized and like that . so let me let me make note to do that .
B: 'm actually probably going to be in contact with her pretty soon anyway because of various of us students were going to have reading group about precisely that thing over the summer ,
C: that 's great ! shweta mentioned that , although she said it 's secret . th - the faculty aren't faculty aren't supposed to know .
D: wednesday 's much better for me , .
C: 'm sufficiently clueless that count as
B: it 's as if we didn't tell anyone ,
","The translation of SmartKom to english is in its final stages.
The synthesis module will be the last one to do , after the english syntax trees are completed.
The system is still buggy and unstable , but it will soon be ready for a demonstration.
This is the first of two working demos required for the project.
Further than that , there are no restrictions on the focus of the research or its possible applications.
For example , issues like spatial descriptions could be investigated.
The variety of linguistic conventions seem to develop around an ego/allo-centric and a proximal/distal paradigm.
The latter is also reflected in neuro-physiological data.
From an engineering perspective , the belief-net for the AVE task should be completed within a few weeks.
The majority of the nodes are already there.
This leaves the dependencies between them and the rules of computation to be set.
Since the whole system is going to be re-designed , there are major decisions to be taken regarding the parser and the ontology , as well as what can be re-used from past EML projects.
In parallel , another team is working on formalisation and notation.
Finally , more ideas are expected to come from students and their research.
The final english SmartKom demo will be presented to the whole institute once the system is de-bugged and stabilised.
After the demo , the focus of research can switch towards purely scientific goals , including issues on ontology , deep semantic constructions , execution engines etc.
Moreover , a new system will be designed for the project and at least some parts of it should be built.
Similarly , the construction analyser should be a single , general tool working for both the tourist domain and child language modelling.
The focus for the next meeting will be on the belief-net , of which a working demo should be complete in the next few weeks.
Since there are not enough data , its connections and weights will have to be designed.
Although JavaBayes has been the tool of choice until now , the possibility that Hugin could be a better option should be investigated.
In order to promote the collaboration with EML , the group-ware server there will be updated with all progress being made in the two sites.
A talk on some of the issues will also be organised to take place at DFKI.
The german SmartKom version available on the server does not work.
The english version , although still under development , does work , however , the system is still unstable as -apart from other reasons- it was initially built to work with a touch screen.
De-bugging and cleaning up has to take place before any new modules are added on it.
As regards the belief-net , no connections and dependencies have been built into it.
These will have to be guessed instead of learnt through data , as not enough data is available for such a task.
Finally , it has been noted that the JavaBayes GUI does not satisfy all the presentation requirements for this belief-net and modifying the underlying code would be too time-consuming.
The german SmartKom system has been translated to English up to the speech synthesis level.
The german syntax trees are currently being adapted to English.
These also contribute information to the synthesis module in order to achieve better pronunciation.
The current english version is probably the best working one , since some of the problems with the original system have been corrected.
The design of the belief-net has also progressed significantly: the vast majority of the nodes have been identified and the feasibility of the task from a technical point of view has been confirmed.
"
ami_abstractive_summary,Bmr007.txt,"B: we 're , we we didn't have house before .
D: we 're on again ?
A: that is really great .
H: so if so if anyone hasn't signed the consent form , do so .
A: that 's terrific .
H: the new consent form . the new and improved consent form .
A: now you won't be able to walk or ride your bike , ?
H: and , shall go ahead and do some digits ?
D: we were gonna do that at the end ,
H: whatever you want .
D: just just to be consistent , from here on in at least , that we 'll do it at the end .
B: the new consent form .
H: it 's , it doesn't matter .
D: it ju it might be that someone here has to go ,
F: testing , one , two , three .
D: that was that was the point . so , had asked actually anybody who had any ideas for an agenda to send it to me and no one did .
H: so we all forgot .
F: from last time wanted to the an iss one topic from last time .
D: so one item for an agenda is jane has some some research to talk about , research issues . and , adam has some short research issues .
H: and have some short research issues .
D: have list of things that were done over the last three months was supposed to send off , and , sent note about it to to adam and jane but 'll just run through it also and see if someone thinks it 's inaccurate or insufficient .
A: list that you have to send off to who ?
D: to , ibm . so , so , 'll go through that . and , anything else ? anyone wants to talk about ?
A: what about the , your trip , yesterday ?
D: off - topic . cuz that 's cuz that was all about the , chat with you about that off - line . that 's another thing . and , anything else ? there 's , there is , telephone call tomorrow , which will be conference call that some of us are involved in for possible proposal . we 'll talk we 'll talk about it next week if something
H: do you want me to be there for that ? noticed you ' ed me , but wasn't actually recipient . didn't quite to make of that .
D: we 'll talk about that after our meeting . so it sounds like the three main things that we have to talk about are , this list , jane and jane and adam have some research items , and , other than that , anything , as usual , anything goes beyond that . , jane , since you were cut off last time why don't we start with yours , make we get to it .
F: it 's it 's very it 's very brief , just let me just hand these out .
H: is this the same as the email or different ?
F: it 's slightly different . but , same idea . so , if you 've looked at this you 've seen it before , so , as , part of the encoding includes mark that indicates an overlap . it 's not indicated with , , tight precision , it 's just indicated that , so , it 's indicated to so the people parts of sp which stretches of speech were in the clear , versus being overlapped by others . so , used this mark and , and , , divided the wrote script which divides things into individual minutes , of which we ended up with forty five , and little bit . and , , minute zero , , is the first minute up to sixty seconds . and , what you can see is the number of overlaps and then to the right , whether they involve two speakers , three speakers , or more than three speakers . and , and , what was looking for sp specifically was the question of whether they 're distributed evenly throughout or whether they 're bursts of them . and it looked to me as though this is just , this would this is not statistically verified , but it did look to me as though there are bursts throughout , rather than being localized to particular region . the part down there , where there 's the maximum number of , overlaps is an area where we were discussing whether or not it would be useful to indi to to code stress , , sentence stress as possible indication of , information retrieval . so it 's like , , rather , lively discussion there .
D: what was what 's the parenthesized that says , like the first one that says six overlaps and then two point eight ?
F: th that 's the per cent . so , six is , two point eight percent of the total number of overlaps in the session . at the very end , this is when people were , , packing up to go , there 's this final , we don't remember where the digits fell . 'd have to look at that . but the final three there are no overlaps . and couple times there are not . so , it seems like it goes through bursts but , that 's it . now , another question is there are there individual differences in whether you 're likely to be overlapped with or to overlap with others . and , again want to emphasize this is just one particular one particular meeting , and also there 's been no statistical testing of it all , but , took the coding of the , my had this script figure out , who was the first speaker , who was the second speaker involved in two - person overlap , didn't look at the ones involving three or more . and , this is how it breaks down in the individual cells of who tended to be overlapping most often with who else , and if you look at the marginal totals , which is the ones on the right side and across the bottom , you get the totals for an individual . so , if you look at the bottom , those are the , numbers of overlaps in which adam was involved as the person doing the overlapping and if you look 'm , but you 're alphabetical , that 's why 'm choosing you and then if you look across the right , then that 's where he was the person who was the sp first speaker in the pair and got overlap overlapped with by somebody . and , then if you look down in the summary table , then you see that , th they 're differences in whether person got overlapped with or overlapped by .
H: is this just raw counts or is it so it would be interesting to see how much each person spoke .
F: yes , very true very true
H: normalized to how much
F: it would be good to normalize with respect to that . now on the table did take one step toward , away from the raw frequencies by putting , percentages . so that the percentage of time of the times that person spoke , what percentage , so . of the times person spoke and furthermore was involved in two - person overlap , what percentage of the time were they the overlapper and what percent of the time were they th the overlappee ? and there , it looks like you see some differences , that some people tend to be overlapped with more often than they 're overlapped , but , , this is just one meeting , there 's no statistical testing involved , and that would be required for for finding of any scientific reliability .
D: so , it would be statistically incorrect to conclude from this that adam talked too much .
H: no no actually , that would be actually statistically correct ,
F: no , no . that 's right . that 's right . and 'm , 'm don't see point of singling people out ,
D: rather enjoyed it , but this
F: now , this is case where
A: but the numbers speak for themselves .
E: he 's , .
F: , it 's like 'm not saying on the tape who did better or worse
H: yes , that 's right , so you don't nee .
F: because don't think that it 's and th here 's case where , human subjects people would say be that you anonymize the results , and , so , might as do this .
H: when this is what this is actually when jane sent this email first , is what caused me to start thinking about anonymizing the data .
F: and actually , , not about an individual , it 's the point about tendencies toward , different styles , different speaker styles . and it would be , , there 's also the question of what type of overlap was this , and what were they , and and and know that distinguish at least three types and , probably more , the general cultural idea which , the conversation analysts originally started with in the seventies was that we have this strict model where politeness involves that you let the person finish th before you start talking , and , , we know that an and they 've loosened up on that too in the intervening time , that that 's that 's viewed as being culturally - relative thing , that you have the high - involvement style from the east coast where people will overlap often as an indication of interest in what the other person is saying . there you go . fine , that 's alright , that 's . and and , , in contrast , so deborah and also deborah tannen 's thesis she talked about differences of these types , that they 're just different styles , and it 's you can't impose model of there of the ideal being no overlaps , and , conversational analysts also agree with that , so it 's now , universally ag with . and and , als 't say universally , but anyway , the people who used to say it was strict , now , don't . they also , , ack acknowledge the influence of sub of subcultural norms and cross - cultural norms and things . so , then it beco though so just superficially to give couple ideas of the types of overlaps involved , have at the bottom several that noticed . so , , there are backchannels , like what adam just did now and , , anticipating the end of question and simply answering it earlier , and there are several of those in this in these data where because we 're people who 've talked to each other , we the topic is , what the possibilities are and and we 've spoken with each other so we the other person 's style is likely to be and so and there are number of places where someone just answered early . and places also which were interesting , where two or more people gave exactly th the same answer in unison different words but , the , everyone 's saying "" yes "" or , or ev even more sp specific than that . so , , that , overlap 's not necessarily bad thing and that it would be im useful to subdivide these further and see if there are individual differences in styles with respect to the types involved . and that 's all wanted to say on that , unless people have questions .
D: th the biggest , result here , which is one we 've we 've talked about many times and isn't new to us , but which would be interesting to show someone who isn't familiar with this is just the sheer number of overlaps . that that right ? that ,
E: yes , yes !
D: here 's relatively short meeting , it 's forty plus minute meeting , and not only were there two hundred and fifteen overlaps but , there 's one minute there where there where there wasn't any overlap ?
H: hundred ninety - seven .
D: it 's throughout this thing ?
A: it 'd be interesting
D: it 's you have
F: at the bottom , you have the bottom three . so four minutes all together with none .
D: so the bottom three did have going on ? there was speech ?
F: yes , - . but just no overlaps .
D: so if the this
A: it 'd be interesting to see what the total amount of time is in the overlaps , versus
F: yes , exactly and that 's that 's where jose 's pro project comes in .
E: , have this that infor have th that information now .
G: was about to ask
D: about how much is it ?
E: the the duration of of each of the overlaps .
D: what 's what 's the average length ?
E: haven't averaged it now but , will , will do the study of the with the with the program with the , the different , the , nnn , distribution of the duration of the overlaps .
D: you don you don't have feeling for roughly how much it is ?
E: mmm , because the , @ @ is @ @ . the duration is , the variation of the duration is , very big on the dat
F: suspect that it will also differ , depending on the type of overlap involved . so backchannels will be very brief
E: because , on your surface bit of zone of overlapping with the duration , overlapped and another very short . probably it 's very difficult to because the overlap is , on is only the in the final "" "" of the of the fin the end the end word of the , previous speaker with the next word of the new speaker . considered that 's an overlap but it 's very short , it 's an "" "" with and the idea is probably , when , we studied th that zone , , we we have confusion with noise . with that fricative sounds , but have new information but have to study .
G: you split this by minute , so if an overlap straddles the boundary between two minutes , that counts towards both of those minutes .
F: actually , actually not . so le let 's think about the case where starts speaking and then overlaps with , and then the minute boundary happens . and let 's say that after that minute boundary , is still speaking , and overlaps with , that would be new overlap . but otherwise , let 's say comes to the conclusion of that turn without anyone overlapping with him or her , in which case there would be no overlap counted in that second minute .
G: no , but suppose they both talk simultaneously both portion of it is in minute one and another portion of minute two .
F: in that case , my the coding that was using since we haven't , incorporated adam 's , coding of overlap yets , the coding of "" yets "" is not word . since we haven't incorporated adam 's method of handling overl overlaps yet then that would have fallen through the cra cracks . it would be an underestimate of the number of overlaps because , wou wouldn't be able to pick it up from the way it was encoded so far . we just haven't done th the precise second to sec , second to second coding of when they occur .
D: 'm 'm confused now . so let me restate what andreas was saying and see . let 's say that in second fifty - seven of one minute , you start talking and start talking and we ignore each other and keep on talking for six seconds . so we go over so we were we were talking over one another , and it 's just in each case , it 's just one interval . so , we talked over the minute boundary . is this considered as one overlap in each of the minutes , the way you have done this .
F: no , it wouldn't . it would be considered as an overlap in the first one .
D: so that 's good , , in the sense that andreas meant the question ,
B: that 's that 's good , , cuz the overall rate is
F: they 're not double counted .
G: other - otherwise you 'd get double counts , here and there . and then it would be harder
F: should also say did simplifying , count in that if was speaking overlapped with and then came back again and overlapped with again , didn't count that as three - person overlap , counted that as two - person overlap , and it was being overlapped with by . because the idea was the first speaker had the floor and the second person started speaking and then the the first person reasserted the floor thing . these are simplifying assumptions , didn't happen very often , there may be like three overlaps affected that way in the whole thing .
H: want to go back and listen to minute forty - one . cuz find it interesting that there were large number of overlaps and they were all two - speaker . what what would have thought in is that when there were large number of overlaps , it was because everyone was talking at once , but not .
F: that 's interesting . that 's interesting .
H: that 's really neat .
F: there 's lot of backchannel , lot lot of
H: this is really interesting data .
B: what 's really interesting though , it is before saying "" yes , meetings have lot of overlaps "" is to actually find out how many more we have than two - party . cuz in two - party conversations , like switchboard , there 's an awful lot too if you just look at backchannels , if you consider those overlaps ? it 's also ver it 's huge . it 's just that people haven't been looking at that because they 've been doing single - channel processing for speech recognition . so , the question is , , how many more overlaps do you have of , say the two - person type , by adding more people . to meeting , and it may be lot more but it may it may not be .
D: but see , find it interesting even if it wasn't any more , because since we were dealing with this full duplex thing in switchboard where it was just all separated out we just everything was just , so that so the issue is in situation where th that 's
B: it 's not really "" "" . it depends what you 're doing . so if you were actually having , depends what you 're doing , if right now we 're do we have individual mikes on the people in this meeting . so the question is , "" are there really more overlaps happening than there would be in two - person party "" . and and there may be , but
D: let let let me rephrase what 'm saying cuz don't 'm getting it across . what what what shouldn't use words like "" "" because maybe that 's too too imprecise . but what is that , in switchboard , despite the many other problems that we have , one problem that we 're not considering is overlap . and what we 're doing now is , aside from the many other differences in the task , we are considering overlap and one of the reasons that we 're considering it , , one of them not all of them , one of them is that at least , 'm very interested in the scenario in which , both people talking are equally audible , and from single microphone . and so , in that case , it does get mixed in , and it 's pretty hard to jus to just ignore it , to just do processing on one and not on the other .
B: agree that it 's an issue here but it 's also an issue for switchboard and if you think of meetings being recorded over the telephone , which , , this whole point of studying meetings isn't just to have people in room but to also have meetings over different phone lines . maybe far field mike people wouldn't be interested in that but all the dialogue issues still apply , so if each of us was calling and having meeting that way you kn like conference call . and , just the question is , , in switchboard you would think that 's the simplest case of meeting of more than one person , and 'm wondering how much more overlap of the types that jane described happen with more people present . so it may be that having three people is very different from having two people or it may not be .
D: that 's an important question to ask . what 'm all 'm really saying is that don't think we were considering that in switchboard .
B: not you , me .
H: though it wasn't in the design .
D: were you were you were you measuring it ?
B: actually to tell you the truth , the reason why it 's hard to measure is because of so , from the point of view of studying dialogue , , which dan jurafsky and andreas and had some projects on , you want to know the sequence of turns . so what happens is if you 're talking and have backchannel in the middle of your turn , and then you keep going what it looks like in dialogue model is your turn and then my backchannel , even though my backchannel occurred completely inside your turn . so , for things like language modeling or dialogue modeling it 's we know that 's wrong in real time . but , because of the acoustic segmentations that were done and the fact that some of the acoustic data in switchboard were missing , people couldn't study it , but that doesn't mean in the real world that people don't talk that way . so , it 's
D: wasn't saying that . was just saying that now we 're looking at it . and and , you maybe wanted to look at it before but , for these various technical reasons in terms of how the data was you weren't .
B: we 're looking at it here .
D: so that 's why it 's coming to us as new even though it may be , if your if your hypothes the hypothesis you were offering right ? if it 's the null poth hypothesis , and if actually you have as much overlap in two - person , we the answer to that . the reason we the answer to is cuz it wasn't studied and it wasn't studied because it wasn't set up . right ?
B: all is that if you 're asking the question from the point of view of what 's different about meeting , studying meetings of , say , more than two people versus what kinds of questions you could ask with two - person meeting . it 's important to distinguish that , , this project is getting lot of overlap but other projects were too , but we just couldn't study them .
D: may have been . may have been .
B: there is high rate ,
D: we do kn we the numbers .
B: it 's but how high ,
A: here have question .
B: that would be interesting to know .
D: see , , le let me my point was just if you wanted to say to somebody , "" what have we learned about overlaps here ? "" just never mind comparison with something else , what we 've learned about is overlaps in this situation , is that the first the first - order thing would say is that there 's lot of them . in in the sense that if you said if
B: don't di agree with that .
D: in way , what 'm comparing to is more the common sense notion of how much people overlap . the fact that when when , , adam was looking for stretch of speech before , that didn't have any overlaps , and he he was having such hard time and now look at this and go , "" , see why he was having such hard time "" .
B: that 's also true of switchboard .
D: it 's happening lot .
B: it may not be
D: wasn't saying it wasn't .
B: so it 's just ,
D: was commenting about this .
B: all 'm saying is that from the
D: 'm saying if have this complicated thing in front of me , and we sh which , we 're gonna get much more sophisticated about when we get lots more data , but then , if was gonna describe to somebody what did you learn right here , about , , the modest amount of data that was analyzed 'd say , "" , the first - order thing was there was lot of overlaps "" . and it 's not just an overlap bunch of overlaps second - order thing is it 's not just bunch of overlaps in one particular point , but that there 's overlaps , throughout the thing .
B: no , agree with that .
D: and that 's interesting . that 's all .
B: 'm just saying that it may the reason you get overlaps may or may not be due to the number of people in the meeting . and that 's all .
D: wasn't making any statement about that .
B: and and it would actually be interesting to find out because some of the data say switchboard , which isn't exactly the same context , these are two people who each other and , but we should still be able to somehow say what is the added contra contribution to overlap time of each additional person , like that .
D: that would be good to know ,
H: could certainly see it going either way .
F: wh - , agree agree with adam . and the reason is because there 's limit there 's an upper bound on how many you can have , simply from the standpoint of audibility . when we speak we do make judgment of "" can "" , as adults . children don't adjust so , if truck goes rolling past , adults will , depending , but mostly , adults will will hold off to what to finish the end of the sentence till the till the noise is past . and we generally do monitor things like that , about whether we whether our utterance will be in the clear or not . and partly it 's related to rhythmic structure in conversation , so , , you , this is also , people tend to time their their , when they come into the conversation based on the overall rhythmic , , ambient thing . so you don't want to be cross - cutting . and and , just to finish this , that that that there may be an upper bound on how many overlaps you can have , simply from the standpoint of audibility and how loud the other people are who are already in the fray . but , of certain types . now if it 's just backchannels , people may be doing that with less intention of being heard , just spontaneously doing backchannels , in which case that those might there may be no upper bound on those .
G: have feeling that backchannels , which are the vast majority of overlaps in switchboard , , don't play as big role here , because it 's very unnatural , to backchannel if in multi - audience , in multi - person audience .
B: if you can see them , actually . it 's interesting , so if you watch people are going like right right , like this here , but that may not be the case if you couldn't see them .
G: but but , it 's odd if one person 's speaking and everybody 's listening , and it 's unusual to have everybody going "" - , - ""
D: actually , 've done it fair number of times today .
B: there 's lot of head - nodding , in this
H: we need to put trackers on it .
A: in in the two - person
F: he could , he could .
G: so so actually , that 's in part because the nodding , if you have visual contact , the nodding has the same function , but on the phone , in switchboard you that wouldn't work . so so you need to use the backchannel .
H: you don't have it .
A: so , in the two - person conversations , when there 's backchannel , is there great deal of overlap in the speech ?
H: that is an earphone , so if you just put it so it 's on your ear .
A: cuz my impression is sometimes it happens when there 's pause ,
H: there you go .
A: like you get lot of backchannel , when somebody 's pausing
F: she 's doing that .
B: what were you saying ?
A: it 's hard to do both , no , when when there 's backchannel , , just was just listening , and when there 's two people talking and there 's backchannel it seems like , the backchannel happens when , , the pitch drops and the first person and lot of times , the first person actually stops talking and then there 's backchannel and then they start up again , and so 'm wondering about wonder how much overlap there is . is there lot ?
B: there 's lot of the kind that jose was talking about , where , this is called "" precision timing "" in conversation analysis , where they come in overlapping , but at point where the information is mostly complete . so all you 're missing is some last syllables or the last word or some highly predictable words . so technically , it 's an overlap .
A: but maybe just small overlap ?
B: but , from information flow point of view it 's not an overlap in the predictable information .
H: it 'd be interesting if we could do prediction .
A: was just thinking more in terms of alignment , alignment overlap .
H: language model prediction of overlap , that would be really interesting .
B: that 's exactly , exactly why we wanted to study the precise timing of overlaps ins in switchboard , say , because there 's lot of that .
G: so so here 's here 's first interesting labeling task . to distinguish between , say , backchannels precision timing , benevolent overlaps , and and and , , hostile overlaps , where someone is trying to grab the floor from someone else .
H: let 's pick different word .
G: that might be an interesting , problem to look at .
F: you could do that . ju that in this meeting really had the feeling that wasn't happening , that the hostile type . these were these were benevolent types , as people finishing each other 's sentences , and .
G: could imagine that as there 's fair number of cases where , and this is , not really hostile , but competitive , where one person is finishing something and you have , like , two or three people jumping trying to trying to , grab the next turn .
H: trying to get the floor .
G: and so it 's not against the person who talks first because actually we 're all waiting for that person to finish . but they all want to be next .
D: have feeling most of these things are that are not benevolent kind are are , are competitive as opposed to real really hostile .
A: wonder what determines who gets the floor ?
F: there are various things , you have the
D: vote in florida .
H: it 's been studied lot .
D: one thing wanted to or you can tell good joke and then everybody 's laughing and you get chance to break in . the other thing was thinking was that , these all these interesting questions are , , pretty hard to answer with , , small amount of data . so , wonder if what you 're saying suggests that we should make conscious attempt to have , fair number of meetings with , smaller number of people . we most of our meetings are , meetings currently with say five , six , seven , eight people should we really try to have some two - person meetings , or some three - person meetings and re record them just to to beef up the statistics on that ?
F: that 's control . it seems like there are two possibilities there , it seems like if you have just two people it 's not really , like meeting , is not as similar as the rest of the of the sample . it depends on what you 're after , , but it seems like that would be more case of the control condition , compared to , an experimental condition , with more than two .
D: liz was raising the question of whether it 's the number there 's relationship between the number of people and the number of overlaps or type of overlaps there , and , if you had two people meeting in this circumstance then you 'd still have the visuals . you wouldn't have that difference also that you have in the say , in switchboard data .
F: 'm just thinking that 'd be more like control condition .
H: but from the acoustic point of view , it 's all good .
E: is the same .
D: acoustic is fine ,
G: if if the goal were to just look at overlap you would you could serve yourself save yourself lot of time but not even transcri transcribe the words .
B: was thinking you should be able to do this from the acoustics , on the close - talking mikes ,
H: that 's the that was my status report ,
F: you 've been working on that .
B: right , adam was
H: so once we 're done with this discussing ,
B: not as as what , you wouldn't be able to have any typology , , but you 'd get some rough statistics .
D: but what do you think about that ? do you think that would be useful ? 'm just thinking that as an action item of whether we should try to record some two - person meetings .
B: my first comment was , only that we should not attribute overlaps only to meetings , but maybe that 's obvious , maybe everybody knew that , but that in normal conversation with two people there 's an awful lot of the same kinds of overlap , and that it would be interesting to look at whether there are these kinds of constraints that jane mentioned , that what maybe the additional people add to this competition that happens right after turn , because now you can have five people trying to grab the turn , but pretty quickly there 're they back off and you go back to this only one person at time with one person interrupting at time . to answer your question it don't 's crucial to have controls but it 's worth recording all the meetings we can .
G: have an idea .
B: wouldn't not record two - person meeting just because it only has two people .
G: could we could we , we have in the past and continue will continue to have fair number of phone conference calls . and , , and as to , as another comparison condition , we could see what happens in terms of overlap , when you don't have visual contact .
H: we talked about this repeatedly .
B: can we actually record ?
H: it just seems like that 's very different thing than what we 're doing .
D: we 'll have to set up for it .
B: physically can we record the the other
D: we 're not really set up for it to do that .
G: or , this is getting little extravagant , we could put up some blinds to remove , visual contact .
B: that 's what they did on map task , , this map task corpus ? they ran exactly the same pairs of people with and without visual cues and it 's quite interesting .
D: we record this meeting so regularly it wouldn't be that little strange .
H: we can record , but no one can look at each other .
B: we could just put blindfolds on .
H: close your eyes . turn off the lights .
B: and we 'd take picture of everybody sitting here with blindfolds .
D: th that was the other thing , weren't we gonna take picture at the beginning of each of these meetings ?
H: what had thought we were gonna do is just take pictures of the whiteboards . rather than take pictures of the meeting .
F: linguistic anthropologists would suggest it would be useful to also take picture of the meeting .
D: there 's head nodding here vigorously , .
A: why why do we want to have picture of the meeting ?
B: ee - you mean , transc no
F: the because you get then the spatial relationship of the speakers . and that could be
G: you could do that by just noting on the enrollment sheet the seat number .
H: seat number , that 's good idea . 'll do that . 'll do that on the next set of forms .
G: so you 'd number them somehow .
E: is possible to get information from the rhythmic from the ge , , files .
H: finally remembered to put , put native language on the newer forms .
A: we can't you figure it out from the mike number ?
H: the wireless ones . and even the jacks , , 'm sitting here and the jack is over in front of you .
B: but probably from these you could 've infer it .
G: but it 's it would be trivial
H: it would be another task .
B: it would be research task .
H: having having ground tu truth would be , so seat number would be good .
A: where you could get it ? beam - forming during the digit .
H: so 'm gonna put little labels on all the chairs with the seat number . that 's good idea .
B: but you have to keep the chairs in the same pla like here .
G: not the chairs . the chairs are chairs are movable . put them like , put them on the table where they
F: but , they the the linguistic anthropologists would say it would be good to have digital picture anyway ,
A: just remembered joke .
F: because you get sense also of posture . posture , and we could like , , block out the person 's face or whatever
G: what people were wearing .
B: the fashion statement .
F: but , , these are important cues ,
A: how big their heads are .
F: the how person is sitting is
D: but if you just but from one picture , that you really get that .
G: andreas was wearing that same old sweater again .
D: you 'd want video for that , .
F: it 'd be better than nothing , is from single picture you can tell some aspects . could tell you , if if 'm in certain meetings notice that there are certain people who really do the body language is very is very interesting in terms of the dominance aspect .
G: and and morgan had that funny hair again .
F: , you black out the that part . but it 's just , , the body
H: the where we sit at the table , find is very interesting , that we do tend to cong to gravitate to the same place each time . and it 's somewhat coincidental . 'm sitting here so that run into the room if the hardware starts , , catching fire .
G: no , you just like to be in charge , that 's why you 're sitting
H: want to be at the head of the table .
D: speaking of taking control , you said you had some research to talk about .
H: 've been playing with , , using the close - talking mike to do to try to figure out who 's speaking . so my first attempt was just using thresholding and filtering , that we talked about two weeks ago , and so played with that little bit , and it works , except that it 's very sensitive to your choice of your filter width and your threshold . so if you fiddle around with it little bit and you get good numbers you can actually do pretty good job of segmenting when someone 's talking and when they 're not . but if you try to use the same paramenters on another speaker , it doesn't work anymore , even if you normalize it based on the absolute loudness .
B: but does it work for that one speaker throughout the whole meeting ?
H: it does work for the one speaker throughout the whole meeting .
A: how did you do it adam ?
H: how did do it ? what do you mean ?
A: wh what was the
H: the algorithm was , take every frame that 's over the threshold , and then median - filter it , and then look for runs . so there was minimum run length ,
A: every frame that 's over what threshold ?
H: threshold that you pick .
A: in terms of energy ?
F: say that again ? frame over fres threshold .
H: so you take each frame , and you compute the energy and if it 's over the threshold you set it to one , and if it 's under the threshold you set it to zero , so now you have bit stream of zeros and ones . and then median - filtered that using , fairly long filter length . actually depends on what you mean by long , , tenth of second sorts of numbers . and that 's to average out , pitch , , the pitch contours , and things like that . and then , looked for long runs . and that works , if you fil if you tune the filter parameters , if you tune how long your median filter is and how high you 're looking for your thresholds .
A: did you ever try running the filter before you pick threshold ?
H: certainly could though . but this was just had the program mostly written already so it was easy to do . and then the other thing did , was took javier 's speaker - change detector acoustic - change detector , and implemented that with the close - talking mikes , and unfortunately that 's not working real , and it looks like it 's the problem is he does it in two passes , the first pass is to find candidate places to do break . and he does that using neural net doing broad phone classification and he has the , one of the phone classes is silence . and so the possible breaks are where silence starts and ends . and then he has second pass which is modeling gaussian mixture model . looking for whether it improves or degrades to split at one of those particular places . and what looks like it 's happening is that the even on the close - talking mike the broad phone class classifier 's doing really bad job .
A: who was it trained on ?
H: have no idea . does an do you remember , morgan , was it broadcast news ? so , at any rate , my next attempt , which 'm in the midst of and haven't quite finished yet was actually using the , thresholding as the way of generating the candidates . because one of the things that definitely happens is if you put the threshold low you get lots of breaks . all of which are definitely acoustic events . they 're definitely someone talking . but , like , it could be someone who isn't the person here , but the person over there or it can be the person breathing . and then feeding that into the acoustic change detector . and so that might work . but , haven't gotten very far on that . but all of this is close - talking mike , it 's , just trying to get some ground truth .
E: but , when , saw the the speech from pda and , close talker . the there is great difference in the in the signal . but that in the mixed file you can find , zone with , great different , level of energy .
H: so my intention for this is as an aide for ground truth .
E: for , algorithm based on energy , , that mmm , more or less , , like , mmm , first sound energy detector .
H: say it again ?
E: when you the detect the the first at the end of the detector of , ehm princ . what is the name in english ? the , mmm , the de detector of , ehm of word in the in the in an isolated word in the background that ,
H: 'm 'm not what you 're saying ,
E: that when you use , any
A: he 's saying the onset detector .
H: onset detector , .
E: it 's probably to work , because , you have , in the mixed files great level of energy . and great difference between the sp speaker . and probably is not so easy when you use the pda , that because the signal is , the in the energy level . in that , speech file is , more similar . between the different , speaker , is , it will is my opinion .
H: but different speakers .
E: it will be , more difficult to detect bass - tone energy .
H: in the clo in the , you mean ?
E: in the pda .
H: it 'll be much harder .
E: and the another question , that when review the the work of javier . the , nnn , the , nnn , that the idea of using neural network to get broad class of phonetic , from , candidate from the the speech signal . if you have , , 'm considering , only because javier , only consider , like candidate , the , nnn , the silence , because it is the only model , , he used that , nnn , to detect the possibility of change between the between the speaker , another research thing , different groups , working , on broadcast news prefer to , to consider hypothesis between each phoneme .
H: when phone changes .
E: because , it 's more realistic that , only consider the the silence between the speaker . there exists silence between , speaker . is , acoustic , event , important to consider . found that the , silence in many occasions in the in the speech file , but , when you have , , two speakers together without enough silence between them , is better to use the acoustic change detector and ix or , mmm , bic criterion for consider all the frames in my opinion .
D: the , the reason that he , just used silence was not because he thought it was better , it was it was the place he was starting . so , he was trying to get something going , and , , as as is in your case , if you 're here for only modest number of months you try to pick realistic goal , but his goal was always to proceed from there to then allow broad category change also .
E: but , do you think that if you consider all the frames to apply the , the bic criterion to detect the the different acoustic change , between speaker , without , with , silence or with overlapping , like , general , way of process the acoustic change . in first step , . an - and then , without considering the you you , you can consider the energy like another parameter in the in the feature vector , this this is the idea . and if , if you do that , , with bic criterion , or with another , of distance in first step , and then you , you get the , the hypothesis to the this change acoustic , to po process because , , probably you can find the small gap of silence between speaker with ga mmm , small duration less than , two hundred milliseconds and apply another algorithm , another approach like , detector of ene , detector of bass - tone energy to consider that , zone . of small silence between speaker , or another algorithm to process , the segment between marks founded by the the bic criterion and applied for each frame . is , nnn , it will be an more general approach the if we compare with use , neural net or another , speech recognizer with broad class or narrow class , because , in my opinion it 's in my opinion , if you if you change the condition of the speech , , if you adjust to your algorithm with mixed speech file and to , to , adapt the neural net , used by javier with mixed file . with mixed file ,
H: with the what file ?
A: "" mixed "" .
E: with the mix , mix .
F: "" mixed . ""
H: "" mixed ? ""
E: and and then you , you try to apply that , , , speech recognizer to that signal , to the pda , speech file , you will have problems , because the condition you will need suppose that you will need to to retrain it .
H: this is this is not what was suggesting to do .
D: look , this is one once it 's used to work , like , on voiced on voice silence detection , , and this is this thing . if you have somebody who has some experience with this thing , and they work on it for couple months , they can come up with something that gets most of the cases fairly easily . then you say , "" , don't just wanna get most of the cases want it to be really accurate . "" then it gets really hard no matter what you do . so , the the problem is that if you say , "" have these other data over here , that learn things from , either explicit training of neural nets or of gaussian mixture models or whatever . "" suppose you don't use any of those things . you say you have looked for acoustic change . what does that mean ? that that means you set some thresholds somewhere , and so where do you get your thresholds from ? from something that you looked at . so you always have this problem , you 're going to new data how are you going to adapt whatever you can very quickly learn about the new data ? , if it 's gonna be different from old data that you have ? and that 's problem with this .
H: also what 'm doing right now is not intended to be an acoustic change detector for far - field mikes . what 'm doing is trying to use the close - talking mike and just use can - and just generate candidate and just try to get first pass at something that works .
A: you have candidates . to make marking easier .
H: and haven't spent lot of time on it and 'm not intending to spend lot of time on it .
G: , unfortunately , have to run , but , imagine building model of speaker change detection that takes into account both the far - field and the actually , not just the close - talking mike for that speaker , but actually for all of th for all of the speakers . if you model the effect that me speaking has on your microphone and everybody else 's microphone , as as on that , and you build , you 'd you would build an that has as state space all of the possible speaker combinations and , you can control
H: it 's little big .
G: it 's not that big actually ,
H: two to the . two to the number of people in the meeting .
D: but actually , andreas may maybe just something simpler but along the lines of what you 're saying , was just realizing , used to know this guy who used to build , , mike mixers automatic mike mixers where , , in order to able to turn up the gain , , as much as you can , you you lower the gain on the mikes of people who aren't talking , and then he had some reasonable way of doing that , but , what if you were just looking at very simple measures like energy measures but you don't just compare it to some threshold overall but you compare it to the energy in the other microphones .
H: was thinking about doing that originally to find out who 's the loudest , and that person is certainly talking . but also wanted to find threshold , excuse me , mol overlap . so , not just the loudest .
E: have found that when analyzed the speech files from the , mike , from the close microphone , found zones with different level of energy .
G: have to go .
H: could you fill that out anyway ? just , put your name in . are you want me to do it ? 'll do it .
A: but he 's not gonna even read that .
E: including overlap zone . because , depend on the position of the of the microph of the each speaker to , , to get more or less energy in the mixed sign in the signal . and then , if you consider energy to detect overlapping in , , and you process the in the speech file from the the mixed signals . the mixed signals , . it 's it 's difficult , only to en with energy to consider that in that zone we have , overlapping zone , if you process only the energy of the , of each frame .
D: it 's probably harder , but what was nnn noting just when he when andreas raised that , was that there 's other information to be gained from looking of the microphones and you may not need to look at very sophisticated things , because if there 's if most of the overlaps , this doesn't cover , say , three , but if most of the overlaps , say , are two , if the distribution looks like there 's couple high ones and the rest of them are low ,
H: and everyone else is low , .
D: there 's some information there about their distribution even with very simple measures . , had an idea with while was watching chuck nodding at lot of these things , is that we can all wear little bells on our heads , so that then you 'd know that
H: ding , ding , ding .
F: "" ding "" . that 's cute !
B: that 'd be really interesting too , with blindfolds .
H: nodding with blindfolds ,
B: the question is , like whether
H: "" what are you nodding about ? ""
B: trying with and with and without , .
H: "" , 'm just 'm just going to sleep . ""
B: but then there 's just one @ @ , like .
A: actually , saw woman at the bus stop the other day who , , was talking on her cell phone speaking japanese , and was bowing .
B: , that 's really common . it 's very difficult if you try while you 're trying , say , to convince somebody on the phone it 's difficult not to move your hands . not , if you watch people they 'll actually do these things . still think we should try meeting or two with the blindfolds , at least of this meeting that we have lots of recordings of maybe for part of the meeting , we don't have to do it the whole meeting .
D: it 's great idea .
B: that could be fun . it 'll be too hard to make barriers , was thinking because they have to go all the way see chuck even if you put barrier here .
H: we could just turn out the lights .
F: actually also say made barr barriers for so that the was doing with collin wha which just used , this foam board . you can you can masking tape it together , these are , pretty large partitions .
B: but then we also have these mikes , is the other thing was thinking , so we need barrier that doesn't disturb the sound ,
F: it 's true , it would disturb the , the long - range
D: blindfolds would be good .
B: it sounds weird but it 's it 's cheap and , be interesting to have the camera going .
D: probably we should until after adam 's set up the mikes ,
F: we 're going to have to work on the , on the human subjects form .
A: 'll be peeking .
H: that 's right , we didn't tell them we would be blindfolding .
F: "" do you mind being blindfolded while you 're interviewed ? ""
D: that 's that 's the one that we videotape . wanna move this along . did have this other agenda item which is , @ @ it 's list which sent to couple folks , but wanted to get broader input on it , so this is the things that we did in the last three months not everything we did but highlights that tell some outside person , , what were you actually working on . in no particular order , one , , ten more hours of meeting meetings recorded , something like that , from , three months ago . xml formats and other transcription aspects sorted out and sent to ibm . pilot data put together and sent to ibm for transcription , next batch of recorded data put together on the cd - roms for shipment to ibm ,
H: hasn't been sent yet , but it 's getting ready .
D: but , that 's why phrased it that way , . human subjects approval on campus , and release forms worked out so the meeting participants have chance to request audio pixelization of selected parts of the spee their speech . audio pixelization software written and tested . preliminary analysis of overlaps in the pilot data we have transcribed , and exploratory analysis of long - distance inferences for topic coherence , that was was wasn't if those were the right way that was the right way to describe that because of that little exercise that you and lokendra did .
F: what was that called ?
D: 'm probably saying this wrong , but what said was exploratory analysis of long - distance inferences for topic coherence .
F: the , say again ?
D: something like that . so , lot of that was from , , what what you two were doing so sent it to you , and , mail me , , the corrections or suggestions for changing don't want to make this twice it 's length but , just im improve it . is there anything anybody
H: did bunch of for supporting of digits .
D: "" bunch of for "" maybe send me sentence that 's little thought through about that .
H: so , , 'll send you sentence that doesn't just say "" bunch of "" ?
D: "" bunch of "" , , "" "" is probably bad too ,
H: "" "" is not very technical . 'll try to phrase it in passive voice .
D: "" range of things "" , . and , threw in what you did with what jane did on in under the , preliminary analysis of overlaps . thilo , can you tell us about all the work you 've done on this project in the last , last three months ?
C: so what is what .
A: it 's too complicated .
C: didn't get it . wh - what is "" audio pixelization "" ?
D: audio pix wh he did it , so why don't you explain it quickly ?
H: it 's just , beeping out parts that you don't want included in the meeting so , you can say things like , "" , this should probably not be on the record , but beep ""
D: we we spent fair amount of time early on just talk dealing with this issue about op we realized , "" , people are speaking in an impromptu way and they might say something that would embarrass them or others later "" , and , how do you get around that so in the consent form it says , you we will look at the transcripts later and if there 's something that you 're unhappy with , .
C: and you can say
D: but you don't want to just excise it you have to be careful about excising it , how you excise it keeping the timing right and so that at the moment tho th the idea we 're running with is putting the beep over it .
H: you can either beep or it can be silence . couldn't decide . which was the right way to do it . beep is good auditorily , if someone is listening to it , there 's no mistake that it 's been beeped out , but for software it 's probably better for it to be silence .
A: no , no . you can , you could make as long as you keep using the same beep , people could make model of that beep ,
F: like that idea .
H: and use it 's , it 's an below middle beep ,
B: the beep is really good idea .
F: it 's very clear . then you don't 's long pause .
A: it 's more obvious that there was something there than if there 's just silence .
D: that , he 's he 's removing the old thing
A: yea - right . but if you just replaced it with silence , it 's not clear whether that 's really silence or
F: one one question . do you do it on all channels ?
H: you have to do it on all channels because it 's , audible . it 's it 's potentially audible , you could potentially recover it .
D: ke - keep back door .
F: the other thing that , the alternative might be to
H: haven't thrown away any of the meetings that beeped . actually yours is the only one that beeped and then , the ar darpa meeting .
B: notice how quiet am .
H: and then the darpa meeting excised completely , so it 's in private directory .
B: you have some people who only have beeps as their speech in these meetings .
F: that 's great .
A: they 're easy to find , then .
D: alright , so , we should , , go on to the digits ?
F: have one concept want to say , which is that it 's that you 're preserving the time relations , so you 're you 're not just cutting you 're not doing scissor snips . you 're you 're keeping the , the time duration of de - deleted part . good , digits .
H: since we wanna possibly synchronize these things as . should have done that .
F: it 's great .
B: so if there 's an overlap , like , if 'm saying something that 's bleepable and somebody else overlaps during it they also get bleeped , too ?
H: you 'll lose it . there 's no way around that .
D: did before we do the digits , did also wanna remind people , do send me , , thoughts for an agenda , that would be that 'd be good . so that , , people 's ideas don't get
H: thursday crept up on me this week .
D: it does creep up ,
B: and , wanted to say , this is really interesting analysis .
H: it 's , definitely .
B: to say that before started off on the switchboard .
H: was gonna say "" can you do that for the other meetings ,
B: it 's neat .
H: can you do it for them ? "" and , no actually , you can't .
A: actually actually that 's what you were giving us was another meeting and was like , "" , ! ""
H: "" ooo , ! ""
B: how long does it take , just briefly , like to . to label the ,
F: have the script now , so , , it can work off the , other thing ,
H: it 's as soon as we get labels , .
A: but it has to be hand - labeled first ?
F: because , , once his algorithm is up and running then we can do it that way .
H: if it works enough . right now it 's not . not quite to the point where it works .
F: but worked off of my
B: it 's really neat .
F: what what this has , , caused me so this discussion caused me to wanna subdivide these further . 'm gonna take look at the , backchannels , how much we have anal hope to have that for next time .
A: that 'd be interesting .
H: my algorithm worked great actually on these , but when you wear it like that or with the , lapel or if you have it very far from your face , that 's when it starts failing .
B: wear it , if you
H: it doesn't matter . we want it to work ,
A: it 's too late now .
H: don't want to change the way we do the meeting .
B: feel like this troublemaker .
H: it 's so , it was just comment on the software , not comment on prescriptions on how you wear microphones .
D: that 's let 's let 's do digits .
H: get the bolts , "" whh ""
F: let 's do it . do you want us to put mark on the bottom of these when they 've actually been read , or the only one that wasn't read is is known , so we don't do it .
","The Berkeley Meeting Recorder group focussed its discussion on overlapping speech segments.
Speaker fe008 presented raw counts and percentages for one transcribed meeting , revealing a large number of overlaps throughout the 40-plus-minute transcript.
Efforts by speakers fe008 and fe016 are in progress to categorize and subcategorize types of overlapping speech and evaluate the contribution of multiple speakers in an interaction to the amount and types of overlap observed.
Speaker me011 described his attempts to automatically identify speakers via the close-talking microphone channels using thresholding and filtering methods and an existing speaker-change detection algorithm.
The group also tentatively discussed the erection of visual barriers during meeting recordings , and speaker me013 presented a list of work performed by BMR over the previous three months to be included in a forthcoming report to IBM.
For future meetings , speaker me011 will generate a system for mapping speakers and their positions in the recording room.
Speaker fe008 will analyze backchannels for a subset of meeting data and givee a report in the next meeting.
For language and dialogue modelling , current methods of marking and segmenting overlap are abstracted from real time , as individual speaker turns are indicated sequentially.
A large amount of data must be collected to address research questions concerning overlapping speech.
For automatic speaker identification , thresholding and filtering methods are sensitive regarding the particular filter width and threshold selected.
While such parameters can be finely tuned for one speaker to achieve good results , extending the same parameters to another speaker is problematic.
The broad phone classifier of the speaker-change detector is peforming poorly.
The prospect of erecting visual barriers during meetings would require partitioning off each of the participants.
Also , barriers that do not affect the overall room acoustics would be required.
Efforts are in progress to mark where regions of speaker overlap occur in meeting transcripts and note the number of speakers involved.
Such information is currently being encoded within relatively loose time boundaries.
A large number of overlapping speech regions were identified throughout one recorded meeting , wherein overlaps were found to occur in bursts , rather than being evenly distributed throughout the meeting.
A cursory analysis was done on regions of overlap involving two speakers to determine whether speakers are more likely to be overlapped with or to cause overlap with other speakers.
Attempts were also made to classify types of speaker overlap---e.g . backchannels , answering questions as they are being asked , and responding in unison---with future work focussed on subcategorizing types of backchannels.
Speaker fe016 is interested in the contribution of multiple speakers in an interaction to the amount and types of overlap observed , and comparing this to findings from the Switchboard corpus.
Future work includes generating predictive models of overlap , and the tentative erection of visual barriers during meeting recordings.
Speaker me011 described his attempts to automatically identify speakers via the close-talking microphone channels using thresholding and filtering methods and an existing speaker-change detection algorithm.
"
ami_abstractive_summary,Bed008.txt,"A: alright , so 'm - should read all of these numbers ?
E: piece of paper ? could borrow ?
B: whether ami 's coming or not but we oughta just get started .
E: nancy is currently in berkeley but not here ?
C: nancy 's still stick ?
B: so there you go . anyway , so my idea for today and we can decide that isn't the right thing to do was to at spend at least part of the time trying to build the influence links , which sets of things are relevant to which decisions and actually had specific suggestion to start first with the path ones . the database ones being in some sense less interesting to us although probably have to be done and so to do that so there 's and the idea was we were gonna do two things
C: is your mike on ?
B: we were gonna do two things one of which is just lay out the influence structure of what we nfluences what
D: that 's funny .
B: and then as separate but related task particularly bhaskara and were going to try to decide what kinds of belief nodes are needed in order to do what we what we need to do . so but du we should have all of the basic design of what influences what done before we decide exactly how to compute it . so didn't did you get chance to look yet ?
D: looked at some of that .
B: so let 's start with the belief - nets , the general influence and then we 'll then we 'll also at some point break and talk about the techy .
E: one could go there 's we can di discuss everything . first of all this added , knew from this has to be there
B: are you gonna go there or not ?
E: given given not transverse the castle , the decision is does the person want to go there or is it just
B: does have to be there . and 'm we 'll find more as we go that
E: so go - there in the first place or not is definitely one of the basic ones . we can start with that . is this true or false or maybe we 'll get
A: "" go there "" .
B: so there is this question about
E: we actually get just probabilities , for each down here .
B: when we 're when we 're done . the reason it might not be true or false is that we did have this idea of when so it 's , current @ @ and and so on or not , and so that decision would be do we want that so you could two different things you could do , you could have all those values for go - there or you could have go - there be binary and given that you 're going there when . we 'll see .
A: it seems that you could it seems that those things would be logically independent like you would wanna have them separate or binary , go - there and then the possibilities of how to go there
B: that 's let 's start that way .
A: because , it might be easy to figure out that this person is going to need more film eventually from their utterance but it 's much more complex to query when would be the most appropriate time .
E: and so 've tried to come up with some initial things one could observe so who is the user ? everything that has user comes from the user model everything that has situation comes from the situation model - . we should be clear . but when it comes to writing down when you when you do these things is it here ? you have to write the values this can take . and here was really in some sometimes was really standing in front of wall feeling very stupid because this case it 's pretty simple , but as we will see the other ones if it 's running budget so what are the discrete values of running budget ? so maybe my understanding there is too impoverished . how can write here that this is something , number that cr keeps on changing ? thus is understandable ?
B: you 've have you seen this before keith , these belief - net things ?
A: but 'm following it .
E: so here is the we had that the user 's budget may influence the outcome of decisions . there we wanted to keep running total of things .
D: is this like number that represents how much money they have left to spend ? how is it different from user finance ?
E: the finance is here thought of as the financial policy person carries out in his life , he is he cheap , average , or spendy ? didn't want to write greediness ,
B: thrift , that 's good .
E: there it is .
B: so keith what 's behind this is actually program that will once you fill all this in actually solve your belief - nets for you and . so this is not just display , this is actually gui to simulator that will if we tell it all the right things we 'll wind up with functioning belief - net at the other end .
E: and it 's so simple even use it .
A: that is simple .
E: think of people being cheap , average , or spendy or we can even have finer scale moderately cheap , but here wasn't what to write in .
D: you 've written in you 've written in what seems to be required like what else is do you want ?
E: if that 's permissible then 'm happy .
B: so here 's here 's what 's permissible is that you can arrange so that the the value of that is gonna have to be updated and it 's not belief update , it 's you took some actions , you spent money and , so the update of that is gonna have to be essentially external to the belief - net . and then what you 're going to need is for the things that it influences . let 's first of all let 's see if it does influence anything . and if it does influence anything then you 're gonna need something that converts from the number here to something that 's relevant to the decision there . so it could be ra they create different ranges that are relevant for different decisions or whatever but for the moment this is just node that is conditioned externally and might influence various things .
E: let 's forget it .
B: that 's fine . anyway , go ahead .
E: and so this , that
D: the other thing is that every time that 's updated beliefs will have to be propagated but then the question is do you do we wanna propagate beliefs every single time it 's updated or only when we need to ?
B: that 's good question . and does it have lazy mode ?
D: , in srini 's thing there was this thing there was this option like proper inferences which suggests that doesn't happen , automatically .
B: someone has to track that down , one of the we items for the user home base should be essentially non - local . they 're only there for the day and they don't have place that they 're staying .
E: just accidentally erased this , had values here such as is he we had in our list we had "" is he staying in our hotel ? "" , "" is he staying with friends ? "" ,
B: it 's clear where where we are right now . so my suggestion is we just pick
E: something down here ?
B: one , one particular one of the let 's do the first one let 's do the one that we already think we did so that was the of the endpoint ?
D: so it 's true or false ?
B: no , that 's that 's
E: missed that one .
C: what 's the difference between mode and endpoint ?
D: mode of transportation ? also true or false .
B: no , he has he hasn't filled them in yet , is what 's true .
E: did or didn't ? probably nothing done yet , did it on the upper ones , . so this was eva . maybe we can think of more things ,
A: climb , rob .
B: these are ju that 's just point ,
D: some of those are subsumed by approach .
C: would it be an endpoint if you were crossing over it ?
A: the charles bridge , .
B: would be for given segment . you you go first go the town square
A: no , , if you go to re if you go to prague or whatever one of your key points that you have to do is cross the charles bridge and doesn't really matter which way you cross which where you end up at the end but the part the good part is walking over it ,
B: that 's subtle , but true . so let 's just leave it three with three for now and let 's see if we can get it linked up just to get ourselves started . you 'll see it you 'll see something comes up immediately , that the reason wanna do this .
E: the user was definitely more likely to enter if he 's local more likely to view if he 's tourist and then we had the fact that given the fact that he 's thrifty and there will be admission then we get all these cross
B: we did , but the three things that it contributed to this the other two aren't up there . so one was the ontology
E: we 'll what type of building is it ?
B: and the and the third thing we talked about was something from the discourse .
E: what he has mentioned before .
B: right , so what what we seem to need here , this is why it starts getting into the technical the way we had been designing this , there were three intermediate nodes which were the endpoint decision as seen from the user model as seen from the ontology and as seen from the discourse . so each of those the way we had it designed , now we can change the design , but the design we had was there was decision with the same three outcomes based on the th those three separate considerations so if we wanted to do that would have to put in three intermediate nodes
E: we can load it up it very simple .
B: and then what you and have to talk about is , if we 're doing that and they get combined somehow how do they get combined ? but the they 're undoubtedly gonna be more things to worry about .
E: so this was adjusted for this one mode thing . so that 's in our in johno 's pictogram everything that could contribute to whether person wants to enter , view , or approach something .
B: it was called mode , so this is mode here means the same as endpoint .
E: is now this endpoint .
B: why don't we ch can we change that ?
E: we can just rename that , .
B: but that was actually , unfortunately that was an intermediate versio that 's don't think what we would currently do .
A: can ask about "" slurred "" and "" angry "" as inputs to this ?
D: like they 're either true or false
C: if the if the person talking is angry or slurs their speech they might be tired or , and , , possibly
A: less likely to enter .
D: was thinking less likely to view
B: but that 's - that seems to , so so my advice to do is get this down to what we actually likely to be strong influence . but , that was what he had in mind . so let 's think about this question of how do we wanna handle so there 're two separate things . at least two . one is how do we want to handle the notion of the ontology now what we talked about , and this is another technical thing bhaskara , is can we arrange so that so that the belief - net itself has properties and the properties are filled in from on ontology items . so the let 's take the case of the this endpoint thing , the notion was that if you had few key properties like is this tourist site , some landmark is it place of business is it something you physically could enter so that there 'd be certain properties that would fit into the decision node and then again as part of the ou outer controlling conditioning of this thing those would be set , so that some somehow someone would find this word , look it up in the ontology , pull out these properties , put it into the belief - net , and then the decision would flow .
E: seems to me that we 've embedded lot , embedded lot of these things we had in there previously in in some of the other final decisions done here , if we would know that this thing is exhibiting something if it 's exhibiting itself it is landmark , meaning more likely to be viewed if it is exhibiting pictures or sculptures and like this , then it 's more likely to be entered .
B: that 's that 's completely right and that 's good , so what that says is that we might be able to take and so the ones we talked about were exhibiting and selling no , accessibility meant
E: if it 's closed one probably won't enter . or if it 's not accessible to tourist ever the likelihood of that person actually wanting to enter it , given that he knows it , .
B: so let me suggest this . could you move those up about halfway . the ones that you th and selling .
E: if it 's fixing things selling things , or servicing things
B: so here 's what it looks like to me . is that you want an intermediate structure which is essentially the or of for this purpose of selling , fixing , or servicing . that is , for certain purposes , it becomes important but for this purpose one of these places is quite like the other . does that seem right ?
C: you 're just merging those for just the sake of endpoint decision ?
B: so if it may be more than endpoint decisions , so the idea would be that you might wanna merge those three ser selling , fixing , and servicing .
D: what ex and so either those is true or false ?
B: it here 's where it gets little tricky . from the belief - net point of view it is from another point of view it 's interest it 's it 's important to it 's selling or servicing and . so for this decision it 's just true or false and in th this is case where the or seems just what you want . that that if any of those things is true then it 's the place that you
E: more likely to enter .
B: are more likely to enter .
D: so you just wanna have them all pointing to summary thing ?
B: you could , . so let 's do that . no no , no to an inter no , an intermediate node . that 's the part of the idea , is
E: is that the object type node ? so are they the is it the object that sells , fixes , or services things ?
B: open up object type and let 's see what its values are .
E: created it , it has none so far .
B: first of all it 's not objects , we called them entities ,
E: and then we have the
B: let 's say put commercial .
E: commercial action inside where people
B: couldn't do let 's do commercial
E: and where was the accessible , .
B: cuz that 's tempor that varies temporally ,
C: what would hotel fall under ?
B: would call that service ,
C: in terms of entity type ?
B: say it 's co would again for this purpose it 's commercial . someplace you want to go in to do some business .
D: what does the underscore - at the end of each of those things signify ?
E: so places that service things sell things or fix things and pe places that exhibit things .
D: that also points to entity type .
A: so we 're deriving this the this feature of whether the main action at this place happens inside or outside or what we 're deriving that from what activity is done there ? couldn't you have it as just primitive feature of the entity ?
B: that 's that 's choice .
A: it seems like that 's much more reliable cuz you could have outdoor places that sell things and indoor places that do something else
B: the problem with it is that it putting in feature just for one decision , now we may wind up having to do that this anyway , this at mental level that 's what we 're gonna have to sort out . so , what does this look like , what are what are intermediate things that are worth computing , what are the features we need in order to make all these decisions and what 's the best way to organize this so that it 's clean and consistent and all that .
A: 'm just thinking about how people , human beings who know about places and places to go and so on would store this and it would probably you wouldn't just remember that they sell and then deduce from that it must be going on inside .
E: an entity maybe should be regard as vector of several possible things , it can either do do sell things , fix things , service things , exhibit things , it can be landmark at the same time as doing these things , it 's not either or mmm certainly place can be hotel and famous site . many come to mind . things can be generally landmark and be accessible . or can be landmark or not accessible , some statue can go inside .
B: anyway so let me suggest you do something else . which is to get rid get rid of that long link between who the user and the endpoint .
E: could we just move it like this ?
B: no no , don't want the link there . because what we 're gonna want is an intermediate thing which is the endpoint decisi the endpoint decision based on the user models , so what we what we talked about is three separate endpoint decisions , so let 's make new node
C: just as suggestion maybe you could "" save as "" to keep your old one and clean and so you can mess with this one .
E: the old one was not that important ,
C: , not big deal then .
E: let 's do it then .
C: isn't there "" save as "" inside of java base ?
E: but just take this copy it somewhere else . this was user something
B: let 's put it this let 's do endpoint underbar - . endpoint , end poi it 's the endpoint let 's say underbar - , so that 's the endpoint decision as seen through the
C: as related from the user model .
B: so let 's let 's actually so lin you can link that up to the
E: should rename this too ?
B: so that , that 's endpoint
E: it 's underscore - .
B: underscore - for entity , and we may change all this ,
E: shouldn't be able to move them all ?
B: actually , the easiest thing would move mo move the endpoint , just do whatever .
E: wasn't this possible ?
C: you have to be in move mode before
E: so now we 're looking for user related things that
B: and maybe th maybe it 's just one who is the user , maybe there 's more .
E: if he 's usi if he 's in car right now people with harry drove the car into the cafe
B: anyway , this is crude . now but the now so but then the question is so and we assume that some of these properties would come indirectly through an ontology , but then we had this third idea of input from the discourse .
E: let 's should we finish this , but surely the user interests
C: the user thrift , the user budget .
B: but what we 're gonna wanna do is actually
E: here this was one of my problems we have the user interest is is vector of five hundred values , that 's from the user model ,
D: you mean level of interest ?
E: no not levels of interest but things you can be interested in .
B: somebody else has built this user model .
E: gothic churches versus baroque townhouses versus
D: so why is it it , so it 's like vector of five hundred one 's or zero 's ?
E: yea - is that
D: like for each thing are we are you interested in it or not ?
B: so you cou and so here let me give you two ways to handle that . one is you could ignore it . but the other thing you could do is have an and this will give you the flavor of the of what you could have node that 's that was measure of the match between the object 's feature , , the match between the object the entity , 'm and the user . so you could have "" fit "" node that would have to be computed by someone else
E: just as mental note
B: that 's all .
E: and and should we say that this interests affects the likelihood of entering ? and also if it 's an expensive place to enter , this may also
A: "" do have time to go in and climb all the way to the top of the koelner dome or do have to "" "" time to take picture of the outside ? ""
C: it seems like everything in user model affects
B: that 's what we don't wanna do , cuz then we get into huge combinatorics and like that
C: cuz if the , , and if the user is tired , the user state , it would affect , but 't see why anything everything in the model wouldn't be
B: that 's we can't do that , so we 're gonna have to but this is good discussion , we 're gonna have to somehow figure out some way to encapsulate that so if there 's some general notion of the relation to the time to do this to the amount of time the guy has like that is the compatibility with his current state , so that 's what you 'd have to do , you 'd have to get it down to something which was itself relatively compact , so it could be compatibility with his current state which would include his money and his time and his energy
C: just seems like it 'd push the problem back level .
D: no but , it 's more than that , like the more you break it up like because if you have everything pointing to one node it 's like exponential whereas if you like keep breaking it up more and more it 's not exponential anymore .
B: so it , there are two advantages . that 's tha there 's one technical one and the other is it gets used
C: so we 'd be doing subgrouping ? so make it more tree like going backwards ?
B: but it there 's two advantages , one is the technical one that you don't wind up with such big exponential cbt 's , the other is it can be it presumably can be used for multiple decisions . so that if you have this idea of the compatibility with the requirements of an action to the state of the user one could imagine that was not only is it sim is it cleaner to compute it separately but it could be that it 's used in multiple places . anyway th so in general this is the design , this is really design problem . you 've got signal , set of decisions how do we do this ?
E: what do have under user state anyhow cuz named that already something . that 's tired , fresh , maybe should be renamed into physical state .
B: or fat user fatigue even .
E: that 's with "" "" ? then we can make user state .
B: what 's th what we 're talking about is compatibility .
C: it 's hard for me to imagine how everything wouldn't just contribute to user state again . or user compatibility .
B: but that we we had some things that
E: the user interests and the user who who the user is are completely apart from the fact whether he is tired broke
C: but other though the node we 're creating right now is user compatibility to the current action , seems like everything in the user model would contribute to whether or not the user was compatible with something .
B: the that 's the issue is would even if it was true in some abstract general sense it might not be true in terms of the information we actually had and can make use of . and anyway we 're gonna have to find some way to cl get this sufficiently simple to make it feasible .
E: maybe if we look at the if we split it up again into if we look at the the endpoint again we said that for each of these things there are certain preconditions so you can only enter place if you are not too tired to do so and also have the money to do so if it costs something so if you can afford it and perform it is preconditions . viewing usually is cheap or free . is that always true ?
C: with the way we 're defining it .
B: but that viewing it without ent view with our definition of view it 's free
E: and so is approaching .
A: what about the grand canyon , no , never mind . are there are there large things that you would have to pay to get up close to not in the current
B: no we have to enter the park . almost by definition paying involves entering , ge going through some so let me suggest we switch to another one , clearly there 's more work to be done on this but it 's gonna be more instructive to think about other decisions that we need to make in path land . and what they 're gonna look like .
C: so you can save this one as and open up the old one , and then everything would be clean . you could do it again .
B: why , it 's worth saving this one but 'd 'd like to keep this one cuz wanna see if we 're gonna reuse any of this .
E: so this might be
B: you tell me , so in terms of the planner what 's what 's good one to do ?
E: let 's th this go there or not is good one . is very basic one . what makes things more likely that
B: the fir see the first thing is , getting back to thing we left out of the other is the actual discourse . so keith this is gonna get into your world because we 're gonna want to know , which constructions indicate various of these properties don't yet know how to do this , we 're gonna wind up pulling out discourse properties like we have object properties and we what they are yet . so that the go - there decision will have node from discourse , and why don't we just stick discourse thing up there to be as placeholder for
E: we we also had discourse features for the endpoint . and so again re that 's completely correct , we have the user model , the situation model here , we don't have the discourse model here yet . much the same way as we didn't we don't have the ontology here .
B: the ontology we said we would pull these various kinds of properties from the ontology like exhibiting , selling , and . so in some sense it 's it 's there . but the discourse we don't have it represented yet .
E: this be specific for second year ? and and we probably will have something like discourse for endpoint .
B: but if we do it 'll have the three values . it 'll have the eva values if we have it . for go - there , probably is true and false , let 's say . that 's what we talked about .
E: we 're looking at the little data that we have , so people say how do get to the castle and this usually means they wanna go there . so this should push it in one direction however people also sometimes say how do get there in order to find out how to get there without wanting to go there . and sometimes people say where is it because they wanna know where it is but in most cases they probably
B: but that doesn't change the fact that you 're you want these two values .
E: so this is some external thing that takes all the discourse and then says here it 's either , yay , , or nay .
B: and they 'll be , user go - there and maybe that 's all ,
D: situation go - there , because it 's whether it 's open or not . but that now that what 's the word the that interacts with the eva thing if they just wanna view it then it 's fine to go there when it 's closed whereas if they want to
B: right , so that 's that 's where it starts getting to be essentially more interesting , so what bhaskara says which is completely right is if that they 're only going to view it then it doesn't matter whether it 's closed or not in terms of , whether you wanna go there .
D: the time of day ,
C: it does matter though if there 's like strike or riot .
B: there are other situational things that do matter .
D: that 's what said just having one situational node may not be enough because this that node by itself wouldn't distinguish
B: it can have di various values . but we you 're right it might not be enough .
D: , see 'm 'm thinking that any node that begins with "" go - there "" is either gonna be true or false .
B: that could be .
A: also , that node , the go - there node would just be fed by separate ones for there 's different things , the strikes and the
D: like situation traffic and so on .
A: the time of day .
B: so so now the other thing that bhaskara pointed out is what this says is that there sh should be link , and this is where things are gonna get very messy from the endpoint decision maybe the they 're final re and , the very bottom endpoint decision to the go - there node . and don't worry about layout , then we 'll go we 'll go nuts
D: maybe we could have intermediate node that just the endpoint and the go - there node fed into ? because that 's what we , that 's why this situation comes up .
B: the go - there , actually the endpoint node could feed into the go - there that 's right , so the endpoint node , make that up to the go - there then we 'll have to do layout at some point , but something like that . now it 's gonna be important not to have loops . really important in the belief worl net world not to have loops
E: how long does it take you to compute
B: no it 's much worse than that . it if loo it it 's not def it 's not defined if you 're there are loops ,
D: it things don't converge , .
B: you just you have to there are all sorts of ways of breaking it up so that there isn't
E: but this isn't , this is this line is just coming from over here .
B: no it 's not loop yet , 'm just saying we , in no , in
D: but the good thing is we could have loopy belief propagation which we all love .
B: so anyway , so that 's another decision . what 's what 's another decision you like ?
E: these have no parents yet , but that doesn't matter .
B: the idea is that you go there , you go comes from something about the user from something about the situation and the the discourse is mystery .
E: this comes from traffic and , . sh - should we just make some
B: if you want .
E: if there 's parking maybe and if he has seen it already or not and , and discourse is something that should we make keith note here ? that comes from keith . just so we don't forget . have to get used to this .
B: and then also the discourse endpoint , endpoint sub - is if you wanna make it consistent .
A: actually is this the right way to have it where go there from the user and go there from the situation just about each other but they both feed the go there decision because isn't the , but that still allows for the possibility of the of the user model affecting our decision about whether strike is the thing which is going to keep this user away from th that decision making happens at the go - there node .
B: you you you if you needed to do that .
A: if you needed it to do that . but was just thinking maybe 'm conflating that user node with possible asking of the user hey there 's strike on , does that affect whether or not you wanna go
B: good point , don't how we 're going to
A: so that might not come out of user model but , , directly out of interaction .
B: gu yes my curr , don't that 's enough . my current idea on that would be that each of these decision nodes has questions associated with it . and the question wouldn't itself be one of these conditional things given that there 's strike do you still wanna go ? but if you told him bunch of , then you would ask him do you wanna go ? but trying to formulate the conditional question , that sounds too much .
A: right , right . right , , .
B: alright , but let me let 's stay with this minute because want to do little bit of organization . before we get more into details . the organization is going to be that the flavor of what 's going on is going to be that as we going to this detail keith is going to worry about the various constructions that people might use and johno has committed himself to being the parser wizard , so what 's going to happen is that eventually like by the time he graduates , they 'll be some system which is able to take the discourse in context and have outputs that can feed the rest of belief - net . wa assume everybody knows that , wanna , get closure that 'll be the game then , so the semantics that you 'll get out of the discourse will be of values that go into the various discourse - based decision nodes . and now some of those will get fancier like mode of transportation and so it isn't by any means necessarily simple thing that you want out . so if there is an and there is mode of transportation
E: and it there 's also split if you loo if you blow this up and look at it in more detail there 's something that comes from the discourse in terms of what was actually just said what 's the utterance go giving us and then what 's the discourse history give us .
B: that , , we 'll have to decide how much of th where that goes .
E: that 's two things then .
B: an and it 's not clear yet . it could be those are two separate things , it could be that the discourse gadget itself integrates as which would be my that you 'd have to do see in order to do reference and like that you 've gotta have both the current discourse and the context to say wanna go back there , what does that mean
E: but is th is this picture that 's emerging here just my wish that you have noticed already for symmetry or is it that we get for each decision on the very bottom we get the sub - , sub - , sub - and maybe sub - "" "" for "" ontology "" meta node but it might just
B: it could be . this is this is getting into the thing wanna talk about next , which is if that 's true how do we wanna combine those ? or when it 's true ?
E: but this wou would be though that , , we only have at most four at the moment arrows going to each of the bottom decisions . and four you we can handle . it 's too much ?
B: it see if it 's fou if it 's four things and each of them has four values it turns out to be big cpt , it 's not completely impossi it 's it 's not beyond what the system could solve but it 's probably beyond what we could actually write down . or learn .
E: right , true .
B: but , it 's four to the fourth . it 's pretty big .
C: two fifty - six , is that what that
B: it 's and don't 's gonna don't 'll get worse than that , so le that 's that 's good
E: but but four didn't we decide th of these had true or false ? so is it 's four
B: for go there , but not but not for the other one 's three values for endpoint already .
D: you need actually three to the five because if it has four inputs and then it itself has three values it can get big fast .
E: no it 's it 's sh
B: ev - it 's the eva .
E: but this one only has two .
D: no it still has three ,
B: since ta they will still have three . each so you 're from each point of view you 're making the same decision . so from the point of view of the ob of the entity
E: want to view that ,
D: this and also , , the other places where , like consider endpoint view , it has inputs coming from user budget , user thrift
B: those are not necessarily binary . so we 're we 're gonna have to use some care in the knowledge engineering to not have this explode . and it doesn't in the sense that actually with the underlying semantics and it isn't like you have two hundred and fifty - six different ways of thinking about whether this user wants to go to some place . so we just have to figure out what the regularities are and code them . but what was gonna suggest next is maybe we wanna work on this little longer but do want to also talk about the thing that we started into now of it 's all fine to say all these arrows come into the si same place what rule of combination is used there . so th yes they so these things all affect it , how do they affect it ? and belief - nets have their own beliefs about what are good ways to do that . so is it 's it 's clearer clear enough what the issue is , so do we wanna switch that now or we wanna do some more of this ?
E: we just need to in order to get some closure on this figure out how we 're gonna get this picture completely messy .
B: here he here 's one of the things that th you sh how easy it is to do this in the interface but you it would be great if you could actually just display at given time all the things that you pick up , you click on "" endpoint "" , and everything else fades and you just see the links that are relevant to that . does anybody remember the gui on this ?
C: would almost say the other way to do that would be to open or make - many belief - nets and then open them every time you wanted to look at different one
E: it 's probably pretty easy do it to do it in html , have each of these thing each of the end belief - nets be page and then you click on the thing and then li consider that it 's respective ,
B: anyway so it clear that even with this if we put in all the arrows nobody is gonna be able to read the diagram . so we have to figure out some display hack to do this anyway let me consi suggest that 's not first - order consideration , we have two first - order considerations which is what are the influences , and how do they get combined mathematically , how do we display them is an issue ,
C: don't , don't think this has been designed to support something like that .
D: , it might soon , if this is gonna be used in serious way like java base then it might soon be necessary to start modifying it for our purposes .
B: and that seems like perfectly feasible thing to get into , but we have to we want first . so why don't you tell us little bit about decision nodes and what the choices might be for these ?
C: you can technically wear that as you 're talking .
D: it 's right , do that .
B: put it in your ,
D: this board works fine . so recall the basic problem which is that you have belief - net and you have like lot of different nodes all contributing to one node . so as we discussed specifying this thing is big pain and it 's so will take long time to write down because if these have three possibilities each and this has three possibilities then you have two hundred and forty - three possibilities which is already lot of numbers to write down . so what helps us in our situation is that these all have values in the same set , these are all like saying ev or , so it 's not just generalized situation like we wanna just take combination of we wanna view each of these as experts ea who are each of them is making decision based on some factors and we wanna combine their decisions and create , sorta weighted combination .
E: rover , the rover decision .
D: the what decision ?
E: all of their outputs combined to make decision .
D: so the problem is to specify the so the conditional property of this given all those , that 's the way belief - nets are defined , like each node given its parents , so that 's what we want , let 's call this guy and let 's call these - one , - two xn , so we want probability that equals , , given that these guys are 'll just refer to this as like hat , the co like all of them ? given that the data says , , , , , so we would like to do this combination .
B: wanna make everybody is with us before he goes on . it 's it 's cl is it clear what he wants to compute ?
D: so , right . so what we don't wanna do is to for every single combination of and and and every single letter , give number because that 's not desirable . what we wanna do is find some principled way of saying what each of these is and we want it to be valid probability distribution , so we want it to add up to one , so those are the two things that we need . so what , what jerry suggested earlier was that we , view these guys as voting and we just take the we essentially take averages , so here two people have voted for , one has voted for , and one has voted for , so we could say that the probabilities are , , probability of being is one over four , because one person voted for out of four and similarly , probability of so this is probability of and then probability of given all that is two out of four and probability of is one out of four . so that 's step that 's the that 's the that 's the basic thing .
E: and that one outcome , that 's it 's - one voted for - two voted for
B: so this assumes symmetry and equal weights and all this things , which may or may not be good assumption ,
E: that 's the outcome .
D: so step two is so we 've assumed equal weights whereas it might turn out that , some be that , what the the actual the verbal content of what the person said , like what what might be somehow more important than the
C: - one matters more than - two or
D: so we don't wanna like give them all equal weight so currently we 've been giving them all weight one fourth so we could replace this by - one , - two , - three , and - four and in order for this to be valid probability distribution for each - hat , we just need that the 's sum to one . so they can be , you could have point one , point three , point two , and point four , say .
E: that 's one .
D: and that 'd be one . so that also seems to work fine .
C: so jus just to make understand this , so in this case we would still compute the average ?
D: you 'd compute the weighted average , so the probability of would be
C: so it 'd be so in this case the probability that equals would be one times let 's see , one full quarter times point one
D: not one quarter , so these numbers have been replaced with point one , point three , point two , and point four . so you can view these as gone . so this is step two . so the next possibility is that we 've given just single weight to each expert , whereas it might be the case that in certain situations one of the experts is more reliable and in certain situations the other expert is more reliable . so the way this is handled is by what 's called mixture of experts , so what you can have is you augment these diagrams like this you have new thing called "" "" , this is hidden variable . and what this is it gets its input from - one , - two , - three , and - four , and what it does is it decides which of the experts is to be trusted in this particular situation . and then these guys all come here . so this is sightly more complicated . so what 's going on is that this node looks at these four values of those guys and it decides in given these values which of these isn't likely to be more reliable or most reliable . so produces some , it produces number , either one , two , three , or four , in our situation , now this guy he looks at the value of say it 's two , and then he just selects the thing . that 's all there is to say , about it . right , so you can have mixture that
A: so so the function of the thing that comes out of is very different from the function of the other inputs . it 's driving how the other four are interpreted .
C: so passes vector on to the next node ? vector of the weights as the se
A: vector with three zero 's and one ,
C: it 's to tell the bottom node which one of the situations that it 's in or which one of the weighting systems
D: right , so the way you desc
C: was just , if you wanted to pay attention to more than one you could pass weighting system though too ,
A: does have to have another input to tell it alpha , beta , whatever , or is the that 's determined by what the experts are saying , like the type of situ it it just seems that like without that outside input that you 've got situation where , , like if - one says no , low value coming out of - on or if - one says no then ignore - one , that seems like that 'd be weird ,
D: could be things like if - two and - three say yes then ignore - one also .
A: alright , right .
C: the situations that has , are they built into the net so they could either be hand coded or learned or based on training data , so you specify one of these things for every one of those possi possible situations .
D: to learn them we need data , where are we gonna get data ? we need data with people intentions ,
A: right , right .
D: which is slightly tricky . but what 's the data about like , are we able to get these nodes from the data ?
A: like how thrifty the user is , or do we have access to that ?
D: but that 's my question , like how do we , how do we have data about something like endpoint sub - , or endpoint sub ?
C: you would say , based on in this dialogue that we have which one of the things that they said whether it was the entity relations or whatever was the thing that determined what mode it was ,
D: so this is what we wanna learn . can you bring up the function thing ? where is the thing thows you to
C: that 's on the added variable ,
D: is that it ? and it so either it 'll allow us to do everything which is unlikely , more likely it 'll allow us to do very few of these things and in that case we 'll have to just write up little things thow you to create such cpu 's on your own in the java base format . was assuming that 's what we 'd always do was assuming that 's what we 'd always do ,
C: in terms of java base it 's what you see is what you get in would be surprised if it supports anything more than what we have right here .
A: just talking about about that general end of things is there gonna be data soon from what people say when they 're interacting with the system and so on ? like , , what questions are being given being asked ? fey , you mean . 'm just wondering , because in terms of , , the figure was thinking about this figure that we talked about , fifty constructions or whatever that 's that 's whole lot of constructions and , one might be fairly pleased with getting really good analysis of five maybe ten in summer so , know we 're going for rough and ready . was was talking about the , , if you wanted to do it really in detail and we don't really need all the detail for what we 're doing right now but anyway in terms of just narrowing that task which fifty do do , wanna see what people are using , it will inspire me .
","A detailed diagram of the belief-net had already been disseminated.
Its structure was discussed during the meeting.
There are several endpoints ( User , Ontology , Discourse etc ) with separate EVA ( Enter/View/Approach ) values.
Details of how different inputs feed into them were discussed at length.
Ideas mentioned included grouping features of buildings like ""selling"" , ""fixing"" and ""exhibiting"" , as well as creating a User-compatibility node that would take different values depending on the situation and the user status.
Similarly , a Go-there ( towards a building ) node can be influenced by things like the user's budget and discourse parameters amongst other things.
The latter are still ill-defined at this stage.
The study of the linguistic constructions that people use in this kind of navigational domain is expected to be prove useful in that respect.
As each node in the tree is the decision point of the combination of its parent nodes , which rules govern this combination is an important issue.
There are several approaches ranging from simply averaging the inputs to using a hidden variable in order to weight them differently depending on context.
If the latter architecture is used , the net could -to an extent- be trained with the data that is currently being collected.
Although this was mainly a brainstorming meeting , some minor tasks were allocated for the near future.
Since the net architecture and possible decision algorithms were discussed , it is necessary to examine how much of this JavaBayes can accommodate and , if not , what modifications would be necessary.
Additionally , the german partners visiting the institute will need to see some results of the new system design.
Finally , the analysis of the linguistic constructions for the current research domain can begin even with limited data , as , at this stage , they need not be very detailed.
The is only a diagrammatic view of how the decision tree for the EVA task looks like.
A lot of the details have been glossed over: the user model can potentially comprise a huge number of factors; a planning ""go-there"" node needs input from several other areas of the net; there are intricate interactions between discourse and the situation model.
Similarly , what discourse properties are of importance and how they influence EVA probabilities is still a mystery.
On a more general note , there is also the question of whether the net should be updated continuously or only when it is needed.
No final decision was taken as to the rules of computation applying in the belief-net.
The more interesting solutions would ideally require training data , and it is still debatable whether the current collection would be appropriate for this particular task.
In any case , how different architectures can be implemented in JavaBayes and what modifications would be necessary for the purposes of this project also need to be investigated.
A simulator of the set of influence links forming the belief-net was created and put up for discussion.
Different sections of the analysis , such as the user model , the ontology and the discourse are represented as a layer of nodes each with its own EVA probabilities.
They form endpoints to which other nodes like Go-there , User_Budget , User_Thrift and Prosody feed into.
The second presentation concerned the set of computational rules that are to be used with the net.
The simple way to decide on the final output is the majority vote ( which E , V or A form the majority of the parent nodes' outputs ).
This assumes that all inputs are of equal importance.
Alternatively , each input can be weighted in a fixed way.
A third option is to create a hidden variable that makes the decision of which of the inputs is more trusted in a particular situation.
The same variable can potentially also change the weighting of each input.
"
ami_abstractive_summary,Bmr015.txt,"B: and we seem to be working . we didn't crash we 're not crashing anymore
C: one , two , three , four ,
B: and it really bothers me .
G: crashed when started this morning .
B: you crashed this morning ? did not crash this morning .
A: maybe it 's just , , how many how many times you crash in day . first time first time in the day ,
G: or maybe it 's once you 've done enough meetings it won't crash on you anymore . it 's matter of experience .
F: self - learning , .
A: that 's that 's great . do we have an agenda ? liz and andreas can't sh can't , can't come . so , they won't be here .
B: and it 's all me . cuz no one sent me anything else .
G: did they send , , the messages to you about the meeting today ?
B: but got it few minutes ago . right when you were in my office it arrived .
G: cuz checked my mail . didn't have anything .
B: so , does anyone have any agenda items other than me ? actually have one more also which is to talk about the digits .
A: right , so was just gonna talk briefly about the nsf itr . and then , you have won't say much , but , but then , , you said wanna talk about digits ?
B: have short thing about digits and then wanna talk little bit about naming conventions , although it 's unclear whether this is the right place to talk about it . so maybe just talk about it very briefly and take the details to the people who for whom it 's relevant .
F: could always say something about transcription . 've been but ,
A: if we , we shouldn't add things in just to add things in . 'm actually pretty busy today , so if we can we short meeting would be fine .
F: this does sound like we 're doing fine , that won't do .
B: so the only thing wanna say about digits is , we are done with the first test set . there are probably forms here and there that are marked as having been read that weren't really read . so won't really know until go through all the transcriber forms and extract out pieces that are in error . so wa . two things . the first is what should we do about digits that were misread ? my opinion is , , we should just throw them out completely , and have them read again by someone else . the grouping is completely random , so it 's perfectly fine to put group together again and have them re - read , just to finish out the test set .
F: ! by throw them out completely ?
B: the other thing you could do is change the transcript to match what they really said . so those are those are the two options .
A: but there 's often things where people do false starts . 've done it , where say
B: what the transcribers did with that is if they did correction , and they eventually did read the right string , you extract the right string .
G: you 're talking about where they completely read the wrong string and didn't correct it ?
B: and didn't notice . which happens in few places .
F: and and you 're talking string - wise , you 're not talking about the entire page ?
B: and so the two options are change the transcript to match what they really said , but then but then the transcript isn't the aurora test set anymore . don't think that really matters because the conditions are so different . and that would be little easier .
G: how many are how often does that happen ?
B: mmm , five or six times .
G: so it 's not very much .
B: no , it 's not much .
G: seems like we should just change the transcripts
A: it 's five or six times out of thousands ?
C: four thous ! four thousand .
A: would , , tak do the easy way , it it 's kinda wh who knows what studies people will be doing on speaker - dependent things and so having it all the speakers who we had is at least interesting .
G: so you , how many digits have been transcribed now ?
B: four thousand lines . and each line is between one and about ten digits .
G: four thousand lines ?
B: didn't didn't compute the average . the average was around four or five .
A: so that 's couple hours of , , speech , probably . which is reasonable test set .
B: and , jane , do have set of forms which you have copies of somewhere .
F: - . , true . - . - .
B: had all of them back from you . and then the other thing is that , , the forms in front of us here that we 're gonna read later , were suggested by liz
F: no , not yet .
B: because she wanted to elicit some different prosodics from digits . and so , , wanted people to , take quick look at the instructions
E: eight eight two nine .
B: and the way it wa worked and see if it makes sense and if anyone has any comments on it .
A: and the decision here , , was to continue with the words rather than the numerics .
B: although we could switch it back . the problem was and zero . although we could switch it back and tell them always to say "" zero "" or always to say "" "" .
A: but it 's just two thing ways that you can say it . that 's the only thought have because if you start talking about these , tr she 's trying to get at natural groupings , but it there 's nothing natural about reading numbers this way . if you saw telephone number you would never see it this way .
B: the the problem also is she did want to stick with digits . 'm speaking for her since she 's not here . but , , the other problem we were thinking about is if you just put the numerals , they might say forty - three instead of four three .
F: if there 's space , though , between them . with when you space them out they don't look like , , forty - three anymore .
B: she and were talking about it , and she felt that it 's very , very natural to do that chunking .
A: she 's right . it 's it 's different problem . it 's it 's an interesting problem we 've done with numbers before , if you say "" three nine eight one "" sometimes people will say "" thirty - nine eighty - one "" or "" three hundred three hundred eighty - nine one "" , or don't think they 'd say that ,
B: but , they certainly could .
A: th thirty - eight ninety - one is probably how they 'd do it .
B: so . , this is something that liz and spoke about and , since this was something that liz asked for specifically , we need to defer to her .
A: , we 're probably gonna be collecting meetings for while and if we decide we still wanna do some digits later we might be able to do some different ver different versions ,
B: do something different ,
A: but this is the next suggestion , so , let me , , get my short thing out about the nsf . actually this is maybe little side thing . sent to what we had , , in some previous mail , as the right joint thing to send to , which was "" mtg rcdr hyphen joint "" . but then got some funny mail saying that the moderator was going to
B: that 's because they set the one up at uw that 's not on our side , that 's on the - dub side . and so - uw set it up as moderated list . and , have no idea whether it actually ever goes to anyone so you might just wanna mail to mari
A: no no , th got got , , little excited notes from mari and jeff and so on ,
B: so the moderator actually did repost it . cuz had sent one earlier actually the same thing happened to me had sent one earlier . the message says , "" you 'll be informed "" and then was never informed but got replies from people indicating that they had gotten it , it 's just to prevent spam .
A: so . , anyway , everybody here are are you are on that list , so you got the note ? so this was , , , , proposal that we put in before on more higher level , , issues in meetings , from higher level from my point of view . and , , meeting mappings , so is for it was proposal for the itr program , information technology research program 's part of national science foundation . it 's the second year of their doing , , these grants . they 're they 're lot of them are some of them anyway , are larger grants than the usual , small nsf grants , so , they 're very competitive , and they have first phase where you put in pre - proposals , and we , , got through that . and so th the next phase will be we 'll actually be doing larger proposal . and 'm hope to be doing very little of it . which was also true for the pre - proposal , there 'll be bunch of people working on it .
B: when 's when 's the full proposal due ?
A: april ninth , . so it 's about month .
B: and they said end of business day you could check on the reviewer forms ,
A: march second , said .
B: 've been day off all week . that 's good thing cuz that way got my papers done early .
G: it would be interesting
A: so that 's amazing you showed up at this meeting !
B: it is . it is actually quite amazing .
G: it 'll be interesting to see the reviewer 's comments .
A: my favorite is was when when one reviewer says , , "" , this should be far more detailed "" , and the nex the next reviewer says , "" , there 's way too much detail "" .
B: or "" this is way too general "" , and the other reviewer says , "" this is way too specific "" . "" this is way too hard "" , "" way too easy "" .
A: we 'll see . maybe there 'll be something useful .
B: it sounded like they the first gate was pretty easy . is that right ? that they didn't reject lot of the pre - proposals ?
A: do anything about the numbers ?
G: it 's just from his message it sounded like that .
E: said something , .
G: there was sentence at the end of one of his paragraphs
A: should go back and look . didn't don't think that 's true .
G: he said the next phase 'll be very , competitive because we didn't want to weed out much in the first phase .
A: we 'll have to see what the numbers are . but they have to weed out enough so that they have enough reviewers . so , , , maybe they didn't weed out as much as usual , but it 's it 's usually pretty it 's it 's certainly not 'm that it 's not down to one in two of what 's left . 'm it 's ,
B: how how many awards are there ,
A: there 's different numbers of awards for different size they have three size grants . this one there 's , see the small ones are less than five hundred thousand total over three years and that they have fair number of them . and the large ones are , boy , forget , more than million and half , more than two million like that . and and we 're in the middle forget what it was . but it 's pr probably along the li could be wrong on this but probably along the lines of fifteen or that they 'll fund , or twenty . when they do you do how many they funded when they in chuck 's , that he got last year ?
B: it was smaller , that it was like four or five , it doesn't matter , we 'll find out one way or another .
A: last time they just had two categories , small and big , and this time they came up with middle one , so it 'll there 'll be more of them that they fund than of the big .
G: if we end up getting this , , what will it mean to icsi in terms of , wh where will the money go to , what would we be doing with it ?
B: exactly what we say in the proposal .
G: which part is icsi though .
A: none of it will go for those yachts that we 've talking about . no , it 's
G: it 's just for the research to continue the research on the meeting recorder ?
A: it 's extending the research ,
B: it 's go higher level than we 've been talking about for meeting recorder .
A: the other things that we have , , been working on with , , the with communicator especially with the newer things with the more acoustically - oriented things are are lower level . this is dealing with , , mapping on the level of , , the conversation of mapping the conversations
G: right , right .
A: to different planes . so . . but , . so it 's all that none of us are doing right now , or none of us are funded for , so it 's it would be new .
G: so assuming everybody 's completely busy now , it means we 're gonna hafta , hire more students , or , something ?
A: there 's evenings , and there 's weekends , there would be there would be new hires , and there would be expansion , also , there 's always for everybody there 's there 's always things that are dropping off , grants that are ending , or other things that are ending , there 's there 's continual need to bring in new things . but but there definitely would be new new , , students , and , both at uw and here .
B: are there any students in your class who are expressing interest ?
A: not clear yet . not clear yet .
B: other than the one who 's already here .
A: we got we have two of them are two in the there 're two in the class already here , then there 's third who 's doing project here , who , but he he won't be in the country that long , maybe another will end up . actually there is one other guy who 's looking that 's that anyway , that 's that 's all was gonna say is that 's , that 's and we 're sorta preceding to the next step , and , it 'll mean some more work , , , in march in getting the proposal out , and then , it 's , , we 'll see what happens . the last one was that you had there , was about naming ?
B: it just , we 've been cutting up sound files , in for ba both digits and for , , doing recognition . and liz had some suggestions on naming and it just brought up the whole issue that hasn't really been resolved about naming . so , , one thing she would like to have is for all the names to be the same length so that sorting is easier . same number of characters so that when you 're sorting filenames you can easily extract out bits and pieces that you want . and that 's easy enough to do . and don't think we have so many meetings that 's big deal just to change the names . so that means , , instead of calling it "" mr one "" , "" mr two "" , you 'd call it "" mrm zero one "" , "" mrm zero two "" , things like that . just so that they 're they 're all the same length .
F: but , , when you , do things like that you can always as long as you have you can always search from the beginning or the end of the string .
B: the problem is that they 're lot of fields .
F: so "" zero two ""
B: so we have th we 're gonna have the speaker id , information on the microphones ,
F: , your example was really
B: information on the speak on the channels and all that . and so if each one of those is fixed length , the sorting becomes lot easier .
D: she wanted to keep them the same lengths across different meetings also . so like , the nsa meeting lengths , all filenames are gonna be the same length as the meeting recorder meeting names ?
B: and as said , the it 's we just don't have that many that 's big deal .
G: cuz of digits .
B: and so , , , at some point we have to take few days off , let the transcribers have few days off , make no one 's touching the data and reorganize the file structures . and when we do that we can also rationalize some of the naming .
F: would think though that the transcribe the transcripts themselves wouldn't need to have such lengthy names . so , , you 're dealing with different domain there , and with start and end times and all that , and channels and ,
B: right . so the only thing that would change with that is just the directory names ,
F: so , it 's different set .
B: would change them to match . so instead of being mr one it would be mrm zero one . but don't think that 's big deal .
F: fine . fine .
B: so for the meetings we were thinking about three letters and three numbers for meeting ds . for speakers , or and then three numbers , for , and , , that also brings up the point that we have to start assembling speaker database so that we get those links back and forth and keep it consistent . and then , , the microphone issues . we want some way of specifying , more than looking in the "" key "" file , what channel and what mike . what channel , what mike , and what broadcaster . or how to say it . so with this one it 's this particular headset with this particular transmitter as wireless . and that one is different headset and different channel . and so we just need some naming conventions on that . that 's gonna become especially important once we start changing the microphone set - up . we have some new microphones that 'd like to start trying out , once test them . and then we 'll we 'll need to specify that somewhere . so was just gonna do fixed list of , , microphones and types . so , as said
G: that sounds good .
A: since we have such short agenda list wi will ask how are the transcriptions going ?
F: the the news is that 've so 've switched to start my new sentence . switched to doing the channel - by - channel transcriptions to provide , , the , tighter time bins for partly for use in thilo 's work and also it 's of relevance to other people in the project . and , , discovered in the process couple of interesting things , one of them is that , , it seems that there are time lags involved in doing this , using an interface that has so much more complexity to it . and and wanted to maybe ask , , chuck to help me with some of the questions of efficiency . maybe was thinking maybe the best way to do this in the long run may be to give them single channel parts and then piece them together later . and have script , piece them together . so it 's like , know that take them apart and put them together and 'll end up with the representation which is where the real power of that interface is . and it may be that it 's faster to transcribe channel at time with only one , , sound file and one , , set of , , utterances to check through .
A: 'm little confused . that one of the reason we thought we were so much faster than , , the other transcription , , thing was that we were using the mixed file .
F: but , , with the mixed , when you have an overlap , you only have choice of one start and end time for that entire overlap , which means that you 're not tightly , , tuning the individual parts th of that overlap by different speakers . so someone may have only said two words in that entire big chunk of overlap . and for purposes of , , things like so things like training the speech - nonspeech segmentation thing . th - it 's necessary to have it more tightly tuned than that . and and , , is it would be wonderful if , , it 's possible then to use that algorithm to more tightly tie in all the channels after that but , , , 've th the exactly where that 's going at this point . but was experimenting with doing this by hand really do think that it 's wise that we 've had them start the way we have with , , working off the mixed signal , having the interface that doesn't require them to do the ti , the time bins for every single channel at , through the entire interaction . did discover couple other things by doing this though , and one of them is that , once in while backchannel will be overlooked by the transcriber . as you might expect , because when it 's backchannel could happen in very densely populated overlap . and if we 're gonna study types of overlaps , which is what wanna do , an analysis of that , then that really does require listening to every single channel all the way through the entire length for all the different speakers . now , for only four speakers , that 's not gonna be too much time , but if it 's nine speakers , then that that is more time . so it 's li , wondering it 's like this it 's really valuable that thilo 's working on the speech - nonspeech segmentation because maybe , , we can close in on that wi without having to actually go to the time that it would take to listen to every single channel from start to finish through every single meeting .
E: but those backchannels will always be problem . especially if they 're really short and they 're not very loud and so it can it will always happen that also the automatic detection system will miss some of them ,
F: so then , maybe the answer is to , , listen especially densely in places of overlap , just so that they 're they 're not being overlooked because of that , and count on accuracy during the sparser phases . cuz there are large spaces of the that 's good point . there are large spaces where there 's no overlap . someone 's giving presentation , that 's that 's good thought . and , , let 's see , there was one other thing was gonna say . it 's really interesting data to work with , have to say , it 's very enjoyable . really , not problem spending time with these data . and not just because 'm in there . no , it 's real interesting .
A: it 's short meeting . you 're you 're still in the midst of what you 're doing from what you described last time , assume ,
C: haven't results , , yet 'm continue working with the mixed signal now , after the last experience . and and 'm tried to , , adjust the to improve , , an harmonicity , , detector that , , implement . because , , get , , very much harmonics now . harmonic possi possible harmonics , and now 'm 'm trying to find , , some , of of help , , using the energy to distinguish between possible harmonics , and other fre frequency peaks , that , , corres not harmonics . have to talk with with you , with the group , , about the instantaneous frequency , because have , , an algorithm , and , get , results similar results , like , , the paper , , that am following . but , , the rules , , that , , people used in the paper to distinguish the harmonics , is doesn't work . and not that , the way to ob the way to obtain the instantaneous frequency is right , or it 's it 's not right . haven't enough file feeling to to distinguish what happened .
A: 'd like to talk with you about it . if if , if don't have enough time and you wanna discuss with someone else some someone else besides us that you might want to talk to , , might be stephane .
C: talked with stephane and thilo they nnn they they didn't
E: 'm not too experienced with harmonics
C: they think that the experience is not enough to
G: is is this the algorithm where you hypothesize fundamental , and then get the energy for all the harmonics of that fundamental ?
C: no , no it 's no
G: and then hypothesize new fundamental and get the energy
C: no . don't proth process the fundamental . ehm calculate the phase derivate using the fft . the algorithm said that , , if you if you change the the , the - the frequency "" "" , , using the in the instantaneous frequency , you can find , , how , , in several frequencies that proba probably the harmonics , , the errors of peaks the frequency peaks , , move around these , frequency harmonic the frequency of the harmonic . and , , if you if you compare the instantaneous frequency , , of the of the , , continuous , , , filters , that , that , , they used , to to get , , the instantaneous frequency , it probably too , you can find , , that the instantaneous frequency for the continuous , , the output of the continuous filters are very near . and in my case in equal with our signal , it doesn't happened .
A: 'd hafta look at that and think about it . it 's it 's haven't worked with that either the way the simple - minded way suggested was what chuck was just saying , is that you could make sieve . you actually say that here is let 's let 's hypothesize that it 's this frequency or that frequency , maybe you maybe you could use some other cute methods to , , short cut it by , making some guesses , you could make some guesses from , from the auto - correlation but then , given those guesses , try , only looking at the energy at multiples of the of that frequency , and see how much of the take the one that 's maximum .
C: using the energy of the of the multiple of the frequency .
A: of all the harmonics of that . .
G: do you hafta do some , , low - pass filter before you do that ?
C: but , know many people use , , low - pass filter to to get , , the pitch .
A: to get the pitch , yes .
C: to get the pitch , yes .
E: to get the pitch , .
C: but the harmonic , no .
G: but the harmonics are gonna be , what the right word is . they 're gonna be dampened by the , vocal tract , the response of the vocal tract . and so just looking at the energy on those at the harmonics , is that gonna ?
A: this is for ,
G: what you 'd like to do is get rid of the effect of the vocal tract . and just look at the at the signal coming out of the glottis .
A: that 'd be good . but , but that you need to but don't need if you need to get rid of it . that 'd that 'd be but if it 's ess if it 's essential . cuz the main thing is that , , you 're trying wha what are you doing this for ? you 're trying distinguish between the case where there is , where there are more than , where there 's more than one speaker and the case where there 's only one speaker . so if there 's more than one speaker , you 're so you 're not distinguished between voiced and unvoiced , so , if you don't if you don't care about that see , if you also wanna just determine if you also wanna determine whether it 's unvoiced , then you want to look at high frequencies also , because the the fact that there 's more energy in the high frequencies is gonna be an ob obvious cue that it 's unvoiced . other than that as far as the one person versus two persons , it would be primarily low frequency phenomenon . and if you looked at the low frequencies , yes the higher frequencies are gonna there 's gonna be spectral slope . the higher frequencies will be lower energy . but so what . that 's that 's
C: will prepare for the next week , all my results about the harmonicity and will try to come in and to discuss here , because , , haven't enough feeling to many time to understand what happened with the with , , so many peaks , and see the harmonics there many time but , , there are lot of peaks , that , , they are not harmonics . have to discover what is the the best way to to to use them
A: but don't think you can you 're not gonna be able to look at every frame , really really thought that the best way to do it , and 'm speaking with no experience on this particular point , but , my impression was that the best way to do it was however you you 've used instantaneous frequency , whatever . however you 've come up you with your candidates , you wanna see how much of the energy is in that as coppo as opposed to all of the all the total energy . and , , if it 's voiced , so maybe you do need voiced - unvoiced determination too . but if it 's voiced , the fraction of the energy that 's in the harmonic sequence that you 're looking at is relatively low , then it should be then it 's more likely to be an overlap .
C: this this is the idea the idea had to compare the ratio of the energy of the harmonics with the , with the , , total energy in the spectrum and try to get ratio to distinguish between overlapping and speech .
A: but you 're looking you 're looking at let 's take second with this . you 're looking at at the phase derivative , this is this is in in bands ?
C: no , no . it 's it 's the band the band is , , from zero to four kilohertz .
A: and you just take the instantaneous frequency ?
C: used two two method two methods . one , , based on the , ftt . to obtain the or to study the harmonics from the spectrum directly , and to study the energy and the multiples of and another algorithm have is the in the instantaneous frequency , on the fft to to calculate the phase derivate in the time . have two algorithms . but , , in in my opinion the the instantaneous frequency , the the behavior , th it was very interesting . because saw , how the spectrum concentrate , , around the harmonic . when apply the rule , of the in the instantaneous frequency of the ne of the continuous filter in the near filter , the rule that , , people propose in the paper
A: but the instantaneous frequency , wouldn't that give you something more like the central frequency of the , of the where most of the energy is ? does does it why would it correspond to pitch ?
C: when first calculate , , using the fft ,
F: di - digital camera .
C: get the spectrum , all the frequency . obtained the instantaneous frequency . and change the @ @ , instantaneous frequency , here .
A: so you scale you you do scaling along that axis according to instantaneous it 's kinda normalization .
C: use these frequency , the range is different , and the resolution is different . more or less , thing like this . the paper said that , , but , , they used , based in the in the they use hanning window . and , they said that , , if these peak are , , harmonics , are very near , or have to be very near . but , , phh ! and what is the what is the distance . and tried to put different distance , to put difference , length of the window , different front sieve , and not what happened .
A: 'm not following it enough . 'll probably gonna hafta look at the paper , but which 'm not gonna have time to do in the next few days , but 'm 'm curious about it .
F: did it did occur to me that this is , the return to the transcription , that there 's one third thing wanted to ex raise as to as an issue which is , , how to handle breaths . so , wanted to raise the question of whether people in speech recognition want to know where the breaths are . and the reason ask the question is , aside from the fact that they 're very time - consuming to encode , the fact that there was some had the indication from dan ellis in the email that sent to you , that in principle we might be able to , , handle breaths by accessi by using cross - talk from the other things , in principle , maybe we could get rid of them , we had this an and didn't couldn't get back to you , but the question of whether it 'd be possible to eliminate them from the audio signal , which would be the ideal situation ,
A: it 'd be ideal . we - see , we 're we 're dealing with real speech and we 're trying to have it be as real as possible and breaths are part of real speech .
F: except that these are really truly ther there 's segment in the one did the first one that did for for this , where truly we 're hearing you breathing like as if we 're you 're in our ear , and it 's like it 's like breath is natural ,
A: it is but it is if you record it .
F: except that we 're we 're trying to mimic see what you 're saying . you 're saying that the pda application would have , have to cope with breath .
G: an - any application may have to .
B: the might not have to , but more people than just pda users are interested in this corpus . so so mean you 're right
F: then the then have two questions .
B: we could remove it , but we don't wanna remove it from the corpus , in terms of delivering it because the people will want it in there .
F: so maybe the question is notating it .
A: if if it gets in the way of what somebody is doing with it then you might wanna have some method which will allow you to block it , but you it 's real data . you don't wanna but you don't if , if there 's little bit of noise out there , and somebody is talking about something they 're doing , that 's part of what we accept as part of real meeting , we have the the fan and the in the projector up there , and , , this is it 's this is actual that we wanna work with .
F: this is in very interesting because it has it shows very clearly the contrast between , , speech recognition research and discourse research because in discourse and linguistic research , what counts is what 's communit communicative . they breathe all the time . and once in while breath is communicative , but very rarely . so now , had discussion with chuck about the data structure and the idea is that the transcripts will that get stored as master there 'll be master transcript which has in it everything that 's needed for both of these uses . and the one that 's used for speech recognition will be processed via scripts . like , don 's been writing scripts to process it for the speech recognition side . discourse side will have this side over he the we 'll have ch not being very fluent here . this the discourse side will have script which will stri strip away the things which are non - communicative . so then the then let 's think about the practicalities of how we get to that master copy with reference to breaths . so what would what would wonder is would it be possible to encode those automatically ? could we get breath detector ?
B: just to save the transcribers time .
F: , you just have no idea . if you 're getting breath several times every minute , and just simply the keystrokes it takes to negotiate , to put the boundaries in , to type it in , it 's just huge amount of time . and you wanna be it 's used , and you wanna be it 's done as efficiently as possible , and if it can be done automatically , that would be ideal .
A: what if you put it in but didn't put the boundaries ? so you just 's between these other things ,
F: . so now there 's there 's another possibility which is , , the time boundaries could mark off words from nonwords . and that would be extremely time - effective , if that 's sufficient .
A: 'm it 's too if it 's too hard for us to annotate the breaths per se , we are gonna be building up models for these things and these things are somewhat self - aligning , so if so , we if we say there is some thing which we call "" breath "" or "" breath - in "" or "" breath - out "" , the models will learn that thing . so but you do want them to point them at some region where the breaths really are .
F: but that would maybe include pause as ,
G: there 's there 's
F: and that wouldn't be problem to have it , , pause plus breath plus laugh plus sneeze ?
A: there is there 's this dynamic tension between marking everything , as , marking just little bit and counting on the statistical methods . the more we can mark the better . but if there seems to be lot of effort for small amount of reward in some area , and this might be one like this although 'd be interested to get input from liz and andreas on this to see if they cuz they 've - they 've got lots of experience with the breaths in , , their transcripts .
B: they have lots of experience with breathing ?
A: yes they do , but we can handle that without them here . but but , , you were gonna say something about
G: , , one possible way that we could handle it is that , as the transcribers are going through , and if they get hunk of speech that they 're gonna transcribe , th they 're gonna transcribe it because there 's words in there or whatnot . if there 's breath in there , they could transcribe that .
F: that 's what they 've been doing . so , within an overlap segment , they do this .
G: right . but if there 's big hunk of speech , let 's say on morgan 's mike where he 's not talking , , don't don't worry about that . so what we 're saying is , there 's no guarantee that , so for the chunks that are transcribed , everything 's transcribed . but outside of those boundaries , there could have been that wasn't transcribed . so you just somebody can't rely on that data and say "" that 's perfectly clean data "" . do you see what 'm saying ?
F: you 're saying it 's uncharted territory .
G: so would say don't tell them to transcribe anything that 's outside of grouping of words .
A: that sounds like reasonable compromise .
E: and that 's that quite co corresponds to the way try to train the speech - nonspeech detector , as really try to not to detect those breaths which are not within speech chunk but with which are just in silence region . and they so they hopefully won't be marked in those channel - specific files .
A: wanted to comment little more just for clarification about this business about the different purposes . see , in in way this is really key point , that for speech recognition , , research , it 's not just minor part . the would say the core thing that we 're trying to do is to recognize the actual , meaningful components in the midst of other things that are not meaningful . so it 's critical it 's not just incidental it 's critical for us to get these other components that are not meaningful . because that 's what we 're trying to pull the other out of . that 's our problem . if we had nothing if we had only linguistically - relevant things if we only had changes in the spectrum that were associated with words , with different spectral components , and , , we didn't have noise , we didn't have convolutional errors , we didn't have extraneous , , behaviors , and , and moving your head and all these sorts of things , then , actually speech recognition isn't that bad right now . it 's it 's the technology 's come along pretty . the the reason we still complain about it is because is when you have more realistic conditions then things fall apart .
F: , , what was wondering is what at what level does the breathing aspect enter into the problem ? because if it were likely that pda would be able to be built which would get rid of the breathing , so it wouldn't even have to be processed at thi at this computational le let me see , it 'd have to be computationally processed to get rid of it , but if there were , , like likely on the frontier , good breath extractor then , , and then you 'd have to
A: but that 's research question ,
F: , see and that 's what wouldn't know .
A: and we don't either . so it 's it right now it 's just raw it 's just data that we 're collecting , and so we don't wanna presuppose that people will be able to get rid of particular degradations because that 's actually the research that we 're trying to feed . so , , an and maybe in five years it 'll work really , and it 'll only mess - up ten percent of the time , but then we would still want to account for that ten percent ,
F: there 's another aspect which is that as we 've improved our microphone technique , we have lot less breath in the in the more recent , , recordings , so it 's in way it 's an artifact that there 's so much on the on the earlier ones .
G: just to add to this one of the ways that we will be able to get rid of breath is by having models for them . that 's what lot of people do nowadays . and so in order to build the model you need to have some amount of it marked , so that where the boundaries are . don't think we need to worry lot about breaths that are happening outside of , , conversation . we don't have to go and search for them to mark them , but , , if they 're there while they 're transcribing some hunk of words , 'd say put them in if possible .
F: and it 's also the fact that they differ lot from one channel to the other because of the way the microphone 's adjusted .
A: should we do the digits ?
D: mmm . alright .
","Topics discussed by the Berkeley Meeting Recorder group included the status of the first test set of digits data , naming conventions for files , speaker identification tags , and encoding files with details about the recording.
The group also discussed a proposal for a grant from the NSF's ITR ( Information Technology Research ) program , transcriptions , and efforts by speaker mn005 to detect speaker overlap using harmonicity-related features.
Particular focus was paid to questions about transcription procedures , i.e . how to deal with overlooked backchannels , and audible breaths.
A small percentage of transcripts will be changed to reflect mis-read , uncorrected digits.
A speaker database will be compiled to establish consistent links between speakers and their corresponding identification tags.
Sections of densely overlapping speech will require hand-checking so that overlooked backchannels may be manually segmented and labelled.
The transcribers should only code audible breaths within a grouping of words , and not outside regions of continuous speech.
It was further determined that audible breaths are an important facet of recorded speech , and that removing them from the corpus would be contrary to the aims of the project.
Speaker mn005 will prepare his results for detecting speaker overlap and present them in the next meeting.
During digits readings , subjects tend to chunk numbers together rather than reading each number separately.
When working from the mixed channel , transcribers may select only one start and end time for overlapping speech , resulting in points of overlap that are less tightly tuned.
Transcribers are likely to overlook backchannels in densely populated sections of speaker overlap.
Speaker mn014 reported that this is also problematic for the automatic detection of speech and non-speech , as backchannels that are very short and not loud enough will inevitably be overlooked.
Speaker mn005 reported problems distinguishing between possible harmonics and other frequency peaks , and creating an algorithm for obtaining the instantaneous frequency.
The encoding of all audible breaths is too time-consuming.
The first test set of digits is complete and includes 4,000 lines , each comprising between 1-10 digits.
New digits forms were distributed for eliciting different prosodic groupings of numbers.
New naming conventions were discussed as means for facilitating the sorting process.
Existing files will be changed so that all filenames are of equal length.
Similar changes will be made to speaker identification tags.
Files will also contain information specifying channel , microphone , and broadcaster information.
A proposal is being drafted for a grant from the NSF's ITR program for extending the research initiatives of the Meeting Recorder project.
Speaker fe008 is performing channel-by-channel transcriptions to create tighter time bins.
Tentative plans are to assign single channels to the transcriber pool and then piece them together afterwards.
Efforts by speaker mn005 are in progress to detect speaker overlap in the mixed signal using harmonicity-related features.
For determining the instantaneous frequency , speaker me013 recommended deriving the maxima from energy multiples of a given frequency.
It was also suggested that speaker mn005 should determine whether portions of the signal are voiced or unvoiced , as voiced intervals reflecting a relatively low fraction of energy in the harmonic sequence are likely to indicate sections of overlap.
"
ami_abstractive_summary,Bro023.txt,"A: we 're going .
C: and hans - , hans - guenter will be here , , by next tuesday or so . so he 's he 's going to be here for about three weeks ,
A: just for visit ?
C: we 'll see . we might end up with some longer collaboration . so he 's gonna look in on everything we 're doing and give us his thoughts . and so it 'll be another good person looking at things .
E: th - that 's his spectral subtraction group ? is that right ? so should probably talk to him bit too ?
C: no , he 'll be around for three weeks . he 's , , , very , easygoing , easy to talk to , and , , very interested in everything .
B: we met him in amsterdam .
C: he 's been here before . he 's he 's he 's
A: wh - back when was grad student he was here for , year or six months .
B: haven't noticed him .
A: something like that .
C: something like that . he 's he 's done couple stays here .
A: so , , we got lots to catch up on . and we haven't met for couple of weeks . we didn't meet last week , morgan . went around and talked to everybody , and it seemed like they had some new results but rather than them coming up and telling me figured we should just week and they can tell both , all of us . why don't we why don't we start with you , dave , and then , , we can go on .
E: so , , since we 're looking at putting this , mean log magnitude spectral subtraction , , into the smartkom system , did test seeing if , , it would work using past only and plus the present to calculate the mean . so , did test , , where used twelve seconds from the past and the present frame to , , calculate the mean .
A: twelve twelve seconds back from the current frame , is that what you mean ?
E: twelve seconds , , counting back from the end of the current frame , so it was , , twen it was twenty - one frames and that worked out to about twelve seconds . and compared to , , do using twelve second centered window , there was drop in performance but it was just slight drop . is is that right ?
C: , it was pretty it was pretty tiny .
E: so that was encouraging . that , that 's encouraging for the idea of using it in an interactive system like and , , another issue 'm 'm thinking about is in the smartkom system . so say twe twelve seconds in the earlier test seemed like good length of time , but what happens if you have less than twelve seconds ? so bef before , back in may , did some experiments using , say , two seconds , or four seconds , or six seconds . in those trained the models using mean subtraction with the means calculated over two seconds , or four seconds , or six seconds . here , was curious , what if trained the models using twelve seconds but gave it situation where the test set was subtracted using two seconds , or four seconds , or six seconds . so did that for about three different conditions . th it was , , four se it was , , something like four seconds and , , six seconds , and eight seconds . something like that . and it seems like it it hurts compared to if you actually train the models using th that same length of time but it doesn't hurt that much . usually less than point five percent , although did see one where it was point eight percent or so rise in word error rate . but this is , , where , , even if train on the , , model , and mean subtracted it with the same length of time as in the test , it the word error rate is around , , ten percent or nine percent . so it doesn't seem like that big difference .
C: but it but looking at it the other way , isn't it what you 're saying that it didn't help you to have the longer time for training , if you were going to have short time for
E: that that 's true .
C: why would you do it , if you knew that you were going to have short windows in testing .
A: it seems like for your , in normal situations you would never get twelve seconds of speech ,
B: you need twelve seconds in the past to estimate , right ? or or you 're looking at six sec seconds in future and six in
C: no , total .
E: for the test it 's just twelve seconds in the past .
B: no , it 's all
A: is this twelve seconds of , regardless of speech or silence ? or twelve seconds of speech ?
E: of of speech .
C: the other thing , , which maybe relates little bit to something else we 've talked about in terms of windowing and so on is , that , , wonder if you trained with twelve seconds , and then when you were two seconds in you used two seconds , and when you were four seconds in , you used four seconds , and when you were six and you build up to the twelve seconds . so that if you have very long utterances you have the best , but if you have shorter utterances you use what you can .
E: and that 's actually what we 're planning to do in so so the que the question was trying to get at with those experiments is , "" does it matter what models you use ? does it matter how much time you use to calculate the mean when you were , , tra doing the training data ? ""
C: but the other thing is that 's the other way of looking at this , going back to , , mean cepstral subtraction versus rasta things , is that you could look at mean cepstral subtraction , especially the way you 're doing it , , as being filter . and so , the other thing is just to design filter . you 're you 're doing high - pass filter or band - pass filter of some sort and just design filter . and then , , filter will have certain behavior and you loo can look at the start up behavior when you start up with nothing . and and , , it will , , if you have an iir filter , it will , , , not behave in the steady - state way that you would like it to behave until you get long enough period , by just constraining yourself to have your filter be only subtraction of the mean , you 're , , tying your hands behind your back because there 's filters have all sorts of be temporal and spectral behaviors . and the only thing , , consistent that we know about is that you want to get rid of the very low frequency component .
B: but do you really want to calculate the mean ? and you neglect all the silence regions or you just use everything that 's twelve seconds ,
E: you do you mean in my tests so far ? most of the silence has been cut out . just there 's just inter - word silences .
B: and they are , like , pretty short . so you really need lot of speech to estimate the mean of it .
E: if only use six seconds , it still works pretty . saw in my test before . was trying twelve seconds cuz that was the best in my test before and that increasing past twelve seconds didn't seem to help . it 's something need to play with more to decide how to set that up for the smartkom system . like , may maybe if trained on six seconds it would work better when only had two seconds or four seconds , and
C: , if you take this filtering perspective and if you essentially have it build up over time . if you computed means over two and then over four , and over six , essentially what you 're getting at is , , ramp up of filter anyway . and so you may just want to think of it as filter . but , , if you do that , then , , in practice somebody using the smartkom system , one would they 're using it for while , it means that their first utterance , instead of , , getting , , forty percent error rate reduction , they 'll get , over what , , you 'd get without this , , , policy , , you get thirty percent . and then the second utterance that you give , they get the full , , full benefit of it if it 's this ongoing thing .
A: so you cache the utterances ? that 's how you get your ,
C: 'm saying in practice , , that 's if somebody 's using system to ask for directions , they 'll say something first . and and to begin with if it doesn't get them quite right , ma maybe they 'll come back and say , "" excuse me ? "" it should have some policy like that anyway . and and , , in any event they might ask second question . and it 's not like what he 's doing doesn't , , improve things . it does improve things , just not as much as he would like . and so , , there 's higher probability of it making an error , , in the first utterance .
A: what would be really is if you could have this probably users would never like this but if you had could have system where , before they began to use it they had to introduce themselves , verbally . my name is so - and - so , 'm from blah - blah . "" and you could use that initial speech to do all these adaptations
C: the other thing which , much about as much as should about the rest of the system couldn't you , , if you if you did first pass what , , capability we have at the moment for doing second passes on , , some little small lattice , or graph , or confusion network , . but if you did first pass with , , the with either without the mean sub subtraction or with very short time one , and then , , once you , , actually had the whole utterance in , if you did , , the , , longer time version then , based on everything that you had , , and then at that point only used it to distinguish between , , top , , possible utterances , you might it might not take very much time . the large vocabulary stu , systems , people were evaluating on in the past , some people really pushed everything in to make it in one pass but other people didn't and had multiple passes . the argument , , against multiple passes was has often been "" but we want to this to be have interactive response "" . and the counterargument to that which , say , , bbn had , was "" , but our second responses are second , , passes and third passes are really , really fast "" . so , , if your second pass takes millisecond who cares ?
E: the idea of the second pass would be waiting till you have more recorded speech ?
C: so if it turned out to be problem , that you didn't have enough speech because you need longer window to do this processing , then , , one tactic is , looking at the larger system and not just at the front - end is to take in , , the speech with some simpler mechanism or shorter time mechanism , do the best you can , and come up with some al possible alternates of what might have been said . and , , either in the form of an - best list or in the form of lattice , or confusion network , or whatever . and then the decoding of that is much , much faster or can be much , much faster if it isn't big bushy network . and you can decode that now with speech that you 've actually processed using this longer time , , subtraction . so , it 's it 's common that people do this thing where they do more things that are more complex or require looking over more time , whatever , in some second pass . , if the second pass is really , really fast , another one 've heard of is in connected digit , , going back and and through backtrace and finding regions that are considered to be digit , but , , which have very low energy . so , , there 's lots of things you can do in second passes , sorts of levels . anyway , 'm throwing too many things out .
A: so is that , that it ?
E: that 's it .
A: do you wanna go , sunil ?
B: the last two weeks was , like so 've been working on that wiener filtering . found that , , single like , do normal wiener filtering , like the standard method of wiener filtering . and that doesn't actually give me any improvement over like , it actually improves over the baseline but it 's not like it doesn't meet something like fifty percent . so , 've been playing with the
A: improves over the base line mfcc system ?
B: so that 's the improvement is somewhere around , like , thirty percent over the baseline .
C: is that using in combination with something else ?
B: just one stage wiener filter which is standard wiener filter .
C: no , no , but in combination with our on - line normalization or with the lda ?
B: so plug in the wiener filtering . in the in our system , where so , di di
C: so , does it does that mean it gets worse ?
B: it actually improves over the baseline of not having wiener filter in the whole system . like have an lda lda plus on - line normalization , and then plug in the wiener filter in that , so it improves over not having the wiener filter . but it doesn't take it like be beyond like thirty percent over the baseline .
C: but that 's what 'm confused about , cuz that our system was more like forty percent without the wiener filtering .
B: it 's like , ,
A: is this with the new vad ?
B: no , it 's the old vad . so my baseline was , , nine this is like the baseline is ninety - five point six eight , and eighty - nine , and
C: so , if you can do all these in word errors it 's lot lot easier actually .
B: what was that ?
C: if you do all these in word error rates it 's lot easier , right ?
B: errors , right , don't have .
C: cuz then you can figure out the percentages .
B: it 's all accuracies .
D: the baseline is something similar to the the baseline that you are talking about is the mfcc baseline , right ?
B: there are two baselines . so the baseline one baseline is mfcc baseline that when said thirty percent improvement it 's like mfcc baseline .
C: so what 's it start on ? the mfcc baseline is what ? is at what level ?
B: it 's just the mel frequency and that 's it .
C: no , what 's what 's the number ?
B: so don't have that number here . have it here . it 's the vad plus the baseline actually . 'm talking about the mfcc plus do frame dropping on it . so that 's like the word error rate is like four point three . like ten point seven .
C: four point three . what 's ten point seven ?
B: it 's medium misma there 's ma matched , medium mismatched , and high matched . so don't have the like the
C: four point three , ten point seven ,
B: forty percent is the high mismatch . and that becomes like four point three it 's like ten point one . still the same . and the high mismatch is like eighteen point five .
C: eighteen point five . and what were you just describing ?
B: the one is this one is just the baseline plus the , , wiener filter plugged into it .
C: but where 's the , , on - line normalization and so on ?
B: so , with the with the on - line normalization , the performance was , , ten so it 's like four point three . that 's the ba the ten point , , four and twenty point one . that was with on - line normalization and lda . so the matched has like literally not changed by adding on - line or lda on it . even the medium mismatch is the same . and the high mismatch was improved by twenty percent absolute .
C: an and what are we talking about here ?
B: it 's the it - it 's italian .
C: is this ti - digits
B: 'm talking about italian ,
C: so , what was the , , , corresponding number , say , for , , , the alcatel system ?
D: so it looks to be ,
B: you have it ?
D: it 's three point four , eight point , , seven , and , , thirteen point seven .
B: this is the single stage wiener filter , with the noise estimation was based on first ten frames . actually started with using the vad to estimate the noise and then found that it works it doesn't work for finnish and spanish because the vad endpoints are not good to estimate the noise because it cuts into the speech sometimes , so end up overestimating the noise and getting worse result . so it works only for italian by for using vad to estimate noise . it works for italian because the vad was trained on italian . so this was , and so this was giving this was like not improving lot on this baseline of not having the wiener filter on it . ran this with one more stage of wiener filtering on it but the second time , what did was estimated the new wiener filter based on the cleaned up speech , and did , , smoothing in the frequency to reduce the variance have 've observed there are , like , lot of bumps in the frequency when do this wiener filtering which is more like musical noise . and so by adding another stage of wiener filtering , the results on the speechdat - car was like , so , still don't have the word error rate . 'm about it . but the overall improvement was like fifty - six point four six . this was again using ten frames of noise estimate and two stage of wiener filtering . and the rest is like the lda plu and the on - line normalization all remaining the same . so this was , like , compared to , fifty - seven is what you got by using the french telecom system ,
D: no , don't . is it on italian ?
B: this is over the whole speechdat - car .
D: , fifty - seven
B: so the new the new wiener filtering schema is like some fifty - six point four six which is like one percent still less than what you got using the french telecom system .
C: but it 's pretty similar number in any event .
B: it 's very similar .
C: but again , you 're you 're more or less doing what they were doing ,
B: it 's it 's different in sense like 'm actually cleaning up the cleaned up spectrum which they 're not doing . they 're what they 're doing is , they have two stage stages of estimating the wiener filter , but the final filter , what they do is they take it to their time domain by doing an inverse fourier transform . and they filter the original signal using that fil filter , which is like final filter is acting on the input noisy speech rather than on the cleaned up . so this is more like 'm doing wiener filter twice , but the only thing is that the second time 'm actually smoothing the filter and then cleaning up the cleaned up spectrum first level . and so that 's that 's what the difference is . and actually tried it on the original clean , the original spectrum where , like , the second time estimate the filter but actually clean up the noisy speech rather the first output of the first stage and that doesn't seems to be giving , , that much improvement . didn't run it for the whole case . and what what tried was , by using the same thing so we actually found that the vad is very , like , crucial . just by changing the vad itself gives you the lot of improvement by instead of using the current vad , if you just take up the vad output from the channel zero , when instead of using channel zero and channel one , because that was the that was the reason why was not getting lot of improvement for estimating the noise . so used the channel zero vad to estimate the noise so that it gives me some reliable mar markers for this noise estimation .
C: what 's channel zero vad ? 'm 'm confused about that .
B: so , it 's like
D: so it 's the close - talking microphone .
B: the close - talking without so because the channel zero and channel one are like the same speech , but only , the same endpoints . but the only thing is that the speech is very noisy for channel one , so you can actually use the output of the channel zero for channel one for the vad . that 's like cheating method .
C: so are they going to pro what are they doing to do , do we know yet ? about as far as what they 're what the rules are going to be and what we can use ?
D: so actually received new document , describing this . and what they did finally is to , mmm , , not to align the utterances but to perform recognition , only on the close - talking microphone ,
B: which is the channel zero .
D: and to take the result of the recognition to get the boundaries , of speech .
C: so it 's not like that 's being done in one place or one time . that 's that 's just rule and we 'd you were permitted to do that . is is that it ?
D: they will send , , files but we don't ,
C: so they will send files so everybody will have the same boundaries to work with ?
B: but actually their alignment actually is not seems to be improving in like on all cases .
D: so what happened here is that , , the overall improvement that they have with this method so , to be more precise , what they have is , they have these alignments and then they drop the beginning silence and the end silence but they keep , , two hundred milliseconds before speech and two hundred after speech . and they keep the speech pauses also . and the overall improvement over the mfcc baseline so , when they just , , add this frame dropping in addition it 's , forty percent , right ? fourteen percent , . which is the overall improvement . but in some cases it doesn't improve . like , , do you remember which case ?
B: it gives like negative , in like some italian and ti - digits ,
D: some @ @ .
B: so by using the endpointed speech , actually it 's worse than the baseline in some instances , which could be due to the word pattern .
D: and , the other thing also is that fourteen percent is less than what you obtain using real vad . so with without cheating like this . so this shows that there is still work , working on the vad is still important .
A: can ask just high level question ? can you just say like one or two sentences about wiener filtering and why are people doing that ? what 's what 's the deal with that ?
B: the wiener filter , it 's it 's like you try to minimize so the basic principle of wiener filter is like you try to minimize the , , , difference between the noisy signal and the clean signal if you have two channels . like let 's say you have clean signal and you have an additional channel where what is the noisy signal . and then you try to minimize the error between these two . so that 's the basic principle . you can do that if you have only noisy signal , at level which you , you try to estimate the noise from the assuming that the first few frames are noise or if you have voice activity detector , , you estimate the noise spectrum .
A: do you assume the noise is the same ?
B: in , after the speech starts . but that 's not the case in , , many of our cases but it works reasonably . and and then you what you do is you , write down some of these eq and then you do this this is the transfer function of the wiener filter , so "" sf "" is clean speech spectrum , power spectrum and "" "" is the noisy power spectrum . and so this is the transfer function . and then you multiply your noisy power spectrum with this . you get an estimate of the clean power spectrum . but that you have to estimate the sf from the noisy spectrum , what you have . so you estimate the nf from the initial noise portions and then you subtract that from the current noisy spectrum to get an estimate of the sf . so sometimes that becomes zero because you do you don't have true estimate of the noise . so the filter will have like sometimes zeros in it because some frequency values will be zeroed out because of that . and that creates lot of discontinuities across the spectrum because @ @ the filter . so that 's what that was just the first stage of wiener filtering that tried .
A: so is this , , , similar to just regular spectral subtraction ?
C: it 's all pretty related , it 's it 's there 's di there 's whole class of techniques where you try in some sense to minimize the noise . and it 's typically mean square sense , , in in some way . and , , spectral subtraction is , , one approach to it .
A: do people use the wiener filtering in combination with the spectral subtraction typically , or is are they competing techniques ?
B: they are very similar techniques . so it 's like haven't seen anybody using wiener filter with spectral subtraction .
C: in the long run you 're doing the same thing but but there you make different approximations , and in spectral subtraction , , there 's an estimation factor . you sometimes will figure out what the noise is and you 'll multiply that noise spectrum times some constant and subtract that even though this really should be in the power domain , sometimes people work in the magnitude domain because it it works better . and , , .
A: so why did you choose , , wiener filtering over some other one of these other techniques ?
B: the reason was , like , we had this choice of using spectral subtraction , wiener filtering , and there was one more thing which 'm trying , is this sub space approach . stephane is working on spectral subtraction .
A: so you 're trying @ @ them all .
B: we just wanted to have few noise production compensation techniques and then pick some from that
C: , there 's car - carmen 's working on another , on the vector taylor series .
B: va , vad .
C: so they were just trying to cover bunch of different things with this task and see , , what are what are the issues for each of them .
A: that makes sense .
B: so one of one of the things that tried , like said , was to remove those zeros in the fri filter by doing some smoothing of the filter . like , you estimate the edge of square and then you do smoothing across the frequency so that those zeros get , like , flattened out . and that doesn't seems to be improving by trying it on the first time . so what did was like did this and then you plugged in the one more the same thing but with the smoothed filter the second time . and that seems to be working . so that 's where got like fifty - six point five percent improvement on speechdat - car with that . so the other thing what tried was used still the ten frames of noise estimate but used this channel zero vad to drop the frames . so 'm not still not estimating . and that has taken the performance to like sixty - seven percent in speechdat - car , which is which like shows that by using proper vad you can just take it to further , better levels .
A: so that 's like , , best - case performance ?
B: so far 've seen sixty - seven haven't seen like sixty - seven percent . using the channel zero vad to estimate the noise also seems to be improving but don't have the results for all the cases with that . so used channel zero vad to estimate noise as lesser 2 frame , which is like , everywhere use the channel zero vad . and that seems to be the best combination , , rather than using few frames to estimate and then drop channel .
C: so 'm 'm still little confused . is that channel zero information going to be accessible during this test .
B: this is just to test whether we can really improve by using better vad . so this is like the noise compensation is fixed but you make better decision on the endpoints . that 's , like seems to be so , which means , like , by using this technique what we improve just the vad we can just take the performance by another ten percent or better . so , that was just the , , reason for doing that experiment . but this all these things , have to still try it on the ti - digits , which is like 'm just running . and there seems to be not improving lot on the ti - digits , so 'm like investigating that , why it 's not . so the other the other thing is like 've been 'm doing all this on the power spectrum . tried this on the mel as mel and the magnitude , and mel magnitude , and all those things . but it seems to be the power spectrum seems to be getting the best result . so , one of one of reasons like doing the averaging , after the filtering using the mel filter bank , that seems to be maybe helping rather than trying it on the mel filter ba filtered outputs . th that 's that 's the only thing that could think of why it 's giving improvement on the mel . so that 's it .
C: how about the subspace ?
B: subspace , 'm 'm like that 's still in little bit in the back burner because 've been putting lot effort on this to make it work , on tuning things and other . was like going parallely but not much of improvement . 'm just have some skeletons ready , need some more time for it .
A: tha - that it ? do you wanna go , stephane ?
D: so , 've been , , working still on the spectral subtraction . so to to remind you little bit of what did before , is just to apply some spectral subtraction with an overestimation factor also to get , , an estimate of the noise , , spectrum , and subtract this estimation of the noise spectrum from the , , signal spectrum , but subtracting more when the snr is , , low , which is technique that it 's often used .
A: "" subtracting more "" , meaning ?
D: so you overestimate the noise spectrum . you multiply the noise spectrum by factor , , which depends on the snr . so , above twenty db , it 's one , so you just subtract the noise . and then it 's generally , use , actually , linear , , function of the snr , which is bounded to , like , two or three , when the snr is below zero db . doing just this , , either on the fft bins or on the mel bands , , doesn't yield any improvement
C: , what are you doing with negative , , powers ?
D: so there is also threshold , , because after subtraction you can have negative energies , so what do is to put , to add to put the threshold first and then to add small amount of noise , which right now is speech - shaped .
A: speech - shaped ?
D: so it 's it has the overall energy , it has the overall power spectrum of speech . so with bump around one kilohertz .
A: so when when you talk about there being something less than zero after subtracting the noise , is that at particular frequency bin ?
D: there can be frequency bins with negative values .
A: and so when you say you 're adding something that has the overall shape of speech , is that in in particular frequency bin ? or you 're adding something across all the frequencies when you get these negatives ?
D: for each frequencies 'm adding some , , noise , but the the amount of the amount of noise add is not the same for all the frequency bins . right now don't it makes sense to add something that 's speech - shaped , because then you have silence portion that have some spectra similar to the sp the overall speech spectra . so this is something still work on ,
A: so what does that mean ? 'm trying to understand what it means when you do the spectral subtraction and you get negative . it means that at that particular frequency range you subtracted more energy than there was actually
D: so so , you have an estimation of the noise spectrum , but sometimes , , it 's as the noise is not perfectly stationary , sometimes this estimation can be , , too small , so you don't subtract enough . but sometimes it can be too large also . if if the noise , , energy in this particular frequency band drops for some reason .
A: so in an ideal word world if the noise were always the same , then , when you subtracted it the worst that you would get would be zero . the lowest you would get would be zero , cuz if there was no other energy there you 're just subtracting exactly the noise .
C: there 's all there 's all sorts of , , deviations from the ideal here . , you 're you 're talking about the signal and noise , , at particular point . and even if something is stationary in ster terms of statistics , there 's no guarantee that any particular instantiation or piece of it is exactly particular number or bounded by particular range . so , you 're figuring out from some chunk of of the signal what you think the noise is . then you 're subtracting that from another chunk , and there 's no reason to think that you 'd know that it wouldn't , , be negative in some places . on the other hand that just means that in some sense you 've made mistake because you certainly have stra subtracted bigger number than is due to the noise . also , we speak the whole where all this comes from is from an assumption that signal and noise are uncorrelated . and that certainly makes sense in in statistical interpretation , that , , over , , all possible realizations that they 're uncorrelated or assuming , , ergodicity that , across time , , it 's uncorrelated . but if you just look at quarter second , , and you cross - multiply the two things , , you could very , , end up with something that sums to something that 's not zero . so , the two signals could have some relation to one another . and so there 's all sorts of deviations from ideal in this . and and given all that , you could definitely end up with something that 's negative . but if down the road you 're making use of something as if it is power spectrum , , then it can be bad to have something negative . now , the other thing wonder about actually is , what if you left it negative ?
B: is that the log ?
C: are you taking the log before you add them up to the mel ? so , wonder how if you put your thresholds after that , wonder how often you would end up with , with negative values .
B: but you end up reducing some neighboring frequency bins @ @ in the average , right ? when you add the negative to the positive value which is the true estimate .
C: but nonetheless , , , these are it 's another smoothing , right ? that you 're doing . so , you 've done your best shot at figuring out what the noise should be , and now then you 've subtracted it off . and then after that , instead of instead of , , leaving it as is and adding things adding up some neighbors , you artificially push it up . which is , , it 's there 's no particular reason that 's the right thing to do either , what you 'd be doing is saying , "" , we 're we 're we 're going to definitely diminish the effect of this frequency in this little frequency bin in the in the overall mel summation "" . it 's just thought . if it would be
A: the opposite of that would be if you find out you 're going to get negative number , you don't do the subtraction for that bin .
B: that is true .
A: that would be almost the opposite , instead of leaving it negative , you don't do it . if your if your subtraction 's going to result in negative number , you don't do subtraction in that .
C: but that means that in situation where you thought that the bin was almost entirely noise , you left it .
A: 'm just saying that 's like the opposite .
C: that 's that 's the opposite ,
D: some people also if it 's negative value they , , re - compute it using inter interpolation from the edges and bins .
B: for frames , frequency bins .
D: there are different things that you can do .
C: people can also , , reflect it back up and essentially do full wave rectification instead of instead of half wave . but it was just thought that it might be something to try .
D: actually tried , something else based on this , , is to put some smoothing , because it seems to help or it seems to help the wiener filtering so what did is , , some nonlinear smoothing . actually have recursion that computes let me go back little bit . actually , when you do spectral subtraction you can , , find this equivalent in the in the spectral domain . you can compute , you can say that your spectral subtraction is filter , and the gain of this filter is the , , signal energy minus what you subtract , divided by the signal energy . and this is gain that varies over time , and , , , , depending on the on the noise spectrum and on the speech spectrum . what happen actually is that during low snr values , the gain is close to zero but it varies lot . and this is the of musical noise and all these the fact you we go below zero one frame and then you can have an energy that 's above zero . so the smoothing is did smoothing actually on this gain , , trajectory . but it 's the smoothing is nonlinear in the sense that tried to not smooth if the gain is high , because in this case we know that , , the estimate of the gain is correct because we are not close to to zero , and to do more smoothing if the gain is low . that 's this idea , and it seems to give pretty good results , although 've just tested on italian and finnish . and on italian it seems my result seems to be little bit better than the wiener filtering ,
B: the one you showed yesterday .
D: if you have these improvement the detailed improvements for italian , finnish , and spanish there
B: no , don't have , for each ,
D: or you have just have your own .
B: have the final number here .
C: so these numbers he was giving before with the four point three , and the ten point one , and , those were italian , right ?
B: so so , no , actually didn't give you the number which is the final one , which is , after two stages of wiener filtering . that was , like the overall improvement is like fifty - six point five . his number is still better than what got in the two stages of wiener filtering .
D: but on finnish it 's little bit worse , .
C: but do you have numbers in terms of word error rates on italian ? so just so you have some sense of reference ?
D: so , it 's , , three point , , eight . and then , , , nine point , , one . and finally , , sixteen point five .
C: and this is , , spectral subtraction plus what ?
D: plus plus nonlinear smoothing . it 's the system it 's exactly the sys the same system as sunil tried ,
C: on - line normalization and lda ?
D: but instead of double stage wiener filtering , it 's it 's this smoothed spectral subtraction .
A: what is it the , , france telecom system uses for do they use spectral subtraction , or wiener filtering ,
B: they use spectral subtraction ,
D: it it 's wiener filtering ,
B: it 's it 's wiener filtering .
D: it 's some wiener filtering
B: it 's not exactly wiener filtering but some variant of wiener filtering .
C: plus , , they have some cepstral normalization , as .
B: th the just noise compensation technique is variant of wiener filtering , plus they do some smoothing techniques on the final filter . the th they actually do the filtering in the time domain . so they would take this hf squared back , taking inverse fourier transform . and they convolve the time domain signal with that . and they do some smoothing on that final filter , impulse response .
D: but they also have two different smoothing @ @ .
B: 'm 'm @ @ .
D: one in the time domain and one in the frequency domain by just taking the first , , coefficients of the impulse response . so , it 's similar . what you did , it 's similar
B: it 's similar in the smoothing
D: because you have also two smoothing . one in the time domain , and one in the frequency domain ,
B: the frequency domain .
A: does the smoothing in the time domain help do you get this musical noise with wiener filtering or is that only with , , spectral subtraction ?
B: no , you get it with wiener filtering also .
A: does the smoothing in the time domain help with that ? or some other smoothing ?
B: you still end up with zeros in the spectrum .
C: it 's not clear that these musical noises hurt us in recognition . we if they do . they sound bad . but we 're not listening to it , usually .
D: actually the smoothing that did do here reduced the musical noise . not you cannot hear beca actually what did not say is that this is not in the fft bins . this is in the mel frequency bands . it could be seen as smoothing in the frequency domain because used , in ad mel bands in addition and then the other phase of smoothing in the time domain . but , when you look at the spectrogram , if you don't have an any smoothing , you clearly see , like in silence portions , and at the beginning and end of speech , you see spots of high energy randomly distributed over the spectrogram .
A: that 's the musical noise ?
D: which is musical noise , if it if you listen to it if you do this in the fft bins , then you have spots of energy randomly distributing . and if you if you re - synthesize these spot sounds as , like , sounds ,
C: none of these systems , , have , you both are working with , , our system that does not have the neural net , so one would hope , presumably , that the neural net part of it would improve things further as they did before .
D: although if we , , look at the result from the proposals , one of the reason , , the system with the neural net was , , more than , around five percent better , is that it was much better on highly mismatched condition . 'm thinking , , on the ti - digits trained on clean speech and tested on noisy speech . for this case , the system with the neural net was much better . but not much on the in the other cases . if we have no , , spectral subtraction or wiener filtering , , the system is , we thought the neural network is much better than before , even in these cases of high mismatch . so , maybe the neural net will help less
A: could you train neural net to do spectral subtraction ?
C: it could do nonlinear spectral subtraction you have to figure out what your targets are .
A: was thinking if you had clean version of the signal and noisy version , and your targets were the - , , whatever , frequency bins
C: , that 's not so much spectral subtraction then , but but it 's but at any rate , , people ,
A: people do that ?
C: we had visitors here who did that when you were here ba way back when . people done lots of experimentation over the years with training neural nets . and it 's not bad thing to do . it 's another approach . it 's it , the objection everyone always raises , which has some truth to it is that , , it 's good for mapping from particular noise to clean but then you get different noise . and the experiments we saw that visitors did here showed that it there was at least some , , gentleness to the degradation when you switched to different noises . it did seem to help . so that you 're right , that 's another way to go .
A: how did it compare on , for good cases where it , that it was trained on ? did it do pretty ?
C: it did very . but to some extent that 's what we 're doing . we 're not doing exactly that , we 're not trying to generate good examples but by trying to do the best classifier you possibly can , for these little phonetic categories ,
A: you could say it 's built in .
C: it 's built into that . and and that 's why we have found that it does help . , we 'll just have to try it . but would would imagine that it will help some . it we 'll just have to see whether it helps more or less the same , but would imagine it would help some . so in any event , all of this was just confirming th of this was with simpler system .
D: so this is th the , actually , this was the first try with this spectral subtraction plus smoothing , and was excited by the result . then started to optimize the different parameters . the first thing tried to optimize is the , , time constant of the smoothing . and it seems that the one that chose for the first experiment was the optimal one ,
C: it 's amazing how often that happens .
D: so this is the first thing . another thing that it 's important to mention is , , that this has this has some additional latency . because when do the smoothing , , it 's recursion that estimated the means , so of the of the gain curve . this is filter that has some latency . and noticed that it 's better if we take into account this latency . so , instead of using the current estimated mean to , , subtract the current frame , it 's better to use an estimate that 's some somewhere in the future .
A: and that 's what causes the latency ?
B: you mean , the the mean is computed based on some frames in the future also ? or or no ?
D: it 's the recursion , so it 's it 's the center recursion , and the latency of this recursion is around fifty milliseconds .
B: why is that delay coming ? like , you estimate the mean ?
D: the mean estimation has some delay , the filter that estimates the mean has time constant .
B: so it 's like it looks into the future also .
C: what if you just look into the past ?
D: it 's , , not as good . it 's not bad .
C: how by how much ?
D: it helps lot over the ba the baseline
C: by how much ?
D: it 's around three percent , , relative .
C: it 's depending on how all this comes out we may or may not be able to add any latency .
D: so , , it depends . actually , it 's it 's it 's three percent . but don't think we have to worry too much on that right now while you kno .
C: , the only thing is that would worry about it little . because if we completely ignore latency , and then we discover that we really have to do something about it , we 're going to be find ourselves in bind . maybe you could make it twenty - five . just , , just be little conservative because we may end up with this crunch where all of sudden we have to cut the latency in half .
D: there are other things in the , , algorithm that didn't , , @ @ lot yet ,
A: quick question just about the latency thing . if if there 's another part of the system that causes latency of hundred milliseconds , is this an additive thing ? or or is yours hidden in that ?
D: it 's it 's added .
A: it 's additive .
B: we can do something in parallel also , in some like some cases like , if you wanted to do voice activity detection . and we can do that in parallel with some other filtering you can do . so you can make decision on that voice activity detection and then you decide whether you want to filter or not . but by then you already have the sufficient samples to do the filtering . so , sometimes you can do it anyway .
A: couldn't you just also , if that the the largest latency in the system is two hundred milliseconds , don't you couldn't you just buffer up that number of frames and then everything uses that buffer ? and that way it 's not additive ?
C: , everything is sent over in buffers cuz of isn't it the tcp buffer some ?
B: you mean , the data , the super frame ? but that has variable latency because the last frame doesn't have any latency and first frame has twenty framed latency . so you can't rely on that latency all the time . the transmission over the air interface is like buffer . twenty four frames . but the only thing is that the first frame in that twenty - four frame buffer has twenty - four frame latency . and the last frame doesn't have any latency . because it just goes as
A: wasn't thinking of that one in particular but more of , , if there is some part of your system that has to buffer twenty frames , , can't the other parts of the system draw out of that buffer and therefore not add to the latency ?
C: and and that 's one of the all of that is things that they 're debating in their standards committee .
D: there is , these parameters that still have to look at . like , played little bit with this overestimation factor , but still have to look more at this , at the level of noise add after . , know that adding noise helped , , the system just using spectral subtraction without smoothing , but right now if it 's still important or not , and if the level choose before is still the right one . same thing for the shape of the noise . maybe it would be better to add just white noise instead of speech shaped noise .
C: that 'd be more like the jrasta thing in sense .
D: and another thing is to for this use as noise estimate the mean , , spectrum of the first twenty frames of each utterance . don't remember for this experiment what did you use for these two stage
B: used ten just ten frames .
D: the ten frames ?
B: the reason was like in ti - digits don't have lot . had twenty frames most of the time .
D: but , so what 's this result you told me about , the fact that if you use more than ten frames you can improve by
B: that 's that 's using the channel zero . if use channel zero vad to estimate the noise .
D: but this is ten frames plus
B: channel zero dropping .
D: these results with two stage wiener filtering is ten frames but possibly more . if channel one vad gives you but in this experiment did didn't use any vad . used the twenty first frame to estimate the noise . and so expected it to be little bit better , if , , use more frames . that 's it for spectral subtraction . the second thing was working on is to , , try to look at noise estimation , mmm , and using some technique that doesn't need voice activity detection . and for this simply used some code that , , had from belgium , which is technique that , , takes bunch of frame , and for each frequency bands of this frame , takes look at the minima of the energy . and then average these minima and take this as an energy estimate of the noise for this particular frequency band . and there is something more to this actually . what is done is that , , these minima are computed , , based on , , high resolution spectra . so , compute an fft based on the long , , signal frame which is sixty - four millisecond
A: so you have one minimum for each frequency ?
D: what what , do actually , is to take bunch of to take tile on the spectrogram and this tile is five hundred milliseconds long and two hundred hertz wide . in this tile appears , like , the harmonics if you have voiced sound , because it 's it 's the ftt bins . and when you take the the minima of these this tile , when you don't have speech , these minima will give you some noise level estimate , if you have voiced speech , these minima will still give you some noise estimate because the minima are between the harmonics . and if you have other speech sounds then it 's not the case , but if the time frame is long enough , , like five hundred milliseconds seems to be long enough , you still have portions which , , are very close whi which minima are very close to the noise energy .
C: you said five hundred milliseconds but you said sixty - four milliseconds . which is which ?
D: sixty - four milliseconds is to compute the fft , , bins . the the fft . actually it 's better to use sixty - four milliseconds because , , if you use thirty milliseconds , then , , because of the this short windowing and at low pitch , , sounds , the harmonics are not , wha , correctly separated . so if you take these minima , it they will overestimate the noise lot .
C: so you take sixty - four millisecond ts and then you average them over five hundred ? what do you do over five hundred ?
D: so take to take bunch of these sixty - four millisecond frame to cover five hundred milliseconds , and then look for the minima , on the on the bunch of fifty frames , right ? so the interest of this is that , as with this technique you can estimate some reasonable noise spectra with only five hundred milliseconds of signal , so if the the noise varies lot , , you can track better track the noise , which is not the case if you rely on the voice activity detector . so even if there are no speech pauses , you can track the noise level . the only requirement is that you must have , in these five hundred milliseconds segment , you must have voiced sound at least . cuz this these will help you to track the noise level . so what did is just to simply replace the vad - based , , noise estimate by this estimate , first on speechdat - car only on speechdat - car actually . and it 's , , slightly worse , like one percent relative compared to the vad - based estimates . the reason why it 's not better , is that the speechdat - car noises are all stationary . there really is no need to have something that 's adaptive they are mainly stationary . but , expect maybe some improvement on ti - digits because , nnn , in this case the noises are all sometimes very variable . so have to test it .
C: but are you comparing with something 'm little confused again , when you compare it with the - based , vad - is this is this the ?
D: it 's the france - telecom - based spectra , , wiener filtering and vad . so it 's their system but just replace their noise estimate by this one .
C: you 're not doing this with our system ?
D: no , no . it 's our system but with just the wiener filtering from their system . actually , th the best system that we still have is , , our system but with their noise compensation scheme , so 'm trying to improve on this , and by replacing their noise estimate by , , something that might be better .
C: but the spectral subtraction scheme that you reported on also re requires noise estimate . couldn't you try this for that ? do you might help ?
D: because did this in parallel , and was working on one and the other . try also , mmm , the spectral subtraction .
B: so 'm also using that new noise estimate technique on this wiener filtering what 'm trying . so have , like , some experiments running , don't have the results . don't estimate the noise on the ten frames but use his estimate .
D: , also implemented sp spectral whitening idea which is in the , , ericsson proposal . the idea is just to , flatten the log , , spectrum , , and to flatten it more if the probability of silence is higher . so in this way , you can also reduce somewhat reduce the musical noise and you reduce the variability if you have different noise shapes , because the spectrum becomes more flat in the silence portions . with this , no improvement , but there are lot of parameters that we can play with actually , this could be seen as soft version of the frame dropping because , , you could just put the threshold and say that "" below the threshold , will flatten comp completely flatten the spectrum "" . and above this threshold , , keep the same spectrum . so it would be like frame dropping , because during the silence portions which are below the threshold of voice activity probability , , you would have some dummy frame which is perfectly flat spectrum . and this , , whitening is something that 's more soft because , , you whiten you just , , have function the whitening is function of the speech probability , so it 's not hard decision . so maybe it can be used together with frame dropping and when we are not about if it 's speech or silence , maybe it has something do with this .
C: it 's interesting . , , in jrasta we were essentially adding in , , white , white noise dependent on our estimate of the noise . on the overall estimate of the noise . it never occurred to us to use probability in there . you could imagine one that that made use of where the amount that you added in was , , function of the probability of it being speech or noise .
D: right now it 's constant that just depending on the noise spectrum .
C: cuz that brings in powers of classifiers that we don't really have in , , this other estimate . so it could be it could be interesting . what what point does the , , system stop recording ?
A: it 'll keep going till when they run out of disk space ,
C: it went little long ?
D: so there are with this technique there are some did something exactly the same as the ericsson proposal but , , the probability of speech is not computed the same way . and , for , for lot of things , actually good speech probability is important . like for frame dropping you improve , like you can improve from ten percent as sunil showed , if you use the channel zero speech probabilities . for this it might help , the next thing started to do is to , , try to develop better voice activity detector . for this we can maybe try to train the neural network for voice activity detection on all the data that we have , including all the speechdat - car data . and so 'm starting to obtain alignments on these databases . and the way mi do that is that use the htk system but train it only on the close - talking microphone . and then aligned obtained the viterbi alignment of the training utterances . it seems to be , actually what observed is that for italian it doesn't seem th - there seems to be problem .
B: so , it doesn't seems to help by their use of channel zero or channel one . you mean their the frame dropping , right ?
D: so , but actually the vad was trained on italian also , the the current vad that we have was trained on , , spine , right ?
B: ti - digits .
D: italian , and ti - digits with noise and and it seems to work on italian but not on the finnish and spanish data . so , maybe one reason is that finnish and spanish noise are different . actually we observed we listened to some of the utterances and sometimes for finnish there is music in the recordings and strange things , so the idea was to train all the databases and obtain an alignment to train on these databases , also to , , try different features , , as input to the vad network . we came up with bunch of features that we want to try like , , the spectral slope , the , , the degree degree of voicing with the features that , , we started to develop with carmen , , with , , the correlation between bands and different features ,
B: the energy also .
C: hans - guenter will be here next week so he 'll be interested in all of these things . and , so .
A: shall we , , do digits ? want to go ahead , morgan ?
","The ICSI Meeting Recorder Group of Berkeley met for the first time in two weeks.
Group members reported their progress in the areas of spectral subtraction , Wiener filtering and noise estimation.
They also discusses topics relating to the rules and preferences of the project they are working on , including single vs multiple passes.
A number of the group also took time to explain the basics of their approaches to the group.
There are hopes that a visitor coming for three weeks , may lead to a longer term collaboration.
The visitor works on spectral subtraction , so speaker me026 will make sure he talks to him.
Speaker mn007 agreed , at me013's suggestion , to try his noise compensation scheme in compensation with the prior work on spectral subtraction.
In implementing smoothing to the spectral subtraction , latency has been increased; while some feel this is nothing to worry about , others feel it is better to worry now , in case it turns out to be something to worry about.
Speaker me026 has been experimenting with spectral subtraction using different data window sizes.
One possible idea is to use increasing windows as more data becomes available.
Speaker mn049 has been working on Wiener filtering , and testing with just the base system provides 30% improvement.
Using a second stage of filtering led to even more improvement.
Speaker mn007 is working on spectral subtraction , still with minimal results.
Smoothing seems to help , and implementing alongside the neural net should also be positive.
He has also been working on noise estimation with an energy minima approach that does not require the voice activity detector.
"
