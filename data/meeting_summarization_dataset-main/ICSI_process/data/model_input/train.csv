dataset,encounter_id,dialogue,note
ami_abstractive_summary,Bro021.txt,"B: somebody else should run this . 'm sick of being the one to go through and say , "" , what do you think about this ? ""
F: should we take turns ? you want me to run it today ?
B: why don't you run it today ?
F: let 's see , maybe we should just get list of items things that we should talk about . there 's the usual updates , everybody going around and saying , , , what they 're working on , the things that happened the last week . but aside from that is there anything in particular that anybody wants to bring up so why don't we just around and people can give updates . do you want to start , stephane ?
C: the first thing maybe is that the eurospeech paper is , , accepted .
F: this is what do you , what 's in the paper there ?
C: so it 's the paper that describe the , , system that were proposed for the aurora .
F: the one that we we submitted the last round ?
C: so and the , fff comments seems from the reviewer are good .
F: where where 's it gonna be this year ?
C: it 's , , aalborg in denmark . and it 's , then , , whhh 've been working on mainly on - line normalization this week . 've been trying different slightly different approaches . the first thing is trying to play little bit again with the , , time constant . second thing is , , the training of , , on - line normalization with two different means , one mean for the silence and one for the speech . and so have two recursions which are controlled by the , , probability of the voice activity detector . this actually don't doesn't seem to help , although it doesn't hurt . but , both on - line normalization approach seems equivalent .
F: are the means pretty different for the two ?
C: they can be very different .
B: so do you maybe make errors in different places ? different kinds of errors ?
C: didn't look , , more closely . it might be , . , there is one thing that we can observe , is that the mean are more different for - zero and - one than for the other coefficients . and , it the - one is there are strange thing happening with - one , is that when you have different noises , the mean for the silence portion is can be different . so when you look at the trajectory of - one , it 's has strange shape was expecting th the that these two mean helps , especially because of the strange - ze - one shape , which can like , yo you can have , , trajectory for the speech and then when you are in the silence it goes somewhere , but if the noise is different it goes somewhere else . so which would mean that if we estimate the mean based on all the signal , even though we have frame dropping , but we don't frame ev , drop everything , but , this can hurts the estimation of the mean for speech , mmm . but still have to investigate further , . third thing is , , that instead of having fixed time constant , try to have time constant that 's smaller at the beginning of the utterances to adapt more quickly to the something that 's closer to the right mean . and then this time constant increases and have threshold that if it 's higher than certain threshold , keep it to this threshold to still , , adapt , , the mean when if the utterance is , , long enough to continue to adapt after , like , one second , this doesn't help neither , but this doesn't hurt .
F: wasn't there some experiment you were gonna try where you did something differently for each , , whether it was each mel band or each , , , fft bin or someth there was something you were gonna , some parameter you were gonna vary depending on the frequency .
C: maybe it 's this idea of having different on - line normalization , , tunings for the different mfcc 's .
F: morgan , you brought it up couple meetings ago . and then it was something about , , some and then somebody said "" , it does seem like , , - zero is the one that 's , , the major one "" or , , 't remember exactly what it was now .
C: it 's very important to normalize - zero and much less to normalize the other coefficients . , at least with the current on - line normalization scheme . we , we know that normalizing - one doesn't help with the current scheme . in my idea , was thinking that the the reason is maybe because of these funny things that happen between speech and silence which have different means . but maybe it 's not so easy to
B: really would like to suggest looking , , little bit at the kinds of errors . know you can get lost in that and go forever and not see too much , but sometimes , just seeing that each of these things didn't make things better may not be enough . it may be that they 're making them better in some ways and worse in others , or increasing insertions and decreasing deletions , helping with noisy case but hurting in quiet case . and if you saw that then maybe you it would something would occur to you of how to deal with that .
C: so that 's it , , for the on - line normalization . 've been playing little bit with some thresholding , as first experiment , what did is is to take , to measure the average no , the maximum energy of each utterance and then put threshold this for each mel band . then put threshold that 's fifteen db below , couple of db below this maximum , actually it was not threshold , it was just adding noise . so was adding white noise energy , that 's fifteen db below the maximum energy of the utterance . when we look at the , , mfcc that result from this , they are lot more smoother . when we compare , like , channel zero and channel one utterance so clean and , , the same noisy utterance there is almost no difference between the cepstral coefficients of the two . and the result that we have in term of speech recognition , actually it 's not it 's not worse , it 's not better neither , but it 's , , surprising that it 's not worse because you add noise that 's fifteen db just fifteen db below the maximum energy .
F: so why does that smooth things out ? don't don't understand that .
B: there 's less difference . right ?
C: it 's , it 's whitening this the portion that are more silent , as you add white noise that are has very high energy , it whitens everything and the high - energy portion of the speech don't get much affected anyway by the other noise . and as the noise you add is the same is the shape , it 's also the same . so they have the trajectory are very , very similar .
B: so , , again , if you trained in one noise and tested in the same noise , you 'd , given enough training data you don't do do badly . the reason that we that we have the problems we have is because it 's different in training and test . even if the general kind is the same , the exact instances are different . so when you whiten it , then it 's like you the only noise to first order , the only th noise that you have is white noise and you 've added the same thing to training and test . so it 's ,
F: so would that be similar to , like , doing the smoothing , then , over time
B: it 's smoothing ,
C: it 's it 's different . it 's it 's something that , that affects more or less the silence portions anyway , the sp the portion of speech that ha have high energy are not ch lot affected by the noises in the aurora database . if if you compare th the two shut channels of speechdat - car during speech portion , it 's the mfcc are not very different . they are very different when energy 's lower , like during fricatives or during speech pauses .
B: but you 're still getting more recognition errors , which means that the differences , even though they look like they 're not so big , are hurting your recognition .
C: so it distort the speech .
F: so performance went down ?
C: so , but in this case really expect that maybe the two these two stream of features , they are very different . and maybe we could gain something by combining them
B: the other thing is that you just picked one particular way of doing it . , first place it 's fifteen db , , down across the utterance . and maybe you 'd want to have something that was little more adaptive . secondly , you happened to pick fifteen db and maybe twenty 'd be better ,
F: so what was the what was the threshold part of it ? was the threshold , , how far down ?
B: he , he had to figure out how much to add . so he was looking he was looking at the peak value .
F: and and so what 's ho don't understand . how does it go ? if it if the peak value 's above some threshold , then you add the noise ? or if it 's below
C: systematically add the noise , but the , , noise level is just some threshold below the peak . which is not really noise , actually . it 's just adding constant to each of the mel , , energy . to each of the mel filter bank . so , , it 's really , , white noise .
B: so then afterwards log is taken , and that 's so why the little variation tends to go away .
C: the this threshold is still factor that we have to look at . and , maybe constant noise addition would be fine also ,
B: or or not constant but , , varying over time is another way to go . were you using the normalization in addition to this ? what was the rest of the system ?
C: it was it was , , the same system . it was the same system . third thing is that , , play little bit with the , finding what was different between , , and there were couple of differences , like the lda filters were not the same . he had the france telecom blind equalization in the system . the number of mfcc that was were used was different . and we used fifteen . bunch of differences . and , , actually the result that he got were much better on ti - digits especially . so 'm investigated to see what was the maor for this difference . and it seems that the lda filter is was hurting . so when we put some noise compensation the , , lda filter that 's derived from noisy speech is not more anymore optimal . and it makes big difference , , on ti - digits trained on clean . if we use the old lda filter , the lda filter that was in the proposal , we have , like , eighty - two point seven percent recognition rate , on noisy speech when the system is trained on clean speech . and when we use the filter that 's derived from clean speech we jumped so from eighty - two point seven to eighty - five point one , which is huge leap . so now the results are more similar , don't will not , , investigate on the other differences , which is like the number of mfcc that we keep and other small things that we can optimize later on anyway .
B: but on the other hand if everybody is trying different kinds of noise suppression things and , it might be good to standardize on the piece that we 're not changing . so if there 's any particular reason to ha pick one or the other , which which one is closer to what the proposal was that was submitted to aurora ?
C: th , the new system that tested is , , closer because it doesn't have it have less of france telecom ,
D: the whatever you , , tested with recently . right ?
B: you 're trying to add in france telecom . tell them about the rest of it . like you said the number of filters might be different .
D: the number of cepstral coefficients is what ?
B: so , , we 'd wanna standardize there , so , sh you guys should pick something all th all three of you .
C: we were gonna work with this or this new system ,
D: so the right now , the system that is there in the what we have in the repositories , with uses fifteen .
C: but we will use the lda filters derived from clean speech . , actually it 's it 's not the lda filter . it 's something that 's also short enough in latency .
D: so , we haven't we have been always using , , fifteen coefficients , , that 's something 's
B: as long as you guys agree on it , it doesn't matter . we have maximum of sixty , , features that we 're allowed .
D: ma - maybe we can , at least , 'll run some experiments to see whether once have this noise compensation to see whether thirteen and fifteen really matters or not . never tested it with the compensation , but without , , compensation it was like fifteen was slightly better than thirteen , so that 's why we stuck to thirteen .
C: and there is there is also this log energy versus - zero .
D: the log energy versus - zero . that 's that 's the other thing . without noise compensation certainly - zero is better than log energy . be - , because the there are more , , mismatched conditions than the matching conditions for testing . always for the matched condition , you always get slightly better performance for log energy than - zero . for matched and the clean condition both , you get log energy you get better performance with log energy . , maybe once we have this noise compensation , , we have to try that also , whether we want to go for - zero or log energy . we can see that .
F: so do you have more , stephane ,
C: that 's it , .
F: do you have anything , morgan ,
B: no . 'm just , , being manager this week .
F: how about you , barry ?
A: still working on my quals preparation . so 'm 'm thinking about , , starting some , , cheating experiments to , , determine the , the relative effectiveness of , , some intermediate categories that want to classify . so , , , if know where voicing occurs and everything , , would do phone , phone recognition experiment , somehow putting in the , the perfect knowledge that have about voicing . so , , in particular was thinking , , in the hybrid framework , just taking those lna files , and , , setting to zero those probabilities that , that these phones are not voicing . so say , like , know this particular segment is voicing , would say , , go into the corresponding lna file and zonk out the posteriors for , , those phonemes that , , are not voiced , and then see what kinds of improvements get . and so this would be useful thing , , to terms of , like , which , which of these categories are good for , , speech recognition . so , that 's hope to get those , those experiments done by the time quals come around in july .
F: so do you just take the probabilities of the other ones and spread them out evenly among the remaining ones ?
A: so just set to set to some really low number , the non - voiced , , phones . and then renormalize .
F: that will be really interesting to see , so then you 're gonna feed the those into some standard recognizer . wh are you gonna do digits
A: , 'm gonna work with timit
F: with timit . .
A: timit , phone recognition with timit .
F: so then you 'll feed those so where do the outputs of the net go into if you 're doing phone recognition ?
A: the outputs of the net go into the standard , , icsi hybrid , , recognizer . so maybe , , chronos
F: an - and you 're gonna the you 're gonna do phone recognition with that ?
A: right , right . and , , another thing would be to extend this to , , digits where look at whole words . and would be able to see , , not just , like , phoneme events , but , , inter - phoneme events . so , like , this is from stop to vo vocalic so something that is transitional in nature . so that 's that 's it .
F: let 's see , haven't done whole lot on anything related to this week . 've been focusing mainly on meeting recorder . so , , 'll just pass it on to dave .
G: in my lunch talk last week said 'd tried phase normalization and gotten garbage results using that , long - term mean subtraction approach . it turned out there was bug in my matlab code . so tried it again , and , , the results were better . got intelligible speech back . but they still weren't as good as just subtracting the magnitude the log magnitude means . and also 've been talking to , , andreas and thilo about the , , smartkom language model and about coming up with good model for , , far mike use of the smartkom system . 'm gonna be working on , , implementing this mean subtraction approach in the far - mike system for the smartkom system , . one of the experiments we 're gonna do is , , we 're gonna , , train the broadcast news net , which is because that 's what we 've been using so far , and , , adapt it on some other data . , an - andreas wants to use , data that resembles read speech , like these digit readings , because he feels that the smartkom system interaction is not gonna be exactly conversational . so actually was wondering , how long does it take to train that broadcast news net ?
B: the big one takes while . that takes two , three weeks .
G: two , three weeks .
B: so but , , , you can get if you even want to run the big one , , , in the in the final system , cuz , , it takes little while to run it . so , , you can scale it down by it was two , three weeks for training up for the large broadcast news test set training set . how much you 'd be training on . so if you trained on half as much and made the net , , half as big , then it would be one fourth the amount of time and it 'd be nearly as good . also , we had we 've had these , , little di discussions you ha haven't had chance to work with it too much about , other ways of taking care of the phase . so , , that was something could say would be that we 've talked little bit about you just doing it all with complex arithmetic and not , , doing the polar representation with magnitude and phase . but it looks like there 's ways that one could potentially just work with the complex numbers and and in principle get rid of the effects of the average complex spectrum .
G: actually , regarding the phase normalization so did two experiments , so , phases get added , modulo two pi , and because you only know the phase of the complex number to value modulo two pi . and so at first , , that , , what should do is unwrap the phase because that will undo that . but actually got worse results doing that unwrapping using the simple phase unwrapper that 's in matlab than did not unwrapping . and that 's all have to say .
B: so 'm 'm still hopeful that we don't even the phase is something the average phase is something that we do want to remove . maybe there 's some deeper reason why it isn't the right thing to do . at least in principle it looks like there 's there 's , , couple potential ways to do it . one one being to just work with the complex numbers , and , in rectangular coordinates . and the other is to , , do taylor series so you work with the complex numbers and then when you get the spectrum the average complex spectrum , actually divide it out , as opposed to taking the log and subtracting . there might be some numerical issues . we don't really know that . the other thing we talked little bit about was taylor series expansion . actually was talking to dick karp about it little bit , and and , since got thinking about it , so one thing is that you 'd have to do , , we may have to do this on whiteboard , but you have to be little careful about scaling the numbers that you 're taking the complex numbers that you 're taking the log of because the taylor expansion for it has , , square and cube , and . and and so if you have number that is modulus , , , very different from one it should be right around one , cuz it 's expansion of log one or is one plus epsilon , or is it one plus ? there 's an epsilon squared over two and an epsilon cubed over three , so if epsilon is bigger than one , then it diverges . so you have to do some scaling . but that 's not big deal cuz it 's the log of times complex number , then you can just that 's the same as log of plus log of the complex number .
F: how about you , sunil ?
D: so , , 've been , , implementing this , , wiener filtering for this aurora task . actually thought it was it was doing fine when tested it once . it 's , like , using small section of the code . and then ran the whole recognition experiment with italian and got , like , worse results than not using it . so , 've been trying to find where the problem came from . and then it looks like have some problem in the way there is some very silly bug somewhere . and , ugh ! , it actually it actually made the whole thing worse . was looking at the spectrograms that got and it 's , like it 's it 's very horrible .
B: was was distracted . missed the very first sentence . so then , 'm little lost on the rest .
D: actually implemented the wiener fil filtering as module and then tested it out separately . and it it gave , like got the signal out and it was . so , plugged it in somewhere and then , it 's like had to remove some part and then plugging it in somewhere . and then in that process messed it up somewhere . so , it was real it was all fine and then ran it , and got something worse than not using it . was like 'm trying to find where the problem came , and it seems to be , like , somewhere and , , the other thing , , was , hynek showed up one suddenly on one day and then was talking wi
B: as as he is wont to do .
D: so was actually that day was thinking about doing something about the wiener filtering , and then carlos matter of . and then he showed up and then told him . and then he gave me whole bunch of filters what carlos used for his , , thesis and then that was something which came up . so , , 'm actually , , thinking of using that also in this , , wiener filtering because that is modified wiener filtering approach , where instead of using the current frame , it uses adjacent frames also in designing the wiener filter . so instead of designing our own new wiener filters , may just use one of those carlos filters in this implementation and see whether it actually gives me something better than using just the current current frame , which is in way , , something like the smoothing the wiener filter 'm 'm , like that so that is the next thing . once this once sort this pro , problem out maybe 'll just go into that also . the other thing was about the subspace approach . like , plugged some groupings for computing this eigen , , values and eigenvectors . so just @ @ some small block of things which needed to put together for the subspace approach . and 'm in the process of , like , building up that . that 's it . and , , th that 's where am right now .
F: how about you , carmen ?
E: mmm . 'm working with vts . do several experiment with the spanish database first , only with vts and nothing more .
F: what what is vts again ?
E: vectorial taylor series . to remove the noise too .
F: right , right . ask you that every single meeting , ask you that question every meeting .
B: so , that 'd be good from for analysis . it 's good to have some , , cases of the same utterance at different times .
F: "" what is vts ? ""
E: , the question is that remove some noise but not too much . and when we put the the , , vad , the result is better . and we put everything , the result is better , but it 's not better than the result that we have without vts . no , no .
B: so that @ @ given that you 're using the vad also , the effect of the vts is not so far do you how much of that do you due to just the particular implementation and how much you 're adjusting it ? or how much do you intrinsic to ?
C: are you still using only the ten first frame for noise estimation
E: do the experiment using only the onl , to use on only one fair estimation of the noise . and also did some experiment , , doing , , lying estimation of the noise . and , , it 's little bit better but not
C: maybe you have to standardize this thing also , because all the thing that you are testing use different they all need some noise spectra
E: no , do that two did two time .
C: but they use every all use different one .
B: have an idea . if if , , you 're right . each of these require this . given that we 're going to have for this test at least of , boundaries , what if initially we start off by using known sections of nonspeech for the estimation ? first place , even if ultimately we wouldn't be given the boundaries , , this would be good initial experiment to separate out the effects of things . how much is the poor , relatively , , unhelpful result that you 're getting in this or this is due to some inherent limitation to the method for these tasks and how much of it is just due to the fact that you 're not accurately finding enough regions that are really noise ? so maybe if you tested it using that , you 'd have more reliable stretches of nonspeech to do the estimation from and see if that helps .
E: another thing is the , the codebook , the initial codebook . it 's too clean if you want , you say something about the method . because it 's little bit different of the other method . if this if this is the noise signal , {nonvocalsound} , in the log domain , we have something like this . now , we have something like this . and the idea of these methods is to given , how do you say ? will read because it 's better for my english . is the estimate of the pdf of the noise signal when we have , , statistic of the clean speech and an statistic of the noisy speech . and the clean speech the statistic of the clean speech is from codebook . mmm ? this is the idea . like , this relation is not linear . the methods propose to develop this in vectorial taylor series approximation .
B: 'm actually just confused about the equations you have up there . the top equation is is
E: no , this in the it 's this is the log domain . must to say that .
B: which is which is the log domain ?
E: is the is egual is equal to , , log of
B: but is what ?
E: and this is this .
B: no , no . the top is what ? is that power spectrum ?
E: this is the noisy speech .
B: no , is that power spectrum ?
C: it 's the power spectrum of noisy speech .
E: it 's the power spectrum . this is the noisy
B: so this it 's the magnitude squared . so you have power spectrum added there and down here you have you put the but all of this is just you just mean
E: it 's the same .
B: you just mean the log of the of the one up above . and , , so that is times ,
D: one one plus by .
E: we can expre we can put this expression
B: times one plus , , minus ? so that 's log of plus log of one plus ,
E: and the noise signal .
B: is that right ?
D: one plus by .
B: actually don't see how you get that .
E: if we apply the log , we have is log {nonvocalsound} is equal , , to log of plus .
D: and , log of
E: we can say that {nonvocalsound} is equal to log of , {nonvocalsound} {nonvocalsound} , exponential of plus exponential of .
B: that doesn't follow .
E: this is this is in the ti the time domain . we have that , we have first that , , is equal , this is the frequency domain and we can put that the log domain log of omega , but , , in the time domain we have an exponential . maybe it 's am
B: just never mind what they are . it 's just if and are variables
D: what is , ?
B: the the log of plus is not the same as the log of to the plus to the . maybe we can take it off - line ,
E: do this incorrectly . the expression that appear in the in the paper , {nonvocalsound} is ,
D: the taylor series expansion for log one plus by is
C: is it the first - order expansion ?
D: the first one .
B: cuz it doesn't just follow what 's there . it has to be some , , taylor series
D: if if you take log into log one plus by , and then expand the log one plus by into taylor series
E: now , this is the
C: but the second expression that you put is the first - order expansion of the nonlinear relation between
E: no , no . it 's not the first space . we have pfft , , we can put that is equal is equal to log of , ,
B: that doesn't follow .
E: we can put , , this ?
B: that , that the top one does not imply the second one . because cuz the log of sum is not the same as th
E: we know that , , the log of plus is equal to log of plus log to . and we can say here , it
B: right . so you could
C: what is that ?
E: and we can , , put this inside . and then we can ,
B: don't see how you get the second expression from the top one . the , just more generally here , if you say "" log of , , plus "" , the log of log of plus is not or plus is not the , , log of to the plus to the .
E: no , no , no , no .
B: and that 's what you seem to be saying .
E: it 's not . but this is the same
B: cuz you cuz you up here you have the plus
E: say if apply log , have , , log of is equal to log of , in this side , is equal to log of
B: and then how do you go from there to the ?
E: this is right . and then if apply exponential , to have here
C: it 's log of capital .
D: this is , inside .
E: we have this ,
B: that one 's right .
E: th we can put here the set transformation . in this case , , we can put here {nonvocalsound} .
B: it 's just by definition that the individual that the , so , capital is by definition the same as to the little because she 's saying that the little is the , is the log .
E: now we can put this . and here we can multiply by .
B: these things are lot clearer when you can use fonts different fonts there so which is which . but under understand what you mean now .
E: that 's true . that 's true . but this is correct ? and now do it , put log {nonvocalsound} of ex plus log
B: yes . understand now . and that 's where it comes from .
E: now it 's correct . we have fixed this equa
B: so now once you get that one , then you then you do first or second - order , , taylor series expansion of this .
E: this is another linear relation that this to develop this in vector taylor series . and for that , , the goal is to obtain , est estimate pdf for the noisy speech when we have statistic for clean speech and for the noisy speech . the way to obtain the pdf for the noisy speech is we know this statistic and we know the noisy st we can apply first order of the vector st taylor series of the of , the order that we want , increase the complexity of the problem . and then when we have expression , , for the mean and variance of the noisy speech , we apply technique of minimum mean - square estimation to obtain the expected value of the clean speech given the this statistic for the noisy speech the statistic for clean speech and the statistic of the noisy speech . this only that . but the idea is that
C: and the model of clean speech is codebook . right ?
E: we have our codebook with different density gaussian . we can expre we can put that the pdf for the clean test , probability of the clean speech is equal to
B: how much in the work they reported , how much noisy speech did you need to get , , good enough statistics for the to get this mapping ? cuz what 's certainly characteristic of lot of the data in this test is that , , you don't have the the training set may not be great estimator for the noise in the test set . and sometimes it 's not .
E: the clean speech the codebook for clean speech , am using timit . and have now , , sixty - four {nonvocalsound} gaus - gaussian .
B: and what are you using for the noisy ?
E: estimate the noises wi for the noises only use one gaussian .
B: and and you train it up entirely from , , nonspeech sections in the test ?
E: the first experiment that do it is solely to calculate the , mmm , this value the compensation of the dictionary one time using the noise at the beginning of the sentence . this is the first experiment . and fix this for all the all the sentences . the first thing that do is to obtain , , an expression for probability expression of . that mean that the vts mmm , with the vts we obtain , we obtain the means for each gaussian and the variance . this is one . this is the composition of the dictionary . this one thing . and the other thing that this with these methods is to , , obtain to calculate this value . because we can write we can write that the estimation of the clean speech is equal at an expected value of the clean speech conditional to , , the noise signal the probability of the statistic of the clean speech and the statistic of the noise . this is the methods that say that we 're going obtain this . and we can put that this is equal to the estimated value of minus function that conditional to to the to the noise signal . this is this function is the term after develop this , the term that we take . give px and , , the noise . and put that this is equal to the noise signal minus put before this name , and calculate this .
B: what is the first variable in that probability ?
E: this is the gaussian .
B: no , no . 'm . in in the one you pointed at . what 's that variable ?
D: so probably it would do that .
C: it 's one mixture of the model . right ?
E: no , it 's condition it 's not exactly this . it 's modify . if we have clean speech we have the dictionary for the clean speech , we have probability of our weight for each gaussian . and now , this weight is different now because it 's conditional . and this need to calcu because this is from the dictionary that you have . need to calculate this . and for calculate this , have an develop an expression that is
D: it 's overlapping .
E: calculate calculated this value , , with the statistic of the noisy speech that calculated before with the vts approximation . and , normalizing . and know everything . when develop this in taylor series , 't , , calculate the mean and the variance of the for each of the gaussian of the dictionary for the noisy speech . and this is fixed . if never do an estimat newer estimation of the noise , this mean as mean and the variance are fixed . and for each , frame of the speech the only thing that need to do is to calculate this in order to calculate the estimation of the clean speech given our noisy speech .
B: so , 'm 'm not following this perfectly are you saying th of these estimates are done using , , estimates of the probability density for the noise that are calculated only from the first ten frames ? and never change throughout anything else ?
E: this is one of the approximations that am doing .
B: per per utterance ,
E: per utterance . yes . per utterance . yes .
B: so it 's done it 's done new for each new utterance . so this changes the whole mapping for every utterance .
E: it 's fixed , the dictionary . and the other estimation is when do the on - line estimation , change the means and variance of th for the noisy speech each time that detect noise . do it again this estimate the new mean and the variance of the noisy speech . and with th with this new new mean and variance estimate again this .
B: so you estimated , , completely forgetting what you had before ? or is there some adaptation ?
E: no , no . it 's not completely no , it 's am doing something like an adaptation of the noise .
B: now do we know , either from their experience or from yours , that , , just having , , two parameters , the mean and variance , is enough ? know you don't have lot of data to estimate with ,
E: estimate mean and variance for each one of the gaussian of the codebook .
B: no , 'm talking about the noise . there 's only one gaussian .
E: am only using only one .
B: and you and it 's , it 's only one what 's the dimensionality of the gaussian ?
E: it 's in after the mel filter bank .
B: so this is twenty ?
E: twenty - three .
B: so it 's actually forty numbers that you 're getting . maybe you don't have
E: the original paper say that only one gaussian for the noise .
B: but , , no paper is bible ,
E: maybe isn't the right thing .
B: this is this is , the question is , , whether it would be helpful , particularly if you used if you had more so , suppose you did this is almost cheating . it certainly isn't real - time . but if suppose you use the real boundaries that you were were given by the vad and or we 're gonna be given even better boundaries than that . and you look you take all all of the nonspeech components in an utterance , so you have fair amount . do you benefit from having better model for the noise ? that would be another question . so first question would be to what extent are the errors that you 're still seeing based on the fact that you have poor boundaries for the , , nonspeech ? and the second question might be , given that you have good boundaries , could you do better if you used more parameters to characterize the noise ? also another question might be they are doing they 're using first term only of the vector taylor series ? if you do second term does it get too complicated cuz of the nonlinearity ?
E: it 's quite complicated .
B: no , won't ask the next question then .
E: it 's it 's the for me it 's the first time that am working with vts .
B: no , it 's interesting . we haven't had anybody work with it before , so it 's interesting to get your get your feedback about it .
E: it 's another type of approximation because because it 's statistic approximation to remove the noise .
F: we 're about done . so some of the digit forms don't have digits . there were some blanks in there , so not everybody will be reading digits . you 've got some . right , morgan ? why don't you go ahead and start . and it 's just us down here at this end that have them .
D: so , we switch off with this
F: whenever you 're ready . leave it on ,
B: they prefer to have them on just so that they 're continuing to get the distant , , information .
","The ICSI Meeting Recorder Group at Berkeley met once more to discuss group members' progress.
The majority of the group are working on tasks related to the Aurora Project , including on-line normalization and Wiener filtering.
Other progress was also reported.
A large part of the meeting was spent discussing calculations and approaches using the white-board in the room.
At me013's behest , the group need to look closer at the errors made in tests on the aurora project , because the error rate may not be telling the whole picture.
Mn052 volunteers to run some experiments into how different numbers of MFCCs affect results.
Some previously reported results from me026 were determined to be garbage due to a bug in the code  Speaker mn052 also feels that his strange results are down to a bug.
This week , speaker mn007 has mostly been focusing on trying different approaches to on-line normalization , but making little impact on results.
He has also been playing with thresholding , effectively adding white noise to the data , but again with minimal affect.
Also making little improvement is fn002's work with Vectorial Taylor series , as a means of dealing with noise.
Mn052 has been adding Wiener filtering to the aurora task , and is thinking about future work on subspace.
Speaker me026 has been investigating phase normalization , and the possibility of adding spectral subtraction to an existing system.
Speaker me006 is still planning some cheating experiments to investigate features for recognition , alongside preparing for his quals.
also , the groups submission to the Eurospeech conference has been accepted.
"
ami_abstractive_summary,Bed013.txt,"B: almost forgot about the meeting . woke up twenty minutes ago , thinking , what did forget ?
D: it 's great how the br brain does that .
E: something 's not right here .
D: so the news for me is , my forthcoming travel plans in two weeks from today ? more or less ? 'll be off to sicily and germany for couple , three days .
B: now what are what are you doing there ?
D: 'm flying to sicily to drop off simon there with his grandparents . and then 'm flying to germany to go to moku - treffen which is the meeting of all the module - responsible people in smartkom , and , represent ici and myself there . that 's the mmm actual reason . and then 'm also going up to eml for day , and then 'm going to meet the very big boss , wolfgang walster , in saarbruecken and the system system integration people in kaiserslautern and then 'm flying back via sicily pick up my son come back here on the fourth of july .
E: what great time to be coming back to the
B: god bless america .
E: you 'll see maybe see the fireworks from your plane coming in .
D: and 'm all the people at the airport will be happy to work on that day .
E: you 'll get even better service than usual .
B: aren't you flying on lufthansa though ? then the , it 's not big deal . once you get to the united states it 'll be problem ,
D: that 's that bit of news , and the other bit of news is we had , , was visited by my german project manager who , did like what we did what we 're doing here , and , is planning to come here either three weeks in july or three weeks in august , to actually work . and we sat around and we talked and he came up we came up with pretty strange idea . and that 's what 'm gonna lay on you now . and , maybe it might be ultimately the most interesting thing for eva because she has been known to complain about the fact that the we do here is not weird enough . so this is so weird it should even make you happy . imagine if you will , that we have system that does all that understanding that we want it to do based on utterances . it should be possible to make that system produce questions . so if you have the knowledge of how to interpret "" where is ? "" under given conditions , situational , user , discourse and ontological conditions , you should also be able to make that same system ask "" where is ? "" in sper certain way , based on certain intentions . so in instead of just being able to observe phenomenon , , and , the intention we might be able just to give it an intention , and make it produce an utterance .
B: like in ai they generally do the take in , and then they also do the generation phase , like nancy 's thing . you remember , in the hand thing in one - eighty - two , like not only was it able to recognize but it was also to generate based upon situations . you mean that thing ?
D: and once you 've done that what we can do is have the system ask itself . understand the answer , ask something else , and enter dialogue with itself . so the ba basic the same idea as having two chess computers play against each other .
E: except this smacks little bit more of schizophrenic computer than ai .
D: you if you want , you can have two parallel machines , asking each other . what would that give us ? would be something completely weird and strange , and , if you look the factors , we will never observe people let 's say , in wheelchairs under , in under all conditions ,
E: that 's good .
D: when they say "" "" , and there is ride at the goal , and the parking is good , we can never collect enough data . it 's it 's not possible .
E: right , right .
D: but maybe one could do some learning . if you get the system to speak to itself , you may find break downs and errors and you may be able to learn . and make it more robust , maybe learn new things . so there 's no end of potential things one could get out of it , if that works . and he would like to actually work on that with us .
B: then , he probably should be coming back year from now .
D: see the generation bit , making the system generate something , is shouldn't be too hard .
B: once the system understands things . don't think we 're probably year away from getting the system to understand things .
D: , if we can get it to understand one thing , like our "" where is "" run through we can also , maybe , make it say , or ask "" where is ? "" or not .
E: 'm have the impression that getting it to say the right thing in the right circumstances is much more difficult than getting it to understand something given the circumstances and so on , just cuz it 's harder to learn to speak correctly in foreign language , rather than learning to understand it . right ? just the fact that we 'll get that getting it to understand one construction doesn't mean that it will always know exactly when it 's correct to use that construction . right ?
D: it 's it 's 've 've done generation and language production research for fo four and half years . and so it 's you 're right , it 's not the same as the understanding . it 's in some ways easier and some ways harder . nuh ? it 'd be fun to look at it , or into that question . it 's pretty strange idea . and so that 's but
B: the basic idea would be to give allow the system to have intentions , ? cuz that 's what needs to be added to the system for it .
D: eee , even think even what it would be the prior intention . so let 's , let 's say we have this
B: we 'd have to seed that ,
D: no . let 's we have to we have some top - down processing , given certain setting . now we change nothing , and just say ask something . what would it ask ?
B: it wouldn't to ask . unless it was in situation . we 'd have to set up situation where , it didn't know where something was and it wanted to go there . which means that we 'd need to set up an intention inside of the system . right ? which is , "" where something is and need to go there "" .
D: do we really need to do that ? it 's 's it 's strange , but look at it look at our bayes - net . if we don't have let 's assume we don't have any input from the language . right ? so there 's also nothing we could query the ontology , but we have certain user setting . if you just ask , what is the likelihood of that person wanting to enter some something , it 'll give you an answer . that 's just how they are . and so , @ @ whatever that is , it 's the generic default intention . that it would find out . which is , wanting to know where something is , maybe nnn and wanting what it 's gonna be , but there 's gonna be something that
E: you 're not gonna are you gonna get variety of intentions out of that then ? you 're just talking about like given this user , what 's the th what is it what is that user most likely to want to do ?
D: you can observe some user and context and ask , what 's the posterior probabilities of all of our decision nodes .
E: and , have it talk about
D: you could even say , "" let 's take all the priors , let 's observe nothing "" , and query all the posterior probabilities . it - it 's gonna tell us something .
B: it will assign values to all the nodes . yes .
D: yes . and come up with posterior probabilities for all the values of the decision nodes . which , if we have an algorithm that filters out whatever the best or the most consistent answer out of that , will give us the intention ex nihilo . and that is exactly what would happen if we ask it to produce an utterance , it would be based on that extension , ex nihilo , which we what it is , but it 's there . so we wouldn't even have to to kick start it by giving it certain intention or observing anything on the decision node . and whatever that maybe that would lead to "" what is the castle ? "" , or "" what is that whatever "" .
B: what 'm afraid of is if we don't , , set up situation , we 'll just get bunch of garbage out , like , everything 's exactly thirty percent .
D: so what we actually then need to do is write little script that changes all the settings , go goes through all the permutations , which is we did didn't we calculate that once ?
B: that was that was absurdly low , in the last meeting , cuz went and looked at it cuz was thinking , that could not be right , and it would it was on the order of twenty output nodes and something like twenty
C: and like thirty input nodes
B: thirty input nodes . so to test every output node , , would at least let 's see , so it would be two to the thirty for every output node ? which is very th very large .
D: that 's that 's nothing for those neural guys . they train for millions and millions of epochs .
B: was gonna take drink of my water . 'm talking about billions and billions and two to the thirty is like bhaskara said , we had calculated out and bhaskara believes that it 's larger than the number of particles in the universe .
E: if that 's right or not . th - that 's big . that 's just that 's it 's billion , right ?
B: two to the thirty ? two to the thirty is billion , but if we have to do it two to the twenty times , then that 's very large number .
E: , that 's big .
B: cuz you have to query the node , for every , or query the net two to the twenty times . or not two to th excuse me , twenty times .
E: so , is it comes to twenty billion ? that 's pretty big , though .
B: that 's @ @ that 's big . ! we calculated different number before . how did we do that ?
E: remember there being some other one floating around . but anyway , .
C: don't really know .
E: it 's anyway , that given all of these different factors , it 's it 's it 's still going to be impossible to run through all of the possible situations or whatever .
C: ooo , it 's just big .
E: but , this 'll get us bit closer at least , right ?
B: if it takes us second to do , for each one , and let 's say it 's twenty billion , then that 's twenty billion seconds , eva , do the math . hours and hours and hours . but we can do randomized testing .
E: tah - dah !
B: which probabilistically will be good enough .
D: so , it be it 's an idea that one could run past , , what 's that guy 's name ? ? he - he 's usually here .
E: here in the group ?
D: . that 's the guy .
E: that would the the bald guy .
B: ! my advisor !
D: so this is just an idea that 's floating around and we 'll see what happens . what other news do have ? we fixed some more things from the smartkom system , but that 's not really of general interest , 'll ask eva about the bayes and she 's working on that . how is the generation xml thing ?
B: 'm gonna work on that today and tomorrow .
D: no need to do it today or tomorrow even . do it next week or
B: 'm gonna finish it today , hopefully . wanna do one of those things where stay here . cuz , if go home , 't finish it . 've tried about five times so far , where work for while and then 'm like , 'm hungry . so go home , and then
E: 'm not going back .
B: either that or to myself , work at home . and then try to work at home , but fail miserably . like ended up at blakes last night .
E: non - conducive .
B: almost got into brawl . but did not finish the , but 've been looking into it . th @ @ it 's not like it 's blank slate . found everything that need and stu and , furthermore , told jerry that was gonna finish it before he got back .
E: that 's approaching . he 's coming back when ?
B: we think we 'll see him definitely on tuesday for the next or , no , . the meetings are on thursday . we 'll see him next week .
D: that 's good .
B: was thinking about that . will try to work on the smartkom and 'll if finish it today , 'll help you with that tomorrow , if you work on it ? don't have problem with us working on it though ?
D: so you would say it 's funky
B: we just it wouldn't hurt to write up paper , cuz then , , was talking with nancy and nancy said , you whether you have paper to write up until you write it up . and since jerry 's coming back , we can run it by him too .
D: what 's your input ?
E: , don't have much experience with , conference papers for compu in the computer science realm , and so when looked at what you had , which was complete submission , said didn't really to do with it , like , this is the the basic outline of the system or whatever , "" here 's an idea "" , right ? that 's what that paper was , "" here 's here 's one possible thing you could do "" , and what you have in mind for expanding . like 'd what didn't do is go to the web site of the conference and look at what they 're looking for or whatever .
D: it seems to me that
B: is this computer science conference
D: it 's both , right ? it 's it 's cognitive , neural , psycho , linguistic , but all for the sake of doing computer science . so it 's cognitive , psycho , neural , plausibly motivated , architectures of natural language processing . so it seems pretty interdisciplinary , and , the keynote speaker is tomasello and blah - blah ,
E: right . , .
D: the question is what could we actually do and and keep straight face while doing it .
B: really can't keep straight face doing anything .
D: my idea is ,
E: setting that aside .
D: you can say we have done little bit and that 's this , and the rest is position paper , "" we wanna also do that "" . which is not too good . might be more interesting to do something like let 's assume , we 're right , we have as jerry calls it , delusion of adequacy , and take "" where is "" sentence , and say , "" we will just talk about this , and how we cognitively , neurally , psycho - linguistically , construction grammar - ally , motivated , envision , understanding that "" . so we can actually show how we parse it . that should be able to we should be able to come up with , , parse . it 's on , just put it on .
B: did ben harass you ?
A: was he supposed to harass me ? he just told me that you came looking for me . figure this out .
D: you will suffer in hell ,
E: there 's diagram somewhere which tells you how to put that
A: didn't understand that either !
B: no . you have to put it on exactly like that ,
D: this is it .
B: so put that those things over your ears like that . see the how the plastic things ar arch out like that ? there we go . it hurts . it hurts real bad .
A: 'm didn't mean to
E: but that 's what you get for coming late to the meeting .
A: 'm , these are all the same . ! th this is not very on target .
B: is your mike on ?
A: alright , you guys can continue talking about whatever you were talking about before .
D: we 're talking about this , alleged paper that we may , just ,
A: ! which johno mentioned to me .
D: and brought forth the idea that we take sentence , "" where is the powder - tower "" , and we pretend to parse it , we pretend to understand it , and we write about it .
E: about how all of these things
A: what 's the part that 's not pretend ?
D: then we pretend to write about .
E: the submitting to major international conference . .
A: tha - which conference is it for ?
D: it 's the whatever , architectures , , where there is this conference , it 's the seventh already international conference , on neu neurally , cognitively , motivated , architectures of natural language processing . and the keynote speakers are tomasello , macwhinney ?
A: whinney . macwhinney - .
D: we - macwhinney , .
A: so , interesting , both , like , child language people .
D: so maybe you wanna write something too .
A: maybe wanna go . why are they speaking at it if it
E: mmm . mmm .
A: is it normally like , dialogue systems , or , , other nlp - ish things ?
D: no no no . it 's it 's like
A: it 's cognitive . both learning and like , comprehension , production , that kinda .
D: you could look at the web site . and the ad and the deadline is the fifteenth of june .
A: that 's pretty soon .
D: hey . plenty of time .
E: why , we 've got over week !
D: it would be to go write two papers actually . and one from your perspective , and one from our peve per
A: th that 's the kinda thing that maybe like , , the general con like ntl - ish like , whatever , the previous simulation based pers maybe you 're talking about the same thing . general paper about the approach here would probably be appropriate . and good to do at some point anyway .
D: also think that if we write about what we have done in the past six months , we we could craft little paper that if it gets rejected , which could happen , doesn't hurt because it 's something we
A: having it is still good thing .
D: having it is good thing . it 's exercise , usually enjoy writing papers . it 's not don't re regard it as painful thing .
A: - . it 's fun .
D: and , we should all do more for our publication lists . and . it just never hurts . and keith and - or johno will go , probably .
A: when is it and where ?
D: it 's on the twenty second of september , in saarbruecken germany .
A: it 's in germany . tomasello 's already in germany anyway , so makes sense . . so , is the what are you just talking about , the details of how to do it , or whether to do it , or what it would be ?
E: what would one possibly put in such paper ?
D: what to write about .
A: or what to write about ?
D: what is our what 's our take home message . what what do we actually because , it don't like papers where you just talk about what you plan to do . it 's obvious that we can't do any evaluation , and have no , we can't write an acl type paper where we say , "" , we 've done this and now we 're whatever percentage better than everybody else "" . . it 's far too early for that . but , we can tell them what we think . never hurts to try . maybe even that 's maybe the time to introduce the new formalism that you guys have cooked up .
E: are in the process of
A: how many pages ?
B: don't they need to finish the formalism ?
D: it 's just like four pages . it 's it 's not even
A: so it 's little thing .
B: you said it was four thousand lines ? is that what you
A: four pages is , like , really not very much space .
D: did you look at it ? it depends on the format .
E: my gosh . , you were we were talking about something which was much more like ten .
D: no that 's that 's actually problem . it 's difficu it 's more difficult to write on four pages than on eight .
A: and it 's also difficult to even if you had lot of substance , it 's hard to demonstrate that in four pages , .
E: that would be hard .
A: it 's still it 's still
D: maybe it 's just four thousand lines . do don't they don't want any they don't have tex style @ @ guide .
A: - , - .
D: they just want ascii . pure ascii lines , why , for whatever reason ,
A: not including figures and such ?
D: very unspecific unfortunately .
B: would say that 's closer to six pages actually . four thousand lines of ascii ?
E: four thousand lines . isn't isn't it about fifty fifty five , sixty lines to page ?
D: don't quote me on this . this is numbers have from looking
B: how many characters are on line ?
D: let 's let 's wh what should we should we , , discuss this over tea and all of us look at the web ? 'm wizarding today .
A: look at the web page ?
D: look at the web page and let 's talk about it maybe tomorrow afternoon ?
A: more cues for us to find it are like , neural cons
D: johno will send you link .
A: you have link . .
B: got an email . keith is comfortable with us calling him "" keith "" .
E: he he decided 'm chilling in the five - one - .
A: "" keith "" . that 's very - shirt .
D: and 'm also flying
E: got this from the two one two .
D: 'm flying to sicily next in two weeks from now , and week of business in germany . should mention that for you . and otherwise you haven't missed much , except for really weird idea , but you 'll hear about that soon enough .
A: the idea that you and already know about ? that you already told me ?
D: no , no . that is something for the rest of the gang to
E: the thing with the goats and the helicopters ?
D: change the watchband . it 's time to walk the sheep . did you catch thusion ? it 's time to walk the sheep ? it 's presumably one of the watergate codes they don't make any plans for spring break next year . that 's the other thing . we 're gonna do an int edu internal workshop in sicily .
A: that 's what that 's what he says .
D: 've already got the funding .
A: kn that 's great ! does that mean does that mean you 'll get you 'll fly us there ?
E: we 'll see .
D: no , that 's that 's what it means .
B: and he 'll put us up , too .
A: know about that part . know about the almond trees and . , , kiwi ?
D: mmm , too easy . mangos go everywhere . so do kiwi .
A: , but was trying to find something that he didn't grow on his farm .
D: but coconut anana pineapple , that 's that 's tricky , .
E: so , but we have to decide what , like , the general idea of we 're gonna have an example case to like this "" where is "" case , .
D: maybe you have it would be the paper ha would have , in my vision , flow if we could say , here is th the th here is parsing if you wanna do it right , here is understanding if you wanna do it right , and without going into technical
A: but then in the end we 're not doing like those things right yet , right ? would that be clear in the paper or not ?
D: that would be clear , mailed around little paper that have
A: it would be like , this is the idea . didn't get that ,
D: we could say , this is
B: no , don't think you got it .
D: see this , if you if you 're not around , and don't partake in the discussions , and you don't get any email ,
A: 'm . 'm , 'm . . so parsing done right is like chicken done right .
D: so we could we could say this is what 's state of the art today . nuh ? and say , this is bad . nuh ? and then we can say , what we do is this .
A: parsing done right , interpretation done right , example .
D: - . . and
A: and how much to get into the cognitive neural part ?
B: that 's the only that 's the question mark . don't you need to reduce it if it 's or reduce it , if it 's cognitive neuro
A: the conference may be cognitive neural , doesn't mean that every paper has to be both . like , nlp cognitive neural .
D: and you can you can just point to the to the literature , you can say that construction - based
A: so so this paper wouldn't particularly deal with that side although it could reference the ntl - ish , like , , approach . the fact that the methods here are all compatible with or designed to be compatible with whatever , neurological neuro - biol su . four pages you could you could definitely it 's definitely possible to do it . it 's just it 'd just be small . like introducing the formalism might be not really possible in detail , but you can use an example of it .
E: looking at that paper that you had , , like , you didn't really explain in detail what was going on in the xml cases or whatever you just sorta said , , here 's the general idea , some gets put in there . hopefully you can you can say something like constituents tells you what the construction is made out of , , without going into this intense detail .
A: so it be like using the formalism rather than , introducing it per se .
E: give them the one paragraph whirlwind tour of what this is for ,
A: and people will figure out or ask about the bits that are implicit .
D: so this will be documenting what we think , and documenting what we have in terms of the bayes - net . and since there 's never bad idea to document things , no ?
A: that 's th that 's definitely good idea .
D: that would be my , we we should sketch out the details maybe tomorrow afternoon - ish , if everyone is around . you probably wouldn't be part of it . maybe you want ? think about it . you may ruin your career forever , if you appear .
B: you might get blacklisted .
D: the , other thing , we actually have we made any progress on what we decided , , last week ? 'm you read the transcript of last week 's meeting in red so sh so you 're up to dated caught up . we decided that we 're gonna take "" where is something "" question , and pretend we have parsed it , and see what we could possibly hope to observe on the discourse side .
B: remember came in and started asking you about how we were sor going to sort out the , decision nodes ?
A: what 'd you say ?
B: remember you talking to me , just not what you said .
A: do remember you talking to me . few more bits .
B: there was like we needed to or , in my opinion we need to design bayes another sub - bayes - net it was whether it was whether we would have bayes - net on the output and on the input , or whether the construction was gonna be in the bayes - net , and outside of it ,
A: so that was that the question ?
B: that was related to what we were talking about .
D: should introduce it as sudo - square ? we have to put this in the paper . if we write it . this is this is my only constraint . the sudo - square {nonvocalsound} is , "" situation "" , "" user "" , "" discourse "" , right ? "" ontology "" .
E: saw the diagram in the office ,
A: my god , that 's amazing ! someone 's gonna start making phil collins jokes .
E: god , hope not .
A: you guys are too young .
E: like "" sussudio "" , that horrible , horrible song that should never have been created .
A: know , that was horrible .
B: 've blocked every aspect of phil collins out of my mind .
A: 'm , haven't . not on purpose .
D: also he 's talking about suicide , and that 's that 's not notion wanna have evoked .
A: no , he 's not . didn't really listen to it , was too young .
E: it sounds too rocking for that . anyway . so , what 's going on here ? so what are what was wollte der kuenstler uns damit sagen ?
A: stop excluding me .
D: so we have tons of little things here ,
A: 't believe that 's never been thought of before .
B: what are the dots ? don't remember what the dots were .
E: those are little bugs .
D: these are our , whatever , belief - net decision nodes , and they all contribute to these {nonvocalsound} things down here .
A: , what 's the middle thing ?
D: that 's edu .
A: but what is it ?
D: in the moment it 's bayes - net . and it has fifty not - yet - specified interfaces . have taken care that we actually can build little interfaces , {nonvocalsound} to other modules that will tell us whether the user likes these things and , the or these things , and he whether he 's in wheelchair or not ,
A: is that supposed to be the international sign for interface ?
B: 'd 'd never seen it before either .
D: mmm . so .
E: cuz things fit onto that , see ? in vaguely obscene fashion .
D: no , this is rme core by agent design ,
A: that 's so great .
D: there 's maybe different
E: what what are these letters again , situr - situation , user , discourse and
D: situation , user , ontology .
A: what about the utterance ?
D: that 's here .
A: so that 's not like context , .
E: discourse is all things linguistic , .
D: so this includes the current utterance plus all the previous utterances . and irena gurevich is going to be here , end of july . she 's new linguist working for eml . and what she would like to do is great for us . she would like to take the ent ontolog we have discussed in terms of the eva
A: grateful for us ? did you just say grateful for us ?
D: think of back at the eva vector , and johno coming up with the idea that if the person discussed the discussed the admission fee , in previously , that might be good indication that , "" how do get to the castle ? "" , actually he wants to enter . or , , "" how do get to ? "" discussing the admission fee in the previous utterance , is good indication . we don't want hard code , set of lexemes , or things , that person 's , filter , or search the discourse history . so what would be is that if we encounter concepts that are castle , tower , bank , hotel , we run it through the ontology , and the ontology tells us it has , admission , opening times , it has admission fees , it has this , it has that , and then we we make thesaurus lexicon , look up , and then search dynamically through the , discourse history for occurrences of these things in given window of utterances . and that might , , give us additional input to belief versus .
A: so it 's not just particular word 's so the you 're looking for few keys that are cues to , few specific cues to some intention .
B: you can dynamically look up keys , .
E: so , so , since this since this technical is going over my head ,
B: and then grep , .
E: that you that when someone 's talking about castle , that it 's the thing that people are likely to wanna go into ? or , is it the fact that if there 's an admission fee , then one of the things we know about admission fees is that you pay them in order to go in ? and then the idea of entering is active in the discourse ? and then blah - blah ?
D: the idea is even more general . the idea is to say , we encounter certain entity in in utterance . so le let 's look up everything we the ontology gives us about that entity , what it does , what roles it has , what parts , whatever it has . and , then we look in the discourse , whether any of that , or any surface structure corresponding to these roles , functions aaa has ever occurred . and then , the discourse history can tell us , "" "" , or "" no "" . and then it 's up for us to decide what to do with it .
E: no , go ahead .
D: so , we may think that if you say , "" where is the theater "" , , whether or not he has talked about tickets before , then we he 's probably wanna go there to see something . or "" where is the opera in par - paris ? , lots of people go to the opera to take pictures of it and to look at it , and lots of people go to attend performance . and , the discourse can maybe tell us what 's more likely if we to look for in previous statements . and so we can hard code "" for opera , look for tickets , look for this , look for that , or look for mozart , look for thi "" but the smarter way is to go via the ontology and dynamically , then look up .
E: but you 're still doing look up so that when the person so that when the person says , "" where is it ? "" then you say , let 's go back and look at other things and then decide , rather than the other possibility which is th through discourse as they talk about different things prior to the "" where is it "" question they say , , "" how much does it cost to get in , , to see movie around here "" , "" where is the closest theater "" the that by mentioning admission fees , that just stays active now . that becomes part of like , their current ongoing active conceptual structure . and then , , over in your bayes - net or whatever , when the person says "" where is it "" , you 've already got , since they were talking about admission , and that evokes the idea of entering , , then when they go and ask "" where is it "" , then you 're enter node is already active because that 's what the person is thinking about . that 's the cognitive linguistic - way ,
D: ultimately that 's also what we wanna get at .
E: and probably not practical .
D: that 's that 's the correct way . so , we have to keep memory of what was the last intention , and how does it fit to this , and what does it tell us , in terms of the what we 're examining . and furthermore , we can idealize that , , people don't change topics , but they do . but , even th for that , there is student of ours who 's doing dialogue act , recognition module . so , maybe , we 're even in position where we can take your approach , which is much better , as to say how do these pieces
E: and much harder to program . and much harder to to program .
D: how how do these pieces fit together ? but , , nevertheless . so these are issues but we what we actually decided last week , is to , and this is , again , for your benefit is to , pretend we have observed and parsed an utterance such as "" where is the powder - tower "" , or "" where is the zoo "" , and specify , what we think the output , observe , out input nodes for our bayes - nets for the sub - , for the discourse bit , should be . so that and will will then come up with the ontology side , bits and pieces , so that we can say , we always just look at this utterance . that 's the only utterance we can do , it 's hard coded , like srini , hand parsed , but this is what we hope to be able to observe in general from utterances , and from ontologies , and then we can fiddle with these things to see what it actually produces , in terms of output . so we need to find out what the "" where is "" construction will give us in terms of semantics and simspec type things .
A: just "" where is "" ? or any variants of that .
D: look at it this way , what did we decide . we decided the prototypical "" where is "" , where , we don't really know , does he wanna go there , or just wanna know where it is . so the difference of "" where is the railway station "" , versus where "" where is greenland "" . nuh ?
B: was just dancing , .
D: we 're not videotaping any of this .
E: so , , we 're supposed to we 're talking about anything that has the semantics of request for location , right ? anyway , the node in the the ultimate , , in the bayes - net thing when you 're done , the node that we 're talking about , is one that says "" request for location , true "" , like that , right ? and exactly how that gets activated , , like whether we want the sentence "" how do get there ? "" to activate that node or not , , that 's that 's the issue that the linguistic - side has to deal with , right ?
D: actually more more the other way around . we wanted something that represents uncertainty we in terms of going there or just wanting to know where it is , . some generic information . and so this is prototypically @ @ found in the "" where is something "" question , surface structure , which can be , should be maps to something that activates both . the idea is to let 's have it fit nicely with the paper .
B: don't see unde how we would be able to distinguish between the two intentions just from the utterance , though . bef or , before we don't before we cranked it through the bayes - net .
D: that 's exactly what we want . we want to get no . we wouldn't .
B: but then so it 's just for every construction we have node in the net , right ? and we turn on that node .
D: what what is this gonna
B: and then given that we know that the construction has these two things , we can set up probabilities we can define all the tables for ev for those
D: it should be so we have let 's assume we call something like loc - node and path - node . and what we actually get if we just look at the discourse , "" where is "" should activate should be both , whereas maybe "" where is located "" , we find from the data , is always just asked when the person wants to know where it is , and "" how do get to "" is always asked when the person just wants to know how to get there . so we want to come up with what gets , input , and how inter in case of "" where is "" question . so what would the outcome of your parser look like ? and , what other discourse information from the discourse history could we hope to get , squeeze out of that utterance ? so define the input into the bayes - net based on what the utterance , "" where is "" , gives us . so definitely have an entity node here which is activated via the ontology , so "" where is "" produces something that is stands for , whether it 's castle , bank , restroom , toilet , whatever . and then the ontology will tell us
A: that it has location like that ? or th the ontology will tell us where actually it is located ?
D: no . not . where it is located , we have , user proximity node here somewhere , which tells us how far the user how far away the user is in respect to that entity .
A: so you 're talking about , , the construction involves this entity or refers to this entity , and from the construction also that it is location is or thing that can be located . right ? ontology says this thing has location slot . sh - and that 's the thing that is being that is the content of the question that 's being queried by one interpretation of "" where is "" . and another one is , , path from current user current location to that location . so is the question it 's just that 'm not what the is the question , for this particular construction how we specify that 's the information it provides ? or or asked for ? both sides , right ?
D: you don't need to even do that . it 's just what would be @ @ observed in in that case .
A: observed when you heard the speaker say "" where is "" , or when that 's been parsed ? so these little circles you have by the ?
D: that 's exactly what we 're looking for .
B: don't like having characterizing the constructions with location and path , or li characterizing them like that . cuz you don't it seems like in the general case you wouldn't know how to characterize them . or , for when . there could be an interpretation that we don't have node for in the it just seems like @ @ has to have node for the construction and then let the chips fall where they may . versus , saying , this construction either can mean location or path . and , in this cas and since it can mean either of those things , it would light both of those up .
D: it 's the same .
E: 'm thinking about it .
D: it will be the same . so in here we have "" 'll go there "" , right ? and we have our info - on . so in my my case , this would make this happy , and this would make the go - there happy . what you 're saying is we have where - question , where - node , that makes both happy . that 's what you 're proposing , which is , in my mind just as fine . so if we have construction node , "" where is "" , it 's gonna both get the po posterior probability that it 's info - on up , info - on is true - up , and that go - there is true - up , as . which would be exactly analogous to what 'm proposing is , this makes makes something here true , and this makes something also something here true , and this makes this true - up , and this makes this true - up as .
E: kinda like it better without that extra level of indirection too . with this points to that , and so on
D: because we get we get tons of constructions . because , , mmm people have many ways of asking for the same thing ,
B: change changed my mind actually .
A: so agree with that . have different kinda question , might be related , which is , so implicitly everything in edu , we 're always inferring the speaker intent , right ? like , what they want either , the information that they want , or it 's always information that they want probably , of some kind . or what 's something that they
D: the system doesn't massage you , no . no .
A: let 's see . so if the if th just there 's more here that 's not shown that you it 's already like part of the system whatever , but , "" where is "" , like , the fact that it is , , speech - act , whatever , it is question . it 's question that , , queries on some particular thing , and is that location . there 's , like , lot of structure in representing that . so that seems different from just having the node "" location - "" and that goes into edu , right ?
D: that 's that 's
A: so tha is that what you 're talking about ?
D: exactly . we have su we have specified two .
A: wh what kinds of structure we want .
D: the next one would be here , just for mood . the next one would be what we can squeeze out of the maybe we wanna observe the , , the length of the words used , and , or the prosody and and make conclusions about the user 's intelligence .
A: so in some ways so in some ways in the other parallel set of mo more linguistic meetings we 've been talking about possible semantics of some construction . the simulation that 's , according to it , that corresponds to it , and as the as discourse , whatever , conte infor in discourse information , such as the mood , and , , other . so , are we looking for abbreviation of that , that 's tailored to this problem ? cuz that has , , , , it 's in progress still it 's in development still , but it definitely has various feature slots , attributes , , bindings between things
D: that 's exactly , why 'm proposing it 's too early to have to think of them of all of these discourse things that one could possibly observe , so let 's just assume
A: for the subset of
D: human beings are not allowed to ask anything but "" where is "" . this is the only utterance in the world . what could we observe from that ?
A: that exactly "" where is "" , not the choices of "" where is "" or "" how do get to "" . just "" where is "" .
D: just just "" where is "" . and , but , do it do it in such way that we know that people can also say , "" is the town hall in front of the bank "" , so that we need something like wh focus . nuh ? should be should be there , that , , this the whatever we get from the
A: so do , or do not take other kinds of constructions into account ?
D: if you if you can , definitely do , where possible . right ? if if it 's not triggered by our thing , then it 's irrelevant , and it doesn't hurt to leave it out for the moment .
A: it seems like , "" where is "" , the fact that it might mean , "" tell me how to get to "" , do so , would you wanna say that those two are both , like those are the two interpretations , right ? the ones that are location or path . so , you could say that the construction is question asking about this location , and then you can additionally infer , if they 're asking about the location , it 's because they wanna go to that place , in which case , the you 're jumping step and saying , "" , know where it is but also know how to get they wanna seem they seem to wanna get there so 'm gonna tell them "" . so there 's like structure
E: right , th this it 's not that this is like semantically ambiguous between these two .
A: do you kn , that
E: it 's really about this but why would you care about this ? it 's because you also want to know this , like that right ?
A: so it 's like you infer the speaker intent , and then infer plan , larger plan from that , for which you have the additional information , you 're just being extra helpful .
D: think , this is just mental exercise . if you think about , focus on this question , how would you design that ? is it do you feel confident about saying this is part of the language already to detect those plans , and why would anyone care about location , or do you actually , this is perfectly legitimate , and would not have any problems with erasing this and say , that 's all we can activate , based on the utterance out of context .
A: and just by an additional link
D: and then the the miracle that we get out the intention , go - there , happens , based on what we know about that entity , about the user , about his various beliefs , goals , desires , blah - blah .
A: with context and enough user information ,
D: but this is the thing , propose that we think about , so that we actually end up with , nodes for the discourse and ontology so that we can put them into our bayes - net , never change them , so we all there is "" where is "" , and , eva can play around with the observed things , and we can run our better javabayes , and have it produce some output . and for the first time in th in the world , we look at our output , and and see whether it 's any good .
E: here 's hoping . here 's hoping . right ? now cross your fingers .
D: , for me this is just ba matter of curiosity , wanna would like to look at , what this ad - hoc process of designing belief - net would actually produce . if if we ask it where is something . and , maybe it also enables you to think about certain things more specifically , come up with interesting questions , to which you can find interesting answers . and , additionally it might fit in really nicely with the paper . because if if we want an example for the paper , suggest there it is . so th this might be opening paragraph for the paper as saying , "" people look at kinds of at ambiguities "" , in the literature there 's "" bank "" and whatever kinds of garden path phenomenon . and we can say , , that 's all nonsense . , these things are never really ambiguous in discourse , , don't ever occur really in discourse , but normal statements that seem completely unambiguous , such as "" where is the blah - blah "" , actually are terribly complex , and completely ambiguous . and so , what every everybody else has been doing so far in , has been completely nonsensical , and can all go into the wastepaper bin ,
E: that 's always good way to begin . .
D: and the the only
E: all others are useless . that 's good .
D: but , , just not really 'm eja exaggerating , but that might be , , saying "" hey "" , , some is actually complex , if you look at it in in the vacuum and ceases to be complex in reality . and some that 's as that 's straightforward in the vacuum , is actually terribly complex in reality . would be , , also , , bottom - up linguistics , , type message . versus the old top - down school . 'm running out of time .
B: when do you need to start wizarding ?
D: at four ten . this is the other bit of news . the subjects today know fey , so she can't be here , and do the wizarding . so 'm gonna do the wizarding and thilo 's gonna do the instructing . also we 're getting person who just got fired , from her job . person from oakland who is interested in maybe continuing the wizard bit once fey leaves in august . and , she 's gonna look at it today . which is good news in the sense that if we want to continue , after the thir after july , we can . and that 's also maybe interesting for keith and whoever , if you wanna get some more into the data collection . remember this , we can completely change the set - up any time we want . look at the results we 've gotten so far for the first , whatever , fifty some subjects ?
A: you 've had fifty so far ,
D: no , we 're approaching twenty now . but , until fey is leaving , we surely will hit the some of the higher numbers . so that 's . can do more funky .
E: 'll have to look more into that data . is that around ? like , cuz that 's getting posted right away when you get it ? it has to be transcribed , ?
D: we have , found someone here who 's hand st hand transcribing the first twelve . just so we can build language model for the recognizer . but , so those should be available soon . the first twelve .
E: that that looked at the first the first one and got enough data to keep me going for , , probably most of july . so . but , . probably not the right way to do it actually .
D: but you can listen to you can listen to all of them from your solaris box . if you want . it 's always fun .
","An idea for future work was suggested during the visit of the german project manager: the possibility to use the same system for language generation.
Having a system able to ask questions could contribute significantly to training the belief-net.
Setting up certain inputs in the Bayes-net would imply certain intentions , which would trigger dialogues.
There is potential to make a conference paper out of presenting the current work and the project aspirations within a parsing paradigm.
The focus should be the Bayes-net , to which all other modules interface.
Situation , User , Discourse and Ontology feed into the net to infer user intentions.
Someone asking where the castle is after having asked about the admission fee , indicates that -given that the castle is open to tourists- they want to go there , as opposed to knowing its whereabouts.
It was suggested that they start analysing what the Discourse and Ontology would give as inputs to the Bayes-net by working on simple utterances like ""where is X?"".
With this addition , all input layers of the net would be functioning.
Although this function would be limited , it would allow for the Bayes-net to be tested in its entirety and , henceforth , extended.
The possibility of incorporating language generation into the system will have to be discussed further.
Similarly , as no one could recall some of the points of the conference call , the group will have to meet again and define the exact structure and content of the paper they are going to submit.
The Bayes-net is going to be the focus of the presentation.
In order to complete a functioning prototype of the belief-net , it was decided to start expanding the Ontology and Discourse nodes by working with a simple construction , like ""where is X?"".
A robust analysis of such a basic utterance will indicate what the limits of the information derived from the construction are , as well as ways to design the whole module and fit other constructions in.
The idea to create a language generation module for the system , along with the language understanding , was met with interest , although it was made clear that generation is not just the inverse of understanding.
Understanding what a construction entails does not mean the system can use the construction in all appropriate circumstances.
A dialogue producing system would be useful for training the system further , even though the number of input permutations could render the process computationally unwieldy.
Regarding the conference paper , it was noted that at this stage they have not completed any big parts of the system and there is no evaluation.
Similarly , the length of the paper would not allow for presentation of the formalism in detail.
The focus would have to be on cognitive motivations of the research , and not on system design , anyway.
Such motivations also apply to the belief-net: there are various direct or indirect ways to link features of the Ontology or Discourse with specific intentions.
The originating observation behind the whole project is that utterances like ""Where is X?"" are seemingly unambiguous , but , in context , they can acquire much more complex interpretations.
The SmartKom prototype was in need of de-bugging , which is now on its way.
Similarly , the work on XML is going to be finished within a day.
On the other hand , the data recording has started: almost twenty subjects have already taken part and the transcription of the recordings is running in parallel.
Meanwhile a new person , who is also a possible replacement for the wizard's task in the data collection , has been hired.
"
ami_abstractive_summary,Bed015.txt,"B: what things to talk about .
F: that 's horrible !
A: we 're recording .
B: alright . good .
F: are you doing something ? then 'm doing something . so the result of much thinking since the last time we met , , but not as much writing , , is sheet that have lot of , like , thoughts and justification of comments on but 'll just pass out as is right now . if you could pass this around ? and there 's two things . and so one on one side is on one side is the revised updated semantic specification . and the other side is , , revised construction formalism .
E: this is just one sheet , right ?
D: just one sheet .
F: it 's just one sheet . it 's just nothing else .
D: front , back .
F: enough to go around ? and in some ways it 's it 's very similar to there are very few changes in some ways from what we 've , , , done before but don't think everyone here has seen all of this . so , , 'm not where to begin . as usual the disclaimers are there are all these things are it 's only slightly more stable than it was before . and , , after little bit more discussion and especially like keith and have more linguistic things to settle in the next few days , , it 'll probably change again some more . let 's start let 's start on number two actually on the notation , because that 's , 'm thinking , possibly little more familiar to , to people . so the top block is just abstract nota it 's like , , listings of the kinds of things that we can have . and certain things that have , , changed , have changed back to this . there there 's been little bit of , , going back and forth . but all constructions have some name . forgot to include that you could have type included in this line . so something like , there 's an example the textual example at the end has clausal construction . just to show it doesn't have to be beautiful it could be , , simple old text as . there are couple of these three have various ways of doing certain things . so 'll just try to go through them . so they could all have type at the beginning . and then they say the key word construction and they have some name .
C: so so the current syntax is if it if there 's type it 's before construct that 's fine .
F: and then it has block that is constituents . and as usual all the constructions her all the examples here have only , , tsk one type of constituent , that is constructional constituent . that 's actually gonna turn out to be certainly the most common kind . but in general instead of the word "" construct "" , th here you might have "" meaning "" or "" form "" as . so if there 's some element that doesn't that isn't yet constructional in the sense that it maps form and meaning . the main change with the constructs which each of which has , , the key word "" construct "" and then some name , and then some type specification , is that it 's it 's pro it 's often sometimes the case in the first case here that what construction it is . so whatever have here is gonna be form of the word "" throw "" , or it 's gonna be form of the word , , , "" happy "" , like that . or , , some it 'll be specific word or maybe you 'll have the type . you 'll say "" need spatial relation phrase here "" or "" need directional specifier here "" . so - you could have actual type here . or you could just say in the second case that you only know the meaning type . so very common example of this is that , , in directed motion , the first person to do something should be an agent of some kind , so if , the , , run down the street then run down the street , it 's typed , , "" "" , meaning category is what 's there . the the new kind is this one that is pair skipping fonts and whatever . the idea is that sometimes there are , , general constructions that , that you 're going to need . it 's it 's the equivalent of noun phrase or prepositional phrase , like that there . and usually it has formal , considerations that will go along with it . and then , you might know something much more specific depending on what construction you 're talking about , about what meaning what specific meaning you want . so the example again at the bottom , which is directed motion , you might need nominal expression to take the place of , , , "" the big th "" , , "" the big the tall dark man "" , , "" walked into the room "" . but because of the nature of this particular construction not just that it 's nominal of some kind but in particular , that it 's some animate nominal , and which will apply just as to like , , per , simple proper noun or to some complicated expression . so if the syntax will hold but something that gives you way to do both constructional and meaning types . then don't think the , none of these examples have anything different for formal constraints ? but you can refer to any of the , , available elements and scope , right ? which here are the constructs , to say something about the relation . and if you not if you compare like the top block and the textual block , , we dropped like the little subscript . the subscripts refer to the "" form "" piece of the construct . and that , , in general it 'll be unambiguous . like if you were giving formal constraint then you 're referring to the formal pole of that . so so by saying if said "" name one "" then that means name one formal and we 're talking about formal struc which which makes sense . there are certain times when we 'll have an exception to that , in which case you could just indicate "" here the meaningful for some reason "" . or actually it 's more often that , only to handle this one special case of , , "" george and jerry walk into the room in that order "" . so we have few funny things where something in the meaning might refer to something in the form . but but we 're not gonna really worry about that for right now and there are way we can be more specific if we have to later on . and so in terms of the relations , as usual they 're before and ends . should have put an example in of something that isn't an interval relation but in form you might also have value binding . you could say that , , , "" name - one dot "" , , "" number equals "" , , plural like that . there are certain things that are attribute - value , similar to the bindings below but they 're just us usually they 're going to be value fillers , right ? and then again semantic constraints here are just are just bindings . there was talk of changing the name of that . and johno and you and like fight about that if you like ? but about changing it to "" semantic effects "" , which was little bit too order - biased and "" semantic bindings "" , which might be too restrictive in case we don't have only bindings . and so it was an issue whether constraints , there were some linguists who reacted against "" constraints "" , saying , "" , if it 's not used for matching , then it shouldn't be called constraint "" . but we want to be uncommitted about whether it 's used for matching or not . right ? cuz there are we thought of some situations where it would be useful to use whatever the bindings are , for actual , , like modified constraining purposes .
C: you definitely want to de - couple the formalism from the parsing strategy . so that whether or not it 's used for matching or only for verification ,
F: it 's used shouldn't matter , right ?
C: what , , term we want to use but we don't want to
F: , there was one time when hans explained why "" constraints "" was misleading word for him . and the reason that he gave was similar to the reason why johno thought it was misleading term , which was just an interesting coincidence . and so was like , "" , both of you don't like it ?
C: it 's it 's gone .
F: fine , we can change it "" . but 'm starting to like it again . so that 's why that 's why 'll stick with it .
A: if you have an "" if - then "" phrase , do what the "" then "" phrase is called ?
F: con - , consequent ? but it 's not an "" if - then "" .
C: anyway , so the other the other strategy you guys could consider is when you what word to put , you could put no word , and the then let
F: that 's true .
B: so that 's why you put semantic constraints up top and meaning bindings down here ?
F: no . that was just mistake of cut and paste from when was going with it . so , 'm . didn't mean that one 's an in unintentional .
B: so this should be semantic and
F: sometimes 'm intentionally inconsistent cuz 'm not yet . here , actually it was just mistake .
B: th - so this definitely should be "" semantic constraints "" down at the bottom ?
F: unless go with "" meaning "" but , like "" meaning "" better than "" semantic "" but there 's vestiges of other people 's biases . so the middle block doesn't really give you any more information , ex than the top block . and the bottom block similarly only just illus , all it does is illustrate that you can drop the subscripts and that you can drop the , , that you can give dual types . one thing should mention is about "" designates "" . 'm actually inconsistent across these as . so , , strike out the subscript on the middle block . so now , , this is actually this little change actually goes along with big linguistic change , which is that "" designates "" isn't only something for the semantics to worry about now . so we want "" designates "" to actually know one of the constituents which acts like head in some respects but is , , really important for say composition later on . so , if some other construction says , , "" are you of type is this part of type whatever "" , , the "" designates "" tells you which part is the meaning part . so if you have like "" the big red ball "" , , you wanna there 's an object or noun . ball is going to be the designated element of that phrase . there is slight complication here which is that when we talk about form it 's useful sometimes to talk about , to talk about there also being designated object and we think that 'll be the same one , right ? so the ball is the head of the phrase , "" the the "" , , "" big red ball "" , and the entity denoted by the word "" ball "" is the semantic head in some ways of this , , in interesting larger element .
C: and there 's there 's ca some cases where the grammar depends on some form property of the head . and and this enables you to get that , if understand you right .
F: right , right .
E: that 's the idea .
F: and , , you might be able to say things like if the head has to go last in head - final language , you can refer to the head as the , the formal head as opposed to the rest of the form having to be at the end of that decision . so that 's useful thing so that you can get some internal structural constraints in .
C: so th looks good . were you finished ?
F: there was list of things that isn't included but you can you can ask question . that might @ @ it .
C: so , if understand this the aside from , , construed and all that , the differences are mainly that , we 've gone to the possibility of having form - meaning pairs for type or actually gone back to , if we go back far enough
F: except for their construction meaning , so it 's not clear that , right now it 's contr construction type and meaning type . so what form type is .
C: you 're right . that 's fine .
F: and previous , , , version of the notation certainly allowed you to single out the meaning bit by it . so you could say "" construct of type whatever designates something "" . but that was mostly for reference purposes , just to refer to the meaning pole . don't think that it was often used to give an extra meaning const type constraint on the meaning , which is really what we want most of the time . if we 'll ever have case where we actually if there is form category constraint , you could imagine having triple there that says , that 's weird .
C: no , no , don't . that you 'll you 'll do fine . these are , , as long as mark isn't around , these are form constraints . so nominal expression is , the fact that it 's animate , is semantic . the fact that it 's , nominal expression would say on most people 's notion of , higher form types , this this is one .
F: right , right .
C: and that 's just fine .
F: which is fine , .
E: it 's that now , , 'm mentioned this , if ever explained this but the point of , , mentioned in the last meeting , the point of having something called "" nominal expression "" is , , because it seems like having the verb subcategorize for , , like say taking as its object just some expression which , , designates an object or designates thing , or whatever , , that leads to some syntactic problems ? so you wanna , you have this problem like "" , , 'll put the word "" , , let 's say , the word "" dog "" , and that has to come right after the verb cuz we know verb meets its object . and then we have construction that says , , you can have "" the "" preceding noun . and so you 'd have this problem that the verb has to meet the designatum . and you could get , , "" the kicked dog "" like that , meaning "" kicked the dog "" . so you have to let this phrase idea in there
C: that have no problem with it . it 's fine .
F: you may be you may not be like everyone else in berkeley , but that 's .
E: we we thought we were getting away with , with ,
F: we don't mind either ,
E: this is not reverting to the - bar theory of phrase structure . know that this is like , we didn't originally have in mind that , that verbs would subcategorize for particular form .
C: but they do .
E: but they does .
F: there 's an alternative to this
E: at least in english .
F: which is , the question was did we want directed motion , which is an argument structure construction did we want it to worry about , , anything more than the fact that it , , has semantic it 's frame - based construction . so one option that , , keith had mentioned also was like , if you have more abstract constructions such as subject , predicate , things like grammatical relations , those could intersect with these in such way that subject , predicate , or subject , predicate , subject , verb , ob , verb object would require that those things that fill subject and object are nom expressions . and that would be little bit cleaner in some way . but , for now , ,
C: but it it 's , just moving it moving the the cons the constraints around .
F: moving it to another place , right . but there does , there has to be that constraint somewhere , right ?
C: and so that was the
F: robert 's not happy now ?
C: and going with that is that the designatum also now is pair . instead of just the meaning . and that aside from some terminology , that 's it . want to 'm 'm asking .
F: the un the un - addressed questions in this , , definitely would be semantic constraints we talked about . here are just bindings we might want to introduce mental spaces there 's all these things that we don't
C: the whole the mental space thing is clearly not here .
F: so there 's going to be some extra , definitely other notation we 'll need for that which we skip for now .
C: do want to get on that as soon as robert gets back . so , , the mental space thing . , construal is is big component of that so this probably not worth trying to do anything till he gets back . but as soon as he gets back , we ought to
E: so what 's the what 's the time frame ? you 're going away for how long ?
A: just , , as mental bridge , 'm not 'm skipping fourth of july . so , , right afterwards 'm back .
F: you 're missing like the premier american holiday ? what 's the point of spending year here ?
A: 've had it often enough .
F: so , anyway .
B: he he went to college here .
C: and furthermore it 's worth missing .
F: not in california . that 's true . like like spending fourth of july in other countries , whenever .
C: so that 's great .
F: so there was one question that came out . hate this thing . so something like "" past "" which , we very simple , we 've often just stuck it in as feature , "" , this event takes place before speech time "" , , is what this means . it 's often thought of as it is also considered mental space , by , , lots of people around here . so there 's this issue of sometimes there are really exotic explicit space builders that say "" in france , blah - blah "" , and you have to build up you ha you would imagine that would require you , , to be very specific about the machinery , whereas past is very conventionalized one and we it means but it we doesn't don't necessarily want to , , unload all the notation every time we see that it 's past tense . so , , we could think of our , just like - schema "" walk "" refers to this complicated structure , past refers to , , certain configuration of this thing with respect to it .
C: that 's exactly right .
F: so so we 're like having our cake and eating it having it both ways , right ?
C: no , that we 'll have to see how it works out when we do the details but my intuition would be that 's right .
A: do you want to do the same for space ?
F: , , instead of just time ? so there are very conventionalized like deictic ones , right ? and then for other spaces that you introduce , you could just attach you could build up an appropriately , appropriate structure according to the the sentence .
A: this would involve everything you can imagine to fit under your dot something where it 's contextually dependent , "" what is now , what was past , what is in the future , where is this , what is here , what is there ,
F: so time and space . we 'll we 'll get that on the other side little , like very minimally . there 's there 's slot for setting time and setting place . you could imagine for both of those are absolute things you could say about the time and place , and then there are many in more interestingly , linguistically anyway , there are relative things that , , you relate the event in time and space to where you are now . if there 's something lot more complicated like , or so hypothetical or whatever , then you have to do your job , like or somebody 's job anyway . 'm gonna point to at random .
E: 'm 'm curious about how much of the mental 'm not that the formalism , the grammatical side of things , is gonna have that much going on in terms of the mental space . , all of these so - called space builders that are in the sentence are going to of it as , giving you the coordinates of , assuming that at any point in discourse there 's the possibility that we could be talking about bunch of different world scenarios , whatever , and the speaker 's supposed to be keeping track of those . the , the construction that you actually get is just gonna give you cue as to which one of those that you 've already got going , , you 're supposed to add structure to . so "" in france , , watergate wouldn't have hurt nixon "" like that . , you say , "" alright , 'm supposed to add some structure to my model of this hypothetical past france universe "" like that . the information in the sentence tells you that much but it doesn't tell you like exactly what it what the point of doing so is . so , depending on the linguistic con , context it could be like the question is , what does "" watergate "" refer to there ? does it , does it refer to , if you just hear that sentence cold , the assumption is that when you say "" watergate "" you 're referring to "" watergate - like scandal as we might imagine it happening in france "" . but in different context , "" , , if nixon had apologized right away it wouldn't , watergate wouldn't have hurt him so badly in the us and in france it wouldn't have hurt him "" . now we 're now that "" watergate "" we 're now talking about the real one ,
F: they 're real , right .
E: and the "" would "" it 's different dimension of hypothe - theticality , right ? we 're not saying what 's hypothetical about this world . in the first case , hypothetically we 're imagining that watergate happened in france . in the second case we 're imagining hypothetically that nixon had apologized right away so lot of this isn't happening at the grammatical level . where that sits then , the idea of sorting out what the person meant .
F: it seems like , , the grammatical things such as the auxiliaries that introduce these conditionals , whatever , give you the most basi th those we we can figure out what the possibilities are , right ? there are relatively limited number . and then how they interact with some extra thing like "" in france "" or "" if such - and - such "" , that 's like there are certain ways that they they can one is more specific version of the general pattern that the grammat grammar gives you . but , , whatever ,
C: in the short run all we need is enough mechanism on the form side to get things going .
E: but the whole point of the whole point of what fauconnier and turner have to say about , , mental spaces , and blending , and all that is that you don't really get that much out of the sentence . there 's not that much information contained in the sentence . it just says , "" here . add this structure to this space . "" and exactly what that means for the overall ongoing interpretation is quite open . an individual sentence could mean hundred different things depending on , quote , "" what the space configuration is at the time of utterance "" . and so somebody 's gonna have to be doing whole lot of work but not me , .
C: that 's right . , , that 's not th don't 's completely right . sentence examples you gave in did constrain the meaning the form did constrain the meaning , and so , , it isn't ,
E: but like what was the point of saying that sentence about nixon and france ? that is not there is nothing about that in the in the sentence really .
F: we usually the point of the sentence . but we it 's trying to say . we we know that it 's what predication it 's setting up .
C: but but bottom line , agree with you ,
F: that 's all .
C: that that we 're not expecting much out of the ,
F: purely linguistic cues , right ?
C: the purely form cues , . and , , you 're you 're the linguist but , , it seems to me that th these we , we 've talked about maybe half dozen linguistics theses in the last few minutes . , that 's my feeling that these are really hard , problems that decide exactly what 's going on .
F: so , , one other thing want to point out is there 's lot of confusion about the terms like "" profile , designate , focus "" , et cetera , et cetera .
C: right , right .
F: for now 'm gonna say like "" profile "" 's often used like two uses that come to mind immediately . one is in the traditional like semantic highlight of one element with respect to everything else . so "" hypotenuse "" , you profiled this guy against the background of the right right triangle . and the second use , , is in framenet it 's was asking hans about this . they use it to really mean , , this in frame th this is the profiles on the these are the ones that are required . so they have to be there or expressed in some way . which which 'm not saying one and two are mutually exclusive but they 're they 're different meanings . so the closest thing so was thinking about how it relates to this notation . so how is it
C: does that is that really what they mean in
F: so "" designate "" framenet ?
C: didn't know that .
F: was little bit surprised about it too . that would be something like there 's another term that 've heard for that thing but they , , at least hans says they use it that way . and may maybe he 's wrong . the "" designate "" that we have in terms of meaning is really the "" highlight this thing with respect to everything else "" . ? so this is what it means . but the second one seems to be useful but we might not need notation for it ? we don't have notation for it but we might want one . so we 've talked about if you 're talking about the lexical item "" walk "" , it 's an action . it also has this idea it carries along with it the idea of an actor or somebody 's gonna do the walking . or if you talk about an adjective "" red "" , it carries along the idea of the thing that has the property of having color red . so we used to use the notation "" with "" for this and that 's closest to their second one . so don't yet know , have no commitment , as to whether we need it . it 's the thing that parser might want to think about whether we require these things are like it 's semantically part of it
C: no , no . , th critically they 're not required syntactically . often they 're pres presu presupposed and all that .
F: right , right . , , definitely . "" in "" was good example . if you walk "" in "" , like , in what ?
C: right , there 's
F: like you have to have the so so it 's only semantically is it it is still required , say , by simulation time though to have something . so it 's that the idea of like that the semantic value is filled in by sim simulation . if that 's something we need to spa to like say ever as part of the requirement ? or the construction ? we 'll we 'll again defer .
C: or , or ,
F: have it construed , is that the idea ? just point at robert . whenever 'm confused just point to him .
C: it 's it 's his thesis , right ?
F: you tell me .
C: right , , this is gonna be you 're right , this is bit of in mess and we still have emphasis as , or stress , or whatever .
F: we 'll get , , we have thoughts about those as . some of this is just like my , by fiat . 'm going to say , this is how we use these terms . don't - , there 's lots of different ways in the world that people use it .
C: that 's fine .
F: that , , the other terms that are related are like focus and stress . that the way we would like to think , , is focus is something that comes up in , , lots of this is the information structure . it 's like , it 's not it might be that there 's syntactic , , device that you use to indicate focus or that there are things like , , keith was telling me , things toward the end of the sentence , post - verbal , tend to be the focused element , the new information . if "" walked into the room "" , you tend to think that , whatever , "" into the room "" is like the more focused thing . and when you , , you have stress on something that might be , , cue that the stressed element , or , the negated element is related to information structure . so that 's like the new the like import or whatever of this thing . so that 's to keep "" focus "" being an information structure term . th and then there are different kinds of focus that you can bring to it . so , , like "" stress "" , th stress is pun on you might have like whatever , like , , accent stress . and that 's just we 'll want to distinguish stress as form device . like , , high volume or whatever . and distinguish that from it 's effect which is , "" , the focus we have is we 're emphasizing this value often as opposed to other values "" , right ? so focus carries along scope . like if you 're gonna focus on this thing and you wanna evokes all the other possibilities that it wasn't . so my classic my now - classic example of saying , "" , he did go to the meeting ? "" , that was my way of saying as opposed to , , "" , he didn't "" or "" there was meeting ? "" that was the example that was caught on by the linguists immediately . and so , , the like if you said he there 's all these different things that if you put stress on different part of it then you 're , focusing , whatever , on , "" he walked to the meeting "" as opposed to "" he ran "" , or "" he did walk to the meeting "" as opposed to "" he didn't walk "" . , so we need to have notation for that that 's still in progress . so , 'm still working it out . but it did one implication it does have for the other side , which we 'll get to in minute is that couldn't think of good way to say "" here are the possible things that you could focus on "" , cuz it seems like any entity in any sentence , , or any meaning component of anyth all the possible meanings you could have , any of them could be the subject of focus . but one the one thing you can schematize is the focus , right ? so , you could say it 's the tense on this as opposed to , , the action . . or it 's , it 's an identity thing or contrast with other things , or stress this value as opposed to other things . it 's it is like profile - background thing but 't think of like the limited set of possible meanings that you would that you would focu
E: light up with focus , .
F: as opposed to other ones . so it has some certain complications for the , later on . li - , , the best thing come up with is that information has list of focused elements . you , one other type that forgot to mention is like query elements and that 's probably relevant for the like "" where is "" , , "" the castle "" thing ? because you might want to say that , , location or cert certain wh words bring , automatically focus in , , "" the identity of this thing "" way on certain elements . anyway . so that 's onl there are there are many more things that are uncl that are like little bit unstable about the notation but it 's most it 's this is , , the current form . other things we didn't deal with , ,
E: there 's bunch .
F: we 've had lot of other that keith and have them working on in terms of like how you deal with like an adjective . we should have put an example of this and we could do that later . but the not inherently like the general principles still work though , that , , we can have constructions that have constituent structure in that there is like , , , one , they have constituents , right ? so you can like nest things when you need to , but they can also overlap in flatter way . so if you don't have like lot of grammar experience , then like this might , , be little opaque . but , , we have the properties of dependency grammars and some properties of constituents constituent - based grammar . so that 's that 's the main thing we wanted to aim for and so far it 's worked out .
A: say two things about the maybe you want to forget stress . no , as just don't don't think about it .
F: what 's that ?
A: canonically speaking you can if you look at curve over sentence , you can find out where certain stress is and say , "" hey , that 's my focus exponent . "" it doesn't tell you anything what the focus is . if it 's just that thing ,
F: or the constituent that it falls in .
A: little bit more or the whole phrase .
F: you mean forget about stress , the form cue ?
A: because , , as form cue , , not even trained experts can always , they can tell you where the focus exponent is sometimes . and that 's also mostly true for read speech . in in real speech , , people may put stress . it 's so context dependent on what was there before , phrase ba breaks , , restarts . it 's just , it 's absurd . it 's complicated .
E: , 'm inclined to say let 's worry about specifying the information structure focus of the sentence
F: believe you , . ways that you can get it come from th
E: hhh , the phonology component can handle actually assigning an intonation contour to that . , later on we 'll worry about exactly how
A: or or map from the contour to what the focus exponent is .
E: but figure out how the
A: but , , if you what you 're what you 're focus is then you 're you 're hopeless - - ly lost anyways ,
F: that 's fine , .
A: and the only way of figuring out what that is , is , , by generating all the possible alternatives to each focused element , decide which one in that context makes sense and which one doesn't . and then you 're left with couple three . so , , again , that 's something that humans can do , but far outside the scope of any anything .
F: , , , wouldn't have assumed that it 's an easy problem in absence of all the oth you need all the other information .
A: but it 's what it , it 's pretty easy to put it in the formalism , though . you can just say whatever , "" is the container being focused or the entire whatever , both , and . ""
F: - , - . exactly . so the effect of it is something we want to be able to capture .
C: so but the poi but here 's what th going on . that if we do the constructions right when particular construction matches , it the fact that it matches , does specify the focus .
F: 'm not about that . or it might limit it cert certainly constrains the possibilities of focus .
C: at the very least it constrai
F: that 's that 's , th that 's certainly true . and depending on the construction it may or may not specify the focus , right ?
C: , for , yes . there are constrai , it 's not every but there are constructions , , where you explicitly take into account those considerations that you need to take into account in order to decide which what is being focused .
A: so we talked about that little bit this morning . "" john is on the bus , not nancy . "" so that 's focuses on john . "" john is on the bus and not on the train . "" "" john is on the bus "" versus "" john is on the train . "" and "" john is on the bus "" versus "" was "" , and
F: "" john is on the bus "" .
A: "" it 's the bu "" so
C: all of those .
A: and will we have is it all the same constructions ? just with different foc focus constituent ?
F: would say that argument structure in terms of like the main like , the fact that you can get it without any stress and you have some whatever is predicated anyway should be the same set of constructions . so that 's why was talking about overlapping constructions . so , then you have separate thing that picks out , , stress on something relative to everything else .
C: so , the question is actually
F: and it and that would have to it might be ambiguous as , , whether it picks up that element , or the phrase , like that . but it 's still is limited possibility . so that should , , interact with it should overlap with whatever other construction is there .
C: the question is , do we have way on the other page , , when we get to the semantic side , of saying what the stressed element was , or stressed phrase , .
F: so that 's why was saying how since couldn't think of an easy like limited way of doing it , , all say is that information structure has focused slot and that should be able to refer to
C: so that 's down at the bottom here when we get over there .
F: and , infer and don't have don't have great way or great examples
C: 'll - 'll .
F: but that something like that is probably gonna be , , more what we have to do . that was one comment . and you had another one ?
A: the once what the focus is the everything else is background . how about "" topic - comment "" that 's the other side of information .
F: how about what ?
A: topic - comment .
F: so that was the other thing . and so didn't realize it before . it 's like , "" ! "" it was an epiphany that it , topic and focus are contrast set . topic - focused seems to me like , , background profile , , or landmark trajector , or some something like that . there 's there 's definitely , , that thing going on . don't have as many great examples of like topic - indicating constructions on like focus , right ? topic it seems , that might be an ongoing thing .
E: japanese has this though . that 's what "" wa "" is , just to mark which thing is the topic . it doesn't always have to be the subject .
F: so again , information structure has topic slot . and , , stuck it in thinking that we might use it . stuck it in .
C: it 's there .
F: one thing that didn't do consistently , , is when we get there , is like indicate what thing fits into every role . have an idea of what it should be so far we 've been getting away with like either type constraint or , , , whatever . forg it 'll be frame . it 'll be it 'll be another predication or it 'll be , , , some value from some something , some variable and scope like that , or slot chain based on variable and scope . should we flip over to the other side officially then ? keep , , like , pointing forward to it . now we 'll go back to so this doesn't include something which mi may have some effect on it , which is , , the discourse situation context record , right ? so didn't just like draw line and like , , you also have , , some tracking of what was going on . and this is big scale comment before , , look into the details of this . but you could imagine instead of having changed the name of it used to be "" entities "" . so you see it 's "" scenario "" , "" referent "" and "" discourse segment "" . and "" scenario "" is essentially what what 's the basic predication , what event happened . and actually it 's just list of various slots from which you would draw in order to paint your picture , bunch of frames , bi and bindings , right ? and there are other ones that are not included here , general cultural frames and general like , , other action specific - schema frames . the middle thing used to be "" entities "" because you could imagine it should be like really list where here was various information . and this is intended to be grammatically specifiable information about referent , , about some entity that you were going to talk about . so "" harry walked into the room "" , "" harry "" and "" room "" , th but they would be represented in this list somehow . and it could also have , it has this category slot . it should be either category or in or instance . it could be pointer to ontology . so that everything about this could be could be drawn in . but the important things for grammatical purposes are for things like number , gender , ki the ones included here are slightly arbitrary but you could imagine that , , you need to figure out wheth if it 's group whether , , some event is happening , linear time , linear spaces , like , , are they doing something serially or is it like , 'm 'm not . because this partly came from , , talmy 's schema and 'm not we 'll need all of these actually . and then the "" status "" used was like , again , in some languages , , like in child language you might distinguish between different status . so , th the big com and finally "" discourse segment "" is about speech - act - information structure - , like utterance - specific kinds of things . so the comment was going to make about , , changing entity the entity 's block to reference is that you can imagine your discourse like situation context , you have set of entities that you 're referring to . and you might that might be general , , database of all the things in this discourse that you could refer to . and changed to "" reference "" cuz would say , for particular utterance you have particular referring expressions in it . and those are the ones that you get information about that you stick in here . 's going to be plural . 's gonna be feminine like that . and and these could actually just point to , , the id in my other list of enti active entities , right ? th there 's there 's all this about discourse status . we 've talked about . almost listed "" discourse status "" as slot where you could say it 's active . there 's this , , hierarchy there 's schematization of , , things can be active or they can be , , accessible , inaccessible . it was the one that , , keith , , emailed to us once , to some of us , not all of us . that noticed that , , list was discourse dependent . it was like in this particular set , , instance , it has been referred to recently or it hasn't been , or this is something that 's like in my world knowledge but not active .
C: there seems to be context properties .
F: they 're contex and , used to have location thing there but actually that 's property of the situation . and it 's again , time , at cert certain points things are located , , near or far from you
C: , this is recursive cuz until we do the , mental space story , we 're not quite th - th which is fine . we 'll just we 'll
F: so some of these are ,
C: we just yet .
F: so so for now , maybe 'll just have in this list the things that are relevant to this particular utterance , right ? everything else here is utterance - specific . and left the slot , "" predications "" , open because you can have , , things like "" the guy know from school "" . or , , like your referring expression might be constrained by certain like unbounded na amounts of prep , predications that you might make . and it 's unclear whether you could just have in your scenario , "" here are some extra few things that are true "" , right ? and then you could just not have this slot here . right ? you 're but it 's used for identification purposes . so it 's it 's little bit different from just saying "" all these things are true from my utterance "" .
E: right , "" this guy know from school came for dinner "" does not mean , , "" there 's guy , know him from school , and he came over for dinner "" . that 's not the same effect .
F: it 's little bit it 's little bit different . or maybe that 's like restrictive , non - restrictive it 's like it gets into that thing for but maybe 'm mixing , this is like the final result after parsing the sentence . so you might imagine that the information you pass to , in identifying particular referent would be , "" , some "" , "" it 's guy and it 's someone know from school "" . so maybe that would , , be some intermediate structure that you would pass into the disc to the , whatever , construal engine or whatever , discourse context , to find , either create this reference , in which case it 'd be created here , so you could imagine that this might not so , , 'm uncommitted to couple of these things .
A: but to make it precise at least in my mind , , it 's not precise . so "" house "" is gender neuter ?
F: it could be in semantically , . . so it , table . thing that doesn't have gender . so . , it could be that , maybe you 'd maybe not all these wou would say that tried to keep slots here that were potentially relevant to most things .
A: no , just to make that we everybody that 's completely that it has nothing to do with , , form .
F: that is semantic as opposed to that 's right .
A: then "" predications "" makes sense to have it open like , , accessibility or not .
F: open to various things . so . let 's see . so maybe having made that big sca like large scale comment , should go through each of these slots , each of these blocks , , little bit ? mostly the top one is image schematic . and just note , which was that , so when we actually ha some of them seem more inherently static , , like container or support - ish . and others are little bit seemingly inherently dynamic like "" source , path , goal "" is often thought of that way or "" force "" , like that . but in actual fact , that they 're intended to be neutral with respect to that . and different - schemas use them in way that 's either static or dynamic . so "" path "" , you could just be talking about the path between this and this . and , "" container "" that you can go in and out . all of these things . and so , , this came up when , , ben and were working with the spaniards , , the other day the "" spaniettes "" , as we called them to decide like how you want to split up , like , image schematic contributions versus , like , - schematic contributions . how do you link them up . , it 's gonna be something in the - schema that tells you "" is this static or is this dynamic "" . so we definitely need that aspectual type gives you some of that . that , , is it , , state or is it change of state , or is it , , action of some kind ?
A: is there any meaning to when you have parameters behind it and when you don't ?
F: ! you mean , in the slot ? no , it 's like - sc it 's it 's like was thinking of type constraints but - schema , it has to be an - schema . "" agent "" , , the performer of the - schema , that depends on the - schema . and in general it would probably be ,
E: so the difference is whether you thought it was obvious what the possible fillers were .
F: "" aspectual type "" probably isn't obvious but should have so , neglected to stick something in . "" perspective "" , "" actor "" , "" undergoer "" , "" observer "" , , we 've often used "" agent "" , "" patient "" , obser
E: "" whee ! "" that 's that one , right ?
F: exactly . exactly . and so one thing that , , we had talked about is this example of like , if you have passive construction then one thing it does is ch definitely , it is one way to for you to , , specifically take the perspective of the undergoing object . and so then we talked about , , whether , does that specify topic as ? maybe there are other things . now that it 's subject is more like topic . and now that , anyway . so . 'm gonna trail off on that one cuz it 's not that important right now .
C: now , for the moment we just need the ability to write it down if somebody figured out what the rules were .
F: some of these other ones , let 's see . one thing 'm uncertain about is how polarity interacts . so polarity , , is using for like action did not take place . so by default it 'll be like "" true "" , , if you 're specifying events that did happen . you could imagine that you skip out this , leave off this polarity , not don't have it here . and then have it part of the speech - act in some way . there 's some negation . but the reason why left it in is cuz you might have change of state , let 's say , where some state holds and then some state doesn't hold , and you 're just talking , if you 're trying to have the nuts and bolts of simulation you need to know that , , whatever , the holder doesn't and
C: no , th at this lev which is it should be where you have it .
F: it 's so it 's it 's fine where it is .
C: how you get it may in will often involve the discourse
F: may come from few places .
C: but by the time you 're simulating you sh you should know that .
E: so , 'm still just really not clear on what 'm looking at . the "" scenario "" box , like , what does that look like for an example ? like , not all of these things are gonna be here . this is just says
F: it 's grab bag of
E: "" part of what 'm going to hand you is whole bunch of , schemas , image , and - schemas . here are some examples of the sorts of things you might have in there "" .
F: so that 's exactly what it is . and for particular instance which will , , make an example of something , is that you might have an instance of container and path , let 's say , as part of your , , "" into "" , definition . so you would eventually have instances filled in with various values for all the different slots . and they 're bound up in , , their bindings and and values .
E: do you have to say about the binding in your is there slot in here for that tells you how the bindings are done ?
C: no , no . let 's see , we 're we 're not don't think we have it quite right yet . so , , what this is , let 's suppose for the moment it 's complete . , then this says that when an analysis is finished , the whole analysis is finished , you 'll have as result , , some resulting semspec for that utterance in context , which is made up entirely of these things and , , bindings among them . and bindings to ontology items . so that the who that this is the tool kit under whi out of which you can make semantic specification . so that 's . but , which is more relevant to your life , is this is also the tool kit that is used in the semantic side of constructions . so this is an that anything you have , in the party line , anything you have as the semantic side of constructions comes , from pieces of this ignoring li in general , you ignore lots of it . but it 's got to be pieces of this along with constraints among them . so that the , , goal of the , , "" source , path , goal "" has to be the landmark of the conta , the interior of this container . or whate whatever . so those constraints appear in constructions but this is the full range of semantic structures available to you .
F: except for "" "" , that forgot . but anyway , there 's som some causal structure for composite events .
C: let 's let 's mark that .
F: , so it gets little funny . these are all so far these structures , especially from "" path "" and on down , these are relatively familiar , , image schematic slots . now with "" "" , , the fillers will actually be themselves frames . right ? so you 'll say , "" event one causes event
C: and and this this again may ge our , and we and , , worlds .
F: event two "" , so that 's , these are all implicitly one within , within one world . even though saying that place takes place , whatever . if if said "" time "" is , , "" past "" , that would say "" set that this world "" , , "" somewhere , before the world that corresponds to our current speech time "" . so . but that that 's . the the within the event it 's st it 's still one world . so "" "" and other frames that could come in , unfortunately you could bring in say , , , "" desire "" like that , like "" want "" . and actually there is right now under "" discourse segments "" , , "" attitude "" ? "" volition "" ? could fill that . so there are couple things where like , "" , 'm not if wanted to have it there or "" there was whole list of possible speaker attitudes that like say talmy listed . and , like , , don't , it was like "" hope , wish . desire "" , blah - blah . and it 's like , , feel like if wanted to have an extra meaning if those are grammatically marked in the first place . so they 're more lexically marked , right ? at least in english . so if wanted to would stick in an extra frame in my meaning , saying , so th it 'd be hierarchical frame them , right ? like "" naomi wants su certain situation and that situation itself is state of affairs "" .
C: so so , "" want "" itself can be
F: can be just another frame that 's part of your
C: and it it 's an action . in in our in our in our
F: situation . right , right .
C: in our in our terminology , "" want "" can be an action and "" what you want "" is world . so that 's , it 's certainly one way to do it . there are other things . causal we need . mental space we need . the context we need . so anyway , keith so is this comfortable to you that , , once we have this defined , it is your tool kit for building the semantic part of constructions . and then when we combine constructions semantically , the goal is going to be to fill out more and more of the bindings needed in order to come up with the final one . and that 's the wh and , that according to the party line , that 's the whole story .
E: right . that makes sense . so , there 's this in the off in the scenario , which just tells you how various what schemas you 're using and they 're how they 're bound together . and that some of the discourse segment is that where you would sa that 's where the information structure is which is profiling on different parts of , , of this . what 's interesting is that the information structure there 's almost , we keep coming back to how focus is like this , , trajector - landmark thing . so if say , , , "" in france it 's like this "" . we 've learned something about france but the fact is that utterances of that sort are generally used to help you draw conclusion also about some implicit contrast , like "" in france it 's like this "" . and therefore you 're supposed to say , "" boy , life "" "" in france kids are allowed to drink at age three "" . and you 're that 's not just fact about france . you also conclude something about how boring it is here in the . right ?
F: right , right . so would prefer not to worry about that for right now and to think that there are , , discourse level constructions in sense , topic - focus constructions that would say , "" , when you focus something "" then just done the same way just actually in the same way as the lower level . if you stressed , , "" john went to the "" , , "" the bar "" whatever , you 're focusing that and in possible inference is "" in contrast to other things "" . so similarly for whole sentence , , "" in france such - and - such happens "" . so the whole thing is like again implicitly as opposed to other things that are possible .
A: just , , look read even sem semi formal mats rooth . if you haven't read it . it 's . and just pick any paper on alternative semantics . so that 's his that 's the best way of talking about focus , is his way .
E: what was the name ?
A: yes , th . never know how to pronounce his name because he 's , and , but very confused background . so and , , and sadly enough he also just left the ims in stuttgart . so he 's not there anymore . where he is right now but alternative semantics is if you type that into an , , browser or search engine you 'll get tons of . and what 'm confused about is what the speaker and the hearer is doing there .
F: so for particular segment it 's really just reference to some other entity again in the situation , right ? so for particular segment the speaker might be you or might be me . hearer is little bit harder . it could be like multiple people . that that 's not very clear from here
A: but you don't we ultimately want to handle that analogously to the way we handle time and place ,
F: that 's not allowed here .
A: because "" you "" , "" me "" , "" he "" , "" they "" , "" these guys "" , all these expressions , nuh , are in much the same way contextually dependent as "" here , "" and "" now , "" and "" there ""
C: now , this is this is assuming you 've already solved that . so it 's it 's fred and mary , so the speaker would be fred
F: right , so the constructions might will refer , using pronouns or whatever . in which case they have to check to see , , who the , , speaker in here wa in order to resolve those . but when you actually say that "" he walked into "" , whatever , , the "" he "" will refer to particular you you will already have figured who "" he "" or "" you "" , mmm , or "" "" , maybe is bett better example , who "" "" refers to . and then you 'd just be able to refer to harry , , in wherever that person whatever role that person was playing in the event .
A: that 's up at the reference part . and down there in the speaker - hearer part ?
F: so , that 's that 's just speaker is known from the situation , right ? you 're when you hear something you 're told who the speaker is who the speaker is . that 's constraining how in some ways this before you get to the you fill in all the rest of it . how else would you
A: , it 's the speaker may in english is allowed to say "" . "" among the twenty - five percent most used words . but wouldn't the "" "" then set up the referent that happens to be the speaker this time and not "" they , "" whoever they are .
F: right , right .
A: or "" you "" much like the "" you "" could
F: so , so would say ref under referent should be something that corresponds to "" "" . and maybe each referent should probably have list of way whatever , the way it was referred to . so that 's "" "" but , , should we say it refers to , what ? if it were "" harry "" it would refer to like some ontology thing . if it were if it 's "" "" it would refer to the current speaker , which is given to be like , , whoever it is .
A: so there 's "" and then he said , "" - .
F: "" "" within the current world .
C: that 's right . so so again , this , this is gonna to get us into the mental space and because , "" fred said that mary said "" , and whatever . and and so we 're , gonna have to , , chain those as .
A: twhhh - whhh .
F: so this entire thing is inside world , not just like the top part .
C: except it 's it 's trickier than that because , the reference so he where it gets really tricky is there 's some things , and this is where blends and all terribl so , some things which really are meant to be identified and some things which aren't . all we need for the moment is some way to say that .
F: so of having like for each referent , having the list of the things with which it is identified . which , , you you
C: you could do that .
F: it depends on if it is referring exp if it 's identifiable already or it 's new thing . if it 's new thing you 'd have to like create structure or whatever . if it 's an old thing it could be referring to , , usually something in situation , right ? there 's , whatever , it it could point at one of these .
C: had had an idea that would be very if it works . , haven't told you what it is yet .
F: if it works .
C: this was my build - up .
F: - . mmm .
C: an an idea that would be
F: we 're crossing our fingers .
B: so we 're building mental space , good .
C: if it worked . right , it was space builder . we might be able to handle context in the same way that we handle mental spaces because , , you have somewhat the same things going on of , , things being accessible or not . it it , if we did it right we might be able to get at least lot of the same structure .
F: use the same .
C: so that pulling something out of discourse context is similar to other kinds of , , mental space phenomena . 've 've never seen anybody write that up but maybe they did . that may be all over the literature .
E: there 's things like ther , there 's all kinds of like , , in mentioned last time in czech if you have verb of saying then
F: so so by default
E: , you say something like or was thinking you can say something like , "" , , , you are republican "" like that . where as in english you would say , "" you were "" . , the past tense being copied onto the lower verb doesn't happen there , so you have to say something about , , tense is determined relative to current blah - blah . same things happens with pronouns . there 's languages where , , if you have verb of saying then , so situation like "" bob said he was going to the movies "" , where that lower subject is the same as the person who was saying or thinking , you 're actually required to have "" "" there . and it 's in an extended function
C: so we would have it be in quotes in english .
E: but it 's not perceived as quotative construction . it 's been analyzed by the formalists as being logophoric pronoun , which means pronoun which refers back to the person who is speaking or that thing , right ?
F: right . , that makes sense .
E: but , that happens to sound like the word for "" "" but is actually semantically unrelated to it .
C: good , love the formali
F: you 're kidding .
E: there 's whole book which operates on this assumption . this book , ninety - three book on , on pronoun .
F: no , that 's horrible . that 's horrible . .
E: . and then the same thing for asl where , , you 're signing and someone says something . and then , , so "" he say "" , and then you do role shift . and then you sign "" , this , that , and the other "" . and , "" did this "" . that 's also been analyzed as logophoric and having nothing to do with "" "" . and the role shift thing is completely left out and so on . that pronoun references , , , ties in with all this mental space and so on , and . and so , ,
C: so that that does sound like it 's co consistent with what we 're saying , .
F: so it 's like the unspecified mental spaces just are occurring in context . and then when you embed them sometimes you have to pop up to the , depending on the construction or the whatever , , you you 're scope is might extend out to the base one . it would be to actually use the same , , mechanism since there are so many cases where you actually need it 'll be one or the other . it 's like , , actually , it 's the same operation .
C: , so this is worth some thought .
E: it 's like it 's like what 's happening that , , what 's happening , , there is that you 're moving the base space like that , right ? so that 's that 's how fauconnier would talk about it . and it happens diff under different circumstances in different languages . things like pronoun reference and tense which we 're thinking of as being these discourse - things actually are relative to bayes space which can change . and we need all the same machinery .
C: but , , this is very good actually cuz it to the extent that it works , it
F: ties it all into it .
C: it ties together several of these things .
A: and 'm gonna read the transcript of this one . but the , , but it 's too bad that we don't have camera . all the pointing is gonna be lost .
B: every time nancy giggles it means it means that it 's your job .
F: that 's why said "" point to robert "" , when did it .
A: mmm , isn't , 'm was dubious why he even introduces this reality , , as your basic mental space and then builds up doesn't start with some because it 's so obvi it should be so obvious , at least it is to me , that whenever say something could preface that with "" . "" so there should be no categorical difference between your base and all the others that ensue .
C: no , but there 's there 's gricean thing going on there , that when you say "" "" you 're actually hedging .
F: it 's like don't think
E: it 's an it 's an evidential . it 's semi - grammaticalized . people have talked about it this way . and , you can do special things . you can , th put just the phrase "" "" as parenthetical in the middle of sentence and so on , and .
F: actually one of the child language researchers who works with tomasello studied bunch of these constructions and it was like it 's not using any interesting embedded ways just to mark , , uncertainty like that .
A: but about linguistic hedges , those tend to be , , funky anyways
C: so we don't have that in here either do we ?
F: hhh , there used to be slot for speaker , , it was something like factivity . couldn't really remember what it meant so took it out . but it 's something
E: we were just talking about this evidentiality and like that , right ?
F: we were talking about sarcasm too , right ?
E: that 's what is , telling you what percent reality you should give this
C: so we probably should . confidence like that .
E: and the fact that 'm , the fact maybe if it versus he thinks that might , , depending on how much you trust the two of us or whatever ,
A: great word in the english language is called "" about "" . if you study how people use that it 's also
F: what 's the word ?
A: "" about . ""
C: that in that use of "" about "" , .
F: , as hedge .
C: and if you want us to spend pleasant six or seven hours you could get george started on that .
E: he wrote paper about thirty - five years ago on that one .
B: read that paper , the hedges paper ? read some of that paper actually .
E: would you believe that paper lead directly to the development of anti - lock brakes ? ask me about it later 'll tell you how . when we 're not on tape .
F: 'd love to know . so , and , , someone had raised like sarcasm as complication at some point .
C: there 's all that .
F: we just won't deal with sarcastic people .
E: we we don't have to care too much about the speaker attitude , right ? like there 's not so many different
F: certainly not as some they 're intonational markers for the most part . too much about the like grammatical
E: there 's lots of different attitudes that the speaker could have and that we can clearly identify , and so on , and . but like what are the distinctions among those that we actually care about for our current purposes ?
C: right , so , , this raises the question of what are our current purposes .
F: , do we have any ?
E: here it is three - fifteen already .
C: but , , it does seem that , this is this is coming along . it 's it 's converging . it 's as far as tell there 's this one major thing we have to do which is the mental the whole mental space thing . and then there 's some other minor things . and we 're going to have to bound the complexity . if we get everything that anybody ever thought about , we 'll go nuts . so we had started with the idea that the actual , , constraint was related to this tourist domain and the kinds of interactions that might occur in the tourist domain , assuming that people were being helpful and weren't trying to there 's all sorts of god knows , irony , and like which you isn't probably of much use in dealing with tourist guide . no end of things th that , , we don't deal with .
A: isn't that part easy though because in terms of the simspec , it would just mean you put one more set of brack brackets around it , and then just tell it to negate whatever the content of that is in terms of irony
F: in model theory cuz the semantics is always like "" speaker believes not - "" , like "" the speaker says and believes not - "" .
E: we have theoretical model of sarcasm now .
C: no , no .
F: right , right , but ,
C: anyway , so , , let me make proposal on how to proceed on that , which is that , , it was keith 's , , job over the summer to come up with this set of constructions . and my suggestion to keith is that you , over the next couple weeks , don't try to do them in detail or formally but just try to describe which ones you think we ought to have . and then when robert gets back we 'll look at the set of them . just just , , define your space . and , , so th these are this is set of things that we ought to deal with . and then we 'll we 'll go back over it and people will give feedback on it . and then we 'll have at least initial spec of what we 're actually trying to do . and that 'll also be useful for anybody who 's trying to write parser .
E: in case there 's any around .
F: if we knew anybody like that .
C: "" who might want "" so and we get this , , portals fixed and then we have an idea of the initial range . and then nancy you 're gonna have to , , do your set of but you have to do that anyway .
F: for the same , , data . , - .
C: so so we 're gonna get the we 're dealing with two domains , the tourist domain and the and the child language learning . and we 'll see what we need for those two . and then my proposal would be to , , not cut off more general discussion but to focus really detailed work on the subset of things that we 've we really want to get done . and then as separate thread , think about the more general things and all that .
A: also think the detailed discussion will hit , bring us to problems that are of general nature even suggest some solutions .
C: but what want to do is is to constrain the things that we really feel responsible for . so that we say these are the things we 're really gonna try do by the end of the summer and other things we 'll put on list of research problems , because you can easily get to the point where nothing gets done because every time you start to do something you say , "" , , but what about this case ? "" this is this is called being linguist .
B: there 's that quote in jurafsky and martin where it goes where some guy goes , "" every time fire linguist the performance of the recognizer goes up . ""
C: so , is that does that make sense as , general way to proceed ?
E: , we 'll start with that , just figuring out what needs to be done then actually the next step is to start trying to do it .
A: we have little bit of news , , just minor .
B: ooo , can ask
E: you ran out of power .
B: can ask quick question about this side ? is this , was it intentional to leave off things like "" inherits ""
F: just on the constructions , right ?
B: like constructions can inherit from other things ,
F: didn't want to think too much about that for now . so , , maybe it was subconsciously intentional .
E: , there should be wanted to find out someday if there was gonna be some way of dealing with , , if this is the right term , multiple inheritance , where one construction is inheriting from , from both parents , or different ones , or three or four different ones . cuz the problem is that then you have to which of , which are how they 're getting bound together .
F: refer to them .
C: right , right .
F: and there are certainly cases like that . even with just semantic schemas we have some examples . and we 've been talking little bit about that anyway .
C: so what would like to do is separate that problem out . my argument is there 's nothing you can do with that you can't do by just having more constructions . it 's uglier and it doesn't have the deep linguistic insights and .
E: that 's right . no , no .
F: those are over rated .
E: no , by all means ,
C: and so what 'd like to do is in the short run focus on getting it right .
E: right . , .
C: and when we think we have it right then saying , "" aha ! , can we make it more elegant ? "" can can we , what are the generalizations , and ?
E: connect the dots .
C: but rather than try to inheritance structure and all that before we we 're doing . so would say in the short run we 're not gonna first of all , we 're not doing them yet . and and it could be that half way through we say , "" aha ! , we now see how we want to clean it up . "" and inheritance is only one , that 's one way to organize it but there are others . and it may or may not be the best way . you had news .
A: to eva on our web site we can now , if you want to run javabayes , , you could see get download these classes . and then it will enable you she modified the gui so it has now button menu item for saving it into the embedded javabayes format . so that 's wonderful . and , and she , you tested it out . do you want to say something about that , that it works , right ?
D: was just checking like , when we wanna , , get the posterior probability of , like , variables . how you asked whether we can , like , just observe all the variables like in the same list ? you have to make separate queries every time .
A: that 's that 's bit unfortunate for the time being it 's it 's fine to do it
D: you just have to have long list of , , all the variables .
F: all the things you want to query , you just have to like ask for separately .
A: that 's probably maybe in the long term that 's good news because it forces us to think little bit more carefully how we want to get an out output . but that 's different discussion for different time . we 're really running late , so had , , an idea yesterday but , , whether we should even start discussing .
C: , tell us what it is .
A: the construal bit that , , has been pointed to but hasn't been , , made precise by any means , , may may work as follows . that we would , that the following thing would be in incredibly and have no clue whether it will work or nothing . so that 's just tangent , couple of mental disclaimers here . imagine you write bayes - net , bayes - net , completely from scratch every time you do construal . so you have nothing . just white piece of paper . you consult your ontology which will tell you bunch of , and parts , and properties , -
F: grout out the things that you need .
A: then you 'd simply write , , these into onto your white piece of paper . and you will get lot of notes and out of there . you won't get you won't really get any 's , therefore we need everything that configures to what the situation is , ie , the context dependent . so you get whatever comes from discourse but also filtered . so only the ontology relevant from the discourse plus the situation and the user model . and that fills in your cpt 's with which you can then query , , the net that you just wrote and find out how thing is construed as an utterance . and the embedded javabayes works exactly like that , we have , , precise format in which to write it , so we write it down . you query it . you get the result , and you throw it away . and the thing about this idea is that you don't ever have to sit down and think about it or write about it . you may have some general rules as to how things can be can be construed as what , so that will allow you to craft the the initial notes . but it 's in that respect it 's completely scalable . because it doesn't have any prior , , configuration . it 's just you need an ontology of the domain and you need the context dependent modules . and if this can be made to work , that 'd be funky .
C: it sounds to me like you want
A: ms - , prm since you can unfold prm into straightforward bayes - net
C: beca - because it because no , no , you can't . see the critical thing about the prm is it gives these relations in general form . so once you have instantiated the prm with the instances and ther then you can then you can unfold it .
A: then you can . no , was using it generic . so , , probabilistic , whatever , relational models . whatever you write it .
C: no , but it matters lot because you what you want are these generalized rules about the way things relate , th that you then instantiate in each case .
A: and then instantiate them . that 's ma maybe the way the only way it works .
C: that 's the only way it could work . we have our local expert on but my is that they 're not currently good enough to do that . but we 'll we 'll have to see . this is that 's that would be good thing to try . it 's related to the hobbs abduction story in that you th you throw everything into pot and you try to come up with the ,
A: except there 's no theorem prover involved .
C: no , there isn't theorem prover but there but the , , the cove the ms are like rules of inference and you 're you 're coupling bunch of them together . and then ins instead of proving you 're trying to , , compute the most likely . but you , it 's good it 's good thing to put in your thesis proposal .
A: what 's it ?
C: so are you gonna write something for us before you go ? you have something .
A: in the process thereof , or whatever .
C: so , what 's what when are we gonna meet again ?
F: when are you leaving ?
A: thursday 's my last day here . would suggest as soon as possible . do you mean by we , the whole ben gang ?
C: no , didn't mean just the two of us . we we can we can do this . but the question is do you want to , , send the little group , , draft of your thesis proposal and get , , another session on feedback on that ?
A: we can do it th - thursday again .
E: fine with me . should we do the one pm time for thursday since we were on that before
A: thursday at one ? also maybe then run through the , the talk have to give at eml which highlights all of our work . and we can make some last minute changes on that .
B: you can just give him the abstract that we wrote for the paper .
C: that - that 'll tell him exactly what 's going on .
F: can we do can we do one - thirty ? you already told me no .
A: but we can do four .
F: it 's fine . it 's fine . it 's fine .
A: one or four .
E: to me this is equal .
A: if it 's equal for all ? what should we do ?
F: it 's fine . no , no , , don't care . it 's fine .
A: it 's equal to all of us , so you can decide one or four .
B: the pressure 's on you nancy .
A: liz actually said she likes four because it forces the meeting recorder people to cut , the discussions short .
E: if you insist , then .
","The discussion concerned the revised semantic specification and the construction formalism.
The different levels of the latter focus on what construction types are encountered and what bindings there are between them.
The notation maintains properties of both dependency and constituent-based grammars.
The encoding of features is still incomplete: frame profiles , focus , adjectives , nominal expressions are phenomena in the process of being integrated.
Similarly , ways to handle mental spaces will have to be added on top.
On the other hand , the semantic specification structures information in terms of ""scenario"" , ""referent"" and ""discourse segment"".
Each category comprises a number of slots filled in by information derived from the utterance.
It is , essentially , a toolkit with which to create semantic constructions , as well as the bindings between them and with the ontology.
Among the issues still being defined , mental spaces and context ( eg pronoun references ) present similarities that can be echoed in the specification.
Work on both of these formalisms will continue with circumscription of the construction space that will be studied in more detail.
Work on construal will use Bayes-nets , which will be fed information from other modules and implement general rules to infer how utterances are construed.
The semantic specification requires some adjustments.
Amongst other things ""cause"" has to be added as another X-schema.
Linguistic hedging will also be encoded as a demarcation of evidentiality or speaker confidence.
Mental spaces can be tackled with mechanisms that can also deal with context issues ( time , space etc . ): creating a base space and rules of interaction with other interconnected spaces.
However , the complexity of these mechanisms has to be bound as well: it is necessary to define the range of constructions to be studied.
Given the domains currently used ( tourist , child language learning ) , some features , like speaker attitude , are not of equal importance at this stage.
On the other hand , it was decided for the inheritance between constructions to be left out for now , as the notation can be rendered more elegant later on.
Finally , a preliminary presentation on the idea of how to use Bayes-nets for construal will take place in the next meeting.
The construction formalism is not yet complete as to the semantic constraints -the terminology has also been met with objections- and does not deal with mental spaces.
On their own , constructions can only give limited information regarding mental spaces: forms can provide cues to create a different mental space , but the semantic nuances are defined by context.
It is not decided at this stage whether the necessary values should be coded within the construction or as part of construal.
Other issues concern focus and stress: focus is seen as an information structure device , but there has been no suggestion as to how to predict its effects or break it down in possible focused elements; as to stress , it may not be useful as a form value , as it shows the focus exponent , but not what the focus is on.
Moving to the semantic specification , the analysis still needs mechanisms to deal with causality , as well as mental spaces and bindings between them.
Additionally , how referring expressions are linked to referents or even how mental spaces affect this linking are still to lay down in detail.
The revised semantic specification and construction formalism are more stable than the previous versions.
In the latter , we find both construction types and meaning types along with formal considerations like verb subcategorisation , or the ones a ""directed motion"" construction would dictate.
Semantic constraints also come into play.
The semantic specification , on the other hand , is split into three levels: ""scenario"" is a list of schemas and bindings between them , which describes the current event in terms of Source-Path-Goal , Container , etc.; ""referent"" is about the entities in the discourse and includes grammatical information and pointers to the ontology; ""discourse segment"" comprises utterance-specific things.
Apart from the presentation , JavaBayes can now run through the modified web page of the project.
"
ami_abstractive_summary,Bro007.txt,"B: today we 're looking at number of things we 're trying and fortunately for listeners to this we lost some of it 's visual but got tables in front of us . what is what does combo mean ?
C: so combo is system where we have these features that go through network and then this same string of features but low - pass filtered with the low - pass filter used in the msg features . and so these low - pass filtered goes through another mlp and then the linear output of these two mlp 's are combined just by adding the values and then there is this klt . the output is used as features as .
B: so let me try to restate this and see if have it right . there is there is the features there 's the ogi features and then those features go through contextual let 's take this bottom arr one pointed to by the bottom arrow . those features go through contextualized klt . then these features also get low - pass filtered
C: could perhaps draw this on the blackboard
B: that 's good .
C: so we have these features from ogi that goes through the three paths . the first is klt using several frames of the features . the second path is mlp also using nine frames several frames of features the third path is this low - pass filter . adding the outputs just like in the second propose the proposal from for the first evaluation . and then the klt and then the two together again .
B: no , the klt . and those two together . that 's it . so that 's that 's this bottom one . and so and then the the one at the top and presume these things that are in yellow because overall they 're the best ?
C: that 's the reason , .
B: let 's focus on them then so what 's the block diagram for the one above it ?
C: for the first yellow line you mean ? so it 's the same except that we don't have this low - pass filtering so we have only two streams . there 's there 's no low - pass processing used as additional feature stream .
B: do you they mentioned made some when was on the phone with sunil they mentioned some weighting scheme that was used to evaluate all of these numbers .
C: actually the way things seems to it 's forty percent for ti - digit , sixty for all the speechdat - cars , all these languages . ehm the match is forty , medium thirty five and high mismatch twenty - five .
B: and we don't have the ti - digits part yet ?
C: generally what you observe with ti - digits is that the result are very close whatever the system .
B: and so have you put all these numbers together into single number representing that ? so that should be pretty easy to do and that would be good then we could compare the two and say what was better . and how does this compare to the numbers so ogi two is just the top row ?
C: actually ogi two is the baseline with the ogi features but this is not exactly the result that they have because they 've they 're still made some changes in the features and but actually our results are better than their results . by how much because they did not send us the new results
B: so the one place where it looks like we 're messing things up bit is in the highly mismatched italian .
C: there is something funny happening here because but there are thirty - six and then sometimes we are we are around forty - two and
B: so one of the ideas that you had mentioned last time was having second silence detection .
C: so there are some results here
D: for the italian .
C: so the third and the fifth line of the table
D: for this one .
B: so filt is what that is ?
C: so it seems for the match and mismatched condition it 's it brings something . but actually there are there 's no room left for any silence detector at the server side because of the delay .
B: we can't do it .
D: for that for that we
B: good idea , but can't do it .
C: except because they they are still working . two days ago they were still working on this trying to reduce the delay of the silence detector if we had time perhaps we could try to find some compromise between the delay that 's on the handset and on the server side . perhaps try to reduce the delay on the handset but for the moment they have this large delay on the feature computation and so we don't
B: alright so for now at least that 's not there you have some results with low - pass filter cepstrum doesn't have huge effect but it but it looks like it maybe could help in couple places . and let 's see what else did we have in there ? it makes at this point this is should probably look at these others little bit and you yellowed these out see that one you can't use because of the delay . those look pretty good . let 's see that one even the just the second row doesn't look that bad right ? and and that looks like an interesting one too .
C: actually the the second line is like the first line in yellow except that we don't have this klt on the first on the left part of the diagram . we just have the features as they are .
B: so when we do this weighted measure we should compare the two cuz it might even come out better . and it 's it 's little slightly simpler . so so there 's so would put that one also as as maybe . and it 's actually does significantly better on the highly mismatched italian , and little worse on the mis on the case , it 's worse than few things so let 's see how that see how that comes out on their measure and are we running this for ti - digits now is ti di is that part of the result that they get for the development th the results that they 're supposed to get at the end of end of the month , the ti - digits are there also ?
C: it 's included , .
B: and see what else there is here . the one was looking down here at the the row below the lower yellowed one . that 's that 's with the reduced klt size reduced dimensionality . what happens there is it 's around the same and so you could reduce the dimension as you were saying before bit perhaps .
C: it 's it 's significantly worse but - .
B: it 's significantly worse it 's it 's it 's it 's mostly worse .
C: exc - except for the hm
D: for many mismatch it 's worse .
B: but it is little . not by huge amount , what are what are the sizes of any of these sets , 'm 'm you told me before , but 've forgotten . so how many words are in one of these test sets ?
C: it 's it depends the matched is generally larger than the other sets and it 's around two thousand or three thousand words perhaps , at least .
D: but words word .
C: the words , . some sets have five hundred sentences ,
B: so the so the sets so the test sets are between five hundred and two thousand sentences , let 's say and each sentence on the average has four or five digits or is it most of them longer or
D: for the italian even seven digits more or less but sometime the sentence have only one digit and sometime like the number of credit cards , something like that .
B: right , so between one and sixteen . see the the reason 'm asking is is we have all these small differences and how to take them , right ? so if you had just to give an example , if you had if you had thousand words then tenth of percent would just be one word , so so it wouldn't mean anything . so it be 'd like to the sizes of these test sets were actually .
D: the size that we have ?
C: we could we could run some significance tests
B: also just to know the numbers , so these are word error rates so this is on how many words .
D: we have the result that the output of the htk the number of sentences , no it 's the number isn't .
B: so anyway if you could just mail out what those numbers are and then that be great . what else is there here ? see the second from the bottom it says sil , but this is some different silence or thing or what was that ?
D: it the output silence of the mlp . it 's only one small experiment to happened . to apply also to in include also the silence of the mlp we have the fifty - six form and the silence to pick up the silence and we include those .
B: - , - . the silence plus the klt output ? so you 're only using the silence .
D: because when we apply the klt
C: no they 're there is this silence in addition to the klt outputs
D: in addition , yes .
C: it is because we we just keep we don't keep all the dimensions after the klt
D: and we not we are not if we pick we have the silence .
C: so we try to add the silence also in addition to the these twenty - eight dimensions .
B: and what and what 's ogi forty - five ? the bottom one there ?
C: it 's it 's ogi two , it 's so the th it 's the features from the first line
D: it 's ogi two .
B: right , but what 's the what does the last row mean ?
C: so it 's this but without the klt on the from the left path .
B: that was the one that was the second row . so what 's the difference between the second
C: the second line you don't have this combo so you just
B: so this is like the second line but with the combo .
D: and with the all the output of the combo .
B: so it looks to me the same given that we have to take the filt ones out of the running because of this delay problem so it looks to me like the ones you said agree are the ones to look at but would add the the second row one and then if we can also when they 're using this weighting scheme of forty , thirty - five , twenty - five is that on the percentages or on the raw errors ? it 's probably on the percentages right ?
C: it 's not clear here .
B: maybe maybe they 'll argue about it . so if we can how many words are in each and then dave dave promised to get us something tomorrow which will be there as far as they 've gotten friday and then we 'll operate with that and how long did it if we 're not doing all these things if we 're only doing since this is development data it 's legitimate to do more than one , ordinarily if in final test data you don't want to do several and take the best that 's that 's not proper but if this is development data we could still look at couple .
C: but we have to decide we have to fix the system on this on this data , to choose the best
B: but the question is when do we fix the system , do we fix the system tomorrow or do we fix the system on tuesday ? except that we do have to write it up .
C: we fixed on tuesday , . it 's this with perhaps some printing and some other @ @ .
B: so maybe what we do is we we as soon as we get the data from them we start the training and but we start the write - up right away because as you say there 's only minor differences between these .
C: you we could start soon , . write up something .
B: and would , would 'd like to see it maybe edit it bit the my what in this si in this situation is my forte which is english . have have you seen alt do they have format for how they want the system descriptions or anything ?
C: there is the format of the table which is quite impressive .
B: yes , for those who are listening to this and not looking at it it 's not really that impressive , it 's just tiny . it 's all these little categories set , set , set , multi - condition , clean . do what no what no mitigation means here ?
C: it should be the problem with the error channel error
B: that 's probably the this is probably channel error this is right , it says right above here channel error resilience , so recognition performance is just the top part , actually . and they have yes , split between seen databases and non - seen so between development and evaluation . it 's presumed there 's all sorts of tuning that 's gone on the see what they call seen databases and there won't be tuning for the unseen . multi - condition multi - condition . so they have looks like they have so they splitting up between the ti - digits and everything else , see . so the everything else is the speechdat - car , that 's the multi multilingual
C: so it 's not divided between languages you mean or
B: but there 's also there 's these tables over here for the for the ti - digits and these tables over here for the car data which is which is all the multilingual and then there 's they also split up between multi - condition and clean only .
C: for ti - digits . for the ti - digits they want to train on clean and on noisy
B: so we 're doing that also , .
C: do we have the features ? for the clean ti - digits but we did not test it yet . the clean training .
B: anyway , sounds like there 'll be lot to do just to work with our partners to fill out the tables over the next next few days they have to send it out let 's see the thirty - first is wednesday and the it has to be there by some hour european time on wednesday
D: we lost time wednesday maybe because that the difference in the time may be is long different of the time . maybe the thursday the twelfth of the night of the thurs - thirty - one is not valid in europe . we is happening .
B: yes , so we have to actually get it done tuesday
C: except if it 's the thirty - one at midnight we can still do some work on wednesday morning .
B: is but is it midni it was actually something like five pm on was like it was five pm , didn't was midnight . they said they wanted everything by so five pm their time is
D: not five pm , three pm .
B: alright , that 's six in the morning here .
D: three - three pm ?
C: no , we are wondering about the the hour that we have to if it 's three pm it 's
D: three pm here is in europe midnight .
C: it 's it 's midnight but
B: yes , yes , but didn't was midnight that it was due , it was due at some hour during the day like five pm .
D: - . - ,
B: so we should look but my assumption is that we have to be done tuesday . so then next thursday we can have little aftermath but then we 'll actually have the new data which is the german and the danish but that really will be much less work because the system will be fixed so all we 'll do is take whatever they have and and run it through the process . we won't be changing the training on anything so there 'll be no new training , there 'll just be new htk runs , so that 's means in some sense we can relax from this after tuesday and maybe next meeting we can start talking little bit about where we want to go from here in terms of the research . what things did you think of when you were doing this process that you just didn't really have time to adequately work on
A: stephane always has these great ideas but we don't have time .
C: 'm not these are great ideas .
B: but they 're ideas . that was good . and and also it 's still true that it 's true that we at least got fairly consistent improved results by running the neural net transformation in parallel with the features rather than in sequence which was your suggestion and that that seems to have been borne out . the fact that none of these are , enormous is is not too surprising most improvements aren't enormous some of them are but you have something really wrong and you fix it you can get big and really enormous improvements but cuz our best improvements over the years that we 've gotten from finding bugs , see where we are and everybody knows what they 're doing and is there is there anything else we should talk about or are we done ?
C: so we will we 'll try to focus on these three architectures and perhaps was thinking also fourth one with just single klt because we did not really test that removing all these klt 's and putting one single klt at the end .
B: that would be pretty low maintenance to try it . if you can fit it in . have do have one other piece of information which should tell people outside of this group too if we 're gonna need it but jeff up at the university of washington has gotten hold of some server farm of of ten multiprocessor ibm machines rs six thousands and so each one is four processors or , eight hundred megahertz and there 's four processors in box and there 's ten boxes and there 's some ti so if he 's got lot of processing power we 'd have to schedule it but if we have some big jobs and we wanna wanna run them he 's he 's offering it . when he was here he used not only every machine here but every machine on campus as far as could tell , so in some ways he just got his payback , but again if we 'll end up with if we 're gonna be cpu limited on anything that we 're doing in this group but if we are that 's an offer . you guys doing great so that 's that 's really neat we 'll don't think we need to the other thing that will say is that the digits that we 're gonna record momentarily is starting to get are starting to get into pretty good size collection and in addition to the speechdat we will have those to work with really pretty soon now so that 's that 's another source of data . which is under somewhat better control and that we can we can make measurements of the room the that if we feel there 's other measurements we don't have that we 'd like to have we can make them dave and were just talking about that little while ago so that 's another possibility for this work . if nobody has anything else maybe we should go around do our digits do our digits duty . let me say that again . we 're done .
","The ICSI Meeting Recorder Group at Berkeley are approaching an important milestone on their project.
They discussed most recent results , finalized plans to continue and discussed the work required and timing needed for completion of this stage of the project.
Mn007 and fn002 Need to find a way of combining result figures into one easily comparable way of judging performance.
They were also asked to mail round numbers detailing the size of their test-sets , so that group members can assess the seriousness of figures such as word error rates.
There are now just 4 architectures that will be carried forward for testing.
Though the final system is not due to be fixed , until Tuesday , writing it up must begin sooner.
Anything written must go through me013 for editing.
Discussion on future work once this stage is out of the way will be held at the next meeting.
While using a second silence detection system it was found that while providing some improvement , it added too great a delay on the server side of the system.
The experiment team have been narrowing down their experiments , coming close to fixing their system.
Partner OGI have been using a weighting scheme , but the ICSI group do not yet have all the parts to run a similar system.
They have been able to come close to the OGI results , but since OGI have changed something they do differ , though for the better.
So far , testing on Italian is the worst performing condition.
With regards to the digits the group have been recording during meetings , the collection of data is growing , and will soon be a workable size.
"
ami_abstractive_summary,Bed012.txt,"B: so this is more or less now just to get you up to date , johno . this is what , ,
C: this is meeting for me .
B: eva , bhaskara , and did .
D: did you add more to it ? later ? there were , like , the , @ @ and all that . but . you said you were adding
B: so we thought that , we can write up , an element , and for each of the situation nodes that we observed in the bayes - net ? what 's the situation like at the entity that is mentioned ? if we know anything about it ? is it under construction ? or is it on fire happening to it ? or is it stable ? going all the way , through parking , location , hotel , car , restroom , @ @ riots , fairs , strikes , or disasters .
C: so is this is situation are is all the things which can be happening right now ? or , what is the situation type ?
B: that 's just specifying the input for the what 's
C: why are you specifying it in xml ?
B: just because it forces us to be specific about the values here ? and , also , , this is what the input is going to be . so , we will , this is schema . this is
C: . if this is th what the does this is what java bayes takes ? as bayes - net spec ?
B: no , because if we we 're gonna interface to we 're gonna get an xml document from somewhere . and that xml document will say "" we are able to we were able to observe that the element , , @ @ of the location that the car is near . "" so that 's gonna be .
C: so this is the situational context , everything in it . is that what situation is short for , shi situational context ?
B: so this is just , again , an xml schemata which defines set of possible , , permissible xml structures , which we view as input into the bayes - net .
C: and then we can possibly run one of them transformations ? that put it into the format that the bayes or java bayes or whatever wants ?
B: yea - are you talking are you talking about the structure ? when you observe node .
C: when you when you say the input to the java bayes , it takes certain format , which don't this .
B: no , it 's certainly not this .
C: so you could just couldn't you just run to convert it into the java bayes for format ?
B: that 's that 's no problem , but even think that , once once you have this as running as module what you want is you wanna say , "" , give me the posterior probabilities of the go - there node , when this is happening . "" when the person said this , the car is there , it 's raining , and this is happening . and with this you can specify the what 's happening in the situation , and what 's happening with the user . so we get after we are done , through the situation we get the user vector . so , this is
C: so this is just specification of all the possible inputs ?
B: all the possible outputs , too . so , we have , , , the , , go - there decision node which has two elements , going - there and its posterior probability , and not - going - there and its posterior probability , because the output is always gonna be all the decision nodes and all the all the posterior probabilities for all the values .
C: and then we would just look at the , , struct that we wanna look at in terms of if we 're only asking about one of the so like , if 'm just interested in the going - there node , would just pull that information out of the struct that gets return that would that java bayes would output ?
B: but it 's little bit more complex . as , if understand it correctly , it always gives you all the posterior probabilities for all the values of all decision nodes . so , when we input something , we always get the , , posterior probabilities for all of these . so there is no way of telling it not to tell us about the eva values .
C: that 's , use , , .
B: so so we get this whole list of , , things , and the question is what to do with it , what to hand on , how to interpret it , so you said if you "" 'm only interested in whether he wants to go there or not "" , then look at that node ,
C: look at that struct in the output ,
B: look at that struct in the output , even though wouldn't call it "" struct "" .
C: it 's an xml structure that 's being res returned ,
B: so every part of structure is "" struct "" .
C: was abbreviated it to struct in my head , and started going with that .
B: that element or object , would say .
C: not struct . that 's not what was trying to
B: the reason is why it 's little bit more complex or why we can even think about it as an interesting problem in and of itself is so . the , let 's look at an example .
C: wouldn't we just take the structure that 's outputted and then run another transformation on it , that would just dump the one that we wanted out ?
B: we 'd need to prune . throw things away .
C: actually , you don't even need to do that with xml . can't you just look at one specific
B: exactly . the @ @ xerxes allows you to say , "" just give me the value of that , and that . "" but , we don't really we 're interested in before we look at the complete at the overall result . so the person said , , "" where is ? "" we want to know , , is does he want info ? or know the location ? or does he want to go there ? let 's assume this is our question . do this in perl . let 's assume this is the output . we should con be able to conclude from that it 's always gonna give us value of how likely we it is that he wants to go there and doesn't want to go there , or how likely it is that he wants to get information . but , maybe we should just reverse this to make it little bit more delicate . so , does he wanna know where it is ? or does he wanna go there ?
C: he wants to know where it is .
B: tend to agree . and if it 's if
C: now , , you could
B: and if there 's clear winner here , and , and this is pretty , indifferent , then we then we might conclude that he actually wants to just know where , , he does want to go there .
C: out of curiosity , is there reason why we wouldn't combine these three nodes ? into one smaller subnet ? that would just be the question for we have "" where is ? "" is the question , that would just be info - on or location ?
B: or go - there . lot of people ask that , if they actually just wanna go there . people come up to you on campus and say , "" where 's the library ? "" you 're gonna say you 're gonna say , "" go down that way . "" you 're not gonna say "" it 's it 's five hundred yards away from you "" or "" it 's north of you "" , or "" it 's located ""
C: but the there 's so you just have three decisions for the final node , that would link thes these three nodes in the net together .
B: whether understand what you mean . but . again , in this given this input , we , also in some situations , may wanna postulate an opinion whether that person wants to go there now the nicest way , wants to wants to know where it is because he wants something fixed there , because he wants to visit it or whatever . so , it all 'm saying is , whatever our input is , we 're always gonna get the full output . and some things will always be too not significant enough .
C: or or it 'll be tight . you won't it 'll be hard to decide . but , , , this is another , smaller , case of reasoning in the case of an uncertainty , which makes me think bayes - net should be the way to solve these things . so if you had if for every construction , you could say , "" , there here 's the where - is construction . "" and for the where - is construction , we know we need to look at this node , that merges these three things together as for th to decide the response . and since we have finite number of constructions that we can deal with , we could have finite number of nodes . say , if we had to deal with arbitrary language , it wouldn't make any sense to do that , because there 'd be no way to generate the nodes for every possible sentence . but since we can only deal with finite amount of
B: so , , the idea is to to feed the output of that belief - net into another belief - net .
C: so take these three things and then put them into another belief - net .
B: but , why why only those three ? why not the whol
C: , for the where - is question . so we 'd have node for the where - is question .
B: but we believe th the decision nodes are can be relevant for the where - is , and the where how - do - - get - to or the tell - me - something - about .
C: you can come in if you want .
B: yes , it is allowed .
C: as long as you 're not wearing your headphones . do see , if this is good idea or not . 'm just throwing it out . but , it seems like we could have mea or we could put all of the information that could also be relevant into the where - is node answer
B: let 's not forget we 're gonna get some very strong input from these sub dis from these discourse things , "" tell me the location of . "" or "" where is located at ? ""
C: know , but the bayes - net would be able to the weights on the on the nodes in the bayes - net would be able to do all that , 'll until you 're plugged in . don't sit there . how you don't like that one . that 's the weird one . that 's the one that 's painful . that hurts . it hurts so bad . 'm 'm happy that they 're recording that . that headphone . the headphone that you have to put on backwards , with the little thing and the little foam block on it ? it 's painful , painful microphone .
B: it 's th called "" the crown "" . versus "" the sony "" .
A: is that the actual name ?
C: don't see manufacturer on it . here it is . it 's "" the crown "" . the crown of pain !
B: you 're on - line ?
C: are you are your mike is your mike on ? so you 've been working with these guys ? what 's going on ?
A: and , do . so where are we ?
B: we 're discussing this .
A: don't can handle french ,
B: assume we have something coming in . person says , "" where is ? "" , and we get certain we have situation vector and user vector and everything is fine ? an - an and our and our
C: did you just sti did you just stick the the the microphone actually in the tea ?
A: 'm not drinking tea . what are you talking about ?
B: let 's just assume our bayes - net just has three decision nodes for the time being . these three , he wants to know something about it , he wants to know where it is , he wants to go there .
C: in terms of , these would be wha how we would answer the question where - is , this is that 's what you it seemed like , explained it to me earlier
B: but , mmm .
C: we we 're we wanna know how to answer the question "" where is ? ""
B: no , do the timing node in here , too , and say "" . ""
C: , but in the , let 's just deal with the the simple case of we 're not worrying about timing or anything . we just want to know how we should answer "" where is ? ""
B: go - there has two values , go - there and not - go - there . let 's assume those are the posterior probabilities of that . info - on has true or false and location . so , he wants to know something about it , and he wants to know something he wants to know where - it - is , has these values .
C: see why we can't do that .
B: and , , in this case we would probably all agree that he wants to go there . our belief - net thinks he wants to go there , in the , , whatever , if we have something like this here , and maybe here also some
A: you should probably make them out of
B: something like that , then we would , "" aha ! he , our belief - net , has stronger beliefs that he wants to know where it is , than actually wants to go there . ""
C: that it doesn't this assume , though , that they 're evenly weighted ? they are evenly weighted .
A: the different decision nodes , you mean ?
C: the go - there , the info - on , and the location ?
A: , this is making the assumption .
B: what do you mean by "" differently weighted "" ? they don't feed into anything really anymore .
A: but , why do we if we trusted the go - there node more th much more than we trusted the other ones , then we would conclude , even in this situation , that he wanted to go there . so , in that sense , we weight them equally
C: so the but the the question that was as er wondering or maybe robert was proposing to me is how do we make the decision on as to which one to listen to ?
A: so , the final decision is the combination of these three . so again , it 's it 's some ,
C: bayes - net . so , then , the question so then my question is to you then , would be so is the only reason we can make all these smaller bayes - nets , because we know we can only deal with finite set of constructions ? cuz oth if we 're just taking arbitrary language in , we couldn't have node for every possible question ,
A: decision node for every possible question , you mean ?
C: like , in the case of . in the ca any piece of language , we wouldn't be able to answer it with this system , if we just cuz we wouldn't have the correct node . what you 're proposing is where - is node , and and if we and if someone says , , , something in mandarin to the system , we 'd - wouldn't know which node to look at to answer that question , so , but if we have finite
B: don't see your point . what what am thinking , or what we 're about to propose here is we 're always gonna get the whole list of values and their posterior probabilities . and now we need an expert system or belief - net that interprets that , that looks the values and says , "" the winner is timing . now , go there . "" "" , go there , timing , now . "" or , "" the winner is info - on , function - off . "" so , he wants to know something about it , and what it does . regardless of of the input . wh - regardle
C: but but how does the expert but how does the expert system know how who which one to declare the winner , if it doesn't know the question it is , and how that question should be answered ?
B: based on the what the question was , so what the discourse , the ontology , the situation and the user model gave us , we came up with these values for these decisions .
C: know . but how do we weight what we get out ? as , which one which ones are important ? so my so , if we were to it with bayes - net , we 'd have to have node for every question that we knew how to deal with , that would take all of the inputs and weight them appropriately for that question . does that make sense ?
A: , are you saying that , what happens if you try to scale this up to the situation , or are we just dealing with arbitrary language ? is that your point ?
C: no . my question is , is the reason that we can make node or . so , lemme see if 'm confused . are we going to make node for every question ? does that make sense ?
A: for every question ? don't not necessarily , would think . it 's not based on constructions , it 's based on things like , , there 's gonna be node for go - there or not , and there 's gonna be node for enter , view , approach .
C: so , someone asked question . how do we decide how to answer it ?
B: look at look face yourself with this pr question . you get this you 'll have this is what you get . and now you have to make decision . what do we think ? what does this tell us ? and not knowing what was asked , and what happened , and whether the person was tourist or local , because all of these factors have presumably already gone into making these posterior probabilities . what what we need is just mechanism that says , "" aha ! there is ""
C: don't think "" winner - take - all "" type of thing is the
A: in general , like , we won't just have those three , we 'll have , , like , many nodes . so we have to , like so that it 's no longer possible to just look at the nodes themselves and figure out what the person is trying to say .
B: because there are interdependencies , no . so if , the go - there posterior possibility is so high , , if it 's if it has reached certain height , then all of this becomes irrelevant . so . if even if the function or the history is scoring pretty good on the true node , true value
C: cuz that would suggest that
B: he wants to go there and know something about it ?
C: do they have to be mutual do they have to be mutually exclusive ?
B: to some extent they are . or maybe they 're not .
C: cuz , the way you describe what they meant , they weren't mutu , they didn't seem mutually exclusive to me .
B: if he doesn't want to go there , even if the enter posterior proba go - there is no . enter is high , and info - on is high .
C: , just out of the other three , though , that you had in the those three nodes . the - they didn't seem like they were mutually exclusive .
B: no , there 's no . it 's through the
C: so th so , , but some so , some things would drop out , and some things would still be important . but what 's confusing me is , if we have bayes - net to deal another bayes - net to deal with this , is the only reason , so , , if we have ba - another bayes - net to deal with this , the only reason we can design it is cuz we each question is asking ?
A: that 's true .
C: and then , so , the only reason way we would question he 's asking is based upon so if let 's say had construction parser , and plug this in , would each construction the communicative intent of the construction was and so then would know how to weight the nodes appropriately , in response . so no matter what they said , if could map it onto where - is construction , could say , "" ! the intent , here , was where - is "" , and could look at those .
A: you do need to know , to have that information .
B: 'm also agreeing that simple pru take the ones where we have clear winner . forget about the ones where it 's all middle ground . and just hand over the ones where we have winner . because that would be the easiest way . we just compose as an output an xml mes message that says . "" go there now . "" "" enter historical information . "" and not care whether that 's consistent with anything . but in this case if we say , "" definitely he doesn't want to go there . he just wants to know where it is . "" or let 's call this "" look - at - "" he wants to know something about the history of . so he said , "" tell me something about the history of that . "" now , the but for some reason the endpoint - approach gets really high score , too . we can't expect this to be at point three , three , point , three , three , three . somebody needs to zap that . or know there needs to be some knowledge that
C: we , but , the bayes - net that would merge realized that had my hand in between my mouth and my micr er , my and my microphone . so then , the bayes - net that would merge there , that would make the decision between go - there , info - on , and location , would have node to tell you which one of those three you wanted , and based upon that node , then you would look at the other . does that make sense ?
B: it 's one of those , that 's it 's more like decision tree , if you want . you first look at the lowball ones ,
C: didn't intend to say that every possible there was confusion there , didn't intend to say every possible thing should go into the bayes - net , because some of the things aren't relevant in the bayes - net for specific question . like the endpoint is not necessarily relevant in the bayes - net for where - is until after you 've decided whether you wanna go there or not . show us the way , bhaskara .
A: the other thing is that , . when you 're asked specific question and you don't even like , if you 're asked where - is question , you may not even look like , ask for the posterior probability of the , , eva node , cuz , that 's what , in the bayes - net you always ask for the posterior probability of specific node . you may not even bother to compute things you don't need .
B: aren't we always computing all ?
A: you can compute , , the posterior probability of one subset of the nodes , given some other nodes , but ignore some other nodes , also . things you ignore get marginalized over .
B: but that 's that 's just shifting the problem . then you would have to make decision ,
A: so you have to make
B: "" , if it 's where - is question , which decision nodes do query ? ""
A: but would think that 's what you want to do .
D: eventually , you still have to pick out which ones you look at . so it 's the same problem ,
B: it 's it 's apples and oranges . maybe it does make difference in terms of performance , computational time . so either you always have it compute all the posterior possibilities for all the values for all nodes , and then prune the ones you think that are irrelevant , or you just make @ @ priori estimate of what you think might be relevant and query those .
C: so , you 'd have decision tree query , go - there . if if that 's false , query this one . if that 's true , query that one . and just do binary search through the ?
A: if it would necessarily be that , , complicated .
C: in the case of go - there , it would be . cuz if you needed an if if go - there was true , you 'd wanna endpoint was . and if it was false , you 'd wanna look at either lo - income info - on or history .
A: that 's true , . so , in way you would have that .
C: also , 'm somewhat boggled by that hugin software .
A: why 's that ?
C: 't figure out how to get the probabilities into it . like , 'd look at it 's somewha it 's boggling me .
A: hopefully it 's fixable . it 's there 's
C: . haven't figured out what the terms in hugin mean , versus what java bayes terms are .
B: , are do we know whether jerry and nancy are coming ?
A: so we can figure this out . they should come when they 're done their , , whenever that is .
C: what what do they need to do left ?
A: jerry needs to enter marks , but if he 's gonna do that now or later . but , , if he 's gonna enter marks , it 's gonna take him awhile , , and he won't be here .
C: and what 's nancy doing ?
A: she was sorta finishing up the , , calculation of marks and assigning of grades , but if she should be here . or , she should be free after that , assuming she 's coming to this meeting . if she knows about it .
C: she 's on the email list ,
B: what where we also have decided , prior to this meeting is that we would have rerun of the three of us sitting together sometime this week again and finish up the , , values of this . so we have , believe it or not , we have all the bottom ones here .
D: you added bunch of nodes , for ?
B: we we have actually what we have is this line .
C: what do the , , structures do ? so the , this location node 's got two inputs ,
A: those are the bottom things are inputs , also .
C: that makes lot more sense to me now . cuz it was like , that one in stuart 's book about , , the
A: alarm in the dog ?
C: or the earthquake and the alarm .
A: , 'm confusing two .
C: there 's dog one , too , but that 's in java bayes , but there 's something about bowel problems with the dog .
B: and we have all the top ones , all the ones to which no arrows are pointing . what we 're missing are the these , where arrows are pointing , where we 're combining top ones . so , we have to come up with values for this , and this , this , and . and maybe just fiddle around with it little bit more . and then it 's just , , edges , and , , we won't meet next monday .
C: cuz of memorial day ?
A: we 'll meet next tuesday , .
C: when 's jerry leaving for italia ?
B: on on friday . this this friday .
C: as in , four days ? or , three days ?
A: is he how long is he gone for ? what 's , what 's there ?
B: it 's country .
C: but it 's not conference or anything . he 's just visiting .
A: it 's pretty place , in my brief , , encounter with it .
B: . so . part of what we actually want to do is schedule out what we want to surprise him with when he comes back .
C: we should disappoint him .
B: you or have finished construction parser and working belief - net ,
C: that wouldn't be disappointing . we should do no work for the two weeks that he 's gone .
B: that 's actually what had planned , personally . had had scheduled out in my mind that you guys do lot of work , and do nothing .
C: , that sounds good , too .
B: bask in your glory . but , , do you guys have any vacation plans , because myself am going to be , , gone , but this is actually not really important . just this weekend we 're going camping .
C: 'm wanna be this gone this weekend , too .
B: but we 're all going to be here on tuesday again ? looks like it ? then . let 's meet again next tuesday . and , , finish up this bayes - net . and once we have finished it , we can , and that 's going to be more just you and me , because bhaskara is doing probabilistic , recursive , structured , object - oriented , ,
C: killing , reasoning . what 's the difference ?
D: so you 're saying , next tuesday , is it the whole group meeting , or just us three working on it , or ?
B: the whole group . and we present our results ,
D: so , when you were saying we need to do re - run of , like what like , just working out the rest of the
B: we should do this th the upcoming days . so , this week , .
C: when you say , "" the whole group "" , you mean the four of us , and keith ?
B: and , ami might .
C: ami might be here , and it 's possible that nancy 'll be here ?
B: because , th , once we have the belief - net done
C: you 're just gonna have to explain it to me , then , on tuesday , how it 's all gonna work out .
B: because then , once we have it up and running , then we can start , defining the interfaces and then feed into it and get out of it , and then hook it up to some fake construction parser
C: that you will have in about nine months or so . the first bad version 'll be done in nine months .
B: worry about the ontology interface and you can keith can worry about the discourse . this is pretty , , hope everybody knows that these are just going to be dummy values , so if the endpoint if the go - there is yes and no , then go - there - discourse will just be fifty - fifty .
A: what do you mean ? if the go - there says no , then the go - there is
D: don't get it .
A: like , the go - there depends on all those four things .
B: but , what are the values of the go - there - discourse ?
A: it depends on the situation . if the discourse is strongly indicating that
B: but , , we have no discourse input .
A: see . the see , , specifically in our situation , and are gonna be , so , whatever .
D: so , so far we have is that what the keith node is ? and you 're taking it out ? for now ?
B: this , get it in here .
D: all the 's are
B: get it in here , so th we have the , , , sk let 's let 's call it "" keith - johno there is an somewhere printed .
C: there you go .
A: people have the same problem with my name .
C: does th does the go before the or after the ?
A: in my name ?
C: cuz you kn when you said people have the same problem , cuz my goes after the the
A: people have the inverse problem with my name .
C: always have to check , every time send you an email , past email of yours , to make 'm spelling your name correctly .
A: that 's good .
C: worry about you .
B: but , when you abbreviate yourself as the "" basman "" , you don't use any 's .
A: "" basman "" ? it 's because of the chessplayer named michael basman , who is my hero .
C: you 're geek . how do you pronou how do you pronounce your name ? what if were what if were to call you eva ?
D: 'd probably still respond to it . 've had people call me eva ,
C: no , not just eva , eva . like if take the and pronounce it like it was german ?
D: no idea then .
C: it sounds like an . there 's also an in german ,
B: it 's just the difference between voiced and unvoiced .
C: as long as that 's . might slip out and say it accidentally . that 's all 'm saying .
D: that 's fine .
A: it doesn't matter what those nodes are , anyway , because we 'll just make the weights "" zero "" for now .
B: we 'll make them zero for now , because it who knows what they come up with , what 's gonna come in there . should we start on thursday ? and not meet tomorrow ? 'll send an email , make time suggestion .
C: maybe it 's , so that that we can that we have one node per construction . cuz even in people , like , they what you 're talking about if you 're using some strange construction .
B: they would still get the closest , best fit .
C: , but , the , , that 's what the construction parser would do . , if you said something completely arbitrary , it would find the closest construction , but if you said something that was completel er theoretically the construction parser would do that but if you said something for which there was no construction whatsoever , people wouldn't have any idea what you were talking about . like "" bus dog fried egg . "" .
B: or , if even something chinese , .
C: or , something in mandarin , . or cantonese , as the case may be . what do you think about that , bhaskara ?
A: but how many constructions do could we possibly have nodes for ?
C: in this system , or in
A: no , we . like , when people do this thing .
C: when how many constructions do people have ? have not the slightest idea .
A: is it considered to be like in are they considered to be like very , , abstract things ?
C: every noun is construction .
A: so it 's like in the thousands .
C: any any form - meaning pair , to my understanding , is construction . and form starts at the level of noun or actually , maybe even sounds . until you get the ditransitive construction . and then , , the , maybe there can be the can there be combinations of the dit
A: discourse - level constructions .
C: the "" giving speech "" construction ,
B: but , , , you can probably count the ways .
C: it 's probab , would definitely say it 's finite . and at least in compilers , that 's all that really matters , as long as your analysis is finite .
A: how 's that ? {nonvocalsound} how it can be finite , again ?
C: nah , 't think of way it would be infinite .
B: you can come up with new constructions .
C: if the if your brain was non - deterministic , then perhaps there 's way to get , , infin an infinite number of constructions that you 'd have to worry about .
A: but , , in the {nonvocalsound} practical sense , it 's impossible .
C: right . cuz if we have fixed number of neurons ? so the best - case scenario would be the number of constructions or , the worst - case scenario is the number of constructions equals the number of neurons .
A: two to the power of the number of neurons .
C: but still finite . not necessarily , is it ? we can end the meeting . can't you use different var different levels of activation ? across , lots of different neurons , to specify different values ?
A: , but there 's , like , certain level of
C: there 's bandwidth issue ,
A: bandw - , so you can't do better than something .
B: turn off the mikes . otherwise it gets really tough for the tr
","The focus of the meeting was on a presentation of the work done already on the building of the Bayes-net.
The input layer deriving information from things like the user and situation models , feeds into a set of decision nodes , such as the Enter/View/Approach ( EVA ) endpoint.
In any particular situation , most of the outputs will not be relevant to the given context.
Therefore , they will either have to be pruned a posteriori , or only a subset of the possible decision nodes will be computed in each occasion.
The latter option could could follow a binary search-tree approach and it could also be better in computational terms.
In any case , on what basis the ""winner"" output is chosen is not clear.
One suggestion was discussed: the particular constructions used can determine the pertinent decision ( output ) nodes.
The complete prototype of the Bayes-net will be presented in the next meeting.
After that , it will be possible to define interfaces and a dummy construction parser , in order to test and link modules together.
The suggestion that the most appropriate decision node of the belief-net in each situation could be chosen as a function of what construction was used , was deemed unsuitable at this stage.
There are many interdependencies between the output nodes that this approach could not take into account.
The rest of the values for the Bayes-net nodes will be built in within the week.
The finished prototype will be presented during the next meeting.
Any set of inputs will provide either the whole range of output values of the Bayes-net or an a priori selection of those outputs.
In both cases , what is needed is a way to single out the appropriate outputs for any given context.
For example , in the case of a ""where is"" question , whether the prevalent output should be ""Go-there"" or ""Info-on"" or even a third option has to be computed somehow.
In any case , there are many input values that have not been entered in the Bayes-net at this stage.
Furthermore , no inputs for the Ontology and Discourse can be built in yet , as they involve research that will be carried out in the future.
Finally , there has been a problem with adding probabilities in a net created with the Hugin software , but this should be overcome very shortly.
The presented Bayes-net takes inputs from the Situation , User , Discourse and Ontology models.
There are several values ( elements ) defined in each of these models.
The inputs are fed into the belief-net , which , in turn , outputs the posterior probabilities for the values of all the decision nodes.
These comprise ""Go-there"" , ""EVA"" , ""Info-on"" , ""Location"" , ""Timing"" , etc.
At this stage , all the decision nodes are evenly weighted: regardless of the context , each output is trusted equally.
Input and output node structure was presented in XML , as this is the format that will be used for the system.
A large number of the value probabilities have already been set.
"
ami_abstractive_summary,Bmr003.txt,"A: this is one channel . can you , say your name and talk into your mike one at time ?
C: this is eric on channel three , believe .
A: don't 's on there , jane .
D: tasting one two three , tasting .
E: this is jane on channel five .
A: still don't see you jane .
E: darn , what am doing wrong ?
D: can you see me on channel four ? my lucky day .
E: maybe it just warmed up ? can you can't see channel five yet ?
A: , the mike isn't close enough to your mouth ,
E: is that better ?
A: try speaking loudly ,
D: like the high quality labelling . david , can we borrow your labelling machine to improve the quality of the labelling little bit here ? how how many are there , one to five ?
E: would you like to join the meeting ?
A: we don't wanna renumber them , cuz we 've already have like , forms filled out with the numbers on them . so , let 's keep the same numbers on them .
B: that 's good idea .
A: dan , are you on ?
B: 'm on 'm on two and should be on .
D: want to join the meeting , dave ? do we do we have spare ,
A: and 'm getting lots of responses on different ones , so assume the various and assorted ms are on .
D: we ' we 're we ' this is this is meeting .
E: this is abou we 're we 're mainly being taped but we 're gonna talk about , , transcription for the future meeting meetings .
A: this is not something you need to attend .
C: you 're always having one of those days , dave .
E: you 'd be welcome .
A: besides , don't want anyone who has weird accent .
E: you 'd be welcome .
A: right , dan ?
D: so , don't understand if it 's neck mounted you don't get very good performance .
C: it 's not neck mounted . it 's supposed to be head mounted .
D: it it should be head mounted .
A: then put it on your head . what are you doing ?
D: cuz when you do this , you can rouww - rouww .
E: why didn't you were saying that but could hear you really on the on the transcription on the , , tape .
A: would prefer that people wore it on their head but they were complaining about it . because it 's not it doesn't go over the ears .
E: it 's badly designed .
A: it 's very badly designed so it 's
B: it 's very badly designed ?
D: what do you mean it doesn't go over the ears ?
B: it 's not it 's not supposed to cover up your ears .
A: but , there 's nowhere to put the pad so it 's comfortable .
B: it 's only badly
E: so that 's what you 're he 's got it on his temples so it cuts off his circulation .
B: that 's strange .
C: that 's that 's what have .
A: and it feels so good that way .
C: it feels so good when stop .
A: so again would like to do some digits .
D: somebody wanna close the door ?
E: we could do it with noise .
C: you 're always doing digits .
A: , 'm just that digit - sorta guy . so this is adam .
E: this is the same one had before .
B: it 's still the same words .
A: we 're session four . or it might be five .
D: that 's good .
A: didn't bring my previous thing .
E: now , just to be , the numbers on the back , this is the channel ?
B: that 's the microphone number .
E: that 's the microphone number .
A: leave the channel blank .
D: but number has to be ? so we have to look up the number .
E: this is jane , on mike number five . do need to say anything more ?
C: this is eric on microphone number three ,
D: this is beck on mike four .
A: should turn off the vu meter dan ? do you think that makes any difference ?
B: no , let me do it .
A: are you gonna do something other than hit "" quit "" ?
B: but 'm gonna look at the , logs as .
A: should have done it before .
E: you said turn off the what ?
A: the vu meter which tells you what the levels on the various mikes are and there was one hypothesis that perhaps that the act of recording the vu meter was one of the things that contributed to the errors .
D: but eric , , you didn't think that was reasonable hypothesis , right ?
A: that was me ,
D: that was malarkey .
A: the only reason that could be is if the driver has bug . because the machine just isn't very heavily loaded .
D: no chance of that .
A: no chance of that . just because it 's beta .
B: there there was there was bug . there was glitch last time we ran .
D: are - are yo are you recording where the table mikes are ?
A: we usually do that .
B: no , we don't . but we ought to st we ought to standardize . , spoke to somebody , morgan , about that . we should put mar , no , we can do that .
D: why don't you just do this ?
A: that 's what we 've done before .
B: they 're they 're four , three , two , one . in order now . two , and one . but we should put them in standard positions . we should make little marks on the table top .
A: which means we need to move this thing , and sorta decide how we 're actually going to do things .
B: so that we can put them that 's the point . it 'll be lot easier if we have if we have them permanently in place like that .
E: do wish there were big booms coming down from the ceiling .
C: would it make you feel more important ?
D: till the projector gets installed .
A: that 'll work .
E: that 'll be good .
A: that 'll work .
D: cuz it 's gonna hang down , make noise .
B: when 's it gonna be installed ?
D: is this is this being recorded ?
A: that 's right .
D: lila actually is almost getting pretty close to even getting ready to put out the purchase order . handed it off to her about month ago .
A: topic of this meeting is wanna talk little bit about transcription . 've looked little bit into commercial transcription services and jane has been working on doing transcription . and so we wan wanna decide what we 're gonna do with that and then get an update on the electronics , and then , , maybe also talk little bit about some infrastructure and tools , and so on . , eventually we 're probably gonna wanna distribute this thing and we should decide how we 're gonna how we 're gonna handle some of these factors . so we 're we 're collecting corpus and it 's gonna be generally useful . it seems like it 's not corpus which is , has been done before . and so people will be interested in having it , and so we will
D: using , like , audio ds like that ?
A: and and so how we do we distribute the transcripts , how do we distribute the audio files , how do we how do we just do all that infrastructure ?
C: , for that particular issue ther there are known sources where people go to find these things like the ldc .
A: but so should we do it in the same format as ldc
E: that 's right .
A: and what does that mean to what we 've done already ?
B: it 's not so much the actu the logistics of distribution are secondary to preparing the data in suitable form for distribution .
A: as it is , it 's ad - hoc combination of dan set and set up , which we may wanna make little more formal .
B: and the other thing is that , , university of washington may want to start recording meetings as , in which case we 'll have to decide what we 've actually got so that we can give them copy .
A: that 's right . was actually thinking wouldn't mind spending the summer up there . that would be fun . visit my friends and spend some time
B: different for you .
A: and then also have bunch of for doing this digits . so have bunch of scripts with waves , and some perl scripts , and other things that make it really easy to extract out and align where the digits are . and if uw 's going to do the same thing it 's worth while for them to do these digits tasks as . and what 've done is pretty ad - hoc , so we might wanna change it over to something little more standard . stm files , or xml , .
D: an - and there 's interest up there ?
A: what 's that ?
D: there 's interest up there ?
A: they certainly wanna collect more data . and so they 're applying , is that right ? something like that . for some more money to do more data . so we were planning to do like thirty or forty hours worth of meetings . they wanna do an additional hundred or so hours . so , they want very large data set . but we 're not gonna do that if we don't get money . and would like that just to get disjoint speaker set and disjoint room . one of the things morgan and were talking about is we 're gonna get to know this room really , the acoustics of this room .
B: all about that .
D: including the fan .
A: including the fan .
D: did you notice the fan difference ?
B: now you 've touched the fan control , now all our data 's gonna be
D: hear the difference ?
A: it 's enormous .
B: it 's great .
E: that 's better .
D: do you wanna leave it off or not ?
E: that 's better .
A: all the others have been on .
D: things after the then this fan 's wired backwards . this is high speed here .
E: it 's noticeable .
B: it 's like "" low "" is mid - scale .
D: maybe it maybe it isn't .
B: so it could be that it 's not actually wired backwards
D: that 's right .
B: it 's just that ambiguous .
D: was wondering also , get ready . whether the lights made any noise . so , do our meetings in the dark with no air conditioning in the future .
A: just get variety .
E: candles would be if they don't make noise .
A: they 're very good .
C: it would , it would real really mean that we should do short meetings when you turn off the turn off the air conditioning ,
A: carbon monoxide poisoning ?
D: that 's right .
C: got to finish this meeting .
D: tear tear your clothing off to stay .
C: that 's right .
D: actually , the th air the air conditioning 's still working , that 's just an auxiliary fan .
C: in addition to this issue about the uw there was announced today , , via the ldc , , corpus from believe santa barbara .
E: 've been watching for that corpus .
C: of general spoken english . and exactly how they recorded it but there 's lot of different styles of speech and what not .
E: they had people come in to certain degree and they and they have dat recorders .
C: so it is far field .
E: assume so , actually , hadn't thought about that . unless they added close field later on but , , 've listened to some of those data and , , 've been was actually on the advisory board for when they set the project up .
B: what 's it sound like ?
E: 'm glad to see that it got released . so it 's very thing .
A: wish we had someone here working on adaptation because it would to be able to take that and adapt it to meeting setting .
C: but it may be it may be useful in
E: how do you mean do you mean mechanical adaptation or
A: to adapt the speech recognition .
C: what was thinking is it may be useful in transcribing , if it 's far field , in doing , , some of our first automatic speech recognition models , it may be useful to have that data because that 's very different than any data that we have so far .
A: that 's true .
E: and and their recording conditions are really clean . 've 've heard 've listened to the data .
A: that 's not good , right ?
C: that 's that 's not great .
E: but what is that ,
D: but far field means great distance ? not head mounted ? and so that 's why they 're getting away with just two channels , or are they using multiple dats ?
E: and 't ans answer it .
A: we can look into it .
C: no , and their web their web page didn't answer it either . so 'm , , was thinking that we should contact them . so it 's that 's beside - the - point .
A: so we can get that just with , , media costs , is that right ?
C: we get it for free cuz they 're distributing it through the ldc .
A: so that would be , that would be something to look into .
C: so , actually arrange for it to arrive in short order if we 're
E: the other thing too is from
A: it 's silly to do unless we 're gonna have someone to work on it , so maybe we need to think about it little bit .
E: the other thing too is that their jus their transcription format is really and simple in the discourse domain . but they also mentioned that they have it time aligned . saw that write - up .
C: maybe we should maybe we should get copy of it just to see what they did so that we can we can compare .
E: it 's very .
A: why don't you go ahead and do that then eric ?
C: alright , 'll do that . 't remember the name of the corpus . it 's corps -
E: corpus of spoken american english . sp 've been was really pleased to see that . knew that they had some funding problems in completing it this is clever .
C: this was like phase one
E: got it through the ldc .
C: and the there 's still more that they 're gonna do like that unless they have funding issues and then it ma they may not do phase two but from all the web documentation it looked like , "" , this is phase one "" , whatever that means .
E: that , they 're really respected in the linguistics side too and the discourse area , so this is very good corpus .
C: but , it it would also maybe help be helpful for liz , if she wanted to start working on some discourse issues , , looking at some of this data and then , so when she gets here maybe that might be good thing for her .
A: actually , that 's another thing was thinking about is that maybe jane should talk to liz , to see if there are any transcription issues related to discourse that she needs to get marked .
C: maybe we should have big meeting .
D: that would be meeting ?
A: this is the meeting about the meeting .
C: but maybe we should , find some day that liz , liz and andreas seem to be around more often . so maybe we should find day when they 're gonna be here and morgan 's gonna be here , and we can meet , at least this subgroup . not necessarily have the - dub people down .
A: was even thinking that maybe we need to at least ping the - dub to see
C: we need we need to talk to them some more .
A: say "" this is what we 're thinking about for our transcription "" , if nothing else . so , shall we move on and talk little bit about transcription then ? so since that 's what we 're talking about . what we 're using right now is tool , , from this french group , called "" transcriber "" that seems to work very . so it has , , useful tcl - tk user interface
D: thi - this is the process of converting audio to text ? and this requires humans just like the stp .
A: right , right . so we 're we 're at this point only looking for word level . so all so what you have to do is just identify segment of speech in time , and then write down what was said within it , and identify the speaker . and so the things we that we know that want are the text , the start and end , and the speaker . but other people are interested in stress marking . and so jane is doing primary stress , , stress marks as . and then things like repairs , and false starts , and , filled pauses , and all that other , we have to decide how much of that we wanna do .
E: did include glo , certain first pass . my my view on it was when you have repair then , it seems we saw , there was this presentation in the one of the speech group meetings about how and liz has done some too on that , that it , that you get it bracketed in terms of like if it 's parenthetical , which know that liz has worked on , then you 'll have different prosodic aspects . and then also if it 's if it 's repair where they 're like what did , then it 's to have sense of the continuity of the utterance , the start to be to the finish . and , , it 's little bit deceptive if you include the repai the pre - repair part and sometimes or of it 's in the middle . anyway , so what was doing was bracketing them to indicate that they were repairs which isn't , very time - consuming .
D: is there already some plan in place for how this gonna be staffed or done ? or is it real is that what we 're talking about here ?
A: that 's part of the thing we 're talking about . so what we wanted to do was have jane do one meeting 's worth , forty minutes to an hour ,
E: as pilot study .
D: it this is like five times real time or ten times real time
E: as pilot study .
A: ten times about , is and so one of the things was to get an estimate of how long it would take , and then also what tools we would use . and so the next decision which has to be made actually pretty soon is how are we gonna do it ?
D: and so you make jane do the first one so then she can decide , , we don't need all this , just the words are fine .
E: that 's right , that 's right .
B: that 's right .
E: wanna hear about these , we have you were continuing with the transcription conventions for
A: so one option is to get linguistics grad students and undergrads to do it . and that 's happened in the past . and that 's probably the right way to do it . it will require post pass , people will have to look at it more than once to make that it 's been done correctly , but can't imagine that we 're gonna get anything that much better from commercial one . and the commercial ones 'm will be much more expensive .
D: can't we get joy to do it all ?
E: no , that 's
A: we will just get joy and jane to do everything .
D: is tha wasn't that what she was doing before ? that 's right .
A: but , , that 's what we 're talking about is getting some slaves who need money
E: object to that characterization !
A: and so again , have to say "" are we recording "" and then say , , morgan has consistently resisted telling me how much money we have .
D: the answer is zero . there 's reason why he 's resisted .
A: if it 's zero then we can't do any transcription . cuz we 're we
B: have such hard name .
A: 't imagine us doing it ourselves .
D: we already we already we already have plan in place for the first meeting .
E: th there is als there is also the other possibility which is if you can provide not money but instructional experience or some other perks , you can you could get people to , to do it in exchange .
D: but , , morgan 's in bind over this and thing to do is just the field of dreams theory , which is we go ahead as though there will be money at the time that we need the money . and that 's that 's the best we can do . to not do anything until we get money is ridiculous . we 're not gonna do any get anything done if we do that .
A: so at any rate , jane was looking into the possibility of getting students , at is that right ? talking to people about that ?
E: 'm afraid haven't made any progress in that front yet . should 've sent email and haven't yet .
D: do so until you actually have little experience with what this french thing does we don't even have
A: she 's already done quite bit .
E: have bunch of hours ,
D: so that 's where you came up with the the ten number ? or is that really just ?
E: actually that 's the one people usually use , ten .
C: how fast are you ?
E: and haven't really calculated how fast am ? see , 've been at the same time doing boot strapping in deciding on the transcription conventions that are , and like , , how much there 's some interesting human factors problems like , , what span of time is it useful to segment the thing into in order to , transcribe it the most quickly . cuz then , , you get like if you get span of five words , that 's easy . but then you have to take the time to mark it . and then there 's the issue of it 's easier to hear it th right the first time if you 've marked it at boundary instead of somewhere in the middle , cuz then the word 's bisected or whatever so , 've been playing with , , different ways of mar cuz 'm thinking , , , if you could get optimal instructions you could cut back on the number of hours it would take .
D: does this tool you 're using is strictly it doesn't do any speech recognition does it ?
E: no , it doesn't but what super tool . it 's great environment .
D: but but is there anyway to wire speech recognizer up to it and actually run it through
E: that 's an interesting idea .
A: we 've we 've thought about doing that but the recognition quality is gonna be horrendous .
D: first of all the time marking you 'd get you could get by tool .
B: that 's true .
D: and so if the if the issue really
E: that 's interesting .
D: 'm think about the close caption that you see running by on live news casts .
A: most of those are done by person .
D: no , understand . and in lot of them you see typos and things like that , but it but it occurs to me that it may be lot easier to correct things than it is to do things from scratch , no matter how wonderful the tool is . but if there was way to merge the two
C: , but sometimes it 's easier to type out something instead of going through and figuring out which is the right
A: we 've talked about it
E: that 'd be fun .
C: it depends on the error rate ,
D: but again the timing is for fr should be for free . the timing should be
C: but we don't care about the timing of the words .
D: you just that 's said that was critical issue .
A: we don't care about the timing of the words , just of the utterances .
B: we don't we , actually . we haven't decided which time we care about , and that 's one of the things that you 're saying , is like you have the option to put in more or less timing data and , , be in the absence of more specific instructions , we 're trying to figure out what the most convenient thing to do is .
A: so what she 's done so far , is more or less breath not breath groups , phrases , continuous phrases . and so , , that 's because you separate when you do an extract , you get little silence on either end . so that seems to work really .
E: that 's ideal . although was , the alternative , which was experimenting with before ran out of time , recently was , that , , ev if it were like an arbitrary segment of time pre - marked cuz it does take time to put those markings in . it 's really the the interface is wonderful because , , the time it takes is you listen to it , and then you press the return key . but then , , it 's like , , you press the tab key to stop the flow and , , the return key to to put in marking of the boundary . but , , there 's lag between when you hear it and when you can press the return key so it 's slightly delayed , so then you listen to it second time and move it over to here . so that takes time . now if it could all be pre - marked at some , , good
D: are are those delays adjustable ? those delays adjustable ? see lot of people who actually build with human computer interfaces understand that delay , and so when you by the time you click it 'll be right on because it 'll go back in time to put the
B: it could do that
E: not in this case .
A: we could program that pretty easily , couldn't we dan ? mis mister tcl ?
B: would have thought so ,
E: ! interesting point . that would make difference . it 's not bad
A: but , if we tried to do automatic speaker id .
E: but it does take twice .
A: cuz primarily the markings are at speaker change . but that would be
B: but we 've got we 've got the most channel data . we 'd have to do it from your signal . we 've we 've got lot of data .
A: the question is how much time will it really save us versus the time to write all the tools to do it .
E: we 've got volume .
B: but the chances are if we 're talking about collecting ten or hundred hours , which is going to take hundred or thousand hours to transcribe
D: if we can go from ten to five we 're doing big
A: we 're gonna need we 're gonna need ten to hundred hours to train the tools , and validate the tools the do the to do all this anyway .
B: if we 're just doing silence detection
E: but but it op
A: knew you were gonna do that . just saw it coming .
E: wish you had told me wish you 'd told me .
D: put put it on your sweater .
E: at what part ?
B: it 's it 's maybe like week 's work to get to do something like this . so forty or fifty hours .
E: could you get it so that with so it would it would detect volume on channel and insert marker ? and the format 's really transparent . it 's just matter of very clear it 's xml , isn't it ? it 's very , looked at the file format and it 's just it has time time indication and then something or other , and then an end time or other .
C: maybe we could try the following experiment . take the data that you 've already transcribed
D: is this already in the past or already in the future ?
C: already in the past .
D: you 've already you 've already done some ?
A: she 's she 's done about half meeting .
C: she she 's done one she 's one
D: - , see .
E: 'm not if it 's that 's much but anyway , enough to work with .
C: and throw out the words , but keep the time markings . and then go through , and go through and try and re - transcribe it , given that we had perfect boundary detection . and see if it see if it feels easier to you .
D: and forgetting all the words because you 've been thr
E: that 's what was thinking . 'd 'd be cheating little bit with familiarity effect .
C: , that 's part of the problem is , is that what we really need is somebody else to come along .
B: no , you should do it you should do it do it again from scratch and then do it again at the boundaries . so you do the whole thing three times and then we get
E: now , there 's plan .
D: and then since we need some statistics do it three more . and so you 'll get you 'll get down to one point two by the time you get done .
E: 'll do that tomorrow . should have it finished by the end of the day .
D: no , but the fact that she 's she 's did it before just might give lower bound . that 's all . which is fine . and if the lower bound is nine then it 's waste of time .
E: but there 's an extra problem which is that didn't really keep accurate it wasn't pure task the first time , so , it 's gonna be an upper bound in that case . and it 's not really strictly comparable . so though it 's good proposal to be used on new new batch of text that haven't yet done yet in the same meeting . could use it on the next segment of the text .
B: the point we where do we get the the oracle boundaries from ? or the boundaries .
A: one person would have to assign the boundaries and the and the other person would have to
E: but couldn't do it for the next
B: we we could get fake
A: that 's easy enough .
E: see what you mean .
A: could do that .
E: but the oracle boundaries would come from volume on partic specific channel wouldn't they ?
A: no , no .
B: that would be the automatic boundaries .
C: no , no , no . you wanna know given given perfect human segmentation , , you wanna know how the question is , is it worth giving you the segmentation ?
E: see what you mean .
A: that 's easy enough . could generate the segmentation and you could do the words , and time yourself on it .
D: little double - blind - ear thing .
A: so it that might be worth doing .
E: that 's good .
A: that would at least tell us whether it 's worth spending week or two trying to get tool , that will compute the segmentations .
D: and the thing to keep in mind too about this tool , guys is that , you can do the computation for what we 're gonna do in the future but if uw 's talking about doing two , or three , or five times as much and they can use the same tool , then there 's real multiplier there .
E: and the other thing too is with speaker identification , if that could handle speaker identification that 's big deal .
D: that 's why we bought the expensive microphones .
E: , that 's feature . that 's major that 's like , one of the two things that
C: there 's gonna there 's gonna be in the meeting , like the reading group meeting that we had the other day , that 's it 's gonna be bit of problem because , like , wasn't wearing microphone and there were other people that weren't wearing microphones .
D: but you didn't say anything worth while anyway , right ?
A: it might save ninety percent of the work though .
C: but , yes .
B: so need to we need to look at what the final output is but it seems like we it doesn't it seems like it 's not really not that hard to have an automatic tool to generate the phrase marks , and the speaker , and speaker identity without putting in the words .
A: 've already become pretty familiar with the format ,
E: that 'd be so great .
A: it would be easy . if you 'd tell me where it is , ?
E: we didn't finish the part of work already completed on this , you talked little bit about the transcription conventions , and , you 've mentioned in your progress report , or status report , that you had written script to convert it into so , when the it 's quickest for me in terms of the transcription part to say something like , , if adam spoke to , to just say , "" colon "" , like who could be , , at the beginning of the line . and colon instead of entering the interface for speaker identification and clicking on the thing , , indicating the speaker id . so , and then he has script that will convert it into the thing that , , would indicate speaker id .
A: it 's pretty cute .
E: if that 's clear .
A: but at any rate .
E: it 's perl script .
A: so so the at ten seems to be pretty standard . everyone more or less everyone you talk to says about ten times for hard technical transcription .
D: using wh using stone age using stone age tools .
E: that 's right .
A: using using stone age tools . looked at cyber transcriber
E: that 's true ,
A: which is service that you send an audio file , they do first - pass speech recognition . and then they do clean up . but it 's gonna be horrible . they 're never gonna be able to do meeting like this .
E: what approximately , what did you find out in terms of price or whatever ?
A: for cyber transcriber they don't quote price . they want you to call and talk . so for other services , , they were about thirty dollars an hour .
E: of of tape ? or of action ?
A: for thirty dollars an hour for of their work . so so if it 's ten times it 's three hundred dollars an hour .
C: so that 's three that 's three hours .
D: did you talk to anybody that does closed captioning for , tv ? cuz they usually at the end of the show they 'll tell what the name of the company is , the captioning company that 's doing it .
A: so my search was pretty cursory . it was just net search . and , , so it was only people who have web pages and are doing through that .
D: , the thing the thing about this is thinking , maybe little more globally than should here but that really this could be big contribution we could make . , we 've been through the stp thing , we it what it 's like to manage the manage the process , and admittedly they might have been looking for more detail than what we 're looking for here but it was big hassle , , , they constantly could 've reminding people and going over it . and clearly some new needs to be done here . and it 's it 's only our time , where "" our "" includes dan , dan and you guys . it doesn't include me .
B: if we 'd be able to do any thing to help stp type problems . but certainly for this problem we can do lot better than
D: because they wanted lot more detail ?
B: because they had because they only had two speakers , right ? the segmentation problem is
D: only had two .
A: they had two speakers over the telephone .
D: so what took them so long ?
A: mostly because they were doing much lower level time . so they were doing phone and syllable transcription , as as , , word transcription . and so we 're we decided early on that we were not gonna do that .
D: but there 's still the same issue of managing the process , of reviewing and keeping the files straight , and all this , that which is clearly hassle .
A: and so what 'm saying is that if we hire an external service we can expect three hundred dollars an hour . that 's the ball park . there were several different companies that and the range was very tight for technical documents . twenty - eight to thirty - two dollars an hour .
C: who knows if they 're gonna be able to manage multal multiple channel data ?
B: they they 'll refuse to do it .
A: we 'll have to mix them .
B: no , but , they they won't they will refuse to transcribe this material .
E: and then there 's the problem also that
B: that 's not what they 're quoting for , right ?
A: yes , it is .
D: they might they might quote it
B: for quoting meetings ?
A: sev - several of them say that they 'll do meetings , and conferences , and and so on . none of them specifically said that they would do speaker id , or speaker change mark . they all just said transcription .
D: th - th the th there may be just multiplier for five people costs twice as much and for ten people co something like that .
A: the way it worked is it was scaled . so what they had is , if it 's an easy task it costs twenty - four dollars an hour and it will take maybe five or six times real time . and what they said is for the hardest tasks , bad acoustics , meeting settings , it 's thirty - two dollars an hour and it takes about ten times real time . so that we can count on that being about what they would do . it would probably be little more because we 're gonna want them to do speaker marking .
D: lot of companies 've worked for the , the person leading the meeting , the executive or whatever , would go around the room and mentally calculate how many dollars per hour this meeting was costing , in university atmosphere you get little different thing . it 's lot like , "" he 's worth fifty an hour , he 's worth "" and so he so here we 're thinking , "" let 's see , if the meeting goes another hour it 's going to be another thousand dollars . ""
A: we have to have short meeting .
D: so ch so every everybody ta talk really fast .
E: that 's very interesting .
D: let 's get it over with .
E: talk slowly but with few words .
B: that 's right .
D: only talk when you 're pointed to .
E: there you go .
A: content words only .
E: we could have some telegraphic meetings . that might be interesting .
B: it 'd be cheap . cheap to transcribe .
A: but at any rate , so we have ballpark on how much it would cost if we send it out .
D: and we 're talking about do doing how many hours worth of meetings ?
A: thirty or forty .
D: so thirty or forty thousand dollars .
B: for ten thousand dollars .
D: what , it was thirty times
A: three hundred dollars an hour .
D: got an extra factor of three there .
C: so it 's thirty dollars an hour , essentially , right ? but we can pay graduate student seven dollars an hour . and the question is what 's the difference
B: how how much lower are they ?
C: or ei eight dollars . what do what the going rate is ? it 's it 's on the order of eight to ten .
E: that would give us good estimate .
C: but 'm not .
E: was gonna say eight you 'd say ten ?
C: let 's say ten .
B: give them break .
C: cuz it 's easier .
D: the - these are not for engineering graduate students , right ?
A: these are linguistics grad students .
C: what the what the standard
D: that 's right .
C: but there is standard pay scale what it is .
E: that 's right . that 's right .
C: so that means that even if it takes them thirty times real time it 's cheaper to do graduate students .
E: and there 's another aspect too .
A: that 's why said originally , that couldn't imagine sending it out 's gonna be cheaper .
B: no , it isn't .
E: the other thing too is that , , if they were linguistics they 'd be , in terms of like the post editing , tu content wise they might be easier to handle cuz they might get it more right the first time .
A: and also we would have control of , we could give them feedback . whereas if we do service it 's gonna be limited amount . we can't tell them , , "" for this meeting we really wanna mark stress and for this meeting we want "" and and they 're not gonna provide they 're not gonna provide stress , they 're not gonna re provide repairs , they 're not gonna provide they may or may not provide speaker id . so that we would have to do our own tools to do that .
D: just hypoth hypothetically assuming that we go ahead and ended up using graduate students . who 's the person in charge ? who 's gonna be the steve here ?
A: hope it 's jane . is that alright ?
E: now would this involve some manner of , monetary compensation or would be the voluntary , , coordinator of multiple transcribers for checking ?
A: would imagine there would be some monetary involved but we 'd have to talk to morgan about it .
B: out of out of adam 's pocket .
D: it just means you have to stop working for dave . that 's why dave should have been here .
E: don't wanna stop working for dave .
D: to pr protect his people .
A: would like you to do it because you have lot more experience than do , but if that 's not feasible , will do it with you as an advisor .
D: we 'd like you to do it and we 'd like to pay you .
E: we 'll see .
D: not being morgan though , it 's
B: we 'd like to .
A: six dollars an hour .
E: boy , if wanted to increase my income could start doing the transcribing again .
B: that 's right .
D: an and be and say , would you like fries with that when you 're thinking about your pay scale .
E: no , that would be interested in that in becoming involved in the project in some aspect like that
A: any more on transcript we wanna talk about ?
B: what so what are you so you 've done some portion of the first meeting . and what 's your plan ? to carry on doing it ?
E: what , what was right now we have so gave him the proposal for the transcription conventions . he made his , , suggestion of improvement . the the it 's good suggestion . so as far as 'm concerned those transcription conventions are fixed right now . and so my next plan would be
B: what what do they cover ?
E: they 're very minimal . so , it would be good to just to summarize that . so , , one of them is the idea of how to indicate speaker change , and this is way which meshes with , , making it so that , , , on the at the boy , it 's such interface . when you when you get the , you get the speech signal you also get down beneath it , an indication of , , if you have two speakers overlapping in in single segment , you see them one displayed one above each other . and then at the same time the top part of the screen is the actual verbatim thing . you can clip click on individual utterances and it 'll take you immediately to that part of the speech signal , and play it for you . and you can , you can work pretty between those two these two things .
D: is there limit to the number of speakers ?
A: the user interface only allows two . and so if you 're using their interface to specify overlapping speakers you can only do two . but my script can handle any . and their save format can handle any . and so , , using this the convention that jane and have discussed , you can have as many overlapping speakers as you want .
D: do is this , , university project ? th - this is the french software , right ?
A: and they 're they 've been quite responsive . 've been exchanging emails on various issues .
D: did you ask them to change the interface for more speakers ?
A: and they said that 's on in the works for the next version .
C: so multi multichannels .
A: they said they wanted to do it but that the code is really very organized around single channels . so that 's unlikely to ha happen .
D: do - do what they 're using it for ? why 'd they develop it ?
A: for this exact task ?
D: are they linguists ? but , are they are they linguists or are they speech recognition people ?
A: they 're linguists .
C: they 're they have some connection to the ldc cuz the ldc has been advising them on this process , the linguistic data consortium . but apart from that .
A: it 's also all the source is available . if you if you speak tcltk . and they have they 've actually asked if we are willing to do any development and said , , maybe . so if we want if we did something like programmed in delay , which actually is great idea , , 'm they would want that incorporated back in .
D: their pre - lay .
B: pre - lay .
E: pre - lay . and they 've thought about things . , they do have so you have when you play it back , , it 's it is useful to have , , break mark to se segment it . but it wouldn't be strictly necessary cuz you can use the , the tabbed key to toggle the sound on and off . it 'll stop the speech if you press tab . that 's feature . and then also once you 've put break in then you have the option of cycling through the unit . you could do it like multiply until you get crazy and decide to stop cycling through that unit .
D: yo - you , there 's al also the user interface that 's missing . it 's missing from all of our offices , and that is some analog input like this . it 's what audio people actually use . it 's something that wh when you move your hand further , the sound goes faster past it , like fast forward . or , you could wire mouse or trackball to do something like that .
E: why , that 's that 's not something wanted to have happen .
D: no , but 'm saying if this is what professionals who actually do this thing for for video or for audio where you need to do this , and so you get very good at jostling back and forth , rather than hitting tab , and backspace , and carriage return , and enter , and things like that .
A: we talked about things like foot pedals and other analog so , tho those are things we could do how much it 's worth doing . we 're just gonna have
E: they they have several options . so , , , mentioned the looping option . another option is it 'll pause when it reaches the end of the boundary . and then to get to the next boundary you just press tab and it goes on to the next unit . it 's very nicely thought out . and also it 'll go around the the , , but 'm not if that 's the right thing . anyway , you can so they thought about different ways of having windows that you work within , and but so in terms of the con the conventions , then , , , , it 's strictly orthographic which means with some provisions for , , , colloquial forms . so if person said , "" cuz "" instead of "" because "" then put an apostrophe at the beginning of the word and then in double ang angle brackets what the full lexical item would be . and this could be something that was handled by table but to have convention marking it as non - standard or wha don't mean standard but non , ortho orthographic , , whatever .
A: non - canonical .
E: "" gonna "" or "" wanna "" , the same thing . and and there would be limits to how much refinement you want in indicating something as non - standard pres pronunciation .
C: how are you handling backchannels ?
E: in my view , when when you 've got it densely overlapping , , didn't worry about didn't worry about specific start times .
C: what do you mean by du
E: that this is not gonna be easily processed anyway and maybe shouldn't spend too much time getting exactly when the person said "" no "" , or , , , "" immediate "" . and instead just rendered "" within this time slot , there were two people speaking during part of it and if you want more detail , figure it out for yourself "" ,
A: what what eric was talking about was channels other than the direct speech ,
E: was the way felt @ @
C: what is wh , when somebody says "" - "" in the middle of , , @ @
E: that happened very seldom .
C: cuz was was listening to dan was agreeing lot to things that you were saying as you were talking .
E: if it if there was word like "" right "" , , then wou would indicate that it happened within the same tem time frame
A: there 's an overlapping mark .
E: but wouldn't say exactly when it happened .
D: 'll be right back .
B: transcribed minute of this and there was lot of overlapping .
E: lot of overlapping , .
A: there 's lot of overlapping at the beginning and end .
B: it was at the beginning .
A: when no one when we 're not actually in the meeting , and we 're all separated , and doing things . but even during the meeting there 's lot of overlap but it 's marked pretty clearly . some of the backchannel jane had some comments and but lot of them were because you were at the meeting . and so that often you can't tell .
E: that 's true . that 's another issue .
A: jane had comments like , to who the person was speaking to .
E: only when it was otherwise gonna be puzzling because he was in the other room talking .
A: but someone who , , was just the transcriber wouldn't have known that . or when dan said , "" wa wasn't talking to you "" .
E: that 's true .
D: so you take bathroom break in the middle and keep your head mount
A: you have to turn off your mike .
B: you don't have to .
E: so he was checking the meter levels and we were handling things while he was labeling the whatever it was , and and so he was in you were talking so was saying , like "" and could label this one left . and he and he said , "" don't see anything "" . and he said he said , "" wasn't talking to you "" . or it wasn't it didn't sound quite that rude . but really , no , in the context if he can't hear what he 's saying
A: but when you when you listen to it
D: it was lot funnier if you were there though .
A: what it what happens is if you 're transcriber listening to it sounds like dan is just being total impolite .
E: you 'll see . you can listen to it . it was you who was . no , , but you were you were asking off the wall questions .
A: but but if you knew that wasn't actually in the room , and that dan wasn't talking to me , it became .
E: and that 's that 's where added comments . the rest of the time didn't bother with who was talking to who but this was unusual circum circumstance .
D: so this is this is gonna go on the meeting transcriber bloopers tape , right ?
E: and part of it was funny , reason was because it was mixed signal so you couldn't get any clues from volume that , , he was really far away from this conversation . you couldn't do that symmetrically in any case .
A: should rewrite the mix tool to put half the people in one channel and half in the other . have auto - gain - mixer tool that mixes all the head mounted microphones into one signal
E: that 's good idea .
A: and that seems to work really for the transcribers .
E: but it would be , didn't wanna add more contextual comments than were needed but that , it seemed to me , clarified that the con what was going on .
C: was just gonna ask , , so wanted to finish off the question had about backchannels , if that 's , which was , so say somebody 's talking for while and somebody goes "" - "" in the middle of it , and and what not , does the conversation come out from the or the person who 's speaking for the long time as one segment and then there 's this little tiny segment of this other speaker or does it does the fact that there 's backchannel split the it in two .
E: my focus was to try and maintain conten con content continuity and , , to keep it within what he was saying . like wouldn't say breath groups but prosodic or intonational groups as much as possible . so if someone said "" - "" in the middle of of someone 's , , intonational contour , indicated it as , like what you just did . then indicated it as segment which contained @ @ this utterance plus an overlap .
B: but that 's but there 's only one there 's only one time boundary for both speakers ,
E: that 's right . and , it could be made more precise than that
D: whenever we use these speech words we should always do the thing like you 're talking about , accent ,
E: see what you mean . and then "" hesitation "" . and so then , , in terms of like words like "" "" and "" "" wrote them because figured there 's limited number , and keep them to , limited set because it didn't matter if it was "" mmm "" or "" "" , , versus "" "" . so always wrote it as . and "" - "" , , "" . "" , like set of like five . but in any case didn't mark those .
B: "" - "" is "" . ""
E: 'd be happy with that . that 'd be fine . it 'd be good to have that in the in the conventions , what 's to be used .
A: did notice that there were some segments that had pauses on the beginning and end . we should probably mark areas that have no speakers as no speaker . then , so question mark colon is fine for that .
E: that 's fine idea . that 's fine idea .
A: just say silence .
D: what 's that mean ?
A: no one 's talking .
D: silence all around .
B: we have to mark those ? don't they can't we just leave them unmarked ?
E: you see , that 's possible too .
A: wanna leave the marked don't want them to be part of another utterance . so you just you need to have the boundary at the start and the end .
E: now that 's refinement that , , maybe it could be handled by part of the part of the script more
B: it seems like the , , tran the transcription problem would be very different if we had these automatic speaker detection turn placing things . actually it sounds like there might be problem putting it into the software if the software only handles two parallel channels . but assuming we can get around that somehow .
E: you were saying , it can read
A: it can read and write as many as you want , it 's just that it
B: but what if you wanna edit it ? we 're gonna generate this transcript with five tracks in it , but with no words . someone 's gonna have to go in and type in the words . and if there are five people speaking at once ,
A: right , it 's didn't explain it . if we use the little the conventions that jane has established , have script that will convert from that convention to their saved convention .
E: which allows five . and it can be edited after the fact , can't it also ? but their but their format , if you wanted to in indicate the speakers right there instead of doing it through this indirect route , then they window comes up and it only allows you to enter two speakers .
D: but you 're saying that by the time you call it back in to from their saved format it opens up window with five speakers ?
A: it 's just user interface .
D: they didn't quite go the whole they didn't go the whole route ,
A: the the whole saved form the saved format and the internal format , all that , handles multiple speakers . it 's just there 's no user interface for specifying multiple any more than two .
D: so your script solves doesn't it solve all our problems , cuz we 're always gonna wanna go through this preprocessing assuming it works .
E: and that works nicely cuz this so quick to enter . so wouldn't wanna do it through the interface anyway adding which worry who the speaker was . and then , , let 's see what else . in terms of like the continuity of thought for transcriptions , it 's it isn't just words coming out , it 's like there 's some purpose for an utterance . and sometimes someone will do backchannel in the middle of it but you wanna show that it 's continued at later point . so have have convention of putting like dash arrow just to indicate that this person 's utterance continues . and then when it , catches back up again then there 's an arrow dash , and then you have the opposite direction to indicate continuation of ones own utterance versus , sometimes we had the situation which is , which you which you get in conversations , of someone continuing someone else 's utterance , and in that case did tilde arrow versus arrow tilde , to indicate that it was continuation did equal arrow for the for the own for yourself things cuz it 's the speakers the same . and then tilde arrow if it was different if different speaker , , con continuation . but just , , the arrows showing continuation of thought . and then you could track whether it was the same speaker or not by knowing at the end of this unit you 'd happened later . and that was like this person continued and you 'd be able to look for the continuation .
B: but the only time that becomes ambiguous is if you have two speakers . like , if you if you only have one person , if you only have one thought that 's continuing across particular time boundary , you just need one arrow at each end , and if it 's picked up by different speaker , it 's picked up by different speaker . the time it becomes ambiguous if you have more than one speaker and that and they swap . if you have more than one thread going , then you then you need to know whether they were swapped or not .
C: how often does that happen do you think ?
B: hopefully not very much .
E: didn't use it very often .
A: especially for meetings . if if you were just recording someone 's day , it would be impossible . , if you were trying to do remembrance agent . but for meetings it 's probably alright . but , lot of these issues , that for , from my point of view , where wanna do speech recognition and information retrieval , it doesn't really matter . but other people have other interests .
B: but it does feel it does feel like it 's really in there . did this did this transcription and marked that , marked it with ellipsis because it seemed like there was difference . it 's something you wanted to indicate that it that this was the end of the phrase , this was the end of that particular transcript , but it was continued later . and picked up with an ellipsis . didn't have the equal , not equal thing .
E: that 's , that 's why didn't didn't do it that 's why about it , and re - ev and it didn't do didn't do it in ten times the time .
A: so anyway , are we interested then in writing tools to try to generate any of this automatically ? is that something you want to do , dan ?
B: but it 's something @ @ that feel we definitely ought to do .
E: also wanted to ask you if you have time estimate on the part that you transcribed . do you have sense of how long
B: it took me half an hour to transcribe minute , but didn't have any didn't even have was trying to get transcriber to run but couldn't . so was doing it by typ typing into text file and trying to fit it was horrible .
D: so thirty to one 's what you got ? so that 's new upper limit ?
E: , that 's that 's because you didn't have the segmentation help and all the other
A: but for first try that 's about right .
C: so so if we hired who if we hired whole bunch of dan 's
D: that 's right .
B: it was actually it was quite it was
A: if we hire an infinite number of dan 's
E: and there 's always warm up thing of
A: are we gonna run out of disk space ?
D: doesn't it beep in the other room when you 're out of disk space ?
C: maybe we should consider also , , starting to build up web site around all of these things .
B: that 's great !
A: dan 's already started .
B: we could have like business - to - business - commerce as !
C: that 's right . no , but 'm it would be interesting it would be interesting to see
A: can we sell banner ads ?
D: get get paid for click - throughs ?
A: what good idea , that 's how we could pay for the transcription .
C: want to introduce the word "" snot - head "" into the conversation at this point .
D: you wanna word that won't be recognized ?
C: you see , cuz , cuz
A: hey , what about me ?
E: you 're the one who raised the issue .
C: see here 's here 's my thought behind it which is that , , the that you 've been describing , jane , gu one has to , indicate , , is very interesting , 'd like to be able to pore through , , the types of tr conventions that you 've come up with and like that . so would like to see that on the web .
E: now , the alternative to web site would be to put it in doctor speech . cuz cuz what have is soft link to my transcription that have on my account
C: either 's fine .
E: but it doesn't matter .
A: we can do it all .
B: we can do it all !
E: web site 's . then you have to you have to do an ht access .
D: web site 's what ?
B: we could actually maybe we could use the tcl plug - in .
E: he 's committed himself to something .
C: see he said the word tcl and that 's
D: but he does such good job of it . he should be allowed to , , do it .
E: know , know .
B: but that but , but should be allowed to
D: if you just did crappy job , no nobody would want you to do it .
B: sh shouldn't be allowed to by by my own by my according to my own priorities . let 's look at it anyway . so definitely we should we should have some access to the data .
A: and we have we have quite disparate number of web and other sorts of documents on this project spread around . and dan has few ,
C: so we can add in links and like that to other things .
A: try try to consolidate . who wants to do that though ?
B: the other side is , .
A: no one wants to do that .
B: that 's the problem .
C: we could put we could put disorganized group gestalt
D: what what 's the issue ?
B: no one owns the project .
D: no one what ?
B: no one owns the project .
A: but don't wanna do it .
B: no one wants to own the project .
A: it 's mine !
B: then you have to do the web site .
A: "" wah - hah - hah - hah . ""
B: it 's like , it 's that simple .
D: but but what are you what are you talking about for web site hacking ? you 're talking about writing html , right ?
A: 'm talking about putting together all the data in form that is legible , and pleasant to read , and up to date , and et cetera , et cetera .
D: but , is it against the law to actually use tool to help your job go easier ?
A: it 's it 's against the law to use tool . haven't found any tools that like . it 's just as easy to use to edit the raw html as anything else .
B: that 's not true ,
A: it 's not true .
D: no , it it 's true that he hasn't found any he likes .
B: that 's true .
D: the question is what is what 's he looked at .
E: which one do you use jim ?
D: use something called trellix .
E: that 's right . which produces also site maps .
A: now , if were if were doing more powerful excuse me more complex web sites might want to .
D: it 's - it 's very powerful .
A: most of the web sites do aren't that complex .
E: would this be to document it also for outside people or mainly for in house use ?
A: mostly in house .
B: that 's right .
D: but what does internal mean ?
B: no , both .
D: you 're leaving . people at uw wanna look at it . it 's it 's internal until
C: internal to the project .
E: we could do an ht access which would accommodate those things .
A: send me pointers , rather , and 'll put it together .
B: 'm not how important that distinction is . don't think we should say , "" , it 's internal therefore we don't have to make it very good "" . you can say "" , it 's internal therefore we can put data in it that we don't we don't have to worry about releasing "" . but to try and be coherent and make it presentation .
E: it is true , that is it benefits to
D: cuz you 're gonna have to wor do the work sooner or later .
E: that 's right . it 's the early on .
D: even if it 's just writing things up .
E: it 's great idea .
A: let 's move on to electronics .
D: we out of tape out of disk ?
B: we 're doing we 're doing great .
D: was looking for the actual box plan to use , but all could couldn't find it at the local store . but this is the technology . it 's actually little bit thinner than this . and it 's two by two , by one , and it would fit right under the right under th the the lip ,
A: does everyone know about the lip on the table ? it 's great .
D: there 's lip in these tables . and , it oc especially brought the bottom along to try and generate some frequencies that you may not already have recorded . let 's see what it does to the but this was the just to review , and also brought this along rather than the projector so we can put these on the table , and push them around .
A: and and crinkle them and
E: and th "" that "" being diagram .
D: that that 's the six tables that we 're looking at . these six tables here , with little boxes , , in the middle here . the boxes are out of the way anyway . 'll - 'll show you the cro this is the table cross section . if people realize what they 're looking at .
B: you trying to screw up the the microphones ?
D: cuz this is what 's gonna happen . you got plenty of data . won't come to your next meeting . and you so this is the box 's
A: get your paper off my pda !
E: let the record show that this is exhibit two .
D: that 's right . "" or not to be "" . the box , there 's half inch lip here . the box is an inch thick so it hangs down half an inch . and so the two head set jacks would be in the front and then the little led to indicate that box is live . the the important issue about the led is the fact that we 're talking about eight of these total , which would be sixteen channels . and , , even though we have sixteen channels back at the capture , they 're not all gonna be used for this . so there 'd be subset of them used for just use the ones at this end for this many . you 'd like way to tell whether your box is live , so the led wouldn't be on .
B: all the lights .
D: so if you 're plugged in it doesn't work and the led is off that 's that 's tip off . and then the , would wire the all of the cables in in bundle come through here and collect these cables at the same time .
E: that 's good .
D: so this notion of putting down the ms and taking them away would somehow have to be turned into leaving them on the table
A: we wanna do that definitely .
D: and so the you we just epoxy them down . big screw into the table . and even though there 's eight cables they 're not really very big around so my model is to get piece of that that people put with the little you slip the wires into that 's shaped like that cross section .
A: not just sleeve them all ?
D: 'm 'm 'm going up and then 'm going down .
A: and leave them loose ?
E: that looks like semi - circle .
B: it 's like it 's sleeping policeman .
A: "" sleeping policeman "" !
D: it 's like speed bum an
E: that 's good .
D: and they 're ac they 're actually ext extruded from plastic . they sorta look like this .
C: what does that mean ?
B: that 's the that 's british for speed bump ,
C: is it speed bump ?
D: so that the wires go through here .
E: is that right ? never heard that .
A: that 's really cruel .
D: so it would go on the diagonal here .
C: it could go either way .
A: so why do we have sixteen channels instead of like some fewer number ?
B: how else are you gonna distribute them around the tables ?
D: because they 're there .
A: let me rephrase that . why two each ?
B: because then you don't have to just have one each . so that if if you have two people sitting next to each other they can actually go into the same box .
D: and to see , thi this is really the way people sit on this table . dot , dot .
E: which means two at each station .
D: that 's the way people sit . that 's how many chairs are in the room .
E: 'm just saying that for the recording .
D: and certainly you could do thing where all sixteen were plugged in .
A: but then none of these .
D: if you ha if you had nothing else .
A: none of these and no ms then .
B: only if you had it depends on this box , right ?
D: and actually , at the my plan is to only bring eight wires out of this box . thi - thi this box is one off deal .
E: that being the wiring box .
D: and , , it 's function is to to , , essentially wire converter to go from these little blue wires to these black wires , plus supply power to the microphones cuz the he the , , cheap head mounteds all require low voltage .
A: so so you 'd imagine some in some patch panel on top to figure out what the mapping was between each of these two and each of those one or what ?
D: the simplest thing could imagine , which is really , really simple is to quite literally that these things plug in . and there 's there 's plug on the end of each of these , , ei eight cables .
E: each of the blue wires ?
B: but there are only four .
D: an - and there 's only there 's only four slots that are , in the first version or the version we 're planning to build . so that was the whole issue with the led , that you plug it in , the led comes on , and and you 're live .
A: then it comes on . see , see .
D: now the the subtle issue here is that tha haven't really figured out solution for this . so , we it 'll have to be convention . what happens if somebody unplugs this because they plug in more of something else ? the there 's no clever way to let the up stream guys know that you 're really not being powered . th there will be certain amount of looking at cables has to be done if people , , rewire things .
B: , we had that last time . but there are actually that , there 's an extra there 's mix out on the radio receiver ? so there are actually six xlr outs on the back of the radio receiver and only five cables going in , had the wrong five , so ended up not recording one of the channels and recording the mix .
D: did you do any recognition on the mix out ? wonder whether it works any
B: but subtracted the four that did have from the mix and got pretty good approximation of the @ @ .
D: got the fifth ?
A: and did it work ? did it sound good ?
B: it 's not bad . it 's not bad ,
D: ain't science wonderful ?
E: that 's amazing .
A: so what 's the schedule on these things ?
B: but , you always
D: was wrestling with th with literally the number of connectors in the cable and the , , powering system . and was gonna do this very clever phantom power and decided couple days ago not to do it . so 'm ready to build it . which is to say , , the neighborhood of week to get the circuit board done .
A: so the other thing 'd like to do is , do something about the set up so that it 's little more presentable and organized . and 'm 'm just not what that is .
D: the the difficulty for this project is the intellectual capital to design the cabinet . in other words , to figure out ex exactly what the right thing is . that cabinet can go away . we can use that for kindling . but if you can imagine what the right form factor is . dan - dan and have gone around on this , and we were thinking about something that opened up in the top to allow access to the mixer . but there 's these things sticking out of the mixer which are pain , so you end up with this thing that if you stuck the mixer up here and the top opened , it 'd be it 'd be fine . you understand what 'm the you can start sketching it out , and certainly build it out of oak would it , arb , arbitrarily amount of
A: need desk at home too , alright ? is that gonna be better solution than just going out and buy one ?
D: the as we found out with the thing that , , jeff bought long time ago to hold our stereo system the you buy is total crap . and this is something you buy .
A: and it 's total crap .
D: it 's total crap . it 's useless for this function . works fine for holding kleenex ,
A: kleenex and telephones . so , it 's just question , is that something you wanna spend your time on ?
D: 'm paid for . have no problem . no , but certainly one of the issues is the , is security . we 've been been lax and lucky . really lucky with these things . but they 're not ours , the , the flat panels .
A: 'm telling you , 'm just gonna cart one of them away if they stay there much longer .
D: let the record show at at four thirty - five adam janin says
B: we 'll know we 'll know to come after .
A: then the other question is do we wanna try to do user interface that 's available out here ?
D: slipped almost slipped it by dan .
E: use - user interface
A: do we wanna try to get monitor ? or just something . and how do we want to do that ?
E: you mean like see meter readings , from while sitting here .
A: just so we see something .
D: how about use the thing that aciri 's doing . which is to say just laptop with wireless .
B: which we 'll borrow from them , when we need it .
D: what 's wrong with yours ? if we bought you
B: you could use my machine .
A: have an iram machine 've borrowed and we can use it .
D: 'm 'm serious . does does the wireless thing work on your
A: isn't that an ethernet connection or is that phone ?
B: that 's an ethernet connection . it 's going next door .
D: no 'm ain't joking here . 'm serious , that it
B: no , no , that 's the right way to do it . to have it , just
D: it 's very convenient especially if dan happens to be sitting at that end of the table to not have to run down here and look in the thing every so often ,
B: and given that we 've got wireless that we 've got we got the field .
D: but just have the it 's right there . the antenna 's right there , we need need to clear this with aciri how tough can that be ? there it you 'd all you need 's web access , isn't it ?
B: we don't need access
D: in in theory .
B: but that 's fine . that 's that 's what it does ,
A: right , so it 's just question of getting laptop and wireless modem .
D: and he had , reque @ @ my proposal is you have laptop . if if we bought you the thing would you mind using it with the
B: but 'm not if my laptop is compatible with the wave lan thing they 're using . apple has their own thing , right ?
D: your new one ?
B: apple has their own thing .
D: it just came through serial or an ethernet port .
B: you it just plug plugs in pc card , so you could probably make it run with that ,
A: the question is , is there an apple driver ?
B: imagine there is . there are there are abs there are bunch of machines at icsi that have those cards and so if if it doesn't we should be able to find machine that does that . doesn't don't the important people have those little blue vaios that
D: , that to me that 's whole nother . that 's whole nother issue . the the idea of con convincing them that we should use their network is fairly straight forward . the idea of being able to walk into their office and say , "" , can borrow your machine for while "" , is is non - starter . that don't think that 's gonna work . so , , either we figure out how to use machine somebody already in the group already owns , and the idea is that if it 's it perk , , it 's an advantage not disadvan or else we literally buy machine exactly for that purpose . certainly it solves lot of the problems with leaving monitor out here all the time . 'm not big fan of doing things to the room that make the room less attractive for other people , which is part of the reason for getting all this out of the way and , so monitor sitting here all the time people are gonna walk up to it and go , "" how come 't get , , pong on this "" or , whatev
A: 've 've borrowed the iram vaio sony thingy , and don't think they 're ever gonna want it back .
B: you 're kidding !
D: the next conference they will .
A: but that does mean so we can use that as .
D: , the certainly , you should give it shot first see whether you can get compatible . ask them what it costs . ask them if they have an extra one . who knows , they might have an extra hardware
B: 'd trade them flat panel display for it .
C: what is the , , projector supposed to be hooked up to ?
D: the , tsk . it 's gonna be hooked up to all sorts of junk . there 's gonna be actually plug at the front that 'll connect to people 's laptops so you can walk in and plug it in . and it 's gonna be con connected to the machine at the back . so we certainly could use that as constant reminder of what the vu meters are doing .
B: huge vu meters .
D: so people sitting here are going "" testing , one , two , three "" !
C: but , that 's another that 's another possibility that , , solves
B: that 's an end
D: but but the idea of having control panel it 's that 's there in front of you is really .
B: and , having it on wireless is the neatest way neatest way to do it .
D: as long as you as as long as you 're not tempted to sit there and keep fiddling with the volume controls going , "" can you talk bit louder ? ""
A: had actually earlier asked if could borrow one of the cards to do wireless and they said , "" , whenever you want "" . so it won't be problem .
D: and and it 's pcmcia card , right ? so you can have slot , in your new machine ?
C: it 's it really come down to the driver .
A: right , , and if and if his doesn't work , as said , we can use the pc .
D: it 'll it 'll work it 'll work the first time . trust steve jobs .
B: that sounds like good solution one way or the other .
A: so jim is gonna be doing wiring and you 're gonna give some thought to cabinets ?
D: we we need to figure out what we want . hey , what are those green lights doing ?
A: they 're flashing !
B: does that it means it 's gonna explode .
D: cut the red wire , the red wire !
A: when people talk , it they go on and off .
B: so again , washington wants to equip system . our system , we spent ten thousand dollars on equipment not including the pc . however , seven and half thousand of that was the wireless mikes .
D: and it and the the five thousand for the wires , so if 'm gonna do it 's joke .
B: but we haven't spent that , right ? but once we once we 've done the intellectual part of these , , we can just knock them out , right ? we can start we you can make hundred of them .
D: of the of the boards ?
B: and then we could washington could have system that didn't have any wireless but would had what 's based on these and it would cost
A: pc and peanuts .
B: pc and two thousand dollars for the - to - . and that 's about cuz you wouldn't even need the mixer if you didn't have the ms cost lot . but anyway you 'd save , on the seven or eight thousand for the for the wireless system . so actually that might be attractive . move my thumb now .
E: that 's great idea . it 's it 's to be thinking toward that .
D: like if we talked softer the disk lasts longer .
A: there 's speech compression program that works great on things like this , cuz if the dynamic range is low it encodes it with fewer bits . and so most of the time no one 's talking so it shortens it dramatically . but if you talk quieter , the dynamic range is lower and it will compress better .
D: it also helps if you talk in monotone . constant volume all the time .
E: and shorter words .
C: now , shorter words wouldn't would induce more dynamics , you want to have
B: but if the words are more predictable .
A: how about if you just go "" "" ?
E: that 's long word !
A: how do you spell that ? can you do one more round of digits ? are we done talking ?
D: it 's choice if we get choice , let 's keep talking .
A: do we have more to talk about ? are you done ?
C: but he 's not gonna say anything .
D: but you there 's problem structural problem with this though . you really need an incentive at the end if you 're gonna do digits again . like , , candy bars ,
A: 'll 'll remember to bring and 's next time .
D: or or little , , toothbrushes like they give you at the dentist . eric , you and win . we didn't make any mistakes .
A: it 's harder at the end than at the beginning .
E: we that for ,
A: should have mentioned that , to pause between lines but
D: no , know . 'm just giving you hard time .
A: it 's it 's only hard time for the transcriber not for the speech recognizer .
E: also think you said channel four and you meant microphone four . and that 's mistake .
D: so eric , you win . but the other thing is that there 's there 's colon for transcripts . and there shouldn't be colon . because see , everything else is you fill in .
B: that 's been filled in for you . but they 're in order ! they start , six , seven , eight , nine , zero , one , two , three , four , five , six , eight , nine .
D: where 'd they come from ?
B: and they 're in order because they 're sorted lexically by the file names , which are have the numbers in digits . and so they 're actually this is like all the all utterances that were generated by speaker mpj . and then within mpj they 're sorted by what he actually said .
A: didn't know that . should have randomized it .
B: it doesn't matter ! it 's like cuz you said "" six , seven , eight "" .
D: we doesn't matter .
B: we doesn't matter .
D: but the real question have is that , why bother with these ? why don't you just ask people to repeat numbers they already know ? like phone numbers , social security numbers .
B: cuz we have these writt written down , right ?
A: if we have it ,
E: social security numbers .
A: we don't have to transcribe .
B: you can you can generate
E: bank account numbers .
D: credit card numbers ,
A: we don't have to tran
B: that 's great idea .
D: so you just say your credit card numbers , say your phone numbers , say your mother 's maiden name .
A: bet we could do it .
E: password to your account .
D: people off the street .
A: actually , this got this directly from another training set , from aurora . we can compare directly .
B: looks like there were no errors .
E: was the reason made my mistake was wa - was this ?
B: there were no there were no direct driver errors , by the look of it , which is good .
A: the mike 's off .
B: so 'm gonna stop it .
D: mony on the mike .
","The Berkeley Meeting Recorder group discussed the aims , methods , timing , and outsourcing issues concerning transcription of the Meeting Recorder corpus.
The Transcriber software tool was introduced , along with a set of transcription conventions for coding different speech events.
The prospect of sending the data to an external transcription service was weighed against that of hiring a graduate student transcriber pool.
It was tentatively decided that the latter option would be less costly and allow BMR to maintain greater control over the transcription process.
Methods for distributing the data were briefly discussed , along with an initiative for creating a BMR project website.
The group received an update on the meeting room recording setup and electronics.
The group will obtain a copy of the Corpus of Spoken American English ( CSAE ) from the LDC to compare the methods and conventions used by UC Santa Barbara with those being considered for the Meeting Recorder project.
Speakers fe008 and me011 will experiment with pre-segmentation procedures in hopes of facilitating the transcription process.
Speaker fe008 will perform the transcription for one meeting ( 40-60 minutes of data ) as a pilot project.
A tentative decision was made to put speaker fe008 in charge of the in-house transcription effort.
Modifications to the Transcriber source code , e.g . adjusting the delay between the audio play function and the inputting of time boundaries , may be undertaken by the BMR group.
An initiative for creating an internal BMR project website was discussed , along with ideas for providing web access to external organizations , such as the University of Washington.
A cabinet will be built to house wires and other electronic equipment used in the recording setup.
A laptop and wireless modem will be avaiable to participants for monitoring the recording progress.
How should transcripts and corresponding audio files be formatted and distributed?
External transcription services are expensive , difficult to monitor , and are unlikely to be able to handle multi-channel data.
It is unclear which levels of transcription should be encoded.
What size of segment is most useful for doing transcriptions?
Which level of segmentation is most suitable for the aims of the project?
Transcriber's interface only allows the user to view two overlapping speakers.
Decisions must be made regarding the security of electronic recording equipment.
Efforts are in progress to collect and transcribe 30-40 hours of Meeting Recorder data.
The Transcriber tool is being used to do word-level transcriptions , and was reported to work well , when used with supplementary scripts , for specifying multiple speakers.
Other levels of transcription being considered include marking stress , repairs , and false starts.
A set of transcription conventions have been formulated for marking colloquial forms , the continuity of utterances , etc.
A cost assessment was made for sending Meeting Recorder data to an external transcription service.
It was agreed that hiring linguistics graduate students would be cheaper and allow the group to maintain greater control over the transcription process.
Tentative pre-segmentation efforts will enable the automatic generation of phrase boundaries and speaker identity coding , and will be extendable for use at UW.
Perl and XWaves scripts are available for extracting and aligning digits data.
Other suggestions for future work included performing multi-channel speech/non-speech detection , and linking an ASR system to the Transcriber tool.
The recording room electronics setup has been diagrammed and will take approximately one week to configure.
It was suggested that such efforts will enable researchers at UW and other collaborating institutions to create their own recording setups more cheaply.
"
ami_abstractive_summary,Bmr014.txt,"C: are we going ?
E: it is , must be february fifteenth .
C: the date 's written in there , . and actually if everyone could cross out the - nine next to "" session "" , and write mr eleven .
E: we didn't have front - end meeting today .
C: and let 's remember also to make that one 's gets marked as unread , unused .
F: that sounds like spy code .
C: there 's lots of clicking 'm as 'm trying to get this to work correctly .
E: any agenda items today ?
C: wanna talk little bit about getting how we 're gonna to get people to edit bleeps , parts of the meeting that they don't want to include . what 've done so far , and wanna get some opinions on , how to how to finish it up .
F: wanna ask about , some aud audio monitoring on some of the some of the equipment . in particular , the that 's just what wanna ask .
E: audio monitoring , jane .
F: ba - based on some of the tran in listening to some of these meetings that have already been recorded there are sometimes big spikes on particular things , and in pact this one 'm talking on is one of the ones that showed up in one of the meetings ,
B: "" spikes "" , you mean like , instantaneous click type spikes , or ?
F: and what the electronics is but .
C: it could be number of things . it could be touching and fiddling , and the other thing is that it could the fact that it 's on wired mike is suspicious . it might be connector .
F: then we don't really have to talk about that as an
B: you could try an experiment and say "" , 'm about to test for spikes "" ,
F: take that off the agenda .
B: and then wiggle the thing there , and then go and when they go to transcribe it , it could , ask them to come and get you . "" come get me when you transcribe this and see if there 's spikes . ""
E: were this professional audio recording , what we would do what you would do is in testing it is , you would actually do all this wiggling and make that that things are not giving that performance . and if they are , then they can't be used . let 's see . would like to have discussion about where we are on , recording , transcription where we are on the corpus . and then , the other thing which would like to talk about which is real meta - quest , , deal is , , agendas . so maybe 'll 'll start with that actually . . andreas brought up the fact that he would kinda like to know , if possible , what we were gonna be talking about because he 's peripherally involved to this point , and if there 's gonna be topic about discussion about something that he strongly cares about then he would come and and part of part of his motivation with this is that he 's trying to help us out , in the because of the fact that the meetings are tending to become reasonably large now on days when everybody shows up and so , he figures he could help that out by not showing and 'm help out his own time . by not showing up if it 's meeting that he 's he 's so , in order 'd that this is wish on his part . it 's actually gonna be hard because it seems like lot of times things come up that are unanticipated but , we could try anyway , do another try at coming up with the agenda , at some point before the meeting , say the day before .
C: maybe it would be good idea for one of us to like on wednesday , or tuesday send out reminder for people to send in agenda items .
E: you you wanna volunteer to do that ? alright so we 'll send out agenda request .
C: 'll put that on my spare brain or it will not get done .
B: that 'll help lot , actually .
E: have to tell you for the for the admin meeting that we have , lila does that every time before an admin meeting . and , she ends up getting the agenda requests , ten minutes before the meeting . but but but . but we can try . maybe it 'll work .
C: weirder things have happened .
F: 'm wondering if he were to just , , specify particular topics , maybe we 'd be able to meet that request of his little more .
B: would would also that as we get more into processing the data and things like that there 'll be more things of interest to him .
E: this this maybe brings up another topic which is so we 're done with that topic . the other topic was thinking of was the sta status on microphones and channels , and all that .
C: actually was going to say we need to talk about that too .
E: why why don't we do that .
C: the new microphones , the two new ones are in . and they are being assembled as we speak , hope . and didn't bring my car today so 'm gonna pick them up tomorrow . and then the other question was thinking about is , couple things . first of all , if the other headsets are lot more comfortable , we should probably just go ahead and get them . so we 'll have to evaluate that when they come in , and get people 's opinions on what they think of them . then the other question had is maybe we should get another wireless . another wireless setup . it 's expensive , but it does seem to be better than the wired .
E: so how many channels do you get to have in wireless setup ?
C: , 'm pretty that you can daisy - chain them together so what we would do is replace the wired mikes with wireless . so we currently have one base station with six wireless mike , possibility of six wireless receivers , and you can chain those together . and so we could replace our wired mikes with wireless if we bought another base station and more wireless mikes . so , it 's still , it 's fifteen minus six .
E: so let 's see we
C: so we could have up to nine .
E: and right now we can have up to six .
C: and we have five , we 're getting one more . and it 's , about nine hundred dollars for the base station , and then eight hundred per channel .
E: so so the only beyond the mike the cost of the mikes the only thing is the base station that 's nine hundred dollars . we should do it .
C: so 'll look into how you daisy - chain them and then just go ahead and order them .
B: don't quite understand how that how that works , . so we 're not increasing the number of channels .
C: no , we 're just replacing the wired the two wired that are still working , along with couple of the wired that aren't working , one of the wired that 's not working , with wireless .
B: three wireds work ,
C: three wireds work , .
E: but we 've had more problems with that . and that bypasses the whole the whole jimbox thing and all that . and so , we seem to have , reliable way of getting the data in , which is through the ra sony radio mikes , as long as we 're conscious about the batteries . that seems to be the key issue .
C: everyone 's battery ?
B: checked them this morning , they should be .
E: that 's the only thing with them . but the quality seems really good heard from uw that they 're they 're very close to getting their , setup purchased . they 're they 're buying something that you can just buy off the shelf .
C: we should talk to them about it because know that sri is also in the process of looking at , and so , , what we should try to keep everyone on the same page with that . they got sa apparent maybe this needs to be bleeped out ? have no clue . how much of it 's public .
E: probably we shouldn't probably we shouldn't talk about funding . but anyway there 's there 's , other activities that are going on there and and nist and uw . but but thin that at least the message we can tell other people is that our experience is quite positive with the sony , radio - mikes . now the one thing that you have said that actually concerns me little is you 're talking about changing the headsets meaning changing the connector , which means some hand - soldering ,
C: we 're having the them do it . so it 's so hand - soldering it , but 'm not doing it . so , they charge
E: nothing against you and your hand - soldering
C: you 've never seen my hand - soldering . but , as said they 're coming in .
E: , so that 's being done professionally
C: as professionally as you can get it done .
E: if they do lot of it , it 's
C: it 's just their repair shop . their maintenance people .
E: we 'll see what it 's like . that tha that can be quite good . so let 's go with that .
C: and , we 'll see , tomorrow , , what it looks like .
E: so , , , dave isn't here but he was going to start working on some things with the digits . so he 'll be interested in what 's going on with that . was the decision last time was that the transcribers were going to be doing with the digits as ? has that started , or is that ?
F: it would be to use his interface and was going to meet with him today about that .
C: right , so , the decision was that jane did not want the transcribers to be doing any of the paperwork . so did the all that last week . so all the all the forms are now on the computer . and , then have bunch of scripts that we 'll read those and let the transcribers use different tools . and want to talk to jane about how we transition to using those .
F: so he has set up that they it it will be efficient for them to do that .
C: don't 'll take too long . so , , just , matter of few days suspect .
E: so anyway we have at least one , user for the digits once they get done , which will be dave .
C: 've already done five or six sets . so if he wanted to , , just have few to start with , he could . and also have bunch of scripts that will , like , generate - files and run recognition on them also .
E: he might he might be asking if dave is on the list , if he 's invited to these meetings , if he knows .
F: don't tend to get an invitation myself for them even .
A: no , no .
C: we don't have active one but 'll make he 's on the list .
F: should we call him ? is he is he definitely not available today ? should call his office and see ?
A: he was in .
C: he 's still taking classes , so , he may have conflicts .
F: he wasn't there at cof
E: so this might be conflict for him .
C: didn't he say his signal - processing class was like tuesdays and thursdays ?
A: he has class .
B: he might have .
D: you talking about david gelbart ? he 's taking two twenty - five which is now .
E: so , that 's why we 're not seeing him . transcriptions , , beyond the digits , where we are , and so on . and the and the recordings also , just where we are .
F: so , should we don't wan wanna do the recording status first , or ?
C: we have about thirty - two hours as of , week and half ago , so we probably now have about thirty - five hours .
E: and and that 's that 's how much of that is digits ? that 's including digits ,
C: that 's including digits . haven't separated it out so have no clue how much of that is digits .
E: so anyway there 's at least probably thirty hours , there 's got to be more than thirty hour
C: of of non - digits ?
E: of of non - digits .
C: the digits don't take up that much time .
F: , don't have the exact numbers , but it would come to about eleven hours that are finished , transcribing from them right now . the next step is to that 'm working on is to insure that the data are clean first , and then channelized . what by clean is that they 're spell - checked , that the mark - up is consistent all the way throughout , and also that we now incorporate these additional conventions that , liz requested in terms of , in terms of having systematic handling of numbers , and acronyms which hadn't been specific about . , they 'll say "" ninety - two "" . and , so how you could so if you just say "" nine two "" , the there are many ways that could have been expressed . an - and had them certain number of them did put the words down , but now we have convention which also involves having it followed by , , gloss th and things .
B: and you may already be doing this , but 've noticed in the past that when 've gone through transcriptions and in order to build lexicons and things , if you , just take all the transcriptions and separate them into words and then alphabetize them , lot of times just scanning down that list you 'll find lot of inconsistencies and mis
F: you 're talking about the type token frequency listings , and use those too . you mean just on each line there 's one word it 's one token from the from the corpus . those are extremely efficient and agree that 's very good use of it .
B: so you already have that ,
F: that 's that 's way that 's the spell - check does that yes , that 's that 's exactly the strategy wanna do in terms of locating these things which are colloquial spoken forms which aren't in the lexicon .
B: cuz lot of times they 'll appear next to each other , and ,
F: and then you ca then you can do
B: in alphabetized lists , they 'll appear next to each other and so it makes it easier .
F: that 's very good that 's very good , suggestion . and that was that 's my strategy for handling lot of these things , in terms of things that need to be glossed . didn't get to that point so there are numbers , then there are acronyms , and then , there 's he she wants the , actually an explicit marker of what type of comment this is , so curly inside the curly brackets 'm gonna put either "" voc "" for vocalized , like cough or like laugh or whatever , "" nonvoc "" for door - slam , and "" gloss "" for things that have to do with if they said spoken form with this this pronunciation error . already had that convention
B: that 's great .
F: but haven't been asking these people to do it systematically cuz it most ha most efficiently handled by by filter . that was what was always planing on . so that , you get whole long list exactly what you 're saying , you get whole list of things that say "" curly bracket laugh curly bracket "" , then it 's it 's you you risk less error if you handle it by filter , than if you have this transcriber ch laboriously typing in voc space , so man so many ways that error prone . so , , 'm 'm going to convert that via filter , into these tagged , subcategorized comments , and same thing with , we see you get subset when you do what you 're saying , you end up with with , you 're collapsing across frequency you just have the tokens and you can , have filter which more efficiently makes those changes . but the numbers and acronyms have to be handled by hand , because , , jus
C: you what they could be .
F: now timit 's clear and plp is clear but there are things that are not so known , in or have variant uses like the numbers you can say "" nine two "" or you can say "" ninety - two "" ,
C: so how are you doing the
F: 'd handle the numbers individually .
C: how are you doing the , acronyms so if say pzm what would it appear on the transcript ?
F: it would be separate the letters would be separated in space and potentially they 'll have curly bracket thing afterwards but 'm not if that 's necessary , clarifying what it is , so gloss of whatever . if that 's really necessary to do that . maybe it 's thing to do because of it then indicating this is , step away from indicating that it really is intentional that those spaces are there , and indicating why they 're there to indicate that it 's the , enumerated , or it 's not good way of saying but it 's it 's the specific way of stating these letters .
C: so it sounds good .
F: and so anyway , the clean those are those things and then channelized is to then , get it into this multichannel format . and at that point then it 's ready for use by liz and don . but that 's been my top priority beyond getting it tanel channelized , the next step is to work on tightening up the boundaries of the time bins . and , thilo had breakthrough with this last week in terms of getting the channel - based speech - nonspeech segmentation , up and running and haven't haven't been able to use that yet this is my top priority get the data clean , and channelized .
C: have you also been doing spot checks , jane ?
F: you see that 's part of the cleaning process . actually have segment of ten minutes that was transcribed by two of our transcribers , and went through it last night , it 's it 's almost spooky how similar these are , word for word . and there are some differences in commas cuz commas left them discretion at commas . because it 's not part of our st of our ne needed conventions . and so they 'll be difference in commas , but it 's word - by - word the same , in huge patches of the data . and have ten minute stretch where where show that . and and sometimes it turns out that one of these transcribers has better ear for technical jargon , and the other one has better ear for colloquial speech . so , the one the colloquial speech person picked up "" gobbledy - gook "" . and the other one didn't . and on this side , this one 's picking up things like "" neural nets "" and the one that 's good on the sp on th the vocabulary on the colloquial didn't .
B: for the person who missed "" gobbledy - gook "" what did they put ?
F: it was an interesting approximation , put in parentheses , cuz have this convention that , if they 're not what it was , they put it in parentheses . so they tried to approximate it , but it was it was spelled gabbl
B: how it sounds .
F: more of an attempt to it was very clear to her that these the this was sound these are the sounds ,
C: it was technical term that she didn't recognize ,
F: but she knew that she didn't . maybe it was technical ter but she even though her technical perception is just really you 've 'm tempted to ask her if she 's taken any courses in this area or if she 's taken cognitive science courses then cuz "" neural nets "" and she has some things that are "" downsampled "" , she got that right . and some of these are rather unexpected . but ch ten solid ch chunk of ten solid minutes where they both coded the same data .
E: and the main track that you 're working with is elev eleven hours ? is that right ?
F: and that 's part of this
E: is that is that including digits ?
F: yes it is .
E: so let 's say roughly ten hours or so of it 's probably more than that but with of non - digits .
F: it 'd be more than that because my recollection is the minutes that da digits don't take more than half minute . per person . but the total set that gave them is twelve hours of tape , but they haven't gotten to the end of that yet . so they 're still working some of them are two of them are still working on completing that .
B: boy , they 're moving right along .
F: - . they 're very efficient . there 're some who have more hours that they devote to it than others .
E: so what what 's the deal with your
A: the channel thing ? it 's just , ran the recognizer , the speech - nonspeech detector on different channels and , it 's just in in this new multi - channel format and output , and gave one meeting to liz who wanted to try it for the recognizer as , the recognizer had problems with those long chunks of speech , which took too much memory or whatever , and so she will try that 'm 'm working on it .
C: is this anything different than the system you were using before ?
A: mmm , use some different features but not the basic thing is this base .
C: so there 's still no knowledge using different channels at the same time .
A: there is some , as the energy is normalized across channels
C: across all of them .
A: but that 's one of the main changes .
E: what are some of the other features ? besides the energy ? you said you 're trying some different features , .
A: mmm , use our loudness - based things before there were they were some in the log domain and changed this to the to the
E: cu - cube root ?
A: no , changed this to the to the loudness thingy with the with the how do you call it ? 'm not about the term . 'll look it up . and say it to you . that 's that 's the the thing . and and tried to normalize the features , there 's loudness and modified loudness , , within one channel , because they 're , to be able to distinguish between foreground and background speech . and it works quite . but , not always .
E: let 's see . were were you done with the transcription part ? so the next thing is this bleep editing .
C: so the the idea is that we need to have we need to provide the transcripts to every participant of every meeting to give them an opportunity to bleep out sections they don't want . so 've written bunch of tools that will generate web pages , with the transcription in it so that they can click on them and piece pieces and they can scroll through and read them , and then they can check on each one if they want it excluded . and then , it 's form , html form , so they can submit it and it will end up sending me email with the times that they want excluded . and so , , some of the questions on this is what do we do about the privacy issue . and so about this little bit and the best way to do it is every participant will have password , each person will have single password , user name and password . and then each meeting , we 'll only allow the participants who were at that meeting to look at it . and that way each person only has to remember one password .
E: 't help but wonder if this is maybe little more elaborate than is needed . for me would actually want to have some pieces of paper that had the transcription and would flip through it . and then if it was , 'd say "" it 's "" . it depends how this really ends up working out , but my thought was that the occasion of somebody wondering whether something was or not and needing to listen to it was gonna be extremely rare .
C: right , so th the fact that you could listen to it over the web is minor thing that had already done for other reasons . and so that 's minor part of it , wanted some web interface so that people you didn't actually have to send everyone the text . so what my intention to do is that as the transcripts become ready , would take them , and generate the web pages and send email to every participant or contact them using the contact method they wanted , and just , tell them , "" here 's the web page "" , "" you need password "" . so th question number one is how do we distribute the passwords , and question number two is how else do we wanna provide this information if they want it .
E: what was saying is that if you just say "" here is here is "" this maybe it sounds paleolithic but thought if you handed them some sheets of paper , that said , , "" here 's what was said in this transcription is it with you ? and if it is , here 's this other sheet of paper that you sign that says that it 's "" .
C: that there are subset of people who will want printouts that we can certainly provide .
E: and then they 'd hand it back to you .
C: but certainly wouldn't want printout . these are big , and would much rather be ha be able to just sit and leaf through it .
E: you find it easier to go through large how do you read books ?
C: certainly read books by hand . but like this , it 's easier to do it on the web . cuz you 're gonna get , , if 'm 'm in bunch of meetings and don't wanna get stack of these . wanna just be able to go to go to the web site and visit it as want .
E: going to web site is easy , but flipping through hundred pounds hundred pages of is not easy on the web .
C: don't 's that much harder than , paper .
F: have one question . so are you thinking that the person would have transcript and go strictly from the transcript ? because do think that there 's benefit to being able to hear the tone of voice and the
E: so here 's the way was imagining it , and maybe 'm wrong , but the way imagined it was that , the largest set of people is gonna go "" , didn't say anything funny in that meeting just go ahead , where 's the where 's the release ? "" and then there 'll be subset of people , think of who it is we 've been recording mostly . there 'll be subset of people , who , will say "" , , really would like to see that . "" and for them , the easiest way to flip through , if it 's really large document , unless you 're searching . searching , , should be electronic , but if you 're not so if you provide some search mechanism you go to every place they said something like that , but see then we 're getting more elaborate with this thing . if you don't have search mechanisms you just have this really , really long document , whenever 've had really , really long document that it was sitting on the web , 've always ended up printing it out . so it 's it 's you 're you 're not necessarily gonna be sitting at the desk all the time , you wanna figure you have train ride , and there 's all these situations where this is how was imagining it , anyway . and then figured , that out of that group , there would be subset who would go "" 'm really not about this section here , "" and then that group would need it if 'm right in that , it seems like you 're setting it up for the most infrequent case , rather than for the most frequent case . so that , now we have to worry about privacy ,
C: no fre for the most
E: we have to worry about all these passwords , for different people
C: for the most frequent case they just say "" it 's "" and then they 're done . and almost everyone would rather do that by email than any other method .
F: the other thing too is it seems like
E: , that 's true .
C: cuz you don't have to visit the web page if you don't want to .
E: we don't need their signature . an email is alright .
C: that was another thing had assumed that we didn't need their signature , that it that an email approval was sufficient . but don't actually know .
B: are are people going to be allowed to bleep out sections of meeting where they weren't speaking ?
C: if someone feels strongly enough about it , then they should be allowed to do that .
B: so that means other people are editing what you say ? if like that .
C: the only other choice is that the person would say "" no , don't distribute this meeting "" , and would rather they were able to edit out other people then just say "" don't distribute it "" .
E: but th what they signed in the consent form , was something that said you can use my voice .
C: but if someone is having conversation , and you only bleep out one side of it , that 's not sufficient .
E: but that 's our decision then .
C: because if object to the conversation . if say "" we were having conversation , and consider that conversation private , "" and consider that your side of it is enough for other people to infer , wanna be able to bleep out your side .
F: agree that the consent forms were , cons agree with what adam 's saying , that , the consent form did leave open this possibility that they could edit things which they found offensive whe whether they said them or didn't say them .
E: , if that 's what it said .
F: and the other thing is from the standpoint of the 'm not law lawyer , but it strikes me that , we wouldn't want someone to say "" yes , was little concerned about it but it was too hard to access "" . so it 's to have this facility to listen to it . now in terms of like editing it by hand , it 's some people would find that easier to specify the bleep part by having document they edited . but but it seems to me that sometimes , if person had bad day , and they had tone in their voice that they didn't really like , it 's it 's to be able to listen to it and be that was .
C: certainly provide printable version if people want it .
E: it 's also mixture of people , some people are do their work primarily by sitting at the computer , flipping around the web , and others do not . others would consider it this set of skills that they would have to gain .
C: most of the people in the meetings are the former .
E: it depends on what meetings .
F: that 's true .
E: in the meetings so far , . but we 're trying to expand this , so actually think that paper is the more universal thing .
C: but if they want to print it out that 's alright . everyone in the meeting can access the web .
E: no , we have to be able to print it out . it 's not just if they want to print it out .
C: so does that mean that 't use email ?
F: cuz you could send it through email you 're thinking .
C: don't think we can send the text through email because of the privacy issues . so giving them , you think web site to say , "" if you wanna print it out here it is "" , is not sufficient ?
E: certainly for everybody who 's been in the meetings so far it would be sufficient .
C: 'm just thinking for people that 's not sufficient for , what the only sufficient thing would be for me to walk up to them and hand it to them .
E: 'm just wondering about
F: you could mail it to them . get an mailing address . but it 's easier to drop in the box .
A: just put the button on the web page which say "" send me the scripts "" .
C: that 's right .
F: that 's interesting .
B: when you display it on the web page , what are what are you showing them ? and so can they bleep within an utterance ?
C: whole utterances only . and that was just convenience for my sake , that it 's , it would end up being fairly difficult to edit the transcripts if we would do it at the sub - utterance level . because this way just delete an entire line out of transcript file rather than have to do it by hand .
E: there 's another aspect to this which maybe is part of why this is bothering me . you 're really trying very hard to make this as convenient as possible for people to do this .
C: that 's why did the web form , because for me that would be my most convenient .
B: know where you 're going .
E: that 's the bad idea . see because you 're gon you 're you 're gonna end up with all these little patchy things , whereas really what we want to do is have the the bias towards letting it go . one or twi once or twice , in the re in the meetings we 've heard , where somebody said something that they might be embarrassed by , but overall people are talking about technical topics . nobody 's gonna get hurt . nobody 's being libeled . this is this we 're covering we 're playing the lawyer 's game , and we 're playing we 're we 're looking for the extreme case . if we really orient it towards that extreme case , make it really easy , we 're gonna end up encouraging headache . 'm psyching myself out here ,
C: don't see having few phrases here and there in meeting being that mu much of headache , bleeped out .
B: what morgan 's saying is the easier it is , the more is gonna be bleeped .
E: and and it really depends on what research you 're doing . some researchers who are gonna be working with this corpus years from now are really gonna be cursing the fact that there 's bunch of in there that 's missing from the dialogue . it depends on the research they 're doing , but it might be , it might be really pain . and , where it 's really gonna hurt somebody , in some way the one who said it or someone who is being spoken about , we definitely want to allow the option of it being bleeped out . but really think we wanna make it the rare incidence . and and , am just little worried about making it so easy for people to do , and so much fun ! that they 're gonna go through and bleep out .
F: so much fun .
E: and they can bleep out they don't like too , from somebody else , as you say , so "" didn't like what he said . ""
C: don't see any way of avoiding that . we have to provi we have promised that we would provide them the transcript and that they can remove parts that they don't like .
E: no , no , don't
C: the only question is
E: you - you 've talked me into that , but think that we should make it harder to do .
C: the problem is if it 's harder for them it 's also harder for me . whereas this web interface , get email , it 's all formatted , it 's all ready to go and just insert it .
E: so maybe you don't give them access to the web interface unless they really need it . so so maybe this is way out of it . you 've provided something that 's useful for you to do handle , and useful for someone else if they need it . but the issue of privacy and ease and should be that , they get access to this if they really need it .
B: so you 're saying the sequence would be more like first adam goes to the contact lists , contacts them via whatever their preferred method is , to see if they want to review the meeting . and then if they don't , you 're done . if they do , then he provides them access to the web site .
C: to some extent have to do that anyway because as said we have to distribute passwords .
B: or printed - out form .
E: but you don't necessarily have to distribute passwords is what 'm saying .
B: only if they want it .
C: what 'm saying is that 't just email them the password because that 's not secure . so they have to call me and ask .
E: no , no . but you aren't necessarily giving them but we don't even necessarily need to end up distributing passwords .
C: we do because of privacy . we can't just make it openly available on the web .
E: no , no . you 're missing the point . we 're we 're trying we 're trying to make it less of an obvious just fall off log , to do this .
F: not everyone gets password , unless they ask for it .
E: so th so what would see , is that first you contact them and ask them if they would like to review it for to check for the not just for fun , but to check this for things that they 're worried about having said or if they 're willing to just send an approval of it , at from their memory . and , , and we should think carefully actually we should review go through how that 's worded , then , if someone wants to review it , , and know you don't like this , but 'm offering this as suggestion , is that is that we then give them print out . and then if they say that "" have potential problem with these things , "" then , you say "" you might wanna hear this in context to you need that , "" you issue them password , in the
C: but the problem with what you 're suggesting is it 's not just inconvenient for them , it 's inconvenient for me . because that means multiple contacts every time for every single meeting every time anyone wants anything . would much prefer to have all be automatic , they visit the web site if they want to . they don't have to .
E: know you 'd prefer it , but the proble
C: so you 're thinking people are going to arbitrarily start bleeping and don't think that 's gonna happen .
E: there 's problem with it .
F: 'm also concerned about the spirit of the of the informed consent thing . cuz if they feel that , it 's th th if it turns out that something gets published in this corpus that someone really should have eliminated and didn't detect , then it could have been because of their own negligence that they didn't pursue that next level and get the password and do that , but they might be able to argue "" it was cumbersome , and was busy and it was gonna take me too much time to trace it down "" . so it could that the burden would come back onto us . so 'm little bit worried about , making it harder for them , from the legal standpoint .
E: you can go too far in that direction , and you need to find somewhere between ,
C: it seems to me that sending them email , saying "" if you have an - reply to this email and say , if you have problem with it contact me and 'll give you password "" , seems like is perfectly , reasonable compromise . and if they want printout they can print it out themselves .
F: or we could print it up for them , we could offer that but there 's , another aspect to that and that is that in the informed consent form , , my impression is that they that we offered them at the very least that they definitely would have access to the transcript . that there 's chance of really skipping that stage . maybe misinterpreted what you said but it 's
E: having access to it doesn't necessarily mean , that having it
F: giving it to them .
E: it just means they have the right to have it .
C: the consent form is right in there if anyone wants to look at it , you want me to grab one ? but you 're wired
F: that is true .
E: , don't wanna fool them , meant that every ev any time you say anything to anyone there is bias that is presented ,
C: "" if you agree to participate you 'll have the opportunity to have anything ex anything excised , which you would prefer not to have included in the data set . ""
F: that 's true .
C: "" once transcript is available we will ask your permission to include the data in the corpus for the larger research community . there again you will be allowed to indicate any sections that you 'd prefer to have excised from the database , and they will be removed both from the transcript and the recording . ""
F: that 's more open than realized .
C: the one question is definitely clear with anything as opposed to just what you said .
E: no that it tha
F: tha - that 's true . that 's more severe , but the next one says the transcript will be around .
E: that 's right .
F: and it doesn't really say we 'll send it to you , or wi it 'll be available for you on the web , or anything .
B: it probably leaves it open how we get it to them .
F: at least it more often . it means also we don't have to to give it to them . like morgan was saying they
C: they just have to make that it is available to them .
F: it 's available to them if they ask for it .
E: so . wh have an idea that may be sat may satisfy both you and me in this which is , , it 's it we just go over carefully how these notes to people are worded . so want it to be worded in such way where it gives the strong impre it gives very , nothing hidden , very strongly the bias that we would really like to use all of these data . that that we really would rather it wasn't patchwork of things tossed out , that it would be better for , , our , , field if that is the case . but if you really mething is gonna and don't think there 's anything in the legal aspects that is hurt by our expressing that bias .
F: great , great .
E: and then my concern about which you might be right , it may be it was just paranoia on my part , but people just see 'm @ @ worried about this interface so much fun that people start bleeping out just as just because they can .
C: it 's just check box next to the text , it 's not any fun .
E: had fun when you played me something that was bleeped out .
C: but they won't get that feedback . no because it doesn't automatically bleep it at the time . it just sends me
E: so you haven't made it so much fun .
C: it just sends me the time intervals . and then at some point 'll incorporate them all and put bleeps . don't wanna have ha do that yet until we actually release the data because , then we have to have two copies of every meeting and we 're already short on disk space . so wanna keep the times until we actually wanna release the data and then we bleep it .
E: so if we have if again let 's , circulate the wording on each of these things and get it right ,
C: since you seem to feel heart , strongest about it , would you like to do the first pass ?
E: turn about is fair play ,
F: al - also it ther there is this other question , the legal question that adam 's raised , about whether we need concrete signature , or email suffices or whatever and how that works . there 's something down there about "" if you agree to ""
E: 'm 'm about it with one of my background processes and it 's , it 's fine to do the email .
C: because thi th they 're signing here that they 're agreeing to the paragraph which says "" you 'll be given an opportunity . "" and so don't think they need another signature .
E: it 's now fairly routine in lot of arrangements that do with people on contracts and that if it 's if it 's that thing where you 're saying "" agree , we want eighty hours of this person at such - and - such amount , and agree that 's , "" if it 's follow up to some other agreement where there was signature it 's often done in email now so it 's it 's .
C: so probably should at the minimum , think about how to present it in printed form . 'm not really what 's best with that . the problem is lot of them are really short , and so don't necessarily wanna do one per line . but how else to do it .
F: it 's you have it , viewab her hearable on the on the web for those who might wonder about , the non nonverbal side , agree that our bias should be as expressed here , and but it 's that person could check . cuz sometimes you the words on on the page , come out soun sounding different in terms of the social dynamics if they hear it . and realize we shouldn't emphasize that people , shouldn't borrow trouble . what it comes down to but
C: my opinion probably is that the only time someone will need to listen to it is if the transcript is not good . if there are lots of mumbles and parentheses and things like that .
F: , or what if there was an error in the transcript that didn't get detected and there was whole segment against some personal th
C: that was all mumbled ?
F: or or even or even there was line about how "" - mmm bill gates duh - duh - duh . "" but it was all the words were all visible , but they didn't end up some there was slip in the transcript .
C: they 're gonna hate this meeting .
F: that 's true .
C: actually liz will like it .
E: liz will like it . we had pretty strong disagreement going there .
C: , that 's right .
F: we 're assuming that the transcript is close enough approximation and that my double checking will be so close to perfect that it that nothing will slip by .
E: some something might sometime , and they if it 's something that they said , they might you might be very accurate in putting down what they actually said , but , when they hear it , themselves , they may hear something different because they they meant .
F: how to notate that . that 's right .
B: how do you how do you indicate sarcasm ?
F: that 's right .
E: no , 'm serious . so the so the so we might we might get some feedback from people that such - and - such was , , not really what said .
C: that would be good to get , definitely . just for corrections . so , in terms of password distribution , phone is really the only way to do it , phone and in person . or mail , physical mail .
F: leave it on their voice mail .
B: any sub - word level thing .
C: any sub - wor you could do it with pgp or things like that but it 's too complex .
F: realized something , which is of th this question about the the possible mismatch of and actually also the lawyer saying that , we shouldn't really have them have the people believing that they will be cleared by our checks . so it 's like in way it 's it 's to have the responsibility still on them to listen to the tape and hear the transcript , to have that be the
E: but you can't dep most people will not wanna take the time to do that , though .
F: , fair enough . and they 're they 're absorbing the responsibility themselves .
E: and they have to
F: so it 's not it 's not
E: but if you were at meeting , and you don't think , at least , that you said anything funny and the meeting was about , , some funny thing about semantics , or
C: you probably won't listen to it .
F: it is true that tec that the content is technical , and so and we 're not having these discussions which when listen to these things , don't find things that are questionable , in other people 's speech or in my own .
E: you would would be rare ,
F: it should be very rare .
E: we 're not talking about the energy crisis , people have
C: how about them energy crises .
E: actually , was gonna di - did you have anything that 's going on , or
D: my project is going along but , 'm really just here to fill the project the overall progress . don't really have anything specific to talk about .
E: that 's fine . didn't wanna go by you , if you had something . you don't have anything to say . transcribers , he was rattling the marbles in his brain back and forth just then this
C: shall we do digits ? we should count out how many more digits to forms do we have back there ?
B: there were quite few .
C: that 's what . was going through them all and found actually lot filed in with them , that were blanks , that no one had actually read . and so we still have more than we did . so , we have few more digits before we 're done .
B: having this headset reminds me of like working at burger king .
F: did you do that ?
C: 'd like burger with that ,
B: no never did .
C: do you want fries with that ?
B: but feel like could now .
","The Berkeley Meeting Recorder group discussed recording equipment issues , including the purchase of two additional headsets and the prospect of getting a new base station and a set of wireless microphones to replace those wired microphones currently in use.
Speaker fe008 presented the current status on transcriptions , and explained procedures for cleaning up transcripts and ensuring they conform with set conventions.
Speaker mn014 briefly described his efforts to normalize loudness levels across speech channels to distinguish between foreground and background speech.
Finally , the group discussed legal and procedural issues concerning the provision of transcripts to meeting participants for 'bleeping out' any sections of speech they want excluded from the Meeting Recorder database.
The consent form issued to subjects prior to meetings will be revised to make more explicit details concerning access to transcripts and the ability of subjects to mark sections of meetings for exclusion from the database.
The group decided to replace wired microphones with a wireless setup , i.e . a new base station and set of wireless microphones.
Efforts will be made to ensure that recording conventions are consistent across ICSI , the University of Washington , and SRI.
Some of the meeting recordings contain spikes.
It was surmised that such disturbances are probably due to the connectors attached to a set of wired microphones in use.
With respect to editing bleeps , should participants be allowed to edit out others' speech?
It was suggested that making transcripts available to all of the subjects involved might make it too easy for them to edit out sections of meetings , whereas the bias should be to ensure that editing bleeps occur only rarely in the database.
Two additional wireless headsets will soon be made available.
Approximately 32-35 hours of meeting data have been recorded , roughly 30 hours of which comprise non-digits recordings.
The transcribers have begun performing digit extraction ( see abstract for Bmr013 ) and should be finished within a few days.
Approximately 11 hours of speech have been transcribed.
Efforts by speaker fe008 are in progress to ensure that transcripts are clean ( i.e . spell checked ) , channelized , and conform to set conventions regarding the coding of numbers , acronyms , and explicit comments ( e.g . door slams , coughs , and laughter ).
Subsequent efforts by speaker fe008 will be to tighten up boundaries on the time bins.
Inter-annotator agreement was reported to be very good.
Speaker mn014's multi-channel speech/non-speech segmenter is in use.
The SRI recognizer will be fed with pre-segmented output to eliminate difficulties with processing overly long speech segments.
Efforts by speaker mn014 to normalize loudness and distinguish between foreground and background speech have been largely successful.
The group discussed procedural issues concerning the provision of transcripts to meeting participants for 'bleeping out' any sections of speech they want excluded from the Meeting Recorder database.
"
ami_abstractive_summary,Bed002.txt,"A: we 're on . so just make that th your wireless mike is on , if you 're wearing wireless . and you should be able to see which one which one you 're on by , , watching the little bars change .
B: so , which is my bar ?
A: so , actually , if you guys wanna go ahead and read digits now , as long as you 've signed the consent form , that 's alright .
E: are we supposed to read digits at the same time ?
A: we 're talking about doing all at the same time but cognitively that would be really difficult . to try to read them while everyone else is .
E: everyone would need extreme focus .
A: so , when you 're reading the digit strings , the first thing to do is just say which transcript you 're on .
C: we we may wind up with ver we we may need versions of all this garbage .
A: so the first thing you 'd wanna do is just say which transcript you 're on . you can see the transcript ? there 's two large number strings on the digits ? so you would just read that one . and then you read each line with small pause between the lines . and the pause is just so the person transcribing it can tell where one line ends and the other begins . and 'll give 'll read the digit strings first , so can see how that goes . again , 'm not how much should talk about before everyone 's here .
C: we have one more coming .
A: why don't go ahead and read digit strings and then we can go on from there .
C: we can start doing it .
A: so , , just also note on wearing the microphones . all of you look like you 're doing it reasonably correctly , but you want it about two thumb widths away from your mouth , and then , at the corner . and that 's so that you minimize breath sounds , so that when you 're breathing , you don't breathe into the mike . that 's good . so , everyone needs to fill out , only once , the speaker form and the consent form . and the short form you should read the consent form , but , the thing to notice is that we will give you an opportunity to edit all the transcripts . so , if you say things and you don't want them to be released to the general public , which , these will be available at some point to anyone who wants them , , you 'll be given an opportunity by email , , to bleep out any portions you don't like . on the speaker form just fill out as much of the information as you can . if you 're not exactly about the region , we 're not exactly either . so , don't worry too much about it . the it 's just self rating . and that 's about it . should do you want me to talk about why we 're doing this and what this project is ?
C: no . there was there was let 's see .
E: does nancy know that we 're meeting in here ?
B: sent an email .
C: she got an emai she was notified . whether she knows is another question . so are the people going to be identified by name ?
A: what we 're gonna we 'll anonymize it in the transcript . but not in the audio .
C: so , then in terms of people worrying about , , excising things from the transcript , it 's unlikely . since it does isn't attributed . but the but the but the
A: right , so if said , "" , hi jerry , how are you ? "" , we 're not gonna go through and cancel out the "" jerry ""s . so we will go through and , in the speaker id tags there 'll be , , - one seven , - one eight . good way of doing it on the audio , and still have people who are doing discourse research be able to use the data .
C: no , wasn't complaining , wanted to understand .
B: we can make up aliases for each of us .
A: , whatever you wanna do is fine , but we find that we want the meeting to be as natural as possible . so , we 're trying to do real meetings . and so we don't wanna have to do aliases and we don't want people to be editing what they say . so that it 's better just as pro post - process to edit out every time you bash microsoft .
C: . so why don't you tell us briefly your give your normal schpiel .
A: so this is the project is called meeting recorder and there are lots of different aspects of the project . so my particular interest is in the pda of the future . this is mock - up of one . yes , we do believe the pda of the future will be made of wood . the idea is that you 'd be able to put pda at the table at an impromptu meeting , and record it , and then be able to do querying and retrieval later on , on the meeting . so that 's my particular interest , is portable device to do , information retrieval on meetings . other people are interested in other aspects of meetings . so the first step on that , in any of these , is to collect some data . and so what we wanted is room that 's instrumented with both the table top microphones , and these are very high quality pressure zone mikes , as as the close talking mikes . what the close talk ng talking mikes gives us is some ground truth , gives us , , high quality audio , especially for people who aren't interested in the acoustic parts of this corpus . so , for people who are more interested in language , we didn't want to penalize them by having only the far field mikes available . and then also , , it 's very , very hard task in terms of speech recognition . and so , , on the far field mikes we can expect very low recognition results . so we wanted the near field mikes to at least isolate the difference between the two . so that 's why we 're recording in parallel with the close talking and the far field at the same time . and then , all these channels are recorded simultaneously and framed synchronously so that you can also do things like , , beam - forming on all the microphones and do research like that . our intention is to release this data to the public , , probably through through body like the ldc . and , , just make it as generally available corpus . there 's other work going on in meeting recording . so , we 're we 're working with sri , nist has started an effort which will include video . we 're not including video , . and and then also , , small amount of assistance from ibm . is also involved . , and the digit strings , this is just more constrained task . so because the general environment is so challenging , we decided to do at least one set of digit strings to give ourselves something easier . and it 's exactly the same digit strings as in ti - digits , which is common connected digits corpus . so we 'll have some , , comparison to be able to be made . so when the last person comes in , just have them wear wireless . it should be on already . either one of those . and , read the digit strings and fill out the forms . so , the most important form is the consent form , so just be be everyone signs that , if they consent .
B: 'm it 's pretty usual for meetings that people come late , so you will have to leave what you set .
A: and , just give me call , which , my number 's up there when your meeting is over . and 'm going to leave the mike here but it 's {nonvocalsound} , but 'm not gonna be on so don't have them use this one . it 'll just be sitting here .
B: there we go .
C: adam , we will be using the , , screen as . so you guys who got email about this , friday about what we 're up to .
E: what was the nature of the email ?
C: this was about , inferring intentions from features in context , and the words , like "" go to see "" , or "" visit "" , or some you didn't get it ? these have got better filters . cuz sent it to everybody . you just blew it off .
B: it 's really simple though . so this is the idea . we could pursue , , if we thought it 's it 's worth it but , , we will agree on that , , to come up with with very , very first crude prototype , and do some implementation work , and do some research , and some modeling . so the idea is if you want to go somewhere , focus on that object down actually walk with this . that 's the powder - tower . now , , we found in our , , data and from experiments , that there 's three things you can do . you can walk this way , and come really , really close to it . and touch it . but you cannot enter or do anything else . unless you 're interested in rock climbing , it won't do you no good standing there . it 's just dark alley . but you can touch it . if you want to actually go up or into the tower , you have to go this way , and then through some buildings and up some stairs and . if you actually want to see the tower , and that 's what actually most people want to do , is just have good look of it , take picture for the family , you have to go this way , and go up here . and there you have vre really view it exploded , the during the thirty years - war . really , interesting sight . and , these these lines are , , paths , or so that 's ab er , the street network of our geographic information system . and you can tell that we deliberately cut out this part . because otherwise we couldn't get our gis system to take to lead people this way . it would always use the closest point to the object , and then the tourists would be faced , , in front of wall , but it would do them no good . so , what we found interesting is , first of all , intentions differ . maybe you want to enter building . maybe you want to see it , take picture of it . or maybe you actually want to come as close as possible to the building . for whatever reason that may be .
E: what 's it what 's it made out of ? so maybe you would wanna touch it .
B: maybe you would want to touch it . this , these intentions , we we could , if we want to , call it the vista mode , where we just want to get the overview or look at it , the enter mode , and the , , tango mode . always come up with silly names . so this "" tango "" means , literally translated , "" to touch "" . so but sometimes the tango mode is really relevant in the in the sense that , , if you want to , if you don't have the intention of entering your building , but that something is really close to it , and you just want to approach it , or get to that building . consider , , the post office in chicago , building so large that it has its own zip code . so the entrance could be miles away from the closest point . so sometimes it makes sense maybe to to distinguish there . so , , 've looked , , through twenty some didn't look through all the data . and there 's , lot more different ways in people , the ways people phrase how to get if they want to get to certain place . and sometimes here it 's it 's little bit more obvious maybe should go back couple of steps and go through the
C: no , come in , sit down . if you grab yourself microphone .
B: you need to sign some and read some digits .
C: you can sign afterwards .
E: you have to al also have to read some digits .
D: . afterwards is fine .
B: they are uncomfortable . but that was our idea .
C: and it it also has to be switched on , nance .
E: no , that one 's already on , he said .
C: it 's on ?
D: it 's on .
B: that was the idea . people , when they when they want to go to building , sometimes they just want to look at it . sometimes they want to enter it . and sometimes they want to get really close to it . that 's something we found . it 's just truism . and the places where you will lead them for these intentions are sometimes ex in incredibly different . gave an example where the point where you end up if you want to look at it is completely different from where if you want to enter it . so , this is how people may , may phrase those requests to mock - up system at least that 's the way they did it . and we get tons of these "" how do get to "" , "" want to go to "" , but also , "" give me directions to "" , and "" would like to see "" . and , what we can do , if we look closer closer at the data that was the wrong one . we can look at some factors that may make difference . first of all , and , that 've completely forgot that when we talked . this is crucial factor , "" what type of object is it ? "" so , some buildings you just don't want to take pictures of . or very rarely . but you usually want to enter them . some objects are more picturesque , and you more more highly photographed . then the actual phrases may give us some idea of what the person wants . sometimes found in the , looking at the data , in superficial way , found some modifiers that may also give us hint , "" 'm trying to get to "" "" need to get to "" . hints to the fact that you 're not really sightseeing and just there for pleasure and and so on . and this leads us straight to the context which also should be considered . that whatever it is you 're doing at the moment may also inter influence the interpretation of phrase . so , this is , , really my suggestion is really simple . we start with , now , let me , , say one more thing . what we do know , is that the parser we use in the smartkom system will never differentiate between any of these . so , all of these things will result in the same xml - three - structure . action "" go "" , and then an object . so it 's it 's way too crude to capture those differences in intentions . so , , "" mmm ! maybe for deep understanding task , that 's playground or first little thing . "" where we can start it and look "" , we need , we gonna get those - three - structures . the crude , undifferentiated parse . we may need additional part of speech , or maybe just some information on the verb , and modifiers , auxiliaries . we 'll see . and will try to come up with list of factors that we need to get out of there , and maybe we want to get switch for the context . so this is not something which we can actually monitor , now , but just is something we can set . and then you can all imagine constrained satisfaction program , depending on what , , comes out . we want to have an structure resulting if we feed it through belief - net along those lines . we 'd get an inferred intention , we produce structure that differentiates between the vista , the enter , and the , , tango mode . which we maybe want to ignore . but . that 's my idea . it 's up for discussion . we can change all of it , any bit of it . throw it all away .
F: now @ @ this email that you sent , actually . now remember the email .
E: still , have no recollection whatsoever of the email . 'll have to go back and check .
C: so , what is important is that we understand what the proposed task is . and , the , robert and talked about this some on friday . and we 's - formed . so we 's - formed , , starter task for this , , deeper understanding in the tourist domain .
F: so , where exactly is the , , deeper understanding being done ? like , is it before the bayes - net ?
C: it 's the it 's always all of it . so , in general it 's always going to be , the answer is , everywhere . so the notion is that , , this isn't real deep . but it 's deep enough that you can distinguish between these th three quite different kinds of , , going to see some tourist thing . and , so that 's that 's the quote "" deep "" that we 're trying to get at . and , robert 's point is that the current front - end doesn't give you any way to not only doesn't it do it , but it also doesn't give you enough information to do it . it isn't like , if you just took what the front - end gives you , and used some clever inference algorithm on it , you would be able to figure out which of these is going on . and this is bu - in general it 's gonna be true of any deep understanding , there 's gonna be contextual things , there 're gonna be linguistic things , there 're gonna be discourse things , and they gotta be combined . and , my idea on how to combine them is with belief - net , although it may turn out that some different thing is gonna work better . the idea would be that you , , take your you 're editing your slide ?
B: as , as get ideas , so , discourse about that . that needs to go in there .
C: so . this is minutes taking minutes as we go , in his in his own way . anyway . so , , naively speaking , you 've you 've got for this little task , belief - net , which is going to have as output , the conditional pr probability of one of three things , that the person wants to , to view it , to enter it , or to tango with it . so that the output of the belief - net is pretty formed . and , then the inputs are going to be these kinds of things . and , then the question is there are two questions is , , one , where do you get this information from , and two , what 's the structure of the belief - net ? so what are the conditional probabilities of this , that , and the other , given these things ? and you probably need intermediate nodes . we what they are yet . so it may be that , , , that , , knowing whether another thing you want is some information abou , about the time of day . now , they may wanna call that part of context . but the time of day matters lot . and , if things are closed , then , you
B: people won't want to enter it .
C: pe - people don't wanna enter them . and , if it 's not obvious , you may want to actually , point out to people that it 's closed , what they 're going to is closed and they don't have the option of entering it . so another thing that can come up , and will come up as soon as you get serious about this is , that another option is to have more of dialogue . so if someone says something you could ask them . and now , one thing you could do is always ask them , but that 's boring . and it also it also be pain for the person using it . so one thing you could do is build little system that , said , "" whenever you got question like that 've got one of three answers . ask them which one you want . "" but that 's , , not what we 're gonna do .
B: but maybe that 's false state of the system , that it 's too close to call .
C: you want the you want the ability to you want the ability to ask , but what you don't wanna do is onl build system that always asks every time , that 's not getting at the scientific problem , in general you 're , it 's gonna be much more complex than that . this is purposely really simple case .
B: have one more point to bhaskara 's question . also the the deep understanding part of it is going to be in there to the extent that we , want it in terms of our modeling . we can start , , basic from human beings , going , walking , seeing , we can mem model all of that and then compose whatever inferences we make out of these really conceptual primitives . that will be extremely deep in the in my understanding .
C: so the way that might come up , if you wanna suppose you wanted to do that , you might say , "" , as an intermediate step in your belief - net , is there source - path - goal schema involved ? "" and if so , , is there focus on the goal ? or is there focus on the path ? and that could be , , one of the conditiona th the in some piece of the belief - net , that could be the appropriate thing to enter .
F: so , where would we extract that information from ? from the - three - ?
C: no . see , the - three - is not gonna give th what he was saying is , the - three - does not have any of that . all it has is some really crude saying , "" person wants to go to place . ""
E: the - three - is the old smartkom output ?
C: - three , - three - itself refers to multimedia mark - up language .
E: it 's just language .
C: so we have th we have to have better way of referring to
B: the parser output ? "" analyzed speech "" it 's what they call it , th no , actually , intention lattices is what we 're gonna get .
C: is - but they they call it intention lattice ,
B: in - in intention lattice hypothesis . they call it intention hypotheses .
C: so , th they 're gonna give us some cr or we can assume that you get this crude information . and that 's all they 're going to provide . and they don't give you the object , they don't give you any discourse history , if you want to keep that you have to keep it somewhere else .
B: they keep it . we have to request it . but it 's not in there .
C: they kee they keep it by their lights . it may it may or may not be what we want .
E: so , if someone says , "" wanna touch the side of the powder - tower "" , that would , we need to pop up tango mode and the and the directions ?
C: if if , if it got as simple as that , . but it wouldn't .
E: but that doesn't necessarily but we 'd have to infer source - path - goal to some degree for touching the side , right ?
B: th the there is point there if understand you . correct ? because , sometimes people just say things this you find very often . "" where is the city hall ? "" and this do they don't wanna sh see it on map , or they don't wanna 's five hundred yards away from you , or that it 's to the your north . they wanna go there . that 's what they say , is , "" where is it ? "" . where is that damn thing ?
E: and the parser would output
B: that 's question mark . lot of parsers , , that 's way beyond their scope , is of interpreting that . still outcome the outcome will be some form of structure , with the town hall and maybe saying it 's wh focus on the town hall . but to interpret it , somebody else has to do that job later .
E: 'm just trying to figure out what the smartkom system would output , depending on these things .
B: it will probably tell you how far away it is , at least that 's that 's even what deep map does . it tells you how far away it is , and shows it to you on map . because we can not differentiate , at the moment , between , , the intention of wanting to go there or the intention of just know wanting to know where it is .
D: people no might not be able to infer that either , right ? like the fact like , could imagine if someone came up to me and asked , "" where 's the city hall ? "" , might say , ar "" are you trying to get there ? "" because how describe , its location , probably depend on whether should give them , , directions now , or say , , whatever , "" it 's half mile away "" like that .
B: it 's granularity factor , because where people ask you , "" where is new york ? "" , you will tell them it 's on the east coast . you won't tell them how to get there , ft , take that bus to the airport and blah - blah . but if it 's the post office , you will tell them how to get there . so th they have done some interesting experiments on that in hamburg as .
C: go go back to the , th
B: so this is "" onto "" is knowledge about buildings , their opening times , and then coupled with time of day , , this should
D: so that context was like , , their presumed purpose context , like business or travel , as as the utterance context , like , "" 'm now standing at this place at this time "" .
C: we ought to as we have all along , we we 've been distu distinguishing between situational context , which is what you have as context , and discourse context , which you have as dh , what the means . so we can work out terminology later . so , they 're they 're quite distinct . you need them both , but they 're quite distinct . and , so what we were talking about doing , as first shot , is not doing any of the linguistics . except to find out what seems to be useful . so , the the reason the belief - net is in blue , is the notion would be this may be bad dis bad idea , but the idea is to take as first goal , see if we could actually build belief - net that would make this three way distinction , in plausible way , these we have all these transcripts and we 're able to , by hand , extract the features to put in the belief - net . saying , "" aha ! here 're the things which , if you get them out of out of the language and discourse , and put them into the belief - net , it would tell you which of these three , intentions is most likely . "" and if to actually do that , build it , , run it run it on the data where you hand - transcribe the parameters . and see how that goes . if that goes , then we can start worrying about how we would extract them . so where would you get this information ? and , expand it to other things like this . but if we can't do that , then we 're in trouble . th if you can't do this task ,
B: we need different , , engine .
C: it if it if it 's the belief - nets , we 'll switch to , logic or some terrible thing , but don't think that 's gonna be the case . that , , if we can get the information , belief - net is perfectly good way of doing the inferential combination of it . the real issue is , do what are the factors involved in determining this ? hold on hold on second . so , know . , is it clear what 's going on here ?
D: missed the beginning , could you back to the slide , the previous one ? so , is it that it 's , these are all factors that , these are the ones that you said that we are going to ignore now ? or that we want to take into account ?
C: take them into account . but but you don't worry about
D: take the linguistic factors too . how to extract these features .
C: how to extract them . so , let 's find out which ones we need first ,
D: and and it 's clear from the data , , like , sorta the correct answer in each case .
C: let 's go back to th let 's go back to the the slide of data .
D: that 's that 's the thing 'm curious ab like do we know from the data wh which
B: not from that data . but , , since we are designing an , compared to this , even bigger data collection effort , , we will definitely take care to put it in there , in some shape , way , form over the other , to see whether we can , then , get empirically validated data . from this , we can sometimes , an and that 's that but that isn't that what we need for belief - net anyhow ? sometimes when people want to just see it , they phrase it more like this ? but it doesn't exclude anybody from phrasing it differently , even if they still but then other factors may come into play that change the outcome of their belief - net . so , , this is exactly what because you can never be . and 'm even the most , , deliberate data collection experiment will never give you data that say , "" , if it 's phrased like that , the intention is this . "" because then , , you
D: the only way you could get that is if you were to give th the subjects task . where you have where your , , current goal is to
B: that 's what we 're doing . but but we will still get the phrasing all over the place .
D: so that 's what you want ? so you will know . the no , that 's fine . it 's just knowing the intention from the experimental subject .
C: from that task , . so , , you all know this , but we are going to actually use this little room and start recording subjects probably within month . so , this is not any lo any of you guys ' worry , except that we may want to push that effort to get information we need . so our job is to figure out how to solve these problems . if it turns out that we need data of certain sort , then the data collection branch can be , , asked to do that . and one of the reasons why we 're recording the meeting for these guys is cuz we want their help when we we start doing , recording of subjects . so , you 're right , though . no , you will not have , and there it is ,
D: and the other concern that has come up before , too , is if it 's if this was collected what situation this data was collected in . was it is it the one that you showed in your talk ?
B: no , no .
D: so was this , like , someone actually mobile , like using device ?
B: no , no not but not with real wizard system . so there were never answers .
D: but , is it the situation of collecting th the data of , like here you could imagine them being walking around the city . as like one situation . and then you have all sorts of other situational context factors that would influence how to interpret , like you said , the scope and things like that . if they 're doing it in "" 'm sitting here with map and asking questions "" , would imagine that the data would be really different . so it 's just
B: but it was never th the goal of that data collection to serve for sat for such purpose . so that 's why the tasks were not differentiated by intentionality , there was there was no label , intention , intention , intention . or task , , . 'm we can produce some if we need it , that will help us along those lines . but , , you gotta leave something for other people to model . so , to finding out what , , situational con what the contextual factors of the situation really are , is an interesting interesting thing . 'm , at the moment , curious and 'm want to approach it from the end where we can start with this toy system that we can play around with , so that we get clearer notion of what input we need for that , what suffices and what doesn't . and then we can start worrying about where to get this input , what do we need , ultimately once we are all experts in changing that parser , , maybe , there 's just couple three things we need to do and then we get more whatever , part of speech and more construction - type - like out of it . it 's pragmatic approach , , at the moment .
E: how exactly does the data collection work ? do they have map , and then you give them scenario of some sort ?
B: imagine you 're the subject . you 're gonna be in here , and and you see , , either th the three - model , or , quicktime animation of standing in square in heidelberg . so you actually see that . first thing is you have to read text about heidelberg . so , just off textbook , , tourist guide , to familiarize , , yourself with that odd - sounding german street names , like fischergasse and . so that 's part one . part two is , you 're told that this huge new , wonderful computer system exists , that can tell you everything you want to know , and it understands you completely . and so you 're gonna pick up that phone , and you get certain amount of tasks that you have to solve . first you have to know find out how to get to that place , maybe with the intention of buying stamps in there . maybe so , the next task is to get to certain place and take picture for your grandchild . the third one is to get information on the history of an object . and then the system breaks down .
D: at the third ?
B: after the third task . or after the fourth . some find @ @ forget that for now . and then , human operator comes on , and exp apologizes that the system has crashed , but , , urges you to continue , ? now with human operator . and so , you have the same tasks again , just with different objects , and you go through it again , and that was it . and one little bit and , the computer you are you are being told the computer system knows exactly where you are , via gps . when the human operator comes on , , that person does not know . so the gps is crashed as . so the person first has to ask you "" where are you ? "" . and so you have to do some tell the person where you are , depending on what you see there . this is bit that don't think we did we discuss that bit ? squeezed that in now . but it 's something , , that would provide some very interesting data for some people know .
D: so , in the display you can , you said that you cou you might have display that shows , like , the
B: additionally , you have map type display .
D: your perspective ? ? and so , as you so as you move through it that 's - they just track it on the for themselves
B: but don't think you really move , that would be an an enormous technical effort , we can show it walks to , . we can have movies of walking , you walking through heidelberg , and ultimately arriving there . maybe we wanna do that .
D: was just trying to figure out how ambitious the system is .
B: the map was intended to you want to go to that place . and it 's there . and you see the label of the name so we get those names , pronunciation , and , and we can change that .
D: so your tasks don't require you to yo you 're told so when your task is , , "" go buy stamps "" like that ? so , do you have to respond ? what are you ste what are you supposed to be telling the system ? what you 're doing now ?
B: we 'll see what people do .
D: so it 's just like , "" let 's figure out what they would say under the circumstances "" .
B: and we will record both sides . we will record the wi - the wizard in both cases it 's gonna be human , in the computer , and in the operator case . and we will re there will be some dialogue , ? so , you first have to do this , and that , see wh what they say . we can ins instruct the , , wizard in how expressive and talkative he should be . maybe the maybe what you 're suggesting is what you 're suggesting that it might be too poor , the data , if we limit it to this ping pong one , task results in question and then there 's an answer and that 's the end of the task ? you wanna have it more steps , ?
D: how much direction is given to the subject about what their interaction th they 're unfamiliar with interacting with the system . all they it 's this great system that could do .
C: but to some extent this is different discussion . so . , we have to have this discussion of th the experiment , and the data collection , and all that sorta and we do have , , student who is candidate for wizard . she 's gonna get in touch with me . it 's student of eve 's . do you do you sh - is sh
D: she started taking the class last year and then didn't , , didn't continue .
C: she 's graduated .
D: is she an undergradua she is graduate , . know her very , very briefly . know she was inter , interested in aspect and like that .
C: so , anyway , she 's looking for some more part time work while she 's waiting actually for graduate school . and she 'll be in touch . so we may have someone , , to do this , and she 's got , some background in all this . and is linguist st so . that 's so , nancy , we 'll have an at some point we 'll have another discussion on exactly wha , how that 's gonna go . and , jane , but also , , liz have offered to help us do this , , data collection and design and . so , when we get to that we 'll have some people doing it that they 're doing .
D: the reason was asking about the the de the details of this thing is that , , it 's one thing to collect data for , , speech recognition or various other tasks that have pretty clear correct answers , but with intention , , as you point out , there 's lot of di other factors and 'm not really , , how the question of how to make it appropriate toy version of that , it 's ju it 's just hard . so , , it 's
E: , actually that was my question . is the intention implicit in the scenario that 's given ? like , do the
D: it is , if they have these tasks that they 're supposed to
E: wasn't to what level of detail the task was .
B: no one is , at the moment .
C: so , we that 's part of what we 'll have to figure out . the the problem that was tr gonna try to focus on today was , let 's suppose by magic you could collect dialogues in which , one way or the other , you were able to , , figure out both the intention , and set the context , and language was used . so let 's suppose that we can get that data . the issue is , can we find way to , , featurize it so that we get some discrete number of features so that , , when we know the values to all those features , or as many as possible , we can come up with the best estimate of which of the , in this case three little intentions , are most likely .
D: what are the three intentions ? is it to go there , to see it , and
B: to come as close as possible to it .
C: th - the terminology we 're using is to
D: it 's @ @ .
C: to view it . to enter it . now those it seems to me those are cl you you have no trouble with those being distinct . "" take picture of it "" you might want to be really rather different place than entering it . and , for an object that 's big , , getting to the nearest part of it , could be quite different than either of those .
D: so now understand the referent of tango mode . didn't get that before .
E: see , would have thought it was more of waltz .
B: to "" waltz "" it ?
D: like , how close are you gonna be ? like , tango 's really close .
F: so , like , the question is how what features can like , do you wanna try to extract from , say , the parse or whatever ? like , the presence of word or the presence of certain , stem , or certain construction or whatever .
C: is there construction , or the object , or , anything else that 's in the si it 's either in the in the the discourse itself or in the context . so if it turns out that , whatever it is , you want to know whether the person 's , tourist or not , ? that becomes feature . now , how you determine that is another issue . but fo for the current problem , it would just be , "" , if you can be that it 's tourist , versus businessman , versus native , "" , , that would give you lot of discriminatory power and then just have little section in your belief - net that said , "" pppt ! "" though sin in the short run , you 'd set them , and see ho how it worked , and then in the longer run , you would figure out how you could derive them . from previous discourse or any anything else you knew .
F: so , how should what 's the , plan ? like , how should we go about figuring out these
C: so , first of all is , do either of you guys , you got favorite belief - net that you 've , , played with ?
F: no , not really .
C: anyway . get one . ? so so one of th one of the things we wanna do is actually , , pick package , doesn't matter which one , presumably one that 's got good interactive abilities , cuz lot of what we 're gonna be we don't need the one that 'll solve massive , , belief - nets quickly . these are not gonna get big in the foreseeable future . but we do want one in which it 's easy to interact with and , , modify . because that 's lot of what it 's gonna be , is , , playing with this . and probably one in which it 's easy to have , , what amounts to transcript files . so that if we have all these cases so we make up cases that have these features , and then you 'd like to be able to say , "" , here 's bunch of cases "" there 're even ones tha that you can do learning ? so you have all their cases and their results and you have algorithms to go through and run around trying to set the probabilities for you . probably that 's not worth it . my is we aren't gonna have enough data that 's good enough to make the these data fitting ones worth it , so would say you guy the first task for you two guys is to , pick package . and you wanna it , the standard things you want it stable , you want it and , as soon as we have one , we can start trying to , , make first cut at what 's going on .
B: an - nuh .
C: but it what like about it is it 's very concrete . ? we we have we the outcomes are gonna be , and we have some data that 's loose , we can use our own intuition , and see how hard it is , and , importantly , what intermediate nodes we think we need . so it if it turns out that just , thinking about the problem , you come up with things you really need to , this is the thing that is , , an intermediate little piece in your belief - net . that 'd be really interesting .
B: and it and it may serve as platform for person , maybe me , or whoever , who is interested in doing some linguistic analysis . we have the for - framenet group here , and we can see what they have found out about those concepts already , that are contained in the data , , to come up with little set of features and , maybe even means of , extracting them . and and that altogether could also be , become paper that 's going to be published somewhere , if we sit down and write it . when you said javabayes belief - net you were talking about ones that run on coffee ? or that are in the program language java ?
C: no , th it turns out that there is , the new end of java libraries . and it turns out one called which is one that fair people around here use fair amount . have no idea whether that 's the obvious advantage of that is that you can then , relatively easily , get all the other java packages for guis or whatever else you might want to do . so that that 's why lot of people doing research use that . but it may not be have no idea whether that 's the best choice an and there 're plenty of people around , students in the department who , , live and breathe bayes - nets .
D: there 's the tool kit that , kevin murphy has developed , which might be useful too .
C: so , , kevin would be good person to start with .
D: and it 's available matlab code .
C: nancy knows him . whether you guys have met kevin yet or not ,
B: but since we all probably are pretty that , , the this th the dialogue history is , producing xml documents . - three - is xml . and the ontology that , the student is constructing for me back in eml is in oil and that 's also in xml . and so that 's where lot of knowledge about bakeries , about hotels , about castles and is gonna come from . so , if it has that io capability and if it 's java package , it will definitely be able we can couple .
C: so , , we 're {nonvocalsound} committed to xml as the , , interchange . but that 's , , not big deal . so , in terms of interchanging in and out of any module we build , it 'll be xml . and if you 're going off to queries to the ontology , , you 'll have to deal with its interface . but that 's that 's fine all of these things have been built with much bigger projects than this in mind . so they have worked very hard . it 's blackboards and multi - wave blackboards and ways of interchanging and registering your that don't even worth us worrying about just yet . if we can get the core of the thing to work , in way that we 're comfortable with , then we ca we can get in and out of it with , , xml , , little descriptors .
B: , like , , the what you said about the getting input from just files about where you where you have the data , have specified the features and . that 's , , easy also to do with , , xml .
C: you could have an , you could make and xml format for that . . feature value xml format is probably as good way as any . so it 's als , it 's also worth , , while you 're poking around , poke around for xml packages that , do things you 'd like .
F: doesn't does smartkom system have such packages ?
B: the the lib - three - library does that .
C: and the question is , you you 'll have to we 'll have to that should be ay we should be able to look at that
B: what what came to my mind is was the notion of an idea that if there are nets that can actually lear try to set their own , , probability factors based on on input which is in file format , if we , , get really wild on this , we may actually want to use some corpora that other people made and , , if they are in mate , then we get documents with discourse annotations , from the discourse act down to the phonetic level . michael has project where , recognizing discourse acts and he does it all in mate , and so they 're actually annotating data and data . so if we if we 's worth it one of these days , not with this first prototype but maybe with second , and we have the possibility of taking input that 's generated elsewhere and learn from that , that 'd be .
C: it 'd be , but do don't wanna count on it . you can't you can't run your project based on the speculation that the data will come ,
B: no , no , , just for
C: and you don't have to actually design the nets .
B: just back door that we should devote
C: so in terms of the , the what the smartkom gives us for - three - packages , it could be that they 're fine , or it could be eeh . you don't , you don't really like it . so we 're not we 're not abs we 're not required to use their packages . we are required at the end to give them in their format , it doesn't control what you do in , internally .
E: what 's the time frame for this ?
B: two , three days ?
C: bu 'd like that this , this week , to ha to to have guys , , , pick the , belief - net package and tell us what it is , and give us pointer so we can play with it . and , then as soon as we have it , we should start trying to populate it for this problem . make first cut at , , what 's going on , and probably the ea easiest way to do that is some on - line way . you can figure out whether you wanna make it web site
B: was actually more joking . with the two or three days . so this was usual jo it will take as long as yo you guys need for that . but , maybe it might be interesting if the two of you can agree on who 's gonna be the speaker next monday , to tell us something about the net you picked , and what it does , and how it does that .
C: , or both of them speak .
B: or you can split it up .
C: we don't care .
B: so that will be the assignment for next week , is to for slides and whatever net you picked and what it can do and how far you 've gotten .
C: 'd like to also , though , , ha have first cut at what the belief - net looks like . even if it 's really crude . so , , here here are
E: so we 're supposed to @ @ about features and whatnot ,
C: and , as said , what 'd like to do is , what would be really great is you bring it in if if we could , , in the meeting , say , , "" here 's the package , here 's the current one we have , "" , "" what other ideas do you have ? "" and then we can think about this idea of making up the data file . , get tentative format for it , let 's say xml , that says , , "" these are the various scenarios we 've experienced . "" we can just add to that and there 'll be this file of them and when you think you 've got better belief - net , you just run it against this , this data file .
F: so we 'll be like , hand , , doing all the probabilities .
C: , unt until we know more .
E: and what 's the relation to this with changing the table so that the system works in english ?
B: so this is whi - while you were doing this , received two lovely emails . the the full nt and the full linux version are there . 've downloaded them both , and started to unpack the linux one the nt one worked fine . and started unta pack the linux one , it told me that 't really unpack it because it contains future date . so this is the time difference between germany . had to until one ' clock this afternoon before was able to unpack it . now , then it will be my job to get this whole thing running both on swede and on this machine . and so that we have it . and then hopefully that hoping that my urgent message will now come through to ralph and tilman that it will send some more documentation along , maybe that 's what will do next monday is show the state and show the system and show that .
C: so the answer , johno , is that these are , at the moment , separate . what one hopes is that when we understand how the analyzer works , we can both worry about converting it to english and worry about how it could ex extract the parameters we need for the belief - net .
E: my question was more about time frame . so we 're gonna do belief - nets this week ,
C: none of this is neither of these projects has got real tight time - line , in the sense that over the next month there 's there 's deliverable . so , it 's opportu in that sense it 's opportunistic . if if , if we don't get any information for these guys for several weeks then we aren't gonna sit around , , wasting time , trying to do the problem or what they go on and do other things .
B: but but the this point is really very , very valid that ultimately we hope that both will merge into harmonious and , , wonderful , , state where we can not only do the bare necessities , ie , changing the table so it does exactly in english what it does in german , but also that we can have the system where we can say , "" , this is what it usually does , and now we add this little thing to it "" , johno 's and bhaskara 's great belief - net , and we plug it in , and then for these certain tasks , and we know that navigational tasks are gonna be core domain of the new system , it all of sudden it does much better . because it can produce better answers , tell the person , as showed you on this map , produce either , red line that goes to the vista point or red line that goes to the tango point or red line that goes to the door , which would be great . so not only can you show that something sensible but ultimately , if you produce system like this , it takes the person where it wants to go . rather than taking him always to the geometric center of building , which is what they do now . and we even had to take out bit . nancy , you missed that part . we had to take out bit of the road work . so that it doesn't take you to the wall every time . so this was actually an actual problem that we encountered , which nobody have has because car navigation systems don't really care . they get you to the beginning of the street , some now do the house number . but even that is problematic . if you go if you wanna drive to the sap in waldorf , 'm the same is true of microsoft , it takes you to the address , whatever , street number blah - blah , you are miles away from the entrance . because the postal address is maybe mailbox somewhere . but the entrance where you actually wanna go is somewhere completely different . so unless you 're mail person you really don't wanna go there .
C: probably not then , cuz you probably can't drop the mail there anyway .
B: probably neither not even that .
E: the powder - tower is made of red limestone .
B: do you wanna see picture ? have to reboot for that though .
D: so , you two , who 'll be working on this , li are you gl will you be doing , are you supposed to just do it by thinking about the situation ? can you use the sample data ?
C: they use the sample data .
D: , ho is there more than is there lot of sample data that is beyond what you what you have there ?
B: there there 's more than showed , but , this is , in part my job to look at that and to see whether there are features in there that can be extracted , and to come up with some features that are not , empirically based on real experiment or on on reality but on your intuition of , "" aha ! this is maybe sign for that , and this is maybe sign for this . ""
F: so , . later this week we should get together , and start thinking about that , hopefully .
C: we can end the meeting and call adam , and then we wanna look at some filthy pictures of heidelberg . we can do that as .
B: they had they used the ammunition they stored the ammunition in that tower . and that 's why , when it was hit by , cannon ball , it exploded .
E: that 's why they call it the powder - tower . first thought it had something to do with the material that it that 's why asked .
D: that 's right , .
","The initial task of the EDU group is to work on inferring intentions through context.
In the navigational paradigm used for the task , these intentions are to ""see"" to ""enter"" or to ""get to the closest point of"" a building.
There will be purpose-designed experiments carried out.
However , the starting point is , through the use of existing data , to determine possible linguistic , discourse or situation features that define intentionality.
These may include the type of building , time of day , particular phrases used or whether the user is a tourist or a native.
Initially , these features will be hand-coded , but the goal is to find ways of extracting them automatically from the XML data.
Consequently , they will be fed into a belief-net -implemented on a software package like JavaBayes- and the conditional probability of each intention calculated.
A prototype system will be put together to test hypotheses regarding both the exact nature of the features and how intentions are derived from them.
Inferring intentions in a navigational context is an appropriate task both in project and real-world terms.
Its goals are clearly defined and contributre to a smarter system.
Although there are some preliminary data to work on , task-specific experiments and recordings will take place.
The XML format is going to be used has not been defined , although the SmartKom data can be used as a foundation.
In the first instance , the group will have to decide on the software package to be used for the creation and manipulation of the belief-nets.
Stability and ease-of-use -in addition to ability to handle XML- of the package are the focus at this stage , instead of the ability to handle large amounts of data.
Experts in Bayes nets within ICSI can be consulted on the matter.
The decision will be presented in the next meeting along with a first schema of the belief-nets themselves.
Possible intermediate nodes can be added to the nets after this.
The hypothesis that a set of features from which intentions can be derived exists has to be assessed , before moving on to how to extract these features from the data automatically.
Curent navigation systems do not provide for the user's particular intentions when asking for directions.
They always compute the shortest path between source and destination.
The SmartKom parser , for example , does not mark up data with features adequate for the inference of these intentions.
Although it is understandable that language , discourse and situation features will play a role in how they are weighed , the exact nature of those features is unclear.
Also hard to evaluate at this stage , is how the assumed features will combine in a belief-net , in order to provide the conditional probabilities of the users' intentions.
Even if these problems are solved , extracting the features from the data may prove to be a bottleneck.
The existing data are appropriate only for preliminary work , as they don't include intention-related information.
On the other hand , the details of the experiments that will have to be designed to get more appropriate data are not clearcut and are yet to be settled.
When asking for directions , a user of a navigational device may wish to either view , enter or simply approach a building.
This was identified as an initial problem to be tackled through ""deep understanding""-type inferences.
There is a set of data to start work on from previous work.
Similarly , the SmartKom data-format and an ontology developed for the tourist domain ( both in XML-standard formats ) can be used as groundwork for defining the features , which indicate the user's intentions.
For the creation and management of the belief-nets necessary for the task , there are readily available packages -such as JavaBayes- and tools that can provide the infrastructure for a prototype system.
"
ami_abstractive_summary,Bmr016.txt,"D: and we already got the crash out of the way . it did crash , so feel much better , earlier .
F: will you get the door , you collected an agenda , ?
D: did collect an agenda . so 'm gonna go first . mwa - ha ! it shouldn't take too long . so we 're out of digits . we 've gone once through the set . so the only thing have to do
F: no there 's only ten .
D: that 's right . so have to go through them and pick out the ones that have problems , and either correct them or have them re - read . so we probably have like four or five more forms to be read , to be once through the set . 've also extracted out about an hour 's worth . we have about two hours worth . extracted out about an hour 's worth which are the digits with for which whose speaker have speaker forms , have filled out speaker forms . not everyone 's filled out speaker form . so extracted one for speakers who have speaker forms and for meetings in which the "" key "" file and the transcript files are parsable . some of the early key files , it looks like , were done by hand , and so they 're not automatically parsable and have to go back and fix those . so what that means is we have about an hour of transcribed digits that we can play with .
F: so you think two you think two hours is the is the total that we have ? and you think we th , didn't quite catch all these different things that are not quite right , but you think we 'll be able to retrieve the other hour , reasonably ?
D: so it 's just question of little hand - editing of some files and then waiting for more people to turn in their speaker forms . have this web - based speaker form , and sent mail to everyone who hadn't filled out speaker form , and they 're slowly trickling in .
F: so the relevance of the speaker form here ,
D: it 's for labeling the extracted audio files . by speaker id and microphone type .
F: wasn't like whether they were giving us permission to use their digits .
D: no , spoke with jane about that and we decided that it 's probably not an issue that we edit out any of the errors anyway . right ? so the there are no errors in the digits , you 'll always read the string correctly . so 't imagine why anyone would care . so the other topic with digits is , liz would like to elicit different prosodics , and so we tried last week with them written out in english . and it just didn't work because no one grouped them together . so it just sounded like many more lines instead of anything else . so in conversations with liz and jane we decided that if you wrote them out as numbers instead of words it would elicit more phone number , social security number - like readings . the problem with that is it becomes numbers instead of digits . when look at this , that first line is "" sixty one , sixty two , eighteen , eighty six , ten . "" and so the question is does anyone care ? 've already spoken with liz and she feels that , correct me if 'm wrong , that for her , connected numbers is fine , as opposed to connected digits . two hours is probably fine for test set , but it may be little short if we actually wanna do training and adaptation and all that other .
F: you want different prosodics , so if you always had the same groupings you wouldn't like that ? is that correct ?
G: we actually figured out way to the groupings are randomly generated .
F: no but , was asking if that was something you really cared about because if it wasn't , it seems to me if you made it really specifically telephone groupings that maybe people wouldn't , , go and do numbers so much .
G: they may still do it ,
F: maybe some , but probably not so much .
B: what about putting hyphen between the numbers in the group ?
F: so if you if you have
D: six dash one , you mean ?
F: if you go six dash two nine three one .
G: it might help , would like to get away from having only one specific grouping .
F: that 's what was asking , .
G: so if that 's your question , but it seems to me that , at least for us , we can learn to read them as digits if that 's what people want . don't think that 'd be that hard to read them as single digits . and it seems like that might be better for you guys since then you 'll have just more digit data , and that 's always good thing . it 's little bit better for me too because the digits are easier to recognize . they 're better trained than the numbers .
D: so we could just , , put in the instructions "" read them as digits "" .
G: right . right , read them as single digits , so sixty - one is read as six one , and if people make mistake we
D: how about "" "" versus "" zero "" ?
F: the other thing is we could just bag it because it 's it 's it 's - 'm not worrying about it because we do have digits training data that we have from from ogi . digits numbers training that we have from ogi , we 've done lots and lots of studies with that .
G: but it 's to get it in this room with the acous
F: no , no , what 'm saying is that
D: just let them read it how they read it .
F: to some extent maybe we could just read them have them read how they read it and it just means that we have to expand our vocabulary out to that we already have .
G: that 's fine with me as long as it 's just that didn't want to the people who would have been collecting digits the other way to not have the digits .
F: we can go back to the other thing later . we we 've we can do this for awhile and then go back to digits for awhile , do yo , do you want do you want this do you need training data or adaptation data out of this ? how much of this do you need ?
G: it 's actually unclear right now . thought we 're if we 're collec collecting digits , and adam had said we were running out of the ti forms , it 'd be to have them in groups , and probably , all else being equal , it 'd be better for me to just have single digits since it 's , , recognizer 's gonna do better on those anyway , and it 's more predictable . so we can know from the transcript what the person said and the transcriber , in general . but if they make mistakes , it 's no big deal if the people say hundred instead of "" one oo "" . and also maybe we can just let them choose "" zero "" versus "" "" as they as they like because even the same person sometimes says "" "" and sometimes says "" zero "" in different context , and that 's interesting . so don't have specific need cuz if did 'd probably try to collect it , , without bothering this group , but if we can try it
D: so just add to the instructions to read it as digits not as connected numbers .
G: right , and you can give an example like , , "" six sixty - one would be read as six one "" .
E: and actually it 's no more artificial than what we 've been doing with words .
G: and people will get it .
E: 'm people can adapt to this , read it single .
G: right , right .
E: the spaces already bias it toward being separated .
G: it 's just easier to read .
E: and 'm gonna find this easier than words .
D: cognitively it 's much easier .
G: also had hard time with the words , but then we went back and forth on that . so let 's give that try
D: and is the spacing alright or do you think there should be more space between digits and groups ? or is that alright ?
G: what do other people think cuz you guys are reading them .
E: that it 's fine . it to me it looks like you 've got the func the idea of grouping and you have the grou the idea of separation and , , it 's just matter of the instructions , that 's all .
D: and there are about ten different gouping patterns
F: let 's try it .
G: let 's give it try .
D: isn't that right , liz ? that we did .
G: righ - right , and you just they 're randomly {nonvocalsound} generated and randomly assigned to digits .
F: was just gonna say , so we have in the vicinity of forty hours of recordings now . and you 're saying two hours , , is digits , so that 's roughly the ratio then , something like twenty to one . which makes sense . so if we did another forty hours of recordings then we could get another couple hours of this . like you say , couple hours for for test set 's . it 'd be to get , , more later because we 'll we might use this up , , in some sense ,
E: also would like to argue for that cuz it seems to me that , , there 's real strength in having the same test replicated in whole bunch of times and adding to that basic test bank . cuz then you have , , more and more , chances to get away from random errors . and , , the other thing too is that right now we have stratified sample with reference to dialect groups , and it might be there might be an argument to be made for having for replicating all of the digits that we 've done , which were done by non - native speakers so that we have core that replicates the original data set , which is american speakers , and then we have these stratified additional language groups overlapping certain aspects of the database .
D: that trying to duplicate , spending too much effort trying to duplicate the existing ti - digits probably isn't too worthwhile because the recording situation is so different . it 's gonna be very hard to be comparable .
E: except that if you have the stimuli comparable , then it says something about the contribution of setting
F: no it 's it 's not the same . but the other differences are so major .
D: read versus not .
F: they 're such major sources of variance that it 's it 's
E: what 's an example of of some of the other differences ? any other difference ?
F: individual human glottis is going to be different for each one , it 's just there 's so many things .
D: and not just that ,
F: it 's it and enunciation .
D: the the corpus itself . we 're collecting it in read digit in particular list , and 'm that they 're doing more specific . if remember correctly it was like postman reading zipcodes and things like that .
F: ti - digits was ? it was read .
D: was it read ?
F: the reading zipcode you 're thinking of would be ogi . no ti - digits was read in th in read in the studio believe .
D: haven't ever listened to ti - digits . so don't really know how it compares . but but regardless it 's gonna it 's hard to compare cross - corpus .
F: it - it 's different people is the core thing . and they 're different circumstances with different recording environment and , so it 's it 's really pretty different . but the idea of using set thing was just to give you some framework , so that even though you couldn't do exact comparisons , it wouldn't be valid scientifically at least it 'd give you some frame of reference .
B: hey liz , what what do the groupings represent ? you said there 's like ten different groupings ?
G: right , just groupings in terms of number of groups in line , and number of digits in group , and the pattern of groupings .
B: are the patterns like are they based on anything or
G: roughly looked at what kinds of digit strings are out there , and they 're usually grouped into either two , three , or four , four digits at time . and they can have , actually , things are getting longer and longer . in the old days you probably only had three sequences , and telephone numbers were less , and . so , there 's between , if you look at it , there are between like three and five groups , and each one has between two and four groupings purposely didn't want them to look like they were in any pattern .
D: and which group appears is picked randomly , and what the numbers are picked randomly . so unlike the previous one , which simply replicated ti - digits , this is generated randomly .
B: mmm , , .
G: but it 'd be great to be able to compare digits , whether it 's these digits or ti - digits , to speakers , , and compare that to their spontaneous speech , and then we do need fair amount of digit data because you might be wearing different microphone and , so it 's it 's to have the digits , replicated many times . especially for speakers that don't talk lot . no , 'm serious ,
D: all we have for some people is digits .
G: so we have problem with acoustic adaptation , and we 're not using the digit data now ,
D: you 're not .
G: not for adaptation , nope . we 're not we were running adaptation only on the data that we ran recognition on and 'd as soon as someone started to read transcript number , that 's read speech and "" , we 're gonna do better on that , that 's not fair to use "" .
D: that 's true , .
G: but , it might be fair to use the data for adaptation , so those speakers who are very quiet , shy
D: that would be interesting to see whether that helps . do you think that would help adapting on have real problem with that .
G: it sh it 's the same micropho see we have that in the in the same meeting ,
D: same same acoustics ,
G: and so you don't get right , and so still like the idea of having some digit data .
F: for the for the acoustic research , for the signal - processing , farfield , see it as as the place that we start . but , th , it 'd be to have twenty hours of digits data , but the truth is 'm hoping that we through the that you guys have been doing as you continue that , we get , , the best we can do on the spontaneous , nearfield , and then , we do lot of the testing of the algorithms on the digits for the farfield , and at some point when we feel it 's mature and we understand what 's going on with it then we have to move on to the spontaneous data with the farfield .
G: the only thing that we don't have , know this sounds weird , and maybe it 's completely stupid , but we don't have any overlapping digits .
D: we talked about that couple times .
G: an - yea 's weird ,
D: the the problem see with trying to do overlapping digits is the cognitive load .
G: alright everybody 's laughing .
D: no it 's it 's not stupid , it 's just , try to do it .
G: 'm just talkin for the that like dan ellis is gonna try ,
D: here , let 's try it .
G: cross - talk cancellation .
D: you read the last line , 'll read the first line .
F: let 's try it .
G: it these are all the same forms .
F: sixty - one .
D: so so you read the last line , 'll read the first line .
G: so you plu you plug your ears .
D: if you plug you 're ears you could do it , but then you don't get the same effects .
G: what is actually no not the overlaps that are - governed linguistically , but the actual fact that there is speech coming from two people and the beam - forming stuf all the acoustic that like dan ellis and company want to do . digits are and behaved ,
D: we could try .
G: anyway , it 's just thought .
D: we could try doing some .
G: it it would go faster . it would take one around amount of ti
B: it 's the - make of digit reading .
D: let 's try it .
G: that 's right . mea 'm was serious , but really , , 'm don't feel strongly enough that it 's good idea ,
D: you do the last line , 'll do the first line . that 's not bad .
F: no , do it .
B: couldn't understand single thing you guys were saying .
G: and that prosody was great , .
E: it was numbers , but 'm not .
G: it it sounded like duet , .
F: alright , let 's try three at once you pick one in the middle .
A: the aurora theater .
G: 'm mean it 's doable ,
D: they 're gonna hate us .
G: so , we could have round like where you do two at time , and then the next person picks up when the first guy 's done , . what do you call it ?
F: row , row your boat .
B: it 's gonna require some coordination .
G: then it would go like twice as fast , or third as fast .
E: you have to have similar pace .
G: anyway , it 's just thought . 'm actually serious if it would help people do that kind but the people who wanna work on it we should talk to them .
F: don't think we 're gonna collect vast amounts of data that way , but having little bit might at least be fun for somebody like dan to play around with ,
D: maybe if we wanted to do that we would do it as separate session , rather than doing it during real meeting and , do two people at time then three people at time and things like that .
G: can try it out .
D: see see what dan thinks .
G: if we have nothing if we have no agenda we could do it some week .
F: spend the whole time reading digits with different qu quantities .
D: this was gonna be fast .
E: can have an another question about this ? so , , there are these digits , which are detached digits , but there are other words that contain the same general phon phoneme sequences . like "" wonderful "" has "" one "" in it and victor borge had had piece on this where he inflated the digits . wonder if there 's , , an if there would be value in having digits that are in essence embedded in real words to compare in terms of like the articulation of "" one "" in "" wonderful "" versus "" one "" as digit being read .
F: that 's "" two "" bad .
G: 'm all "" four "" it .
E: there you go .
D: not after "" eight "" though .
F: they don't all work as , do they ? what does nine work in ?
C: you scream it .
D: you have to be german ,
A: that 's german , .
B: it 's great for the germans .
F: that 's right !
C: it only sounds good when you scream it , though .
F: everybody 's little punchy here today .
E: , wanted to offer that as possible task because , , if we were to each read his embedded numbers words in sent in sentences cuz it 's like an entire sketch he does and wouldn't take the inflated version . so he talks about the woman being "" two - derful "" , and but , , if it were to be deflated , just the normal word , it would be like little story that we could read . if it would be useful for comparison , but it 's embedded numbers .
D: like that we 'd be better off doing like timit .
F: the question is what the research is , so , presume that the reason that you wanted to have these digits this way is because you wanted to actually do some research looking at the prosodic form here . so if somebody wanted to do that , if they wanted to look at the the difference of the phones in the digits in the context of word versus the digits non - digit word versus in digit word , that would be good thing to do , but someone would have to express interest in that . if you were interested in it then we could do it , .
D: are we done with digits ? we have asr results from liz , transcript status from jane , and disk space and storage formats from don . does do we have any prefer preference on which way we wanna we wanna go ?
G: was actually gonna skip the asr results part , in favor of getting the transcription talked about since that 's more important to moving forward , but morgan has this paper copy and if people have questions , it 's pretty preliminary in terms of asr results because we didn't do anything fancy , but just having the results there , and pointing out some main conclusions like it 's not the speaking style that differs , it 's the fact that there 's overlap that causes recognition errors . and then , the fact that it 's almost all insertion errors , which you would expect but you might also think that in the overlapped regions you would get substitutions and , leads us to believe that doing better segmentation , like your channel - based segmentation , or some , echo cancellation to get back down to the individual speaker utterances would be probably all that we would need to be able to do good recognition on the on the close - talking mikes .
D: why don't you , if you have hard copy , why don't you email it to the list .
G: so , that 's about the summary but this is morgan has this paper .
D: it 's in the paper .
F: so it 's the same thing ? it 's the same thing mailed to every everybody that where it was ,
G: it 's that paper .
D: then , it 's already been mailed .
G: so , we , , did lot of work on that let 's see , th the other neat thing is it shows for that the lapel , within speaker is bad . and it 's bad because it picks up the overlapping speech .
A: so , your asr results were run on the channels synchronized ,
G: yes , cuz that 's all that had been transcribed at the time , but as we wanted to here more about the transcription . if we can get the channel asynchronous or the that would be very interesting for us
F: that 's that 's why only used the part from use which we had about the alt over all the channels rather mixed signal .
B: so if there was segment of speech this long and and someone said "" , "" the whole thing was passed to the recognizer ?
D: and someone said "" "" in the front in the middle .
A: there were several speakers in it ,
G: that 's right . pulled out couple classic examples in case you wanna use them in your talk of
B: that 's why there 's so many insertion errors ?
G: chuck on the lapel , so chuck wore the lapel three out of four times .
D: noticed that chuck was wearing the lapel lot .
B: early on , .
G: and wore the lapel once , and for me the lapel was .
D: probably how you wear it wore it would .
G: for you it was or who was next to me like that .
C: where you were sitting probably affected it .
G: right , but when chuck wore the lapel and morgan was talking there 're couple really long utterances where chuck is saying few things inside , and it 's picking up all of morgan 's words pretty and so the rec , there 're error rates insertions aren't bounded , so with one - word utterance and ten insertions you got huge error rate . and that 's that 's where the problems come in . so this is what we expected , but it 's to be able to show it . and also wanted to mention briefly that , , andreas and called up dan ellis who 's still stuck in switzerland , and we were gonna ask him if there 're , what 's out there in terms of echo cancellation and things like that . not that we were gonna do it , but we wanted to would need to be done .
D: and he said , "" lots lots . ""
G: and he we 've given him the data we have so far , so these sychronous cases where there are overlap . and he 's gonna look into trying to run some things that are out there and see how it can do because right now we 're not able to actually report on recognition in real paper , like eurospeech paper , because it would look premature .
B: so the idea is that you would take this big hunk where somebody 's only speaking small amount in it , and then try to figure out where they 're speaking based on the other peopl
G: right . or who 's at any point in time who 's the foreground speaker , who 's the background speaker .
B: we were just gonna move the boundaries in .
D: that 's with the hand .
G: so there 's like
D: but how would you do that automatically ?
A: 've actually done some experiments with cross - correlation and it seems to work pretty to get rid of those overlaps ,
D: that 's the thing that you would do .
G: exactly , so it 's it 's
B: so why do you want to do echo cancellation ?
G: it would be techniques used from adaptive echo cancellation which enough about to talk about .
F: it just it just to to remove cross - talk .
G: right , , and that would be similar to what you 're also trying to do , but using , , more than energy what exactly would go into it .
B: so it would be
G: so the idea is to run this on the whole meeting . and get the locations , which gives you also the time boundaries of the individual speak
B: so do what he 's already what he 's trying to do .
G: right . except that there are many techniques for the kinds of cues , , that you can use to do that .
A: in another way ,
F: dave is , , also gonna be doin usin playing around with echo cancellation for the nearfield farfield , so we 'll be
G: this is is he here too ? may also be working so it would just be ver that 's really the next step because we can't do too much , , on term in terms of recognition results knowing that this is big problem until we can do that processing . and so , once we have some of yours ,
A: 'm working on it .
G: and @ @ we 'll move on .
B: this also ties into one of the things that jane is gonna talk about too .
D: also wanted to say have done all this chopping up of digits ,
E: - . - .
D: so have some naming conventions that we should try to agree on . so let 's do that off - line , we don't need to do it during the meeting . and and have scripts that will extract it out from "" key "" files and do all the naming automatically , so you don't have to do it by hand .
C: you 've compiled the list of , , speaker names ?
G: so that 's it for the
D: names in the names to ds , and it does all sorts of matches because the way people filled out names is different on every single file so it does very fuzzy match .
G: so at this point we can finalize the naming , and , and we 're gonna re rewrite out these waveforms that we did because as you notice in the paper your "" and "" - two "" in another meeting and it 's we just need to standardize the
C: that was my fault .
G: no it 's it 's
F: no , didn't notice that actually .
G: that 's why those comments are are in there .
C: then disregard it then .
D: so th now have script that you can just say look up morgan , and it will give you his id .
G: great , great .
D: don , you had disk space and storage formats . is that something we need to talk about at the meeting , or should you just talk with chuck at some other time ?
C: had some general questions just about the compression algorithms of shortening waveforms and exactly who to ask . that maybe you would be the person to talk to . so , is it lossless compression when you compress , it just uses entropy coding ? so , , my question would be is got this new eighteen gig drive installed .
D: and assume half of it is scratch and half of it is ?
C: 'm not exactly how they partitioned it .
F: that 's typical , .
C: what 's typical here , it 's local though ,
D: that doesn't matter . you can access it from anywhere in icsi .
C: how do you do that ?
F: this is an eighteen gig drive , or is it thirty six gig drive with eighteen
G: eigh - eighteen . it was spare that dave had around
D: slash slash machine name , slash in all likelihood .
C: alright , did know that .
D: so the only question is how much of it the distinction between scratch and non - scratch is whether it 's backed up or not . so what you wanna do is use the scratch for that you can regenerate . the that isn't backed up is not big deal because disks don't crash very frequently , as long as you can regenerate it .
C: all of this can be regenerated , it 's just question
D: then put it all on scratch because we 're icsi is bottlenecked by backup .
E: - , very good point .
D: so we wanna put
G: 'd leave all the all the transcript shouldn't should be backed up , but all the waveform sound files should not be backed up , the ones that you write out .
C: so , , th the other question was then , should we shorten them , downsample them , or keep them in their original form ?
D: it just depends on your tools . because it 's not backed up and it 's just on scratch , if your sc tools can't take shortened format , would leave them expanded , so you don't have to unshorten them every single time you wanna do anything .
G: we can downsample them ,
C: do you think that 'd be ? to downsample them ?
G: we get the same performance . the the front - end on the sri recognizer just downsamples them on the fly ,
C: the only argument against downsampling is to preserve just the original files in case we want to experiment with different filtering techniques .
F: over all our data , we want to not downsample .
G: you 'd you wanna not . so we 're what we 're doing is we 're writing out this is just question . we 're writing out these individual segments , that wherever there 's time boundary from thilo , or jane 's transcribers , , we chop it there . and the reason is so that we can feed it to the recognizer , and throw out ones that we 're not using and . and those are the ones that we 're storing .
D: as said , since that 's it 's regeneratable , what would do is take downsample it , and compress it however you 're the sri recognizer wants to take it in .
G: so we can't shorten them , but we can downsample them .
F: as , as long as there is form that we can come from again , that is not downsampled , then ,
C: those are gonna be kept .
G: that that 's why we need more disk space cuz we 're duplicating the originals ,
F: then it 's fine . but for fu future research we 'll be doing it with different microphone positions and so on
G: no . we always have the original long ones .
F: we would like to
B: so the sri front - end won't take an large audio file name and then list of segments to chop out from that large audio file ? they actually have to be chopped out already ?
G: it 's better if they 're chopped out , and it will be we could probably write something to do that , but it 's actually convenient to have them chopped out cuz you can run them , , in different orders . you you can actually move them around .
D: and that 's the whole point about the naming conventions
G: you can get rid of
D: is that you could run all the english speaking ,
G: it 's lot faster .
D: all the native speakers , and all the non - native speakers ,
G: right . you can grab everything with the word "" the "" in it ,
D: and all the men , and all the women .
G: that 's lot quicker than actually trying to access the wavefile each time , find the time boundaries and so in principle , , you could do that ,
B: don't don't think that 's really right .
D: "" that 's just not right , man . ""
G: these are long these are long
D: so so , what if you wanted to run all the native speakers .
G: this is an hour of speech .
D: right , so if you did it that way you would have to generate program that looks in the database somewhere , extracts out the language , finds the time - marks for that particular one , do it that way . the way they 're doing it , you have that already extracted and it 's embedded in the file name . and so , , you just say
G: we - that 's so that 's part of it
D: so you just say "" asterisk asterisk dot wave "" , and you get what you want .
G: and the other part is just that once they 're written out it is lot faster to process them .
D: rather than doing seeks through the file .
G: otherwise , you 're just accessing
D: this is all just temporary access , so don't it 's all just it 's fine . fine to do it however is convenient .
F: it just depends how big the file is . if the file sits in memory you can do extremely fast seeks
G: the other thing is that , believe it or not , we have some
D: and they don't .
G: so we 're also looking at these in waves like for the alignments and . you can't load an hour of speech into waves . you need to have these small files , and , even for the transcriber program
D: yes you can .
B: you can give waves start and an end time .
G: if you try to load really long waveform into waves , you 'll be waiting there for
B: no , 'm not suggesting you load long wave file , 'm just saying you give it start and an end time . and it 'll just go and pull out that section .
D: the transcribers didn't have any problem with that did they jane ?
E: what 's th in what respect ?
A: no , with the transcriber tool , it 's no problem .
D: they loaded they loaded the long files into waves .
G: it takes very long ti
A: just to load transcription takes long time ,
G: it takes very long time .
A: but not for the wavefile . the wavefile is there immediately .
D: are you talking about transcriber or waves ?
A: 'm tr talking about transcriber .
G: actually , you 're talking about transcriber , right ?
D: because because we used waves to do the digits .
E: it was also true of the digits task which was waves .
D: and they were loading the full mixed files then , and it didn't seem to be any problem .
G: we have problem with that , time - wise on it - it 's lot slower to load in long file ,
D: seemed really fast .
G: and also to check the file , so if you have transcript , ,
D: regardless , it 's
G: overall you could get everything to work by accessing the same waveform and trying to find two , the begin and end times . but it 's more efficient , if we have the storage space , to have the small ones .
D: and , it 's no problem , right ? because it 's not backed up .
G: it 's it 's just
D: if we don't have spare disk sitting around we go out and we buy ourselves an eighty gigabyte drive and make it all scratch space . it 's not big deal .
E: you 're right about the backup being bottleneck . it 's good to think towards scratch .
G: so these wouldn't be backed up , the
D: so remind me afterward and 'll and we 'll look at your disk and see where to put .
C: could just do du on it right ? and just see which how much is on each
D: and you wanna use , either xa or scratch . anything starting with is scratch .
E: with two digits .
D: two digits , right , xa , xb , xc .
F: so , @ @ .
E: so got little print - out here . so three on this side , three on this side . and stapled them . alright so , first of all , , there was an interest in the transcribe transcription , , checking procedures and tell you first , , to go through the steps although you 've probably seen them . as you might imagine , when you 're dealing with , , really fair number of words , and , @ @ natural speech which means self - repairs and all these other factors , that there 're lots of things to be , , standardized and streamlined and checked on . and , , so , did bunch of checks , and the first thing did was spell - check . and at that point discovered certain things like , , "" accommodate "" with one "" "" , and then , in addition to that , did an exhaustive listing of the forms in the data file , which included detecting things like faulty punctuation and things
B: 'm 'm to interrupt you could back up little bit so you 're doing these so the whole process is that the transcribers get the conversation and they do their pass over it . and then when they 're finished with it , it comes to you ,
E: that 's right .
B: and you begin these sanit these quality checks .
E: do these checks . and so , , do an exhaustive listing of the forms actually , will go through this in order , so if we could maybe and stick keep that for second cuz we 're not ready for that .
D: so on the fifth page , seven down
E: , . exactly ! exactly ! alright so , spelling check first then an exhaustive listing of the , all the forms in the data with the punctuation attached and at that point pick up things like , , , word followed by two commas . and th and then another check involves , , being that every utterance has an identifiable speaker . and if not , then that gets checked . then there 's this issue of glossing so - called "" spoken - forms "" . mo for the most part , we 're keeping it standard wo word level transcription . and that 's done with the assumption that pronunciation variants can be handled . so for things like "" and "" , the fact that someone doesn't say the "" "" , that 's not important enough to capture in the transcription because good pronunciation , , , model would be able to handle that . however , things like "" cuz "" where you 're lacking an entire very prominent first syllable , and furthermore , it 's form that 's specific to spoken language , those are reasons for those reasons kept that separate , and used the convention of using "" cuz "" for that form , however , glossing it so that it 's possible with the script to plug in the full orthographic form for that one , and couple of others , so "" wanna "" is another one , "" going "" , "" gonna "" is another one , with just the assumption , again , that this th these are things which it 's not really fair to consider expect that pronunciation model , to handle . and chuck , you in you indicated that "" cuz "" is one of those that 's handled in different way also , didn't you ? so so it might not have been it might not have been you , but someone told me that "" cuz "" is treated differently in , , in this context because of that reason that , , it 's little bit farther than pronunciation variant . so after that , let 's see ,
B: so that was part of the spell - check , or was that was after the spell - check ?
E: so when get the exhau so the spell - check picks up those words because they 're not in the dictionary . so it gets "" cuz "" and "" wanna "" and that
D: and then you gloss them ?
E: have sed , so do sed script saying whenever you see "" gonna "" , "" convert it to gonna "" , , "" gloss equals quote going - to quote "" , and with all these things being in curly brackets so they 're always distinctive . also wrote script which will , , retrieve anything in curly brackets , or anything which 've classified as an acronym , and pronounced acronym . and the way tag ac pronounced acronyms is that have underscores between the components . so if it 's "" acl "" then it 's "" "" underscore "" "" underscore "" "" .
D: and so your list here , are these ones that actually occurred in the meetings ?
E: yes . - , . so now . and
D: we are acronym - loaded .
G: can ask question about the glossing , before we go on ? so , for word like "" because "" is it that it 's always predictably "" because "" ? is "" cuz "" always meaning "" because "" ?
E: yes , but not the reverse . so sometimes people will say "" because "" in the meeting , and if they actually said "" because "" , then it 's written as "" because "" with no "" cuz "" doesn't even figure into the equation .
F: but but in our meetings people don't say "" hey cuz how you doing ? ""
G: right . right .
D: except right there .
G: so , so , from the point of view of
E: that 's good point .
G: the the only problem is that with for the recognition we map it to "" because "" , and so if we know that "" cuz ""
E: that 's fine .
D: but they have the gloss .
E: don has script .
G: but , we don't
D: you have the gloss form so you always replace it . if that 's how what you wanna do .
E: and don knows this , and he 's bee he has glo he has script that
C: replace the "" cuz "" with "" because "" if it 's glossed .
G: but , if it 's but then there are other glosses that we don't replace , right ?
E: yes . and that 's why there 're different tags on the glosses ,
G: so , then it 's fine .
E: on the different on the different types of comments , which we 'll which we 'll see in just second . so the pronounceable acronyms get underscores , the things in curly brackets are viewed as comments . there 're comments of four types . so this is good time to introduce that . the four types . and maybe we 'll expand that but the but the comments are , , of four types mainly right now . one of them is , , the gloss type we just mentioned . another type is ,
D: so are we done with acronyms ? cuz had question on what this meant .
E: 'm still doing the overview . haven't actually gotten here yet . so , gloss is things like replacing the full form with the , , more abbreviated one to the left . then you have if it 's , there 're couple different types of elements that can happen that aren't really properly words , and wo some of them are laughs and breathes , so we have that 's prepended with tag of "" voc "" . and the non - vocal ones are like door - slams and tappings , and that 's prepended with no non - vocalization .
B: so then it just an ending curly brace there , or is there something else in there .
E: let 's just take one example . and then the no non - vocalization would be something like door - slam . they always end . so it 's like they 're paired curly brackets . and then the third type right now , , is things that fall in the category of comments about what 's happening . so it could be something like , , "" referring to so - and - so "" , "" talking about such - and - such "" , , "" looking at so - and - so "" .
B: on the middle so , in the first case that gloss applies to the word to the left . but in the middle two th - it 's not applying to anything , right ?
E: and this gets substituted here .
D: they 're impulsive .
E: no , they 're events .
D: the "" qual "" can be the "" qual "" is applying to the left .
E: they 're actually they have the status of events .
B: right , meant the middle two ones ,
E: and actually , , it is true that , with respect to "" laugh "" , there 's another one which is "" while laughing "" ,
D: "" while laughing "" .
E: and that is , , an argument could be made for this tur turning that into qualitative statement because it 's talking about the thing that preceded it , but at present we haven't been , , , coding the exact scope of laughing , , and so to have "" while laughing "" , that it happened somewhere in there which could mean that it occurred separately and following , or , , including some of the utterances to the left . haven't been awfully precise about that , but have here , now we 're about to get to the to this now , so you 'll see how often these different things occur . but , , , the very front page deals with this , , final pa , aspect of the standardization which has to do with the spoken forms like "" - "" and "" ha "" and "" - "" and all these different types . and , , , someone pointed out to me , this might have been chuck , about , about how recognizer , if it 's looking for "" - "" with three 's , and it 's transcribed with two 's , that it might , that it might increase the error rate which is which would really be shame because , personally would not be able to make claim that those are dr dramatically different items . so , right now 've standardized across all the existing data with these spoken forms .
D: so it 's small list .
E: all existing data except thirty minutes which got found today . so , 'm gonna 'm gonna check
D: that that 's known as "" found data "" .
E: acsu - actually . got it was stored in place didn't expect ,
C: it 's like the zapruder film .
E: we , , sh yea reconstructed how that happened .
F: wanna work with lost data .
D: it 's much easier .
E: and this is this 'll be great . so 'll 'll be able to get through that tonight , and then everyth , actually later today probably . and so then we 'll have everything following these conventions . but you notice it 's really rather small set of these kinds of things . and made it so that these are , , with couple exceptions but , things that you wouldn't find in the spell - checker so that they 'll show up really easily .
C: jane , can ask you question ? what 's that very last one correspond to ? don't even know how to pronounce that .
E: . now that only occurs once , and 'm thinking of changing that .
C: is that like someone 's like burning or some such thing ?
E: so - haven't listened to it
C: like their hair 's on fire ?
E: haven't heard it actually . need to listen to that one .
A: it 's the castle of !
G: actually we gave this to our pronunciation person ,
C: it looks like that .
G: she 's like , "" what that is either "" .
E: did she hear the th did she actually hear it ? cuz haven't heard it .
G: no , we just gave her list of words that , , weren't in our dictionary and so it picked up like this , and she just didn't listen so she didn't know . we just we 're waiting on that just to do the alignments .
E: 'm curious to se hear what it is , but didn't know wanna change it to something else until knew .
G: maybe it 's "" argh "" ?
C: but that 's not really like no one really says "" argh , "" ,
G: right , no one say
F: you just did .
B: except for now !
C: there 's another there 's another word error .
E: that 's right .
D: yes , that 's right . we 're gonna have big problem when we talk about that .
C: cha - ching .
B: we 're gonna never recognize this meeting .
D: in monty python you say "" argh "" lot . or if you 're programmer . you say arg - and arg - all the time .
E: that 's right . that 's right .
C: that 's true .
G: but it has different prosody .
F: arg arg - max , arg - min ,
G: so , jane , what 's the
D: maybe he died while dictating .
G: have one question about the "" "" versus like the "" "" and the "" "" .
E: that 's partly nonnative - native thing , but have found "" "" in native speakers too . but it 's mostly non - native
B: that 's "" "" versus "" "" ?
G: "" , "" right , cuz there were some speakers that did definite "" 's "" but right now we
B: they were the canadians , right ?
F: canadians , , .
E: that 's right .
G: so , it 's actually probably good for us to know the difference between the real "" "" and the one that 's just like "" "" or transcribed "" aaa "" cuz in like in switchboard , you would see all of these forms , but they all were like "" "" .
D: you mean just the single letter "" "" as in the particle ?
G: no , no , like the "" "" , or the "" "" , "" "" , "" "" were all the same . and then , we have this additional non - native version of , like "" eeh "" .
C: all the "" "" 's 've seen have been like that . they 've been like "" "" like that have bee has been transcribed to "" "" . and sometimes it 's stronger ,
E: - , that 's right .
C: like "" eeh "" which is like closer to "" "" .
D: 'm just these poor transcribers , they 're gonna hate this meeting .
C: we should go off - line .
E: we 're not doing we 're not doing length .
F: quick thilo , do do filled pause for us .
E: that 's right .
G: but you 're native german speaker so it 's not not issue for no , only if you don't have lax vowels , .
E: this makes sense .
G: so it 's like japanese and spanish
D: didn't get that ,
E: that makes sense . and so , , , th have there are some , , americans who are using this "" "" too , and haven't listened to it systematically , maybe with some of them , , they 'd end up being "" 's "" but , , my spot - checking has made me think that we do have "" "" in also , , american data represented here . any case , that 's the this is reduced down from really quite long much longer list ,
G: this is great .
D: it 's good ,
G: this is really helpful .
E: functionally pretty , , also it was fascinating , was listening to some of these , , two nights ago , and it 's just hilarious to liste to do search for the "" - 's "" . and you get "" - "" and diff everybody 's doing it .
D: and just listen to them ?
E: just wanted to say would be fun to make montage of it because there 's "" - .
D: just extract them all .
E: it 's really it 's really fun to listen to .
B: morgan can make song out of it .
E: all these different vocal tracts , , but it 's it 's the same item . it 's very interesting . and the ones in parentheses are ones which the transcriber wasn't of , and haven't been able to listen to to clarify , but you can see that the parenthesis convention makes it very easy to find them
D: how about question mark ?
E: cuz it 's the only place where they 're used .
A: the question marks , . what are those ?
E: question mark is punctuation . so it they said that @ @ "" dc ? ""
D: so they so it 's "" plp ? ""
E: and do have stress marker here . sometimes the contrastive stress is showing up ,
F: 'm , got lost here . what - what 's the difference between the parenthesized acronym and the non - parenthesized ?
E: the parenthesized is something that the transcriber thought was ann , but wasn't entirely . so 'd need to go back or someone needs to go back , and say , , yes or no , and then get rid of the parentheses . but the parentheses are used only in that context in the transcripts , of noti noticing that there 's something uncertain .
G: cuz they have no idea ,
D: that 's good one . that 's correct .
G: if you hear ctpd , , they do pretty
F: don't recognize lot of these .
G: how are how are they gonna know ?
D: was saying that lot of them are the networks meeting .
E: that 's true . lot of these are coming from them . listened to some of that .
C: we don't have that many acronyms comparatively in this meeting .
D: although see see plenty of
C: it 's not so bad .
E: and robustness has fair amount , but the nsa group is just very many .
G: the recognizer , it is funny . kept getting pta for pda .
D: that 's pretty close .
G: this is close ,
C: that 's not bad .
G: and the pta was in these , , topics about children , so , anyway .
E: that 's interesting .
G: is the - pta working ?
E: right and sometimes , , you see couple of these that are actually "" 's "" so it 's may be that they got to the point where it was low enough understandable understandability that they weren't entirely the person said "" . "" so it isn't really necessarily an undecipherable acronym ,
C: there 's lot of "" 's "" .
E: but just needs to be double checked . now we get to the comments .
F: the number to the left is the number of incidences ?
E: number of times out of the entire database , except for that last thirty minutes haven't checked yet .
F: so cts is really big here ,
D: wonder what it is .
A: so what is the difference between "" papers rustling "" and "" rustling papers "" ?
E: 'd have to listen . 'd like to standardize these down farther but , , , to me that sounds equivalent . but , 'm little hesitant to collapse across categories unless actually listen to them .
D: 'm we 've said xml more than five times .
E: then , at least now .
A: now it 's at least six times , .
F: six now , . wh - the self - referential aspect of these
D: yes , it 's very bad .
G: this is exactly how people will prove that these meetings do differ because we 're recording , right ? no normally you don't go around saying , "" now you 've said it six times .
D: that 's right .
G: now you 've said ""
E: but did you notice that there were seven hundred and eighty five instances of "" "" ?
A: seven hundred eighty - five instances .
E: and that 's just without the without punc punctuation .
F: no , didn't .
D: and that 's an underestimate
E: extra forty one if it 's questioned .
B: where 's that ?
E: on the page two of acronyms .
C: is this after like did you do some replacements for all the different form of "" "" to this ?
F: seven hundred eighty .
E: of "" "" , yes . so that 's the single existing convention for "" "" .
F: so now we 're up to seven hundred and eighty eight .
C: although , what 's there 's one with slash after it . that 's disturbing .
D: we 'll have to look at it .
E: that 's that 's looked for that one . actually explicitly looked for that one , and that , , 'm not exactly about that .
B: was that somewhere where they were gonna say "" new speaker "" ?
E: no , looked for that , but that doesn't actually exist . and it may be , don't 't explain that .
C: that 's alright . 'm just pointing that out .
E: it 's the only it 's the only pattern that has slash after it , and it 's it 's an epiphenomenon .
G: there 's not @ @ .
D: so 'll just was just looking at the bottom of page three there , is that "" to be "" or "" not to be "" .
B: there 's no tilde in front of it ,
E: that 's cute . that 's funny .
D: "" try to stay on topic , adam . ""
E: there is th one no , that 's that 's legitimate . so now , , comments , you can see they 're listed again , same deal , with exhaustive listing of everything found in everything except for these final th thirty minutes .
D: so , , on some of these quals , are they really quals , or are they glosses ? so like there 's "" qual tcl "" .
E: "" tcl "" . where do you see that ? the reason is because it was said "" tickle "" .
F: what 's qual ?
D: see , see . so it 's not gloss .
C: sh - shouldn't it be "" qual tickle "" ?
D: it wasn't said "" tcl "" .
C: like it 's not
E: on the in the actual script in the actual transcript , so this happens in the very first one . actually wrote it as "" tickle "" . because we they didn't say "" tcl "" , they said "" tickle "" . and then , following that is "" qual tcl "" .
F: what 's qual ?
E: qual - qualifier .
B: it 's just comment about what they said .
C: it 's not something you wanna replace with
E: comment or contextual comment .
B: so they didn't mean "" tickle "" as in elmo , they meant "" tickle "" as in
G: but at some point , we probably shoul
D: we 'll probably add it to the language model .
G: but we should add it to the dictionar no , to the pronunciation model .
D: what did say ?
A: to the language model .
B: add what , liz ?
D: we can go on lan add it to both dictionary and language model .
G: it 's in the language model , but it so it 's the pronunciation model that has to have pronunciation of "" tickle "" .
D: "" tickle "" was pronounced "" tickle "" .
A: "" tickle "" is pronounced "" tickle "" ?
B: what are you saying ?
D: it 's pronounced the same it 's pronounced the same as the verb . so it 's the language model that makes it different .
G: what is that there should be pronunciation "" tickle "" for tcl as word . and that word in the in , , it stays in the language model wherever it was . you never would put "" tickle "" in the language model in that form , there 's actually bunch of cases like this with people 's names and
B: so how there 'd be problem for doing the language modeling then with our transcripts the way they are .
G: so th there 's few cases like that where the , the word needs to be spelled out in consistent way as it would appear in the language , but there 's not very many of these . tcl 's one of them .
D: and and you 'll ha you 'll have to do it sychronously . right , so so , whoever 's creating the new models , will have to also go through the transcripts and change them synchronously .
C: it 's just disturbing .
G: we have this there is this thing was gonna talk to you about at some point about , , what do we do with the dictionary as we 're up updating the dictionary , these changes have to be consistent with what 's in the like spelling people 's names and . if we make spelling correction to their name , like someone had deborah tannen 's name mispelled , and since we know who that is , , we could correct it ,
D: you can correct it .
G: but we need to make we have the mispel if it doesn't get corrected we have to have pronunciation as mispelled word in the dictionary . things like that .
D: these are so funny to read .
E: now the tannen corre the spelling change . that 's what gets picked those up in the frequency check .
G: right . right . so if there 's things that get corrected before we get them , it 's it 's not an issue , but if there 's things that , we change later , then we always have to keep our the dictionary up to date . and then , , in the case of "" tickle "" we would just have , , word "" tcl "" which
D: you add it to the dictionary .
G: which normally would be an acronym , but just has another pronunciation .
E: "" icsi "" is one of those that sometimes people pronounce and sometimes they say "" icsi . "" so , those that are are listed in the acronyms , actually know they were said as letters . the others , , those really do need to be listened to cuz haven't been able to go to all the ic icsi things ,
G: right , exactly .
E: and until they 've been listened to they stay as "" icsi "" .
F: don and were just noticing , love this one over on page three , "" vocal gesture mimicking sound of screwing something into head to hold mike in place . ""
C: that 's great .
D: it 's this , "" rrre - rrre "" . it was me . lot of these are me the "" beep is said with high pit high pitch and lengthening . ""
E: he he he said he said get
D: that was the was imitating , beeping out
E: that 's it . that 's it .
G: there is something spelled out "" beeeeeep ""
E: that 's it . that 's that 's been changed .
G: because he was saying , "" how many 's do have to allow for ? ""
C: you need lot of
D: what was "" beep "" .
C: you need lot of qualification adam .
E: that 's been changed . so , exactly , that 's where the lengthening comment came in . chan brought it down .
D: so they 're vocalization ,
E: and those get picked up in the frequency check because you see "" beep "" and it gets kicked out in the spelling , and it also gets kicked out in the , , freq frequency listing . have the there 're various things like "" breathe "" versus "" breath "" versus "" inhale "" and , hhh , they don't have any implications for anything else so it 's like 'm tempted to leave them for now an and it 's easy enough to find them when they 're in curly brackets . we can always get an exhaustive listing of these things and find them and change them .
F: "" sings finale - type song ""
C: that was in the first meeting .
F: that 's that 's good .
E: but don't actually remember what it was . but that was eric did that .
F: tah - dah !
E: maybe something like that . that 'd qualify .
D: on the glosses for numbers , it seems like there are lots of different ways it 's being done .
E: now first of all ooo - ooo !
D: "" ooo - ooo . ""
E: chuck led to refinement here which is to add "" nums "" if these are parts of the read numbers . now you already that had , , in places where they hadn't transcribed numbers , put "" numbers "" in place of any numbers , but there are places where they , it th this convention came later an and at the very first digits task in some transcripts they actually transcribed numbers . chuck pointed out that this is read speech , and it 's to have the option of ignoring it for certain other prob , things . and that 's why there 's this other tag here which occurs hundred and five or three hundred and five times right now which is just "" nums "" by itself
D: "" nums "" ,
E: which means this is part of the numbers task . may change it to "" digits "" . with the sed command you can really just change it however you want because it 's systematically encoded , ? have to think about what 's the best for the overall purposes , but in any case , , "" numbers "" and "" nums "" are part of this digits task thing . now th then have these numbers that have quotation marks around them . didn't want to put them in as gloss comments because then you get the substitution . and actually , th , the reason did it this way was because initially started out with the other version , you have the numbers and you have the full form and the parentheses , however sometimes people stumble over these numbers they 're saying . so you say , "" seve - seventy eight point two "" , or whatever . and there 's no way of capturing that if you 're putting the numbers off to the side . you can't have the seven and
D: so what 's to the left of these ?
E: so example the very first one , it would be , spelled out in words , "" point five "" .
D: that 's what was asking .
E: only it 's spelled out in words .
D: point five , .
E: so this is also spelled out in words . "" point five . "" and then , in here , "" nums "" , so it 's not going to be mistaken as gloss . it comes out as "" nums quote dot five "" .
D: now , the other example is , in the glosses right there , "" gloss one dash one three zero "" . what what 's to the left of that ?
E: in that case it 's people saying things like "" one dash so - and - so "" or they 're saying "" two zero "" whatever . and in that case , it 's part of the numbers task , and it 's not gonna be included in the read digits anyway ,
B: so there will be "" nums "" tag on those lines ?
E: 've added th now too .
C: there 's "" numbers "" tag 'm 'm didn't follow that last thing .
E: so , so gloss in the same line that would have "" gloss quote one dash one thirty "" , you 'd have gloss at the end of the line saying , , "" curly bracket nums curly bracket "" . so if you if you did , , "" grep minus nums ""
G: so you could do "" grep minus nums "" .
E: and you get rid of anything that was read .
G: so that 's the so there wouldn't be something like if somebody said something like , "" boy , 'm really tired , . "" and then started reading that would be on separate line ? cuz was doing the "" grep minus "" quick and dirty and looked like that was working , now why do we what 's the reason for having like the point five have the "" nums "" on it ? is that just like when they 're talking about their data ?
E: this is more because these are all these , the "" nums point "" , this all where they 're saying "" point "" something or other .
G: these are all like inside the spontaneous
E: and the other thing too is for readability of the transcript . if you 're trying to follow this while you 're reading it 's really hard to read , "" so in the data column five has "" , , "" one point five compared to seventy nine point six "" , it 's like when you see the words it 's really hard to follow the argument . and this is just really way of someone who would handle th the data in more discourse - way to be able to follow what 's being said . so this is where chuck 's , , overall architecture comes in , where we 're gonna have master file of the channelized data . there will be scripts that are written to convert it into these these main two uses and th some scripts will take it down th into for ta take it to format that 's usable for the recognizer an , other scripts will take it to form that 's usable for the for linguistics an and discourse analysis . and , , the implication that have is that th the master copy will stay unchanged . these will just be things that are generated , by using scripts .
D: master copies of superset .
E: when things change then the script will cham change but the but there won't be stored copies of in different versions of things .
G: so , 'd have one request here which is just , , maybe to make it more robust , th that the tag , whatever you would choose for this type of "" nums "" where it 's inside the spontaneous speech , is different than the tag that you use for the read speech .
B: right . that would argue for changing the other ones to be "" digits "" .
G: that way if we make mistake parsing , , we don't see the "" point five "" , or it 's not there , then we just an and actually for things like "" seven eighths "" , or people do fractions too , you maybe you want one overall tag for that would be similar to that , as long as they 're sep as they 're different strings that we that 'll make our processing more robust . cuz we really will get rid of everything that has the "" nums "" string in it .
B: suppose what you could do is just make that you get rid of everything that has "" curly brace nums curly brace "" .
E: ex - exactly .
B: that would be the
E: that was that was my motivation . and these can be changed , like said . , as said was considering changing it to "" digits "" . and , it just , it 's just matter of deciding on whatever it is , and being the scripts know .
G: it would probably be safer , if you 're willing , to have separate tag just because , then we know for . and we can also do counts on them without having to do the processing . but you 're right , we could do it this way , it should work .
B: and it makes it the thing about
G: but it 's probably not hard for person to tell the difference because one 's in the context of , transcribed word string ,
E: the other thing is you can get really so minute with these things and increase the size of the files and the re and decrease the readability to such an extent by simply something like "" percent "" . now could have adopted similar convention for "" percent "" , but somehow percent is not so hard , ? it 's just when you have these points and you 're trying to figure out where the decimal places are and we could always add it later . percent 's easy to detect . point however is word that has couple different meanings . and you 'll find both of those in one of these meetings , where he 's saying "" the first point wanna make is so - and - so "" and he goes through four points , and also has all these decimals .
B: so liz , what does the recognizer do , what does the sri recognizer output for things like that ? "" seven point five "" . does it output the word
G: "" seven point five "" .
B: the word "" seven "" ? the number "" seven "" ? the word "" seven "" , .
F: so 'd so "" 'd like 'd like to talk about point five "" .
G: and and actually , the language it 's the same point , actually , the , the word "" to "" and the word th "" going to "" and "" to go to "" those are two different "" to 's "" and so there 's no distinction there . it 's just the word "" point "" has every word has only one , one version even if even if it 's actually even like the word "" read "" and "" read "" those are two different words . they 're spelled the same way , right ? and they 're still gonna be transcribed as read . like the idea of having this in there , was little bit worried that , , the tag for removing the read speech because what if we have like "" read letters ""
D: we might wanna just separate tag that says it 's read .
G: like "" read something "" like "" read "" but other than that it sounds great .
D: are we done ?
E: wanted to say also regarding the channelized data ,
D: we 're not done .
E: that , , thilo requested , , that we ge get some segments done by hand to reduce the size of the time bins wh like was chuc - chuck was mentioning earlier that , , if you if you said , "" "" and it was in part of really long , complex , overlapping segment , that the same start and end times would be held for that one as for the longer utterances ,
D: we did that for one meeting , right , so you have that data don't you ?
A: that 's the training data .
E: and he requested that there be , , similar , , samples done for five minute stretches involving variety of speakers and overlapping secti sections . he gave me he did the very , he did some shopping through the data and found segments that would be useful . and at this point , all four of the ones that he specified have been done . in addition the 've have the transcribers expanding the amount that they 're doing actually . so right now , , know that as of today we got an extra fifteen minutes of that type , and 'm having them expand the realm on either side of these places where they 've already started . but if , and and he 's gonna give me some more sections that he thinks would be useful for this purpose . because it 's true , if we could do the more fine grained tuning of this , , using an algorithm , that would be so much more efficient . so this is gonna be useful to expand this .
A: so we sh perhaps we should try to start with those channelized versions just to just to try it . give it give one tr transcriber the channelized version of my speech - nonspeech detection and look if that 's helpful for them , or just let them try if that 's better or if they if they can
E: you mean to start from scratch in brand new transcript ? that 'd be excellent . that 'd be really great . as it stands we 're still in the phase of , , cleaning up the existing data getting things , , in more tight tightly time , aligned . also wanna tell , also wanted to raise the issue that so , there 's this idea we 're gonna have this master copy of the transcript , it 's gonna be modified by scripts into these two different functions . and actually the master
B: two or more . two or more different functions .
E: two two or more . and that the master is gonna be the channelized version . so right now we 've taken this initial one , it was single channel the way it was input . and now , , to the advances made in the interface , we can from now on use the channelized part , and , , any changes that are made get made in the channelized version thing . but wanted to get all the finished all the checks
B: so that has implications for your script .
C: so , , have those the vis the ten hours that have been transcribed already , have those been channelized ? and 've seen @ @ 've seen they 've been channelized ,
E: yes , they have .
D: all ten hours ?
E: except for the missing thirty minutes .
C: have they have they been has the time have the time markings been adjusted , , on per channel
E: for total of like twenty let 's see , four times total of about an thirty minutes . that 's that 's been the case . and plus the training , whatever you have .
C: , if we should talk about this now , or not ,
D: it 's just we 're missing tea .
C: no , but my question is like should until all of those are processed , and channelized , like the time markings are adjusted before do all the processing , and we start like branching off into the our layer of transcripts .
E: the problem the problem is that some of the adjustments that they 're making are to bring are to combine bins that were time bins which were previously separate . and the reason they do that is sometimes there 's word that 's cut off . and so , it 's true that it 's likely to be adjusted in the way that the words are more complete .
C: no know that adjusting those things are gonna is gonna make it better .
E: so it 's gonna be more reliable thing
C: 'm about that , but do you have like time frame when you can expect like all of it to be done , or when you expect them to finish it , or
E: partly it depends on how , how effective it will be to apply an algorithm because this takes time , it takes couple hours to do , , ten minutes .
C: don't doubt it .
B: so right now the what you 're doing is you 're taking the , the original version and you 're channelizing yourself , right ?
C: 'm doing it myself . if the time markings aren't different across channels , like the channelized version really doesn't have any more information . so , was just , originally had done before like the channelized versions were coming out .
B: so th probably the way it 'll go is that , , when we make this first general version and then start working on the script , that script @ @ that will be ma primarily come from what you 've done , , we 'll need to work on channelized version of those originals .
C: and so it 's question of like what
B: and so it should be identical to what you have except for the one that they 've already tightened the boundaries on . and then probably what will happen is as the transcribers finish tightening more and more , , that original version will get updated and then we 'll rerun the script and produce better versions . but the the ef the effect for you guys , because you 're pulling out the little wave forms into separate ones , that would mean these boundaries are constantly changing you 'd have to constantly re rerun that ,
G: but that 's not hard . the harder part is making that the transc the transcription so if you merge two things , then that it 's the sum of the transcripts , but if you split inside something , you don't where the word which words moved . and that 's wh that 's where it becomes little bit , having to rerun the processing . the cutting of the waveforms is pretty trivial .
C: as long as it can all be done automatically , , then that 's not concern . if have to run three scripts to extract it all and let it run on my computer for an hour and half , or however long it takes to parse and create all the reference file , that 's not problem . as long as we 're at that point . and know exactly like what the steps will work what 's going on , in the editing process ,
E: so that 's could there were other checks that did , but it 's that we 've unless you think there 's anything else , that 've covered it .
B: 't think of any of the other ones .
","The Berkeley Meeting Recorder group discussed digits data , recent ASR results , the status of transcriptions , and disk space and storage format issues.
Approximately two hours of digits have been recorded , half of which have been extracted.
Researchers doing ASR are looking into methods for generating a better channel-based segmentation to improve recognition results for close-talking microphone data.
Transcription checking procedures were reviewed , and efforts to coordinate the channelization and presegmention of data with the tightening of time bins were discussed.
The group also talked about downsampling and strategies for coping with low disk space.
Digits forms will instruct speakers to read digits separately and not as connected numbers.
A tentative decision was made to collect overlapping digits from speakers.
Transcribers will be given channelized data that has been segmented for speech/non-speech boundaries to determine whether such pre-processing facilitates the transcription process.
Participants have been slow in returning the relevant forms necessary for matching digits data with speaker IDs . Forms containing digits that were written out in English were unsuccessful for obtaining desired prosodic groupings.
Acoustic adaptation is problematic for speakers who seldom talk during meetings.
Speaker overlap causes recognition errors.
The lapel microphone is problematic as it picks up overlapping background speech.
More disk space is needed.
Loading long waveforms in X Waves is very time consuming.
The dictionary must be updated with forms introduced as part of speaker fe008's set of transcription conventions.
The ongoing tightening of boundaries on time bins causes segment boundaries to change , indicating potential problems for other ongoing processing tasks.
A test set of digits data totalling two hours is nearly complete.
Digit extraction has been performed on roughly half of this data.
Future work may involve experimenting with the reading of digits in different prosodic groupings.
Preliminary ASR results were discussed.
Subsequent efforts will involve generating a better channel-based segmentation , and possibly doing echo cancellation , to improve recognition on the close-talking microphone data.
Filename conventions are being standardized.
Transcription checking procedures have been formalized , including a spell check , producing an exhaustive list of forms identified in the data , attributing every utterance to the appropriate speaker ID , glossing spoken forms with their full orthographic counterparts , e.g . 'cuz' and 'because' , transcribing acronyms , and encoding comments , i.e . glosses , vocalic and non-vocalic non-speech events , pragmatic cues , and the standardization of spoken forms , e.g . 'mm-hmm'.
Scripts will be used to convert a channelized master copy into forms that are appropriate for doing both recognition and linguistic analysis.
Coordinated efforts are in progress between the transcriber pool and speaker mn014 to fine-tune presegmented output to handle data from a variety of speakers and regions of speaker overlap.
"
ami_abstractive_summary,Bro026.txt,"B: so we we had meeting with , with hynek , , in which , , sunil and stephane , summarized where they were and , , talked about where we were gonna go . so that happened mid - week .
E: did you guys get your code pushed together ?
D: it 's it 's it was updated yesterday ,
A: you probably received the mail .
E: right , saw saw the note .
B: what was the update ?
A: what was the update ? so there is th then the all the new features that go in . the , , noise suppression , the re - synthesis of speech after suppression .
E: is the , the cvs mechanism working ? are are people , , up at ogi grabbing code , via that ?
A: if they use it ,
D: don't think anybody up there is like working on it right now .
B: it more likely that what it means is that when sunil is up there he will grab it .
D: so right now nobody 's working on aurora there .
B: they 're working on different task . but what 'll happen is he 'll go back up there and , , pratibha will come back from , , the east coast . and , and actually , , after eurospeech for little bit , , he 'll go up there too . so , actually everybody who 's working on it will be up there for at least little while . so they 'll remotely access it from there .
E: so has has anybody tried remotely accessing the cvs using , , ssh ?
A: if hari did that or you
D: today . , just log into
E: have you tried it yet ?
D: no , didn't . so 'll try it today .
A: actually tried wh while when installed the repository , tried from belgium . logged in there and tried to import
E: it worked good ?
A: but it 's so , right now it 's the mechanism with ssh . don't didn't set up you can also set up cvs server on new port . it 's like , main server , or you can do cvs server .
E: then that 's using the cvs password mechanism and all that ,
A: but didn't do that because was not about security problems .
E: so when you came in from belgian belgium , using ssh , , was it asking you for your own password into icsi ? so if yo you can only do that if you have an account at icsi ? cuz there is an way to set up anonymous cvs
A: you ha in this way you ca you have to set up cvs server but then , , you can access it . you can set up priorities .
E: so the anonymous mechanism
A: you can access them and mostly if you if the set the server is set up like this .
E: because lot of the open source works with anonymous cvs and 'm just wondering , , for our transcripts we may want to do that .
B: for this don't think we 're quite up to that . we 're still so much in development . we want to have just the insiders .
E: wasn't suggesting for this . 'm thinking of the meeting recorder what 's new ?
B: , maybe the thing to me might be me 'm you 've just been working on , , details of that since the meeting ,
A: mmm , since the meeting , 've been 've been train training new vad and new feature net .
B: that was that was tuesday .
A: so they should be ready .
B: but maybe the thing since you weren't yo you guys weren't at that meeting , might be just to , , recap , , the conclusions of the meeting .
E: you 're talking about the meeting with hynek ?
B: cuz that was , we 'd been working up to that , , he would come here this week and we would since he 's going out of town like now , and 'm going out town in couple weeks , , and time is marching , , given all the mu many wonderful things we could be working on , what will we actually focus on ? and , and what do we freeze ? and , , what do we ? this software that these guys created was certainly key part . so then there 's something central and there aren't at least bunch of different versions going off in ways that differ trivially . , and , ,
E: that 's that 's .
B: and then within that , the idea was to freeze certain set of options for now , to run it , , particular way , and decide on what things are gonna be experimented with , as opposed to just experimenting with everything . so keep certain set of things constant . maybe describe roughly what we are keeping constant for now ,
A: so we 've been working like six weeks on the noise compensation and we end up with something that seems reasonable .
E: are you gonna use which of the two techniques ?
A: so finally it 's it 's , , wiener filtering on fft bins . and it uses , , two steps , smoothing of the transfer function , the first step , that 's along time , which use recursion . and after this step there is further smoothing along frequency , which use sliding window of twenty fft bins .
E: so this is on the , before any mel scaling has been done ?
B: this this smoothing is done on the estimate , , of what you 're going to subtract ? or on the thing that has already had something subtracted ?
A: it 's on the transfer function .
B: it 's on the transfer function for the wiener filter .
A: so we tried different configuration within this idea . we tried applying this on mel bands , having spectral subtraction instead of wiener filtering . finally we end up with this configuration that works , , quite . so we are going to fix this for the moment and work on the other aspects of the whole system .
B: actually , let me int , dave isn't here to talk about it , but let me just interject . this module , in principle , , you would know whether it 's true , is somewhat independent from the rest of it . because you re - synthesize speech , you don't you don't re - synthesize speech , but you could
A: we we do not fo
B: but you could .
A: we do , but we don't don't re - synthesize . in in the program we don't re - synthesize and then re - analyze once again . we just use the clean fft bins .
B: but you have re - synthesized thing that you that 's an option here .
A: this is an option that then you can
B: gu my point is that , , in some of the work he 's doing in reverberation , one of the things that we 're finding is that , , it 's for the for an artificial situation , we can just deal with the reverberation and his techniques work really . but for the real situation , problem is , is that you don't just have reverberation , you have reverberation in noise . and if you don't include that in the model , it doesn't work very . so it might be very thing to do , to just take the noise removal part of it and put that in front of what he 's looking at . and , , generate new files or whatever , and , and then do the reverberation part .
E: so dave hasn't tried that yet ?
B: no , no . he 's ,
E: he 's busy with
B: prelims , right .
C: pre - prelim hell .
B: but , , that 'll it 's clear that we , we are not with the real case that we 're looking at , we can't just look at reverberation in isolation because the interaction between that and noise is considerable . and that 's , in the past we 've looked at , , and this is hard enough , the interaction between channel effects and , and additive noise , , so convolutional effects and additive effects . and that 's hard enough . don't think we really we 're trying to deal with that . in sense that 's what we 're trying to deal with in this aurora task . and we have , , the , , lda that in principle is doing something about convolutional effects . and we have the noise suppression that 's doing something about noise . even that 's hard enough . and and the on - line normalization as , in that category . there 's all these interactions between these two and that 's part of why these guys had to work so hard on juggling everything around . but now when you throw in the reverberation , it 's even worse , because not only do you have these effects , but you also have some long time effects . and , , so dave has something which , , is doing some things under some conditions with long time effects but when it 's when there 's noise there too , it 's it 's pretty hard . so we have to start since any almost any real situation is gonna have , where you have the microphone distant , is going to have both things , we actually have to think about both at the same time . so there 's this noise suppression thing , which is worked out and then , , maybe you should just continue telling what else is in the form we have .
A: , the , , the other parts of the system are the blocks that were already present before and that we did not modify lot .
B: so that 's again , that 's the wiener filtering , followed by , , that 's done at the fft level .
A: th then the mel filter bank , then the log operation ,
B: the the filtering is done in the frequency domain ? and then the mel and then the log , and then the
A: then the lda filter , mmm , then the downsampling , then , , on - line normalization ,
B: on - line norm ,
A: followed by upsampling . then finally , we compute delta and we put the neural network also .
B: right , and then in parallel with an neural net . and then following neural net , some probably some orthogonalization .
A: and finally frame dropping , which , would be neural network also , used for estimated silence probabilities . and the input of this neural network would be somewhere between log mel bands or one of the earlier stages of the processing .
B: so that 's most of this is , is operating parallel with this other . so the things that we , , , there 's there 's some , , neat ideas for so , , in there 's like there 's bunch of tuning things to improve . there 's questions about various places where there 's an exponent , if it 's the right exponent , or ways that we 're estimating noise , that we can improve estimating noise . and there 's gonna be host of those . but structurally it seemed like the things the main things that we brought up that , , are gonna need to get worked on are , , significantly better vad , , putting the neural net on , , which , , we haven't been doing anything with , the , , neural net at the end there , and , , the , , opening up the second front .
E: the other half of the channel ?
B: , , cuz we have we have , , half the , , data rate that they allow .
E: that what you mean ?
B: and , , so the initial thing which came from , , the meeting that we had down south was , , that , , we 'll initially just put in mel spectrum as the second one . it 's , , cheap , easy . there 's question about exactly how we do it . we probably will go to something better later , but the initial thing is that cepstra and spectra behave differently , tony robinson used to do was saying this before . he used to do mel , , spectra and mel cepstra . he used them as alternate features . put them together .
E: so if you took the system the way it is now , the way it 's fro you 're gonna freeze it , and it ran it on the last evaluation , where it would it be ? in terms of ranking ?
A: ri - right now it 's second .
B: although , you haven't tested it actually on the german and danish ,
A: no , we didn't .
E: so on the ones that you did test it on it would have been second ?
B: when you 're saying second , you 're comparing to the numbers that the , that the best system before got on , also without german and danish ?
D: and th the ranking actually didn't change after the german and danish .
B: ranking didn't before , but 'm just asking where this is to where theirs was without the german and danish ,
E: where where were we actually on the last test ?
B: we were also esp essentially second , although there were , we had couple systems and they had couple systems . and so , by that we were third , but , there were two systems that were pretty close , that came from the same place . so institutionally we were we were second , with , , the third system .
E: we 're so this second that you 're saying now is system - wide second ?
B: no it 's also institutional ,
E: still institutionally second ?
B: both of their systems probably
A: we are between their two systems . it is triumph .
D: their their first system is fifty - four point something . and , , we are fifty - three point something .
A: but everything is within the range of one percent .
D: and their second system is also fifty - three point something .
B: so they 're all they 're all pretty close .
E: that 's very close .
B: and and , , , in some sense we 're all doing fairly similar things . , one could argue about the lda and but , , in lot of ways we 're doing very similar things .
E: so how did they fill up this all these bits ?
B: why are we using half ? so you could you
E: or how are they using more than half , maybe is what
B: so , you guys are closer to it than me , so correct me if 'm wrong , but that what 's going on is that in both cases , some normalization is done to deal with convola convolutional effects . they have some cepstral modification , in our case we have couple things . we have the on - line normalization and then we have the lda rasta . and they seem to comple complement each other enough and be different enough that they both seem to help us . but in any event , they 're both doing the same thing . but there 's one difference . the lda rasta , , throws away high modulation frequencies . and they 're not doing that . so that if you throw away high modulation frequencies , then you can downsample .
E: so what if you didn't so do you explicitly downsample then ? do we explicitly downsample ? and what if we didn't do that ? would we get worse performance ?
A: not better , not worse .
B: it doesn't affect it , so , since we 're not evidently throwing away useful information , let 's try to put in some useful information . and , , so , we 've found in lot of ways for quite while that having second stream , helps lot . so that 's that 's put in , and , it may even end up with mel spectrum even though 'm saying we could do much better , just because it 's simple . and , in the long run having something everybody will look at and say , "" , , understand "" , is very helpful .
E: so you would you 're you 're thinking to put the , , mel spectrum in before any of the noise removal ? or after ?
B: that 's question . we were talking about that . it looks like it 'd be straightforward to , , remove the noise ,
E: cuz that happens before the mel conversion ,
B: so , , to do it after the mel conversion , after the noise removal , after the mel conversion . there 's even question in my mind anyhow of whether th you should take the log or not .
A: what about norm normalizing also ?
B: but normalizing spectra instead of cepstra ? some kind would be good .
D: it so it actually makes it dependent on the overall energy of the , the frame .
B: if you do or don't normalize ?
D: if yo if you don't normalize and if you don't normalize .
B: yes , so , one would think that you would want to normalize . my thought is , , particularly if you take the log , try it . and then if normalization helps , then you have something to compare against , and say , "" , this much effect "" , you don't want to change six things and then see what happens . you want to change them one at time . so adding this other stream in , that 's simple in some way . and then saying , particularly because we 've found in the past there 's all these these different results you get with slight modifications of how you do normalization . normalization 's very tricky , sensitive thing and you learn lot . so , would think you would wanna have some baseline that says , "" , we don't normalize , this is what we get "" , when we do this normalization , when we do that normalization . but but the other question is so ultimately we 'll wind up doing some normalization .
E: so this second stream , will it add latency to the system
B: no , it 's in parallel . we 're not talking about computation time here . we 're ta we 're pretty far out . so it 's just in terms of what data it 's depending on . it 's depending on the same data as the other . so it 's in parallel .
C: so with this , , new stream would you train up vad on both features , somehow ?
D: no , the vad has its own set of features . which could be this one of these streams , or it can be something derived from these streams .
A: and there is also the idea of using traps , maybe , for the vad , pratibha showed , when , she was at ibm , that it 's good idea .
C: would would that fit on the handset ,
A: have no idea .
D: it has the th
A: it would have to fit
D: if it has to fit the delays and all this .
B: there 's the delays and the storage , but don't think the storage is so big for that . th the biggest we 've run into for storage is the neural net . and so the issue there is , are we are we using neural - net - based traps , and how big are they ? so that 'll that 'll be , , an issue . maybe they can be little ones . mini - traps .
C: cuz she also does the , the correlation - based , , traps , with without the neural net , just looking at the correlation between
B: and maybe for vad they would be . that 's true . or simple neural net , , if you 're doing correlation , you 're just doing simple , dot product , , with some weights which you happened to learn from this learn from the data . putting nonlinearity on it is , , not that big deal . it certainly doesn't take much space . so , , the question is , how complex function do you need ? do you need to have an added layer ? in which case , , potentially , , it could be big . so what 's next ? maybe remind us .
E: so the meeting with hynek that you guys just had was to decide exactly what you were gonna freeze in this system ? or was there ? were you talking about what new ,
B: what to freeze and then what to do after we froze . and like was saying , the , the basic directions are , , there 's lots of little things , such as improve the noise estimator but the bigger things are adding on the neural net and , , the second stream . and then , , improving the vad .
D: so , 'll , 'll actually after the meeting 'll add the second stream to the vad and maybe 'll start with the feature net in that case . it 's like , you 're looking at the vad ,
A: 've new feature net ready also .
D: for the vad ?
A: no , . two network , one vad and one feature net .
D: you already have it ? so just figure how to take the features from the final
A: but , , there are plenty of issues to work on for the feature net @ @ .
E: what about the , , the new part of the evaluation , the , , wall street journal part ?
B: have you ever ? very good question . have you ever worked with the mississippi state , software ? you may be called upon to help , , on account of , , all the work in this here has been , , with small vocabulary .
E: so what how is the , , interaction supposed to happen ? remember the last time we talked about this , it was up in the air whether they were going to be taking , , people 's features and then running them or they were gonna give the system out or so they 're gonna just deliver system .
B: do we already have it ?
D: th it 's almost ready . so they have released their , , document , describing the system .
B: maybe you could , , point it at chuck ,
E: so we 'll have to grab this over cvs ?
D: it - no , it 's just downloadable from their from their web site .
E: is that how they do it ?
B: cuz one of the things that might be helpful , if you 've if you 've got time in all of this is , is if these guys are really focusing on improving , , all the digit , , maybe and you got the front - end from them , maybe you could do the runs for the and , , iron out hassles that you have to , , tweak joe about or whatever , because you 're more experienced with running the large vocabulary .
D: so 'll point you to the web site and the mails corresponding .
E: and it but it 's not ready yet , the system ?
D: they are still , , tuning something on that . so they 're like , they 're varying different parameters like the insertion penalty and other , and then seeing what 's the performance .
E: are those going to be parameters that are frozen , nobody can change ?
D: there is , , time during which people are gonna make suggestions .
E: but everybody 's gonna have to use the same values .
D: so these sugges these this , , period during which people are gonna make suggestions is to know whether it is actually biased towards any set of features or
B: so th certainly the thing that would want to know about is whether we get really hurt , , on in insertion penalty , language model , scaling , sorts of things .
E: using our features .
B: in which case , , hari or hynek will need to , , push the case more about this .
E: and we may be able to revisit this idea about , , somehow modifying our features to work with
B: yes . in this case , that 's right . that 's right . some of that may be , , last minute rush thing because if the if our features are changing the other thing is that even though it 's months away , , it 's starting to seem to me now like november fifteenth is right around the corner . and , , if they haven't decided things like this , like what the parameters are gonna be for this , , when "" deciding "" is not just somebody deciding . , there should be some understanding behind the , , deciding , which means some experiments and . it it seems pretty tight to me .
E: so wha what 's the significance of november fifteenth ?
B: that 's when the evaluation is . so , , so after but , , they may even decide in the end to push it off . it wouldn't , , entirely surprise me . but , , due to other reasons , like some people are going away , 'm 'm hoping it 's not pushed off for long while . that would be , put us in an awkward position . that 'll be helpful . there 's there 's not anybody ogi currently who 's who 's , , working with this
E: is is this part of the evaluation just small part , or ho how important is this to the overall ?
B: it 's it 's , it depends how badly you do . that it is .
E: this is one of those things that will be debated afterwards ?
B: , it 's conceptually , it my impression , again , you guys correct me if 'm wrong , but my impression is that , , they want it as double check . that you haven't come across you haven't invented features which are actually gonna do badly for significantly different task , particularly one with larger vocabulary . and , , but it 's not the main emphasis . the truth is , most of the applications they 're looking at are pretty small vocabulary . so it 's it 's double check . so they 'll probably assign it some low weight .
E: seems to me that if it 's double check , they should give you one or zero . you passed the threshold or you didn't pass the threshold , and they shouldn't even care about what the score is .
B: but , , we 'll we 'll see what they come up with . but in the current thing , , where you have this - matched , moderately - matched , and mis highly - mismatched , , the emphasis is somewhat on the on the - matched , but it 's only marginal , it 's like forty , thirty - five , twenty - five , like that . so you still if you were way , way off on the highly - mismatched , it would have big effect . and , , it wouldn't surprise me if they did something like that with this . so again , if you 're if you get if it doesn't help you much , , for noisy versions of this of large vocabulary data , then , , , it may not hurt you that much . but if it if you don't if it doesn't help you much , , or to put it another way , if it helps some people lot more than it helps other people , , if their strategies do , then
E: so is this , ? guenter was putting bunch of wall street journal data on our disks .
B: that 's it .
E: so that 's the data that we 'll be running on ?
B: so we have the data , just not the recognizer .
E: so this test may take quite while to run , then . may - judging by the amount of data that he was putting on .
B: there 's training and test , no , , if it 's like the other things , there 's there 's data for training the ms and data for testing it . so , training the recognizer , but it 's trained on clean and is it trained on clean and test on ?
D: the wall street ?
A: it 's training on range between ten and twenty db , , and testing between five and fifteen . that 's what got on
D: it 's , it 's like medium - mismatch condition , .
A: and so the noise is there is range of different noises also which are selected randomly and added randomly , , to the files . and there are noises that are different from the noises used on ti - digits .
B: , wouldn't imagine that the amount of testing data was that huge . they probably put training , almost certain they put training data there too . that 's that . anybody have anything else ?
E: one last question on that . when did they estimate that they would have that system available for download ?
D: one some preliminary version is already there .
E: so there 's something you can download to just learn ?
D: it 's already there . but they 're actually parallel - doing some modifications also , . so the final system will be frozen by middle of , like , one more week maybe .
B: that 's pretty soon .
D: that 's just one more .
C: is this their , , svm recognizer ?
D: no , it 's just straightforward .
B: their they have lot of options in their recognizer and the svm is one of the things they 've done with it , but it 's not their more standard thing . for the most part it 's it 's gaussian mixtures .
D: it 's just , gaussian mixture model .
B: the svm thing was an also . it was just it was like hybrid , like
E: so , just so that understand , they 're providing scripts and everything so that , , you push button and it does training , and then it does test , and everything ? is that the idea ?
D: something like that . it 's like as painless as possible , is what do they provide all the scripts , everything , and then just ,
E: somehow yo there 's hooks to put your features in and
D: ju , th .
B: , if you look into it little bit , it might be reasonable just to ask him about the issue of , , different features having different kinds of , , scaling characteristics and so on . so that , , possibly having entirely different optimal values for the usual twiddle factors and what 's what 's the plan about that ?
D: so sh shall we , like , add chuck also to the mailing lists ? it may be better , , in that case if he 's going to because there 's mailing list for this .
E: that 'd be great .
D: maybe hari or hynek , one of them , has to send mail to joe . or maybe if you
E: could send him an email .
D: , to add or maybe wh
E: know him really .
D: so that 's just fine .
E: was just talking with him on email the other day actually .
B: , and just , , se maybe see .
E: about other things ,
B: do you have hari 's , ? so maybe just cc hari and say that you 've just been asked to handle the large vocabulary part here , and , , ,
E: would it be better if asked hari to ask joe ?
B: why don't you just ask joe but cc hari , and then in the note say , "" hari , hopefully this is with you "" . and then if joe feels like he needs confirmation , har answer it . that way you can get started asking joe quickly while he 's while he 's maybe still , , putting in nails and screws and
D: and there is an , , archive of all the mails that has been gon that has gone , , between these people among these people . so just you can see all this mails in the isip web site mississippi web site .
E: is that password controlled ?
D: it 's password protected . so , like , it 's , like
B: have you thought about how long would be , most useful for you to go up to ogi ?
A: we can for september , we can set up work schedule and we can maybe work independently . and then at some point it maybe be better to work together again .
B: so you 're you 're imagining more that you would come back here first for while and then and then go up there ? it 's to you . ju you guys are anyway , you don't have to decide this second but th about it about what you would think would be the best way to work it . 'll support it either way , so . got anything to tell us ?
C: 've been reading some literature about clustering of data . just , , , let me put it in context . so we 're talking about discovering intermediate categories to , to classify . and , , was looking at some of the work that , , sangita was doing on these traps things . so she has , she has temporal patterns for , , certain set of phonemes , from timit , the most common phonemes . and each one of them has pattern over time , one second window . and it has these patterns . so she has , trap for each one of the phonemes , , times fifteen , for each of the fifteen critical bands . and , , she does this agglomerative hierarchical clustering which , , is clustering algorithm that , , starts with many , many different points many different clusters , corresponding to the number of data , , patterns that you have in the data . and then you have this distance mej metric which , , measures how closely related they are . and you start , by merging the patterns that are most closely related .
E: and you create tree . and then you can pick , , values anywhere along that tree to fix your set of clusters .
C: right , usually it 's when , when the sol similarity measures , , don't go down as much . and so , so you stop at that point . and what she found was , sh , was there were five broad , broad categories , , corresponding to , , things like , , fricatives and , , vocalic , , and , , stops . and , , one for silence and another one for schwa sounds . and , , was thinking about ways to generalize this because you 're it 's like it 's not completely automatic way of clustering , because yo beforehand you have these traps and you 're saying that these frames correspond to this particular phoneme . and that 's that 's constraining your clustering to the set of phonemes that you already have . whereas maybe we want to just take look at , , arbitrary windows in time , , of varying length , , and cluster those . and 'm thinking if we if we do that , then we would probably , , at some point in the clustering algorithm find that we 've clustered things like , , thi this is transition , , this is relatively stable point . and 'm hoping to find other things of similarity and maybe use these things as the intermediate , intermediate categories that , , , 'll later classify .
B: are you looking at these in narrow bands ? cuz that 's what you 're gonna be using ,
C: haven't exactly figured out , , the exact details for that but , , the representation of the data that was thinking of , was using , , critical band , , energies , , over different lengths of time .
B: , it seems somehow that needs th , there 's couple things that wonder about with this . so one is , again , looking at the same representation , if you 're going for this thing where you have , little detectors that are looking at narrow bands , then what you 're going to be looking for should be some category that you can find with the narrow bands . that that seems to be fundamental to it . and then the other thing , , is that wonder about with it , and don't take this in the wrong way , like 'm doing or anything , but , . , just wondering really . the standard answer about this thing is that if you 're trying to find the right system in some sense , whether you 're trying by categories or parameters , and your goal is discrimination , then having choices based on discrimination as opposed to , , unsupervised nearness of things , , is actually better . and if that , since you 're dealing with issues of robustness , , maybe this isn't right , but it 'd be something 'd be concerned about . because , , you can imagine , , if you remember from , from your quals , john ohala saying that , , "" buh "" and "" puh "" differed , , not really cuz of voicing but because of aspiration . in as far as wha what 's really there in the acoustics . so , , if you looked if you were doing some coarse clustering , you probably would put those two sounds together . and yet , would gue would that many of your recognition errors were coming from , , , pfft , screwing up on this distinction . so , , it 's little hard because recognizers , to first order , work . and the reasons we 're doing the things we 're doing is because they don't work as as we 'd like . and since they work , , it means that they are already doing if you go and take any recognizer that 's already out there and you say , "" how is it distinguishing between schwas and stops ? "" boy , bet they 're all doing nearly perfectly on this , so these big categories that differ in huge obvious ways , we already know how to do . so , what are we bringing to the party ? what we wanna do is have something that , particularly in the presence of noise , , is better at distinguishing between , , categories that are actually close to one another , and hence , would probably be clustered together . so that 's th that 's the hard thing . understand that there 's this other constraint that you 're considering , is that you wanna have categories that , that would be straightforward for , say , human being to mark if you had manual annotation . and it 's something that you really think you can pick up . but it 's also essential that you wanna look at what are the confusions that you 're making and how can you come up with , , categories that , , can clarify these confusions . so , , the standard way of doing that is take look at the algorithms you 're looking at , but then throw in some discriminative aspect to it . this is more like , , how does lda differ from pca ? they 're the same thing . they 're both orthogonalizing . and , , this is little harder because you 're not just trying to find parameters . you 're actually trying to find the the categories themselves . so little more like brain surgery , anyway . that 's my thought . you 've been thinking about this problem for long time actually . actually , you stopped thinking about it for long time , but you used to think about it lot . and you 've been thinking about it more now ,
E: don't , it 's not clear to me how to reconcile , , what you 're saying , which is right , with the way 've been looking at it . that it 's it 's all not very clear to me . but it seems to me that the desire the desirable feature to have is something that , , is bottom - up . however we do that . and and so what don't understand is how to do that and still be discriminative , because to be discriminative you have to have categories and the only categories that we know of to use are these human sig significant categories that are significant to humans , like phonemes , things like that . but that 's what you want to avoid . and so that feels how to get out of this .
B: here 's here 's , here 's generic and possibly useless thought , which is , , what do you really , in sense the only systems that make sense , , are ones that have something from top - down in th in them . because if even the smallest organism that 's trying to learn to do anything , if it doesn't have any reward for doing or penal penalty for doing anything , then it 's just going to behave randomly . so whether you 're talking about something being learned through evolution or being learned through experience , it 's gotta have something come down to it that gives its reward or , , at least some reinforcement learning ,
E: so the question is , how far down ? we could stop at words , but we don't , we go all the way down to phonemes .
B: right , but me that maybe in some ways part of the difficulty is trying to deal with the with these phonemes . and and it 's almost like you want categories if our if our , , , metric of goodness , , if our correction if our metric of badness is word error rate then , , maybe we should be looking at words . for for very , , reasons we 've looked for while at syllables , and they have lot of good properties , but if you go all the way to words , , that 's really , in many applications you wanna go further . you wanna go to concepts , or have have concepts , actions , this thing .
E: but words would be
B: words aren't bad , .
E: so the common right , the common wisdom is you can't do words because there 's too many of them , so you have to have some smaller set that you can use , and so everybody goes to phonemes . but the problem is that we build models of words in terms of phonemes and these models are really cartoon - ish , so when you look at conversational speech , , you don't see the phonemes that you that you have in your word models .
B: but but we 're not trying for models of words here . see , so her here 's maybe where if the issue is that we 're trying to come up with , , some intermediate categories which will then be useful for later , , then maybe it doesn't matter that we can't have enough what you wanna do is build up these categories that are that are best for word recognition . and and somehow if that 's built into the loop of what the categories we do this every day in this very gross way of running thousand experiments because we have fast computers and picking the thing that has the best word error rate . in some way , we derive th the time . in some ways it 's really not bad thing to do because it tells you how your adjustments at the very low level affect the final goal . so maybe there 's way to even put that in much more automatic way , where you take , , something about the error at the level of the word or some other it could be syllable but in some large unit , and , you may not have word models , you have phone models , whatever , but you don't worry about that , and just somehow feed it back through . so that 's , , wh what called useless comments because 'm not really telling you how to do it . but , it 's it 's it 's , it
E: no , but the important part in there is that , , if you want to be discriminative , you have to have , , categories . and this the important categories are the words , and not the phones . if you can put the words in to the loop somehow for determining goodness of your sets of clusters
B: now , that being said , that if you have something that is , once you start dealing with spontaneous speech , all the things you 're saying are really true . if you have read speech that 's been manually annotated , like timit , then , , you the phones are gonna be right , actually , for the most part . so so , , it doesn't really hurt them to do that , to put in discrimination at that level . if you go to spontaneous speech then it 's it 's trickier and and , , the phones are , it 's gonna be based on bad pronunciation models that you have of and , and it won't allow for the overlapping phenomenon
E: so it 's almost like there 's this mechanism that we have that , , when we 're hearing read speech and all the phonemes are there , we deal with that , but when we go to conversational , and then all of sudden not all the phonemes are there , it doesn't really matter that much to us as humans because we have some mechanism thows for these word models , whatever those models are , to be munged , , and it doesn't really hurt , 'm not how to build that in .
B: the other thing is to think of little bit we when when you start looking at these results it usually is pretty intuitive , but start looking at , what are the kinds of confusions that you do make , , , between words if you want or or , , even phones in in read speech , say , , when there is noise . so is it more across place or more across manner ? or is it cor , is it ? know one thing that happens is that you you , , you lose the , , , low energy phones . if there 's added noise then low energy phones sometimes don't get heard . and if that if that is if it , if that turns it into another word or different , or another pair of words , then it 's more likely to happen . but , , , would would that you 'd anyway , that 's
E: part of the difficulty is that lot of the robustness that we have is probably coming from much higher level . we understand the context of the situation when we 're having conversation . and so if there 's noise in there , , our brain fills in and imagines what should be there .
C: we 're we 're doing some prediction of what
B: , that 's really big . but , even if you do , , diagnostic rhyme test things , , where there really isn't an any information like that , , people are still better in noise than they than they are in , , than the machines are . so , , that 's right . we can't we can't get it without any language models . language models are there and important if we 're not working on that then we should work on something else and improve it , but especially if it looks like the potential is there . should we do some digits ? since we 're here ?
E: go ahead , morgan .
B: that 's all folks .
","ICSI's Meeting Recorder Group at Berkeley met mainly to discuss work on their main project , the Aurora task , but also talked about the work of one of their student members.
Some members of the group met recently with research partners to settle on the current state of their software , and decide on the future work they would investigate , and these decisions were relayed to the rest of the group.
Of the three areas for the future , they touched mostly upon the use of a second , parallel , data stream.
The group also discussed a new part to the evaluation , the use of a chunk of the Wall Street Journal.
Speaker me006 is working on data clustering , and discussion of related issues led to more general acoustic matters.
After the meeting , mn052 volunteered to get the second data stream up and running in the current software.
Since he has been asked to assist in a particular aspect of the work , me018 has to contact the relevant persons in order to be added to the according mailing list.
There is a new system coming from OGI for dealing with the Wall Street Journal data , and me013 wanted everyone to pay attention to areas where the groups might get hurt because of their features.
The group's code has been updated , and in it's frozen state , runs at the second best level in the project.
The CVS allowing access to the code is up and running , but now one at OGI is actually working on it yet.
Speaker me006 has been reading literature on data clustering , with particular attention to a previous work , and is contemplating how to generalise it.
"
ami_abstractive_summary,Bmr018.txt,"E: we 're recording .
C: alright , and no crash .
E: pre - crashed it .
F: pre - crashed !
D: it never crashes on me . what is what is that ?
E: it depends on if the temp files are there or not , that at least that 's my current working hypothesis , that what happens is it tries to clear the temp files and if they 're too big , it crashes .
B: when the power went out the other day and restarted it , it crashed the first time .
E: that 's right .
B: after the power out
D: so then there would be no temp files .
E: no , it doesn't it doesn't clear those necessarily ,
D: it doesn't clear them ,
E: it 's they 're called temp files , but they 're not actually in the temp directory they 're in the scratch , they 're not backed up , but they 're not erased either on power failure .
D: but that 's usually the meeting that recorded , and it neve it doesn't crash on me .
B: this wasn't actually , this wasn't before your meeting , this was , , tuesday afternoon when , , , robert just wanted to do little recording , and the power had gone out earlier in the day .
C: when would be good excuse for it , but can't to be giving talk and and use the example from last week with everybody doing the digits at once .
A: that was fun .
C: 'd love to play somebody that .
A: that was fun .
D: it was quick .
C: it was really efficient .
B: talk about good noise shield . you wanted to pe keep people from listening in , you could like have that playing outside the room . nobody could listen in .
D: had this idea we could make our whole meeting faster that way .
C: everybody give the reports about what they were doing at exactly the same time ,
D: and we 'll just all leave ,
B: and then we 'll we 'll go back later and review the individual channels ,
E: and then everyone can listen to it later .
C: actually isn't that what we have been doing ?
E: it 's what it sounds like .
B: with all the overlaps .
C: what are we doing ?
E: since 've been gone all week , didn't send out reminder for an agenda , do we have anything to talk about or should we just read digits and go ?
B: wouldn't mind hearing how the conference was .
D: had one question about
E: it 's all blur .
D: aren't the uw folks coming this weekend ?
F: no . the next ,
E: next weekend , week from
C: that is right . the next weekend .
D: not not the days coming up , but
F: it 's like the
E: week from saturday .
C: that 's when they 're coming .
D: within ten days .
C: that 's correct .
D: so , are we do we have like an agenda or anything that we should be
C: no , but that would be good idea .
F: so so the deal is that , , , be available after , , like ten thirty . how how early you wanted to
C: they 're not even gonna be here until eleven or so .
E: that 's good .
C: cuz they 're flying up that day .
D: this is on sunday ?
E: eurospeech is due on friday and then 'm going down to san , san jose friday night , so , if , if we start and late saturday that 's good thing .
C: no , , they 're flying up from down from seattle .
E: they 're flying from somewhere to somewhere ,
C: and they 'll end up here . so and also brian kingsbury is actually flying from , , the east coast on that morning . so , will be , he 's taking very early flight and we do have the time work difference running the right way , but still think that there 's no way we could start before eleven . it might end up really being twelve . so when we get closer we 'll find people 's plane schedules , and let everybody know . so . that 's good .
E: but , , maybe an agenda , or at least some things to talk about would be good idea .
C: we can start gathering those ideas , but then we should firm it up by next thursday 's meeting .
A: will we have time to , , to prepare something that we in the format we were planning for the ibm transcribers by then ,
E: so have you heard back from brian about that ,
B: he 's 'm , should have forwarded that along . mentioned at the last meeting , he said that , , he talked to them and it was fine with the beeps they would be that 's easy for them to do .
E: so , , , though thi - thilo isn't here , have the program to insert the beeps . what don't have is something to parse the output of the channelized transcripts to find out where to put the beeps , but that should be really easy to do . so do we have meeting that 's been done with ,
A: he 's he 's
E: that we 've tightened it up to the point where we can actually give it to ibm and have them try it out ?
A: he generated , , channel - wise presegmented version of meeting , but it was robustness rather than edu so depends on whether we 're willing to use robustness ?
B: for this experiment we can use pre anything . this experiment of just
E: we had we had talked about doing maybe edu as good choice , though . whatever we have .
B: we 've talked about that as being the next ones we wanted to transcribe . but for the purpose of sending him sample one to
E: maybe it doesn't matter .
A: 'll 'll , , get make that available .
E: and has it been corrected ? hand - checked ? cuz that was one of the processes we were talking about as .
B: right , so we need to run thilo 's thing on it ,
A: that 's right .
B: and then we go in and adjust the boundaries .
A: that 's right . we haven't done that . could set someone on that tomorrow .
E: and time how long it takes .
B: and we probably don't have to do necessarily whole meeting for that if we just wanna send them sample to try .
A: what would be good number of minutes ?
B: maybe we can figure out how long it 'll take @ @ to do .
E: it seems to me we probably should go ahead and do whole meeting because we 'll have to transcribe the whole meeting anyway sometime .
C: except that if they had if there was choice between having fifteen minutes that was fully the way you wanted it , and having whole meeting that didn't get at what you wanted for them it 's just dependent of how much
E: like if we have to do it again anyway ,
B: the only thing 'm not about is , , how quickly can the transcribers scan over and fix the boundaries , is it pretty easy ?
E: it 's gonna be one or two times real time at excuse me , two or more times real time , cuz they have to at least listen to it .
C: can we pipeline it so that say there 's , , the transcriber gets done with quarter of the meeting and then we you run it through this other ?
E: 'm just thinking that from data keeping - track - of - the - data point of view , it may be best to send them whole meetings at time and not try to send them bits and pieces .
C: that 's right . so the first thing is the automatic thing , and then it 's then it 's the transcribers tightening up , and then it 's ibm .
A: - , - .
C: so you might as ha run the automatic thing over the entire meeting , and then and then , , you would give ibm whatever was fixed .
A: and have them fix it over the entire meeting too ?
C: , but start from the beginning and go to the end , so if they were only half way through then that 's what you 'd give ibm .
B: as of what point ? the the question on my mind is do we for the transcribers to adjust the marks for the whole meeting before we give anything to ibm , or do we go ahead and send them sample ?
C: why wouldn't we @ @ if they were going sequentially through it , why wouldn't we give them are we trying to get something done by the time brian comes ?
E: that was the question . though .
C: so if we if we were , then it seems like giving them something , whatever they had gotten up to , would be better than nothing .
E: they typically work for what , four hours , something like that ? the they should be able to get through whole meeting in one sitting . unless it 's lot harder than we is , which it could be , certainly .
A: if it 's got like for speakers then if
B: we 're just doing the individual channels ,
E: or seven or eight .
B: so it 's gonna be , depending on the number of people in the meeting ,
A: there is this issue of , , if the segmenter thought there was no speech on particular stretch , on particular channel , and there really was , then , if it didn't show up in mixed signal to verify , then it might be overlooked , so , , the question is "" should transcriber listen to the entire thing or can it can it be based on the mixed signal ? "" and th so far as 'm concerned it 's fine to base it on the mixed signal at this point ,
E: that 's what it seems to me too , in that if they need to , just like in the other cases , they can listen to the individual , if they need to .
A: and that cuts down the time .
E: but they don't have to for most of it .
A: that 's good . good , good .
B: don't see how that will work , though .
A: what what aspect ?
C: so you 're talking about tightening up time boundaries ? so how do you
E: so , they have the normal channeltrans interface where they have each individual speaker has their own line , but you 're listening to the mixed signal and you 're tightening the boundaries , correcting the boundaries . you shouldn't have to tighten them too much because thilo 's program does that .
A: should be pretty good ,
D: except for it doesn't do on short things , remember .
E: right , so you 'll have to
D: it will miss them . it will miss most of the really short things .
A: but those would be those would be
D: it will it will miss you have to say "" - "" more slowly to get no , 'm 'm actually serious .
E: 'll work on that .
D: so it will miss like that which
E: so that 's something that the transcribers will have to have to do .
A: but presumably , most of those they should be able to hear from the mixed signal unless they 're embedded in the heavil heavy overlap section when in which case they 'd be listening to the channels anyway .
B: that 's that 's what 'm 'm concerned about the part .
D: and that 's what 'm not about .
A: and it 's an empirical question .
B: can't we couldn't we just have , , maybe this just doesn't fit with the software , but if didn't know anything about transcriber and was gonna make something to let them adjust boundaries , would just show them one channel at time , with the marks , and let them adju
E: but then they have to do but then they for this meeting they would have to do seven times real time , and it would probably be more than that .
A: that 's it .
E: because they 'd have to at least listen to each channel all the way through .
B: but but it 's very quick , you scan , if you have display of the waveform .
E: you 're talking about visually .
A: the other problem is the breaths cuz you also see the breaths on the waveform . 've 've looked at the int , 've tried to do that with single channel , and you do see all sorts of other besides just the voice .
E: and that they 're going much more on acoustics than they are on visuals .
A: that 'm not . what you the digital what the digital task that you had your interface ? know for fact that one of those sh she could really she could judge what th what the number was based on the on the waveform .
E: that 's actually true . you 're right . you 're right . found the same thing that when was scanning through the wave form could see when someone started to read digits just by the shapes .
A: she could tell which one was seven .
C: 'm 'm now entirely confused about what they do . so , they 're they 're looking at mixed signal , or they 're looking what are they looking at visually ?
A: they have choice . they could choose any signal to look at . 've tried lookin but usually they look at the mixed . but 've 've tried looking at the single signal and in order to judge when it when it was speech and when it wasn't , but the problem is then you have breaths which show up on the signal .
C: but the procedure that you 're imagining , , people vary from this , is that they have the mixed signal wave form in front of them , and they have multiple , , let 's see , there isn't we don't have transcription yet . so but there 's markers of some sort that have been happening automatically , and those show up on the mixed signal ? there 's @ @ clicks ?
A: they show up on the separate ribbons . so you have separate ribbon for each channel ,
C: there 're separate ribbons .
A: and it 'll be because it 's being segmented as channel at time with his with thilo 's new procedure , then you don't have the correspondence of the times across the bins across the ribbons
C: and is there line moving across the waveform as it goes ? so the way you 're imaging is they play it , and they see this happened , then and if it 's about right , they just let it slide , and if it there 's question on something , they stop and maybe look at the individual wave form .
A: not "" look "" .
E: they wouldn't look at it at this point . they would just listen .
C: they they might look at it ,
E: the problem is that the interface doesn't really allow you to switch visuals .
A: not very quickly .
E: the problem is that the tcl - tk interface with the visuals , it 's very slow to load waveforms .
A: you can but it takes time . that 's it .
E: and so when tried that was the first thing tried when first started it ,
A: you can you can switch quickly between the audio , but you just can't get the visual display to show quickly . so you have to it takes , , three , four minutes to , it takes it takes long enough
D: it 's very slow to do that .
A: it takes long enough cuz it has to reload the exactly what it 's doing frankly cuz but it it takes long enough that it 's just not practical alternative .
E: it does some shape pre - computation so that it can then scroll it quickly ,
G: but you can cancel that .
E: but then you can't change the resolution or scroll quickly .
A: now you could set up multiple windows , each one with different signal showing , and then look between the windows . maybe that 's the solution .
E: we could do different interfaces ,
G: what if you preload them all ?
E: so we could use like waves instead of transcriber , and it loads faster , certainly .
G: what if you were to preload all the channels or initially
E: that 's what tried originally . so actually before , , dave gelbart did this , did an interface which showed each waveform and ea ribbon for each waveform , but the problem with it is even with just three waveforms it was just painfully slow to scroll . so you just scroll screen and it would , go "" kur - chunk ! "" and so it just was not doable with the current interface .
A: am thinking if we have meeting with only four speakers and , , you could fire up transcriber interface for , , in different windows , multiple ones , one for each channel . and it 's hack but it would be one way of seeing the visual form .
E: that if we decide that we need that they need to see the visuals , we need to change the interface so that they can do that .
D: that 's actually what of , loading the chopped up waveforms , , , that would make it faster
E: the chopped up waveforms .
B: the problem is if anything 's cut off , you can't expand it from the chopped up
D: right , but if you
E: and wouldn't that be the same as the mixed signal ?
D: no , the individual channels that were chopped up that it 'd be to be able to go back and forth between those short segments . cuz you don't really nee like nine tenths of the time you 're throwing most of them out , but what you need are tho that particular channel , or that particular location , might be , cuz we save those out already , , to be able to do that . but it won't work for ibm , it only works here cuz they 're not saving out the individual channels .
A: do think that this will be doable procedure , and have them starting with mixed and , , then when they get into overlaps , just have them systematically check all the channels to be that there isn't something hidden from audio view .
E: the mixed signal , the overlaps are pretty audible because it is volume equalized . so they should be able to hear . the only problem is , , counting how many and if they 're really correct or not .
D: that you can locate them very from the mixed signal ,
E: right but once that they happen , you can at least listen to the close talking ,
D: but you would know that they were there , and then you would switch . and then you would switch into the other
C: but right now , to do this limitation , the switching is going to be switching of the audio ? is what she 's saying . so they 're using their ears to do these markings anyway .
E: did dave did dave do that change where you can actually just click rather than having to go up to the menu to listen to the individual channels ? had suggested it before . whether he did it or not .
A: 'm not what click on the ribbon ? you can get that get you can get the , you can get it to switch audio ? not last tried , but , , maybe he 's changed it again .
E: we should get him to do that because , , that would be much , much faster than going to the menu .
A: there 's reason disagree , and that is that , , you it 's very good to have dissociation between the visual and the audio . there 're times when wanna hear the mixed signal , bu but want to transcribe on the single channel .
E: then maybe just buttons down at the bottom next to it .
A: maybe , don't don't see that it 's
E: just something so that it 's not in the menu option so that you can do it much faster .
A: , that 's the that might be personal style thing . find it really convenient the way the way it 's set up right now .
E: it just seems to me that if you wanna quickly "" was that jane , no , was that chuck , no , was that morgan "" , right now , you have to go up to the menu , and each time , go up to the menu , select it , listen to that channel then click below , and then go back to the menu , select the next one , and then click below .
A: that 's fine . it 's true .
E: so you can definitely streamline that with the with the interface .
A: it could be faster , but , , , th in the ideal world no agree that 'd be .
C: so , , done with that ? does any forget , does anybody , , working on any eurospeech submission related to this ?
E: would like to try to do something on digits but if we have time . it 's due next friday so we have to do the experiments and write the paper . so , 'm gonna try , we 'll just have to see . so actually wanna get together with both andreas and , , stephane with their respective systems .
C: there was that we that 's right , we had that one conversation about , , what what did it mean for , , one of those speakers to be pathological ,
E: and haven't had chance to sit down and listen .
F: haven't haven't listened to them either ,
E: was going to do that this afternoon .
F: but there must be something wrong ,
E: morgan and were having debate about that . whereas it 's probably something pathologic and actually stephane 's results , confirm that . he he did the aurora system also got very lousy average error , like fifteen or , , fifteen to twenty percent average ? but then he ran it just on the lapel , and got about five or six percent word error ? so that means to me that somewhere in the other recordings there are some pathological cases . but , , we th that may not be true . it may be just some of the segments they 're just doing lousy job on . so 'll 'll listen to it and find out since you 'd actually split it up by segment . so actually listen to it .
B: did you run the andreas the sri recognizer on the digits ?
E: he had sent that around to everyone , did you just sent that to me ?
F: no , didn't . since considered those preliminary , didn't . but , , if you take
E: it was bimodal .
F: it 's actually , , it it was trimodal , actually
E: was it trimodal , .
C: there 's zero , little bit , and lot .
F: there were there was there was one one bump at ze around zero , which were the native speakers ,
B: zero percent error ?
F: the non - pathological native speakers . then there was another bump at , , , like fifteen .
B: this is error you 're talking about ?
C: was it fifteen ?
F: those were the non - natives . and then there was another distinct bump at , like , hundred , which must have been some problem .
G: what is patho what do you mean by pathological ?
E: just just something really wrong with bug is what , so that it 's like
F: and there was this one meeting , forget which one it was , where like , , six out of the eight channels were all , like had hundred percent error .
E: which probably means like there was th the recording interface crashed , or there was short , someone was jiggling with cord or , , extracted it incorrectly , it was transcribed incorrectly , something really bad happened , and haven't listened to it yet to find out what it was .
F: so , if excluded the pathological ones , by definition , those that had like over ninety - five percent error rate , and the non - natives , then the average error rate was like one point four ,
C: what we 're calling .
F: which seemed reasonable given that , , the models weren't tuned for it . and the grammar wasn't tuned either .
B: and it didn't matter whether it was the lapel or whether it was the
F: it was just @ @ . haven't split it up that way ,
D: but there 's no overlap during the digit readings , so it shouldn't really matter .
F: but it would be
C: no , but there 's little difference ,
E: there 's lot .
C: and we haven't looked at it for digits ,
B: so was curious about that .
C: cuz because what he was what was saying when looked at those things is it was almost gonna call it quadrimodal because there was whole lot of cases where it was zero percent . they just plain got it all right . and then there and then there was another bunch that were couple percent .
F: but if you if you actually histogrammed it , and it was , , it was zero was the most of them , but then there were the others were decaying from there . and then there was the bump for the non - natives and then the pathological ones ,
E: cuz some of our non - natives are pretty non - native .
A: you did you have , , something in the report about , , about , , for , forced alignment ? have you have you started on that ?
F: , , so 've been struggling with the forced alignments . so the scheme that drew on the board last time where we tried to , allow reject models for the speech from other speakers , most of the time it doesn't work very . so , , and the haven't done , the only way to check this right now was for me to actually load these into waves and , , plus the alignments , and play them and see where the and it looks and so looked of the utterances from you , chuck , in that one conversation , which you probably know which one , it 's where you were on the lapel and morgan was sitting next to you and we can hear everything morgan says . but and some of what you , you also appear quite bit in that cross - talk . so , actually went through all of those , there were fifty - five segments , , in waves , and did crude check , and more often than not , it gets it wrong . so there 's either the beginning , mostly the beginning word , where th you , , , chuck talks somewhere into the segment , but the first , , word of what he says , often "" "" but it 's very reduced "" , "" that 's just aligned to the beginning of someone else 's speech , in that segment , which is cross - talk . so , , 'm still tinkering with it , but it might be that we can't get clean alignments out of this out of those , , channels ,
C: unless maybe we do this , , , cancellation business .
D: right , but that 's , that was our plan , but it 's clear from dan that this is not something you can do in short amount of time .
C: the short amount of time thing , right .
D: so we , we had spent lot of time , , writing up the hlt paper and we wanted to use that , , analysis , but the hlt paper has , , it 's very crude measure of overlap . it 's not really something you could scientifically say is overlap , it 's just whether or not the , , the segments that were all synchronized , whether there was some overlap somewhere . and , , that pointed out some differences , so he thought if we can do something quick and dirty because dan said the cross - cancellation , it 's not straight - forward . if it were straight - forward then we would try it , so , it 's good to hear that it was not straight - forward , thinking if we can get decent forced alignments , then at least we can do overall report of what happens with actual overlap in time ,
B: didn't think that his message said it wasn't straight - forward .
E: if we 'd just
B: he 's just saying you have to look over longer time window when you do it .
D: and the but there are some issues of this timing , , in the recordings
B: so you just have to look over longer time when you 're trying to align the things , you can't you can't just look
E: are you talking about the fact that the recording software doesn't do time - synchronous ? is that what you 're referring to ? that seems to me you can do that over the entire file and get very accurate
F: don't thi don't think that was the issue .
D: that was side issue .
F: the issue was that you have to you have you first have to have pretty good speech detection on the individual channels .
D: and it 's dynamic , so it was more dynamic than some simple models would be able to so there are some things available , and too much about this area where if people aren't moving around much than you could apply them , and it should work pretty if you took care of this recording time difference .
E: right , which should be pretty straight forward .
D: which at least is defined , but then if you add the dynamic aspect of adapting distances , then it wasn't it just wasn't something that he could do quickly and not in time for us to be able to do something by two weeks from now , less than week . so , so what we can do if anything , that 's worth , , eurospeech paper at this point .
B: andreas , how did it work on the non - lapel ?
E: that 's what was gonna say .
F: haven't checked those yet . it 's very tedious to check these . we would really need , ideally , transcriber to time mark the , the be at least the beginning and ends of contiguous speech . and , , then with the time marks , you can do an automatic comparison of your of your forced alignments .
B: because really the at least in terms of how we were gonna use this in our system was to get an ideal an idea , , for each channel about the start and end boundaries . we don't really care about like intermediate word boundaries ,
F: no , that 's how 've been looking at it . don't care that the individual words are aligned correctly , but you don't wanna , , infer from the alignment that someone spoke who didn't .
B: right , exactly . so that 's why was wondering if it maybe if it doesn't work for lapel , we can just not use that
F: haven't ha just haven't had the time to , , do the same procedure on one of the so would need would need channel that has speaker whose who has lot of overlap but , is non - lapel mike . and , , where preferably , also there 's someone sitting next to them who talks lot .
E: so meeting with me in it .
F: maybe someone can help me find good candidate and then would be willing to
B: maybe the best way to find that would be to look through these . cuz you can see the seat numbers , and then you can see what type of mike they were using . and so we just look for , , somebody sitting next to adam at one of the meetings
D: actually we can tell from the data that we have ,
F: from the insertions , maybe ?
D: , there 's way to tell . it might not be single person who 's always overlapping that person but any number of people , and , , if you align the two hypothesis files across the channels , , just word alignment , you 'd be able to find that . so so that 's last ther there 're few things we could do . one is just do like non - lapels if we can get good enough alignments . another one was to try to get somehow align thilo 's energy segmentations with what we have . but then you have the problem of not knowing where the words are because these meetings were done before that segmentation . but maybe there 's something that could be done .
B: what what is why do you need the , , the forced alignment for the hlt for the eurospeech paper ?
D: wanted to just do something not on recognition experiments because that 's ju way too early , but to be able to report , , actual numbers . like if we if we had hand - transcribed pe good alignments or hand - checked alignments , then we could do this paper . it 's not that we need it to be automatic . but without knowing where the real words are , in time
B: so it was to get it was to get more data and better to squeeze the boundaries in .
D: to to an overlap really if it 's really an overlap , or if it 's just segment correlated with an overlap , and that 's the difference to me between like real paper and , promissory paper . so , , if we it might be possible to take thilo 's output and like if you have , , like right now these meetings are all ,
E: forgot the digital camera again .
D: they 're time - aligned , so if these are two different channels and somebody 's talking here and somebody else is talking here , just that word , if thilo can tell us that there 're boundaries here , we should be able to figure that out because the only thing transcribed in this channel is this word . but , , , if there are things if you have two and they 're at the edges , it 's like here and here , and there 's speech here , then it doesn't really help you ,
B: thilo 's won't put down two separate marks in that case
D: it it would , but , , we exactly where the words are because the transcriber gave us two words in this time bin
E: thilo 's will . but .
D: and we don't really know ,
A: it 's merging problem . if you had if you had if you had script which would 've thought about this , and 've discussed 've discussed it with thilo ,
D: if you have any ideas .
A: the , , in principle could imagine writing script which would approximate it to some degree , but there is this problem of slippage ,
E: maybe maybe that will get enough of the cases to be useful .
D: that would be really helpful . that was another possibility .
E: cuz it seemed like most of the cases are the single word sorts , or at least single phrase
A: they can be stretched .
E: in most of the bins .
A: wouldn't make that generalization cuz sometimes people will say , "" and then "" and there 's long pause and finish the sentence and sometimes it looks coherent and the it 's it 's not simple problem . but it 's really and then it 's coupled with the problem that sometimes , , with fricative you might get the beginning of the word cut off and so it 's coupled with the problem that thilo 's isn't perfect either . we 've th it 's like you have merging problem plus so merging plus this problem of , , not if the speech - nonspeech were perfect to begin with , the detector , that would already be an improvement , but that 's impossible , , that 's too much to ask . and so and may , , it 's that there always th there would have to be some hand - tweaking , but it 's possible that script could be written to merge those two types of things . 've 've discussed it with thilo and in terms of not him doing it , but we discussed some of the parameters of that and how hard it would be to in principle to write something that would do that .
D: in the future it won't be as much as an issue if transcribers are using the tightened boundaries to start with , then we have good idea of where the forced alignment is constrained to .
A: it 's just , , matter of we had the revolution we had the revolution of improved , , interface , , one month too late ,
D: so 'm no if this
A: but it 's like , , it 's wonderful to have the revolution ,
D: it 's it 's
A: so it 's just matter of , , from now on we 'll be able to have things channelized to begin with .
E: and we 'll just have to see how hard that is .
A: that 's right .
E: so so whether the corrections take too much time .
A: that 's right .
E: was just thinking about the fact that if thilo 's missed these short segments , that might be quite time - consuming for them to insert them .
D: but he also can adjust this minimum time duration constraint and then what you get is noises mostly , but that might be ,
E: it might be easier to delete something that 's wrong than to insert something that 's missing .
D: and you can also see in the waveform
E: what do you think , jane ?
C: if you can feel confident that what the , that there 's actually something that you 're not gonna miss something ,
E: cuz then you just delete it , and you don't have to pick time .
A: the problem is it 's really good question , and really find it pain in the neck to delete things because you have to get the mouse up there on the on the text line and and otherwise you just use an arrow to get down it depends on how lar th there 's so many extra things that would make it one of them harder than the other , or vice versa . it 's not simple question . but , , , in principle , like , , if one of them is easier then to bias it towards whichever one 's easier .
E: the semantics aren't clear when you delete segment , because you would say you would have to determine what the surroundings were .
D: you could just say it 's noise , though , and write , , post - processor will just all you have to do is just
E: if it 's really noise .
D: or just say it 's just put "" , "" , like "" not speech "" ,
A: it 's easier to add than delete , frankly ,
D: and then you can get
A: because you have to , , maneuver around on the on both windows then .
E: to add or to delete ? that maybe that 's an interface issue that might be addressable .
A: it 's possible .
E: but it 's the semantics that are that are questionable to me , that you delete something so let 's say someone is talking to here , and then you have little segment here . is that part of the speech ? is it part of the nonspeech ? what do you embed it in ?
D: there 's something , though , about keeping , and this is probably another discussion , keeping the that thilo 's detector detected as possible speech and just marking it as not speech than deleting it . because then when you align it , then the alignment can you can put reject model or whatever ,
E: so then they could just like put that 's what you meant by just put an "" "" there .
D: and you 're consistent with th the automatic system ,
E: that 's an interesting idea .
D: whereas if you delete it
E: so so all they so th they would have to do is put like an "" "" there .
D: or some , , dummy reject mod
E: so blank for blank for silence , "" "" "" "" for speech , "" "" "" "" else .
D: that 's actually better way to do it cuz the the forced alignment will probably be more consistent than
A: like , there 's complication which is that you can have speech and noise in
D: if it 's just as easy ,
A: , on the same channel , the same speaker , so now sometimes you get ni microphone pop and , , , there 're these fuzzy hybrid cases , and then the problem with the boundaries that have to be shifted around . it 's not simple not simple problem .
D: anyway , quick question , though , at high level do people think , let 's just say that we 're moving to this new era of like using the , , pre - segmented , non - synchronous conversations , does it make sense to try to take what we have now , which are the ones that , , we have recognition on which are synchronous and not time - tightened , and try to get something out of those for purposes of illustrating the structure and the nature of the meetings , or is it better to just , , forget that and tr
E: we 'll have to , eventually . and my hope was that we would be able to use the forced alignment to get it .
D: that was everybody 's hope .
E: but if we can't
D: and maybe we can for the non - lapel , but
E: but if we can't , then maybe we just have to
D: if we can't then we can fake it even if we 're we report , , we 're wrong twenty percent of the time or ten percent of the time .
E: are you talking about for paper , or are talking about for the corpus .
D: that 's good question actually .
E: cuz for the corpus it would be if everything were
D: actually that 's good question because we 'd have to completely redo those meetings , and we have like ten of them now .
E: we wouldn't have to re - do them , we would just have to edit them .
A: and also , , still haven't still haven't given up on forced alignment .
D: no , you 're right ,
A: that when brian comes , this 'll be an interesting aspect to ask him as when brian kingsbury comes .
E: you you said ryan . and it 's like , "" who 's ryan ? ""
A: ryan could come .
D: no , that 's good point , though , because for feature extraction like for prosody , , the meetings we have now , it 's good chunk of data we need to get decent
A: that 's what my hope has been ,
D: so we should at least try it even if we can't ,
A: and that 's what , ever since the february meeting that transcribed from last year , forced alignment has been on the on the table as way of cleaning them up later .
E: on the table ,
A: and and so 'm hopeful that 's possible . know that there 's complication in the overlap sections and with the lapel mikes ,
D: we might be able , at the very worst , we can get transcribers to correct the cases where you have good estimate where these places are because the recognition 's so poor .
B: we were never just gonna go with these as the final alignments .
D: and so you 're
B: we were always gonna run them past somebody .
D: so we need some way to push these first chunk of meetings into state where we get good alignments .
F: 'm probably going to spend another day or so trying to improve things by , , by using , , acoustic adaptation . the right now 'm using the unadapted models for the forced alignments , and it 's possible that you get considerably better results if you , , manage to adapt the , , phone models to the speaker and the reject model to the to all the other speech .
B: could you could you at the same time adapt the reject model to the speech from all the other channels ?
C: that 's what he just said .
E: that 's what he was saying .
F: that 's what said .
B: not just the speech from that of the other people from that channel , but the speech from the actual other channels .
E: don't think that would work , lot of it 's dominated by channel properties .
D: but what you do wanna do is take the , even if it 's klugey , take the segments the synchronous segments , the ones from the hlt paper , where only that speaker was talking .
F: so you want to
D: use those for adaptation , cuz if you if you use everything , then you get all the cross - talk in the adaptation , and it 's just blurred .
F: that 's good point .
D: and that we know , , we have that . and it 's about roughly two - thirds , , very roughly averaged . that 's not completely negligible . like third of it is bad for adaptation or so .
E: it was higher than that , that 's pr
D: it really it depends lot . this is just an overall
C: we 're not turning in to eurospeech , redo of the hlt paper . that don't wanna do that ,
E: 'm doing that for avios .
D: but we 're , morgan 's talk went very , .
E: "" bleep "" .
D: morgan 's talk went very it woke it was really presented and got people laughing
F: some good jokes in it ?
E: especially the batteried meter popping up , that was hilarious . right when you were talking about that .
C: that wa that was the battery meter saying that it was fully charged ,
E: it 's full .
A: you said , "" speaking about energy "" , .
E: but that was funny .
A: that was very .
E: he he was onto the bullet points about talking about the the little hand - held , and trying to get lower power and so on ,
F: po - low power
E: and microsoft pops up little window saying "" your batteries are now fully charged . ""
A: that 's great .
E: 'm thinking about scripting that for my talk , , put little script in there to say "" your batteries are low "" right when 'm saying that .
C: no , in your case , , you were joking about it , but , , your case the fact that your talking about similar things at couple of conferences , it 's not these are conferences that have really different emphases . whereas hlt and eurospeech , pretty pretty similar , so 't see really just putting in the same thing ,
E: are too close ,
D: no , don't think that paper is really the hlt paper is really more of introduction - to - the - project paper , and ,
E: for eurospeech we want some results if we can get them .
D: , it 's probably wouldn't make sense ,
C: or some or some would see eurospeech if we have some eurospeech papers , these will be paper , submissions . these will be things that are particular things , aspects of it that we 're looking at , rather than , , attempt at global paper about it .
D: right , right .
A: did go through one of these meetings . had , , one of the transcribers go through and tighten up the bins on one of the , , nsa meetings , and then went through afterwards and double - checked it so that one is really very accurate . men mentioned the link . sent that one ?
G: the which one ?
A: 'm trying to remember don't remember the number off hand . it 's one of the nsa 's . sent email before the conference , before last week . bef - what is wednesday , thursday .
D: that might have been the one of the ones that we did .
A: 'm that one 's accurate , 've been through it myself .
D: so that might actually be useful but they 're all non - native speakers .
F: so we could compare before and after
E: that 's what was gonna say . the problem with those , they 're all german .
G: that 's the problem with the nsa speakers .
D: and and extremely hard to follow , like word - wise , bet the transcri , have no idea what they 're talking about ,
A: corrected it for number of the words . 'm that , , they 're they 're accurate now .
F: actually have to go .
D: this is tough for language model probably but that might be useful just for speech .
E: andreas is leaving the building .
C: don't think we 'll go much longer .
E: , before you go it 's alright for you to talk little without the mike noticed you adjusting the mike lot , did it not fit you ?
A: won noticed when you turned your head , it would it would tilt .
E: maybe it wasn't just tightened enough , or
D: maybe the , the thing that you have tightened @ @ ,
B: actually if you have larger head , that mike 's gotta go farther away which means the balance is gonna make it wanna tip down .
E: cuz , 'm just thinking , , we were we 're we 've been talking about changing the mikes , , for while , and if these aren't acoustically they seem really good , but if they 're not comfortable , we have the same problems we have with these stupid things .
A: this is the first time 've worn this , find it very comfortable .
E: find it very comfortable too , but , , it looked like andreas was having problems , and morgan was saying it
C: but had it on had it on this morning and it was fine .
B: can see that ?
E: you did wear it this morning ? it 's off , so you can put it on .
B: don't want it on , want to , , say what is problem with this . if you are wearing this over your ears and you 've got it all the way out here , then the balance is gonna want to pull it this way . where as if somebody with smaller head has it back here ,
E: it 's more balanced .
B: then it then it falls back this way so it 's
D: so we have to
E: wh what it 's supposed to do is the backstrap is supposed to be under your crown , and so that should be should be if it 's right against your head there , which is what it 's supposed to be , that balances it so it doesn't slide up .
B: so this is supposed to be under that little protuberance .
E: if you feel the back of your head , you feel little lump , and so it 's supposed to be right under that .
B: so it 's really supposed to go more like this than like this .
E: yes , exactly .
B: but then isn't that going to you can control that .
E: that that tilts , in lots and lots of different ways .
D: so 'm not saying anything about bias towards small headsize , but does seem ,
B: it would be an advantage .
A: wonder if it 's if he was wearing it over his hair instead of under his hair .
C: we should we shou we should work on compressing the heads , and
E: it probably just wasn't tight enough to the back of his head . so the directions do talk about bending it to your size , which is not really what we want .
B: the other thing that would do it would be to hang five pound weight off the back .
C: that 's good !
A: what did you say ?
C: hang five pound weight off the off the back .
B: hang five pound weight off the back .
E: we at boeing used was doing augmented reality so they had head - mounts on , and we had little jury - rigged one with welder 's helmet ,
B: counter - balance .
E: and we had just bag with bunch of marbles in it as counter - balance .
C: or maybe this could be helpful just for evening the conversation between people . if people those who talk lot have to wear heavier weights , so , , what was gonna say ? , was gonna say , , had these , , conversations with nist folks also while was there and , , , so they have their plan for room , , with , , mikes in the middle of the table , and , , close - mounted mikes , and they 're talking about close - mounted and lapels , just cuz and the array .
D: which is the interesting
C: and , like multiple video cameras coverin covering every everybody every place in the room ,
D: and video , right .
C: the the mikes in the middle , the head - mounted mikes , the lapel mikes , the array , , with there 's some discussion of fifty - nine ,
E: fifty - nine elements .
C: they might go down to fifty - seven because , , there is , , some pressure from couple people at the meeting for them to use kemar head . forget what kemar , , stands for , but what it is it 's dummy head that is very specially designed ,
E: that 's right .
C: and and , so what they 're actually doing is they 're really there 's really two recording systems .
D: that 's great idea .
C: so they may not be precisely synchronous , but the but there 's two recording systems , one with , , twenty - four channels , and one with sixty - four channels . and the sixty - four channel one is for the array , but they 've got some empty channels there , and anyway they like they 're saying they may give up couple if for the kemar head if they go with that .
E: it is good idea . , jonathan fiscus did say that , , they have lots of software for doing calibration for skew and offset between channels and that they 've found that 's just not big deal .
C: 'm not too worried about that .
D: but they 're still planning to do like fake
E: scenario - based .
D: they have to do something like that ,
E: their their legal issues won't allow them to do otherwise . but it sounded like they were pretty thought out
D: th that 's true .
E: and they 're they 're gonna be real meetings , it 's just that they 're with str with people who would not be meeting otherwise .
B: did did they give talk on this or was this informal ?
C: no , we just had some discussions , various discussions with them .
E: it 's just informal . also sat and chatted with several of the nist folks . they seemed like good group .
B: what was the , the paper by , , lori lamel that you mentioned ?
C: , we sh we should just have you have you read it , but , mea ba , we 've all got these little proceedings , but , , , it was about , , , going to new task where you have insufficient data and using data from something else , and adapting , and how that works . so it was pretty related to what liz and andreas did , , except that this was not with meeting , it was with like they didn't they start off with broadcast news system ? and then they went to
E: the - their broadcast news was their acoustic models and then all the other tasks were much simpler . so they were command and control and that thing .
C: ti - digits was one of them , and , , wall street journal .
B: what was their rough what was their conclusion ?
E: read wall street journal .
D: it 's it 's good paper ,
E: that was one of the ones that liked . that it not only works , in some cases it was better , which was pretty interesting , but that 's cuz they didn't control for parameters . the broadcast news nets were not nets ,
B: did they ever try going the other direction from simpler task to more complicated tasks ,
E: acoustic models were lot more complex . not in that paper .
C: that might be hard .
E: , one of the big problems with that is often the simpler task isn't fully doesn't have all the phones in it , and that makes it very hard . but 've done the same thing . 've been using broadcast news nets for digits , like for the spr speech proxy thing that did ? that 's what did . so . it works .
C: and they have they have better adaptation than we had than that system ,
E: you mean they have some .
C: we should probably what would actually what we should do , , haven't said anything about this , but probably the five of us should pick out paper or two that , , , got our interest , and we should go around the room at one of the tuesday lunch meetings and say , , what was good about the conference ,
E: do trip report .
D: the summarization was interesting , anything about that field , but for this proposal on meeting summarization , , it 's far cry because they weren't working with meeting type data , but he got an overview on some of the different approaches ,
B: do you remember who the groups were that we 're doing ?
D: this was the last day ,
E: lot of different ones .
D: but , , there 's that 's huge field and probably the groups there may not be representative of the field , exactly that everyone submits to this particular conference ,
B: was were there folks from bbn presenting ?
D: yet there was , let 's see , this was on the last day , mitre , bbn , and , , prager
E: mitre , bbn , ibm .
C: columbia have anything ?
E: wasn't who who did the order one ?
D: this was wednesday morning . the sentence ordering one , was that barselou , and these guys ?
E: ugh ! 'm just so bad at that .
D: anyway , it 's in the program , should have read it to remind myself , but that 's useful and like when mari and katrin and jeff are here it 'd be good to figure out some kinds of things that we can start doing maybe just on the transcripts cuz we already have
E: we do have word transcripts .
A: like the idea that adam had of , , maybe generating minutes based on some of these things that we have because it would be easy to to do that it has to be , though , someone from this group because of the technical nature of the thing .
E: someone who actually does take notes , 'm very bad at note - taking .
D: but what 's interesting is there 's all these different evaluations , like just , , how do you evaluate whether the summary is good or not ,
E: always write down the wrong things .
A: do take notes .
D: and that 's what 's was interesting to me is that there 's different ways to do it ,
B: was sra one of the groups talking about summarization , no ?
D: hm - umm .
A: it was an interesting session .
E: and as said , like the microsoft talk on scaling issues in , , word sense disambiguation , that was interesting .
C: that was an interesting discussion ,
E: it it was the only one it was the only one that had any real disagreement about .
D: the data issue comes up all the ti
C: didn't have as much disagreement as would have liked , but didn't wanna wouldn didn't wanna get into it because , , , it was the application was one didn't know anything about , it just would have been , , me getting up to be argumentative , so what they were saying it 's one of these things is , all you need is more data , but mea wh it @ @ that 's that 's dissing it , , improperly , it was study . they were doing this it wasn't word - sense disambiguation , it was was it was it word - sense ?
E: but it was it was very simple case of "" to "" versus "" too "" versus "" two "" and "" there "" , "" their "" , "" they 're ""
D: and there and their and and that you could do better with more data , , that 's clearly statistically
C: and so , what they did was they had these different kinds of learning machines , and they had different amounts of data , and so they did like , , eight different methods that everybody , , , argues about , "" my learning machine is better than your learning machine . "" and , , they were started off with million words that they used , which was evidently number that lot of people doing that particular task had been using . so they went up , being microsoft , they went up to billion . and then they had this log scale showing and naturally everything gets
E: them being beep , they went off to billion .
C: it 's big company , didn't didn't mean it as ne anything negative ,
D: you mean the bigger the company the more words they use for training ?
E: the reason they can do that , is that they assumed that text that they get off the web , like from wall street journal , is correct , and edit it . so that 's what they used as training data . it 's just saying if it 's in this corpus it 's correct .
C: but , , yes . there was the effect that , , one would expect that that you got better and better performance with more and more data . but the real point was that the different learning machines are all over the place , and by going up significantly in data you can have much bigger effect then by switching learning machines and furthermore which learning machine was on top depended on where you were in this picture ,
B: this was my concern about the recognizer in aurora . that the differences we 're seeing in the front - end is once you get real recognizer at the back - end .
D: if you add more data ?
C: so so , , that was that was , , it 's good point , but the problem had with it was that the implications out of this was that , , the choices you make about learning machines were therefore irrelevant which is not at as for as tasks 'm more familiar with @ @ is not true . what what is true is that different learning machines have different properties , and you wanna those properties are . and someone else implied that we , all the study of learning machine we still what those properties are . we them perfectly , but we know that some kinds use more memory and some other kinds use more computation and some are hav have limited discrimination , but are just easy to use , and others are
B: but doesn't their conclusion just you could have guessed that before they even started ? because if you assume that these learning things get better and better , then as you approach there 's point where you can't get any better , you get everything right .
D: it 's just no
B: so they 're all approaching .
E: no , but there was still spread . they weren't all up they weren't converging .
B: but what 'm saying is that th they have to , as they all get better , they have to get closer together .
E: they were all still spread . right , right . but they hadn't even come close to that point . all the tasks were still improving when they hit billion .
B: but they 're all going the same way , so you have to get closer .
E: but they didn't get closer . they just switched position .
C: that 's getting cl the spread was still pretty wide that 's th that 's true , but , , it would be irntu intu intuition that this would be the case , but , , to really see it and to have the intuition is quite different , somebody let 's see who was talking about earlier that the effect of having lot more data is quite different in switchboard than it is in broadcast news ,
D: it 's different for different tasks .
E: it was liz .
D: so it depends lot on whether , , it disambiguation is exactly the case where more data is better , you 're you can assume similar distributions , but if you wanted to do disambiguation on different type of , , test data then your training data , then that extra data wouldn't generalize ,
E: but , one of their they they had couple points . one of them was that "" , maybe simpler algorithms and more data are is better "" . because their simplest , most brain - dead algorithm did pretty darn when you got gave it lot more data . and then also they were saying , "" , you have access to lot more data . why are you sticking with million words ? "" their point was that this million - word corpus that everyone uses is ten or fifteen years old . and everyone is still using it ,
C: but anyway , it 's it 's just the it 's it 's not really the conclusion they came to so much , as the conclusion that some of the , , commenters in the crowd came up with
E: but we could talk about this , this would be fun to do .
C: that , , , this therefore is further evidence that , , more data is really all you should care about , and that was just going too far the other way ,
E: machine - learning .
C: and the , , one person ga got up and made brief defense , but it was different grounds , it was that , , the reason people were not using so much data before was not because they were stupid or didn't realize data was important , but th they didn't have it available . but the other point to make again is that , , machine learning still does matter , but it matters more in some situations than in others , and it and also there 's there 's not just mattering or not mattering , but there 's mattering in different ways . you might be in some situation where you care how much memory you 're using , or you care , , what recall time is , or you care , , and
E: or you only have million words for your some new task .
D: or done another language , or you so there 's papers on portability and rapid prototyping and blah - blah , and then there 's people saying , "" , just add more data . ""
C: and there 's cost !
D: these are like two different religions , .
C: there 's just plain cost ,
E: that 's big one .
C: so these , th the in the speech side , the thing that @ @ always occurs to me is that if you one person has system that requires ten thousand hours to train on , and the other only requires hundred , and they both do about the same because the hundred hour one was smarter , that 's that 's gonna be better . because people , , there isn't gonna be just one system that people train on and then that 's it for the for all of time . people are gonna be doing other different things , and so it these things matters matter .
A: that 's it .
E: so that 's one of the slides they put up .
A: so , , this was very provocative slide . she put this up , and it was like this is this people kept saying , "" can see that slide again ? "" and then they 'd make comment , and one person said , - known person said , , , "" before you dismiss forty - five years including my work ""
E: forty - five years of research .
D: but th , the same thing has happened in computational linguistics , you look at the acl papers coming out , and now there 's turn back towards , we 've learned statistic we 're getting what we expect out of some statistical methods , the there 's arguments on both sides ,
E: the matters is the thing that was misleading .
A: that was very offending ,
E: is th of them are based on all the others , just , you can't say
B: maybe they should have said "" focus "" .
E: and 'm saying the same thing happened with speech recognition , for long time people were hand - coding linguistic rules and then they discovered machine - learning worked better . and now they 're throwing more and more data and worrying perhaps worrying less and less about , , the exact details of the algorithms .
D: and and then you hit this
E: except when they have eurospeech paper .
C: tea is tea is , , starting .
E: shall we read some digits ? are we gonna do one at time ? or should we read them all agai at once again .
C: let 's do it all at once .
A: that 's good .
C: we @ @ let 's try that again .
D: so , and maybe we won't laugh this time also .
E: so remember to read the transcript number so that , , everyone knows that what it is . three , two , one .
C: boy , is that ever efficient .
E: that 's really fast .
","The Berkeley Meeting Recorder group discussed the preparation of a data sample for IBM , the manual adjustment of time bins by transcribers , recognition results for a test set of digits data , and forced alignments.
Participants also talked about Eurospeech 2001 submissions , and exchanged comments on the proceedings of the recently attended Human Language Technologies conference ( HLT'01 ).
Preliminary recognition results were presented for a subset of digits data.
Efforts to deal with cross-talk and improve forced alignments for non-digits data were also discussed.
Subsequent manual adjustment of speech and non-speech boundaries will be delegated to the transcriber pool.
A subset of Meeting Recorder data will be prepared ( i.e . pre-segmented and manually adjusted ) for delivery to IBM.
The Transcriber interface may require modifications if it becomes necessary for transcribers to quickly switch among waveform displays.
Transcribers risk overlooking speech that is deeply embedded in the mixed signal.
Should transcriptions be derived from each of the close-talking channels or from the mixed signal alone?
The pre-segmentation tool does not perform well on short utterances , e.g . backchannels.
The Transcriber interface does not allow the user to quickly switch among visual displays , i.e . multi-channel waveforms.
Forced alignments were problematic for non-digits data due to cross-talk.
This problem was reported to be particularly bad for cross-talk featuring more than one word.
Echo cancellation was considered as a means of improving forced alignments , but was ultimately deemed to be too time-consuming given the dynamic aspect of adapting distances between speakers.
Comparing error rates in terms of the recording device used , i.e . lapel versus wireless microphones , is tedious.
Deleting segments of the recordings is expected to be very time-consuming for transcribers.
More results are needed for generating adequate submissions for Eurospeech'01.
Participants have complained that the head-mounted microphone is uncomfortable.
One meeting recording has been channelized and pre-segmented for delivery to IBM.
A sample of digits data is being prepared for IBM.
Preliminary recognition results were obtained for a subset of digits data.
The error rate distribution was multimodal , reflecting differences in performance for native versus non-native speakers , and also possible pre-processing errors.
Future efforts will involve an attempt to get good forced alignments on digits data and generate a report for Eurospeech'01.
A program has been developed for replacing sections of recorded speech with editing bleeps.
The tightening of time bins for one NSA meeting was checked and judged to be highly accurate.
Efforts are ongoing to improve forced alignments for a subset of non-digits data , including acoustic adaptation manipulations.
"
ami_abstractive_summary,Bmr027.txt,"C: adam , what is the mike that , , jeremy 's wearing ?
F: it 's the ear - plug mike .
A: ear - plug .
E: that 's good .
C: is that wireless ,
G: it 's wired .
A: is that does that mean you can't hear anything during the meeting ?
D: it 's old - school .
F: ? what ? ?
B: should we , , close the door , maybe ?
F: it it 's fairly good mike , actually . shouldn't say it 's good mike . all really that the signal level is . so didn't send out agenda items because until five minutes ago we only had one agenda item and now we have two . so . and , .
B: so , just to repeat the thing bef that we said last week , it was there 's this suggestion of alternating weeks on more , , automatic speech recognition related or not ? was that the division ? so which week are we in ?
F: we haven't really started , but we more we more or less did meeting recorder last week , so we could do ,
B: we had thing about speech recognition last week too .
F: but figure also if they 're short agenda items , we could also do little bit of each . seem to be having difficulty getting this adjusted . here we go . so , , as most of you should know , did send out the consent form thingies so far no one has made any ach ! any comments on them . so , no on no one has bleeped out anything . don't expect anyone to .
B: so , what follows ? at some point you go around and get people to sign something ?
F: we had spoken about this before
B: but 've forgotten .
F: and we had decided that they have they only needed to sign once . and the agreement that they already signed simply said that we would give them an opportunity . so as long as we do that , we 're covered .
B: and how long of an opportunity did you tell them ? so they have plenty of time , given that it 's that long , why was that date chosen ? you just felt you wanted to ?
F: jane told me july fifteenth . so , that 's what set it .
A: meant that was the release date that you had on the data .
F: didn't understand that there was something specific . had heard july fifteenth , so that 's what put .
B: no , the only th the only mention recall about that was just that july fifteenth or so is when this meeting starts .
A: that 's right . that 's why . you said you wanted it to be available then . didn't mean it to be the hard deadline . it 's fine with me if it is , but it might be good to remind people two weeks prior to that in case , , "" this is your last ""
B: we probably should have talked about it , cuz because if we wanna be able to give it to people july fifteenth , if somebody 's gonna come back and say "" , don't want this and this used "" , , clearly we need some time to respond to that .
F: as said , we got one date and that 's the one used . so . but send follow - up . it 's almost all us . the people who are in the meeti this meeting was , , these the meetings that in are in set one .
C: was my was my response ?
A: that 's right .
C: wrote you replied to the email saying they 're all fine .
F: right . , that 's fine . we don't my understanding of what we had upon when we had spoken about this months ago was that , , we don't actually need reply .
C: that makes it easy .
F: we just need to tell them that they can do it if they want . and so no reply is no changes .
A: and he 's got it so that the default thing you see when you look at the page is "" "" . so that 's very clear all the way down the page , "" "" . and they have two options they can change it to . one of them is "" censor "" , and the other one is "" incorrect "" . is it is your word is "" incorrect "" ? which means also we get feedback on if , there 's something that they that needs to be adjusted , because , , these are very highly technical things . it 's an added , , level of checking on the accuracy of the transcription , as see it . but in any case , people can agree to things that are wrong .
F: the reason did that it was just so that people would not censor not ask to have removed because it was transcribed incorrectly ,
A: and the reason liked it was because
F: as opposed to ,
A: was because it , it gives them the option of , , being able to correct it . approve it and correct it . so , you have it nicely set up so they email you
F: when they submit the form , it gets processed and emailed to me .
A: - . - . and wanted to say the meetings that are involved in that set are robustness and meeting recorder . the german ones will be ready for next week . those are three of those . different set of people . and we can impose
C: the german ones ?
A: the the german , french , the german , dutch , and spanish ones .
C: those are the nsa meetings ?
E: the non - native
B: german , dutch , swiss and spanish .
E: the all non - native
A: that 's that 's it 's the other group .
B: it was the network services group .
A: didn't mean to isolate them .
B: otherwise known as the german , dutch , and spanish .
A: it was it was not the best characterization . but what to say was that it 's the other group that 's not no no overlap with our present members . and then maybe it 'd be good to set an explicit deadline , something like week before that , july fifteenth date , or two weeks before .
B: would suggest we discuss if we 're going to have policy on it , that we discuss the length of time that we want to give people , so that we have uniform thing . so , tha that 's month , which is fine .
F: the only thing said in the email is that the data is going to be released on the fifteenth . didn't give any other deadline . so my feeling is if someone after the fifteenth says , "" suddenly found something "" , we 'll delete it from our record . we just won't delete it from whatever 's already been released .
A: that 's little bit difficult .
F: what else can we do ? if someone says "" hey , look , found something in this meeting and it 's libelous and want it removed "" . what can we do ?
A: that 's true .
F: we have to remove it .
A: agree with that part , but that it would it , we need to have , , message to them very clearly that beyond this date , you can't make additional changes .
B: that somebody might request something even though we say that . but it 's good to at least start some place like that .
A: - . good .
B: so if we , , how long is reasonable amount of time for people to have if we say two weeks , or if we say month , we should just say that say that , , as , "" per the the , , page you signed , you have the ability to look over this "" and "" and , , because we "" these , would would imagine some generic thing that would say "" because we , , will continually be making these things available to other researchers , , this can't be open - ended and so , , give us back your response within this am , within this amount of time "" , whatever time we agree upon .
F: did you read the email and look at the pages sent ?
B: no , haven't yet .
F: no . , why don't you do that and then make comments on what you want me to change ?
B: no , no . 'm not saying that you should change anything . 'm what 'm 'm trying to spark discussion hopefully among people who have read it so that you can you can , , decide on something . so 'm not telling you what to decide . 'm just saying you should decide something ,
F: already did decide something , and that 's what 's in the email . and if you disagree with it , why don't you read it and give me comments on it ?
A: that there 's one missing line .
B: the one thing that did read and that you just repeated to me was that you gave the specific date of july fifteenth . and you also just said that the reason you said that was because someone said it to you . so what 'm telling you is that what you should do is come up with length of time that you guys enough and you should use that rather than this date that you just got from somewhere . that 's all 'm saying .
A: ha have one question . this is in the summer period and presumably people may be out of town . but we can make the assumption , can't we ? that , , they will be receiving email , , most of the month .
B: it , it , you 're right . sometimes somebody will be away and , , , there 's , for any length of time that you , choose there is some person sometime who will not end up reading it . that 's it 's , , just certain risk to take .
H: am on , ?
F: you should be .
H: hello ? hello ?
F: you should be channel .
H: . alright . so . the , maybe we should say in when the whole thing starts , when they sign the agreement that specify exactly , what , , how they will be contacted and they can , they can be asked to give phone number and an email address , or both . and , , then
A: we did that , believe .
H: so . and , then , , say very clearly that if they don't if we don't hear from them , , as morgan suggested , by certain time or after certain period after we contact them that is implicitly giving their agreement .
F: they 've already signed form .
A: and the form says
E: and nobody really reads it anyway .
F: and the and the form was approved by human subjects ,
H: if that 's tha if that 's already if
F: so , , that 's gonna be little hard to modify .
A: the form , the form doesn't say , if , , "" if you don't respond by number of days or number of weeks ""
H: so what does it say about the the process of , the review process ?
A: it doesn't have time limit . that you 'll be provided access to the transcripts and then , , allowed to remove things that you 'd like to remove , before it goes to the general , larger audience . there you go .
F: you can read what you already signed .
E: when read it , 'm not as diligent as chuck , but had the feeling should probably respond and tell adam , like , "" got this and will do it by this date , and if you don't hear from me by then "" , in other words responding to your email once , right away , saying "" as soon as you get this could you respond . "" and then if you if the person thinks they 'll need more time because they 're out of town or whatever , they can tell you at that point ?
F: didn't wanna do that , because don't wanna have discussion with every person if avoid it . so what wanted to do was just send it out and say "" on the fifteenth , the data is released , if you wanna do something about it , do something about it , but that 's it "" .
E: so , we 're assuming that
H: that 's that would be great if but you should probably have legal person look at this and make it 's . because if you if you , , do this and you then there 's dispute later and , , some , someone who understands these matters concludes that they didn't have , , , enough opportunity to actually exercise their right
E: or they might never have gotten the email , because although they signed this , they by which date to expect your email . and so someone whose machine is down or whatever in internally we know that people are there ,
F: . let me let me reverse this .
E: but we have no confirmation that they got the mail .
F: so let 's say someone send this out , and someone doesn't respond . do we delete every meeting that they were in ?
E: it we 're hoping that doesn't happen , but that 's why there 's such thing as registered mail
F: that will happen .
H: that will happen .
F: that will happen . because people don't read their email , or they 'll read and say "" don't care about that , 'm not gonna delete anything "" and they don just won't reply to it .
H: maybe , do we have mailing addresses for these people ?
F: we have what they put on the speaker form , which was just generic contact information .
A: but the ones that we 're dealing with now are all local , except the ones who we 're in contact with all the ones in those two groups . so maybe , , , that 's not that many people and if if , there is an advantage to having them admit and if help with processing that , will . it 's it 's there is an advantage to having them be on record as having received the mail and indicating
F: we had discussed this , like , year ago .
A: yes , we did .
F: and so it seems like this is little odd for it to be coming up yet again .
A: you 're right .
B: we haven't experienced it before .
A: that 's right .
E: you 'll either wonder at the beginning or you 'll wonder at the end .
A: need to get it right .
E: there 's no way to get around it 's the same am amount of work except for an additional email just saying they got the email . and maybe it 's better legally to wonder before little bit earlier than
A: it 's much easier to explain this way .
F: , why don't you talk
A: to have it on record .
F: morgan , can you talk to our lawyer about it , and find out what the status is on this ? cuz don't wanna do something that we don't need to . what 'm telling you , people won't respond to the email . no matter what you do , you there 're gonna be people who you 're gonna have to make lot of effort to get in contact with .
A: then we make the effort .
F: and do we want to spend that effort ?
A: we make the effort .
D: it 's like signing up for mailing list . they have opt in and opt out . and there are two different ways . and either way works
A: except really this case 'm agr agree with liz , that we need to be in the clear and not have to after the fact say "" , but assumed "" , and "" , 'm that your email address was just accumulating mail without notifying you "" ,
B: if this is purely administrative task , we can actually have administration do it . but that , , , without going through whole expensive thing with our lawyers , from my previous conversations with them , my sense very much is that we would want something on record as indicating that they actually were aware of this .
F: we had talked about this before and that we had even gone by the lawyers asking about that and they said you have to they 've already signed away the with that form that they 've already signed once .
A: don't remember that this issue of the time period allowed for response was ever covered .
B: we never really talked about that .
E: or the date at which they would be receiving the email from you .
A: or or how they would indicate
E: they probably forgot all about it .
B: we certainly didn't talk , , about with them about , , the manner of them being made the , , materials available .
H: we do it like with these
B: that was something that was just within our implementation .
H: we can use it we can use ploy like they use to , that when they serve , like like dead - beat dads , they they make it look like they won something in the lottery and then they open the envelope
D: and they 're served .
H: because and then the served . so you just make it , , "" , you won go to this web site and you 've , you 're ""
E: that 's why you never open these things that come in the mail .
F: it 's just , we 've gone from one extreme to the other , where at one point , few months ago , morgan was you were saying let 's not do anything ,
H: right . right . no , it it might
A: it doesn't matter .
H: it might be the case
F: and now we 're we 're saying we have to follow up each person and get signature ? what are we gonna doing here ?
H: it might be the case that this is perfectly , this is enough to give us basis to just , , assume their consent if they don't reply . but , 'm not , me not being lawyer , wouldn't just wanna do that without having the expert , , opinion on that .
A: and how many people ? al - altogether we 've got twenty people . these people are people who read their email almost all the time .
F: then we had better find out , so that we can find
B: let me look at this again .
A: really don't see that it 's problem . that it 's common courtesy to ask them , to expect for them to , , be able to have @ @ us try to contact them , just in case they hadn't gotten their email . they 'd appreciate it .
B: my adam , my view before was about the nature of what was of the presentation , the things that we 're questioning were along the lines of how easy how how much implication would there be that it 's likely you 're going to be changing something , as opposed to that was the dispute was making before . but , , the attorneys , , guarantee you , the attorneys will always come back with and we have to decide how stringent we want to be in these things , but they will always come back with saying that , , you need to you want to have someth some paper trail or which includes electronic trail that they have , , 'd it . that if you if we send the email as you have and if there 's half the people , say , who don't respond by , , some period of time , we can just make list of these people and hand it to , just give it to me and 'll hand it to administrative staff or whatever , and they 'll just call them up and say , , "" have you is is this ? and would you mail , mail adam that it is , if if it , , is or not . "" so , , we can we can do that .
E: the other thing that there 's psychological effect that at least for most people , that if they 've responded to your email saying "" yes , will do it "" or "" yes , got your email "" , they 're more likely to actually do it later than to just ignore it . and we don't want them to bleep things out , but it 's little bit better if we 're getting the their , , final response , once they 've answered you once than if they never answer you 'd at al . that 's how these mailing houses work . so , , it 's not completely lost work because it might benefit us in terms of getting responses . an official from somebody is better than no answer , even if they responded that they got your email . and they 're probably more likely to do that once they 've responded that they got the email .
A: also think they 'd just simply appreciate it . it 's good good way of fostering goodwill among our subjects .
B: the main thing is , what lawyers do is they always look at worst cases .
F: sending lots of spam .
B: so they so tha - that 's what they 're paid to do . and so , it is certainly possible that , , somebody 's server would be down and they wouldn't actually hear from us , and then they find this thing is in there and we 've already distributed it to someone . so , what it says in there , , is that they will be given an opportunity to blah - blah , but if if we sent them something or we thought we sent them something but they didn't actually receive it for some reason , , then we haven't given them that .
F: so how far do we have to go ? do we need to get someone 's signature ? or , is email enough ?
B: email is enough .
F: do we have to have it notarized ?
B: 've been through this 'm not lawyer , but 've been through these things things like this few times with lawyers now so 'm pretty comfortable with that .
C: do you track , , when people log in to look at the ?
F: if they submit the form , get it . if they don't submit the form , it goes in the general web log . but that 's not sufficient . cuz if someone just visits the web site that doesn't imply anything in particular .
C: except that they got the mail .
A: - . that 's right . could get you on the notify list if you want me to .
F: 'm already on it .
A: for that directory ?
B: so again , hopefully , , this shouldn't be quite as odious problem either way , in any of the extremes we 've talked about because , we 're talking pretty small number of people .
F: for this set , 'm not worried , because we know everyone on it . they 're all more or less here or it 's it 's eric and dan and so on . but for some of the others , you 're talking about visitors who are gone from icsi , whose email addresses may or may not work , so what are we gonna do when we run into someone that we can't get in touch with ?
A: don't think , they 're so recent , these visitors . and they 're also so they 're prominent enough that they 're easy to find through 'll be able to if you have any trouble finding them , really could find them .
B: cuz it what it really does promise here is that we will ask their permission . and , , if you go into room and close the door and ask their permission and they 're not there , it doesn't seem that that 's the intent of , , meaning here .
F: the qu the question is just whether how active it has to be . because they filled out contact information and that 's where 'm sending the information . and so far everyone has done email . there isn't anyone who did , , any other contact method .
B: the way icsi goes , people , , who , , were here ten years ago still have acc have forwards to other accounts and so on . so it 's unusual that they ,
F: so my original impression was that was sufficient , that if they give us contact information and that contact information isn't accurate that we fulfilled our burden .
E: then they just come back .
C: all my files were still here .
E: same as us .
B: so if we get to boundary case like that then maybe will call the attorney about it . but , , hopefully we won't need to .
A: don't think we will . for all the reasons that we 've discussed .
B: so we 'll we 'll see if we do or not .
F: and we 'll see how many people respond to that email . so far , two people have .
B: very few people will and and , , people see long emails about things that they don't gonna be high priority , they typically , , don't don't read it , or half read it . cuz people are swamped .
A: so that 's why didn't give this comment , and it this discussion has made me might be to have follow - up email within the next couple of days saying "" , , we wanna hear back from you by date and then add what liz said "" , , respond to indicate you received this mail . ""
B: or , maybe even additionally , , , "" even if you 've decided you have no changes you 'd like to make , if you could tell us that "" .
F: respond to the email . .
A: it is the first time through the cycle .
E: right . that would that would definitely work on me . it makes you feel like , if you were gonna if you 're predicting that you might not answer , you have chance now to say that . whereas , , would be much more likely myself ,
C: and the other th
E: given all my email , to respond at that point , saying "" what , 'm probably not gonna get to it "" or whatever , rather than just having seen the email , thinking might get to it , and never really , , pushing myself to actually do it until it 's too late .
C: was thinking that it also lets them know that they don't have to go to the page to accept this .
E: right . right . that 's true .
C: so that way they could they can see from that email that if they just write back and say "" got it , no changes "" , they 're off the hook . they don't have to go to the web page
B: the other thing 've learned from dealing with dealing with people sending in reviews and , , is , , if you say "" you 've got three months to do this review "" , , people do it , , two and seven eighths months from now .
E: that 's true .
B: if you say "" you 've got three weeks to do this review "" , they do it , , two and seven eighths weeks from now they do the review . and , so , if we make it little less time , don't 'll be that much
F: and also if we want it ready by the fifteenth , that means we better give them deadline of the first , if we have any prayer of actually getting everyone to respond in time .
B: there 's the responding part and there 's also what if , , hope this doesn't happen , what if there are bunch of deletions that have to get put in and changes ? then we actually have to deal with that
A: - . some lead time .
B: if we want it to
A: has jeremy signed the form ?
F: hadn't thought about that . that for every meeting any meeting which has any bleeps in it we need yet another copy of .
C: just that channel .
D: can't you just do that channel ?
C: no . we have to do
F: no , not .
E: you have to do all of them ,
F: you need all the channels .
C: do you have to do the other close - talking ?
E: as as all of these . you have to do all you could just do it in that time period , though ,
F: yes . . there 's lot of cross - talk .
E: but it 's pain .
F: but you have to copy the whole file . because we 're gonna be releasing the whole file .
E: you 're right .
A: at certain point , that copy that has the deletions will become the master copy .
F: it 's just hate deleting any data . so don't want really would rather make copy of it , rather than bleep it out
B: are you del are you bleeping it by adding ?
F: so , it 's it 's exactly censor bleep . so what really "" bleep ""
B: but is it summing signals
F: and then want to
B: or do you delete the old one and put the new one in ?
F: delete the old one , put the new one in . there 's nothing left of the original signal .
B: cuz if you were summing , you could no . but anyway
F: it would be qui quite easy to get it back again .
A: but and then was gonna say also that the they don't have to stay on the system , as ,
E: then someday we can sell the unedited versions .
A: once it 's been successfully bleeped , can't you rely on the ?
C: or we 'll tell people the frequency of the beep and then they could subtract the beep out .
D: you can hide it . .
A: can't you rely on the archiving to preserve the older version ?
D: it wouldn't be that hard to hide it .
E: right . exactly . see .
F: that 's true . . , that 's true .
E: see , this is good . wanted to create some side conversations in these meetings .
B: you could encrypt it , with with two hundred bit thousand bit ,
D: you can use spread spectrum .
C: here we go .
D: there you go .
E: cuz we don't have enough asides .
H: have an idea . you reverse the signal ,
D: there you go .
H: so it lets people say what they said backwards .
D: then you have , like , subliminal , , messages ,
F: ha you 've seen the this the speech recognition system that reversed very short segments . did you read that paper ? it wouldn't work . the speech recognizer still works .
E: and if you do it backward then
C: that 's cuz they use forward - backward .
E: - good old .
F: forward but backward . that 's right .
E: no , it 's backward - forward .
F: 'm if sound little peeved about this whole thing . it 's just we 've had meeting after meeting on this and it seems like we 've never gotten it resolved .
B: but we never also we 've also never done it .
A: this is the first cycle . there 're bound to be some glitches the first time through .
B: so . and , and 'm responding without , , having much knowledge , but , , am , like , one of these people who gets gazillion mails and comes in as
F: and that 's exactly why did it the way did it , which is the default is if you do nothing we 're gonna release it . because , , have my stack of emails of to to be done , that , , fifty or sixty long , and the ones at the top 'm never gonna get to . and , so so
C: move them to the bottom .
B: so so the only thing we 're missing is some way to respond to easily to say , , "" , go ahead "" .
F: so , this is gonna mean
C: just re - mail them to yourself and then they 're at the bottom .
F: that 's actually definitely good point . the email doesn't specify that you can just reply to the email , as op as opposed to going to the form
A: and it also doesn't give specific didn't think of it . it 's good idea an ex explicit time by which this will be considered definite . and and it has to be time earlier than that endpoint .
B: it 's converging .
A: that 's right .
H: this , 've seen this recently . and it if use mime - capable mail reader , it actually says , , click on this button to confirm receipt of the mail .
A: that 's interesting .
D: it 's like certified mail .
F: lot of mailers support return receipt .
A: could do that .
F: but it doesn't confirm that they 've read it .
H: no , no . this is different . this is not so , know , you can tell , , the , , mail delivery agent to confirm that the mail was delivered to your mailbox . but but , no . this was different . ins - in the mail , there was th there was button that when you clicked on it , it would send , , , actual acknowledgement to the sender that you had actually looked at the mail .
F: unfor - , we could do that . but hate that .
H: but it but it only works for , , mime - capable if you use netscape like that for your
E: you might as just respond to the mail .
B: and we actually need third thing . it 's not that you 've looked at it , it 's that you 've looked at it and and agree with one of the possible actions .
H: no , no . you can do that . you can put this button anywhere you want , and you can put it the bottom of the message and say "" here , by , by clicking on this , agree , , acknowledge ""
B: that my first - born children are yours ,
F: could put url in there without any difficulty and even pretty simple mime readers can do that .
A: but why shouldn't they just email back ? don't see there 's problem . it 's very . like the high - tech aspect of it ,
H: no , no . actually don't . 'm just saying that
F: cuz use text mail reader .
H: if ev but 'm
E: don't you use vi for your mai ?
B: that 's that 's my guy .
F: you you read email in vi ?
H: there 's these logos that you can put at the bottom of your web page , like "" powered by vi "" .
E: anyway , quick question .
F: you could put wed bugs in the email .
E: like , there were three meetings this time , or so or how many ? but , no of different people . so if you 're in both these types of meetings , you 'd have lot . it also depends on how many like , if we release this time it 's fairly small number of meetings , but what if we release , like , twenty - five meetings to people ?
F: what my expectation is , is that we 'll send out one of these emails every time meeting has been checked and is ready .
E: so this time was just the first chunk . .
F: so . tha - that was my intention . that we just happened to have bunch all at once .
E: that 's good idea .
F: is that the way it 's gonna be , you think , jane ?
A: agree with you . it 's we could do it , could 'd be happy with either way , that was exactly right , that we had , had wanted to get the entire set of twelve hours ready . don't have it . but , , this was the biggest clump could do by time where it was reasonable . people would be able to check it and still have it ready by then . my , was thinking that with the nsa meetings , 'd like there are three of them , and they 're , will have them done by monday . unfortunately the time is later and how that 's gonna work out , but it 'd be good to have that released as clump , too , because then , , they 're they have it 's in category , it 's not quite so distracting to them , is what was thinking , and it 's all in one chu but after that , when we 're caught up bit on this process , then , , could imagine sending them out periodically as they become available . could do it either way . it 's question of how distracting it is to the people who have to do the checking .
B: we heard anything from ibm ?
C: let 's see . so we got the transcript back from that one meeting . everything seemed fine . adam had script that will put everything back together and there was , there was one small problem but it was simple thing to fix . and then , , we , sent him pointer to three more . and so he 's off and working on those .
F: now we haven't actually had anyone go through that meeting , to see whether the transcript is correct and to see how much was missed and all that .
A: that 's on my list .
F: so at some point we need to do that .
A: that 's on my list .
C: it 's gonna have to go through our regular process .
F: the one thing noticed is it did miss lot of backchannels . there are fair number of "" yeahs "" and "" - huhs "" that it 's just that aren't in there .
B: but . like you said , , that 's that 's gonna be our standard proc that 's what the transcribers are gonna be spending most of their time doing , would imagine ,
A: - , - .
F: yes , . .
A: one question about the backchannels . do you suppose that was because they weren't caught by the pre - segmenter ?
F: yes , . . they 're they 're not in the segmented . it 's not that the ibm people didn't do it . just they didn't get marked .
A: so maybe when the detector for that gets better there 's another issue which is this we 've been , , contacted by university of washington now , , to , we sent them the transcripts that correspond to those six meetings and they 're downloading the audio files . so they 'll be doing that . chuck 's chuck 's , , put that in .
C: - . , pointed them to the set that andreas put , , on the web so th if they want to compare directly with his results they can . and , , then once , , th we can also point them at the , , , the original meetings and they can grab those , too , with scp .
E: so you put the reference files ?
C: no , no . they they wanted the audio . jane sent them the , , transcripts .
E: no , of the transcripts . we can talk about it off - line .
F: there 's another meeting in here , what , at four ? so we have to finish by three forty - five .
H: so , does washi - does uw wanna do this wanna use this data for recognition or else ?
E: didn't they want to do language modeling on , , recognition - compatible transcripts
A: this is to show you , , some of the things that turn up during the checking procedure . @ @ so , this is from one of the nsa meetings and , , if you 're familiar with the diff format , the arrow to the left is what it was , and the arrow to the right is what it was changed to . and now the first one . "" . so , then we started weekly meeting . the last time , "" and the transcriber thought "" little too much "" really , , it was "" we learned too much "" , which makes more sense syntactically as .
H: and these the parentheses were from
A: this that 's the convention for indicating uncertain . so the transcriber was right . she was uncertain about that . so she 's right to be uncertain . and it 's also good indication of the of that . the next one . this was about , , claudia and she 'd been really busy with , such as waivers . this was an interesting one . so the original was "" so that 's not so claudia 's not the bad master here "" , and then he laughs , but it really "" web master "" . and then you see another type of uncertainty which is , , they just didn't to make out of that . so instead of "" split upon unknown "" , it 's "" split in principle "" .
D: jane , these are from ibm ? the top lines ?
A: no , no . these are these are our local transcriptions of the nsa meetings .
F: no , these are ours .
A: the transcribers transcriber 's version ver versus the checked version . my my checked version , after go through it . then you get down here . sometimes some speakers will insert foreign language terms . that 's the next example , the next one . the , , version beyond this is so instead of saying "" or "" , especially those words , "" also "" and "" oder "" and some other ones . those sneak in . and it 's and it makes sense cuz it 's , like , below this it 's little subliminal there . , the next one , this is term . the problem with terminology . description with th the transcriber has "" as an advance "" . but really it 's "" qs in advance "" . 've benefited from some of these , , cross - group meetings . then you got , instead of "" from something - or - other cards "" , it 's "" for multicast "" . and instead of "" ann system related "" , it 's "" end system related "" . this was changed to an acronym initially and it should shouldn't have been . and then , you can see here "" gps "" was misinterpreted . it 's just understanda this is this is lot of jargon . and the final one , the transcriber had th "" in the core network itself or the exit unknown , not the internet unknown "" . and it comes through as "" in the core network itself of the access provider , not the internet backbone core "" . now this is lot of terminology . and they 're generally extremely good , but , in this area it really does pay to , to double check and 'm hoping that when the checked versions are run through the recognizer that you 'll see substantial improvements in performance cuz the , there 're lot of these in there .
H: so how often ?
F: but bet bet they 're acoustically challenging parts anyway , though .
A: no , actually no .
F: so it 's just jargon .
A: it 's jargon . . this is cuz , you don't realize in daily life how much you have top - down influences in what you 're hearing . and it 's jar it 's jargon coupled with foreign accent .
H: but we don't , our language model right now doesn't know about these words anyhow . un until you actually get decent language model , @ @ adam 's right .
F: it probably won't do any better .
H: you probably won't notice difference . but it 's , it 's definitely good that these are fixed .
A: also from the standpoint of getting people 's approval , cuz if someone sees page full of , , barely decipherable , sentences , and then is asked to approve of it or not , it 's ,
F: did say that ?
B: that would be shame if people said "" , don't approve it because the it 's not what said "" .
F: that 's exactly why put the extra option in ,
A: exactly . that 's why we discussed that .
F: is that was afraid people would say , "" let 's censor that because it 's wrong "" , and don't want them to do that .
A: and then also the final thing have for transcription is that made purchase of some other headphones because of the problem of low gain in the originals . and and they very much appro they mu much prefer the new ones , and actually , that there will be fewer things to correct because of the choice . we 'd originally chosen , , very expensive head headsets but , , they 're just not as good as these , , in this with this respect to this particular task .
H: return the old ones .
F: it 's probably impedance matching problems .
A: but we chose them because that 's what 's been used here by prominent projects in transcription . so it we had every reason to think they would work .
H: so you have spare headsets ? you have spare headsets ?
F: they 're just earphones . they 're not headsets . they 're not microphones .
H: no , no . , just earphones ? because , , could use one on my workstation , because sometimes have to listen to audio files and don't have to go borrow it from someone
A: we have actua actually have , that if we have four people come to work for day , was was hanging on to the others for , for spares , but tell you what recommend .
B: no , but you 'd if you , we should get it .
F: but if you need it , just get it .
B: if you need it .
A: it 'd just have to be separate order an added order .
D: still still need to get pair , too .
B: they 're they 're they 're pretty inexpensive .
E: we should order cou , two or three or four , actually .
D: 'm using one of these .
H: have pair that brought from home , but it 's just for music listening
B: no . just just buy them .
E: sh - just get the model number
H: and it 's not
B: just buy them .
E: where do you buy these from ?
A: cambridge soundworks , just down the street .
E: you just go and
A: they always have them in stock .
E: that 'd be good idea .
F: could you email out the brand ? cuz sounds like people are interested .
A: it 's made difference in how easy .
B: realized something should talk about . so what 's the other thing on the agenda actually ?
F: the only one was don wanted to , , talk about disk space yet again .
D: it 's short . if you wanna go , we can just throw it in at the end .
B: no , no . why don't you why don't you go ahead since it 's short .
F: you meant the disk space . we know disk space is short .
H: the disk space was short . that 's what too .
E: that 's great ambiguity . it 's one of these it 's it 's social and , , discourse level
B: it 's great .
F: it was really goo
E: see , if had that little scratch - pad , would have made an there .
F: , we 'll give you one then .
D: without thinking about it , when offered up my hard drive last week this is always suspect phrase .
E: it was while was out of town .
D: but , , no . , realized that we 're going to be doing lot of experiments , , for this , , paper we 're writing , so we 're probably gonna need lot more we 're probably gonna need that disk space that we had on that eighteen gig hard drive . but , , we also have someone else coming in that 's gonna help us out with some .
B: we 've just ordered hundred gigabytes .
D: we just need to
E: we need , like , another eighteen gig disk to be safe .
B: we 're getting three thirty - sixes . that are going into the main file server .
C: markham 's ordering and they should be coming in soon .
D: , , all need is to hang it off , like , the person who 's coming in , sonali 's , computer .
H: so , you mean the the internal the disks on the machines that we just got ?
D: or we can move them .
C: these are gonna go onto abbott .
F: ne - new disks .
H: or extra disk ?
B: the file server .
D: so are we gonna move the off of my hard drive onto that when those come in ?
F: once they come in . .
D: that 's fine .
E: do when is this planned for roughly ?
C: they should be imagine next week .
F: if you 're if you 're desperate , have some space on my drive . but vacillate between no space free and few gig free .
D: find something if 'm desperate and , , in the meantime 'll just hold out . that was the only thing wanted to bring up .
C: it should be soon .
B: so there 's another hundred gig .
D: alright . great .
B: it 's great to be able to do it ,
D: that 's it .
B: just say "" , hundred gig , no big deal "" .
F: hundred gig here , hundred gig there .
E: each meeting is like gig ,
F: it 's eventually real disk space .
E: so it 's really
B: . was just going to comment that 'm going to , , be on the phone with mari tomorrow , late afternoon . we 're supposed to get together and talk about , , where we are on things . there 's this meeting coming up , and there 's also an annual report . now , was asking about this . don't really quite understand this . she was re she was referring to it as this actually didn't just come from her , but this is what , , darpa had asked for . she 's referring to it as the an annual report for the fiscal year . but the fiscal year starts in october , so don't quite understand why we do an annual report that we 're writing in july .
C: she 's either really late or really early .
F: or she 's getting good early start .
B: it 's none of those . it 's that the meeting is in july so they so darpa just said do an annual report . so anyway , 'll be putting together . 'll do it , , , as much as without bothering people , just by looking at papers and status reports . the status reports you do are very helpful . so grab there . and if , if have some questions 'll
F: when we remember to fill them out .
B: if people could do it as soon as you can , if you haven't done one si recently . but , , 'm 'm before it 's all done , 'll end up bugging people for more clarification about . people have been doing . we have these meetings and there 's the status reports . but , . . so that wasn't long one . just to tell you that . and if something hasn't , 'll be talking to her late tomorrow afternoon , and if something hasn't been in status report and you 's important thing to mention on this thing , , just pop me one - liner and and 'll 'll have it in front of me for the phone conversation . , you 're still pecking away at the demos and all that , probably .
F: and don is gonna be helping out with that .
B: that 's right .
F: did you wanna talk about that this afternoon ? not here , but later today ?
D: we should probably talk off - line about when we 're gonna talk off - line .
B: might want to get updated about it in about week cuz , , 'm actually gonna have few days off the following week , after the after the picnic . that 's all had .
F: so we were gonna do status of speech transcription but we 're running late .
E: how long does it take you to save the data ?
F: if you wanna do quick
E: we should stop , like , twenty of at the latest . we we have another meeting coming in that they wanna record .
B: and there 's the digits to do . so maybe may maybe
F: , we can skip the digits .
B: fi - five minute report .
E: it 's up to you .
F: whatever you want .
B: would love to hear about it ,
F: what do you have to say ?
B: , 'm gonna be on the phone tomorrow , so this is just good example of the thing 'd like to hear about .
E: why is everybody looking at me ?
B: cuz he looked at you and says you 're sketching .
E: 'm not what you were referring to .
H: 'm not actually , 'm not what ? are we supposed to have done something ?
F: no . we were just talking before about alternating the subject of the meeting . and this week we were gonna try to do automatic transcription status .
E: wasn't here last week .
F: but we failed .
H: we did that last week .
F: so now we have the schedule . so next week we 'll do automatic transcription status , plus anything that 's real timely . dodged that bullet .
B: nicely done , liz .
A: woman of few words .
B: but but lots of prosody .
H: , we really haven't done anything .
A: since last week .
H: the next thing on our agenda is to go back and look at the , the automatic alignments because , , got some learned from thilo what data we can use as benchmark to see how we 're doing on automatic alignments of the background speech or , of the foreground speech with background speech .
E: and then , , , the new data that don will start to process
H: but , we haven't actually
E: when he can get these before we were working with these segments that were all synchronous and that caused lot of problems because you have timed sp at on either side .
F: right , right .
E: and so that 's stage - two of trying the same kinds of alignments with the tighter boundaries with them is really the next step .
A: 'll be interested .
E: we did get our , we got our abstract accepted for this conference , isca workshop , in , , , new jersey . and we sent in very poor abstract , but we 're hoping to have paper for that as , which should be an interesting
F: when 's it due ?
E: the paper isn't due until august . the abstracts were already due . so it 's that workshop . but , , the good news is that will have the european experts in prosody and we 're the only people working on prosody in meetings so far , so that should be interesting .
A: what 's the name of the meeting ?
E: it 's isca workshop on prosody in speech recognition and understanding , like that
H: it 's called prosody to
E: so it 's focused on using prosody in automatic systems and there 's , web page for it .
B: you going to , , eurospeech ?
F: but 'd kinda like to go , is that alright ?
B: we 'll discuss it .
F: that 's "" no "" .
B: my my car needs good wash , .
F: , that th hey , if that 's what it takes , that 's fine with me . 'll pick up your dry - cleaning , too . should we do digits ?
H: can go next ? because have to leave , actually .
F: go for it .
B: so you get to be the one who has all the paper rustling .
","Although the Meeting Recorder group only list two agenda items , this meeting explores transcription , and in particular , consent forms in depth , and at times results in heated debate.
With regard to obtaining consent , the group discuss the extent to which they need to attempt to contact people , which methods are most appropriate , and how much responsibility rests on participants being available and checking their e-mail regularly.
The group suggest sending reminder e-mails , although since many participants are local they can be contacted by other means if necessary.
Transcriptions are back from IBM , and the group discuss the checking of these , particularly since the pre-segmenter has interfered with back-channel data.
Checking of the NSA meetings has revealed that this non-native English meeting data contains transcription inaccuracies due to the use of foreign language terms and technical vocabulary.
Additional topics covered more briefly in this meeting are disk space , the DARPA annual report , progress with the demo , conference submissions and attendance , and requests from the University of Washington for data.
The group discuss whether this meeting will relate to either meeting recorder or speech recognition issues.
They decide that covering such topics over alternate weeks will commence at the next meeting , although other topics will be discussed if time allows.
The group decide that it would be good to set a date for having the non-native network services group data , and one or two weeks before the 15th of July is suggested.
With regard to contacting participants to request consent , the group decide that no signature is required , and an e-mail would be enough.
However for ""boundary cases"" legal advice would be sought.
As soon as the next set of data is ready for checking , participants should be contacted , so that this process is on-going.
When the deadline for giving consent is approaching , a reminder e-mail should be sent out.
In cases where no consent response is given , participants could be chased up since many are local.
Original uncensored copies of meetings will be kept , with all of the old signal deleted and replaced with new when censoring.
Gaining consent from participants for the use of the meeting data is raising a number of issues for the group , some of which may have legal implications.
Firstly a relatively arbitrary deadline of 15 July has been set , and since this is during the summer break , the group debate whether enough action has been made to contact participants.
If people don't respond in time , the group discuss what facility should there be for later amendments , and whether a meeting can be used if they don't respond at all.
Checking of the NSA meeting transcripts has shown that although acoustically fine , some errors have shown up , especially relating to foreign language terms and jargon or technical terminology.
Additionally , the discussions reveal that there is a shortage of headphones amongst group members , and also that disk space is in short supply , especially if original copies of edited transcripts are retained.
Progress has been made regarding gaining consent from participants to publish the meeting data.
E-mails were sent out to request that the transcripts are checked , and corrected or censored , in time for the data to be used in the DARPA meeting in July.
Transcriptions are back from IBM , although there was a small problem , this was simple to fix.
They have not yet been checked to see whether they are correct , however , back-channels appear to be missed as these were not caught by the pre-segementer.
The University of Washington has been in touch with the group requesting audio files and transcripts , and also  new headphones have been purchased for the transcribers which are much better than the previous ones.
Disk space is again filling up fast , and a new 100 gig hard drive will soon be available.
As  a temporary measure , the group will use up disk space on each other's machines.
The annual report for DARPA will be written over the next week based on project status information;
The DARPA demo is ongoing , with automatic alignment and tighter boundaries to be investigated.
A conference abstract has been accepted.
"
ami_abstractive_summary,Bed003.txt,"D: is that good ?
C: 've have never handled them .
B: goats eat cans , to my understanding .
D: did we need to do these things ?
B: could hit - seven to do that ? the remote will do it cuz 'm already up there ?
A: in control here .
B: you are in control .
D: we 're all so high tech here . yet another powerpoint presentation .
B: it makes it easier to do so , we were
C: johno , where are you ?
B: so , let 's see . which one of these buttons will do this for me ?
C: should you go back to the first one ?
B: do wanna go back to the first one ?
C: , "" the search for the middle layer "" . it 's talks about it just refers to the fact that one of main things we had to do was to decide what the intermediate nodes were ,
A: but if you really want to find out what it 's about you have to click on the little light bulb .
B: although 've 've never what the light bulb is for . didn't install that into my powerpoint presentation .
A: it opens the assistant that tells you that the font type is too small . do you wanna try ?
B: 'd prefer not to .
D: it 's needless good idea . is that the idea ?
A: why are you doing this in this mode and not in the presentation mode ?
B: because 'm gonna switch to the javabayes program and then if do that it 'll mess everything up .
C: can you maximize the window ?
B: you want me to what do you want me to do ?
C: can you maximize the window so all that on the side isn't doesn't appear ?
A: no , it 's . it 's it 'll work .
B: but then have to end the presentation in the middle so go back to open up here , let 's see if is that better ? 'll also get rid of this "" click to add notes "" . so then the features we decided or we decided we were talked about , the prosody , the discourse , verb choice . we had list of things like "" to go "" and "" to visit "" and what not . the "" landmark - iness "" of knew you 'd like that . of of building . and this we actually have separate feature but decided to put it on the same line for space . "" walls "" which we can look up because if you 're gonna get real close to building in the tango mode , there 's gotta be reason for it . and it 's either because you 're in route to something else or you wanna look at the walls . the context , which in this case we 've limited to "" business person "" , "" tourist "" , or "" unknown "" , the time of day , and "" open to suggestions "" , isn't actually feature . it 's "" we are open to suggestions . ""
D: can ask the walls part of it is that , in this particular domain you said be it could be on two different lines but are you saying that in this particular domain it happens the that landmark - iness cor is correlated with
B: they 're separate things . either could put "" walls "" on its own line or "" open to suggestions "" off the slide .
C: like you could have
D: by "" "" you mean
C: you like you could have post office with , murals .
B: or one time was at this
D: so "" walls "" is stand in for like architecturally it , significant
B: but see , if it 's
C: architecturally appealing from the outside .
B: but if it 's architecturally significant you might be able to see it from like you might be able to "" vista "" it , and be able to versus , like , was at this place in europe where they had little carvings of , like , dead people on the walls . it was long time ago .
D: there 's lot of those .
B: but if you looked at it real close , you could see the in intricacy of the of the walls .
D: so that count as counts as wall . something you want to inspect at close range because it 's interesting .
A: there is term that 's often used . that 's "" saliency "" , or the "" salience "" of an object . and was just wondering whether that 's the same as what you describe as "" landmark - iness "" . but it 's really not . an object can be very salient but not landmark .
D: there 's landmark for , touristic reasons and landmark for
C: we meant , , touristic reasons .
D: but you can imagine maybe wanting the oth both kinds of things there for different , goals .
B: tourist - landmarks also happen to be wouldn't couldn't they also be they 're not exclusive groups , like non - tourist - landmarks and
A: or it can be als
D: they 're not mutually exclusive ?
B: so our initial idea was not very satisfying , because our initial idea was all the features pointing to the output node .
D: so , big flat structure .
B: and , so we reasons being , , it 'd be pain to set up all the probabilities for that . if we moved onto the next step and did learning of some sort , according bhaskara we 'd be handicapped . belief - nets very .
C: usually , , , if you have features , then it 's two to the or exponential in .
B: and they wouldn't look pretty .
C: they 'd all be like pointing to the one node .
B: so then our next idea was to add middle layer , so the thinking behind that was we have the features that we 've drawn from the communication of some like , the someone the person at the screen is trying to communicate some abstract idea , like "" 'm "" the abstract idea being "" am tourist want to go to this place . "" so we 're gonna set up features along the lines of where they want to go and what they 've said previously and whatnot . and then we have the means that they should use . but the middle thing , we were thinking along the lines of maybe trying to figure out , like , the concept of whether they 're tourist or whether they 're running an errand like that along those lines . yes , we could things we couldn't extract the from the data , the hidden variables . so then the hidden variables hair variables we came up with were whether someone was on tour , running an errand , or whether they were in hurry , because we were thinking , if they were in hurry there 'd be less likely to like or th
C: want to do vista , because if you want to view things you wouldn't be in hurry .
B: or they might be more likely to be using the place that they want to go to as like navigational point to go to another place . whether the destination was their final destination , whether the destination was closed . and then "" let 's look at the belief - net "" . so that means that should switch to the other program . right now it 's still in toy version of it , because we didn't know the probabilities of or 'll talk about it when get the picture up .
A: no one knows it .
B: so this right what we let 's see . what happens if maximize this ? there we go . so . the mode has three different outputs . the probability whether the probability of vista , tango , or enter . the "" context "" , we simplified . it 's just the businessman , the tourist , unknown . "" verb used "" is actually personally amusing mainly because it 's it 's just whether the verb is tango verb , an enter verb , or vista verb .
C: that one needs lot of
D: and are those mutually exclusive sets ?
C: that 's that needs lot of work . but that would 've made the probably significantly be more complicated to enter , so we decided that for the purposes of this it 'd be simpler to just have three verbs .
D: stab at it .
B: why don't you mention things about this , bhaskara , that am not that are not coming to my mind right now .
C: so , so note the four nodes down there , the , the things that are not directly extracted . actually , the five things . the "" closed "" is also not directly extracted ,
D: from the utterance ?
B: it 's so it is
C: actually , no ,
B: because it 's because have the time of day
C: "" closed "" is .
B: it just had the er and what time it closed .
C: but the other ones , the final destination , the whether they 're doing business , whether they 're in hurry , and whether they 're tourists , that thing is all probabilistically depends on the other things .
D: inferred from the other ones ?
C: and the mode , , depends on all those things only .
B: the actual parse is somewhere up around in here .
C: so we haven't , managed like we don't have nodes for "" discourse "" and "" parse "" , although like in some sense they are parts of this belief - net . but the idea is that we just extract those features from them , so we don't actually have node for the entire parse , because we 'd never do inference on it anyway ,
D: so some of the top row of things what 's what 's "" disc admission fee "" ?
C: whether they discuss the admission fees . so we looked at the data and in lot of data people were saying things like "" can get to this place ? "" "" what is the admission fee ? "" . so that 's like huge clue that they 're trying to enter the place rather than to tango or vista ,
B: there were there 'd be other things besides just the admission fee , but , we didn't have
C: that was like our example .
B: that was the initial one that we found .
D: so there are certain cues that are very strong either lexical or topic - based , concept cues
B: from the discourse that
D: for one of those . and then in that second row or whatever that row of time of day through that so all of those some of them come from the utterance and some of them are either world knowledge or situational things . so that you have no distinction between those and
B: one , . , anything else you want to say bhaskara ?
D: "" unmark @ @ time of day ""
A: they 're they 're are couple of more things . would actually suggest we go through this one more time so we all , agree on what the meaning of these things is at the moment and maybe what changes we
B: so one thing 'm unsure about , is how we have the discus the "" admission fee "" thing set up . so one thing that we were thinking was by doing the layers like this , we kept things from directly affecting the mode beyond the concept , but you could see perhaps discus the "" admission fee "" going directly to the mode pointing at "" enter "" , versus pointing to just at "" tourist "" , but we just decided to keep all the things we extracted to point at the middle and then down .
A: why is the landmark the landmark is facing to the tourists . that 's because we 're talking about landmarks as touristic landmarks
B: that would be whatever building they referred to .
C: so let 's see . disc - "" admission fee "" is binary thing , "" time of day "" is like morning , afternoon , night . is that the deal ?
B: that 's how we have it currently set up , but it could be , , based upon hour or dis we could discrete it des descret - ize it .
C: normally context will include huge amount of information , but , we are just using the particular part of the context which consists of the switch that they flick to indicate whether they 're tourist or not , .
D: so that 's given in their input .
C: so it 's not really all of context . similarly prosody is not all of prosody but simply for our purposes whether or not they appear tense or relaxed .
A: that 's very , the the so the context is switch between tourist or non - tourist ? or also unknown ?
B: or un unknown ,
D: so it seems like that would really help you for doing business versus tourist ,
C: which is th which one ?
D: so the context being , if that question 's in general , "" are you "" do they allow business people to be doing non - business things at the moment ? so then you just have some probabilities over
C: everything is probablistic , and there 's always
D: over which of those it is .
C: so then landmark is "" verb used "" is like , right now we only have three values , but in general they would be probability distribution over all verbs . let me rephrase that . it it can take values in the set of all verbs , that they could possibly use . "" walls "" is binary , "" closed "" is binary "" final destination "" , again all those are binary . and "" mode "" is one of three things .
A: so , the middle layer is also binary ?
C: anything with question mark after it in that picture is binary node .
A: but all those things without question marks are also binary .
C: "" walls "" is something that we extract from our world knowledge . . it is binary .
B: but it doesn't have question mark because it 's extracted .
C: that 's true . see your point . similarly "" closed "" , .
A: so we can either be in hurry or not , but we cannot be in medium hurry at the moment ?
C: to do that we would add another value for that . and that would require updating the probability distribution for "" mode "" as . because it would now have to like take that possibility into account .
D: so , this will happen when we think more about the kinds of verbs that are used in each cases but you can imagine that it 's verb plus various other things that are also not in the bottom layer that would that would help you like it 's conjunction of , the verb used and some other that would determine
C: other syntactic information you mean ?
A: the the landmark is the object the argument in sense ?
D: if that 's always the case haven't looked at the data as much as you guys have .
A: that 's always warping on something some entity , and maybe at this stage we will we do want to get modifiers in there because they may also tell us whether the person is in hurry or not
B: want to get to the church quickly ,
D: that would be cue .
A: what 's the fastest way
B: do we have anything else to say about this ?
C: we can do little demo .
B: but the demo doesn't work very .
A: then it wouldn't be demo
C: we can do demo in the sense that we can , just ob observe the fact that this will , do inference . so we can , , set some of the nodes and then try to find the probability of other nodes .
B: dat - dat - dah . what should observe ?
C: just se set few of them . you don't have to do the whole thing that we did last time . just like , maybe the fact that they use certain verb actually forget the verb . say they discussed the admission fee and the place has walls
B: 'm big fan .
C: and it 's night .
D: it 's starting to grow on me
B: and the time of day is night ?
C: it 's not really consistent . they don't discuss the admission fee . make that false . and it 's night . that didn't work .
D: 'd like to do that again .
B: one thing that bugs me about javabayes is you have to click that and do this . th you want ? so let 's see . want to query ,
C: "" go "" and , right , "" query "" .
B: and then on here so let 's see .
C: so that is the probability that they 're entering , vista - ing or tango - ing .
D: so slightly biased toward "" tango "" ing
B: if it 's night time , they have not discussed admission fee , and the walls are . that makes sense . the reason say the demo doesn't work very is yesterday we observed everything in favor of taking tour , and it came up as "" tango "" , over and over again . we couldn't we couldn't figure out how to turn it off of "" tango "" .
C: it loves the tango . that 's just to do with our probabilities . like , we hand - tuned the probabilities , we were like "" , if the person does this and this , let 's say forty percent for this , fifty per "" like , . so that 's gonna happen .
D: maybe the bias toward "" tango "" ing was yours , then ?
B: that 's that 's at
C: it 's so we have to like fit the probabilities .
B: spent my youth practicing the tango de la muerte .
D: so , the real case ?
A: however , it the purpose was not really , at this stage , to come up with meaningful probabilities but to get thinking about that hidden middle layer .
B: once we look at the data more we 'll get more hidden nodes , but 'd like to see more . not because it would expedite the probabilities , cuz it wouldn't . it would actually slow that down tremendously .
C: not that much though . only little early .
B: we should have exponentially more middle nodes than features we 've extracted . 'm ju 'm just jo
D: so . are "" doing business "" versus "" tourist "" they refer to your current task . like like current thing you want to do at this moment .
C: that 's that 's an interesting point . whether you 're it 's whether it 's not it 's more like "" are you are tourist ? are you in ham - like heidelberg for ""
D: so , that was directly given by the context switch .
C: that 's different thing . what if the context , which is not set , but still they say things like , "" want to go , see the the castle and , et cetera . ""
B: the of "" doing business "" as more of running an errand type thing .
C: business on the other hand is , , definitely what you 're doing .
A: so if you run out of cash as tourist , and and you need to go to the at
D: you may have task . wh you have to go get money and so you are doing business at that stage .
A: "" how do get to the bank ? ""
C: and that 'll affect whether you want to enter or you if you
D: so the "" tourists "" node should be , very consistent with the context node . if you say that 's more their in general what their background is .
C: this context node is bit of do we wanna have
D: are you assuming that or not ? like is that to be if that 's accurate then that would determine tourist node .
C: if the context were to set one way or another , that like strongly , says something about whether or not they 're tourists . so what 's interesting is when it 's not when it 's set to "" unknown "" .
A: we - what set the they set the context to "" unknown "" ?
C: right now we haven't observed it , so it 's averaging over all those three possibilities . you can set it to un "" unknown "" .
A: and if we now do leave everything else as is the results should be the same ,
C: because we th - the way we set the probabilities might not have it 's it 's an issue , so the issue is that in belief - nets , it 's not common to do what we did of like having , , bunch of values and then "" unknown "" as an actual value . what 's common is you just like don't observe the variable , and then just marginalizes but we didn't do this because we felt that there 'd we were thinking in terms of switch that actually but what the right thing is to do for that . 'm not if am happy with the way it is .
A: how long would it take to add another node on the observatory and , , play around with it ?
C: another node on what ?
B: it depends on how many things it 's linked to .
A: let 's just say make it really simple . if we create something that would be so th some things can be landmarks in your sense but they can never be entered ? so maybe we wanna have "" landmark "" meaning now "" enterable landmark "" versus , something that 's simply just vista point , .
B: that 's true .
C: so it 's addressing variable that 's "" enterable or not "" . so like an "" enterable , question mark "" .
B: also , didn't we have size as one ? the size of the landmark . cuz if it 's
C: not when we were doing this , but at some point we did .
B: for some reason had that , that was thought that had at one point but then went away .
C: so you want to have node for like whether or not it can be entered ?
A: , if we include that , "" is it can it be entered ? "" then , this is binary as . and then , there 's also the question whether it may be entered . in the sense that , , if it 's tom the house of tom cruise , , it 's enterable but you may not enter it . you 're not allowed to . unless you are , whatever , his divorce lawyer . and and these are very observable from the from the ontology things .
B: does it actually help to distinguish between those two cases though ? whether it 's practically speaking enterable , or actually physically enterable or not ?
A: if you 're running an errand you maybe more likely to be able to enter places that are usually not al you 're not usually not allowed to
D: it seems like it would for , determining whether they wanna go into it or not .
A: let 's get this clearer . so it 's matrix between if it 's not enterable ,
B: whether it 's whether it 's public building , and whether it 's actually has door . so tom cruise 's house is not public building but it has door . explain to me why it 's necessary to distinguish between whether something has door and is not public . or , if something it seems like it 's equivalent to say that it doesn't have door and it or "" not public "" and "" not door "" are equivalent things , it seems like in practice .
A: so we would have what does it mean , then , that we have to we have an object type statue . that really is an object type . so there is there 's gonna be bunch of statues . and then we have , , an object type , , that 's hotel . how about hotels ? so , the most famous building in heidelberg is actually hotel . it 's the hotel zum ritter , which is the only renaissance building in heidelberg that was left after the big destruction and for the thirty years war , blah - blah .
B: does it have walls ?
A: it has wonderful walls . - and lots of detail , and carvings , engravings and , but , , it 's still an unlikely candidate for the tango mode must say . but . . so so if you are it 's very tricky . so your question is so far have no really arg no real argument why to differentiate between statues as statues and houses of celebrities , from that point of view . can we add , just so see how it 's done , , "" has door "" property
C: what would it , , connect to ? like , what would , , it affect ?
A: , , it might affect actually it 's it wouldn't affect any of our nodes ,
C: what was thinking was if you had like
A: it 's it affects th the "" doing business "" is certainly not .
B: you could affect theoretically you could affect "" doing business "" with "" has door "" .
A: it should , , inhibit that ,
B: let 's see .
C: if javabayes is about that . it might be that if you add new thing pointing to variable , you just like it just overwrites everything . but you can check .
B: we have it saved . so . we can rel open it up again .
C: it 's true .
B: the safety net .
D: you could just add it .
C: that 's fine , but we have to see the function now . has it become all point fives or not ?
B: let 's see . so this is "" has door "" true , false . that 's acceptable . and want to edit the function going to that ,
C: this is fine ,
B: it was fine . added this one .
C: what would be if it is if it just like kept the old function for either value didn't do it .
B: that 's not good .
C: that 's annoying .
A: so just dis dismiss everything . close it and load up the old state so it doesn't screw that up .
B: let 's see .
A: maybe you can read in ?
C: ha - so have you used javabayes lot ?
D: really ha 've haven't used it lot and haven't used it in the last many months , we can ask someone .
C: it might be worth asking around . like , we looked at page that had like bunch of he 'd be the person .
D: srini 's the one to ask would say . he might know .
C: in way this is lot of good features in java it 's cra has gui and it 's those are the main two things . it does learning ,
B: no it doesn't , actually . didn't did learning . maybe it did little bit of learning ,
C: maybe you 're right . but it 's free .
B: which is quite positive ,
C: maybe another thing that but its interface is not the greatest .
B: but actually it had an interface . lot of them were like , .
A: what is the code ? can can we see that ? how do you write the code or do you actually never have to write any code there ?
C: there is actually text file that you can edit . you don't have to do that .
B: there 's like an xml format for bayes - nets .
C: is it xml ?
B: the - there is one . if this uses it .
C: no this doesn't use it . you can look at the text file . but do you have it here ?
B: yes do actually .
C: maybe you don't .
B: let me see .
C: like , there 's the
B: didn't is there an ampersand in dos ?
C: just start up new dos .
B: we - that 's alright . probably double cli click on it . let 's see . let 's see ,
C: it 'll ask you what you what it wants what you want to open it with and see what bat , .
B: one of these days , it should open this ,
A: go right mouse .
B: there we go . maybe it was just it was dead . to the world .
A: through the old notepad . that 's my favorite editor .
B: like like word pad because it has the the returns , the carriage returns on some of them . how they get "" auto - fills "" , or whatever you call it .
C: anyway , there it is .
A: so this is lisp - ?
B: it just looks like it just specifies bunch of
C: that 's how actual probability tables are specified . as , like , lists of numbers . so theoretically you could edit that .
B: it just that it 's
C: but they 're not very friendly .
B: the ordering isn't very clear on
C: so you 'd have to like figure out like you have to go and
D: the layout of the table .
B: actually we could write program that could generate this . we were doing it
C: we can maybe write an interface th for entering probability distributions easily , something like little script . that might be worth it .
A: and that might do .
D: actually seem to recall srini complaining about something to do with entering probability so this is probably
C: the other thing is it is in java
B: we could manipulate the source itself ?
A: do you have the true source files or just the class ?
C: saw directory called "" source "" , go up one ?
B: yes , good . "" source "" . that 's that 's quite .
C: if it actually manipulate the source , though . that might be bit complicated . it might it might be simpler to just have script that , it 's , like , friendly ,
D: the the data tables .
C: it allows you enter things .
A: but if th if there is an xml file that or format that it can also read it just reads this , when it starts .
B: know there is an was looking on the we web page and he 's updated it for an xml version of bayes - nets . there 's bayes - net spec for in xml .
C: he 's like this guy has ? the javabayes guy ? so but , he doesn't use it . so in what sense has he updated it ?
B: th you can either you ca or you can read both . to my understanding .
C: that would be awesome .
B: could have misread the web page , have habit of doing that ,
A: so you got more slides ?
B: do have more slides ? "" future work "" . every presentation have should have "" future work "" slide . we already talked about all this ,
C: the additional thing is learning the probabilities , also . that 's maybe ,
B: that 's future work . and if you have presentation that doesn't have something that doesn't work , then you have "" what learned "" , as slide .
D: can't you have both ?
B: my first approach failed . so that our presentation 's finished . like about these meetings is one person will nod , and then the next person will nod , and then it just goes all the way around the room .
D: missed my turn .
B: no earlier went {nonvocalsound} and bhaskara went {nonvocalsound} and you did it . you did it .
A: it 's like yawning .
D: it 's like yawning .
A: and this announcement was in stereo .
B: should pull up the net again ?
D: could you put the , net up again ?
B: there we go . cuz got wireless mike on .
D: so more general thing than "" discussed admission fee "" , could be 'm just wondering whether the context , the background context of the discourse might be if there 's way to define it or maybe generalize it some way there might be other cues that , say , , in the last few utterances there has been something that has strongly associated with say one of the particular modes if that might be and into that node would be various things that could have specifically come up .
A: this is this is excellent because it gets you thinking along these terms is that maybe we ob we could observe couple of discourse phenomena such as the admission fee , and something else and something else , that happened in the discourse before . and let 's make those four . and maybe there are two so maybe this could be separate region of the net , which has two has it 's own middle layer . maybe this , , has some , funky thing that di and this may influence these hidden nodes of the discourse which is maybe something that is , more general version of the actual phenomenon that you can observe . so things that point towards
B: so instead of single node , for like , if they said the word "" admission fee "" "" admission fee "" , or maybe , , "" how much to enter ""
D: opening hours like that .
B: that would all funnel into one node that would constitute entrance requirements like that .
A: so "" pay visit ""
D: it get into plan recognition kinds of things in the discourse . that 's like the bigger , version of it .
A: and then maybe there are some discourse acts if they happened before , it 's more for cue that the person actually wants to get somewhere else and that you are in in route proceeding past these things , so this would be just something that where you want to pass it . is that it ? however these are then the nodes , the observed nodes , for your middle layer . so this again points to "" final destination "" , "" doing business "" , "" tourist hurry "" and . and so then we can say , "" . we have whole region "" in
D: that 's whole set of discourse related cues to your middle layer .
A: and this is just then just one . so because at the end the more we add , , the more spider - web - ish it 's going to become in the middle and the more of hand editing . it 's going to get very ugly . but with this way we could say "" , these are the discourse phenomena . they ra may have there own hidden layer that points to some of the real hidden layer , or the general hidden layer . and the same we will be able to do for syntactic information , the verbs used , the object types used , modifiers . and maybe there 's hidden layer for that . then we have context .
C: so essentially lot of those nodes can be expanded into little bayes - nets of their own .
B: one thing that 's been bugging me when more look at this is that the the fact that the there 's complete separation between the observed features and in the output . it makes it cleaner , but then .
C: that 's true .
B: if the discourse does
D: what do you mean by that ?
B: the "" discourse admission fee "" node seems like it should point directly to the or increase the probability of "" enter directly "" versus "" going there via tourist "" .
C: or we could like add more , , middle nodes . like we could add node like do they want to enter it , which is affected by admission fee and by whether it 's closed and by whether it has door . so it 's like there are those are the two options . either like make an arrow directly or put new node .
B: that makes sense .
A: and if it if you do it if you could connect it too hard you may get such phenomenon that like "" so how much has it cost to enter ? "" and the answer is two hundred fifty dollars , and then the persons says "" want to see it . "" meaning "" it 's way out of my budget ""
B: there are places in germany where it costs two hundred fifty dollars to enter ?
A: nothing comes to mind . without thinking too hard . or or any good old pink floyd concert .
B: if you want to see "" the magic flute "" .
D: or maybe , famous restaurant . there are various things that you might not want to eat meal there but your own table .
B: the spagos of heidelberg .
A: that the nothing beats the admission charge prices in japan . so there , two hundred dollars is moderate for getting into discotheque . then again , everything else is free then once you 're ins in there . food and drink and . but , we can something somebody can have discussed the admission fee and the answer is if we , still , based on that result is never going to enter that building . because it 's just too expensive .
B: so the discourse refers to "" admission fee "" but it just turns out that they change their mind in the middle of the discourse .
D: you have to have some notion of not just there 's there 's change across several turns of discourse so how if any of this was discussed but how if it all this is going to interact with whatever general , other discourse processing that might be happen .
B: what discourse processing is are the how much is built into smartkom and
A: it works like this . the first thing we get is that already the intention is they tried to figure out the intention , simply by parsing it . and this won't differentiate between all modes , but at least it 'll tell us "" here we have something that somebody that wants to go someplace , now it 's up for us to figure out what going there is is happening , and , if the discourse takes couple of turns before everything all the information is needed , what happens is the parser parses it and then it 's handed on to the discourse history which is , one of the most elaborate modules . it 's it 's actually the whole memory of the entire system , that knows what wh who said what , which was what was presented . it helps an anaphora resolution and it and it fills in all the structures that are omitted , because you say "" , how can get to the castle ? "" , how much is it ? "" and "" would like to let 's do it "" and . so even without an ana anaphora somebody has to make that information we had earlier on is still here . because not every module keeps memory of everything that happened . so whenever the , person is not actually rejecting what happened before , so as in "" no really don't want to see that movie . 'd rather stay home and watch tv "" what movie was selected in what cinema in what town is going to be added into the disc into the representations every di at each dialogue step , by the discourse model discourse model , that 's what it 's called . and , , it does some help in the anaphora resolution and it also helps in coordinating the gesture screen issues . so person pointing to something on the screen , , the discourse model actually stores what was presented at what location on the on the screen so it 's it 's rather huge thing it has very clear interface . we can query it whether admission fees were discussed in the last turn and the turn before that or how deep we want to search which is question . how deep do we want to sear , but we should try to keep in mind that , , we 're doing this for research , so we should find limit that 's reasonable and not go , , all the way back to adam and eve . did that person ever discuss admissions fee fees in his entire life ? and the dialogues are pretty concise
D: so one thing that might be helpful which is implicit in the use of "" admission fee discussion "" as cue for entry , is thinking about the plans that various people might have . like all the different general schemas that they might be following this person is , finding out information about this thing in order to go in as tourist or finding out how to get to this place in order to do business . because then anything that 's cue for one of the steps would be slight evidence for that overall plan . they 're in non in more traditional ai kinds of plan recognition things you have , some idea at each turn of agent doing something , "" , wha what plans is this consistent with ? "" and then get some more information and then you see "" here 's sequence that this roughly fits into "" . it it might be useful here too . you 'd have to figure out what knowl what knowledge representation would work for that .
A: it 's in the these plan schemas . there are some of them are extremely elaborate , "" what do you need to buy ticket ? "" and it 's fifty steps , just for buying ticket at ticket counter , and maybe that 's helpful to look at it to look at those . it 's amazing what human beings can do . when we talked we had the example , , of you being person on ticket counter working at railway station and somebody runs up to you with suitcase in his hands , says new york and you say track seven , and it 's because that person actually is following , you execute whole plan of going through hundred and fifty steps , , without any information other than "" new york "" , inferring everything from the context . so , works . even though there is probably no train from here to new york ,
B: you 'd probably have to transfer in chicago .
A: but it 's possible . no you probably have to transfer also somewhere else . is that san francisco , chicago ? is that possible ?
B: one time saw report on trains , there was line that went from somewhere , maybe it was sacramento to chicago , but there was like california to chicago line of some sort . could be wrong though . it was while ago .
D: the transcontinental railroad , doesn't that ring bell ?
B: but if it 's still
D: it has to exist somewhere .
B: they might have blown it up .
A: it never went all the way , you always had to change trains at omaha ,
D: most of the way .
A: one track ended there and the other one started at five meters away from that
D: you seem to know better than we do so .
A: has anybody ever been on an amtrak ?
D: but not transcontinentally .
B: 'm frightened by amtrak myself . they seem to have lot of accidents on the amtrak .
A: their reputation is very bad . it 's not maybe reality .
D: it 's not like german trains . like german trains are really great
A: but , whether it 's which ones are safer , , statistically .
D: but they 're faster .
C: and there 's much more of them . they 're , it 's way better
A: used amtrak quite bit on the east coast and was surprised . it was actually . on boston new york , new york rhode island ,
C: 've done that thing .
A: that 's different issue .
B: this is going to be an interesting transcript .
C: want to see what it does with "" landmark - iness "" .
D: let 's all say it few more times .
B: it 'd help it figure it out .
D: so tha that structure that robert drew on the board was like more , cue - type - based , here 's like we 're gonna segment off bit of that comes from discourse and then some of the things we 're talking about here are more we mentioned maybe if they talk about , entering or som like they might be more task - based . so if there there 's some more than one way of organizing the variables into something
A: that what you guys did is really nicely sketching out different tasks , and maybe some of their conditions . one task is more likely you 're in hurry when you do that doing business , and less in hurry when you 're tourist tourists may have never have final destinations , because they are eternally traveling around so maybe what what happened what might happen is that we do get this task - based middle layer , and then we 'll get these sub - middle layers , that are more cue - based .
D: that feed into those ?
A: might be might be dichotomy of the world . so , suggest to for to proceed with this in the sense that maybe throughout this week the three of us will talk some more about maybe segmenting off different regions , and we make up some toy observable "" nodes "" is that what th
B: refined re just refine the
A: what 's the technical term ? for the nodes that are observable ? the "" outer layer "" ?
C: just observable nodes ,
A: feature ma make up some features for those identify four regions , maybe make up some features for each region and and , and middle layer for those . and then these should then connect somehow to the more plan - based deep space
B: just refine some of the more general nodes .
A: the - they will be aud ad - hoc for for some time to come .
C: the probabilities and all are completely ad - hoc . we need to look of them . but , they 're even like like , close to the end we were like , , we were like really ad - hoc .
D: it 's even distribution .
C: cuz if it 's like , if it 's four things coming in , and , say , some of them have like three possibilities and all that . so you 're thinking like hundred and forty four possible things numbers to enter ,
D: that 's terrible .
B: some of them are completely absurd too , like they want to enter , but it 's closed , it 's night time , there are tourists and all this weird happens at the line up and you 're like
C: the only like possible interpretation is that they are like come here just to rob the museum to that effect .
D: in which case you 're supposed to alert the authorities , and see appropriate action .
C: another thing to do , , is also to , to ask around people about other bayes - net packages . is srini gonna be at the meeting tomorrow ,
A: the day after tomorrow .
C: day after tomorrow .
B: who 's talking on wednesday ?
C: maybe we can ask him about it .
B: haven't jerry never sent out sent out an email , did he , ever ?
C: but he mentioned at the last meeting that someone was going to be talking ,
A: ben , then ,
D: it 's ben actually , giving his job talk . was just reading the screen .
A: that will be one thing we could do . actually , have , also we can , start looking at the smartkom tables actually wanted to show that to you guys now
B: do you want to trade ?
A: actually made mistake because it fell asleep and when linux falls asleep on my machine it 's it doesn't wake up ever , so had to reboot and if reboot without network , will not be able to start smartkom , because need to have network . so we 'll do that maybe
C: but once you start sart start smartkom you can be on you don't have to be on network anymore . is that the deal ?
B: why does smartkom need network ?
A: it looks up some that , , is that is in the written by the operating system only if it if you get dhcp request , so it , my computer does not ts ip address , unless it boots up with networking .
B: it 's plugged in .
A: and don't have an ip address , they can't look up they who localhost is , and and . but it 's , , simple solution . we can just , go downstairs and and look at this , but maybe not today . the other thing will have to report , data collection . we interviewed fey , she 's willing to do it , meaning be the wizard for the data collection , also maybe transcribe little bit , if she has to , but also recruiting subjects , organizing them , and . so that looks good . jerry however suggested that we should have trial run with her , see whether she can actually do all the spontaneous , eloquent and creativeness that we expect of the wizard . and talked to liz about this and it looks as if friday afternoon will be the time when we have first trial run for the data .
C: so who would be the subject of this trial run ? who will there be is one is you one of you gonna be the subject ?
A: liz also volunteered to be the first subject , which might be even better than us guys .
B: one of us ,
A: if we do need her for the technical , then one of you has to jump in .
B: like how we 've you guys have successfully narrowed it down . "" is one of you going to be the subject ? "" is one of you
D: haven't done it yet .
C: figured it has to be someone who 's , , familiar enough with the data to problems for the wizard , so we can , , see if they 're good .
D: plants ? someone who can plant difficult things .
C: that 's what we wanna check ,
D: in this case it 's it 's testing of the wizard rather than of the subject .
C: isn't that what it is ?
A: yes we would like to test the wizard , but , if we take subject that is completely unfamiliar with the task , or any of the set up , we get more realistic
C: that would be reasonable .
B: that 's probably good enough test of
C: having an actively antagonistic ,
D: that might be little unfair . 'm if we , you think there 's chance we might need liz for , whatever , the technical side of things ? 'm we can get other people around who anything , if we want another subject . like drag ben into it . although he might problems so , is it experimental setup for the , data collection ready determined ?
B: "" test the wizard . "" want that on - shirt .
A: it 's it 's experimental setup on the technical issue except we st we still need recording device for the wizard , just tape recorder that 's running in room . but in terms of specifying the scenario , we 've gotten little further but we wanted to until we know who is the wizard , and have the wizard partake in the ultimate definition probe . so so if on friday it turns out that she really likes it and we really like her , then nothing should stop us from sitting down next week and getting all the details completely figured out .
D: so the ideal task , will have whatever how much the structure of the evolving bayes - net will af affect like we wanna we wanna be able to collect as much of the variables that are needed for that ,
A: mmm - yea - some .
D: in the course of the task ? not all of them
A: bu - 'm even this this tango , enter , vista is , itself , an ad - hoc scenario . the the basic idea behind the data collection was the following . the data we get from munich is very command line , hardly anything complicated . no metaphors whatsoever . not rich language . so we wanted just to collect data , to get that elicits more , , that elicits richer language . and we actually did not want to constrain it too much , just see what people say . and then maybe we 'll discover the phenomenon the phenomena that we want to solve , , with whatever engine we come up with . so this this is parallel track , there they hopefully meet ,
D: so in other words this data collection is more general . it could it could be used for not just this task .
A: it should tell us , , what phenomenon could occur , it should tell us also maybe something about the difference between people who think they speak to computer versus people who think they speak to human being and the differences there . so it may get us some more information on the human - machine pragmatics , , that no one knows anything about , as of yesterday . and nothing has changed since then , and secondly , now that we have started to lick blood with this , and especially since johno can't stop tango - ing , we may actually include , , those intentions . so now we should maybe have at least one navigational task with explicit not ex it 's implicit that the person wants to enter , and maybe some task where it 's more or less explicit that the person wants to take picture , or see it . so that we can label it . that 's how we get corpus that we can label . whereas , , if we 'd just get data we 'd never they actually wanted , we 'd get no cues . that was that .
B: so is this the official end of the meeting now ?
D: looks like it .
C: so what 's "" economics , the fallacy "" ?
B: randomly label things . so that has nothing to do with economics or anything .
A: maybe we ought to switch off these things before we continue .
","The group discussed the first version of the Bayes-net used to work out a user's intentions when asking for directions from a navigation device.
Three intentions were identified: Vista ( to view ) , Enter ( to visit ) and Tango ( to approach ).
The structure of the belief-net comprises , firstly , a feature layer , which includes linguistic , discourse and world knowledge information that can be gleaned from the data.
It is possible for these variables to form thematic clusters(  eg ""entrance"" , ""type of object"" , ""verb"" ) , each one with a separate middle layer.
These feed , in turn , into the main middle layer , that defines more general hidden variables , such as the tourist/business status of the user.
The feature layer can end up being cue-based , while the middle layers task-based.
The latter determine the final probability of each intention in the output layer.
This first model of the belief-net was built in JavaBayes , since it is a free package , has a graphical interface , and it can take XML files as input.
At this stage , all the actual probabilities are ad-hoc and hand-coded.
However , there has been progress in the design and organisation of experiments , that will eventually provide data more useful and appropriate for this task.
It is necessary for the belief-net to have at least one layer of nodes between the features and the final output.
This makes the structure more flexible in terms of coding feature-layer probabilities.
Another technique to systematise the work is the thematic clustering of the features , each cluster forming a Bayes-net of each own: for example features like ""admission fee"" and ""opening hours"" can feed into an intermediate ""entrance"" node connecting to the main middle layer.
The next stage is to refine the set of feature nodes and identify possible clusters.
Although , in theory , traditional AI plan recognition techniques could also be helpful for inferring intentions , the schemas involved are too elaborate for this task.
Further work also includes discussing the possible advantages of Bayes-net packages , other than JavaBayes , with experts at ICSI.
If they continue using JavaBayes , a script to help with the inputting of probabilities in the nodes is needed , as the in-built method is cumbersome.
Finally , it was decided that at least some of the experiments designed for the new data collection initiative will factor in the intentions studied in the current task.
The set of cues that form the feature nodes is not well-defined yet.
Especially with lexical cues ( verbs , modifiers etc ) , no one offered specific intuitions as to how they might contribute to the inference of intentions.
Other features , like ""admission fee"" , may be intuitively linked with one of the outputs ( Enter ) , however , any probabilities are coded in an ad-hoc fashion and are by no means realistic.
Cases like this , where feature and output seem to be linked directly , bring the necessity of a middle layer in the belief-net to question.
Nevertheless , not having a middle layer would not allow for shifts in the discourse and would make the setting of probabilities and manipulation of the belief-net clumsy.
Some issues with the use of JavaBayes also arose: the addition of new variables in an existing node overwrites all previous settings , and the native text file where the probability tables are set is not easy to read; this makes adding and changing variables and nodes problematic.
Finally , it is unclear how much learning can be done on the created nets.
There was a demonstration of the structure and the function of a toy version of the belief-net for the intentionality task.
The features nodes include things like prosody , discourse , verb choice , ""landmark-iness"" of a building , time of day and whether the admission fee was discussed.
The values these nodes take feed into the middle layer nodes identified as hidden variables of the user/device interaction , such as whether the user is on tour , running an errand or in a hurry.
These , in turn , help infer whether the user wants to see , enter or simply approach a building.
The set of features nodes is derived from linguistic cues , world knowledge and discourse history.
SmartKom , although it does not code for intentions as specified in this task , provides a model of the discourse , which can be useful for the detection of features through querying and anaphora resolution.
Experiments for the collection of new data will start soon , since someone who will recruit subjects and help run the experiments has already been hired and the designing of the experiments has also progressed significantly.
"
ami_abstractive_summary,Bed014.txt,"B: mental mental palm pilot . hence no problem .
F: let 's see . so . what ? 'm supposed to be on channel five ? her . nope . doesn't seem to be ,
B: hello 'm channel one .
E: what does your thing say on the back ?
F: nnn , five . alright , 'm five .
D: sibilance . three , three . see , that matches the seat up there .
F: , it 's coming up then , or
D: cuz it 's that starts counting from zero and these start counting from one . ergo , the classic off - by - one error .
B: but mine is correct . it 's one .
D: your mike number is what we 're
E: look at the back .
D: 've bested you again , nancy .
B: no , but the paper 's correct .
D: the paper is correct .
B: look at the paper .
D: didn't det was saying the microphone , not the paper .
C: it 's always offset . .
B: yes , you 've bested me again . that 's how of our continuing interaction .
D: so is keith showing up ? he 's talking with george right now . is he gonna get rip rip himself away from that ?
B: he 'll probably come later .
C: he - he 's probably not , is my .
D: then it 's just gonna be the five of us ?
E: he was very affirmative in his way of saying he will be here at four . but , that was before he knew about that george lecture probably .
C: this this is not it 's not bad for the project if keith is talking to george . so my suggestion is we just forge ahead , .
B: are you in charge ?
E: had informal talks with most of you . so , eva just reported she 's really happy about the cbt 's being in the same order in the xml as in the be java declaration format so you don't have to do too much in the style sheet transversion . the , java the embedded bayes wants to take input , bayes - net in some java notation and eva is using the xalan style sheet processor to convert the xml that 's output by the java bayes for the into the , , bayes input .
F: actually , maybe could try , like , emailing the guy and see if he has any something already . that 'd be weird , that he has both the java bayes and the embedded bayes in
D: but that 's some conversion program ?
F: and put them into different formats .
D: you should demand things from him .
F: he could do that , too .
C: he charges so much . right . no , it 's good idea that you may as ask . .
E: and , , pretty mu on on the top of my list , would have asked keith how the "" where is ? "" hand parse is standing . but we 'll skip that . there 's good news from johno . the generation templates are done .
D: so the trees for the xml trees for the for the gene for the synthesizer are written . so need to do the , write new set of tree combining rules . but those 'll be pretty similar to the old ones .
C: you were gonna send me note about hiring didn't finish the sentence but he understood it .
D: he 's talking about .
C: but nancy doesn't .
E: so natural language generation produces not just surface string that is fed into text - to - speech but , surface string with syntax tree that 's fed into concept - to - speech . now and this concept - to - speech module has certain rules on how if you get the following syntactic structure , how to map this onto prosodic rules . and fey has foolheartedly to rewrite , the german concept syntax - to - prosody rules
B: didn't know she spoke german .
E: no , she doesn't . but she speaks english .
B: rewrite the german ones into english .
E: and therefore the , if it 's that we give her couple of more hours per week , then she 'll do that .
D: what language is that written is that scheme thing that you showed me ?
E: that 's the lisp - type scheme .
D: she knows how to program in scheme ?
E: my is asked for commented version of that file ? if we get that , then it 's doable , even without getting into it , even though the scheme li , is really documented in the festival .
D: if you 're not used to functional programming , scheme can be completely incomprehensible . cuz , there 's no like there 's lots of unnamed functions
C: anyway , it we 'll sort this out . but anyway , send me the note and then 'll - 'll check with , , morgan on the money . don't anticipate any problem but we have to ask . so this was {nonvocalsound} , on the generation thing , if sh she 's really going to do that , then we should be able to get prosody as . so it 'll say it 's nonsense with perfect intonation .
D: are we gonna can we change the voice of the of the thing , because right now the voice sounds like murderer .
E: we ha we have to change the voice .
B: wh - which one ?
D: the the little smarticus smarticus sounds like murderer .
A: that 's good to know .
D: "" have your reservations . ""
A: but will not give them to you unless you come into my lair .
E: it is , we have the choice between the , , usual festival voices , which already told the smartkom people we aren't gonna use because they 're really bad .
C: it 's the name of some program ,
B: . got it . .
A: the usual party voices .
B: that doesn't sound , exactly right either .
E: ogi has , , crafted couple of diphone type voices that are really and we 're going to use that . we can still , , agree on gender , if we want . so we still have male or female .
B: let 's just pick whatever sounds best . whatever sounds best . unfortunately , probably male voices , bit more research on .
D: does ogi stand for ? original german institute ?
C: oregon @ @ graduate institute it turns out there 's the long - standing links with these guys in the speech group . there 's this guy who 's got joint appointment , he 's - spends fair amount of time here . won't be problem .
E: and it 's probably also uninteresting for all of you to , learn that as of twenty minutes ago , david and , per accident , managed to get the whole smartkom system running on the , icsi linux machines with the icsi nt machines thereby increasing the number of running smartkom systems in this house from one on my laptop to three .
B: mmm , that 's good .
D: how was this by accident ?
B: tha - that 's the part didn't understand .
E: suggested to try something that was really even though against better knowledge shouldn't have worked , but it worked .
B: will it work again ,
E: maybe maybe bit for the ai intuition thing . and , , we 'll never found out why . it - it 's just like why the generation ma the presentation manager is now working ?
A: this is something you ha you get used to as programmer , right ? and it 's , it works out that way .
E: so , the people at saarbruecken and decided not to touch it ever again . that would work . was gonna ask you where something is and what we know about that .
B: where the "" where is "" construction is .
A: what what thing is this ?
E: but by , we can ask , , did you get to read all four hundred words ?
D: wa was looking at it . it doesn't follow logically . it doesn't the first paragraph doesn't seem to have any link to the second paragraph .
A: and so on .
D: each paragraph is good , though .
C: , it 's fine .
A: it was written by committee .
C: but the meeting looks like it 's , it 's gonna be good .
B: didn't know about it until robert told me , like ,
C: ra ran across it in don't even know where , some just some weird place . and , , , 'm surprised didn't know about it
B: , . was like , why didn't dan tell me ?
C: since we know all the invited speakers , right , or some so but anyway , so did see that . wha . before we get started on this st so also had email correspondence with daphne kohler , who said yes she would love to work with us on the , , , using these structured belief - nets and but starting in august , that she 's also got new student working on this and that we should get in touch with them again in august and then we 'll figure out way for you you to get connected with , their group . that 's , looks pretty good . 'll say it now . and it looks to me like we 're now at good point to do something start working on something really hard . we 've been so far working on things that are easy . which is mental spaces and and - or
B: it 's hard . it 's hard .
C: it 's hard puzzle . but the other part of it is the way they connect to these , , probabilistic relational models . so there 's all the problems that the linguists know about , about mental spaces , and the cognitive linguists know about , but then there 's this problem of the belief - net people have only done moderately good job of dealing with temporal belief - nets . which they call dynamic they incorrectly call dynamic belief - nets . so there 's term "" dynamic belief - net "" , doesn't mean that . it means time slices . and srini used those and people use them . one of the things would like to do over the next , , month , it may take more , is to st understand to what extent we can not only figure out the constructions for them for multiple worlds what the formalism will look like and where the slots and fillers will be , but also what that would translate into in terms of belief - net and the inferences . so the story is that if you have these probabilistic relational models , they 're set up , in principle , so that you can make new instances and instances connect to each other , and all that , so it should be feasible to set them up in such way that if you 've got the past tense and the present tense and each of those is separate , belief structure that they do their inferences with just the couplings that are appropriate . but that 's that 's , as far as tell , it 's it 's putting together two real hard problems . one is the linguistic part of what are the couplings and when you have certain , , construction , that implies certain couplings and other couplings , between let 's say between the past and the present , or any other one of these things and then we have this inference problem of exactly technically how does the belief - net work if it 's got , let 's say one in , , different tenses or my beliefs and your beliefs , or any of these other ones of multiple models . in the long run we need to solve both of those and my suggestion is that we start digging into them both , , in way we that , , th hopefully turns out to be consistent , and sometimes it 's actually easier to solve two hard problems than one because they constrain each other . if you 've got huge ra huge range of possible choices we 'll see . but anyway , so that 's ,
A: like , solved the problem of we were talking about how do you various issues of how come plural noun gets to quote "" count as noun phrase "" , occur as an argument of higher construction , but bare singular stem doesn't get to act that way . and it would take really long time to explain it now , but 'm about to write it up this evening . solved that at the same time as "" how do we keep adjectives from floating to the left of determiners and how do we keep all of that from floating outside the noun phrase "" to get something like "" the kicked dog "" . did it did it at once .
C: that 's great .
A: so maybe it 'll be similar thing .
C: no , know , th that is gonna be the key to this wh to th the big project of the summer of getting the constructions right is that people do manage to do this so there probably are some , , relatively clean rules , they 're just not context - free trees . and if we if the formalism is good , then we should be able to have , , moderate scale thing . and that is , keith , what encouraged george to be talking with you about . not the formalism yet but the phenomena . there was this , thing that nancy to in in weak moment this morning that
B: was really strong .
C: . in in friendly moment . anyway , , that we were that we 're gonna try to get , first cut at the revised formalism by the end of next week . probably skipping the mental spaces part .
A: right . do .
C: just trying to write up essentially what you guys have worked out so that everybody has something to look at . we 've talked about it , but only the innermost inner group currently , ,
B: and not even all of them really do .
A: there 's the group as whole knows but no individual member kno
C: that th there 's one of the advantages of document , right ? , is that it actually transfers from head to head . communication , documentation and . anyway , so , , with little luck let 's , let 's have that as goal anyway .
A: so , , what was the date there ? it 's friday .
C: no , no . no , we 're talking about week fr end of next week .
A: end of next week .
B: but , , but the two of us will probably talk to you at before th
A: you said beginning of
B: anyway , let 's talk separately about how
A: but after that , gung - ho .
C: , so someti sometime next week . now if it turns out that effort leads us into some big hole that 's fine . if you say we 're we 're dump dump . there 's really hard problem we haven't solved yet that , that 's just fine .
A: but at least try and work out what the state of the art is right now .
C: right , if to the extent that we have it , let 's write it and to the extent we don't , let 's find out what we need to do .
E: can we ? is it worth thinking of an example out of our tourism thing domain , that involves decent mental space shift or setting up
C: but but interrupted before keith got to tell us what happened with "" where is the powder - tower ? "" or whatever
A: , what was supposed to happen ? 've been actually caught up in some other ones , so , , , don't have write - up of or haven't elaborated on the ideas that we were already talking about
E: . we already came to the conclusion that we have two alternative paths that we two alternative ways of representing it .
A: it 's gone . the question of whether the polysemy is like in the construction or pragmatic .
B: one of them was th
E: is resolved later .
A: it has to be the second case . so ' you is it clear what we 're talking about here ? the question is whether the construction is semantic or like ambiguous between asking for location and asking for path .
B: so you might be , and asking for directions .
A: or whether the construction semantically , , is clearly only asking for location but pragmatically that 's construed as meaning "" tell me how to get there "" .
E: so assume these are two , , nodes we can observe in the bayes - net . so these are either true or false and it 's also just true or false . if we encounter phrase such as "" where is ? "" , should that set this to true and this to true , and the bayes - net figures out which under the situation in general is more likely ? or should it just activate this , have this be false , and the bayes - net figures out whether this actually now means ?
C: so that 's that 's separate issue . so th agree with you that , , it 's disaster to try to make separate constructions for every , pragmatic reading , although there are some that will need to be there . there 's some that
B: or have every construction list all the possible pragmatic implications of the same one .
C: you can't do that either . but , , almost certainly "" can you pass the salt "" is construction worth noting that there is this th this
A: so right , this one is maybe in the gray area . is it is it like that or is it just obvious from world knowledge that no one you wouldn't want to know the location without wanting to know how to get there or whatever .
E: or in some cases , it 's it 's quite definitely so that you just know wanna know where it is .
A: the question is , is this conventional or conversational implicature ?
B: might be , .
C: and , see , the more important thing at this stage is that we should be able to know how we would handle it in ei in the short run it 's more important to know how we would treat technically what we would do if we decided and what we would do if we decided , than it is to decide or right now .
A: which of that is . ,
B: which one it is . cuz there will be other examples that are one way or the other . right .
C: we know for that we have to be able to do both . so in the short run , let 's let 's be real clear on what the two alternatives would be .
E: and then the we had another idea floating around , which we wanted to , , get your input on , and that concerns the but we would have person that would like to work on it , and that 's ir - irina gurevich from eml who is going to be visiting us , , the week before , , august and little bit into august . and she would like to apply the ontology that is , being crafted at eml . that 's not the one sent you . the one sent you was from gmd , out of european crumpet .
C: it was terrible .
E: and one of the reas one of the those ideas was , back to the old johno observation that if if you have dialogue history and it said the word "" admission fee "" was , mentioned , it 's more likely that the person actually wants to enter than just take picture of it from the outside . now what could imagine to , , have list for each construction of things that one should look up in the discourse history , ? that 's the really stupid way . then there is the really clever way that was suggested by keith and then there is the , , middle way that 'm suggesting and that is you get , which is whatever , the ontology will tell us that castles have opening hours , that they have admission fees , they have whatever . and then , this is we go via thesaurus and look up certain linguistic surface structures that are related to these concepts and feed those through the dialogue history for each entity . we look it up check whether any of these were mentioned and then activate the corresponding nodes on the discourse side . but keith suggested that much cleaner way would be is , , to keep track of the discourse in such way that you if that something like that ha has been mentioned before , this just continues to add up ,
A: so if someone mentions admission fees , that activates an enter schema which sticks around for little while in your rep in the representation of what 's being talked about . and then when someone asks "" where is ? "" you 've already got the enter schema activated and you 're able to conclude on it .
C: so that 's certainly more realistic .
D: , is it doesn't it seem like if you just managed the dialogue history with thread , that , kept track of ho of the activity of cuz it would the thread would nodes like , needed to be activated , so it could just keep track of how long it 's been since something 's been mentioned , and automatically load it in .
C: you could do that . but here 's here 's way in th in the bl bayes - net you could you could think about it this way , that if at the time "" admissions fee "" was mentioned you could increase the probability that someone wanted to enter .
B: turn prior on .
D: we - th that 's what wa wasn't was wasn't thinking in terms of enter schemas .
C: fair enough , , but , in terms of the the current implementation
B: it would already be higher in the context .
C: th that th the the conditional probability that someone so at the time you mentioned it this is this is essentially the bayes - net equivalent of the spreading activation . it 's in some ways it 's not as good but it 's the implementation we got . we don't have connectionist implementation . now my is that it 's not question of time but it is question of whether another intervening object has been mentioned . we could look at dialo the other thing we ha we do is , is we have this data coming which probably will blow all our theories , so but my is what 'll probably will happen , here 's here 's proposed design . is that there 're certain constructions which , , for our purposes do change the probabilities of eva decisions and various other kinds th that the , , standard way that the these contexts work is stack - like or whatever , but that 's the most recent thing . and so it could be that when another , en tourist entity gets mentioned , you re essentially re - initiali , re - essentially re - initialize the state . and if we had fancier one with multiple worlds you could have , you could keep track of what someone was saying about this and that . "" wanna go in the morning
A: "" here 's my plan for today . here 's my plan for tomorrow . ""
C: or , in the morning 'm planning to go shopping , in the afternoon to the powder - tower tal so 'm talking about shopping and then you say , , , , "" what 's it cost ? "" . so one could imagine , but not yet . but do th think that the it 'll turn out that it 's gonna be depend on whether there 's been an override .
E: , if you ask "" how much does train ride and cinema around the vineyards cost ? "" and then somebody tells you it 's sixty dollars and then you say "" how much is , would like to visit the "" whatever , something completely different , "" then go to , , point reyes "" , it 's not more likely that you want to enter anything , but it 's , , complete rejection of entering by doing that .
B: so when you admit have admission fee and it changes something , it 's only for that particular it 's relational , right ? it 's only for that particular object .
C: and and the simple idea is that it 's on it 's only for for the current , tourist entity of instre interest .
E: so , has the current object been mentioned in with question about concerning its
C: no , no . it 's it it goes the other it goes in the other direction . when th when the this is mentioned , the probability of , let 's say , entering changes
B: of that object .
D: you could just hav , just , ob it it observes an er , it sets the node for "" entered "" or "" true "" ,
C: now , but ro - robert 's right , that to determine that , ? you may want to go through th thesaurus
D: "" discourse enter "" .
C: so , if the issue is , if so now th this construction has been matched and you say "" . does this actually have any implications for our decisions ? "" then there 's another piece of code that presumably does that computation .
B: so , forward chaining in way , rather than backward .
C: but but what 's robert 's saying is , and he 's right , is you don't want to try to build into the construction itself all the synonyms and all , all the wo 'll have to think about that . it th th of arguments in either direction on that . but somehow you want to do it .
E: it 's just another , , construction side is how to get at the possible inferences we can draw from the discourse history or changing of the probabilities , and - or
B: it 's like the other thing is , whether you have user model that has , , whatever , current plan , whatever , plans that had been discussed ,
D: what , what 's the argument for putting it in the construction ? is it just that the synonym selection is better , or ?
C: wel , the ar the the argument is that you 're gonna have the if you 've recognized the word , you 've recognized the word , which means you have lexical construction for it , so you could just as tag the lexical construction with the fact that it 's , , thirty percent increase in probability of entering . you so you could you could invert the whole thing , so you you tag that information on to the lexicon since you had to recognize it anyway . that that 's the argument in the other direction .
E: even though the lexical construction itself out of context , , won't do it . you have to keep track whether the person says "" but but 'm not interested in the opening times "" is more type .
C: there 's , ther there 's that as .
E: but , we 'll we have time to this is just sidetrack , it 's also something that people have not done before , is , abuse an ontology for these kinds of , , inferences , on whether anything relevant to the current something has been , has crept up in the dialogue history already , or not . have the , if we wanted to have that function in the dialogue hi dialogue module of smartkom , have the written consent of jan to put it in there .
C: , this is highly relevant to someone 's thesis .
E: that 's , 'm 'm keeping on good terms with jan .
C: you 've noticed that . so , it 's very likely that robert 's thesis is going to be along these lines , and the local rules are if it 's your thesis , you get to decide how it 's done . so if , if this is , if this becomes part of your thesis , you can say , hey we 're gonna do it this way , that 's the way it 's done .
B: yay , it 's not me . it 's always me when it 's someone 's thesis .
C: no , no ! no , no . we 've got lot we 've got lot of theses going .
A: there 's few of us around now .
B: now it 's not . yay !
E: let 's let 's talk after friday the twenty - ninth . then we 'll see how
C: right . so he 's got th he 's got meet meeting in germany with his thesis advisor .
B: he said he 's gonna finish his thesis by then .
E: should try to finish it by then . .
C: so , that 's the other thing . this is this is , speaking of hard problems , this is very good time , to start trying to make explicit where construal comes in and , where where the construction per - se ends and where construal comes in ,
B: we 've we 've done quite bit of that .
C: cuz this is clearly part of th
B: we 've been doing quite bit of that .
C: said . but that 's part of what the
B: we have many jobs for you , ro - robert .
C: , he 's gonna need this .
A: it seems to always land in your category . you 're lucky .
C: right . so . right . so thing that 's part of why we want the formalism , is because th it is gonna have implicit in it
E: was ? in the room ?
B: no , you weren't there on purpose .
A: made it much easier to make these decisions .
C: right . that 's tentative .
A: right , right .
C: they aren't decisions , they 're ju they 're just proposals .
A: yes . excuse me .
B: no , they 're decisions .
C: that that 's the point , is th
E: let 's call them constraints , around which one has to
B: there 's problem with that word , too , though .
C: anyway . but so that 's
D: but it he the decisions made wer had to do with my thesis . so consequently don't get to decide then that it 's robert 's job ?
B: 'll just pick piece of the problem and then just push the hard into the center and say it 's robert 's .
E: 've always been completely in favor of consensus decisions , so we 'll we 'll find way .
C: we we will ,
E: it it might even be interesting then to say that should be forced to , pull some of the ideas that have been floating in my head out of the , out of the top hat that metaphor is not going anywhere , .
C: ri - no . . so , , wh you had you ha you had done one draft .
E: yes , and , , it 's ha - none of that is still around ,
A: that 's normal .
B: it 's good didn't read it .
C: this is 'm shocked . this is the first time 've seen thesis proposal change . right . anyway , . so . but , , second that would be great . so , , sec you 're gonna need it anyway .
E: and would like to discuss it and , , get you guys 's input and make it bomb - proof . bullet - proof . that 's the word was looking for .
B: good luck . really .
C: so that , so th thi this , so this is the point , is we 're going to have to cycle through this , but th the draft of the proposal on the constructions is going to tell us lot about what we think needs to be done by construal . and , , we oughta be doing it .
E: we need we need some then we need to make some dates . meeting regular meeting time for the summer , we really haven't found one . we did thursdays one for while . talked to ami . it 's - it 's coincidence that he can't do couldn't do it today here .
B: usually , he can .
E: usually he has no real constraints .
C: and the ntl meeting moved to wednesday ,
E: it was just an exception .
C: you weren't here , but , and so , if that 's with you ,
A: it 's is it staying at the wednesday noon ? it was th off this week ,
B: always thought it was staying . it was just this week that we were changing it .
E: and , . how do we feel about doing it wednesdays ? because it seems to me that this is time where when we have things to discuss with other people , there they seem to be tons of people around .
C: the only disadvantage is that it may interfere with other no , you , people in this group connecting with
B: those people who happen to be around .
C: those people who might not be around so much .
A: to tell you the truth , 'd rath 'd , 'd would like to avoid more than one icsi meeting per day , if possible .
C: no , that 's fine .
E: the 'd like to have them all in one day , so package them up and then
C: people differ in their tastes in this matter .
B: 'm always here anyway ,
E: it 's , that
B: it doesn't matter .
C: @ @ that 's me too . 'm 'm here .
E: if one thing is , this room is taken at after three - thirty pr every day by the data collection . so we have subjects anyway except for this week , we have subjects in here . that 's why it was one . so we just knew
B: so did you just say that am't make one '
E: no , he can . so let 's say thursday one . but for next week , this is bit late . so would suggest that we need to talk about the the th
B: could we do thursday at one - thirty ? would that be horrible ?
E: because , , this room is again taken at two - thirty by morgan .
B: . you didn't tell me that . that 's fine .
E: and the meeting recorder meeting recording on meeting meetings
C: so you 're proposing that we meet tuesday .
E: how about that ?
B: we 're meeting tuesday . we usually meet tuesday or like , linguists , at two .
A: that 's right .
B: do you want to meet again here bef
D: is the speech - gen meeting still at on tuesdays ?
E: actually we we did scrap our monday time just because bhaskara couldn't come monday .
B: hhh . maybe do need palm pilot .
E: so there 's nothing 's impeding monday anymore either .
A: that doesn't apply to
D: although you wanted to go camping on monday er , take off mondays lot so you could go camping .
E: that 's another thing . . but , . , there are also usually then holidays anyways . like sometimes it works out that way .
B: , the linguists ' meeting happens to be at two , but that 's .
A: that should be relatively flexible be
B: pretty flexible , .
A: there 's just the two to four of us . and , , nancy and are just always talking anyway and sometimes we do it in that room . so , , .
E: so forget about the the camping thing . so let 's , any other problems ? but , suggested monday . if that 's problem for me then shouldn't suggest it .
D: ha - ha .
A: all of the proposed times sound fine with me .
C: whate what robert 's saying is that
A: earlier in the week
C: at least for next week , there 's lot of we want to get done , so why don't we plan to meet monday and we 'll see if we want to meet any more than that .
B: at one , two , three ?
E: one , two , three ? three 's too late .
C: , actually two is the earliest meet on monday .
E: two - thirty ?
C: here 'm blissfully agreeing to things and realizing that actually do have some scheduled on monday .
A: so that 's the eighteenth .
B: you guys will still remind me , right ? you 'll come and take all the headph the good headphones first and then remind me .
E: why do you ?
B: why do have this unless 'm gonna write ?
E: do get to see th , your formalism before that ?
B: would you like to ? was actually gonna work on it for tomorrow like this weekend .
E: wo would like would get notion of what you guys have in store for me .
C: @ @ , maybe mond - maybe we can put this is part of what we can do monday , if we want .
B: so there was like , , in my head the goal to have like an intermediate version , like , everything know . and then , would talk to you and figure out everything , that , see if they 're consistent .
A: why don't maybe you and should meet more or less first thing monday morning and then we can work on this .
B: that 's fine with me . you said you 're busy over th until the weekend , right ?
A: because kate has photography show .
B: that 's fine . so we might continue our email thing and that might be fine , too . so , maybe 'll send you some
A: if you have time after this 'll show you the noun phrase thing .
B: that would be . and we 'll you wanna
E: so the idea is on monday at two we 'll we 'll see an intermediate version of the formalism for the constructions ,
B: so that 's for you
E: and do an on - line merging with my construal ideas . so it won't be , like , for semi - formal presentation of my proposal . it 'll be more like towards finalizing that proposal .
B: cuz then you 'll find out more of what we 're making you do .
E: that 's fine .
A: oy , deadlines .
B: we 'll make presentation of your propo of your proposal .
E: perfect . can you also write it up ?
B: it 's like , "" this is what we 're doing . and the complement is robert . ""
E: 'll 'll send you 'll 'll send you style file , right ?
B: already sent you my fi my bib file .
A: someday we also have to we should probably talk about the other side of the "" where is "" construction , which is the issue of , , how do you simulate questions ? what does the simspec look like for question ? because it 's little different . we had to we had an idea for this which seemed like it would probably work .
C: simspec may need we may need to re - name that . ? so let 's think of name for whatever the this intermediate structure is . we talked about semspec , for "" semantic spec specification ""
A: it 's more general
C: so it 's minimal change .
B: only have to change one vowel . that 's great . all the old like graphs , just change the just , like , mark out the
C: right , little substi that 's what text substitution macros are for .
A: it 's good for you .
C: anyway , , so let 's let 's for the moment call it that until we think of something better . and , , we need to find part of what was missing were markings of all sorts that weren't in there , incl including the questions we didn't we never did figure out how we were gonna do emphasis in , the semspec .
B: we 've talked little bit about that , too , it 's hard for me to figure out with our general linguistic issues , how they map onto this particular one ,
C: but that 's part of the formalism is got to be , how things like that get marked .
B: do you have data , like the you have preliminary data ? cuz know , , we 've been using this one easy sentence and 'm you guys have , maybe you are the one who 've been looking at the rest of it it 'd it 'd be useful for me , if we want to have it little bit more data oriented .
A: to tell you the truth , what 've been looking at has not been the data so far , said "" alright let 's see if get noun phrases and , , major verb co , constructions out of the way first . "" and have not gotten them out of the way yet . so , have not really approached lot of the data , but like these the question one , since we have this idea about the indefinite pronoun thing and all that , , ca can try and , run with that , try and do some of the sentence constructions now . it would make sense .
E: do you wanna run the indefinite pronoun idea past jerry ?
A: the basic idea is that let 's see if formulate this .
E: so mary fixed the car with wrench . so you perform the mental sum and then , , "" who fixed the car with wrench ? "" you are told , to do this in the in analogously to the way you would do "" someone fixed the car with wrench "" . and then you hand it back to your hippocampus and find out what that , , and then come up with that so who that someone was .
A: the wh question has this as extra thing which says "" and when you 're done , tell me who fills that slot "" or . and , , this is way to do it , the idea of saying that you treat from the simulation point of view or whatever you treat , , wh constructions similarly to , indefinite pronouns like "" someone fixed the car "" because lots of languages , , have wh questions with an indefinite pronoun in situ or whatever ,
B: use actually the same one .
A: and you just get intonation to tell you that it 's question . so it makes sense
C: alright , which is in in logic , it 's it 's @ @ it 's actual ?
B: right . let 's put skolem constant in ,
C: that - that 's not that 's not saying it 's bad ,
A: right . no . .
C: it 's just that that the logicians have ,
A: that 's right . it makes sense from that point of view , too , which is actually better .
E: come up with this
A: anyway , but just that thing and we 'll figure out exactly how to write that up and so on , no , all the focus . we just dropped that cuz it was too weird and we didn't even know , like , what we were talking about exactly , what the object of study was .
C: , if , part of what the exercise is , by the end of next week , is to say what are the things that we just don't have answers for yet . that 's fine .
E: if you if you do wanna discuss focus background and then get me into that because , wo scientifically worked on that for almost two years .
A: then certainly we will .
B: you should definitely , be on that maybe by after monday we 'll you can see what things we are and aren't
A: we should figure out what our questions are , , to ask you .
C: wel - then hans . has haven't seen hans boas ?
B: he 's been around . just maybe not today .
C: so has he been involved with this ,
B: would say that tha that those discussions have been primarily , , keith and keith and me , like in th the meeting , he thin like the last meeting we had , we were all very much part of it
A: sometimes hans has been coming in there as like devil 's advocate type role , like "" this make , 'm going to pretend 'm linguist who has nothing to do with this . this makes no sense . "" and he 'll just go off on parts of it which definitely need fixing but aren't where we 're at right now ,
B: like like what you call certain things , which we decided long ago we don't care that much right now . but in sense , it 's good to know that he of all people like maybe lot of people would have much stronger reactions , so , , he 's like relatively friendly linguist and yet word like "" constraint "" causes lot of problems . and , so . right . so .
C: this is consistent with the role had suggested that he play , which was that one of the things would like to see happen is paper that was tentatively called "" towards formal cognitive semantics "" which was addressed to these linguists who haven't been following this . so it could be that he 's actually , at some level , thinking about how am going to communicate this story so , internally , we should just do whatever works , cuz it 's hard enough . but if he if he turns is really gonna turn around and help to write this version that does connect with as many as possible of the other linguists in the world then it becomes important to use terminology that doesn't make it hard it 's gonna be plenty hard for people to understand it as it is , but you don't want to make it worse .
A: no , right . , tha that role is , , indispensable but that 's not where our heads were at in these meetings . it was little strange .
C: . no , that 's fine . have to catch up with him , and wanted to get feeling for that . .
A: so what his take will be on these meetings exactly , . cuz sometimes he sounds like we 're talking bunch of goobledy - gook from his point of view .
B: it 's good when we 're when we 're into data and looking at the some specific linguistic phenomenon in english or in german , in particular , whatever , that 's great , and ben and hans are , if anything , more , they have more to say than , let 's say , would about some of these things . but when it 's like , , how do we capture these things , , it 's definitely been keith and who have , who have worried more about the
C: that 's good . that 's that should be the core group
B: which is fine .
C: that 's , , very close to the maximum number of people working together that can get something done .
B: we actually have we have been making progress , and its surprising .
C: definitely get that impression . . that 's great .
B: so anyone else would like ruin the balance of
C: but . but th then then we have to come back to the bigger group . great . and then we 're gon we 're gonna because of this other big thing we haven't talked about is actually implementing this ? so that the three of us are gonna connect tomorrow about that .
B: we could talk tomorrow . was just gonna say , though , that , , there was , out of meeting with johno came the suggestion that "" , could it be that the meaning constraints really aren't used for selection ? "" which has been implicit in the parsing strategy we talked about . in which case we we can just say that they 're the effects or the bindings . which , so far , in terms of like putting up all the constraints as , , pushing them into type constraints , the when 've , , propo then proposed it to linguists who haven't yet given me , we haven't yet thought of reason that wouldn't work . right ? as long as we allow our type constraints to be reasonably complex . so anyway , to be to talk about later .
C: it has to in the sense that you 're gonna use them eventu it 's , it 's , , generate and test thing ,
B: - . - .
C: and if you over - generate then you 'll have to do more . if there are some constraints that you hold back and don't use , in your initial matching then you 'll match some things
B: - . - .
C: don't think there 's any way that it could completely fail . it it could be that , you wind up the original bad idea of purely context - free grammars died because there were just vastly too many parses . exponentially num many parses . and so th the concern might be that not that it would fail , but that
B: that it would still generate too many . right ? so by just having semantic even bringing semantics in for matching just in the form of semantic types , right ?
C: it would still genera
B: like "" conceptually these have to be construed as this , and this "" might still give us quite few possibilities that , and and it certainly helps lot . le let 's put it that way .
C: no question . . and it 's it 's perfectly fine place to start . and say , let 's see how far we can go this way .
B: - . - .
D: it definitely makes the problem easier .
C: 'm 'm in favor of that . cuz it 's as , it 's real hard and if if we
B: so . , that 's tuesday . like th that 's the conclusion . .
E: so , you your dance card is completely filled now ?
B: and have nothing to do this weekend but work . no , that 's not really true ,
D: what about what about ddr ?
B: it 's almost true . don't have it this weekend , so , tsk don't have to worry about that .
C: ddr , he asked ?
B: speaking of dance , it 's it 's like game , but it 's for , like , dancing . hard to it 's like karaoke , but for dancing , and they tell you what it 's amazing . it 's so much fun . it 's so good . my friend has home version and he brought it over , and we are so into it . it 's so amazing . it 's one of your hobbies ? it 's great exercise , must say . 't to hear this . definitely . they have , like , places instead of like , instead of karaoke bars now that have , like , ddr , , didn't until started hanging out with this friend , who 's like "" , , bring over the ddr if you want . "" , dance revolution . he actually brought clone called stepping selection , but it 's just as good .
","Minor technical issues,such as format conversions for XML and JavaBayes and the full translation of the SmartKom generation module in English , are currently being resolved.
The voice synthesiser will also be replaced by better technology.
An important research issue to be investigated is how the concept of mental spaces and probabilistic relational models can be integrated into the belief-net.
Mental space interdependencies are based on relatively clean rules , since people seem to manage them easily.
A step towards this goal is the construction formalism being put together.
This module will eventually have to include ways to simulate questions , do emphasis and focus.
The constructions could be built assuming either conventional or conversational implicature.
At this stage both routes need to be examined.
The formalism will also serve as a starting point for the definition of construal mechanisms.
Similarly , issues like time plans and discourse stacks are dependent on how the ontology and discourse history are going to be structured and linked.
One suggestion was to use the spreading activation as a paradigm for activating nodes in the belief-net.
Finally , using type constraints in the construction analysis should work , as long as they are complex enough not to generate too many parses.
It is necessary to ask the JavaBayes programmer whether he already has XML conversion programs.
For the SmartKom generation module , all the syntax-to-prosody rules are going to be re-written for English.
Additionally , OGI can offer a range of synthesiser voices to choose from.
The focus of the next meeting , whose time was rescheduled , will be the discussion of the revised construction formalism.
The presentation will unify the existing ideas and help identify the areas in need of further work , such as how it can deal with time and tense use and how they affect inferences in belief-nets.
The ambiguity in a ""where is X?"" construction can be coded in the formalism as a semantic feature or pushed forward to the belief-net where pragmatic features will disambiguate it: in terms of system design , both options need to be investigated at this stage.
As the translation of the german SmartKom into English moves on , the generation rules may prove difficult to tackle for someone without experience in functional programming , as they are written in LISP.
As far as the construction analysis is concerned , the two problems that will need to be solved are to identify the couplings between constructions in different mental spaces and to define how inferences will work in the belief-net from a technical point of view.
Additionally , in the example ""Where is X?"" construction , the ambiguity ( Location or Path ) could be coded either in the semantics of the construction or as if determined by context.
The former could mean creating a different construction for every slight pragmatic variation.
On the other hand , some of the belief-net probabilities could be instantiated in the lexicon.
Specifying which approach to take when linking the ontology and the discourse history has also proven not to be straightforward.
Finally , it is still undecided where construal comes in , which would help delimit the constructions as well.
Several technical matters are being resolved: a conversion program is being written for data to be translated between XML and the Java Embedded-Bayes notation; the language generation templates are now available for the english version of the SmartKom system; SmartKom now works on three different machines at ICSI.
On the other hand , future collaboration on belief-nets has already been agreed with another research group.
The construction analysis and formalism are also progressing.
Several issues that have been dealt with were mentioned during the meeting: indefinite pronouns and wh-questions , noun-phrase structure , etc.
This analysis is being done with the help of a linguist , who often provides different perspectives to methods and terminology.
"
ami_abstractive_summary,Bed017.txt,"A: no , cuz she already told me it , before she told you .
E: no , she told me long time ago . she told me she told me like two weeks ago .
A: , it doesn't matter what time .
B: how to toggle the display width function
A: maybe she hadn't just started transcribing me yet .
D: what is it ?
E: let me explain something to you . my laugh is better than yours .
A: beg to differ . but you have to say something genuinely funny before you 'll get an example .
D: how to get to the next page . here .
E: you should be at least be self - satisfied enough to laugh at your own jokes .
A: no , it 's different laugh .
E: ! holy mackerel .
D: wasn't even doing anything . .
E: eva 's got laptop , she 's trying to show it off .
D: that was actually robert 's idea . but anyhow .
F: so , here we are . so we haven't had meeting for while , and probably won't have one next week , number of people are gone . so robert , why don't you bring us up to date on where we are with edu ?
B: in in smaller group we had , talked and decided about continuation of the data collection . so fey 's time with us is almost officially over , and she brought us some thirty subjects and , collected the data , and ten dialogues have been transcribed and can be looked at . if you 're interested in that , talk to me . and we found another , cogsci student who 's interested in playing wizard for us . here we 're gonna make it little bit more complicated for the subjects , this round . she 's actually suggested to look , at the psychology department students , because they have to partake in two experiments in order to fulfill some requirements . so they have to be subjected , before they can actually graduate . we want to design it so that they really have to think about having some time , two days , , to plan certain things and figure out which can be done at what time , package the whole thing in in re in few more complicated , structure . that 's for the data collection . as for smartkom , 'm the last smartkom meeting mentioned that we have some problems with the synthesis , which as of this morning should be resolved . and , so , "" should be "" means they aren't yet , but have the info now that need . plus , johno and are meeting tomorrow , so maybe , when tomorrow is over , we 're done . and ha hav we 'll never have to look at it again maybe it 'll take some more time , to be realistic , but at least we 're we 're seeing the end of the tunnel there . that was that . don't think we need to discuss the formalism that 'll be done officially once we 're done . something happened , in on eva 's side with the prm that we 're gonna look at today , we have visitor from bruchsal from the international university . andreas , you 've met everyone except nancy .
A: hi . hi .
B: hi . hi .
A: so when you said "" andreas "" you were talking about stolcke . now know that we aren't ,
B: andy , you actually go by andy ,
C: cuz there is another andreas around , so , to avoid some confusion .
B: that will be reuter ? so my scientific director of the eml is also the dean of the international university , one of his many occupations that just contributes to the fact that he is very occupied . he @ @ might tell us little bit about what he 's actually doing , and why it is somewhat related , and by using maybe some of the same technologies that we are using . and . was that enough of an update ? in what order shall we proceed ? maybe you have your on - line
D: so , 've be just been looking at , , what are you doing ? 've been looking at the prm . so , this is , like the latest thing have on it , sorta constructed couple of classes . like , user class , site class , and , time , route , and then and query class . and tried to simplify it down little bit , so that actually , look at it more . it 's the same paper that gave to jerry last time . so took out lot of , lot of the decision nodes , and then tried to the red lines on the , , graph are the , relations between the different , classes . like , user has like , query , and then , also has , , reference slots to its preferences , the special needs and , , money , and the user interest . this is more or less similar to the flat bayes - net that have , , with the input nodes and all that . so tried to construct the dependency models , lot of these got from the flat bayes - net , and what they depend on , and it turns out , , the cpt 's are really big , if do that , so tried to see how do , put in the computational nodes in between . and what that would look like in prm . and so ended up making several classes actually , , class of with different attributes that are the intermediate nodes , and one of them is like , time affordability money affordability , site availability , and the travel compatibility . and so some of these classes are some of these attributes only depend on from , say , the user , or just from , , like the site . like , , these here , it 's only like , user , but , if you look at travel compatibility for each of these factors , you need to look at pair of , , what the , preference of the user is versus , , what type of an event it is , or , which form of transportation the user has and whether , , the onsite parking matters to the user , in that case . and that makes the scenario little different in prm , because , , then you have one - user objects and potentially you can have many different sites in mind . for each of the site you 'll come up with this rating , of travel compatibility . and , they all depend on the same users , but different sites , 'm tr wa have been trying to see whether the prm would make it more efficient if we do inferencing like that . you end up having fewer number of nodes than in flat bayes - net , cuz otherwise you would it 's probably the same . no , you would definitely have be able to re - use , like , , all the user , and not having to recompute lot of the , because it 's all from the user side . so if you changed sites , you can , , save some work on that . in the case where , it depends on both the user and the site , then 'm still having hard time trying to see how , using the prm will help . so anyhow , using those intermediate nodes then , this would be the class that represent the intermediate nodes . and that would it 's just another class in the model , with , , references to the user and the site and the time . and then , after you group them together this no the dependencies would of the queries would be reduced to this . and so , , it 's easier to specify the cpt and all . so that 's about as far as 've gone on the prm .
F: so you didn't yet tell us what the output is . so what decisions does this make ?
D: so it only makes two decisions , in this model . and one is how desirable site is meaning , , how good it matches the needs of user . and the other is the mode of the visit , whether th it 's the eva decision . so , instead of , doing lot of , , computation about , , which one site it wants of the user wants to visit , 'll come , try to come up with like , list of sites . and for each site , , where how it fits , and rating of how it fits and what to do with it . anything else missed ?
F: so that was pretty quick . she 's ac eva 's got little write - up on it that , probably gives the details to anybody who needs them . the you you didn't look yet to see if there 's anybody has implementation .
D: no , not yet ,
F: so one so one of the questions , , about these ms is we aren't gonna build our own interpreter , so if we can't find one , then we , go off and do something else and until one appears . so one of the things that eva 's gonna do over the next few weeks is see if we can track that down . the people at stanford write papers as if they had one , but , , we 'll see . so anyway . so that 's major open issue . if there is an interpreter , it looks like , what eva 's got should run and we should be able to actually , try to solve , , the problems , to actually take the data , and do it . and we 'll see . actually is cleaner , and the ability to instantiate , , instance of people and sites and , , will help in the expression . whether the inference gets any faster or not . it wouldn't surprise me if it if it doesn't . it 's the same information . there are things that you can express this way which you can't express in normal belief - net , without going to some incredible hacking of rebuilding it on the fly . the notion of instantiating your el elements from the ontology and fits this very nicely and doesn't fit very into the extended belief - net . so that was one of the main reasons for doing it . so , , people who have thought about the problem , like robert it looked to me like if eva were able to come up with , value for each of number of , sites plus its eva thing , that travel planner should be able to take it from there . and , with some other information about how much time the person has and whatever , and then plan route .
B: - , , , first of all , great looks , mu much cleaner , nnn , nnn , certain certain beauty in it , so , , if beauty is truth , then , we 're in good shape . as , , mentioned before we probably should look at the details . so if you have write - up then , 'd love to read it you go all the way back to the very top ? these @ @ these when these are instantiated they take on the same values ? that we had before ?
D: 't really see the whole thing .
B: or are they have they changed , in sense ?
D: leave them to similar things . some of the things might that might be different , maybe like are that the hours for the site . and , eventually that to mean whether they 're open at this hour or not . and status would be , , more or less like , whether they 're under construction , and or like that .
B: and the , , other question would have is that presumably , from the way the stanford people talk about it , you can put the probabilities also on the relations .
D: which is the structural uncertainty ?
F: that was actually in the previous the ubenth . don't remember whether they carried that over to this or not ,
B: it 's in the definition or in the in daphne 's definition of prm is that classes and relations , and you 're gonna have cpt 's over the classes and their relations . more uncertainty , or
D: remember them learning when , , you the structure for , but don't remember reading how you specify
B: that would be exactly my question .
D: wh to start with .
F: so , , the plan is when daphne gets back , we 'll get in touch and supposedly , , we 'll actually get deep connected to their work somebody 'll , if it 's group meeting once week probably someone 'll go down and , whatever . so , we 'll actually figure all this out .
B: then the long term perspective is pretty clear . we get rocking and rolling on this again , once we get package , if , when , and how , then this becomes foregrounded focused , again . until then we 'll come up with something that 's @ @ that 's way more complicated for you . because this was laughingly easy ,
D: actually had to take out lot of the complicated , cuz made it really complicated in the beginning , and jerry was like , "" this is just too much "" .
F: you could , from this , go on and say suppose there 's group of people traveling together and you wanted to plan something that somehow , with some pareto optimal , , thing for
A: that 's good . that 's definitely job for artificial intelligence . except for humans can't really solve it either , so .
B: that 's not even something humans
F: that 's the that would be , you could sell it , as you don't have to fight about this , just give your preferences to the
A: and then you can blame the computer .
B: but what does it would pote potential result be to split up and never talk to each other again ?
A: that should be one of them .
E: that 'd be .
F: so . so there there are some , , , elaborations of this that you could try to put in to this structure , but don't 's worth it now . because we 're gonna see what else what else we 're gonna do . it 's good , and there were couple other ideas of , things for eva to look at in the interim .
B: good . then , we can move on and see what andreas has got out his sleeve . or andy , for that matter ?
C: so , , for having me here , first of all . so maybe just little background on my visit . so , , 'm not really involved in any project , that 's that 's relevant to you , at the moment , the reason is really for me , to have an opportunity to talk to some other researchers in the field . and and so 'll just give you real quick introduction to what 'm working on , and , hope that you have some comments or , maybe you 're interested in it to find out more , and so 'll be , happy to talk to you and , 'd also like to find out some more and maybe 'll just walk around the office and then and ask some questions , , in couple days . so 'll be here for , tomorrow and then , the remainder of , next week . so , , what started looking at , , to begin with is just , content management systems , in general . what 's the state of the art there is to you have bunch of documents or learning units or learning objects , and you store meta - data , associate to them . so there 's some international standards like the - triple - , there 's an - triple - , lon standard , and , these fields are pretty straightforward , you have author information , you have , size information , format information and so on . but they 're two fields that are , more interesting . one is you store keywords associated with the with the document , and one is , you have , , what is the document about ? so it 's some taxonomic , ordering of the of the units . now , if you put on your semantic glasses , you say , that 's not all that easy , because there 's an implicit , , assumption behind that is that , all the users of this system share the same interpretation of the keyword and the same interpretation of , whichever taxonomy is used , that 's that 's very that 's key point of these systems and they always brush over this real quickly without really elaborating much of that and , the only thing that really works out so far are library ordering codes , which are very , very coarse grain , so you have some like , science , biology , and then but that 's really all that we have at the moment . so there 's huge , , need for improvement there . now , what this standard like this would give us is we could , with search engine just query , different repositories all over the world . but we can't really so what 'm what try to do is , to have , so . so the scenario is the following , you 're working on some project and you encounter certain problem . now , what we have at our university quite bit is that , students , try to program certain assignment , , they always run into the same problems , and they always come running to us , and they 'll say why 's it not it 's not working , and we always give out the same answer , so we thought , , it 'd be to have system that could take care of this , and so , what want to build is smart system . now , what you need to do here is you need to provide some context information which is more elaborate than "" 'm looking for this and this keyword . "" and that don't need to tell you this . 'm 'm you have the same when somebody utters sentence in certain , , context it , and the same sentence in another context makes huge difference . so , want to be able to model information like , , so in the in the context of developing distributed systems , of at computer science school , what software is the person using , which homework assignment is he or she working on at the moment , maybe what 's the background of that student 's which error message was encountered . so this information should be transmitted , , when certain document is retrieved . so we somehow need to have formalized , way of writing this down , and that 's where the shared interpretation of certain terms and keywords comes in again . and , using this and some , knowledge about the domain you can do some simple inferences . like that when somebody 's working about , working on servlets , he 's using java , cuz servlets are used are written in java . so some inferences like that , now , , using this you can infer more information , and you could then match this to the meta - data of off the documents you 're you 're searching against . so , what wanna do is have some given these inputs , and then compute how many documents match , and use this as metric in the search . now , what plan to do is want to do try to improve the quality of the search results , and want to do this by having depth , steepest descent approach . so if knew which operating system the person was working on , would this improve my search result ? and and having , symbolic formalized model of this could simply compute that , and find out which which questions are worth , asking . and that 's what then propagate back to the user , and try to optimize the search in this way . now , the big problem that 'm facing right now is , it 's fairly easy to hack up system quickly , that works in the small domain , but the problem is the scalability . and , so robert was mentioning , earlier today is that , microsoft with their printer set up program has bayesian network , which does exactly this , but there you face problem that these are very hard to extend . and so , what 'm what try to do is try to model this , in way that you could really combine , knowledge from very different sources , and , looking into some of the ideas that the semantic web community , came up with . trying to have , an approach how to integrate certain representation of certain concepts and also some computational rules , what you can do with those . what 'm also looking into is probabilistic approach into this because document retrievals is very fuzzy procedure , so it 's probably not that easy to simply have symbolic , computational model . that that probably isn't expressive enough . so . so that 's another thing , which you 're also , looking into right now . and then , as an add - on to this whole idea , , that would be now , depending on what the search engine or the content repository depending on which , , which , rules and which ontologies it uses , or its view of the world , you can get very different results . so it might ma make lot of sense to actually query lot of different search engines . and there you could have an idea where you actually have peer to peer approach , where we 're all carrying around our individual bookshelves , and , if you have question about homework , it 's probably makes sense to ask somebody who 's in your class with you , the guru in the certain area , rather than going to some yahoo - like , search engine . so these are some of the just in nutshell , some of the ideas . and lot of the even though it 's it 's very different domain , but lot of the , , issues are fairly similar .
A: and so some of the how much about the larger heidelberg project ,
C: know , know abou about it .
A: so it seems like lot of some of the issues are the same . it 's like , , , the context - based factors that influence how you interpret ,
C: - . - .
A: how to interpret . in in this case , infer in knowing wanting to kinds of things to ask . we - we 've talked about that , but we haven't worried too much about that end of the discourse . but maybe you guys had that in the previous models .
B: in in one one mmm , small difference in in way , is that he doesn't have to come up with an answer , but he wants to point to the places
A: documents that have the answers .
C: so . so 'm 'm not building an expert want to build smart librarian , that can point you to the right reference . don't wanna compute the answer , so it 's little bit easier for me .
B: , you have to still understand what the content says about itself , and then match it to what you think the informational needs
A: so you also don't have to figure out what the content is . you 're just taking the keywords as topic text ,
C: assume that the there will be learning systems that tag their content . @ @ and what what envision is that you rather than just supplying bunch of keywords you could for an faq you could state like logic condition , when this document applies . so "" this document explains how to set up your , mail account on linux "" like this . so . so something very specific that you can then but the that the key point with these , learning systems is that , learning system is only as good as the amount of content it carries . you can have the best learning system with the best search interface , if there 's no content inside of it , it 's not very useful . so ultimately because , developing these rules and these inference inferences is very costly , so , you must be able to reuse some existing , domain information , or or ontologies that other people wrote and then try to integrate them , and then also search the entire web , rather than just the small , content management system . so that 's that 's crucial for the success of or @ @
A: so , you 're not 'm trying to figure out how it maps to the kinds of things that we 've talked about in this group , and , actually associated groups , cuz some of us do pretty detailed linguistic analyses , and 'm guessing that you won't be doing that ? so , you take the query , and
F: on the other hand , , framenet could be useful . so do the framenet story ?
C: not too much ,
F: th - that 's another thing you might wanna look into while you 're here .
C: have rough overview .
F: because , , , the standard story is that keyworks keywords evoke frames , and the frames may give you additional keywords or , if that that bunch of keywords , indicate frame , then you can find documents that actually have the whole frame , rather th than just , individual
C: mmm . mmm .
F: so there 's lot of , and people are looking at that . most of the work here is just trying to get the frames right . there 's linguists and and there 's lot of it and they 're they 're busily working away . but there are some application efforts trying to exploit it . and this looks it seems to be that this is place where you might be able to do that .
C: 'm could learn lot about , , just how to how to come up with these structures , cuz it 's it 's very easy to whip up something quickly , but it maybe then makes sense to me , but not to anybody else , and if we want to share and integrate things , they must , they must be designed really .
B: remember the , prashant story ? the no linguistic background person that the iu sent over here . and andreas and tried to come up wi or we had come up actually with with him working on an interface for framenet , as it was back then , that would do some of the work for this machine , which , never got done because prashant found happy occupation
F: know , it he he did what he did was much more sensible for him .
B: but so 'm just saying , the , we had that idea
F: the idea was there . , .
B: to exploit framenet there as .
F: actually you guys never
B: and srini 's doing information extraction also , with that framenet base .
F: so you guys never sent anybody else from .
C: except except prashant ?
F: this was supposedly an exchange program , and we , it 's fine . we don't care , but it just 'm little surprised that , andreas didn't come up with anyone else he wanted to send . had forgotten to be honest with you , 'd forgotten we had program .
B: it 's in the program ?
C: it 's it 's really the lack of students , at iu at the moment .
F: no , no . there was whole co there was little contract signed .
C: . it 's ju it 's more the lack of students , really , and we have all these sponsors that are always eager to get some teams . if were student , 'd love to come here , rather than work for some german {nonvocalsound} company , or
B: you are being recorded right now , so beware .
C: didn't say anybody to anything to offend except for the sponsors maybe ,
F: right . so thi tha that 's that 's one of the things that might be worth looking into while you 're here . unfortunately , srini , who is heavily involved in daml and all this is himself out of town .
C: 'll go to the , semantic web workshop , , in two weeks .
F: for some reason he 's not doing that .
A: he had other things to do .
F: why he @ @ , who knows ? anyway , , you 'll see you 'll certainly see lot of the people there .
A: the other person of is dan gildea ? because he did some work on topic spotting
F: st - statistical . that would be very good idea .
A: which is , , you . don't depending on how you wanna integrate with that end , like , taking the data and fig you said the learning systems that figure out we there 's someone in icsi who actually has been working on has worked on that kinda , and he 's worked with frame net , so you could talk to him about , , both of those things at once .
C: - . - .
A: and he just finished writing draft of his thesis . dan gildea , gildea .
C: so , , who is that again ?
A: and , he 's in one of the rooms on the fifth floor and ,
B: take you to his office . it 's just around the corner .
A: if you fal solve the problem , hope you can do one for us too .
F: alright , was there anything else for this ? one of these times soon we 're gonna hear about construal .
B: have it was november two thousand three or some no . wh - had something in my calendar .
E: that 's long way away .
B: maybe bribe my way out of this . so did some double checking and it seems like spring break in two thousand one .
A: talk about changing the topic .
F: no , but he 's he 's as you said , he 's , like the state legislature , he 's trying to offer us bribes .
A: at least this is private meeting . right , exactly , that 's the link .
B: this , they refused the budget again ? is it so about citris ?
F: we 're , , involved in literally three hundred million dollar , program . with the state of california . and , the state of california is now month and half behind its legis its legally required date to approve budget . so the budget has not been approved . and two days ago there 's two , so , two branches of legislature . one branch approved it , yesterdayday there was this that the other branch would just approve it , but now there 's actually little back sliding to people who approved it got flak from there , ! have to tell you wonderful story about this , and then we 'll go . so , it turns out wound up having lunch today with guy named tom kalil . and , , he now works at berkeley . he 's hired to run lot of citris , even though we don't have the money they so they 've been hiring people right and left , so , , they think the money 's coming . so and he was , , the chief staffer to clinton on technology matters . he was in the white house , don't remember what he was saying . anyway , like that . and , is now doing all the politics for citris , but also , has , lot of interest in , actually doing things for society , so digital divide and like that . so that 's interesting to me but maybe not to you . but the really interesting thing was , he st he said something about , 'm interested in things that have high social multiplier , something that is of great social value . he said , "" "" , this was his only example , "" if you had adult literacy program that was as good as an individual tutor , and as compelling as video game , then that would have huge social impact "" . said , "" great ! that 's good problem to work on . "" anyway . so it was that , he 's got this view , of , that 's what you should try to do , and , , language would be good way to do it .
A: mmm . definitely .
F: so anyway , that 's the end of the story .
A: but for adults and not for the children .
F: didn't push him on the ch on the child thing , again , if you if you and this was this was literacy , which actually is somewhat different problem . so this is reading , rather than teaching another project we started on , and didn't get funded for was , , to try to build an automatic tutoring program , for kids whose first language wasn't english . which is like half the school population in california . something like that , enormous problem in california , and the idea was if we 're so smart about language understanding and speech understanding , couldn't we build , programs that would be tutors for the kids . we think we could . anyway . so so but this is slightly different problem , know none of us have the spare time to look at it right now , but it it 's it 's interesting and may , talk to him some more about is somebody already doing this , and like that . so anyway , that was that was today 's little story .
B: so did manage to get pull my head out of the sling by sidetracking into citris ,
F: no , no .
B: but or temporarily putting it out of the sling but , 'll volunteer to put it right back in by stating that am among some other things in the process of writing up that we have been discussing at our daily meetings , and also revising , for all the comments , the the original construal proposal . and , if put one and one together , may end up with number that 's greater than one and that potentially present once you get back .
A: greater than two ?
F: you 're good .
B: nnn . sometimes , the sum is not less than the
F: anyway . , so , so that 'd be great , but 'd it 's it 's time again ,
B: but , and hopefully all sidetracking , other things will have disappeared , soon .
","The first phase of the data collection has finished.
There is a new wizard for phase two , during which subjects will be given more complex scenarios.
Also finished are the modifications on SmartKom: the remaining glitches will take no more than a day to iron out.
A big part of the meeting was covered by the presentation of the PRM of the proposed system.
An alternative representation of the Bayes-net , it depicts context features as classes , and dependencies as relations between them.
The current outputs show the desirability of a site , as well as its EVA mode.
The fact that this model allows for instantiations of classes fits the research purposes much better than the extended belief-net.
Following this , a visiting researcher presented an overview of a parallel project at the International University.
It attempts to build a smart tutoring system for a computer science course.
The assumption is that document searches can give more personalised results , if they take into account contextual parameters ( user , situation ).
Although no detailed linguistic analysis takes place , it was suggested that the use of FrameNet could be a useful approach.
There were also further suggestions for meetings with ICSI researchers.
As the data collection is going into its second phase , more complex scenarios will be used to generate more intricate dialogues.
Subjects can be recruited from within the Psychology department students , since such participation in experiments is compulsory in their syllabus.
As the work on creating a PRM for the system has progressed , it is now necessary to find an implementation that can work as a PRM interpreter.
There are no plans to build one from scratch , but it seems that other research groups at Stanford may already have one.
Moreover , closer collaboration with the local PRM group will be pursued with additional participation in their meetings.
An early version of the PRM of the system presented the same problem as a flat Bayes-net: the CPT's become too large.
Another PRM issue that arose and remained unclear was how the probabilities are specified ( instead of learnt ) on the actual relations between the classes.
Furthermore , the lack of a PRM interpreter is an open issue.
It is not within the remit of the project to build one from scratch , therefore , an existing implementation has to be found.
On the other hand , the discussion about the smart tutoring system being built at the International University showed the importance of finding out  which context parameters are influential in a given domain.
It is easy to hack up a system for a small domain , but making it scalable is much more difficult.
Finally , there was a passing mention of problems encountered with the speech synthesis module of SmartKom.
The first phase of the data collection has been completed.
Thirty subjects were recorded in total.
Of those dialogues , ten have been transcribed.
A new wizard will carry out the second phase.
On top of this , a presentation of a PRM of the proposed system took place.
The PRM comprises a set of classes , such as ""user"" , ""site"" , ""route"" , ""time"" and ""query"" with relations between them.
Another class incorporates a number of attributes ( ""money affordability"" , ""travel compatibility"" etc ) modelling the intermediate nodes of the Bayes-net , as well as references to the other classes in the model.
This model is much cleaner , and it also makes it easier to specify the CPT's.
At this stage , the model makes two decisions ( outputs ): how much a site fits a user's needs and what the user intention is in EVA terms.
"
ami_abstractive_summary,Bro014.txt,"A: it 's not very significant .
D: channel three . alright .
B: did you solve speech recognition last week ? let 's do image processing .
C: yes , again . we did it again , morgan .
E: doo - doop , doo - doo .
A: what 's wrong with ?
B: it 's april fifth . actually , hynek should be getting back in town shortly if he isn't already .
C: is he gonna come here ?
B: we 'll drag him here . know where he is .
C: so when you said "" in town "" , you mean oregon .
B: , , this end of the world , is really what ,
E: doo , doo - doo .
B: cuz he 's been in europe .
E: doo - doo .
C: have something just fairly brief to report on . did some experim , just few more experiments before had to , , go away for the , that week . was it last week or whenever ? so what was started playing with was the th again , this is the htk back - end . was curious because the way that they train up the models , they go through about four rounds of training . and in the first round they do , it 's three iterations , and for the last three rounds they do seven iterations of re - estimation in each of those three . that 's part of what takes so long to train the the back - end for this .
B: didn't quite get that . there 's there 's four and there 's seven
C: maybe should write it on the board . so , there 's four rounds of training . you could say iterations . the first one is three , then seven , and seven . and what these numbers refer to is the number of times that the , , re - estimation is run . it 's this program called
B: but in htk , what 's the difference between , , an inner loop and an outer loop in these iterations ?
C: so what happens is , , at each one of these points , you increase the number of gaussians in the model .
B: this was the mix up .
C: the mix up .
B: that 's right .
C: and so , in the final one here , you end up with , for all of the digit words , you end up with , , three mixtures per state , in the final thing . so had done some experiments where was want to play with the number of mixtures . wanted to first test to see if we actually need to do this many iterations early on .
E: one , two ,
C: ran couple of experiments where reduced that to to be three , two , , five , , and got almost the exact same results . and but it runs much faster . it only took something like , , three or four hours to do the full training ,
B: as opposed to ?
C: as opposed to wh what , sixteen hours like that ? it takes you have to do an overnight , the way it is set up now . even we don't do anything else , doing something like this could allow us to turn experiments around lot faster .
B: and then when you have your final thing , do full one , so it 's
C: and when you have your final thing , we go back to this . and it 's real simple change to make . it 's like one little text file you edit and change those numbers , and you don't do anything else . and then you just run . so it 's very simple change to make and it doesn't seem to hurt all that much .
A: so you run with three , two , five ? that 's
C: have to look to see what the exact numbers were . was , like , three , two , five , but 'll 'll double check . it was over week ago that did it , so 't remember exactly . but it 's so much faster . it makes big difference . so we could do lot more experiments and throw lot more in there .
B: that 's great .
C: the other thing that did was , , compiled the htk for the linux boxes . so we have this big thing that we got from ibm , which is five - processor machine . but it 's running linux . so , you can now run your experiments on that machine and you can run five at time and it runs , , as fast as , , , five different machines . 've forgotten now what the name of that machine is but send email around about it . and so we 've got it now htk 's compiled for both the linux and for , , the sparcs . you have to make you have to make that in your dot cshrc , , it detects whether you 're running on the linux or sparc and points to the right executables . and you may not have had that in your dot cshrc before , if you were always just running the sparc . tell you exactly what you need to do to get all of that to work . but it 'll it really increases what we can run on . so , together with the fact that we 've got these faster linux boxes and that it takes less time to do these , , we should be able to crank through lot more experiments . so after did that , then what wanted to do was try increasing the number of mixtures , just to see , see how that affects performance .
B: , you could do something like keep exactly the same procedure and then add fifth thing onto it that had more .
E: so at the middle where the arrows are showing , that 's you 're adding one more mixture per state ,
C: let 's see , this , try to go it backwards this at this point it 's two mixtures per state . so this just adds one . except that , , actually for the silence model , it 's six mixtures per state . so it goes to two . and what happens here is
B: might be between , , shared , shared variances ,
C: that 's what it is . 't remember now what happens at that first one . have to look it up and see . there because they start off with , , an initial model which is just this global model , and then they split it to the individuals . and so , it may be that 's what 's happening here . have to look it up and see . don't exactly remember . so . that 's it .
B: so what else ?
A: there was conference call this tuesday . yet the what happened tuesday , but the points that they were supposed to discuss is still , , things like the weights ,
B: this is conference call for , , aurora participant thing . do who was since we weren't in on it , , do who was in from ogi ? was was hynek involved or was it sunil
A: have no idea . so the points were the weights how to weight the different error rates that are obtained from different language and conditions . it 's not clear that they will keep the same weighting . right now it 's weighting on improvement . some people are arguing that it would be better to have weights on to combine error rates before computing improvement . and the fact is that for right now for the english , they have weights they combine error rates , but for the other languages they combine improvement . so it 's not very consistent . this is point . and right now actually there is thing also , , that happens with the current weight is that very non - significant improvement on the - matched case result in huge differences in the final number . and so , perhaps they will change the weights to
C: how should that be done ? it seems like there 's simple way this seems like an obvious mistake .
B: , the fact that it 's inconsistent is an obvious mistake .
C: th - they 're
B: but the but , , the other thing haven't thought it through , but one would think that each it it 's like if you say what 's the what 's the best way to do an average , an arithmetic average or geometric average ? it depends what you wanna show . each each one is gonna have different characteristic .
C: it seems like they should do , like , the percentage improvement , rather than the absolute improvement .
A: tha - that 's what they do .
B: they are doing that . no , that is relative . but the question is , do you average the relative improvements or do you average the error rates and take the relative improvement maybe of that ? and it 's not just pure average because there are these weightings . it 's weighted average .
A: and so when you average the relative improvement it tends to give lot of , , importance to the - matched case because the baseline is already very good
C: why don't they not look at improvements but just look at your av your scores ? figure out how to combine the scores with weight or whatever , and then give you score here 's your score . and then they can do the same thing for the baseline system and here 's its score . and then you can look at
B: that 's what he 's seeing as one of the things they could do . it 's just when you when you get all done , that they pro but they started off this process with the notion that you should be significantly better than the previous standard . so they said "" how much is significantly better ? what do you ? "" and and so they said "" , , you should have half the errors , "" , "" that you had before "" . so it 's , but it does seem like it does seem like it 's more logical to combine them first and then do the
A: but there is this is this still this problem of weights . when when you combine error rate it tends to give more importance to the difficult cases , and some people think that they have different , , opinions about this . some people think that it 's more important to look at to have ten percent imp relative improvement on - matched case than to have fifty percent on the mismatched , and other people think that it 's more important to improve lot on the mismatch
C: it sounds like they don't really have good idea about what the final application is gonna be .
B: , that if you look at the numbers on the on the more difficult cases , , if you really believe that was gonna be the predominant use , none of this would be good enough . whereas you with some reasonable error recovery could imagine in the better cases that these systems working . the hope would be that it would , it would work for the good cases and , , it would have reasonable reas soft degradation as you got to worse and worse conditions .
C: was thinking about it in terms of , if were building the final product and was gonna test to see which front - end 'd wanted to use , would try to weight things depending on the exact environment that was gonna be using the system in .
B: but but no . it isn't the operating theater . they don they don't they don't really know , .
C: so if they , doesn't that suggest the way for them to go ? you assume everything 's equal .
B: , one thing to do is to just not rely on single number to maybe have two or three numbers , and and say here 's how much you , you improve the , the relatively clean case or - matched case , and here 's how here 's how much you ,
C: so not try to combine them .
B: actually it 's true . had forgotten this , but , , - matched is not actually clean . what it is just that , the training and testing are similar .
C: the training and testing .
B: what you would do in practice is you 'd try to get as many , , examples of similar as you could , so the argument for that being the the more important thing , is that you 're gonna try and do that , but you wanna see how badly it deviates from that when when the , it 's little different .
C: so you should weight those other conditions very , really small .
B: that 's that 's an arg
C: that 's more of an information thing .
B: that 's an ar that 's an argument for it , but let me give you the opposite argument . the opposite argument is you 're never really gonna have good sample of all these different things . are you gonna have , examples with the windows open , going seventy , sixty , fifty , forty miles an hour ? on what roads ? with what passing you ? that you could make the opposite argument that the - matched case is fantasy . that if you look at the - matched case versus the po , the medium and the and the fo and then the mismatched case , , we 're seeing really , really big differences in performance . and and you wouldn't like that to be the case . you wouldn't like that as soon as you step outside lot of the cases it 's is
C: that 'll teach them to roll their window up .
B: in these cases , if you go from the , don't remember the numbers right off , but if you if you go from the - matched case to the medium , it 's not an enormous difference in the in the training - testing situation , and and it 's really big performance drop . the reference one , this is back old on , on italian , was like six percent error for the - matched and eighteen for the medium - matched and sixty for the for highly - mismatched . and , , with these other systems we helped it out quite bit , but still there 's there 's something like factor of two between - matched and medium - matched . and so that if what you 're if the goal of this is to come up with robust features , it does mean so you could argue , , that the - matched is something you shouldn't be looking , that the goal is to come up with features that will still give you reasonable performance , with again gentle degregra degradation , even though the testing condition is not the same as the training . so , , could argue strongly that something like the medium mismatch , which is not compl pathological but what was the medium - mismatch condition again ?
A: medium mismatch is everything with the far microphone , but trained on , like , low noisy condition , and or stopped car and tested on high - speed conditions , ,
B: so it 's still the same microphone in both cases , but , , it 's there 's mismatch between the car conditions . you could argue that 's pretty realistic situation and , , 'd almost argue for weighting that highest . but the way they have it now , it 's it 's it 's they they compute the relative improvement first and then average that with weighting ? and so then the that makes the highly - matched the really big thing . so , since they have these three categories , it seems like the reasonable thing to do is to go across the languages and to come up with an improvement for each of those . just say "" , in the in the highly - matched case this is what happens , in the the , this other medium if this happens , in the highly - mismatched that happens "" . you should see , , gentle degradation through that . gather that in these meetings it 's it 's really tricky to make anything ac make any policy change because everybody has , , their own opinion
A: but there is probably big change that will be made is that the baseline th they want to have new baseline , perhaps , which is , , mfcc but with voice activity detector . and , , some people are pushing to still keep this fifty percent number . so they want to have at least fifty percent improvement on the baseline , but which would be much better baseline . and if we look at the result that sunil sent , just putting the vad in the baseline improved , like , more than twenty percent , which would mean then mean that fifty percent on this new baseline is like , , more than sixty percent improvement on
B: so nobody would be there , probably . right ?
A: right now , nobody would be there ,
B: work to do . is is is this ?
A: they didn't decide yet . this was one point of the conference call also ,
B: th that would be good . it 's not that the design of the vad isn't important , but it 's just that it it does seem to be , lot of work to do good job on that and as as being lot of work to do good job on the feature design , if we can cut down on that maybe we can make some progress .
A: per - someone told that perhaps it 's not fair to do that because the , to make good vad you don't have enough to with the features that are the baseline features . you need more features . so you really need to put more in the in the front - end .
C: wha - what do you mean ?
B: let 's say for ins see , mfcc doesn't have anything in it , , related to the pitch . so suppose you 've that what you really wanna do is put good pitch detector on there and if it gets an unambiguous if it gets an unambiguous result then you 're definitely in in voice in , , region with speech .
C: so there 's this assumption that the the voice activity detector can only use the mfcc ?
A: that 's not clear ,
B: for the baseline . so so if you use other features then but it 's just question of what is your baseline . what is it that you 're supposed to do better than ? having the baseline be the mfcc 's means that people could choose to pour their ener their effort into trying to do really good vad
C: but they seem like two separate issues .
B: they 're separate . unfortunately there 's coupling between them , which is part of what stephane is getting to , is that you can choose your features in such way as to improve the vad . and you also can choose your features in such way as to prove improve recognition . they may not be the same thing .
C: but it seems like you should do both .
B: you should do both and that this still makes still think this makes sense as baseline . it 's just saying , as baseline , we know we had the mfcc 's before , lots of people have done voice activity detectors , you might as pick some voice activity detector and make that the baseline , just like you picked some version of htk and made that the baseline . and then let 's try and make everything better . and if one of the ways you make it better is by having your features be better features for the vad then that 's so be it . , at least you have starting point that 's cuz some of the some of the people didn't have vad , . then they looked pretty bad and what they were doing wasn't so bad .
C: it seems like you should try to make your baseline as good as possible . and if it turns out that you can't improve on that , , , then , , nobody wins and you just use mfcc .
B: it seems like , it should include the current state of the art that you want are trying to improve , and mfcc 's , , or plp it seems like reasonable baseline for the features , and anybody doing this task , , is gonna have some voice activity detection at some level , in some way . they might use the whole recognizer to do it but rather than separate thing , but they 'll have it on some level .
C: it seems like whatever they choose they shouldn't , , purposefully brain - damage part of the system to make worse baseline ,
B: it wasn't that they purposely brain - damaged it . people hadn't really thought through about the , the vad issue . and and then when the the proposals actually came in and half of them had ds and half of them didn't , and the half that did and the half that didn't did poorly .
A: we 'll see what happen with this . so what happened since , , last week is from ogi , these experiments on putting vad on the baseline . and these experiments also are using , , some noise compensation , so spectral subtraction , and putting on - line normalization , , just after this . so spectral subtraction , lda filtering , and on - line normalization , so which is similar to the pro proposal - one , but with spectral subtraction in addition , and it seems that on - line normalization doesn't help further when you have spectral subtraction .
C: is this related to the issue that you brought up couple of meetings ago with the musical tones
A: have no idea , because the issue brought up was with very simple spectral subtraction approach , and the one that they use at ogi is one from the proposed the aurora prop , proposals , which might be much better . asked sunil for more information about that , and what 's happened here is that we so we have this new , , reference system which use clean downsampling - upsampling , which use new filter that 's much shorter and which also cuts the frequency below sixty - four hertz , which was not done on our first proposal .
B: when you say "" we have that "" , does sunil have it now , too ,
A: because we 're still testing . so we have the result for , , just the features and we are currently testing with putting the neural network in the klt . it seems to improve on the - matched case , but it 's little bit worse on the mismatch and highly - mismatched when we put the neural network . and with the current weighting it 's sh it will be better because the - matched case is better .
B: but how much worse since the weighting might change how much worse is it on the other conditions , when you say it 's little worse ?
A: it 's like , , fff , ten percent relative .
B: but it has the , the latencies are much shorter .
A: - when say it 's worse , it 's not it 's when , compare proposal - two to proposal - one , putting neural network compared to not having any neural network . this new system is is better , because it has , this sixty - four hertz cut - off , , good vad . we put the good vad .
B: but you 've got the latency shorter now . so it 's better than the system that we had before .
A: mainly because of the sixty - four hertz and the good vad . and then took this system and , mmm , , we put the old filters also . so we have this good system , with good vad , with the short filter and with the long filter , with the short filter it 's not worse .
B: so that 's that 's all fine . but what you 're saying is that when you do these so let me try to understand . when when you do these same improvements to proposal - one , that , , on the things are somewhat better , , in proposal - two for the - matched case and somewhat worse for the other two cases . when you say , the th now that these other things are in there , is it the case maybe that the additions of proposal - two over proposal - one are less im important ?
A: but it 's good thing anyway to have shorter delay . then we tried , , to do something like proposal - two but having , , using also msg features . so there is this klt part , which use just the standard features , and then two neura two neural networks . and it doesn't seem to help . however , we just have one result , which is the italian mismatch , we have to for that to fill the whole table ,
B: there was start of some effort on something related to voicing .
A: so we try to , , find good features that could be used for voicing detection , but it 's still , on the ,
F: , have the picture .
A: we we are still playing with matlab to look at what happened ,
C: what sorts of features are you looking at ?
A: so we would be looking at , , the variance of the spectrum of the excitation ,
F: , this , and this .
A: something like this , which is should be high for voiced sounds .
C: what does that mean ? the variance of the spectrum of excitation .
A: so the spectrum of the excitation for purely periodic sig signal shou sh
B: what yo what you 're calling the excitation , as recall , is you 're subtracting the , the mel mel filter , , spectrum from the fft spectrum .
A: that 's right . so we have the mel filter bank , we have the fft ,
B: so it 's it 's not really an excitation , but it 's something that hopefully tells you something about the excitation .
A: that 's right .
F: we have here some histogram , but they have lot of overlap .
A: but it 's it 's still for unvoiced portion we have something tha that has mean around point three , and for voiced portion the mean is point fifty - nine . but the variance seem quite high .
C: how did you get your voiced and unvoiced truth data ?
A: we used , , timit and we used canonical mappings between the phones
F: we , , use timit on this , but if we look at it in one sentence , it it 's good ,
A: so it 's noisy timit . that 's right .
E: it 's noisy timit .
A: it seems quite robust to noise , so when we take we draw its parameters across time for clean sentence and then nois the same noisy sentence , it 's very close . so there are there is this . there could be also the , something like the maximum of the auto - correlation function
C: is this trained system ? or is it system where you just pick some thresholds ? ho - how does it work ?
A: right now we just are trying to find some features . hopefully , what we want to have is to put these features in some , to obtain statistical model on these features and to or just to use neural network and hopefully these features would help
C: because it seems like what you said about the mean of the voiced and the unvoiced that seemed pretty encouraging .
B: , except the variance was big .
A: except the variance is quite high .
C: that would trust that so much because you 're doing these canonical mappings from timit labellings . really that 's cartoon picture about what 's voiced and unvoiced . so that could be giving you lot of variance . it may be that you 're finding something good and that the variance is artificial because of how you 're getting your truth .
B: but another way of looking at it might be that what we are coming up with feature sets after all . so another way of looking at it is that , the mel cepstru mel spectrum , mel cepstrum , any of these variants , , give you the smooth spectrum . it 's the spectral envelope . by going back to the fft , you 're getting something that is more like the raw data . so the question is , what characterization and you 're playing around with this another way of looking at it is what characterization of the difference between the raw data and this smooth version is something that you 're missing that could help ? so , , looking at different statistical measures of that difference , coming up with some things and just trying them out and seeing if you add them onto the feature vector does that make things better or worse in noise , where you 're really just the way 'm looking at it is not so much you 're trying to find the best the world 's best voiced - unvoiced , , classifier , but it 's more that , , , try some different statistical characterizations of that difference back to the raw data maybe there 's something there that the system can use .
A: but ther more obvious is that the the more obvious is that using the th the fft , , you just it gives you just information about if it 's voiced or not voiced , ma mainly , . this is why we started to look by having voiced phonemes
B: that 's the rea what 'm arguing is that 's , what 'm arguing is that that 's givi you gives you your intuition . but in reality , it 's , there 's all of this overlap and , and but what 'm saying is that may be , because what you 're really getting is not actually voiced versus unvoiced , both for the fac the reason of the overlap and then , , th , structural reasons , like the one that chuck said , that , , the data itself is that you 're working with is not perfect . so , what 'm saying is maybe that 's not killer because you 're just getting some characterization , one that 's driven by your intuition about voiced - unvoiced certainly , but it 's just some characterization of something back in the in the almost raw data , rather than the smooth version . and your intuition is driving you towards particular kinds of , , statistical characterizations of , , what 's missing from the spectral envelope . you have something about the excitation , and what is it about the excitation , and , and you 're not getting the excitation anyway , . so would almost take especially if these trainings and are faster , would almost just take , scattershot at few different ways of look of characterizing that difference and , , you could have one of them but and see , , which of them helps .
C: so is the idea that you 're going to take whatever features you develop and just add them onto the future vector ? or , what 's the use of the voiced - unvoiced detector ?
A: we exactly yet .
C: it 's not part of vad system that you 're doing ?
A: no , the idea was , , to use them as features . it could be , it could be neural network that does voiced and unvoiced detection , but it could be in the also the big neural network that does phoneme classification .
B: but each one of the mixture components you have , , variance only , so it 's like you 're just multiplying together these , , probabilities from the individual features within each mixture .
C: it 's neat thing . it seems like good idea .
B: know that , , people doing some robustness things ways back were just doing just being gross and just throwing in the fft and actually it wasn't wasn't so bad . and that it 's gotta hurt you little bit to not have spectral , smooth spectral envelope , so there must be something else that you get in return for that
C: maybe 'm going in too much detail , but how exactly do you make the difference between the fft and the smoothed spectral envelope ? wha - wh , how is that , ?
A: how did we do it up again ?
F: we distend the we have the twenty - three coefficient af after the mel filter , and we extend these coefficient between the all the frequency range . and the interpolation between give for the triang triangular filter , the value of the triangular filter and of this way we obtained this mode this model speech .
B: so you essentially take the values that th that you get from the triangular filter and extend them to sor like rectangle , that 's at that value .
A: we have linear interpolation . so we have we have one point for one energy for each filter bank ,
F: mmm , it 's linear .
A: which is the energy that 's centered on on the triangle
F: at the center of the filter
C: so you end up with vector that 's the same length as the fft vector ?
A: that 's right .
C: and then you just , , compute differences
F: have here one example if you if you want see something like that .
A: then we compute the difference .
C: sum the differences ?
A: and the variance is computed only from , like , two hundred hertz to one to fifteen hundred .
F: two thou two fifteen hundred ? two hundred and fifty thousand . two thousand and fifteen hundred .
A: above , it seems that some voiced sound can have also , like , noisy part on high frequencies ,
B: no , it 's makes sense to look at low frequencies .
C: so this is , this is comparing an original version of the signal to smoothed version of the same signal ?
B: so so this is you could argue about whether it should be linear interpolation or or zeroeth order , at any rate something like this is what you 're feeding your recognizer , typically .
C: like which of the ?
B: so the mel cepstrum is the is the cepstrum of this , , spectrum or log spectrum ,
C: right , right .
B: you - you 're subtracting in power domain or log domain ?
A: in log domain .
B: so it 's like division , when you do the , the spectra .
C: it 's the ratio .
B: but , anyway ,
C: so what 's th , what 's the intuition behind this thing ? really know the signal - processing enough to understand what is that doing .
A: what happen if what we have what we would like to have is some spectrum of the excitation signal ,
B: that makes sense .
A: which is for voiced sound ideally and for unvoiced it 's something that 's more flat . and the way to do this is that we have the we have the fft because it 's computed in the in the system , and we have the mel filter banks , and so if we if we , like , remove the mel filter bank from the fft , we have something that 's close to the excitation signal . it 's something that 's like train of pulse train for voiced sound and that 's that should be flat for
C: so do you have picture that sh ?
A: so - it 's
C: is this for voiced segment , what does it look like for unvoiced ?
A: you have several some unvoiced ?
F: no . unvoiced , don't have
B: so , , all
F: this is the between
A: this is another voiced example .
F: but it 's this , but between the frequency that we are considered for the excitation and this is the difference .
C: this is the difference .
A: so , , it 's around zero ,
F: because we begin , , in fifteen point the fifteen point .
C: does the periodicity of this signal say something about the
A: it 's the pitch .
B: that 's like fundamental frequency . to first order what you 'd what you 're doing ignore all the details and all the ways which is that these are complete lies . the , what you 're doing in feature extraction for speech recognition is you have , , in your head simplified production model for speech , in which you have periodic or aperiodic source that 's driving some filters .
F: this is the auto - correlation the - zero energy .
A: do you have the mean do you have the mean for the auto - correlation ?
B: first order for speech recognition , you say "" don't care about the source "" .
A: for the energy .
F: have the mean .
B: and so you just want to find out what the filters are . the filters roughly act like , , an overall resonant , some resonances and that th that 's processing excitation .
A: they should be more close .
F: this is this ? more close . is this ?
A: this is there is less difference .
B: so if you look at the spectral envelope , just the very smooth properties of it , you get something closer to that .
A: this is less it 's less robust .
B: and the notion is if you have the full spectrum , with all the little nitty - gritty details , that has the effect of both , and it would be multiplication in frequency domain so that would be like an addition in log power spectrum domain . and so this is saying , , if you really do have that vocal tract envelope , and you subtract that off , what you get is the excitation . and call that lies because you don't really have that , you just have some signal - processing trickery to get something that 's smooth . it 's not really what 's happening in the vocal tract so you 're not really getting the vocal excitation . that 's why was going to the why was referring to it in more more , , conservative way , when was saying "" , it 's it 's the excitation "" . but it 's not really the excitation . it 's whatever it is that 's different between
C: this moved in the
B: so so , stand standing back from that , you say there 's this very detailed representation . you go to smooth representation . you go to smooth representation cuz this typically generalizes better . but whenever you smooth you lose something , so the question is have you lost something you can you use ? probably you wouldn't want to go to the extreme of just ta saying "" , our feature set will be the fft "" , cuz we really think we do gain something in robustness from going to something smoother , but maybe there 's something that we missed . so what is it ? and then you go back to the intuition that , you don't really get the excitation , but you get something related to it . and it and as you can see from those pictures , you do get something that shows some periodicity , , in frequency , and and also in time .
C: that 's that 's really neat . so you don't have one for unvoiced picture ?
F: but not here .
B: but presumably you 'll see something that won't have this , , , regularity in frequency , , in the
C: would li would like to see those pictures .
F: 't see you now .
C: and so you said this is pretty doing this thing is pretty robust to noise ?
F: the mean is different with it , because the histogram for the classifica
A: no , no . but th the robustness to noise so if you take this frame , , from the noisy utterance and the same frame from the clean utterance
C: you end up with similar difference
A: we end up with
F: have here the same frame for the clean speech
C: that 's clean .
F: but they are difference . because here the fft is only with two hundred fifty - six point and this is with five hundred twelve .
A: this is inter interesting also because if we use the standard , , frame length of , like , twenty - five milliseconds , , what happens is that for low - pitched voiced , because of the frame length , you don't really have you don't clearly see this periodic structure , because of the first lobe of each of the harmonics .
C: so this one inclu is longer .
A: so , this is like , fifty milliseconds like that . but it 's the same frame
C: it 's that time - frequency trade - off thing . , so this is this the difference here ,
F: this is the signal . this is the signal .
C: that 's the the original .
F: this is the fra the original frame .
A: so with short frame you have only two periods and it 's not enough to have this neat things . so probably we 'll have to use , like , long long frames .
C: that 's interesting .
B: it looks better , but , , if , if you 're actually asking , if you actually , need to do place along an fft , it may be it may be pushing things .
C: would you would you wanna do this , , difference thing after you do spectral subtraction ?
F: maybe we can do that .
B: the spectral subtraction is being done at what level ? is it being done at the level of fft bins or at the level of , , mel spectrum ? how are they doing it ?
A: how they 're doing it ? ericsson is on the , , filter bank ,
F: fft . filter bank ,
A: it 's on the filter bank ,
B: so in that case , it might not make much difference .
C: seems like you 'd wanna do it on the fft bins .
B: certainly it 'd be better .
C: if you were gonna for this purpose , that is .
A: that 's all . so we 'll perhaps try to convince ogi people to use the new the new filters
B: has anything happened yet on this business of having some standard , , source ,
A: but wi will call them now they are they have more time because they have this eurospeech deadline is over
C: when is the next , , aurora deadline ?
A: it 's , , in june .
B: and he 's been doing all the talking but these he 's he 's , this is this bad thing . we 're trying to get , , more female voices in this record as . make sur make carmen talks as . but has he been talking about what you 're doing also ,
F: am doing this . that for the recognizer for the meeting recorder that it 's better that don't speak .
B: , we 'll get we 'll get to , , spanish voices sometime , and we do we want to recognize , , you too .
F: after the after , , the result for the ti - digits on the meeting record there will be foreigns people .
B: we like we 're we are we 're in the , , bourlard - hermansky - morgan , , frame of mind . we like high error rates . that way there 's lots of work to do .
D: not much is new . so when talked about what 'm planning to do last time , said was , , going to use avendano 's method of , , using transformation , , to map from long analysis frames which are used for removing reverberation to short analysis frames for feature calculation . he has trick for doing that involving viewing the dft as matrix . but , , , decided not to do that after all because realized to use it 'd need to have these short analysis frames get plugged directly into the feature computation somehow and right now our feature computation is set to up to , , take , , audio as input , in general . so decided that 'll do the reverberation removal on the long analysis windows and then just re - synthesize audio and then send that .
B: this is in order to use the sri system .
D: or even if 'm using our system , was thinking it might be easier to just re - synthesize the audio , because then could just feacalc as is and wouldn't have to change the code .
B: certainly in short - term this just sounds easier . longer - term if it 's if it turns out to be useful , one might want to do something else ,
D: right . that 's true .
B: , , in other words , you may be putting other kinds of errors in from the re - synthesis process .
D: from the re - synthesis ? anything about re - synthesis . how likely do you think that is ?
B: it depends what you what you do . it 's it 's , , but anyway it sounds like reasonable way to go for for an initial thing , and we can look at exactly what you end up doing and then figure out if there 's some something that could be hurt by the end part of the process . that was it , ?
D: that , that 's it , that 's it .
B: anything to add ?
E: 've been continuing reading . went off on little tangent this past week , looking at , , , modulation spectrum , and learning bit about what , what it is , and , , the importance of it in speech recognition . and found some , , neat papers , , historical papers from , , kanedera , hermansky , and arai . and they did lot of experiments where th where , , they take speech and , , they modify the , they they measure the relative importance of having different , , portions of the modulation spectrum intact . and they find that the spectrum between one and sixteen hertz in the modulation is , is im important for speech recognition .
B: this goes back to earlier by drullman . and and , , the msg features were built up with this notion but , , you had brought this up in the context of , , targets somehow . it 's not , they 're not in the same category as , say , phonetic target or syllabic target
E: was thinking more like using them as the inputs to the detectors .
B: that 's what msg does . anyway , we 'll talk more about it later .
E: we can talk more about it later .
B: so maybe , le
C: should we do digits ?
B: let 's do digits . let you start .
","The ICSI Meeting Recorder Group at Berkeley met to discuss progress on their main project , Aurora.
They discussed a conference call with project partners , there have been some developments that should help speed up experiments , along with some progress made in the current area they are looking , voiced/unvoiced detection.
A number of other members of the group also reported the progress they were making on their work.
Me018 will mail people with details about changes to their system in order to run code on the IBM Linux machine , along with the name of the machine.
Mn007 is going to try and convince OGI to use his new filters , and enquire as to the setting of a standard for the system.
There was a conference call for the Aurora Project , but no one from ICSI was involved.
Not only are the group unsure what if anything was decided , but project changes are being considered including changing the baseline and improvement weighting , though everyone has their own opinion on these matters.
The group needs more female voices in the Meeting Recorder data , though fn002 does not consider herself very suitable.
Me018 has been attempting to make experimentation faster by reducing the iterations in the HTK training.
These will can be reset once the system is finalised.
He then wants to try and improve accuracy may increasing the number of Gaussian mixtures in the models.
Mn007 reported OGI's work on spectral subtraction , as well as his testing his new filter.
The latency is reduced , and improvement increased on well matched case , though decreased on mis-matched.
Along with fn002 he has been looking into voiced/unvoiced detection , and they are still looking for features.
So far they are using features which approximate important details , and they seem reasonably robust on noise.
Me026 has decided against using the exact method of reverberation cancellation he previously discussed , because its output does not fit the current system.
Me006 has been reading on a slight tangent looking at classic work on modulation spectrum , which has inspired some ideas for input.
"
ami_abstractive_summary,Bro016.txt,"E: let 's see . was saying hynek 'll be here next week , won't be here thursday and friday . but my suggestion is that , , at least for this meeting , people should go ahead , cuz hynek will be here , we don't have any czech accent yet , as far as know , there we go . so other than reading digits , what 's our agenda ?
F: don't really have , , anything new . been working on meeting recorder .
E: do you think that would be the case for next week also ? or is , ? what 's your projection on ? cuz the one thing the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me it was an obvious thing is , , adjusting the , , sca the scaling and , , insertion penalty sorta .
F: did play with that , actually , little bit . what happens is , , when you get to the noisy , you start getting lots of insertions . so 've tried playing around little bit with , , the insertion penalties and things like that . it didn't make whole lot of difference . like for the - matched case , it seemed like it was pretty good . could do more playing with that , though .
E: but you were looking at mel cepstrum .
F: you 're talking about for th for our features .
E: so , , it 's not the direction that you were working with that we were saying what 's the , what 's the best you can do with mel cepstrum . but , they raised very valid point , so , to first order , you have other things you were gonna do , but to first order , would say that the conclusion is that if you , , do , , some monkeying around with , , the exact htk training and @ @ with , , , how many states and , that it doesn't particularly improve the performance . in other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad . and you hadn't gotten to all the experiments you wanted to do with number of gaussians , if we had to if we had to draw conclusion on the information we have so far , we 'd say something like that . so the next question to ask , which is the one that that andreas was dre addressing himself to in the lunch meeting , is , , we 're not supposed to adjust the back - end , but anybody using the system would . if you were just adjusting the back - end , how much better would you do , , in noise ? because the language scaling and insertion penalties and are probably set to be about right for mel cepstrum . but , , they 're probably not set right for these things , particularly these things that look over , , larger time windows , in one way or another with lda and klt and neural nets and all these things . in the fa past we 've always found that we had to increase the insertion penalty to correspond to such things . that 's , , @ @ that 's first - order thing that we should try .
F: so the experiment is to , , run our front - end like normal , with the default , , insertion penalties and , and then tweak that little bit and see how much of difference it makes
E: so by "" our front - end "" take , , the aurora - two take some version that stephane has that is , , our current best version of something . don't wanna do this over hundred different things that they 've tried but , , for some version that you say is good one . how how much , , does it improve if you actually adjust that ? but it is interesting . you say you have for the noisy how about for the for the mismatched or or the medium mismatched conditions ? when you adjusted those numbers for mel cepstrum , did it ?
F: don't remember off the top of my head . didn't even write them down . did write down , so , when was doing wrote down some numbers for the - matched case . looking at the wrote down what the deletions , substitutions , and insertions were , for different numbers of states per phone . but , , that 's all wrote down . would need to do that . do that for next week .
E: also , , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise . but it would be it 'd be good to know that .
F: need to get , , front - end , , from you or you point me to some files that you 've already calculated . probably will have time to do that and time to play little bit with the silence model . so maybe have that for next week when hynek 's here .
E: cuz , , the other that , , might have been part of what , , the difference was at least part of it that we were seeing . remember we were seeing the sri system was so much better than the tandem system . part of it might just be that the sri system , they they always adjust these things to be optimized ,
F: wonder if there 's anything that we could do to the front - end that would affect the insertion what could you do ?
E: part of what 's going on , , is the , , the range of values . so , if you have something that has much smaller range or much larger range , and taking the appropriate root . if something is like the equivalent of bunch of probabilities multiplied together , you can take root of some sort . if it 's like seven probabilities together , you can take the seventh root of it , or if it 's in the log domain , divide it by seven . that has similar effect because it changes the scale of the numbers of the differences between different candidates from the acoustic model as opposed to what 's coming from the language model .
F: so , in effect , that 's changing the value of your insertion penalty .
E: it 's more directly like the language scaling or the , the model scaling or acoustic scaling ,
F: that 's interesting .
E: but that those things have similar effect to the insertion penalty anyway . they 're slightly different way of handling it .
F: so if we the insertion penalty is , then we can get an idea about what range our number should be in , so that they match with that .
E: so that 's why that 's another reason other than curiosity as to why it would be kinda neat to find out if we 're way off . the other thing is , are aren't we seeing ? 'm you 've already looked at this bu in these noisy cases , are ? we are seeing lots of insertions . the insertion number is quite high ? know the vad takes pre care of part of that ,
F: 've seen that with the mel cepstrum . don't about the aurora front - end ,
B: it 's much more balanced with , when the front - end is more robust . could look at it at this .
E: wha - what 's typical number ? you , you .
B: don't have this in
E: 'm it 's more balanced , but it it wouldn't surprise me if there 's still in the the old systems we used to do , , remember numbers like insertions being half the number of deletions , as being and both numbers being tend to be on the small side comparing to , , substitutions .
F: the whole problem with insertions was what , , we talked about when the guy from ogi came down that one time and that was when people were saying , we should have , , voice activity detector that , because all that that we 're getting thr the silence that 's getting through is causing insertions . 'll bet you there 's still lot of insertions .
E: and it may be less of critical thing . the fact that some get by may be less of critical thing if you , , get things in the right range . so , , the insertions is symptom . it 's symptom that there 's something , , wrong with the range . but there 's , your your substitutions tend to go up as . so , , that , the most obvious thing is just the insertions , @ @ . if you 're operating in the wrong range , that 's why just in general , if you change what these penalties and scaling factors are , you reach some point that 's that 's minimum . we do have to do over range of different conditions , some of which are noisier than others . but , , we may get better handle on that if we if we see it 's if we actually could pick more stable value for the range of these features , it , , , could even though it 's it 's true that in real situation you can adjust the these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . and if you have front - end that 's in roughly the right range remember after we got our more or less together in the previous systems we built , that we tended to set those scaling factors at standard level , and we would rarely adjust them again , even though you could get for an evaluation you can get an extra point if you tweaked it little bit . once we knew what rou roughly the right operating range was , it was pretty stable , and , we might just not even be in the right operating range .
F: so , would the ? would good idea be to try to map it into the same range that you get in the - matched case ? so , if we computed what the range was in - matched , and then when we get our noisy conditions out we try to make it have the same range as ?
E: no . you don't wanna change it for different conditions . what what 'm saying
F: wasn't suggesting change it for different conditions . was just saying that when we pick range , we wanna pick range that we map our numbers into we should probably pick it based on the range that we get in the - matched case . otherwise , , what range are we gonna choose to map everything into ?
E: it depends how much we wanna do gamesmanship and how much we wanna do it to me , actually , even if you wanna be play on the gamesmanship side , it can be kinda tricky . so , , what you would do is set the set the scaling factors , , so that you got the best number for this point four five times the , and so on . but they might change that sorta think we need to explore the space . just take look at it little bit . and we we may just find that we 're way off . maybe we 're not . as for these other things , it may turn out that , , it 's reasonable . andreas gave very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future people within this tight - knit community who are doing this evaluation are accepting , , more or less , that these are the rules . but , people outside of it who look in at the broader picture are certainly gonna say "" , minute . you 're doing all this standing on your head , , on the front - end , when all you could do is just adjust this in the back - end with one one knob . "" so we have to at least , , determine that 's not true , which would be , or determine that it is true , in which case we want to adjust that and then continue with what we 're doing . and as you say as you point out finding ways to then compensate for that in the front - end also then becomes priority for this particular test , and saying you don't have to do that . what 's new with you ?
B: so there 's nothing new .
E: what 's old with you that 's developed ? what 's old with you that has developed over the last week or two ?
B: so we 've been mainly working on the report
F: mainly working on what ?
B: on the report of the work that was already done . that 's all .
F: how about that ? any - anything new on the thing that , , you were working on with the , ?
C: don't have results yet .
E: what was that ? what 's what 's going on now ? what are you doing ?
C: to try to found , nnn , robust feature for detect between voice and unvoice . and we we try to use the variance of the es difference between the fft spectrum and mel filter bank spectrum . also the another parameter is relates with the auto - correlation function . - ze energy and the variance also of the auto - correlation function .
E: so , that 's that 's what you were describing , , week or two ago .
C: but we don't have res we don't have result of the auro for aurora yet . we need to train the neural network
E: so you 're training neural networks now ? so , what wha wh wha what 's going on ?
C: we work in the report , too , because we have lot of result , they are very dispersed , and was necessary to look in all the directory to to give some more structure .
E: if summarize , what 's going on is that you 're going over lot of material that you have generated in furious fashion , generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens .
B: we 've stopped , , experimenting , we 're just writing some technical report .
F: is this report that 's for aurora ? or is it just like tech report for icsi ,
C: just summary of the experiment and the conclusion something like that .
E: so , my suggestion , though , is that you not necessarily finish that . but that you put it all together so that it 's you 've got clearer structure to it . what things are , you have things documented , you 've looked things up that you needed to look up . so that , so that such thing can be written . when when do you leave again ?
C: first of july .
E: first of july ? and that you figure on actually finishing it in june . because , , you 're gonna have another bunch of results to fit in there anyway . and right now it 's important that we actually go forward with experiments .
C: it 's not .
E: so so , it 's good to pause , and to gather everything together and make it 's in good shape , so that other people can get access to it and so that it can go into report in june . but to really work on fine - tuning the report at this point is probably bad timing , .
B: we just planned to work on it one week on this report , not no more , anyway .
E: but you ma you may really wanna add other things later anyway there 's more to go ?
B: so . there are small things that we started to do .
F: are you discovering anything , , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this ,
B: actually , there were some tables that were also with partial results . we just noticed that , wh while gathering the result that for some conditions we didn't have everything . we have , , extracted actually the noises from the speechdat - car . we can train neural network with speech and these noises . it 's difficult to say what it will give , because when we look at the aurora the ti - digits experiments , , they have these three conditions that have different noises , and this system perform as on the seen noises on the unseen noises and on the seen noises . this is something we have to try anyway . adding the noises from the speechdat - car .
E: that 's permitted ?
B: ogi does did that . at some point they did that for the voice activity detector .
F: could you say it again ? what what exactly did they do ?
B: they used some parts of the , , italian database to train the voice activity detector , .
E: that 's matter of interpretation . the rules as understand it , is that in principle the italian and the spanish and the english italian and the finnish and the english ? were development data
B: and spanish , .
E: on which you could adjust things . and the and the german and danish were the evaluation data . and then when they finally actually evaluated things they used everything .
B: that 's right .
E: and it is true that the performance , , on the german was even though the improvement wasn't so good , the pre the raw performance was really pretty good . it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that going to different language really hurt you . and the noises were not exactly the same . because it was taken from different , they were different drives . it was it was actual different cars and so on . it 's somewhat tuned . it 's tuned more than , , you 'd really like to have something that needed no particular noise , maybe just some white noise like that at most . but that 's not really what this contest is . that 's something 'd like to understand before we actually use something from it ,
F: it 's probably something that , mmm , the , the , , experiment designers didn't really think about , because most people aren't doing trained systems , or , , , systems that are like ours , where you actually use the data to build models . they just doing signal - processing .
E: it 's true , except that , , that 's what we used in aurora one , and then they designed the things for aurora - two knowing that we were doing that .
F: that 's true . and they didn't forbid us to build models on the data ?
E: but , that it it probably would be the case that if , say , we trained on italian , , data and then , , we tested on danish data and it did terribly , , that it would look bad . and someone would notice and would say "" , look . this is not generalizing . "" would hope tha would hope they would . it 's true . maybe there 's parameters that other people have used th that they have tuned in some way for other things . so it 's it 's , we should we should maybe that 's maybe topic especially if you talk with him when 'm not here , that 's topic you should discuss with hynek to , , double check it 's .
F: do we know anything about the speakers for each of the , , training utterances ?
B: what do you mean ?
F: do you have speaker information ? that would be good .
B: like , we have male , female ,
F: just male female ?
E: what information do you mean ?
F: was thinking about things like , , gender , , gender - specific nets and , , vocal tract length normalization . things like that . don't didn't information we have about the speakers that we could try to take advantage of .
E: again , if you had the whole system you were optimizing , that would be easy to see . but if you 're supposedly just using fixed back - end and you 're just coming up with feature vector , 'm not having the two nets suppose you detected that it was male , it was female you come up with different
F: you could put them both in as separate streams . was just wondering if there was other information we could exploit .
E: it 's an interesting thought . maybe having something along the you can't really do vocal tract normalization . but something that had some of that effect being applied to the data in some way .
B: do you have something simple in mind for , vocal tract length normalization ?
F: no . hadn't hadn't thought it was thought too much about it , really . it just something that popped into my head just now . you could maybe use the ideas similar idea to what they do in vocal tract length normalization . you have some , , general speech model , maybe just mixture of gaussians that you evaluate every utterance against , and then you see where each , , utterance like , the likelihood of each utterance . you divide the range of the likelihoods up into discrete bins and then each bin 's got some knob , setting .
E: but just listen to yourself . that really doesn't sound like real - time thing with less than two hundred milliseconds , , latency that and where you 're not adjusting the statistical engine .
F: that 's true . could be expensive .
E: not just expensive . don't see how you could possibly do it . you can't look at the whole utterance and do anything . , you can only each frame comes in and it 's gotta go out the other end .
F: so whatever it was , it would have to be on per frame basis .
E: you can do , fairly quickly you can do male female male female . but as far as , like bbn did thing with , , vocal tract normalization ways back . maybe other people did too . with with , , trying to identify third formant average third formant using that as an indicator of if you imagine that to first order what happens with , , changing vocal tract is that , , the formants get moved out by some proportion so , if you had first formant that was one hundred hertz before , if the fifty if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . so , that 's move of two hundred fifty hertz . whereas the third formant which might have started off at twenty - five hundred hertz , , might be out to thirty - seven fifty , so it 's at although , you frequently get less distinct higher formants , it 's still third formant 's reasonable compromise , so , , , if recall correctly , they did something like that . but , that doesn't work for just having one frame . ? that 's more like looking at third formant over turn like that , but on the other hand , male female is is much simpler categorization than figuring out factor to , , squish or expand the spectrum . you could imagine that just like we 're saying voiced - unvoiced is good to know male female is good to know also . but , you 'd have to figure out way to to , , incorporate it on the fly . , , as you say , one thing you could do is simply , , have the male and female output vectors , tr nets trained only on males and trained only on females if that would really help , because you already have males and females and it 's - putting into one net .
F: is it balanced , in terms of gender
E: you 're you were saying before ?
B: so , this noise , there is something perhaps , could spend some days to look at this thing , cuz it seems that when we train networks on let 's say , on timit with msg features , they look as good as networks trained on plp . when they are used on the speechdat - car data , it 's not the case the msg features are much worse , and so maybe they 're , , less more sensitive to different recording conditions ,
E: they should be less so . but let me ask you this . what what 's the , ? do you kno recall if the insertions were higher with msg ?
B: the error rate is higher .
E: but you should always look at insertions , deletions , and substitutions . msg is very , very dif plp is very much like mel cepstrum . msg is very different from both of them . so , if it 's very different , then this is the thing 'm really glad andreas brought this point up . had forgotten to discuss it . you always have to look at how this , these adjustments , , affect things . and even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features . so if it if , the problem might be that the range of the msg features is quite different than the range of the plp or mel cepstrum . and you might wanna change that .
B: but , it 's it 's after it 's tandem features , we we have estimation of post posteriors with plp and with msg as input ,
E: that means they 're between zero and one . but it it doesn't necessarily they could be , do - doesn't tell you what the variance of the things is . cuz if you 're taking the log of these things , it could be , knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are .
B: so we should look at the likelihood , at the log , perhaps ,
E: or what , what you 're the thing you 're actually looking at . the values that are actually being fed into htk . what do they look like ?
F: and so th the , for the tandem system , the values that come out of the net don't go through the sigmoid . they 're the pre - nonlinearity values ?
E: so they 're kinda like log probabilities is what was saying .
F: and tho that 's what goes into htk ?
E: but then you actually do klt on them . they aren't normalized after that ,
B: mmm . no ,
E: so the question is . whatever they are at that point , , are they something for which taking square root or cube root or fourth root like that is gonna be good or bad thing ? and that 's something that nothing else after that is gonna things are gonna scale it , subtract things from it , scale it from it , but nothing will have that same effect .
F: cuz if the log probs that are coming out of the msg are really big , the standard insertion penalty is gonna have very little effect compared to , , smaller set of log probs .
E: no . again you don't really look at that . it 's something that , and then it 's going through this transformation that 's probably pretty close to it 's , , whatever the klt is doing . but it 's probably pretty close to what discrete cosine transformation is doing . but still it 's it 's not gonna probably radically change the scale of things . it may be entirely off and it may be at the very least it may be quite different for msg than it is for mel cepstrum or plp . so that would be so the first thing 'd look at without adjusting anything would just be to go back to the experiment and look at the , , substitutions , insertions , and deletions . and if the if if there 's fairly large effect of the difference , say , , the ratio between insertions and deletions for the two cases then that would be , , an indicator that it might be in that direction .
B: my point was more that it works sometimes but sometimes it doesn't work . and it works on ti - digits and on speechdat - car it doesn't work ,
E: but , , some problems are harder than others , and , , sometimes , , there 's enough evidence to work and then it 's harder , but it but , , it could be that when you say it works maybe we could be doing much better , even in ti - digits .
B: there is also the spectral subtraction , maybe we should , , try to integrate it in our system . that would involve to mmm use big al already big bunch of the system of ericsson . because he has spectral subtraction , then it 's followed by , , other processing that 's are dependent on the , if it 's speech or noi or silence . and there is this spectral flattening after if it 's silence , and it 's important , , to reduce this musical noise and this increase of variance during silence portions . this was in this would involve to take almost everything from the this proposal and then just add some on - line normalization in the neural network .
E: this 'll be , , something for discussion with hynek next week . how are , how are things going with what you 're doing ?
D: took lot of time just getting my taxes out of the way multi - national taxes . so , 'm 'm starting to write code now for my work but don't have any results yet . it would be good for me to talk to hynek , , when he 's here . do what his schedule will be like ?
E: he 'll be around for three days . we 'll have lot of time . he 'll be talking with everybody in this room
F: but you said you won't you won't be here next thursday ?
E: not thursday and friday . cuz will be at faculty retreat . 'll try to connect with him and people as on wednesday . how 'd taxes go ? , good . . that 's just that 's one of the big advantages of not making much money is the taxes are easier .
F: unless you 're getting money in two countries . they both want their cut .
E: canada canada wants cut ? have to do so you have to do two returns ?
D: mmm . , for two thousand did .
E: that 's right ,
F: but not for this next year ?
E: probably not this next year , .
D: 'll 'll still have bit of canadian income but it 'll be less complicated because will not be considered resident of canada anymore , so won't have to declare my american income on my canadian return .
E: do you wanna say something about your here ?
A: , continuing looking at , , ph , phonetic events , and , , this tuesday gonna be , , meeting with john ohala with chuck to talk some more about these , , ph , phonetic events . came up with , , plan of attack , it 's that 's it .
E: why don't you say something about what it is ?
A: you , you want you want details .
E: we 're all gathered here together .
A: was hoping could wave my hands . so , once wa was thinking getting us set of acoustic events to , to be able to distinguish between , , phones and words and . we would figure out set of these events that can be , , , hand - labeled or derived , , from the hand - labeled phone targets . we could take these events and , , do some cheating experiments , where we feed , , these events into an sri system , , , and evaluate its performance on switchboard task .
D: hey , barry ? can you give an example of an event ?
A: give you an example of twenty - odd events . so , he in this paper , , it 's talking about phoneme recognition using acoustic events . so , things like frication or , , nasality .
E: whose paper is it ?
A: this is paper by hubener and cardson benson bernds - berndsen .
E: from , , university of hamburg and bielefeld .
F: just to expand little bit on the idea of acoustic event . there 's , in my mind , anyways , there 's difference between , , acoustic features and acoustic events . and of acoustic features as being , , things that linguists talk about ,
E: so , that 's not based on data .
F: that 's not based on data , necessarily . that 's not based on , , acoustic data . so they talk about features for phones , like , , its height , things like that , which may or may not be all that easy to measure in the acoustic signal . versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . so it 's , it 's little different , in at least in my mind .
E: when we did the spam work , there we had we had this notion of an , , auditory @ @ auditory event .
A: good . that 's great .
E: called them "" avents "" , , with an at the front . and the the idea was something that occurred that is important to bunch of neurons somewhere . sudden change or relatively rapid change in some spectral characteristic will do this . there 's certainly bunch of bunch of places where that neurons are gonna fire because something novel has happened . that was that was the main thing that we were focusing on there . but there 's certainly other things beyond what we talked about there that aren't just rapid changes ,
F: it 's kinda like the difference between top - down and bottom - up . of the acoustic , phonetic features as being top - down . you look at the phone and you say this phone is supposed to be , have this feature , and this feature . whether tha those features show up in the acoustic signal is irrelevant . whereas , an acoustic event goes the other way . here 's the signal . here 's some event . and then that , that may map to this phone sometimes , and sometimes it may not . it just depen maybe depends on the context , things like that . and so it 's different way of looking .
A: using these events , , , we can we can perform these , , cheating experiments . see how how good they are , , in , in terms of phoneme recognition or word recognition . and then from that point on , would , , design robust event detectors , , in similar , , wa spirit that saul has done , with his graphical models , and this probabilistic and - or model that he uses . try to extend it to , to account for other phenomena like , , cmr co - modulation release . and maybe also investigate ways to modify the structure of these models , , in data - driven way , similar to the way that , , jeff , , bilmes did his work . and while 'm 'm doing these , , event detectors , , ma mea measure my progress by comparing , , the error rates in clean and noisy conditions to something like , , neural nets . so , once we have these , , event detectors , , we could put them together and feed the outputs of the event detectors into the sri , , system , and test it on switchboard or , , maybe even aurora . that 's the big picture of , the plan .
E: there 's , , couple people who are gonna be here forget if already told you this , but , couple people who are gonna be here for six months . there 's professor kollmeier , , from germany who 's , , quite big in the , , hearing - aid signal - processing area and , , michael kleinschmidt , who 's worked with him , who also looks at auditory properties inspired by various , , brain function things . they 'll be interesting to talk to , in this issue as these detectors are , , developing . so , he looks at interesting things in the different ways of looking at spectra in order to get various speech properties out . but that 's . we might as do our digits . and like say , encourage you to go ahead and meet , , next week with , , hynek . 'll 'll start . it 's , , one thirty - five .
","Although the members of ICSI's Meeting Recorder Group at Berkeley had little progress to report , there were still a number of issues relating to their work to discuss.
These included making plans for upcoming experiments , clarifying definitions , and approaches which may or may not be against the rules of the Aurora project , alongside alternatives that would not be.
There was also debate about the necessary continuation of a group report.
Plans were also made with regard to a visitor from research partner OGI
For next weeks meeting , speaker me018 will provide numbers on his experiments into adjusting insertion penalties.
Speaker me013 feels that mn007 and fn002 should just put together the coherent bare-bones of their report , and move back to experimenting , leaving the report for the end of the project.
He also feels that they should discuss some aspects of future work , for clarity's sake , with the visitor from OGI.
The main project the group is working on , Aurora , has a number of rules attaches as to what developers can and cannot play with , but this needs to be clarified.
The rules are adhered to in the small community , but make no sense from a broader research perspective.
While writing their report , mn007 and fn002 have noticed some tables contain only partial results , and there are things they do not recall the reasoning behind.
Speaker me018 has done a little initial research into the next area he is to look at , adjusting the scaling and the insertion penalties.
Playing with the latter made little difference , though was coming from a different feature set.
Speakers mn007 and fn002 have been working on their report , logically writing up everything they have done so far.
Mn007 has also been working with a new dataset , preparing it for use as a more realistic source of noise , though it is not clear if this is allowed.
Speaker me006 has continued to look at phonetic events , and has come up with a plan for his future work.
"
ami_abstractive_summary,Bmr026.txt,"A: we 're on . so , this is gonna be pretty short meeting because have four agenda items , three of them were requested by jane who is not gonna be at the meeting today . so . the first was transcription status . does anyone besides jane the transcription status is ?
F: , do , peripherally .
C: is that english ?
F: first of all with ibm got note from brian yesterday saying that they finally made the tape for the thing that we sent them week or week and half ago
D: that 's our system .
F: and that it 's gone out to the transcribers and hopefully next week we 'll have the transcription back from that .
A: can have pen ?
F: jane seems to be moving right along on the transcriptions from the icsi side . she 's assigned , probably five or six more meetings .
C: we 're up to mr thirteen .
F: so , she 's hired some new transcribers
E: which meetings is she transcribing ?
F: we 've we 've run out of us because certain number of them are , awaiting to go to ibm .
C: for ibm , .
F: and the rest are in process being transcribed here .
D: so does she have transcribers right now who are sitting idle because there 's no data back from ibm
E: so we 're doing some in parallel .
A: no , no . we haven't done that process .
F: we 're not waiting on them .
A: so . they ' they 're doing the full transcription process .
E: so they 're just doing their own thing until
D: because need to ask jane whether it 's it would be for her , some of her people to transcribe some of the initial data we got from the smartkom data collection , which is these short like five or seven minute sessions .
F: we 're doing it in parallel , .
D: and we want it , we need the again , we have similar logistic set - up where we are supposed to send the data to munich and get it transcribed and get it back . but to get going we would like some of the data transcribed right away so we can get started . and so wanted to ask jane if , , maybe one of their transcribers could do since these are very short , that should really be ,
C: there 's only two channels . so it 's only as the synthesis doesn't have to be transcribed .
D: it 's only two so it 's one channel to transcribe . one session is only like seven
B: so that should have ma many fewer and it 's also not bunch of interruptions with people and all that ,
D: and some of it is read speech , so we could give them the thing that they 're reading and they just may
A: make it 's right .
D: was gonna ask her but since she 's not around maybe 'll if that 's with you to , , get that to ask her for that , then 'll do that .
B: if we 're held up on this other little bit in order to encompass that , that 's because , still have high hopes that the ibm pipeline 'll work out for us , so it 's
F: , and also related to the transcription , so 've been trying to keep web page up to date showing what the current status is of the trans of all the things we 've collected and what stage each meeting is in , in terms of whether it 's
A: can you mail that out to the list ?
F: - , will . that 's the thing that sent out just to foo people saying can you update these pages and so that 's where 'm putting it but 'll 'll send it out to the list telling people to look at it .
A: haven't done that . so . have lots of to add that 's just in my own directory . 'll try to get to that . so jane also wanted to talk about participant approval , but don't really think there 's much to talk about . 'm just gonna do it . and , if anyone objects too much then they can do it instead .
B: you are going to
A: 'm gonna send out to the participants , , with links to web pages which contain the transcripts and allow them to suggest edits . and then bleep them out . for the ones that we have .
C: so but it 's just transcripts , not the not the audio ?
A: nope , they 'll have access to the audio also . that 's my intention . because the transcripts might not be right . so you want people to be able to listen to them .
F: so , the audio that they 're gonna have access to , will that be the uncompressed version ? or will you have scripts that like uncompress the various pieces and
A: that 's good point . that 's good point . it 's it 's probably going to have to be the uncompressed versions because , , it takes too long to do random access decompression .
F: was just wondering because we 're running out of the un - backed - up disk space on
A: that was the other point .
F: was that another one ?
A: that 's another agenda item . but that is good point so we 'll get to that , too . darpa demo status , not much to say . the back - end is working out fine . it 's more or less ready to go . 've added some that indes indexes by the meeting type mr , edu , et cetera and also by the user id . so that the front - end can then do filtering based on that as . the back - end is , going more slowly as said before just cuz 'm not much of tcl - tk programmer . and dave gelbart says he 's little too busy . so don and are gonna work on that and you and just talk about it off - line more . but the back - end was pretty smooth . so , we 'll have something . it may not be as as pretty as we might like , but we 'll have something .
B: wondered whe when we would reach dave 's saturation point . he 's been volunteering for everything finally said he was too busy . we reached it .
A: he actually he volunteered but then he then he retracted it .
E: and , also , was just showing andreas , got an waves display , and how much more we can do with it with like the prosodic where we have like stylized pitches and signals and the transcripts on the bottom so , right now it 's just an waves and then you have three windows but , it looked pretty and 'm it has potential for little something ,
B: so again , the issue is for july , the issue 's gonna be what can we fit into windows machine , , and so on ,
A: so it might just be slides .
E: we 'll see ,
C: 've been putting together transcriber things for windows and installed it on dave gelbart 's pc and it worked just fine . so hopefully that will work .
D: because there 's some people it would be if we could get that to work at sri
A: transcriber is tcl - tk , very generic with snack ,
D: we have we have more windows machines to run the
A: so anything you can get snack to run on , it will work .
C: but but the problem is the version transcriber works with , the snack version , is one point six whatever and that 's not anymore supported . it 's not on the web page anymore . but wrote an email to the author of to the snack author and he sent me to one point six whatever library
A: it was packaged with transcriber ?
C: and so it works . but then you can't add our patches and then the new version is different and in , in terms of the source code . you you can't find the tcl files anymore . it 's some whatever wrapped thing and you can't you can't access that so you have to install first install tcl then install snack and then install the transcriber thing and then do the patches .
D: wonder if we should contribute our changes back to the authors so that they maintain those changes along
A: it 's just hasn't made it into the release yet .
F: so did you put the the nt version out on the meeting recorder page ? or
C: no , haven't done that yet . but definitely will do that .
B: so , can some of the that don 's talking about somehow fit into this mean you just have set of numbers that are associated with the
E: it 's ascii files or binary files , whatever representation . it 's waveform and just stylized pitch vector so it 's we could do it in matl - you could do it in number of different places 'm .
D: but it would be if the transcriber interface had like another window for the , maybe above the waveform where it would show some arbitrary valued function that is that is time synchron ti time synchronous with the wavform .
E: that 'd be very .
A: it 'd be easy enough to add that . again it 's it 's more tcl - so someone who 's familiar with tcl - tk has to do it , but , it wouldn't be hard to do .
D: but it would almost be like having another waveform displayed .
C: maybe we could look into that .
A: but it seems to me that it doesn't seem like having that real time is that necessary . so yo it seems to me you could do images .
E: what do you mean by real time ? do you mean like
F: like being able to scroll through it and for the demo . is that what you mean ?
A: it just seems to me jus
E: it would be to see it it would be like to see to hear it and see it ,
C: and to hear it .
E: and see the pitch contours also .
A: but don't you can do all that just statically in just record the audio clip and show an image and that 's
E: right , right . thought if you meant slides you meant like just like view graphs .
B: no , we 're talking about on the computer and , when we were talking about this before we had littl this little demo meeting , we set up range of different degrees of liveness that you could have and , the more live , the better , but , given the crunch of time , we may have to retreat from it to some extent . so for lot of reasons , it would be very to have this transcriber interface be able to show some other interesting signal along with it so it 'd be good thing to get in there . anyway , jus just looking for ways that we could actually show what you 're doing , , in to people . cuz lot of this , particularly for communicator , certainly significant chunk of the things that we waved our arms about th originally had had to do with prosodics it 'd be to show that we can actually get them and see them .
A: and the last item on the agenda is disk issues yet again . so , we 're doing on backed up . we 're we 're only about thirty percent on the second disk . so , , we have little bit of time before that becomes critical , but we are like ninety five percent , ninety eight percent on the scratch disks for the expanded meetings . and , my original intention was like we would just delete them as we needed more space , but unfortunately we 're in the position where we have to deal with all the meeting data all at once , in lot of different ways .
F: there 's lot of transcribers , too .
A: there 're lot of transcribers , so all of those need to be expanded , and then people are doing chunking and want to do , , the permission forms , so want those to be live , so there 's lot of data that has to be around . and jane was gonna talk to , , dave johnson about it . one of the things was thinking is we just got these hundred alright , excuse me ten , sparc - blade sun - blades .
B: did they come in ?
F: sun - blades . they came in the other day .
A: they came in but they 're not set up yet . and so it seems to me we could hang scratch disk on those because they 'll be in the machine room , they 'll be on the fast connection to the rest of the machines . and if we just need un - backed - up space , we could just hang disks off them .
F: why not just hang them off of abbott ,
A: because there 's no more room in the disk racks on abbott .
B: weren't we gonna get maybe it should get another rack .
D: but you still need to store the disks somehow .
A: but the sun - blades have spare drive bays . just put them in .
F: you can put two
D: you mean you put them inside the pizza boxes for the
A: cuz the sun , these sun - blades take commodity hard drives . so you can just go out and buy pc hard drive and stick it in .
B: but if abbott is going to be our disk server it file server it seems like we would want to get it , , second disk rack .
D: plus we 're talking about buying second dis , file server .
A: there are lots of long term solutions . what 'm looking for is where do we expand the next meeting ?
D: see , see .
B: for the next meeting you might be out of luck with those ten , dave johnson is gone for , like , ten days ,
A: didn't know he had left already .
D: you mean he won't set up the
E: how much space do you need for these ?
B: what his schedule is .
A: you we need about gig per meeting .
B: 'm just saying he 's gone .
E: have have an eighteen gig drive hanging off of my computer .
A: what 's your computer 's name ?
B: you had an eighteen gigabyte drive .
E: it 's about there 's about twelve gig left .
A: so it and you have an drives installed ?
E: so , didn't realize it was so critical .
A: and you 're you 're offering ?
E: 'm not doing anything on it right now until get new meetings to transcri or that are new transcriptions coming in really can't do anything . not that 't do anything , jus
F: jus gave thilo some about ten gigs , the last ten gigs of space that there was on abbott . so but that but
A: which one was that , ?
D: that 's also where we store the the hub - five training set waveforms ,
A: but that won't be getting any bigger ,
F: don't think that 's on xg . on xg is only carmen and du - and stephane 's disk .
D: but 've also been storing 've been storing the feature files there and start deleting some because we now the best features are and we won't be using the old ones anymore .
E: have lot of space , though .
F: do don't was on xg .
D: thats xa that 's
C: isn't that xh ?
A: not not for long .
E: have lot of space and it 's not it 's there 's very little not for long . but it 's not going it 's not being used often .
C: but 'm using xh , too .
A: it 's probably probably only about four gig is on on your drive , but we 'll definitely take it up if you
D: you 're right . it 's xh and
E: it 's about four or five gig cuz have four meetings on there ,
D: 'm also using dg got that confused .
E: three or four meetings .
A: so that will get us through the next couple days .
B: we need another gigaquad . there should there should just be should have button .
A: the "" more disk space "" button ?
B: just press press each meeting saying "" we need more disk space "" "" this week "" . skip the rest of the conversation .
F: we 've collected so far something like sixty - five meetings .
B: and how much does each meeting take ?
F: and it 's about gig uncompressed .
C: it 's it 's little bit more as usually don't do not uncompress the all of the pzm and the pda things .
F: is little more ? right , so if you uncompressed everything it 's even more .
C: one point five .
F: compressed how much are they ?
A: for all of them .
F: so we 're definitely are storing , all of those . so there 's what thirty some gig of just meetings so far ?
B: so - so so maybe there 's hundred gig . cuz we have the uncompressed around also . so it 's like
F: we we haven't uncompressed all the meetings ,
A: would like to .
B: it 's the they really are cheap . it 's just question of figuring out where they should be and hanging them , but but , we could , if you want to get four disks , get four disks . it 's it 's small these things ar are just few hundred dollars .
F: sent that message out to , , you and dave asking for if we could get some disk . sent this out day ago
A: and put it where ?
F: but and dave didn't respond so how the whole process works . does he just go out and get them and if it 's , and so was assuming he was gonna take over that . but he 's probably too busy given that he 's leaving .
B: you need direct conversation with him . and just say an - just ask him that , , wha what should you do . and in my answer back was "" are you you just want one ? "" so that what you want to do is plan ahead little bit and figure "" , here 's what we pi figure on doing for the next few months "" .
A: wa - they want . the sysadmins would prefer to have one external drive per machine . so they don't want to stack up external drives . and then they want everything else in the machine room . so the question is where are you gonna hang them ?
F: what the space situation is in the machine room .
B: so this is question that 's pretty hard to solve without talking to dave ,
F: part of the reason why dave can't get the new machines up is because he doesn't have room in the machine room right now .
D: one on - one thing to in to to do when you need to conserve space is
F: so he has to re - arrange bunch of .
D: bet there are still some old , , like , nine gig disks , , around and you can probably consolidate them onto larger disks and recover the space .
B: dave knows all these things , . an - and so , he always has lot of plans of things that he 's gonna do to make things better in many ways an and runs out of time .
A: but know that generally their first priority has been for backed up disk . and so what he 's been concentrating on is the back the back up system , rather than on new disk .
B: but this is very specific question for me . we can easily get one to four disks , you just go out and get four and we 've got the money for it , it 's no big deal . but the question is where they go , and don't think we can solve that here , you just have to ask him .
D: maybe we can put some disks in the in that back room there . to the machine that collects the data . so then you could , at least temporarily , store there .
A: it 's just it 's not on the net , so it 's little awkward
D: what do you mean it 's not on the net ?
C: it 's not bad .
A: it 's behind lots of fire walls that don't allow any services through except
D: because it 's because it 's an aciri machine ?
A: and also on the list is to get it into the normal icsi net , but who knows when that will happen ?
D: but that can't be that hard .
F: that might be good short term solution , though .
A: no , the problem with that is that they don't currently have wire running to that back room that goes anywhere near one of the icsi routers . so , they actually have to run wire somewhere .
B: again , , any one of these things is certainly not big deal . if there was person dedicated to doing it they would happen pretty easily but it 's jus every ever everybody has has
A: but dave has to do all of them .
B: all of us have long lists of different things we 're doing . but at any rate that there 's there 's longer term thing and there 's immediate need and we need conversation with maybe after tea you and go down and talk to him about it just say "" wha , what should we do right now ? ""
F: how long is david gonna be gone ?
B: tomorrow and all of the week after .
A: and that 's all have .
B: let 's see . the only oth thing other thing was gonna add was that , talked briefly to mari and we had both been busy with other things so we haven't really connected that much since the last meeting we had here but we that we would have telephone meeting the friday after next . and wanted to make it , after the next one of these meetings , so something that we wanna do next meeting is to put together , reasonable list for ourselves of what is it , , that we 've done . just bulletize do dream up text but this is gonna lead to the annual report .
A: this is the fifteenth ? so just week from tomorrow ?
B: so , , we can so that 's an
D: is this gotta be in the morning ? because fridays have to leave like around two . so if it could be before that would be
B: no , no but don't need other folks for the meeting . all 'm saying is that on
D: 'm , misunderstood .
B: so what was on the me this meeting if wa something 'm making major thing in the agenda is wanna help in getting together list of what it is that we 've done so tell her . have pretty good idea and then the next day , late in the day 'll be having that discussion with her .
D: one thing we in past meetings we had also various variously talked about the work that was happening on the on the recognition side but isn't necessarily related to meetings specifically . so . . and wondered whether we should maybe have separate meeting and between , whoever 's interested in that because feel that there 's plenty of to talk about but it would be maybe the wrong place to do it in this meeting if it 's that it 's just gonna be ver very boring for people who are not , really interested in the details of the recognition system .
B: , so how many how many people here would not be interested in in meeting about recognition ?
F: jane may not be .
D: know , jane an you mean in separate meeting or ha talking about it in this
A: if we talked about it in this meeting .
F: he 's wondering how much overlap there will be .
B: so you 're su
D: liz and jane probably .
B: so we 're gonna have guy 's meeting .
D: , if you wanna put it that way .
F: good thing liz isn't here .
E: watch ball game ?
B: real real men "" real men do decoding "" like that .
F: don't listen to this , liz .
D: it 's when the talk is about data collection , sometimes 've , 'm bored .
A: the nod off ?
D: so it 's sympathize with them not wanting to to be if cou this could
B: it 's cuz you have so you need better developed feminine side . there 's probably gonna be lot of "" bleeps "" in this meeting .
A: would as would .
B: it must be nearing the end of the week . 've heard some comments about like this . that could be .
D: and we don't have to do it every week . we could do it every other week or so . whatev or whenever we feel like we
F: why don't we alternate this meeting every other week ?
A: or just alternate the focus .
F: tha - that 's what .
A: so on even weeks have basic on data .
D: we could do that , . personally 'd 'm not in favor of more meetings .
F: but do don't lot of times lately it seems like we don't really have enough for full meeting on meeting recorder .
A: except that we keep going for our full time .
F: so if we did that cuz we get into these other topics .
D: we feel we feel obligated to collect more data .
F: so if we could alternate the focus of the meeting
A: let 's read digits and go .
B: why don't we just start with that . and then if we find , we 're just not getting enough done , there 's all these topics not coming up , then we can expand into another meeting . but that 's great idea . so . . let 's chat about it with liz and jane when we get chance , see what they think and
F: that would be good . andreas and have various talks in the halls and there 's lots of things , , details and that would people 'd be interested in and 'd , where do we go from here things and so , it would be good .
B: and you 're you 're attending the the front - end meeting as as the others so you have you have probably one of the best you and , are the main ones who see the bridge between the two . we are doing recognition in both of them .
D: so so we could talk little bit about that now if there 's some time .
A: no , no that would be for next week .
D: jus so the latest result was that yot tested the the final version of the plp configuration on development test data for this year 's hub - five test set . and the recognition performance was exactly , and exactly up to the , the first decimal , same as with the mel cepstra front - end .
F: for both females and males ?
D: there was little bit of they were the males were slightly better and the females were slightly worse but nothing really . definitely not significant . and then the really thing was that if we combine the two systems we get one and half percent improvement .
A: just with rover ?
D: with - best rover , which is like our new and improved version of rover . which actually uses the whole - best list from both systems to mmm , combine that .
B: so except the only key difference between the two really is the smoothing at the end which is the auto - regressive versus the cepstral truncation .
F: but percent and half ?
A: it 's pretty impressive .
D: and so after told the my colleagues at sri about that , , now they definitely want to , , , have next time we have an evaluation they want to do , , at least the system combination . and , , why not ?
A: we clearly gotta add few more features , though .
D: what do you mean ? more features in the sense of front - end features or in the sense of just bells and whistles ?
A: no , front - end features . we did plp and mel cepstra . let 's , , try rasta and msg , and
D: so , we cou that 's the the there 's one thing you don't want to overdo it because every front - end if you multiply your effort by , where is number of different systems so . so one compromise would be to only to have the everything up to the point where you generate lattices be one system and then after that you rescore your lattices with the multiple systems and combine the results and that 's fairly painless thing .
F: do you think we 'd still get the one and half
D: maybe little less because at that point the error rates are lower maybe it 's only one percent but that would still be worthwhile doing . jus - , just wanted to let that 's working out very nicely . and then we had some results on digits , , with so this was really just to get dave going with his experiments . and so , . but as result , , , we were wondering why is the hub - five system doing so on the digits . and the reason is there 's whole bunch of read speech data in the hub - five training set .
B: including digits gather , .
D: no it 's actually , digits is only maybe fifth of it .
B: fifth of it is how much ?
D: the rest is read is read timit data and atis data and wall street journal and like that .
B: but fi fifth is how much ?
D: fifth would be maybe two hours something .
B: so that 's actually not that different from the amount of training that there was .
D: but it definitely helps to have the other read data in there because we 're doing the error rate is half of what you do if you train only on ti timit not timit ti - digits , which is only what two hours something ? so . , more read speech data definitely helps . and you can leave out all the conversational data with no performance penalty .
B: that was the interesting thing . because because , it was apparent if you put in bunch more data it would be better ,
D: right , right .
F: is there even more read speech data around ?
D: so we only for the hub - five training , we 're only using fairly small subset of the macrophone database . so , you could beef that up and probably do even better .
A: could also put in focus condition zero from hub - four from broadcast news , which is mostly prepared speech . it 's not exactly read speech but it 's pretty darn close .
D: that 's plenty of read speech data . wall street journal , , take one example .
A: that 's right .
D: so , that might be useful for the people who train the digit recognizers to use something other than ti - digits .
B: they been using timit . they they they experimented for while with bunch of different databases with french and spanish and cuz they 're multilingual tests and , , and actually the best results they got wa were using timit . but which so that 's what they 're they 're using now . but but certainly if we , if we knew what the structure of what we 're doing there was . there 's still bunch of messing around with different kinds of noise robustness algorithms . so we exactly which combination we 're gonna be going with . once we know , then the trainable parts of it 'd be great to run lots of lots of through .
D: that was that . and then th chuck and had some discussions about how to proceed with the tandem system and you wanna you wanna see where that stands ?
F: so andreas brought over the alignments that the sri system uses . and so 'm in the process of converting those alignments into label files that we can use to train new net with . and so then 'll train the net .
D: an - and one side effect of that would be that it 's that the phone set would change . so the mlp would be trained on only forty - six or forty - eight forty - eight phones ? which is smaller than the than the phone set that we 've been using so far . and that that will probably help , actually ,
F: so it 's little different ?
D: because the fewer dimensions the less trouble probably with the as far as just the , we want to try things like deltas on the tandem features . and so you have to multiply everything by two or three . and so , , fewer dimensions in the phone set would be actually helpful just from logistics point of view .
B: although we , it 's not that many fewer and and we take klt anyway so we could
D: so so that was the other thing . and then we wanted to just limit it to maybe something on the same order of dimensions as we use in standard front - end . so that would mean just doing the top ten or twelve of the klt dimensions .
B: and and we sh again check we should check with stephane . my impression was that when we did that before that had very little he didn't lose very much .
F: by just taking the top whatever ?
D: once we have the new trained up , one thing wanted to try just for the fun of it was to actually run like standard hybrid system that is based on , those features and retrain mlp and also the , the dictionary that we use for the hub - five system .
B: and the and the base starting off with the base of the alignments that you got from from pretty decent system .
D: so that would give us , , more hopefully better system because , compared to what eric did while ago , where he trained up , , system based on broadcast news and then tra retraining it on switchboard but he he he didn't he probably didn't use all the training data that was available . and his dictionary probably wasn't as tuned to conversational speech as the as ours is .
B: that 's that 's certainly one thing , .
D: and the dictionary made huge difference . we we made some improvements to the dictionary 's to the dictionary about two years ago which resulted in something like four percent absolute error rate reduction on switchboard ,
B: the other thing is , dipping deep into history and into our resource management days , when we were collaborating with sri before , it was , it is was really key starting point for us that we actually got our alignment . when we were working together we got our initial alignments from decipher , at the time . and . later we got away from it because once we had decent systems going then it was it was typically better to use our own systems cuz they were self consistent but certainly to start off when we were trying to recover from our initial hundred and forty percent error rate . but that was that was good good way to start . and we 're not quite that bad with our switchboard systems but it was they certainly aren't as good as sri 's ,
F: what is the performance on the best switchboard system that we 've done ?
B: the hybrid system we never got better than about fifty percent error . there 's just whole lot of things that no one ever had time for . we never did really fix up the dictionary . we always had list of half dozen things that we were gonna do and lot of them were pretty simple and we never did . we never did an never did any adaptation we never did any
D: and that number was on switchboard - one data , where the error rate now is in the twenties .
B: we were probably at least factor or two off .
D: so it would be so it would be good to re just at least to give us an idea of how the hybrid system would do .
B: but again it 's it 's the conver it 's the conversational speech bit . because our broadcast news system is actually pretty good .
D: and the other thing that would help us to evaluate is to see how the is trained up . because it 's pretty good indicator of that . so it 's sanity check of the outputs before we go ahead and train up the , use them as basis for the tandem system .
B: it 'll still probably be worse . it 's it 'd be context independent and so on .
F: should we should we bother with using the net before doing embedded training ? should we even use that ?
D: that 's good question .
F: or should go straight to
D: we weren't whether it 's worth to just use the alignments from the recognizer or whether to actually go through one or more iterations of embedded training where you realign .
A: you run it ? keep keep both versions ? see which one 's better ?
B: you would then you proceed with the embedded training . it 's gonna take you while to train at this net anyway . and while it 's training you may as test the one you have and see how it did .
A: could make arguments either way . given up guessing .
D: but in your experience have you seen big improvements in on some tasks with embedded training ? or was it small - ish improvements that you got
B: it depended on the task . in this one would expect it to be important because we 're coming from , alignments that were achieved with an extremely different system .
D: that are from another
A: although , we 've done it with when we were combining with the cambridge recurrent neural net , embedded training made it worse . which 've never figured out . it 's bug .
D: so you started training with outputs from with alignments that were generated by the cambridge system ? , that might probably just that was probably because your initial system your system was ba worse than cambridge 's .
A: they were they were comparable . they were very close .
D: that 's weird . that 's that 's weird .
A: that 's what said .
D: no it 's weird that it did it 's weird that it got worse .
F: that 's ambiguous .
B: tha - we 've see and wi with the numbers ogi numbers task we 've seen number of times people doing embedded trainings and things not getting better .
D: actually it 's not that weird because we have seen we have seen cases where acoustic retraining the acoustic models after some other change made matters worse rather than better .
B: but would would suspect that something that had very different feature set , they were using pretty diff similar feature sets to us . would expect that something that had different feature set would benefit from
F: what about hidden unit size on this .
B: and the other thing , it was the other thing is that what was in common to the cambridge system and our system is they both were training posteriors . so , , that 's another pretty big difference
A: that 's another big difference .
B: and , one bac at least
D: you mean with soft targets ? what 's the key issue here ?
B: that both the cambridge system and our system were training posteriors . and if we 're we 're coming from alignments coming from the sri system , it 's likelihood - based system . so so that 's another difference . , there 's diffe different front - end different , , training criterion would think that in that an embedded embedded training would have at least good shot of improving it some more . you gonna say something ?
F: was wondering what size net should anybody have any intuitions or suggestions ?
B: how much training data ?
F: was gonna start off with the small train set .
B: and how how many hours is that ?
F: that 's why was 'm not how much that is .
D: you 'd would be gender - dependent training , so it 's that 's about mmm , something like thirty hours .
F: gender - dependent , .
D: thirty hours per gender .
A: 'm not what this 'll mean .
F: in the small training set ?
D: it 's definitely less than hundred it 's more like thirty forty hours something like that .
F: they called to tell us that ?
B: so . . after run
F: didn't want to do too big ,
B: at least couple thousand hidden units . it 's it 's th the thing 'll 'll think about it little more but it 'd be toss up between two thousand and four thousand . you definitely wouldn't want the eight thousand . it 's it 's more than
F: and thousand is too small ?
B: let me think about it , but that th at some point there 's diminishing returns . it doesn't actually get worse , typically , but it but there is diminishing returns and you 're doubling the amount of time .
D: remember you 'll have smaller output layer so there 's gonna be fewer parameters there .
A: but not by lot .
B: not by much . fifty fifty four to forty eight ?
A: vast majority is from the input unit .
B: it 'll have very tiny effect .
A: right , because you used the context windows and so the input to hidden is much , much larger .
D: it 's negligible , .
B: so it 's it 'd be way , way less than ten percent of the difference . how bi how big let 's see . what am trying to think of ?
F: the net that we did use already was eight thousand hidden units and that 's the one that eric trained up .
B: and that was trained up on like hundred and forty hours of speech .
D: was that gender - dependent or independent ?
F: gender - dependent .
B: so that would be like trained on sixty or seventy hours . definitely not the one thousand two thousand fr the four thousand will be better and the two thousand will be almost will be faster and almost as good .
A: it 'll be faster .
F: maybe 'll start off with two thousand just to see .
B: thirty hours is like hundred and ten thousand seconds . so that 's like eleven million frames . and two thousand hidden unit net is about seven , eight hundred thousand parameters . so that 's probably that 's probably fine . four thousand is within the range that you could benefit from but the two thousand 'd be faster
D: actually have to go .
B: uncle bernie 's rule is ten to one . bernie woodrow 's rule of
A: we 're just waiting for you to leave .
B: since we have nothing to talk about we only talked for an hour .
A: that 's right . , we started late .
B: de - ba - de . de - ba - de that 's all folks !
","This is a relatively short meeting of the Meeting Recorder group , with only a few agenda items.
Transcription was discussed briefly because Jane was not present , however this appears to be progressing well in parallel with IBM.
Web pages have been set up to show transcription status and to allow participants to approve transcripts.
DARPA demos are progressing well with the back-end indexed to allow front-end filtering , and a potential demo ideas investigated which would use X Waves.
Transcriber is now working for Windows , however live pitch contours may not work in the time available.
Backed-up disk space is now fine , however temporary space is running out fast.
Interim measures are discussed while sysadmin are away.
Improvement has been made in the final version of the PLP , which shows better female performance , and combined with Mel Ceptra offers 1.5% improvement.
Digit performance also improved thanks to training using scripted speech data.
Progress has also been made in SRI alignment for tandem system.
The group note that the annual report needs to be worked on for next week , and it is also suggested to hold recognition meetings separately , however these issues will be discussed in more detail at the next meeting.
Jane will be contacted to see whether transcribers could work on a small amount of SmartKom data , in order to get the project moving.
Details of the transcription status web page will be sent to the group.
Participants will be contacted to approve transcripts or suggest edits , however this depends upon decisions regarding disk space and ( un )compression of audio files.
There are disk space problems regarding scratch space , although the group decide that a solution about adding extra drives cannot be resolved without talking to sysadmin.
Until they can be contacted , the group will use the hard drives on each other's machines.
Displaying pitch contours live in Transcriber would be desirable for the demo , however , if the group run out of time , the group note that they could generate this statically using Powerpoint.
The group decide that it may be more beneficial to have separate meetings to discuss recognition , since Jane and Liz are less likely to be interested in this.
They will discuss this with them before going ahead.
Scratch disk space used to store the uncompressed meetings when they are being processed is getting short - the group are using 98%.
Various options are suggested about adding extra drives , externally to their machines , or to the server , but these cannot be resolved until after the relevant sysadmin person returns from a break in 10 days time.
Time is getting tight for some of the demo development , especially a lack of Tcl-TK skills slowing up back-end progress.
Additionally , time constraints may impinge upon the ""live-ness"" of the Transcriber pitch contour demo.
Annual report is due next week , so this will need to be discussed at the next meeting.
The group are still waiting for IBM to return transcripts next week.
This is not holding the group up , since parallel transcription is being used , and new transcribers have been recruited.
The web page detailing transcription status is working and being updated when possible.
Backed-up disk space has been seen as a priority by sysadmin , and the group are now only using 30% of this.
DARPA demos are progressing , with indexing added to the back-end , which will allow the front end to do filtering.
Transcriber has been developed to run on a Windows machine , with further development being undertaken to add a pitch contour display.
There is also the potential for a demo to be developed from X Waves.
The final version of PLP has been tested which shows similar performance as the system with the Mel Ceptra front-end ( although performance for males is slightly , but non-significantly better ).
Combining the two systems gives a 1.5% improvement in performance.
There has also been some improvement with digits , by training the system on read speech data , rather than training solely on TI digits or TIMIT data.
Progress is being made with SRI system alignment , with label files converted to train the net.
"
ami_abstractive_summary,Bro012.txt,"B: we 're on .
A: so had some interesting mail from dan ellis . actually , he redirected it to everybody also so the pda mikes have big bunch of energy at five hertz where this came up was that was showing off these wave forms that we have on the web and hadn't noticed this , but that the major , major component in the wave in the second wave form in that pair of wave forms is actually the air conditioner . have to be more careful about using that as as as good illustration , it 's not , of of the effects of room reverberation . it is isn't bad illustration of the effects of room noise . on some mikes and then we had this other discussion about whether this affects the dynamic range , cuz know , although we start off with thirty two bits , you end up with sixteen bits and , are we getting hurt there ? but dan is pretty confident that we 're not , that quantization error is not is still not significant factor there . so there was question of whether we should change things here , whether we should change capacitor on the input box for that or whether we should
B: he suggested smaller capacitor ,
A: but then had some other thing discussions with him and the feeling was once we start monk monkeying with that , , many other problems could ha happen . and additionally we already have lot of data that 's been collected with that , simple thing to do is he he has forget if it this was in that mail or in the following mail , but he has simple filter , digital filter that he suggested . we just run over the data before we deal with it . the other thing that the answer to , but when people are using feacalc here , whether they 're using it with the high - pass filter option or not . and if anybody knows .
E: could go check .
A: so when we 're doing all these things using our software there is if it 's if it 's based on the rasta - plp program , which does both plp and rasta - plp then there is an option there which then comes up through to feacalc which allows you to do high - pass filtering and in general we like to do that , because of things like this and it 's pretty it 's not very severe filter . doesn't affect speech frequencies , even pretty low speech frequencies , ,
B: what 's the cut - off frequency it used ?
A: wrote this while ago
B: is it like twenty ?
A: something like that . there 's some effect above twenty but it 's it 's it 's mild . so , it probably there 's probably some effect up to hundred hertz but it 's it 's pretty mild . in the in the strut implementation of the is there high - pass filter or pre - emphasis in the
F: we use pre - emphasis .
A: so . we we want to go and check that in for anything that we 're going to use the mike for . he says that there 's pretty good roll off in the pzm mikes so we don't need to worry about them one way or the other but if we do make use of the cheap mikes , we want to be to do that filtering before we process it . and then again if it 's depending on the option that the our software is being run with , it 's it 's quite possible that 's already being taken care of . but also have to pick different picture to show the effects of reverberation .
B: did somebody notice it during your talk ?
A: if they made output they were they were , they were .
B: didn't say anything ?
A: but . it was since was talking about reverberation and showing this thing that was noise , it wasn't good match , but it certainly was still an indication of the fact that you get noise with distant mikes . it 's just not great example because not only isn't it reverberation but it 's noise that we definitely to do . so , , it doesn't take deep new bold new methods to get rid of five hertz noise , so it was it was bad example in that way , but it 's it still is it 's the real thing that we did get out of the microphone at distance , so it wasn't it wasn't wrong it was inappropriate . so . so , but , someone noticed it later pointed it out to me , and went "" , man . why didn't notice that ? "" so we 'll change our picture on the web , when we 're @ @ . one of the things was , was trying to think about what 's the best way to show the difference an and had couple of thoughts one was , that spectrogram that we show is , but the eyes and the brain behind them are so good at picking out patterns from noise that in first glance you look at them it doesn't seem like it 's that bad because there 's many features that are still preserved . so one thing to do might be to just take piece of the spec of the spectrogram where you can see that something looks different , an and blow it up , and have that be the part that 's just to show as .
B: - . - .
A: some things are going to be hurt . another , was thinking of was taking some spectral slices , like like we look at with the recognizer , and look at the spectrum or cepstrum that you get out of there , and the , , the reverberation does make it does change that . and so maybe that would be more obvious .
C: what what do you mean ?
A: all the recognizers look at frames . so they look at
B: so like one instant in time .
A: so it 's , at one point in time or twenty over twenty milliseconds , you have spectrum or cepstrum . that 's what by slice . and if you look at
B: you could just you could just throw up , , the some mfcc feature vectors . one from one , one from the other , and then , , you can look and see how different the numbers are .
A: right . , that 's why saying either , either spectrum or cepstrum
B: 'm just kidding . don't mean graph . the actual numbers .
A: that would be lovely ,
B: "" see how different these sequences of numbers are ? ""
A: or could just add them up and get different total .
B: it 's not the square .
A: what else wh what 's what else is going on ?
F: at first had remark why am wondering why the pda is always so far . we are always meeting at the beginning of the table and the pda 's there .
A: cuz we haven't wanted to move it . we we could we could move us ,
E: that 's right .
F: since the last meeting we 've we 've tried to put together the clean low - pass downsampling , upsampling , , the new filter that 's replacing the lda filters , and also the delay issue we considered th the delay issue on the for the on - line normalization . so we 've put together all this and then we have results that are not very impressive . there is no real improvement .
A: but it 's not wer worse and it 's better latency ,
F: actually it 's better . it seems better when we look at the mismatched case but we are like cheated here by the th this problem that in some cases when you modify slight slightly modify the initial condition you end up completely somewhere air somewhere else in the in the space , the parameters . the other system are . for italian is at seventy - eight percent recognition rate on the mismatch , and this new system has eighty - nine . but don't indicates something , really . don't don't means that the new system is more robust it 's simply the fact that
A: the test would be if you then tried it on one of the other test sets , if it was right . so this was italian , so then if you take your changes
F: it 's similar for other test sets but from this se seventy - eight percent recognition rate system , could change the transition probabilities for the first and it will end up to eighty - nine also . by using point five instead of point six , point four as in the htk script . so . . that 's
B: looked at looked at the results when stephane did that and it 's it 's really wo really happens .
F: this really happens .
B: th the only difference is you change the self - loop transition probability by tenth of percent and it causes ten percent difference in the word error rate .
A: tenth of per cent .
F: even tenth of percent ? we tried we tried point one ,
B: for point from you change at point one and not tenth of percent , one tenth , so from point five so from point six to point five and you get ten percent better . and it 's it 's what you hypothesized in the last meeting about it just being very and you mentioned this in your email too it 's just very get stuck in some local minimum and this thing throws you out of it .
A: what 's what are according to the rules what are we supposed to do about the transition probabilities ? are they supposed to be point five or point six ?
B: you 're not allowed to that 's supposed to be point six , for the self - loop .
A: point it 's supposed to be point six .
B: but changing it to point five is which gives you much better results , but that 's not allowed .
A: but not allowed ?
F: but even if you use point five , 'm not it will always give you the better results on other test set or it
B: right . we only tested it on the medium mismatch ,
F: on the other training set , .
B: you said on the other cases you didn't notice
F: the reason is , it was in my mail also , is the fact that the mismatch is trained only on the far microphone . in for the mismatched case everything is using the far microphone training and testing , whereas for the highly mismatched , training is done on the close microphone so it 's clean speech so you don't have this problem of local minima probably and for the - match , it 's mix of close microphone and distant microphone so th the mismatch is the more difficult for the training part .
B: somebody , it was morgan , suggested at the last meeting that actually count to see how many parameters and how many frames . and there are almost one point eight million frames of training data and less than forty thousand parameters in the baseline system . so it 's very , very few parameters compared to how much training data .
A: and that says that we could have lots more parameters actually .
B: did one quick experiment just to make had everything worked out and for most of the for for all of the digit models , they end up at three mixtures per state . and so did quick experiment , where changed it so it went to four and it didn't have any significant effect at the medium mismatch and high mismatch cases and it had it was just barely significant for the - matched so 'm gonna run that again but with many more mixtures per state .
A: cuz at forty thou you could have easily four times as many parameters .
B: and also just seeing what we saw in terms of the expected duration of the silence model ? when we did this tweaking of the self - loop ? the silence model expected duration was really different . and so in the case where it had better score , the silence model expected duration was much longer . so it was like it was better match . if we make better silence model that will help lot too for lot of these cases but one thing wanted to check out before increased the number of mixtures per state was in their default training script they do an initial set of three re - estimations and then they built the silence model and then they do seven iterations then the add mixtures and they do another seven then they add mixtures then they do final set of seven and they quit . seven seems like lot to me and it also makes the experiments go take really long time to do one turn - around of the matched case takes like day . and so in trying to run these experiments notice , , it 's difficult to find machines , , compute the run on . and so one of the things did was compiled htk for the linux machines cuz we have this one from ibm that 's got like five processors in it ? and so now 'm you can run on that and that really helps lot because now we 've got , extra machines that we can use for compute . and if 'm do running an experiment right now where 'm changing the number of iterations ? from seven to three ? just to see how it affects the baseline system . and so if we can get away with just doing three , we can do many more experiments more quickly . and if it 's not huge difference from running with seven iterations , , , we should be able to get lot more experiments done . and so . 'll let what happens with that . but if we can , run all of these back - ends with many fewer iterations and on linux boxes we should be able to get lot more experimenting done . so wanted to experiment with cutting down the number of iterations before increased the number of gaussians .
A: so , how 's it going on the so . you you did some things . they didn't improve things in way that convinced you 'd substantially improved anything . but they 're not making things worse and we have reduced latency ,
F: but actually actually it seems to do little bit worse for the - matched case and we just noticed that actually the way the final score is computed is quite funny . it 's not mean of word error rate . it 's not weighted mean of word error rate , it 's weighted mean of improvements . which means that actually the weight on the - matched is what what happened is that if you have small improvement or small if on the - matched case it will have huge influence on the improvement compared to the reference because the reference system is is quite good for the - ma - matched case also .
B: so it weights the improvement on the - matched case really heavily compared to the improvement on the other cases ?
F: no , but it 's the weighting of the of the improvement not of the error rate .
B: and it 's hard to improve on the on the best case , cuz it 's already so good ,
F: but what is that you can have huge improvement on the hmk 's , like five percent absolute , and this will not affect the final score almost this will almost not affect the final score because this improvement because the improvement relative to the baseline is small
A: so they do improvement in terms of accuracy ? rather than word error rate ?
F: no , it 's compared to the word er it 's improvement on the word error rate ,
A: so if you have ten percent error and you get five percent absolute improvement then that 's fifty percent . so what you 're saying then is that if it 's something that has small word error rate , then even relatively small improvement on it , in absolute terms , will show up as quite large in this . is that what you 're saying ? but that 's it 's the notion of relative improvement . word error rate .
F: but when we think about the weighting , which is point five , point three , point two , it 's on absolute on relative figures , so when we look at this error rate
A: that 's why 've been saying we should be looking at word error rate and not at accuracies . we probably should have standardized on th the way through .
B: it 's not it 's not that different , just subtract the accuracy .
A: but you 're but when you look at the numbers , your sense of the relative size of things is quite different . if you had ninety percent correct and five percent , five over ninety doesn't look like it 's big difference , but five over ten is big . so just when we were looking at lot of numbers and getting sense of what was important .
B: see . see . that makes sense .
F: so it hurts little bit on the - match
A: what 's little bit ?
F: like , it 's difficult to say 'm not have the
B: do you remember that signif program that we used to use for testing signi ? is that still valid ? 've been using that .
A: it was actually updated . jeff updated it some years ago and cleaned it up made some things better in it .
B: should find that new one . use my old one from ninety - two or whatever
A: 'm it 's not that different but he he was little more rigorous , as recall .
F: so it 's around , like , point five . no , point six percent absolute on italian
A: out of what ?
F: we start from ninety - four point sixty - four , and we go to ninety - four point four .
A: so that 's six point th
B: ninety - three point six four , is the baseline .
F: no , 've ninety - four . the baseline , you mean . don't 'm not talking about the baseline here . my baseline is the submitted system .
B: ! . , .
F: for finnish , we start to ninety - three point eight - four and we go to ninety - three point seventy - four . and for spanish we are we were at ninety - five point five and we go to ninety - three - point sixty one .
A: so we are getting hurt somewhat . you 've done several changes here .
F: it 's it 's the filter . because nnn , we don't have complete result , but the filter so the filter with the shorter delay hurts on italian - matched , and the other things , like downsampling , upsampling , don't seem to hurt and the new on - line normalization , neither .
B: 'm really confused about something . if we saw that making small change like , , tenth , to the self - loop had huge effect , can we really make any conclusions about differences in this ? especially when they 're this small .
F: we can be completely fooled by this thing , so . there is first this thing , computed the like , the confidence level on the different test sets . and for the - matched they are around point six percent . for the mismatched they are around like let 's say one point five percent . and for the - hm they are also around one point five .
A: but , so you these degradations you were talking about were on the - matched case do the does the new filter make things better or worse for the other cases ?
F: about the same . it doesn't hurt .
A: doesn't hurt , but doesn't get little better , . so the argument one might make is that , "" , if you looked at one of these cases and you jiggle something and it changes then you 're not quite what to make of it . but when you look across bunch of these and there 's some pattern , so here 's all the if in all these different cases it never gets better , and there 's significant number of cases where it gets worse , then you 're probably hurting things , would say . so at the very least that would be reasonably prediction of what would happen with different test set , that you 're not jiggling things with . so the question is if you can do better than this . if you can if we can approximate the old numbers while still keeping the latency down . what was asking , though , is are what 's the level of communication with the gang now , about this
F: we are exchanging mail as soon as we have significant results . for the moment , they are working on integrating the spectral subtraction from ericsson . we are working on our side on other things like also trying sup spectral subtraction but of our own , , another spectral substraction . so it 's it 's .
A: is there any further discussion about this idea of having some source code control ?
F: for the moment they 're there is this eurospeech deadline , as soon as we have something that 's significant and that 's better than what was submitted , we will fix the system but we 've not discussed it this yet ,
A: sounds like great idea but that he 's saying people are scrambling for eurospeech deadline . but that 'll be , done in week . so , maybe after this next one .
B: you 're right . that 's amazing .
A: anybo - anybody in the in this group do doing anything for eurospeech ? or , is that what is that
F: we are we are trying to do something with the meeting recorder digits , and the good thing is that there is this first deadline , and , , some people from ogi are working on paper for this , but there is also the special session about th aurora which is which has an extended deadline . the deadline is in may .
A: for , for eurospeech ?
F: so only for the experiments on aurora . so it 's good ,
A: that 's great .
B: where is eurospeech this year ?
F: it 's in denmark .
A: when 's the deadline ? when 's the deadline ?
F: it 's the thirteenth of may .
A: that 's great ! it 's great . so we should definitely get something in for that . but on meeting digits , maybe there 's
F: so it would be for the first deadline .
A: so , , that you could certainly start looking at the issue but it 's probably , on from what stephane is saying , it 's it 's unlikely to get active participation from the two sides until after they 've
B: 'm going to be out next week but could try to look into like this cvs over the web . that seems to be very popular way of people distributing changes and over , , multiple sites and things so maybe if figure out how do that easily and then pass the information on to everybody so that it 's , as easy to do as possible and people don't it won't interfere with their regular work , then maybe that would be good . and we could use it for other things around here too .
C: and if you 're interested in using cvs , 've set it up here ,
B: used it long time ago but it 's been while so maybe ask you some questions .
C: so . 'll be away tomorrow and monday but 'll be back on tuesday or wednesday .
A: dave , the other thing , actually , is this business about this wave form . maybe you and talk little bit at some point about coming up with better demonstration of the effects of reverberation for our web page , it made good audio demonstration because when we could play that clip the the really obvious difference is that you can hear two voices and in the second one and only hear
B: maybe we could just like , talk into cup . some good reverb .
A: no , , it sound it sounds pretty reverberant , but you can't when you play it back in room with big room , nobody can hear that difference really . they hear that it 's lower amplitude and they hear there 's second voice , that actually that makes for perfectly good demo because that 's real obvious thing , that you hear two voices .
B: but not of reverberation .
A: that that 's . but for the visual , just , , 'd like to have , , the spectrogram again , because you 're you 're visual abilities as human being are so good you can pick out you look at the good one , you look at the cru the screwed up one , and you can see the features in it without trying to @ @
B: noticed that in the pictures . "" hey , th "" my initial thought was "" this is not too bad ! ""
A: but you have to , if you look at it closely , you see "" , here 's place where this one has big formant formant maj major formants here are moving quite bit . "" and then you look in the other one and they look practically flat . so you could that 's why was thinking , in section like that , you could take look at just that part of the spectrogram and you could say "" . this this really distorted it quite bit . ""
B: the main thing that struck me in looking at those two spectrograms was the difference in the high frequencies . it looked like for the one that was farther away , , it really everything was attenuated that was the main visual thing that noticed .
A: but it 's it 's so there are clearly are spectral effects . since you 're getting all this indirect energy , then lot of it does have reduced high frequencies . but the other thing is the temporal courses of things really are changed , and we want to show that , in some obvious way . the reason put the wave forms in there was because they do look quite different . and so "" , this is good . "" after after they were put in there didn't really look at them anymore , cuz they were different . so want something that has is more interesting explanation for why they 're different .
C: so maybe we can just substitute one of these wave forms and then do some zoom in on the spectrogram on an interesting area .
A: something like that . the other thing that we had in there that didn't like was that the most obvious characteristic of the difference when you listen to it is that there 's second voice , and the the cuts that we have there actually don't correspond to the full wave form . it 's just the first there was something where he was having some trouble getting so much in , forget the reason behind it . but it 's it 's the first six seconds of it and it 's in the seventh or eighth second where @ @ the second voice comes in . so we would like to actually see the voice coming in , too , , since that 's the most obvious thing when you listen to it .
F: brought some if some figures here . start we started to work on spectral subtraction . and the preliminary results were very bad . so the thing that we did is just to add spectral subtraction before this , the wall process , which contains lda on - line normalization . and it hurts lot . and so we started to look at things like this , so you have the - zero parameters for one italian utterance .
D: you can @ @ .
F: and plotted this for two channels . channel zero is the close mic microphone , and channel one is the distant microphone . and it 's perfectly synchronized , and the sentence contain only one word , which is "" due "" and it can't clearly be seen . where where is it ? where is the word ?
B: this is this is , plot of - zero ,
F: this is plot of - zero , when we don't use spectral substraction , and when there is no on - line normalization . there is just some filtering with the lda and some downsampling , upsampling .
B: - zero is the close talking ? the close channel ? and channel one is the
F: so - zero is very clean , actually . then when we apply mean normalization it looks like the second figure , though it is not . which is good . the noise part is around zero and and then the third figure is what happens when we apply mean normalization and variance normalization . what we can clearly see is that on the speech portion the two channel come becomes very close , but also what happens on the noisy portion is that the variance of the noise is
B: this is still being plot of - zero ?
F: this is still - zero .
B: can ask what does variance normalization do ? what is the effect of that ?
A: normalizes the variance .
F: it normalized th the standard deviation .
B: no , understand that ,
F: you you get an estimate of the standard deviation .
B: no , understand what it is , but , what does it what 's what is
A: what 's the rationale ?
B: why why do it ?
A: , because everything if you have system based on gaussians , everything is based on means and variances . so if there 's an overall reason it 's like if you were doing image processing and in some of the pictures you were looking at , there was lot of light and in some , there was low light , you would want to adjust for that in order to compare things . and the variance is just like the next moment , so what if one set of pictures was taken so that throughout the course it was went through daylight and night ten times , another time it went thr is , , how much how much vari better example would be how much of the light was coming in from outside rather than artificial light . so if it was lot if more was coming from outside , then there 'd be the bigger effect of the of the change in the so every mean every all of the parameters that you have , especially the variances , are going to be affected by the overall variance . and so , in principle , you if you remove that source , then , , you can
B: so would the major effect is that you 're gonna get is by normalizing the means ,
A: that 's the first order but thing ,
B: but it may help first - order effects .
A: but then the second order is the variances
B: and it may help to do the variance .
A: because , again , if you if you 're trying to distinguish between and if it just so happens that the 's were more , were recorded when the energy was was larger ,
B: - . - .
A: or the variation in it was larger , than with the 's , then this will be give you some bias . so the it 's removing these sources of variability in the data that have nothing to do with the linguistic component . but the but let me as ask you something .
F: and it and this
A: is if if you have good voice activity detector , isn't isn't it gonna pull that out ?
F: if they are good . what it shows is that , , perhaps good voice activity detector is good before on - line normalization and that 's what we 've already observed . voice activity detection is not an easy thing neither .
B: but after you do this , after you do the variance normalization it seems like this would be lot easier than this signal to work with .
F: so . what notice is that , while prefer to look at the second figure than at the third one , because you clearly see where speech is . but the problem is that on the speech portion , channel zero and channel one are more different than when you use variance normalization where channel zero and channel one become closer .
B: but for the purposes of finding the speech you 're more interested in the difference between the speech and the nonspeech ,
F: for th that it perhaps it shows that the parameters that the voice activity detector should use have to use should be different than the parameter that have to be used for speech recognition .
A: so you want to reduce this effect . so you can do that by doing the voi voice activity detection . you also could do it by spect spectral subtraction before the variance normalization ,
F: but it 's not clear , it 's just to the number that at that are here are recognition experiments on italian hm and with these two kinds of parameters . and , , it 's better with variance normalization .
A: so it does get better even though it looks ugly . but does this have the voice activity detection in it ?
F: but the fact is that the voice activity detector doesn't work on channel one .
B: where at what stage is the voice activity detector applied ? is it applied here or after the variance normalization ?
A: spectral subtraction , .
F: it 's applied before variance normalization . so it 's good thing , because voice activity detection on this should could be worse .
B: is it applied all the way back here ?
F: it 's applied the something like this ,
B: maybe that 's why it doesn't work for channel one .
F: so we could perhaps do just mean normalization before vad .
A: can ask , top - level question , which is "" if most of what the ogi folk are working with is trying to integrate this other spectral subtraction , why are we worrying about it ? ""
F: it 's just it 's another they are trying to to use the the ericsson and we 're trying to use something else . and also to understand what happens because when we do spectral subtraction , actually , that this is the two last figures . it seems that after spectral subtraction , speech is more emerging now than before .
B: speech is more what ?
F: the difference between the energy of the speech and the energy of the spectral subtrac subtracted noise portion is larger . if you compare the first figure to this one actually the scale is not the same , but if you look at the numbers you clearly see that the difference between the - zero of the speech and - zero of the noise portion is larger . but what happens is that after spectral subtraction , you also increase the variance of this of - zero . and so if you apply variance normalization on this , it completely sc screw everything . and what they did at ogi is just they don't use on - line normalization , for the moment , on spectral subtraction as soon as they will try on - line normalization there will be problem . so , we 're working on the same thing but
A: intellectually it 's interesting to work on things th one way or the other but 'm 'm just wondering if on the list of things that there are to do , if there are things that we won't do because we 've got two groups doing the same thing . just just asking .
B: there also could be . maybe see reason for both working on it too if , if if you work on something else and you 're waiting for them to give you spectral subtraction it 's hard to know whether the effects that you get from the other experiments you do will carry over once you then bring in their spectral subtraction module . so it 's it 's almost like everything 's held up waiting for this one thing . if that 's true or not , but could see how maybe that 's what you were thinking .
A: , we still evidently have latency reduction plan which isn't quite what you 'd like it to be . that that seems like one prominent thing . and then weren't issues of having second stream ? there was this business that , , we could use up the full forty - eight hundred bits ,
F: we want to work on this . they also want to work on this , we we will try msg , they want to work on the second stream also , but more with some multi - band or , , what they call trap or generalized trap .
A: do you remember when the next meeting is supposed to be ?
F: it 's in june .
A: , the other thing is that you saw that mail about the vad ds performing quite differently ? this there was this experiment of "" what if we just take the baseline ? "" set of features , just mel cepstra , and you inc incorporate the different and it looks like the french vad is actually better significantly better .
B: improves the baseline ?
F: but which vad they use . if the use the small vad th it 's on it 's easy to do better because it doesn't work . it 's pratibha that did this experiment . we should ask which vad she used .
D: don't @ @ . he actually , that he say with the good vad of from ogi and with the alcatel vad . and the experiment was sometime better , sometime worse .
F: but it 's you were talking about the other mail that used vad on the reference features .
A: and on that one , the french one is was better . it was just better . it was enough better that it would account for fair amount of the difference between our performance , actually . so if they have better one , we should use it . you can't work on everything .
F: so we should find out if it 's really better . the compared to the small or the big network . and perhaps we can easily improve if we put like mean normalization before the before the vad . because as you 've mentioned .
A: hynek will be back in town the week after next , back in the country . and start organizing more visits and connections and , working towards june .
D: also is stephane was thinking that maybe it was useful to to think about voiced - unvoiced to work here in voiced - unvoiced detection . and we are looking in the signal .
F: my feeling is that actually when we look the proposals , ev everybody is still using some spectral envelope
A: no use of pitch .
F: , not pitch , but to look at the fine at the high re high resolution spectrum . so . we don't necessarily want to find the pitch of the of the sound cuz have feeling that when we look at the just at the envelope there is no way you can tell if it 's voiced and unvoiced , if there is some it 's it 's easy in clean speech because voiced sound are more low frequency so there would be more , there is the first formant , which is the larger and then voiced sound are more high frequencies cuz it 's frication when you have noise there is no if you have low frequency noise it could be taken for voiced speech
A: you can make these mistakes ,
B: isn't there some other
F: so that it would be good
B: was just gonna say isn't there aren't aren't there lots of ideas for doing voice activity , or speech - nonspeech rather , by looking at , , harmonics or looking across time
A: he was talking about the voiced - unvoiced , though , so , not the speech - nonspeech .
B: even with the voiced - non voiced - unvoiced that you or somebody was talking about
A: we should let him finish what he he was gonna say ,
B: so go ahead .
F: so , if we try to develop second stream there would be one stream that is the envelope and the second , it could be interesting to have that 's something that 's more related to the fine structure of the spectrum . we were thinking about like using ideas from larry saul , have good voice detector , voiced - speech detector , that 's working on the fft larry saul could be an idea . we were are thinking about just taking the spectrum and computing the variance of the high resolution spectrum and things like this .
A: so many tell you something about that . we had guy here some years ago who did some work on making use of voicing information to help in reducing the noise . so what he was doing is you do estimate the pitch . you from that you estimate or you estimate fine harmonic structure , ei either way , it 's more or less the same . but that you then can get rid of things that are not if there is strong harmonic structure , you can throw away that 's that 's non - harmonic . and that is another way of getting rid of part of the noise so that 's something that is finer , brings in little more information than just spectral subtraction . and he had some , he did that in combination with rasta . it was like rasta was taking care of convolutional and got some decent results doing that . so that 's another way . but , there 's there 's there 's all these cues . actually back when chuck was here we did some voiced - unvoiced classification using bunch of these , it 's not perfect but that you can't given the constraints of this task , we can't , in very way , feed forward to the recognizer the information the probabilistic information that you might get about whether it 's voiced or unvoiced , where we can't affect the distributions or anything . but we what we
B: didn't the head dude send around that message ? you sent us all copy of the message , where he was saying that 'm not , exactly , what the gist of what he was saying , but something having to do with the voice activity detector and that it will that people shouldn't put their own in . it was gonna be
A: so that 's voice activity detector as opposed to voicing detector . so we 're talking about something little different . what you could do , maybe this would be useful , if you have if you view the second stream , before you before you do klt 's and , if you do view it as probabilities , and if it 's an independent so , if it 's if it 's not so much envelope - based by fine - structure - based , looking at harmonicity like that , if you get probability from that information and then multiply it by , multiply by all the voiced outputs and all the unvoiced outputs , then use that as the take the log of that or pre pre - nonlinearity , and do the klt on the on that , then that would that would be reasonable use of independent information . so maybe that 's what you meant . and then that would be
F: , was not thinking this this could be an so you mean have some probability for the the voicing
A: right . so you have second neural net .
F: and then use tandem system
A: it could be pretty small . if you have tandem system and then you have some it can be pretty small net we used we did some of this . did , some years ago , and the and you use to use information primarily that 's different as you say , it 's more fine - structure - based than envelope - based so then it you you can guarantee it 's that you 're not looking at very with the other one , and then you only use for this one distinction . and and so now you 've got probability of the cases , and you 've got the probability of the finer categories on the other side . you multiply them where appropriate
F: see , . - .
A: if they really are from independent information sources then they should have different kinds of errors and roughly independent errors , and it 's good choice for that 's good idea .
F: because , , , spectral subtraction is good and we could we could use the fine structure to have better estimate of the noise but still there is this issue with spectral subtraction that it seems to increase the variance of of it 's this musical noise which is annoying if you you do some on - line normalization after . spectral subtraction and on - line normalization don't seem to go together very .
A: or if you do spectral subtraction do some spectral subtraction first and then do some on - line normalization then do some more spectral subtraction maybe you can do it layers so it doesn't doesn't hurt too much . but it but , anyway was arguing against myself there by giving that example cuz was already suggesting that we should be careful about not spending too much time on exactly what they 're doing if you get if you go into harmonics - related thing it 's definitely going to be different than what they 're doing should have some interesting properties in noise . know that when have people have done the obvious thing of taking your feature vector and adding in some variables which are pitch related that it hasn't my impression it hasn't particularly helped . but that 's question for this extending the feature vector versus having different streams .
F: was it nois noisy condition ? the example that you just
A: and and it may not have been noisy conditions . don't remember the example but it was it was on some darpa data and some years ago and so it probably wasn't , actually
F: but we were thinking , we discussed with barry about this , and perhaps thinking we were thinking about some sheet cheating experiment where we would use timit and see if giving the , this voicing bit would help in terms of frame classification .
A: why don't you why don't you just do it with aurora ? just any in each in each frame
F: but but we cannot do the cheating , this cheating thing .
E: we need labels .
F: cuz we don't have for italian perhaps we have , but we don't have this labeling for aurora . we just have labeling with word models but not for phonemes .
D: not for foreigners .
E: we don't have frame level transcriptions .
A: but you could you can you can align so that it 's not perfect , but if you if what was said
B: but the problem is that their models are all word level models . so there 's no phone models that you get alignments for . you so you could find out where the word boundaries are but that 's about it .
E: but we could use the noisy version that timit , which , is similar to the noises found in the ti - digits portion of aurora .
F: that 's right , . we can we can say that it will help , if this voicing bit doesn't help , , we don't have to work more about this it 's just to it how much it will help and to have an idea of how much we can gain .
A: in experiments that we did long time ago it was probably resource management , you were getting something like still eight or nine percent error on the voicing , as recall .
E: another person 's voice .
A: what that said is that , , left to its own devices , like without the strong language model and , that you would you would make significant number of errors just with your probabilistic machinery in deciding
B: the though there was one problem with that in that , , we used canonical mapping so our truth may not have really been true to the acoustics .
A: back twenty years ago when did this voiced - unvoiced , we were getting more like ninety - seven or ninety - eight percent correct in voicing . but that was speaker - dependent actually . we were doing training on particular announcer and getting very good handle on the features . and we did this complex feature selection thing where we looked the different possible features one could have for voicing and and and exhaustively searched all size subsets and for that particular speaker and you 'd find the five or six features which really did on them . and then doing all of that we could get down to two or three percent error . but that , again , was speaker - dependent with lots of feature selection and very complex thing . so would would believe that it was quite likely that looking at envelope only , that we 'd be significantly worse than that .
F: and the all the speechcorders ? what 's the idea behind ? cuz they have to they don't even have to detect voiced spe speech ?
A: the modern ones don't do simple switch .
F: they just work on the code book
A: they work on the code book excitation .
F: and find out the best excitation .
A: they do analysis - by - synthesis . they try they try every possible excitation they have in their code book and find the one that matches best .
F: so it would not help .
B: can mention one other interesting thing ? one of the ideas that we had come up with last week for things to try to improve the system actually we didn't wrote this in after the meeting but the thought had was looking at the language model that 's used in the htk recognizer , which is just big loop , so you it goes "" digit "" and then that can be either go to silence or go to another digit , that model would allow for the production of infinitely long sequences of digits , so . "" 'm gonna just look at the what actual digit strings do occur in the training data . "" and the interesting thing was it turns out that there are no sequences of two - long or three - long digit strings in any of the aurora training data . so it 's either one , four , five , six , up to eleven , and then it skips and then there 's some at sixteen .
A: but what about the testing data ?
B: didn't look at the test data yet .
A: if there 's some testing data that has has two or three
B: but thought that was little odd , that there were no two or three long so for the heck of it , made little grammar which , , had it 's separate path for each length digit string you could get . so there was one - long path and there was four - long and five - long and tried that and it got way worse . there were lots of deletions . so it was , didn't have any weights of these paths or didn't have anything like that . and played with tweaking the word transition penalties bunch , but couldn't go anywhere . "" if only allow "" should have looked at to see how often there was mistake where two - long or three - long path was actually put out as hypothesis . so to do that right you 'd probably want to have allow for them all but then have weightings and things . so . thought that was interesting thing about the data .
A: so we 're gonna read some more digit strings ?
B: you want to go ahead , morgan ?
","The Meeting Recorder group at Berkeley met to discuss recent progress.
Of greatest interest was the progress on improving the latency and performance of their recogniser.
There was also concern over overlap of work with partners OGI , and a lack of a good example of room reverberation for demonstrations.
Everyone must be sure and use the high-pass filtering option on the groups software , to deal with irregularities between mics.
In order to coordinate better with OGI , some sort of source code control is required and me018 has offered to investigate , but only minimal progress can be made until after the upcoming deadline for Eurospeech.
When he returns me026 will help.
Also , in two weeks one of the OGI members will return , and meetings should be arranged with him before the next big project meeting.
OGI seem to be having some good results with voice activation detection , so the group need to find out which is the best VAD and start using it.
The is a waveform example of room reverberation on the groups website that was used in a presentation.
It turns out that it is a good example of many things , but not the reverb it is supposed to contain.
Need to find a better example , maybe by just looking at a closer section of waveform.
Minor experimenting found that by dropping the self-loop transition in the HMMs by just 0.1% can increase performance by 10% , but the rules of the task forbid this change.
There is some confusion over what the results produced mean , since it appears they are weighted , which biases improvements in some cases quite heavily.
Speaker me013 is worried that his groups work on spectral subtraction overlaps with that of OGI , and that it may be time better spent on other tasks.
Speaker mn007 and fn002 have been working on improving the recogniser performance as well as reducing it's latency.
Work on new filters has reduced latency , but made no improvement , though a slight reduction in performance occurred in the well matched case.
Also tried adding some spectral subtraction , but it doesn't work will with on-line normalization and at this stage is just hurting results.
They have also been considering the possibility of using a second stream of data looking at the voicedness of the data , which would draw some ideas from previous work.
Me018 has been looking at the baseline system and feels it may be possible to decrease the run time of experiments by decreasing the iteration , and he has also got the five processor Linux machine capable of running HTKs.
"
ami_abstractive_summary,Bmr023.txt,"C: what channel am on ?
G: make to turn your microphone on . there 's battery .
B: there we go .
G: your channel number 's already on this blank sheet . so you just if you can
F: 'm on channel five .
B: camera one , camera two .
E: this number four ?
G: the gai the gain 's up at it what it usually is , but if you 's it 's default . but set it higher if you like .
F: maybe it should be little higher . it 's not showing much . test , test , test , test , test , test . that seems better ? that 's good . ahh . mmm . so had question for adam . have we started already ?
G: we started recording , but .
D: saw her earlier .
G: she can just walk in , , or
D: she 'll probably come up .
G: since we 're starting late figured we 'd better just start .
F: was gonna ask adam to , , say if he thought anymore about the demo because it occurred to me that this is late may and the darpa meeting is in mid july . but don't remember what we know that we were gonna do something with the transcriber interface is one thing , but there was second thing .
G: we were gonna do mock - up , like , question answering , , that was separate from the interface . do you remember ? remember , like , asking questions and retrieving , but in pre - stored fashion . that was the thing we talked about , , before the transcriber come on in .
F: alright . so anyway , you have to sort out that out and get somebody going on it cuz we 're got month left .
G: you like these .
F: so , what are we else we got ? you got you just wrote bunch of .
G: no . that was all , , previously here . was writing the digits and then realized could xerox them , because didn't want people to turn their heads from these microphones . we all , , have the same digit form , for the record .
F: so , the choice is , , which do we want more , the the comparison , , of everybody saying them at the same time or the comparison of people saying the same digits at different times that ?
G: it 's just cuz didn't have any more digit sheets .
F: but , , which opportunity should we exploit ? unison .
G: it actually it might be good to have them separately and have the same exact strings . we could use them for normalizing , but it goes more quickly doing them in unison .
F: it 's dependent on
G: see how long we go .
F: how long we go and how good the snack is out there .
E: but anyway , they won't be identical as somebody is saying zero in some sometimes , , saying , and so , it 's not not identical .
F: . get some advance intelligence . we 'd have to train .
G: we 'd be like chorus .
F: we 'd have to get get some experience . really boring chorus . do we have an agenda ? adam usually tries to put those together , but he 's ill .
D: 've got couple of things to talk about .
F: ju what might those be ?
D: ibm and , , just getting , meeting information organized .
F: meeting info organized .
C: are you implying that it 's currently disorganized ?
D: in my mind .
F: is there that 's happened about , , , the sri recognizer et cetera , tho those things that were happening before with ? you guys were doing bunch of experiments with different front - ends and then with is is that still where it was , , the other day ?
C: we 're improving .
F: we 're improving .
D: now the you saw the note that the plp now is getting the same as the mfcc .
C: actually it looks like it 's getting better . so . but but it 's not
F: just with age , .
C: with age . . but , , that 's not directly related to me . doesn't mean we can't talk about it . it seems it looks haven't the it 's the experiment is still not complete , it looks like the vocal tract length normalization is working beautifully , actually , using the warp factors that we computed for the sri system and just applying them to the icsi front - end .
F: that 's pretty funny .
G: so you just need to copy over to this one .
C: just had to take the reciprocal of the number because they have different meanings in the two systems .
F: , that 's always good to do .
C: but one issue actually that just came up in discussion with liz and don was , , as far as meeting recognition is concerned , , we would really like to , , move , , to , , doing the recognition on automatic segmentations . because in all our previous experiments , we had the , , we were essentially cheating by having the , , , the the hand - segmentations as the basis of the recognition . and so now with thilo 's segmenter working so , we should consider doing
E: mmm . so .
F: think you think we should increase the error rate .
E: that - that 's what wanted to do anyway , so we should just get together and
G: and even the good thing is that since you , , have high recall , even if you have low precision cuz you 're over - generating , that 's good because we could train noise models in the recognizer for these kinds of , , transients and things that come from the microphones , but know that if we run recognition unconstrained on whole waveform , we do very poorly because we 're we 're getting insertions in places what that you may be cutting out . so we do need some pre - segmentation .
C: we should we should consider doing some extra things , like , , , retraining or adapting the models for background noise to the to this environment , .
G: and , , using thilo 's , , posteriors or some or right now they 're they 're discrete , yes or no for speaker , to consider those particular speaker background models . there 's lots of ins interesting things that could be done .
E: we should do that .
F: so , , why don't we , , do the ibm ?
D: so , , talked with brian and gave him the alternatives to the single beep at the end of each utterance that we had generated before .
F: you had some thing about that ? the , , chuck chunks .
D: the chuck chunks . and so he talked it over with the transcriber and the transcriber thought that the easiest thing for them would be if there was beep and then the nu number , digit , and then beep , , at the beginning of each one and that would help keep them from getting lost . and , , so adam wrote little script to generate those style , , beeps
C: where 'd you get the digits from ?
D: and so we 're came up here and just recorded the numbers one through ten .
A: they sound really good .
D: does it sound ?
G: that 's great idea .
D: so , . we just used those .
C: and do you splice them into the waveform ?
D: he then he recorded actually , recorded one through ten three times at three different speeds and then he picked . he liked the fastest one , so he just cut those out and spliced them in between , , two beeps .
A: it sounds like radio announcer 's voice . really .
E: it will be funny it will be funny when you 're really reading digits , and then there are the chunks with your digits in ?
A: that 's right .
D: that 'll throw them ,
A: we 're are we handling ?
F: maybe we should have you record , , for those .
D: and she said it wasn't gonna the transcriber said it wouldn't be problem cuz they can actually make template , , that has beep , number , beep . so for them it 'll be very quick to put those in there when they 're transcribing . so , , we we 're gonna send them one more sample meeting , and thilo has run his segmentation . adam 's gonna generate the chunked file . and then , , 'll give it to brian and they can try that out . and when we get that back we 'll see if that fixes the problem we had with , , too many beeps in the last transcription .
F: do do what do you have any idea of the turn - around on those steps you just said ?
D: our our on our side ? or including ibm 's ?
F: including ibm 's .
D: the last one seemed like it took couple of weeks . maybe even three . that 's just the side . our side is quick . . how long does your ?
E: it should @ @ be finished today . .
F: the overall thing . the reason 'm asking is because , , jane and have just been talking , and she 's just been doing . , , , further hiring of transcribers . and so we don't really know exactly what they 'll be doing , how long they 'll be doing it , and , because right now she has no choice but to operate in the mode that we already have working . so it 'd be it 'd be good to get that resolved , , soon as we could ,
D: hope @ @ we can get better estimate from this one that we send them . yet how long that 'll take .
F: in particular would would really hope that when we do this darpa meeting in july that we have we 're into production mode , somehow that we actually have stream going and we know how it does and how and how it operates . that would that would certainly be very good thing to know .
D: right . right .
F: maybe before we do the meeting info organize thing , maybe you could say relevant about where we are in transcriptions .
A: so , , we , the transcribers have continued to work past what 'm calling "" set one "" , which was the the set that 've been , , talking about up to this point , but , , they 've gotten five meetings done in that set . right now they 're in the process of being edited . let 's see , hired two transcribers today . 'm thinking of hiring another one , which will because we 've had lot of attrition . and that will bring our total to
F: they die off after they do this for while .
A: , it 's it 's various things .
D: burn - out .
A: so , one of them had baby . , , one of them really wasn't planning
C: that was an unfor unforeseen side effect of
A: one of them , , had never planned to work past january . it 's th all these various things , cuz we , , we presented it as possibly month project back in january so it makes sense . through attrition we 've we 're down to two , but they 're really solid . we 're really lucky the two that we kept . and , , don't mean don't mean anything against the others . what is we 've got good good core . no . we had good core
G: they won't hear this since they 're going . they won't be transcribing this meeting .
A: but still . , it 's just matter of we we 're we 've got , , two of the ones who , , ha had been putting in lot of hours up to this point and they 're continuing to put in lot of hours , which is wonderful , and excellent work . and so , then , in addition , , hired two more today and 'm planning to hire third one with this within this coming week , but the plan is just as , , morgan was saying we discussed this , and the plan right now is to keep the staff on the on the leaner side , rather than hiring , like , eight to ten right now , because if the ibm thing comes through really quickly , then , , we wouldn't wanna have to , , , lay people off and . and this way it 'll , got really lot of response for my notice and could hire additional people if wish to .
F: an - and the other thing is , , in the unlikely event and since we 're so far from this , it 's little hard to plan this way in the unlikely event that we actually find that we have , , transcribers on staff who are twiddling their thumbs because , , there 's , , all the that was sitting there has been transcribed and they 're and they 're faster the pipeline is faster than , than the generation , in the day event that day actually dawns , , bet we could find some other for them to do . so that , , as we were talking , if we if we hire twelve , then we could , , run into problem later . we also just couldn't sustain that forever . but but , for all sorts of reasons but if we hire , we have five on staff five or six on staff at any given time , then it 's small enough number so we can be flexible either way .
G: it 'd be great , too , if , , we can we might need some help again getting the tighter boundaries or some hand to experiment with , , to have ground truth for this segmentation work , which you have some already that was really helpful , and we could probably use more .
E: mmm , . that was thing planned working on , is , , to use the transcriptions which are done by now , and to use them as ,
G: with the tighter boundaries . .
E: and to use them for training or for fo whatever . . to to create some speech - nonspeech labels out of them , and , but that 's thing was what 'm just looking into .
A: the the pre - segmentations are so much are so extremely helpful . now there was , , so , couple weeks ago needed some new ones and it happened to be during the time that he was on vacation for just very few days you were away . but it happened to be during that time needed one , so so started them on the non - pre - segmented and then switched them over to yours and , , they , , they always appreciate that when they have that available . and he 's , , usually , , , . so they really appreciate it . but was gonna say that they do adjust it once in while . once in while there 's something like , and actually you talked to them . did you ? have you ?
E: talked to helen .
A: and and she was and so , asked her they 're very perceptive . really want to have this meeting of the transcribers . haven't done it yet , but wanna do that and she 's out of town , , for couple of weeks , but wanna do that when she returns . cuz she was saying , , in in span of very short period we asked it seems like the ones that need to be adjusted are these these things , and she was saying the short utterances , , the , , you 're you 're aware of this . but but actually it 's so correct for so much of the time , that it 's an enormous time saver and it just gets tweaked little around the boundaries .
G: that 's great .
A: . it 'd be interesting to combine these .
G: is there actually record of where they change ? you can compare , do diff on the just so that we knew
A: you could do it . it 's it 's complicated in that , hhh , hhh ,
E: actually , when they create new , new segments , it will be , , not that easy but . one could do that .
G: if we keep old copy of the old time marks just so that if we run it we know whether we 're which ones were cheating
E: that would be great , , to know that .
A: there is there is one problem with that and that is when they start part way through then what do is merge what they 've done with the pre - segmented version .
G: which one would be good .
A: so it 's not pure it 's not pure condition . wha - what you 'd really like is that they started with pre - segmented and were pre - segmented all the way through . and , @ @ , the it wasn't possible for about four of the recent ones . but , it will be possible in the future because we 're , .
G: mmm , that 's great . as long as we have record , , of the original automatic one , we can always find out how we would do fr from the recognition side by using those boundaries . completely non - cheating version . also if you need someone to record this meeting , , 'm happy to for the transcribers could do it , or chuck or adam .
F: so , , you were saying something about organizing the meeting info ?
D: so , , , jane and adam and had meeting where we talked about the reorganization of the directory structure for all of the meeting
F: did you record it ?
D: for all the meeting recorder data . we should have . and so we 've got plan for what we 're gonna do there . and then , jane also prepared , started getting all of the meetings organized , so she prepared spreadsheet , which spent the last couple of days adding to . so went through all of the data that we have collected so far , and have been putting it into , , spreadsheet with start time , the date , the old meeting name , the new meeting name , the number of speakers , the duration of the meeting , comments , , what its transcription status is , all that . and so , the idea is that we can take this and then export it as html and put it on the meeting recorder web page so we can keep people updated about what 's going on . 've gotta get some more information from jane cuz have some gaps here that need to get her to fill in , but so far , , as of monday , the fourteenth , , we 've had total number of meeting sixty - two hours of meetings that we have collected . some other interesting things , average number of speakers per meeting is six . and 'm gonna have on here the total amount that 's been transcribed so far , but 've got bunch of that 's what have to talk to jane about , figuring out exactly which ones have been completed and . but , , this 'll be thing that we can put up on the web site and people can be informed of the status of various different ones . and it 'll also list , , like under the status , if it 's at ibm or if it 's at icsi , , or if it 's completed or which ones we 're excluding and there 's place for comments , so we can , , say why we 're excluding things and .
F: now would the ones that , , are already transcribed we we have enough there that we 've already done some studies and shouldn't we go through and do the business - es of having the , , , participants approve it , , for approve the transcriptions for distribution and ?
A: in principle , would say yes , although still am doing some the final - pass editing , trying to convert it over to the master file as the being the channelized version and it 's , it seems like get into that certain way and then something else intervenes and have to stop . cleaning up the things like the , , places where the transcriber was uncertain , and doing spot - checking here and there . so , , , it would make sense to until th that 's done ,
F: le let me put in another milestone as did with the , the pipeline . we are gonna have this darpa meeting in the middle of july , and it it 'd be given that we 've been we 've given couple public talks about it already , spaced by months and months , it 'd be pretty bad if we continued to say none of this is available .
A: it 'll certainly be done by then . .
F: right . so we can we wanna be able to say "" here is subset that is available right now ""
A: that 's right .
F: and that 's has been through the legal issues and .
A: that 's right . that 's right . so that
F: so , by before july .
C: and they don't have to approve , , th an edited version , they can just give their approval to whatever version
F: in principle , yes . but , , if if somebody actually did get into some legal issue with it then we
C: but th , the editing will continue . presumably if errors are found , they will be fixed , but they won't change the content of the meetings .
D: content , really .
A: see , this is the this is the issue . subtleties .
G: if jane is clarifying question , then , , how can they agree to it before they know her final version ?
A: the other thing , too , is there can be subtleties where person uses this word instead of that word , which @ @ could 've been transcribed in the other way . and no and they wouldn't have been slanderous if it had been this other word .
F: it , there is point at which agree it becomes ridiculous because , , you could do this final thing and then year from now somebody could say , , that should be period and not question mark . and you don't you there 's no way that we 're gonna go back and ask everybody "" do you approve this , , this document now ? "" so what it is that the the thing that they sign haven't looked at it in while , but it has to be open enough that it says "" , from now on , now that 've read this , you can use do anything you want with these data . "" and , but , we wanna so , assuming that it 's in that wording , which don't remember , , we just wanna have enough confidence ourselves that it 's so close to the final form it 's gonna be in , year from now that they 're
A: mmm . agree . it 's just , , question of , , if the person is using the transcript as the way of them judging what they said and whether it was slanderous , then it seems like it 's it needs to be more correct than if we could count on them re - listening to the meeting . because it becomes , , in way , legal document if they 've to that .
F: forget how we end right . forget how we ended up on this , but remember my taking the position of not making it so easy for everybody to observe everything and adam was taking the position of having it be really straightforward for people to check every aspect of it including the audio . and don't remember who won , adam or me ,
A: if it 's only the transcript , though , th this is my point , that
F: that 's why 'm bringing this up again , because 't remember how we ended up . that it was the transcrip he wanted to do web interface that would make it
A: if it 's just the audio
F: that would give you access to the transcript and the audio . that 's what adam wanted . and don't remember how we ended up .
G: with the web interface it 's interesting , because you could allow the person who signs to be informed when their transcript changes , and , , would say "" no "" . like , don't wanna know , but some people might be really interested and then in other words , they would be informed if there was some significant change other than typos and things like that .
F: you decided you were whispering satanic incantations under your breath when you were
G: what happened to the small heads thing , but , 'm just saying that , like , , you can say that any things that are deemed
F: they disappeared from view .
G: anyway . , agree that at some point people probably won't care about typos but they would care about significant meaning changes and then they could be asked for their consent , , if those change . cuz assumi assuming we don't really distribute things that have any significant changes from what they sign anyway .
C: how about having them approve the audio and not the transcripts ?
A: that would be simpler , if we could count on them listening .
G: but no one will listen to the hours and hours of
C: we just have to give them chance to listen to it , and if they don't , that 's their problem .
A: unfortunately , , in the sign thing that they signed , it says "" transcripts "" .
C: no , 'm serious .
A: "" you 'll be you 'll be provided the transcripts when they 're available . ""
G: that 's lot to ask for people that have been in lot of meetings .
F: anyway , haven't we 've gone down this path number of times . know this can lead to extended conversations and not really get anywhere , so let me just suggest that , off - line that , , the people involved figure it out and take care of it before it 's july . so so that in july we can tell people "" yes , we have this and you can use it "" .
A: it 's done , ready , available .
F: so , let 's see . what else we got ? don did report about his project in class and , an oral and written version . so that was he was doing with you .
G: it 's one thing we 're learning is that the amount we have eight meetings there because we couldn't use the non - native all non - native meetings and it 's , , probably below threshold on enough data for us for the things we 're looking at because the prosodic features are very noisy and so you need lot of data in order to model them . so we 're starting to see some patterns and we 're hoping that maybe with , , double or triple the data with twenty meetings or so , that we would start to get better results . but we did find that some of the features that , gue jane would know about , that are expressing the distance of , , boundaries from peaks in the utterance and some local , , range pitch range effects , like how close people are to their floor , are showing up in these classifiers , which are also being given some word features that are cheating , cuz they 're true words . so these are based on forced alignment . word features like , , word frequency and whether or not something 's backchannel and . so , we 're starting to see , , some interesting patterns .
F: so the dominant features , including everything , were those quasi - cheating things .
G: it depends what you 're looking at , actually .
B: sometimes positions in sentences , or in spurts , was helpful . if that 's cheating , too .
C: spurts wouldn't be .
G: spurts is not cheating except that the real words , but roughly speaking , the recognized words are gonna give you similar type of position .
B: right . would they give you the same number of words , though ?
G: it 's either early or late . not exactly , but
B: but ra somewhat ?
F: on the average .
G: it should be . and actually that 's one of the things we 're interested in doing , is
C: have you tried using just time , as opposed to number of words ?
B: just time position , like when the word starts ? if that was in the
C: no , time position relative to the beginning of the spurt .
B: there 's all these things to do .
G: we didn't try it ,
B: like , there 's lot of different features you could just pull out .
C: that wouldn't be cheating because you can detect pause pretty within the time .
F: how about time position normalized by speak
G: and it depends on speaking rate speaking rate . . that 's actually why didn't use it at first . but we one of the interesting things was you reported on some te punctuation type finding sentence boundaries , finding disfluency boundaries , and then had done some work on finding from the foreground speech whether or not someone was likely to interrupt , so where , if 'm talking now and someone and andreas is about to interrupt me , is he gonna choose certain place in my speech , either prosodically or word - based . and there the prosodic features actually showed up even though the word features were available . and neat thing there too is tried some putting the speaker so , gave everybody short version of their name . so the real names are in there , which we couldn't use . we should use ds . and those don't show up . so that means that overall , , it wasn't just modeling morgan , or it wasn't just modeling single person , but was trying to , , get general idea the model the tree classifier was trying to find general locations that were applicable to different speakers , even though there are huge speaker effects . the but the main limitation now is because we 're only looking at things that happen every ten words or every twenty words , we need more data and more data per speaker . it 'd also be interesting to look at the edu meetings because we did include meeting type as feature , whether you were in meeting recorder meeting or robustness meeting did matter to interrupts because there are just fewer interrupts in the robustness meetings . and so the classifier learns more about morgan than it does about the average person , which is not bad . it 'd probably do better than , but it wasn't generalizing . and don , , we have long list of things he 's starting to look at now over the summer , and he 'll be able to report on more things in the future . but it was great that we could at least go from the , jane 's transcripts and the , , recognizer output and get it to this point . and it 's something mar probably use in her preliminary report like , "" , we 're at the point where we 're training these classifiers and we 're just reporting very preliminary but suggestive results that some features , both word and pro prosodic , work . "" the other thing that was interesting to me is that the pitch features are better than in switchboard . and that really is from the close - talking mikes , cuz the pitch processing that was done has much cleaner behavior than the switchboard telephone bandwidth .
C: better in what sense ?
G: , first of all , the pitch tracks are have less , , halvings and doublings than switchboard and there 's lot less dropout , so if you ask how many regions where you would normally expect some vowels to be occurring are completely devoid of pitch information , in other words the pitch tracker just didn't get high enough probability of voicing for words for , , five word there are much fewer than in switchboard . so the missing we had big missing data problem in switchboard and , so the features weren't as reliable cuz they were often just not available .
D: could it have to do with the lower frequency cut - off on the switchboard ?
G: so that 's actually good . ma - maybe . , the tele we had telephone bandwidth for switchboard and we had the an annoying telephone handset movement problem that may also affect it . so we 're just getting better signals in this data . anyway , don 's been doing great job and we hope to continue with , , andreas 's help and also some of thilo 's help on this , to try to get non - cheating version of how all this would work .
F: has has , ? we just , just talked about this the other day , but has anybody had chance to try changing , , insertion penalty things with the with the , , using the tandem system input for the ?
C: . tried that . it didn't , , help dramatically .
D: were they out of balance ? didn't didn't notice .
C: the relative number of there were higher number of deletions , actually . so , you , so , actually it preferred to have positive er , negative insertion penalty , which means that , but , , it didn't change th the by adjusting that the , the error changed by probably one percent or so . but , , given that word error rate is so high , that 's not
F: so that 's so that 's not the problem .
C: that 's not the problem . but , , we just , , chuck and talked and the @ @ next thing to do is probably to tune the , the size of the gaussian system , , @ @ to this to this feature vector , which we haven't done . we just used the same configuration as we used for the for the standard system . and , , , dan @ @ dan just sent me message saying that cmu used , , something like ten gaussians per cluster each mixture has ten gaussians
D: we 're using sixty - four ,
C: and we 're using sixty - four , so that 's big difference and it might be way off and give very poorly trained , , , gaussians that way , an and poorly trained mixture weights . so so , we have the turn - around time on the training when we train only the male system with , , , our small training set , is less than twenty - four hours , so we can run lots of , just brute force , try whole bunch of different , settings . and , , with the new machines it 'll be even better .
F: we get twelve of those ,
C: but the plp features work , , , continue to improve the , as said before , the using dan 's , , vocal tract normalization option works very . so , , @ @ ran one experiment where we 're just did the vocal tract le normalization only in the test data , so didn't bother to retrain the models , and it improved by one percent , which is about what we get with , with , , just @ @ actually doing both training and test normalization , , with , , the , , with the standard system . so , in few hours we 'll have the numbers for the for retraining everything with vocal tract length normalization and so , that might even improve it further . so , it looks like the - fea features do very now with after having figured out all these little tricks to get it to work .
G: so you mean you improve one percent over system that doesn't have any in it already ?
F: so then we 'll have our baseline to compare the currently hideous , , new thing with .
C: right . and and what that suggests also is that the current switchboard mlp isn't trained on very good features . because it was trained on whatever , , was used , , last time you did hub - five , which didn't have any of the
F: right . but all of these effects were like couple percent .
C: but if you add them all up you have , , almost five percent difference now .
F: add all of them . one was one point five percent and one was point eight .
C: and now we have another percent with the
F: that 's three point three .
C: actually , and it 's , what 's actually qu interesting is that with , you prob maybe another half percent if you do the vtl in training , and then interestingly , if you optimize you get more of win out of rescoring the , , , the best lists , and optimizing the weights ,
D: than you do with the standard ?
F: but the part that 's actually adjustment of the front - end per se as opposed to doing putting vtln in is it was couple percent . right ? it was it was there was there was one thing that was one and half percent and one that was point eight . let me see if remember what they were . one of them was , , the change to , because it did it all at once , to , from bark scale to mel scale , which really feel like saying in quotes , because @ @ they 're essentially the same scale but the but any individual particular implementation of those things puts things in particular place .
G: why did that cha ?
F: so that 's why wanted to look still haven't looked at it yet . wanna look at exactly where the filters were in the two , and it 's probably something like there 's one fewer or one more filter in the sub one kilohertz band and for whatever reason with this particular experiment it was better one way or the other . it could be there 's something more fundamental but it , it yet . and the other and the other that was like one and half , and then there was point eight percent , what was the other thing ?
D: that was combined with the triangular .
F: those those two were together . we weren't able to separate them out cuz it was just done in one thing . but then there was point eight percent which was something else .
D: the low - frequency cut - off .
F: do you remember the ? . so that was that was , that one claim credit for , , in terms of screwing it up in the first place . so that someone until someone else fixed it , which is that , , never put we had some problems before with offsets . this inf this went back to , , wall street journal . so we had , ea everybody else who was doing wall street journal knew that there were big dc offsets in th in these data in those data and and nobody happened to mention it to us , and we were getting these , like , really terrible results , like two , three times the error everybody else was getting . and then in casual conversation someone ment mentioned "" , , , , you 're taking care of the offsets . "" said "" what offsets ? "" and at that point , , we were pretty new to the data and we 'd never really , like , looked at it on screen and then when we just put it on the screen and wroop ! there 's this big dc offset . so , , in plp
G: there was like or some or when they recorded it ?
F: no . it 's just , it 's it 's not uncommon for recorded electronics to have different , , dc offsets . it 's it 's , , no big deal . it 's , you could have ten , twenty , maybe thirty millivolts , whatever , and it 's consistently in there . most people 's front - ends have pre - emphasis with it , with zero at zero frequency , so that it 's irrelevant . but with , we didn't actually have that . we had we had the equivalent of pre - emphasis in , , fletcher - munson style weighting that occurs in the middle of but it doesn't actually have zero at zero frequency , like , , , typical simple fr pre - emphasis does . we had something more fancy . it was later on it didn't have that . so at that point reali "" sh we better have have high - pass filter "" just , just take care of the problem . so put in high - pass filter at , , ninety hertz or so , for sixteen kilohertz sampling rate . and never put anything in to adjust it for different sampling rates . and so , so , , the code doesn't know anything about that and so this is all at eight kilohertz and so it was at forty - five hertz instead of at instead of at ninety . if dan fixed it or , , what he
C: he made it parameter .
F: he made it parameter . so . , if he did it right , he did fix it and then and then it 's taking care of sampling rate , which is great .
D: what what is the parameter ? is it , , just the lower cut - off that you want ?
C: it 's called , , - hpf .
F: does hpf on his feat feature .
C: and but hpf , , when you put number after it , uses that as the hertz value of the cut - off .
F: frankly , we never did that with the rasta filter either , so the rasta filter is actually doing different thing in the modulation spectral domain depending on what sampling rate you 're doing , which is another old bug of mine . so that was the problem there was th we we had always intended to cut off below hundred hertz and it just wasn't doing it , so now it is . so , that hep that helped us by , like , eight tenths of percent . it still wasn't big deal .
C: but , , , again , after completing the current experiments , we 'll we can add up all the differences
F: but but , my point was that , , the hybrid system thing that we did was , , primitive in many ways . and agree with you that if we fixed lots of different things and they would all add up , we would probably have competitive system . but not that much of it is due to the front - end per se . maybe couple percent of it is , as far as see from this . unless you call , if you call vtl the front - en front - end , that 's , , little more . but that 's more both , .
D: one experiment we should we 'll probably need to do though when , at some point , is , since we 're using that same the net that was trained on plp without all these things in it , for the tandem system , we may wanna go back and retrain ,
C: that 's what , . .
D: for the tandem . , so we can see if it what effect it has on the tandem processing .
C: so so , do we expect ? at this point 'm as , 'm wondering is it can we expect , , tandem system to do better than properly trained , gaussian system trained directly on the features with , , the right ch choice of parameters ?
F: that 's what we 're seeing in other areas . yes . so , it 's so ,
D: so , we but but we may not . , if it doesn't perform as , we may not know why . cuz we need to do the exact experiment .
F: the reason to should is because you 're putting in the same information and you 're transforming it to be more discriminative . now , in some databases wouldn't expect it to necessarily give you much and part of what view as the real power of it is that it gives you transformational capability for taking all sorts of different wild things that we do , not just th the standard front - end , but other things , like with multiple streams and , and allows you to feed them to the other system with this through this funnel . so that 's the real power of it . wouldn't expect huge in huge improvements . but it should at least be roughly the same and maybe little better . if it 's , , like way worse then ,
D: so , morgan , an another thing that andreas and were talking about was , so @ @ in the first experiment that he did we just took the whole fifty - six , , outputs and that 's , , compared to thirty - nine input feature vector from either mfcc or plp . but one thing we could do is
F: let let me just ask you something . when you say take the fifty - six outputs , these are the pre final nonlinearity outputs
D: through the regular tandem outputs .
F: and they 're and through the klt .
D: through the klt . all that kinda .
F: and so then you do you use all fifty - six of the klt
D: that 's what we did . so one thing we were wondering is , if we did principal components and , say , took out just thirteen , and then did deltas and double - deltas on that so we treated the th first thirteen as though they were standard features . did dan do experiments like that to ?
F: talk with stephane . he did some things like that . it was either him or carmen . these were all different databases and different , in htk and all that , so it may not apply . but my recollection of it was that it didn't make it better but it didn't make it worse . but , again , given all these differences , maybe it 's more important in your case that you not take lot of these low - variance , , components .
D: cuz in sense , the net 's already got quite bit of context in those features , so if we did deltas and double - deltas on top of those , we 're getting even more .
F: which could be good or not .
C: but there the main point is that , , , it took us while but we have the procedure for coupling the two systems debugged now and , there 's still conceivably some bug somewhere in the way we 're feeding the tandem features either generating them or feeding them to this to the sri system ,
F: there might be , cuz that 's pretty big difference .
C: and 'm wondering how we can how we can debug that . 'm actually quite that the feeding the features into the system and training it up , that that 's this that 's essentially the same as we use with the ce with the fe features . and that 's working great .
D: there could be bug in the somewhere before that .
C: the another degree of freedom is how do you generate the transform ?
F: and another one is the normalization of the inputs to the net . these nets are trained with particular normalization and when that gets screwed up it can really hurt it .
D: 'm doing what eric eric coached me through then that part of it , so 'm pretty confident in that . the only slight difference is that use normalization values that , , andreas calculated from the original plp , which is right . we actually don't do that normalization for the plp , for the st just the straight plp features ?
C: no . the the sri system does it .
D: system does that . right .
C: so , there 's there is room for bugs that we might not have discovered ,
D: so that 's that 's another
F: would actually double check with stephane at this point , cuz he 's probably the one here he and dan are the ones who are at this point most experienced with the tandem thing and there may there may be some little bit here and there that is not being handled right .
D: it 's hard with features , cuz you what they should look like . you can't just , like , print the values out in ascii and , , look at them , see if they 're
F: not unless you had lot of time
G: and also they 're not , as understand it , you don't have way to optimize the features for the final word error . these are just discriminative , but they 're not , , optimized for the final
C: they 're optimized for phone discrimination ,
G: right . so it there 's always this question of whether you might do better with those features if there was way to train it for the word error metric that you 're actually that you 're actually
F: that 's right . you actually are . but but it but in an indirect way .
G: right . it 's indirect , so you
F: so wha what an and you may not be in this case , come to think of it , because , , you 're just taking something that 's trained up elsewhere . so , what you what you do in the full procedure is you , , , have an embedded training . so you the net is trained on , , , , viterbi alignment of the training data that comes from your full system . and so that 's where the feedback comes all around , so that it is actually discriminant . you can prove that it 's it 's , if you believe in the viterbi assumption that , , getting the best path , , is almost equivalent to getting the best , , total probability , , then you actually do improve that by , by training up on local , local frames . but , , we aren't actually doing that here , because we did we did that for hybrid system , and now we 're plugging it into another system and so it isn't it wouldn't quite apply here .
D: so another huge experiment we could do would be to take the tandem features , , do sri forced alignments using those features , and then re - do the net with those .
G: mmm , exactly . exactly . so that you can optimize it for the word error .
F: another thing is since you 're not using the net for recognition per se but just for this transformation , it 's probably bigger than it needs to be . so that would save lot of time .
C: and there 's mismatch in the phone sets . so , you 're using long larger phone set than what
F: actually all those things could could , could affect it as . the other thing , , just to mention that stephane this was an innovation of stephane 's , which was pretty neat one , and might particularly apply here , given all these things we 're mentioning . stephane 's idea was that , , discriminant , , approaches are great . even the local ones , given , , these potential outer loops which , , you can convince yourself turn into the global ones . however , there 's times when it is not good . when something about the test set is different enough from the training set that , , the discrimination that you 're learning is is not good one . so , , his idea was to take as the input feature vector to the , , gaussian mixture system , , concatenation of the neural net outputs and the regular features .
C: we already talked about that .
G: didn't you did you do that already
C: no , but we when first started corresponding with dan about how to go about this , that was one of the things that we definitely went there .
G: that makes lot of sense .
F: , 'm that stephane wasn't the first to think of it , but actually stephane did it
C: - . and does it help ?
F: and and it helped lot . so that 's that 's our current best system in the , , in the aurora thing .
G: that makes sense .
C: and do you do klt transform on the con on the combined feature vector ?
G: as you should never do worse .
F: , missed what you said .
C: do you you do klt transform on the combined feature vector ?
F: actually , , you should check with him , because he tried several different combinations .
C: because you end up with this huge feature vector , so that might be problem , unless you do some form of dimensionality reduction .
F: what don't remember is which came out best . so he did one where he put put the whole thing into one klt , and another one , since the plp things are already orthogonalized , he left them alone and just did klt on the on the net outputs and then concatenated that . and don't remember which was better .
D: did he did he try to ? so he always ended up with feature vector that was twice as long as either one of the ?
F: no . , . you have to check with him .
C: actually , have to run .
F: 'm into big ideas these days .
G: we need to close up cuz need to save the data and , , get call .
F: not to mention the fact that we 're missing snacks .
G: did people wanna do the digits or , , do them together ?
F: given that we 're in hurry for snacks , maybe we should do them together .
G: should we just ? are we trying to do them {nonvocalsound} in synchrony ? that might be fun .
F: it 's it 's it 's not , it 's not gonna work out
G: adam 's not here , so he 's not here to tell me no .
F: but we could we could just , , see if we find rhythm , 's or zeroes , we wanna agree on that ?
G: maybe just whatever people would naturally do ?
F: but if we were singing group , we would wanna decide .
A: mine 's identical to yours . is that correct ?
G: and we didn't have enough digit forms
F: so these are excellent .
G: so xeroxed the same one seven times .
F: why don't we do zer anyone have problem with saying zero ? one and two and three . once more with feeling . no , just just kidding . . it was .
","The Berkley Meeting Recorder project is well underway , and this meeting discusses the progress and ongoing issues.
A pressing concern for the group is the DARPA meeting in July , which is only a short time away , and for which they would like to have some progress.
Specifically , the group would like to have transcripts available , which would mean resolving legal issues for data use and on the basis of feedback from IBM get more transcription underway.
Additionally they would also like to have the question answering mock-up and transcriber interface ready for then.
PLP results for the front-end look good , with the group also reporting progress in segmentation: Thilo's segmenter will now be used and ways of improving performance investigated;
The classifier segmentation is progressing well , especially in the use of prosody for identifying interruption.
Work on the front end continues , with improvements of 3-5% being made.
The group discussed how the digits should be recorded in the meeting.
In the end they decided to record these in unison for all of the meeting participants as a whole.
To improve the performance of Thilo's automatic segmenter , this is going to be retrained and adapted to run with Thilo's posteriors and speaker background models.
Regarding transcription , no new transcribers will be employed until situation regarding IBM is clarified.
Legal issues surrounding the approval and signing off of transcripts by participants has proved to be very complicated , and so will be sorted out off line by those involved by July.
After finding discrepancies with the CMU researchers , the ICSI group have decided to tune the size of their Gaussian system.
After raising the difficulty of checking for bugs in their generation of tandem features , they decide to check with Stephane who has more experience of these procedures.
For the DARPA meeting in July , the group propose that they should have the question answering mock-up and transcriber interface ready for then , and also have data available.
Unfortunately , there are legal issues regarding the approval of transcripts.
Additionally , the group would like to have their data transcriptions in ""production mode"" by then.
However the group do not want to hire more transcribers until IBM confirms in the next 2-3 weeks the acceptability of the data.
Segmentation for the recogniser has been done by hand which the group consider ""cheating"" , instead now they want to use Thilo's automatic segmenter.
The classifier segmentation work is going well , but needs more data to improve results since non-native speaker data cannot be used.
For the front-end , so far the group have been using a high number of Gaussians per cluster ( 64 ) rather than the ten per cluster used by researchers at CMU , therefore they need to tune their Gaussian system to the feature vector.
The group  observed that it would be difficult to check for bugs in the generation of tandem features for the SRI system.
Experimentation is taking place using different front-ends with the SRI recogniser.
This is not yet complete , but PLP results are improving to match those of MFCC , with vocal tract length normalisation working ""beautifully"" on a training set of 24 hours , and giving overall improvement of between 3 and 5%.
Thilo's automatic segmenter is now working , and although it has low precision , this is mediated by the high recall.
The group will send IBM another sample file to check that the beep problems are fixed , and this should take 2-3 weeks.
Progress on transcriptions has been made on 5 ""set one"" meetings , and two more transcribers set on.
Pre-segmentation has proved useful.
Meeting Recorder data of the 62 hours of meetings already analysed has been organised into a spreadsheet with the aim to make this available over the WWW.
Classifier segmentation is expected to give better results from more data: currently ""cheating"" using word features for forced alignment , but looking to use other data such as ""spurts"".
Prosodaic features looking promising for identifying interruptions.
Generally the ICSI data offers better pitch features and vowel voicing than the Switchboard corpus due to the use of close talking mikes rather than telephone handsets.
"
ami_abstractive_summary,Buw001.txt,"G: headphones that aren't so uncomfortable .
B: this should be off the record ,
A: we 're not recording yet , are we ?
F: no , , that wasn't recorded .
G: don't think they 're designed to be over your ears .
B: it just it really hurts . it gives you headache ,
G: but definitely haven't figured it out .
A: meeting recorder meeting .
F: have to stop doing this sigh of contentment , , after sipping cappuccino .
B: with the we kno know .
G: "" sip , sigh . ""
B: we know exactly how much you have left in your cup .
F: was just noticing big
D: so are we recording now ? ! we 're we 're live . so , , what were we gonna talk about again ? so we said we said data collection , which we 're doing .
B: were we gonna do digits ?
A: do we do th do you go around the room and do names or anything ?
E: it 's good idea .
G: usually we 've done that and also we 've done digits as , but forgot to print any out . besides with this big group ,
B: you can write them on the board , if you want .
D: no . it 'd be even better with this big
G: it would take too much time . but it takes too much time .
D: it 's not that long .
E: your your thing {nonvocalsound} may be pointing in funny direction . it 's it helps if it points upwards . so that thing the little th that part should be pointing upwards . that 's it .
H: otherwise you just get heartbeats .
D: , the element , should be as close to you your mouth as possible .
E: that 's good . that thing is good .
A: how 's that working ?
E: it 's working .
D: so what we had was that we were gonna talk about data collection , and , , , you put up there data format , and other tasks during data collection ,
A: so , the goal the goal was what can we do how can you do the data collection differently to get what can you add to it to get , , some information that would be helpful for the user - interface design ?
G: especially for querying .
A: especially for querying . so , getting people to do queries afterwards , getting people to do summaries afterwards .
H: one thing that came up in the morning in the morning was the , , mister lan - doctor landry ?
G: landay . james .
H: la - landay ? so he has , , these , , , tsk note - taking things , then that would be summary which you wouldn't have to solicit . if we were able to do that .
A: if you actually take notes as summary as opposed to take notes in the sense of taking advantage of the time - stamps . so action item or , reminder to send this to so - and - so , blah - blah . so that wouldn't be summary . that would just be that would relate to the query side .
G: but if we had the crosspads , we could ask people , , if something comes up write it down and mark it somehow ,
E: right . , we because you 'd have several people with these pads , you could collect different things . cuz tend to take notes which are summaries .
F: the down - side to that is that he indicated that the , , quality of the handwriting recognition was quite poor .
G: but that 's alright . don't think there 'd be so many that you couldn't have someone clean it up
A: we also could come up with some code for things that people want to do so that for frequent things . and the other things , people can write whatever they want . it 's to some extent , , for his benefit . if that , if we just keep it simple then maybe it 's still useful .
D: realized we skipped the part that we were saying we were gonna do at the front where we each said who we were .
H: the roll call .
A: you did that on purpose . but anyway , shall we do the roll call ?
D: no , my mind went elsewhere . , 'm morgan , 'm on channel three .
G: and 'm adam janin on channel .
H: 'm jane edwards , on channel .
E: 'm dan ellis .
F: eric on channel nine .
B: liz , on channel one .
A: mari on channel zero .
C: katrin on channel two .
H: should we have used pseudo - names ? should we do it second time with pseudo no . no .
D: 'm rocky raccoon on channel
E: let me , , turn that off .
G: and , , do you want to do the as and the
E: pzm nearest , next nearest . pdm - right , pda - right , pda - left .
G: and eventually once this room gets little more organized , the jimlets will be mounted under the table , and these guys will be permanently mounted somehow . probably with double - sided tape , you so we won't have to go through that .
H: have question on protocol in these meetings , which is when you say "" jimlet "" and the person listening won't that is , sh shou how how do we get is that important information ? the box that contains the
D: , suppose we broaden out and go to range of meetings besides just these internal ones . there 's gonna be lots of things that any group of people who know each other have in column common that we will not know .
A: so the there will be jargon that we he there 'll be transcription errors .
D: we were originally gonna do this with vlsi design , and and the reason we didn't go straight to that was because immediately ninety percent of what we heard would be jargon to us .
G: that was just one of the reasons . but , , definitely .
D: that that 's right . there were others .
H: so we were on the data collection and the summary issue .
D: we can go back .
A: so , actually there 's three issues . there 's the crosspad issue . should we do it and , if so , what 'll we have them do ? do we have people write summaries ? everybody or one person ? and then , do we ask people for how they would query things ?
F: there 's there 're sub - problems in that , in that where or when do you actually ask them about that ? that was one thing was thinking about was is that dan said earlier that , , maybe two weeks later , which is when you would want to query these things , you might ask them then . but there 's problem with that in that if you 're not if you don't have an interactive system , it 's gonna be hard to go beyond the first level of question . and furth id explore the data further .
D: there 's there 's another problem which is , , we certainly do want to branch out beyond , , recording meetings about meeting recorder . and , , once we get out beyond our little group , the people 's motivation factor , , reduces enormously . and if we start giving them bunch of other things to do , how , we did another meeting here for another group and , , they were fine with it . but if we 'd said , "" , now all eight of you have to have to come up with , , the summar ""
G: and none of them did .
D: there we go .
G: so , asked them to send me ideas for queries after the meeting and no one ever did . didn't follow up either . so didn't track them down and say "" do th do it now "" . but , , no one spontaneously provided anything .
D: 'm worried that if you did even if you did push them into it , it it might be semi - random , as opposed to what you 'd really want to you were gonna use this thing .
G: how else to generate the queries other than getting an expert to actually listen to the meeting and say "" that 's important , that might be query "" .
H: there is this other thing which which you were alluding to earlier , which is , , there are certain key words like , , "" action item "" and things like that , which could be used in , , to some degree finding the structure . and and also , , was thinking , with reference to the , note - taking , the advantage there is that you get structure without the person having to do something artificial later . and the fir third thing wanted to say is the summaries afterwards , they should be recorded instead of written because that , , it would take so long for people to write that you wouldn't get as good summary .
A: how about this idea ? that normally at most meetings somebody is delegated to be note - taker . and so why don't we just use the notes that somebody takes ?
G: that gives you summary but it doesn't really how do you generate queries from that ?
E: but , , maybe summary is one of the things we 'd want from the output of the system . they 're something . it 's output you 'd like .
G: james and were talking about this during one of the breaks . and the problem with that is , 'm definitely going to do something with information retrieval even if it 's not full - bore what 'm gonna do for my thesis . 'm gonna do something . 'm not gonna do anything with summarization . and so if someone wants to do that , that 's fine , but it 's not gonna be me .
D: that we , the the core thing is that once we get some of these issues nailed down , we need to do bunch of recordings and send them off to ibm and get bunch of transcriptions even if they 're slightly flawed or need some other and then we 'll have some data there . and then , we can start looking and thinking , what do we want to know about these things and at the very least .
B: actually want to say something about the note pad . so , if you could sense just when people are writing , and you tell them not to doodle , or try not to be using that for other purposes , and each person has note pad . they just get it when they come in the room . then you you can just have fff plot of wh , who 's writing when . that 's all you and , you can also have notes of the meeting . but bet that 's that will allow you to go into the the hot places where people are writing things down . you can tell when you 're in meeting when everybody stops to write something down that something was just said . it may not be kept in the later summary , but at that point in time is was something that was important . and that wouldn't take any extra
H: that 's idea .
B: or someone could just pu you could just put your hand on the pad and go like that if you want to .
D: that 's good idea maybe 'm missing something , but that doesn't get to the question of how we come up with queries , right ?
B: then you can go to the points where the you could actually go to those points in time and find out what they were talking about .
A: what it does is provide different it 's an interesting thing . don't gets at the queries per - se , but it does give us an information fusion thing that , , you wanna say "" what were the hot - points of the meeting ? ""
D: that that 's what , is that it gets at something interesting but if we were asking the question , which we were , of of , , "" how do we figure out what 's the nature of the queries that people are gonna want to ask of such system ? "" , knowing what 's important doesn't tell you what people are going to be asking .
B: but bet it 's good superset of it .
E: see , there are th
A: you could say they 're gonna ask about , , when , when did so - and - so talk about blah . and at least that gives you the word that they might run query on .
B: at least you can find the locations where there are maybe keywords
G: this would tell you what the hit is , not what the query is .
B: right , right .
A: it 'll tell you the hit but not the query .
B: but thinking about queries is little bit dangerous right now .
G: and so you could you can generate query from the hits ,
B: if you want to find out what any user will use , that might be true for one domain and one user , but different domain and different user
D: but we 're just looking for place to start with that because , , th what what james is gonna be doing is looking at the user - interface and he 's looking at the query in we we have five hours of pilot data of the other but we have zero hours of of queries . so he 's just going "" where do where do start ? ""
A: th you could do the summaries actually may help get us there , for couple reasons . one , if you have summary if you have bunch of summaries , you can do word frequency count and see what words come up in different types of meetings . so "" action item "" is gonna come up whether it 's vlsi meeting , or speech meeting , or whatever . so words that come up in different types of meetings may be something that you would want to query about . the second thing you could possibly do with it is just run little pilot experiment with somebody saying "" here 's summary of meeting , what questions might you want to ask about it to go back ? ""
G: because then they 're not gonna ask the questions that are in the summary . but , it would give
A: that 's one possi one possible scenario , though , is you have the summary , and you want to ask questions to get more detail .
G: th , it has to be participant . it doesn't have to be . so that is another use of meeting recorder that we haven't really talked about , which is for someone else , as opposed to as remembrance agent , which is what had been my primary thought in the information retrieval part of it would be . if you had meeting participant , they could use the summary to refresh themselves about the meeting and then make up queries . but it 's not how to do it if until you have system .
B: the summary is actually gonna drive the queries then . your research is going to be very circular .
G: that 's what was saying .
E: but th there is this , there is this class of queries , which are the things that you didn't realize were important at the time but some in retrospect you think "" , hang on , didn't we talk about that ? "" and it 's something that didn't appear in the summary but you and that 's what this , , complete data capture is nicest for . cuz it 's the things that you wouldn't have bothered to make an effort to record but they get recorded . so , and th there 's no way of generating those , until we just until they actually occur .
B: but you could always post - hoc label them .
E: right , right . exactly . but , it 's difficult to say "" and if was gonna ask four questions about this , what would they be ? "" those aren't the things that come up .
G: but at least it would get us started .
H: also think that if you can use the summaries as an indication of the important points of the of the meeting , then you might get something like so if th if the obscure item you want to know more about was some form of data collection , maybe the summary would say , , "" we discussed types of na data collection "" . and , and and maybe you could get to it by that . if you if you had the larger structure of the of the discourse , then if you can categorize what it is that you 're looking for with reference to those those larger headings , then you can find it even if you don't have direct route to that .
G: although it seems like that 's , , high burden on the note - taker . that 's pretty fine grain that the note - taker will have to take .
B: maybe landay can put student in to be note - taker .
A: you got to have somebody who knows the pro knows the topic or , whose job it is delegated to be the note - taker . somebody who 's part of the meeting .
B: no , , but someone who can come sit in on the meetings and then takes the notes with them that the real note - taker and that way that one student has , , rough idea of what was going on , and they can use it for their research . this isn't really necessarily what you would do in real system , because that 's lot of trouble and maybe it 's not the best way to do it . but if he has some students that want to study that then they should get to know the people and attend those meetings , and get the notes from the note - taker .
G: that 's little bit of problem . their note - taking application they 've been doing for the last couple of years , and don't think anyone is still working on it . they 're done . so 'm not that they have anyone currently working on notes . so what we 'd have to interest someone in is the combination of note and speech . and so the question is "" is there such person ? "" and right now , the answer is "" no "" . we 'll just have to see .
D: 've been thinking about it little bit here about the , th this , now 'm thinking that the summary summary , , is actually reasonable , , bootstrap into this into what we 'd like to get at . it 's it 's not ideal , but we , we have to get started someplace . so was was just thinking about , , suppose we wanted to get we have this collection of meeting . we have five hours of . we get that transcribed . so now we have five hours of meetings and , , you ask me , , "" morgan , what , what questions do you want to ask ? "" wouldn't have any idea what questions want to ask . 'd have to get started someplace . so if looked at summary of it , 'd go "" , , was in that meeting , what was the part that "" and and th that might then help me to think of things even things that aren't listed in the summary , but just as as refresh of what the general thing was going on in the meeting .
A: it serves two purpo purposes . one , as refresh to help bootstrap queries , but also , , maybe we do want to generate summaries . and then it 's , it 's key .
D: . that 's true too .
G: . then you want to have it .
B: so how does the summary get generated ? 'm not against the idea of summary , but wanted to think carefully about who 's generating it because the summary will drive the queries .
A: what , , in most meetings , this one being different , but in most meetings that attend , there 's somebody explicitly taking notes , frequently on laptop you can just make it be on laptop , so then yo you 're dealing with ascii you don't have to go through handwriting recognition . and then they post - edit it into , , summary and they email it out for minutes . that happens in most meetings .
H: that , , there 's we 're using "" summary "" in two different ways . so what you just described would describe as "" minutes "" . and what originally thought was , , if you asked someone "" what was the meeting about ? "" and then they would say "" , we talked about this and then we talked about that , and so - and - so talked about "" and then you 'd have , like my thought was to have multiple people summarize it , on recording rather than writing because writing takes time and you get irrelevant other things that take time , that whereas if you just say it immediately after the meeting , two - minute summary of what the meeting was about , you would get , see , also worry about having single note - taker because that 's just one person 's perception . it 's releva it 's relative to what you 're focus was on that meeting , and people have different major topics that they 're interested in . so , my proposal would be that it may be worth considering both of those types , , the note - taking and spontaneous oral summary afterwards , no longer than two minutes ,
D: adam , you can
H: from multiple people .
D: you can correct me on this , but , , my impression was that , , , , true that the meetings here , nobody sits with , with laptop
G: never . 've never seen it at icsi . dan is the one who most frequently would take notes ,
E: 've when we when we have other meetings . when have meetings on the european projects , we have someone taking notes .
D: but those are bigger deal things .
E: often do it .
D: where you 've got fifteen peo th this is one of the larger meetings . most of the meetings we have are four or five people
G: that 's true are four or five people .
D: and you 're not you don't have somebody sitting and taking minutes for it . you just get together and talk about where you are .
A: so , it depends on whether it 's business meeting or technical discussion . technical discussions you don't usually have somebody taking notes .
G: the iram meeting , they take notes every there 's person with laptop at each meeting .
E: how many people are those meetings ?
G: there are more . there are ten - ish .
B: you should also have record of what 's on the board .
G: they 're very sparse .
B: find it very hard to reconstruct what 's going on .
G: this is something early in the project we talked lot about .
B: but , , the outline is up here and that 's what people are seeing . and if you have or you shou could tell people not to use the boards . but there 's this missing information otherwise .
E: we sh we should
G: agree , but you just you end up with video , and instrumented rooms . and that 's different project , .
E: for this data capture , it would be to have digital camera just to take pictures of who 's there , where the microphones are , and then we could also put in what 's on the board . like three or four snaps for every
B: people who were never at the meeting will have very hard time understanding it otherwise .
E: for every meeting .
H: that 's wonderful .
G: but don't you think that 's don't you think that but
B: even people who were at the meeting .
E: no . , think , that right now we don't make record of where people are sitting on the tables . and that the at some point that might be awfully useful .
G: but adding photographs adds whole nother level of problems .
H: it 's just digital record .
E: not not as part of the not as part of the data that you have to recover .
B: don't mean that you model it .
E: just just in terms of
B: like archiving it or storing it .
H: yes , agree . it 's because discourse is about things , and then you have the things that are about , and it 's recoverable .
B: someone later might be able to take these and say "" , they , at least these are the people who were there and here 's what they started talking about ,
H: and it 's so simple . like you said , three snapshots just to archive .
D: liz , you sa you sat in on the , , subcommittee meeting or whatever on you on the subcommittee meeting for at the , that workshop we were at that , , mark liberman was having . so wasn't there . they they must have had some discussion about video and the visual aspect , and all that .
B: big , big interest . it personally , don't would never want to deal with it . but 'm just saying first of all there 's whole bunch of fusion issues that darpa 's interested in . fusing gesture and face recognition , even lip movement and things like that , for this task . and there 's also personal interest on the part of mark liberman in this in storing these images in any data we collect so that later we can do other things with it .
D: so so to address what adam 's saying , the key thing there is that this is description of database collection effort that they 're talking about doing . and if the database exists and includes some visual information that doesn't mean that an individual researcher is going to make any use of it .
G: but that it 's gonna be lot of effort on our part to create it , and store it , and get all the standards , and to do anything with it .
D: so we 're gonna so we 're gonna do what we 're gonna do , whatever 's reasonable for us .
B: even doing something very crude like know with atis , we just had tape recorder running all the time . and later on it turned out it was really good that you had tape recorder of what was happening , even though you you just got the speech from the machine . so if you can find some really , , low , , perplexity , way of doing that , it would be worthwhile .
H: and if it 's simple as , as simple as just the digital
B: otherwise you 'd you lose it .
D: minimally , , what dan is referring to at least having some representation of the the spatial position of the people , cuz we are interested in some spatial processing .
G: once the room is little more fixed that 's little easier
B: also cmu has been doing this and they were the most vocal at this meeting , alex waibel 's group . and they have said , talked to the student who had done this , that with two fairly inexpensive cameras they just recorded all the time and were able to get all the information from or maybe it was three from all the parts of the room . so we would be we might lose the chance to use this data for somebody later who wants to do some processing on it if we don't collect it .
G: that if you have that , then people who are interested in vision can use this database . the problem with it is you 'll have more people who don't want to be filmed than who don't want to be recorded . so that there 's going to be another group of people who are gonna say "" won't participate "" .
H: she 's not making
C: that 's true .
B: or you could put paper bag over everybody 's head and not look at each other and not look at boards , and just all be sitting talking . that would be an interes bu
H: there 's that 'd be the parallel , . but she 's we 're just proposing minimal preservation of things on boards ,
B: definitely won't participate if there 's camera .
H: and you could anonymize the faces for that matter .
G: but , , that 's lot of infrastructure and work .
H: we can talk about the
G: to set it up and then anonymize it ?
H: it 's just one snapshot .
B: no , it wa not ,
A: no , no , no .
H: we 're not talking about movie .
B: not for not for cmu .
H: we 're talking about snapshot .
B: they have pretty crude set - up . they just turn on these cameras . they were they were not moving or anything .
G: couldn't find it ?
B: and stored it on analog media . and they didn't actually align it or anything . they just they have it , though .
H: it 's worth considering . maybe we don't want to spend that much more time discussing it ,
F: did they store it digitally , or just put it on videotape ?
B: they just had the videotapes with , counter .
D: for , for our purposes we probably will we might try that some and we certainly already have some recordings that don't have that , which , , we 'll we 'll get other value out of , .
H: if it 's easy to collect it th then it 's wise thing to do because once it 's gone .
B: 'm just the community if ldc collects this data , and - if mark liberman is strong proponent of how they collect it and what they collect , there will probably be some video data in there .
D: there you go .
B: and so that could argue for us not doing it or it could argue for us doing it . the only place where it overlaps is when some of the summarization issues are actually could be , , easier made easier if you had the video .
D: at the moment we should be determining this on the basis of our own , , interests and needs rather than hypothetical ones from community thing . as you say , if they if they decide it 's really critical then they will collect lot more data than we can afford to , and will include all that . 'm not worried about the cost of setting it up . 'm worried about the cost of people looking at it . in other words , it 's it 'd be silly to collect it all and not look at it . and so that we do have to do some picking and choosing of the that we 're doing . but am int do think that we minimally want something we might want to look at some , , subsets of that . like for meeting like this , at least , , take polaroid of the of the of the boards ,
B: of the board . or at least make that the note - taker takes sh , snapshot of the board .
D: and know the position of the people
B: that 'll make it lot easier for meetings that are structured . otherwise later on if nobody wrote this on the board down we 'd have harder time summarizing it or agreeing on summary .
H: especially since this is common knowledge . this is shared knowledge among all the participants , and it 's shame to keep it off the recording .
G: er , if we weren't recording this , this would get lost . right ?
H: don't understand that point .
G: that we 're not saving it anyway . in in our real - life setting .
A: what do you mean we 're not saving it anyway ? 've written all of this down and it 's getting emailed to you .
C: and you 're gonna send it out by email , too .
G: , in that case we don't need to take pictures of it .
B: right . that would be the other alternative , to make that anything that was on the board , , is in the record .
A: that 's why that 's why 'm saying that the note - taking would be in many for many meetings there will be some note - taking , in which case , that 's useful thing to have , we , we don't need to require it . it would be great if we try to get picture with every meeting . so we won't worry about requiring these things , but the more things that we can get it for , the more useful it will be for various applications .
D: so , , departing for the moment from the data collection question but actually talking about , , this group and what we actually want to do , so that 's th the way what you were figuring on doing was was , , putting together some notes and sending them to everybody
H: that 's great .
D: so so the question that we started with was whether there was anything else we should do during th during the collection . and the crosspads was certainly one idea , and we 'll get them from him and we 'll just do that . and then the next thing we talked about was the was the summaries and are we gonna do anything about that .
A: before we leave the crosspads and call it done . so , if 'm collecting data then there is this question of do use crosspads ? so , that if we really have me collect data and 't use crosspads , it 's probably less useful for you guys to go to the trouble of using it , unless you think that the crosspads are gonna 'm not 'm not what they 're gonna do . but but having small percentage of the data with it , 'm not whether that 's useful or not . maybe maybe it 's no big deal . maybe we just do it and see what happens .
D: the point was to try again , to try to collect more information that could be useful later for the ui . so it 's landay supplying it so that landay 's can be easier to do . so it right now he 's operating from zero , and so even if we didn't get it done from uw , it seems like that would could still you shou at least try it .
B: it 'd be useful to have small amount of it just as proof of concept . what you can do with things .
G: and and they seem to not be able to give enough of them away , so we could probably get more as .
B: but not to rely on them for basic modeling .
A: that 's true . so if it if it seems to be really useful to you guys , we could probably get donation to me .
G: it it will again depend on landay , and if he has student who 's interested , and how much infrastructure we 'll need . if it 's easy , we can just do it . but if it requires lot of our time , we probably won't do it .
D: lot of the we 're doing now really is pilot in one sense or another .
G: , we have to figure out what we 're gonna do .
D: and so we try it out and see how it works .
B: wouldn't base any of the modeling on having those .
G: right . ag agree with that . though , the importance marking is good idea , though . that if people have something in front of them
B: that shouldn't be hard for
G: do it on pilots or laptops . if something 's important everyone clap .
A: so crosspads , we 're just gonna try it and see what happens .
G: , that 's right .
A: the note - taking so , that this is gonna be useful . so if we record data will definitely ask for it . so , we should just say this is not we don't want to put any extra burden on people , but if they happen to generate minutes , could they send it to us ?
G: . that 's fine . what was gonna say is that don't want to ask people to do something they wouldn't normally do in meeting . it 's ver want to keep away from the artificiality . if they exist . and then jane 's idea of summarization afterward is not bad one . picking out to let you pick out keywords , and , , construct queries .
D: so who does this summarization ?
G: people in the meeting . just at the end of the meeting , before you go ,
B: without hearing each other though , probably .
G: go around the table .
F: or even just have one or two people stay behind .
E: people with radio mikes can go into separate rooms and continue recording without hearing each other . that 's the thing .
B: then you should try them few weeks later they have all these memory experiments about how little you actually retain
G: and see score them ?
E: that 's right . that 's the interesting thing , though . if we do if we collect four different summaries , , we 're gonna get all this weird data about how people perceive things differently . it 's like this is not what we meant to research .
B: right , right .
H: that could be very interesting .
A: but but again , like the crosspads , don't would base lot of on it ,
G: how you would do it , though .
A: because know when see the clock coming near the end of the meeting , 'm like inching towards the door . you 're probably not gonna get lot of people wanting to do this .
G: maybe is email easier ? when you first said do it , , spoken , what was thinking is , then people have to come up and you have to hook them up to the recorder . so , if they 're already here that 's good , but if they 're not already here for 'd rather do email . 'm much faster typing than anything else .
H: 'd just try , however the least intrusive and quickest way is , and th and closest to the meeting time too , cuz people will start to forget it as soon as they leave .
A: that doing it orally at the end of the meeting is the best time . because they 're captive audience . once they leave ,
G: read the digits , do the summary .
A: but , , don't think that they 'll necessarily you 'll get many people willing to stay . but , , if you get even one
D: it 's like the note - taking thing , that that you can't certainly can't require it or people aren't gonna want to do this . but but if there 's some cases where they will , then it would be helpful .
H: and 'm also wondering , couldn't that be included in the data sample so that you could increase the num , the words that are , , recognized by particular individual ? if you could include the person 's meeting and also the person 's summary , maybe that would be , an ad addition to their database . under the same acoustic circumstance , cuz if they just walk next door with their set - up , nothing 's changed ,
F: so have question about queries ,
G: god , that 's bugging me .
F: which is , ,
G: can we turn that light off ? if can we turn that just that let
D: the fl the fluorescent light is flickering .
H: let the record show the light is flickering .
B: it is it is like .
F: there you go .
A: for little while it was just that was really tired .
C: that 's better .
A: that and too much caffeine and really tired ,
G: too much caffeine .
A: but then "" no , maybe that 's real "" .
G: it was the projector for moment . it was like , "" what 's going on ? ""
F: the question had about queries was , , so what we 're planning to do is have people look at the summaries and then generate queries ? are are we gonna try and
G: we we 've just been talking , how do we generate queries ? and so that was one suggestion .
F: so , the question had is have we given any thought to how we would generate queries automatically given summary ? that 's whole research topic un unto itself , so that it may not be feasible thing .
B: shouldn't landay and his group be in charge of figuring out how to do this ? this is an issue that goes little bit beyond where we are right now . they 're the expert
E: someone wants to know when you 're getting picked up . is someone picking you up ?
A: what 's our schedule ?
D: you still wanted to talk with liz .
A: let 's see , you and need dis , no , we did the liz talk .
D: and you and need to . you already did the liz talk .
A: so so that was the prosody thing .
B: we - don't remember it .
A: we need to finish the it 's already four - fifteen .
B: have like no recall memory .
A: we need to finish this discussion , and you and need little time for wrap - up and quad chart .
D: 'm at your disposal . so , up to you .
A: what 's the plan for this discussion ?
D: we should be able to wind up in another half - hour ,
G: at least . . even if that much ?
B: it 's interesting that he 's got , like , this discussion free
D: , we still haven't talked about the action items from here and so on .
B: yet it 's separate .
A: why don't you say five - thirty ?
E: five - thirty .
A: we 'll probably hit horrible traffic . that 's not lot of time ,
E: that 's that .
G: in answer to "" is it landay 's problem ? "" , he doesn't have student who 's interested right now in doing anything . so he has very little manpower . there 's very little allocated for him and also he 's pretty focused on user interface . so don't think he wants to do information retrieval , query generation , that .
D: there 's gonna be these student projects that can do some things but it can't be , , very deep . actually think that , , again , just as bootstrap , if we do have something like summaries , then having the people who are involved in the meetings themselves , who are cooperative and willing to do yet more , come up with with queries , , could at least give landay an idea of the things that people might want to know . if he doesn't know anything about the area , and the people are talking about and ,
B: but the people will just look at the summaries or the minutes and re and back - generate the queries . that 's what 'm worried about . so you might as just give him the summaries .
F: 'm not 'm not that 's solved problem . of how to how to generate queries from
B: how to do this from the summary .
F: that was what my question was aimed towards .
B: so what you want to to do is , people who were there , who later see , , minutes and put in summary form , which is not gonna be at the same time as the meeting . there 's no way that can happen . are we gonna later go over it and , like , make up some to which these notes would be an answer ,
G: or or just memory refresher .
B: but that 's done off they have to do that off - line .
H: 'm also wondering if we could ask the people question which would be "" what was the most interesting thing you got out of this meeting ? "" becau - in terms of like informativeness ,
B: that 's good one .
H: it might be , , that the summary would not in even include what the person thought was the most interesting fact .
D: would think that would be the most likely thing .
B: dan doesn't sex he is .
A: but actually would say that 's better thing to ask than have them summarize the meeting .
H: you get two different types of information .
A: that 's true .
H: because you get , like , the general structure of important points and what the what the meeting was about .
G: we 're still here .
H: so you get the general structure , the important points of what the meeting was about with the summary . but with the "" what 's the most interesting thing you learned ? "" so the fact that , , know that transcriber uses snack is something that was interesting
B: going to see the kids .
E: you you can keep it on .
H: and that and that dan worked on that . so that was really so , , you could ge pick up some of the micro items that wouldn't even occur as major headings but could be very informative .
A: that 's actually really good idea .
H: it wouldn't be too , , cost - intensive either . , it 's like something someone can do pretty easily on the spur of the moment .
C: are you thinking about just asking one participant or all of them ?
G: as many are willing to do it .
C: make it voluntary thing ,
E: cuz you 'll get cuz you 'll get very different answers from everybody , right ?
C: that 's why was wondering .
G: maybe one thing we could do is for the meetings we 've already done we didn't take minutes and we don't have summaries . but , , people could , like , listen to them little bit and generate some queries . jane doesn't need to . 'm you have that meeting memorized by now .
A: but actually it would be an easy thing to just go around the room and say what was the most interesting thing you learned , for those pe people willing to stay .
H: and that it would pick up the micro - structure , the some of the little things that would be hidden .
A: and and that might be something people are willing to stay for .
D: boy , how we get at this
H: that would be interesting .
C: but when you go around the room you might just get the effect that somebody says something
G: or want to get up and leave .
C: and then you go around the room and they say "" , me too , agree . ""
G: me too , me too .
A: that 's fine .
E: on the other hand people might try and come up with different ones , right ? they might say "" , was gonna say that one but now have to think of something else "" .
G: you have the other thing , that they know why we 're doing it . we 'll , we 'll we 'll be telling them that the reason we 're trying to do this is to generate queries in the future , so try to pick things that other people didn't say .
D: it 's gonna take some thought . it seemed the , , interest that had in this thing initially was , , that the form that you 're doing something else later , and you want to pick up something from this meeting related to the something else . so it 's really the imp the list of what 's important 's in the something else and it might be something minor of minor importance to the meeting . if it was really major , if it 's the thing that really stuck in your head , then you might not need to go back and and check on it even . so it 's it 's that you 're trying to find you 're you 've now say said "" , wasn't that much interested in dialogue , 'm more of an acoustics person "" . but but thr three months from now if for some reason get really interested in dialogue , and 'm "" what is what was that part that that , , mari was saying ? ""
G: like jim bass says "" add few lines on dialogue in your next perf ""
D: and then 'm trying to fi , that 's that 's when look in general when look things up most , is when it 's something that didn't really stick in my head the first time around and but for some new reason 'm 'm interested in in the old .
G: but that 's gonna be very hard to generate .
A: that 's hard to generate
D: so , don't .
A: and that 's half of what would use it for . but also lot of times , make , think to myself "" this is interesting , 've gotta come back and follow up on it "" . so , things that are interesting , , would be , , wanting to do query about . and also , like the idea of going around the room , because if somebody else thought something was interesting , 'd want to know about it and then 'd want to follow up on it .
D: that that might get at some of what was was concerned about , , being interested in something later that , didn't consider to be important the first time , which for me is actually the dominant thing , because if it was really important it tends to stick more than if didn't , but some new task comes along that makes me want to look up .
G: but what 's interesting to me may not have been interesting to you .
D: so having multiple people might get at some of that .
G: by so by going around you can't get of it , we just need to start somewhere .
D: and this is starting point .
F: the question the question then is how much bias do we introduce by , introduce by saying , , this was important now and , , maybe tha something else is important later ? does it does the bias matter ? , that 's , , question for you guys .
H: and one thing , we 're saying "" important "" and we 're saying "" interesting "" . and and those can be two different things .
F: but that 's the question , really , is that , does building queries based on what 's important now introduce an irreversible bias on being able to do what morgan wants to do later ? that 's that 's
D: what keep coming back to in my own mind is that , , the soonest we can do it , we need to get up some system so that people who 've been involved in the meeting can go back later , even if it 's poor system in some ways , and , and ask the questions that they actually want to know . if , if , as soon as we can get that going at any level , then we 'll have much better handle on what questions people want to ask than in any anything we do before that . but we have to bootstrap somehow ,
H: will say that chose "" interesting "" because it includes also "" important "" in some cases . but , , feel like the summary gets at different type of information .
F: "" important "" can often be uninteresting .
E: and "" interesting "" is more interesting than "" important "" .
H: it puts lot of burden on the person to evaluate . inter "" interesting "" is non - threatening in
A: in the interest of , , generati generating an interesting summary , no , in the interest of generating some minutes here , and also moving on to action items and other things , let me just go through the things that wrote down as being important , that we at least decided on . crosspads we were going to try , if landay can get the , get them to you guys , and see if they 're interesting . and if they are , then we 'll try to get do it more . getting electronic summary from note - taking person if they happen to do it anyway . getting just , , digital pictures couple digital pictures of the table and boards to set the context of the meeting . and then going around the room at the end to just say qu ask people to mention something interesting that they learned . so rather than say the most interesting thing , something interesting , and that way you 'll get more variety .
G: wouldn't even say that "" that they learned "" .
H: that 's good .
G: you might want to mention something that you brought up .
A: "" thing that was discussed . "" and then the last thing would be for those people who are willing to stay afterwards and give an oral summary . does that cover everything we talked about ? that , that we want to do ?
H: and one and one qualification on the oral summaries . they 'd be they 'd be separate . they wouldn't be hearing each other 's summaries .
G: that 's gonna predominantly end up being whoever takes down the equipment then .
H: and and that would also be that the data would be included in the database .
G: that would be , let 's see , me .
E: there is still this hope that people might actually think of real queries they really want to ask at some point . and that if that ever should happen , then we should try and write them down .
G: give them reward ,
E: if they 're real queries .
D: , if we can figure out way to jimmy very rough system , say in year , then , so that in the second and third years we actually have something to
A: play with and generate real queries from .
B: wanted to say one thing about queries . the level of the query could be , , very low - level or very high - level . and it gets fuzzier and fuzzier as you go up , right ? so you need to have some if you start working with queries , some way of identifying what the if this is something that requires one - word answer or it 's one place in the recording versus was there general agreement on this issue of all the people who ha you can gen you can ask queries that are meaningful for people . they 're very meaningful cuz they 're very high - level . but they won't exist anywhere in the
G: so we 're gonna have to start with keywords and if someone becomes more interested we could work our way up .
D: 'm not so agree with that .
B: it but it may
D: because , because it depends on , , what our goal is . if our goal is wizard of oz - ish , we might want to is it that people would really like to know about this data .
G: that 's true .
D: and if it 's if it 's something that we how to do yet , th great , that 's , , research project for year four .
G: was thinking about wizard of oz , but it requires the wizard to know all about the meetings .
E: we 'd have to listen to all the data .
D: not maybe not true wizard of oz because people are too aware of what 's going on .
E: get people to ask questions that they def the machine definitely can't answer at the moment ,
D: just "" what would you like to know ? ""
G: but that neither could anyone else , though , is what , , my point is .
H: was wondering if there might be one more source of queries which is indicator phrases like "" action item "" , which could be obtained from the text from the transcript .
G: right . since we have the transcript . that 's something always forget .
H: that 's something to be determined , something to be specified ,
B: probably if you have to sit there at the end of meeting and say one thing you remember , it 's probably whatever action item was assigned to you .
H: but text - oriented .
B: in gen that 's all remember from most meetings .
G: that that 's all wrote down .
H: you 'd remember that , .
B: so , in general , , that could be something you could say , right ? 'm supposed to do this .
H: that 's true . but then you could you could prompt them to say , , "" other than your action item "" , but but the action item would be way to get , , maybe an additional query .
B: that 's realistically what people might be remembering .
H: but , but you could get again @ @
A: we 're piloting . we 'll just do it and see what happens .
D: usually don't remember my action items .
A: - . speaking of action items , can we move on to action items ?
G: can you hand me my note pad ?
A: or maybe we should until the summary of this until this meeting is transcribed and then we will hav
D: we we had ,
E: then we 'll know .
D: somewhere up there we had milestones , but did did you get enough milestone , , from the description things ?
A: , why don't you hand me those transparencies so that remember to take them .
D: and , , there 's detail behind each of those , as much as is needed . so , you just have to let us know .
A: what have down for action items is we 're supposed to find out about our human subject , , requirements . people are supposed to send me for their for web pages , to and 'll put together an overall cover .
E: we need to look at our web page
A: and and you also need to look at your web page
E: and make one that 's
A: and clean it up by mid - july .
E: pda - free .
A: let 's see . choo - choo . you need to put together mailing list .
D: three of them .
A: need to email adam or jane , about getting the data . who should email ?
G: how quickly do you want it ? my july is really very crowded .
A: right now all want personally only want text data . the only thing jeff would do anything with right now but 'm just speaking fr based on conversation with him two weeks ago had in turkey . but all he would want is the digits . but 'll just speak for myself . 'm interested in getting the language model data . so 'm just interested in getting transcriptions . so then just email you ?
H: you could email to both of us , , just , if you wanted to . don't think either of us would mind recei
G: that 's right .
H: but in any case 'd be happy to send you the
A: and your email is ?
G: dot berkeley dot edu , .
D: in in our phone call , , before , we , it turns out the way we 're gonna send the data is by , , and then what they 're gonna do is take the cd - rom and transfer it to analog tape and give it to transcription service , , that will
G: is this ibm ? so do they how are they gonna do the multi - channel ?
D: see , that 's good question .
H: they they don't have way .
D: no , , it 'll be
H: but they have verification .
D: probably about like you did , and then there will be some things , many things that don't work out . and that 'll go back to ibm and they 'll they 'll , they run their aligner on it and it kicks out things that don't work , which , the overlaps will certainly be examples of that . what we will give them all of it . right ?
G: that 's , , my question .
D: we 'll give them all the multi - channel
G: so we 'll give them all sixteen channels and they 'll do whatever they want with it .
B: but you also should probably give them the mixed , equal sound - level they 're not gonna easily be able to do that , probably .
G: it 's not hard .
D: it 's also won't be adding much to the data to give them the mixed .
F: right . it doesn't it isn't difficult for us to do , so we might as just do it .
B: you should that may be all that they want to send off to their transcribers .
A: related to the conversation with picheny , need to email him , , my shipping address and you need to email them something which you already did .
H: emailed them the transcriber url , the on - line , , data that adam set up , so they can click on an utterance and hear it . and emailed them the str streamlined conventions which you got copy of today .
D: right . and was gonna email them the which haven't yet , pointer to the web pages that we that we currently have , cuz in particular they want to see the one with the way the recording room is set up and so on , your page on that .
H: excellent . good . - cc ' ed morgan . should have sent should have cc ' ed you as .
G: not an immediate action item but something we do have to worry about is data formats for higher - level information . or or not even higher level , different level , prosody and all that . we 're gonna have to figure out how we 're gonna annotate that .
A: we never had our data format discussion .
H: we discussed , , musi musical score notation
G: but that 's not that 's display . that 's different than format .
A: my my feeling right now on format is you guys have been doing all the work and whatever you want , we 're happy to live with . other people may not agree with that , but cuz 'm not actually touching the data , so shouldn't be the one to talk .
C: no , that 's fine .
D: so key thing will be that you we tell you what it is .
F: "" here 's mysterious file
D: we also had the , that we were , that you were gonna get us the eight - hundred number and we 're all gonna we 're gonna call up your communicator thing and we 're gonna be good slash bad , depending on how you define it , , users .
C: now , something that mentioned earlier to mari and liz is that it 's probably important to get as many non - technical and non - speech people as possible in order to get some realistic users . so if you could ask other people to call and use our system , that 'd be good . cuz we don't want people who already know how to deal with dialogue systems ,
A: or , like if you have
C: you shouldn't hyper - articulate , , and things like that .
A: or , like if you have somebody who makes your plane reservations for you ,
D: we can do that .
G: get my parents to do it .
A: it could result in some good bloopers , which is always good for presentations .
G: my father would last through the second prompt before he hang hung up .
D: my mother would have very interesting conversation with it
G: he would never use it .
D: but it wouldn't have anything to do with the travel .
A: let 's see , other action items .
D: we talked about that we 're getting the recording equipment running at uw . and so it depends , they 're , they 're if that comes together within the next month , there at least will be , , major communications between dan and uw folks
A: 'm 'm shooting to try to get it done get it put together by the beginning of august .
E: we should talk about it ,
D: but we have it 's pretty he , he said that it was sitting in some room collecting dust and so we ,
A: it 's probably unlikely that we 'll pull this off , but at least it 's worth trying .
G: what is it ?
D: "" recording equipment . ""
G: it 's tape recorder .
D: we 's eight channels . we 's digital .
G: it 's eight tape recorders .
D: we don't even there 're microphones . we 'll find out .
A: and will email these notes 'm not what to do about action items for the data , although , then somebody somebody needs to tell landay that you want the pads .
D: 'll do that . and he also said something about outside there that came up about the outside text sources , that he may have some text sources that are close enough to the thing that we can play with them for language model .
E: that was , that was what he was saying was this he this thing that , , jason had been working on finds web pages that are thematically related to what you 're talking about . that 's the idea . so that that would be source of text which is supposedly got the right vocabulary . but it 's very different material . it 's not spoken material , ,
D: but it 's it might be
A: but but that 's actually what wanna do . that 's that 's what wanna work with , is things that the wrong material but the right da the right source .
G: un - unfortunately landay told me that jason is not gonna be working on that anymore . he 's switching to other again .
A: he seemed when asked him if he could actually supply data , he seemed little bit more reluctant . so , 'll 'll send him email . 'll put it in an action item that send him email about it . and if get something , great . if don't get something
G: landay or jason ?
A: and , , , otherwise , if you guys have any papers could could use , could use your web pages . that 's what we could do . you 've got all the web pages on the meeting recor
D: why search for them ? they 're we know where they are . that 's true .
G: but that 's not very much .
A: one less action item . use what web pages there are out there on meeting recorders .
G: what his software does is it picks out keywords and does google - like search .
D: so we can we can do better than that .
E: we can do that . .
D: there 's there 's some , , carnegie mellon , right ? on on meeting recording ,
A: so , there 's there 's icsi , xerox ,
B: and there 's you should look under , like , intelligent environments ,
G: the "" georgia tech classroom two thousand "" is good one .
B: right . and then that 's where you would want to eventually be able to have board or camera , because of all these classroom
G: georgia tech did very elaborate instrumented room . and want to try to stay away from that .
A: great . that solves that problem . one less action item . that 's good enou that 's that 's all think of .
H: can ask , , one thing ? it relates to data collection and and 'd and we mentioned earlier today , this question of know that from with the near - field mikes some of the problems that come with overlapping speech , , are lessened . but wonder if , is that sufficient or should we consider maybe getting some data gathered in such way that , , we would , have meeting with less overlap than would otherwise be the case ? so either by rules of participation , or whatever . now , , , it 's true , we were discussing this earlier , that depending on the task so if you 've got someone giving report you 're not gonna have as much overlap . so we 're gonna have , non - overlapping samples anyway . but , , in meeting which would otherwise be highly overlapping , is the near - field mike enough or should we have some rules of participation for some of our samples to lessen the overlap ?
A: don't think we should have rules of participation , but we should try to get variety of meetings . that 's something that if we get the meeting going at uw , that probably can do more than you guys , cuz you guys are probably mostly going to get icsi people here . but we can get anybody in ee , , over and possibly also some cs people , , over at uw . so , that there 's good chance we could get more variety .
H: just want to be there 's enough data to
B: they 're still gonna overlap , but mark and others have said that there 's quite lot of found data from the discourse community that has this characteristic and also the political anything that was televised for third party has the characteristic of not very much overlap .
D: wasn - but we were saying before also that the natural language group here had less overlap . so it also depends on the style of the group of people .
B: like the , , dominance relations of the people in the meeting .
H: on the task , and the task . because , it is true people can modify the amount of overlap that they do if they 're asked to . not not entirely modify it , but lessen it if it 's desired . but if that 's sufficient data wanted to be that we will not be having lot of data which can't be processed .
A: so 'm just writing here , we 're not gonna try to specify rules of interaction but we 're gonna try to get more variety by using different groups of people and different sizes .
H: fine . and , know that the near near - field mikes will take care of also the problems to to certain degree .
A: and then the other thing might be , , , technical versus administrative .
H: wanted to be .
A: cuz if recorded some administrative meetings then that may have less overlap , because you might have more overlap when you 're doing something technical and disagreeing or whatever .
H: so know that in in legal depositions people are pr are prevented from overlapping . they 'll just say , , "" till each person is finished before you say something "" . so it is possible to lessen if we wanted to . but but these other factors are fine . wanted to raise the issue .
A: the reason why didn't want to is be why personally didn't want to is because wanted it to be as , , unintrusive as possi as you could be with these things hanging on you .
H: that 's always desired . want to be we don't that we 're able to process , , , as much data as we can .
D: did they discuss any of that in the meeting they had with liberman ?
B: and there was big division ,
D: what what do they
B: so liberman and others were interested in lot of found data . so there 's lots of recordings that they 're not close - talk mike , and and there 's lots of television , , on , , political debates and things like that , congre congressional hearings . boring like that . and then the cmu folks and were on the other side in cuz they had collected lot of meetings that were like this and said that those are nothing like these meetings . so there 're really two different kinds of data . and , we just left it as @ @ that if there 's found data that can be transformed for use in speech recognition easily , then we would do it , but newly collected data would be natural meetings .
D: actually , th @ @ the cmu folk have collected lot of data . is that is that going to be publicly available ,
B: as far as know , they have not .
G: it 's also it 's not near - far , right ?
B: if people were interested they could talk to them , but got the feeling there was some politics involved .
G: @ @ gonna add that to one of my action items .
D: just to check . we should 's out there certainly .
G: cuz had thought they 'd only done far - field ,
B: you need to talk to waibel
G: intelligent - room sorts of things .
E: it 's those guys .
G: hadn't known that then they 'd done any more than that .
D: they only did the far - field ?
B: but they had multiple mikes and they did do recognition , and they did do real conversations . but as far as know they didn't offer that data to the community at this meeting . but that could change cuz mark , mark 's really into this . we should keep in touch with him .
D: once we send out we still haven't sent out the first note saying "" hey , this list exists "" . but but , , once we do that
A: is that an action item ?
D: it 's on already added that one on my board to do that . hopefully everybody here is on that list . we should at least check that everybody here ?
G: everyone here is on the list .
D: we haven't sent anything to the list yet . we 're just compiling the list .
G: added few people who didn't who knew had to be on it even though they didn't tell me .
E: who specifically ask not to be .
G: like jane , . you are on it , aren't you ?
H: so , , just for clarification . so "" found data "" , they mean like established corpora of linguistics and other fields , right ?
B: what they mean is they don't have to fund to collect ,
H: it sounds like such
B: , "" found "" has , , also the meaning that 's it very natural . it 's things occur without any the pe these people weren't wearing close - talking mikes , but they were recorded anyway , like the congressional hearings and , , for legal purposes or whatever .
H: but it includes like standard corpora that have been used for years in linguistics and other fields .
B: mark 's aware of those , too .
E: "" hey , look what we found ! ""
B: that would be found data because they found it and it exists .
E: "" found this great corpora . ""
B: they didn't have to collect it . it 's not "" found "" in the sense that at the time it was collected for the purpose .
G: "" psst . want to buy corpora ? ""
B: but what he means is that , mark was really fan of getting as much data as possible from , reams and reams of , of broadcast ,
H: that 's interesting .
B: but he understands that 's very different than these this type of meeting .
G: it 's not the same .
B: but , so what ? it 's still it 's interesting for other reasons .
H: just wanted to know .
D: so , seems like we 're winding down .
B: you can tell by the prosody .
E: so we should go around and we should go around and say something interesting that happened at the meeting ?
A: yes , we should do that .
G: now , was already thinking about it ,
D: ! good man .
B: this is painful task .
G: really liked the idea of what was interesting was the combination of the crosspad and the speech . especially , , the interaction of them rather than just note - taking . so , can you determine the interesting points by who 's writing ? can you do special gestures and so on that have , , special meaning to the corpora ? really liked that .
H: realized there 's another category of interesting things which is that , , found this discussion very , , this question of how you get at queries really interesting . and and the and and the fact that it 's , , nebulous , what that what query it would be because it depends on what your purpose is . so actually found that whole process of trying to think of what that would involve to be interesting . but that 's not really specific fact . thought we went around discussion of the factors involved there , which was worthwhile .
E: had real revelation about taking pictures . didn't do this before and regret it . so that was very interesting for me .
G: did you take pictures of the boards ?
E: the boards aren't really related to this meeting . will take pictures of them ,
H: that 's good point .
A: they 're related to this morning 's meeting .
G: to the pre previous meeting . that 's right .
E: that 's why 'll take pictures of them , then .
F: of the jane took my answer . so 'm gonna pass for the moment but come back to me .
E: for the moment .
A: "" pass "" is socially acceptable . but will say , will actually spin on different slightly different spin on what you said , this issue of , , realizing that we could take minutes , and that actually may be goal . so that may be the test in sense , test data , the template of what we want to test against , generating summary . so that 's an interesting new twist on what we can do with this data .
C: agree with jane and eric . the question of how to generate queries automatically was the most interesting question that came up , and it 's something that , as you said , is whole research topic in itself , so don't think we 'll be able to do anything on it because we don't have funding on it , , in this project . but , , it 's definitely something would want to do something on .
G: wonder if work 's already been done on it .
H: like expert systems and ,
D: being more management lately than research , the thing that impressed me most was the people dynamics and not any of the facts . that is , really enjoyed hanging out with this group of people today . so that 's what really impressed me .
E: how are we gonna find that in the data ?
G: if we had people wearing the wireless mikes all the time
F: , one thing you could search for is were people laughing lot .
E: how happy were they ?
D: 'd probably search like that .
G: that actually has come up couple times in queries . was talking to landay and that was one of his examples . when when did people laugh ?
E: that 's great .
D: find me funny thing that jeff said .
G: so we need laugh detector . cuz that seems to be pretty common . not in the congressional hearings .
D: so we 're done .
G: we 're done .
H: do we need do need to turn something off here , or do unplug this , or ?
D: now these we turn off .
","The discussion concerned mainly ideas about data collection and the nature and generation of queries on meetings.
Meeting notes taken by participants as standard minutes or summaries , or on devices like CrossPads can provide useful information.
There is also interest in the speech community for fusion of speech with visual data.
Taking some photos of the whiteboard and the positioning of participants is easy enough to do.
Another option would be the recording by participants of short oral summaries of the meeting.
Summaries could be used to bootstrap for queries , the exact nature of which remained nebulous.
Candidate types are keyword searches , action items , elaboration on points of interest , and agreement between participants.
An initial prototype system to test any hypotheses can be pipelined.
The recorded data will be stored on CD-ROM's and sent to IBM for transcription.
There is also work being done on the annotation of prosody.
The corpus could be enriched with found data ( public or collected by other projects ) , if those prove appropriate for use in the project.
Finally , project web pages and mailing list are being set up and UW are going to investigate the suitability of their recording equipment.
Within the piloting of data collection ideas , it was decided that CrossPads are going to be used for detection of ""hot points"" during the meeting.
Other ideas to be tested are the use of summaries or minutes -if a group normally produce them- and the recording of oral summaries by individual participants after the meeting.
Photographing the contents of the board and the positions of the meeting participants will provide extra information.
For query generation purposes , all participants will also be asked for their highlight of the meeting.
The general goal regarding the corpus is to investigate the acquisition of further appropriate data through public sources or available collections of other institutions.
As to recordings at ICSI , the group agreed that imposing rules of participation  in order to avoid speaker overlaps was not desirable.
Instead , they will aim for collecting stylistically varied data ( different group dynamics and types of meeting ).
Further action will also be taken to close other pending issues: the web pages will be organised , the recording room will be finalised and UW will also test their recording infrastructure.
The recording of meetings and any possible additional tasks must be set up in a user-friendly way , otherwise it would be difficult to recruit volunteers.
Asking participants to do more than they normally would in a meeting could put people off.
The video-recording of meetings , apart from adding an extra level of instrumentation complexity , can also make people apprehensive.
The usability and usefulness of CrossPads is not certain.
Acquiring data from other sources will not be straightforward , as they may either not be suitable for this project or not publicly available.
Querying is also a major issue: what users would ask from a system is not clear.
How this system would resolve high-level queries ( eg regarding agreement between participants ) is also hard to tell at this stage.
As transcription has not started yet , there was concern as to how IBM will deal with multi-channel data.
The abundance of speaker overlaps may also affect the quality of the trascription.
However , it was accepted that some problems with the transcription of jargon are , to an extent , unavoidable.
Five hours of recorded pilot data are already available.
IBM , who will be carrying out the transcribing , have been emailed the URL's for the online data set-up and for the transcribing tool.
Some work has already been done with the annotation of speech features like prosody.
"
ami_abstractive_summary,Bmr024.txt,"F: so we 're on .
H: that 's better .
F: and , somewhere is my agenda . the most important thing is morgan wanted to talk about , , the arpa demo .
D: so , here 's the thing . why don't we again start off with , 'll get it . 'll get the door . we want to start off with the agenda . and then , given that , , liz and andreas are gonna be ten , fifteen minutes late , we can try to figure out what we can do most effectively without them here . so so , one thing is , , talk about demo ,
F: ibm transcription status ,
D: what 's smartkom ?
F: we wanna talk about if if we wanna add the data to the mar meeting recorder corpus .
E: the data which we are collecting here .
D: what what are we collecting here ?
F: so why don't we have that on the agenda and we 'll we 'll get to it and talk about it ?
E: the smartkom data ?
A: files and directories ?
D: files and directories .
F: absinthe , which is the multiprocessor unix linux . it was andreas wanted to talk about segmentation and recognition , and update on sri recognition experiments . and then if ti if there 's time wanted to talk about digits , but it looked like we were pretty full , so till next week .
D: let 's see . the certainly the segmentation and recognition we wanna maybe focus on when an - andreas is here since that was particularly his thing .
E: and also the smartkom thing should
D: smartkom also , andreas . absinthe , also he has been involved in lot of those things .
F: he 'll he 'll probably be interested .
D: so , , they 'll be inter 'll be interested in all this , but , , probably , if we had to pick something that we would talk on for ten minutes or so while they 're coming here . or it would be , you think , reorganization status ,
F: , chuck was the one who added out the agenda item . don't really have anything to say other than that we still haven't done it .
B: maybe said maybe we said this before just that we met and we talked about it and we have plan for getting things organized
A: and and crucial part of that is the idea of not wanting to do it until right before the next level zero back - up so that there won't be huge number of added ,
B: that that was it . not not much @ @
F: although dave said that if we wanna do it , just tell him and he 'll do level zero then .
B: so maybe we should just go ahead and get everything ready ,
F: so , we do need to talk little bit about we don't need to do it during this meeting . we have little more to discuss . but , , we 're we 're ready to do it . and , , have some web pages on ts more of the background . so , naming conventions and things like that , that 've been trying to keep actually up to date . and 've been sharing them with - uw folks also .
A: 'm , you 've been what ?
F: sharing them with the uw folks .
D: maybe , since that was pretty short one , maybe we should talk about the ibm transcription status . someone can fill in liz and andreas later .
F: so , we , we did another version of the beeps , where we separated each beeps with spoken digit . chuck came up here and recorded some di himself speaking some digits , and so it just goes "" beep one beep "" and then the phrase , and then "" beep two beep "" and then the phrase . and that seems pretty good . they 'll have easier time keeping track of where they are in the file .
E: and we have done that on the automatic segmentations .
F: and we did it with the automatic segmentation , and don't think we ne we didn't look at it in detail . we just sent it to ibm . we we sorta spot - checked it .
B: listened to probably , , five or ten minutes of it from the beginning .
F: sorta spot - checked here and there and it sounded pretty good . so . it 'll work . and , , we 'll just hafta see what we get back from them .
B: and the main thing will be if we can align what they give us with what we sent them . that 's the crucial part . and we 'll be able to do that at with this new beep format .
F: it 's also they are much less likely to have errors . so the problem wi last time is that there were errors in the transcripts where they put beeps where there weren't any , or and they put in extraneous beeps . and with the numbers there , it 's much less likely .
B: one interesting note is , or problem if this was just because of how play it back , say , , snd - play and then the file , every once in while , @ @ , like beep sounds like it 's cut into two beeps .
E: into two pieces .
B: and if that 's an , , artifact of playback bu , don't 's probably in the original file .
E: recognize that , too .
F: that 's interesting . didn't hear that .
B: but with this new format , , that hopefully they 're not hearing that , and if they are , it shouldn't throw them .
F: maybe we better listen to it again , but , , certainly the software shouldn't do that ,
B: that 's what . it 's probably just , , mmm , somehow the audio device gets hung for second ,
A: as long as they have one number , and they know that there 's only one beep maximum that goes with that number .
F: the only the only part that might be confusing is when chuck is reading digits .
A: , actually , are we having them
F: "" seven four eight beep seven beep eight three two "" .
A: but are we having them do digits ?
F: because , , we don't we didn't in order to cut them out we 'd have to listen to it .
B: we we didn't cut those out .
E: they are not transcribed yet .
F: and we wanted to avoid doing that , so we they are transcribing the digits .
B: we can we can ignore it when we get it back ,
F: although we could tell them we could tell them , if you hear someone reading digits string just say "" bracket digit bracket "" and don't bother actually computing the di writing down the digits .
A: that 'd be great . that 'd be what 'm having the transcribers here do , cuz it can be extracted later .
F: and then wanted to talk about but as said we may not have time what we should do about digits . we have whole pile of digits that haven't been transcribed .
D: le - let 's talk about it , because that 's that 's something that know andreas is less interested in than liz is ,
F: do we have anything else to say about transcription ?
B: brian sent bresset sent brian message about the meeting and haven't heard back yet . so . hope he got it and hopefully he 's maybe he 's gone , he didn't even reply to my message . so . should probably ping him just to make that he got it .
F: so , we have whole bunch of digits , if we wanna move on to digits .
D: actually , maybe one one relate more related thing in transcription . so that 's the ibm . we 've got that sorted out . how 're we doing on the on the rest of it ?
A: we 're doing . hire 've hired two extra people already , expect to hire two more . and , , 've prepared , , , set of five which 'm which 'm calling set two , which are now being edited by my head transcriber , in terms of spelling errors and all that . she 's also checking through and mar and monitoring , , the transcription of another transcriber . , she 's going through and doing these kinds of checks . and , 've moved on now to what 'm calling set three . if do it in sets groups of five , then have , like , parallel processing through the current . and and you indicated to me that we have goal now , for the for the , , {nonvocalsound} the , , darpa demo , of twenty hours . so , 'm gonna go up to twenty hours , be that everything gets processed , and released , and that 's that 's what my goal is . package of twenty hours right now , and then once that 's done , move on to the next .
D: so twenty hours . but the other thing is that , , that 's kinda twenty hours asap because the longer before the demo we actually have the twenty hours , the more time it 'll be for people to actually do things with it .
A: 'm 'm hiring people who , , really are they would like to do it full - time , several of these people . and and don't 's possible , really , to do this full - time , but , that what it shows is motivation to do as many hours as possible .
F: it 'll keep your accuracy up .
A: and they 're really excellent .
D: that 's good .
A: got good core group now .
D: , the so the difference if , , if the ibm works out , the difference in the job would be that they primarily would be checking through things that were already done by someone else ? is that most of what it ?
F: we 'll we 'll expect that they 'll have to move some time bins and do some corrections .
A: and , 've also , discovered so with the new transcriber 'm lemme say that my , at present , , the people have been doing these transcriptions channel at time . and , that , , is useful , and , and then once in while they 'll have to refer to the other channels to clear something up . realize that , , we 're using the pre - segmented version , and , , the pre - segmented version is extremely useful , and wouldn't it be , useful also to have the visual representation of those segments ? and so 've , , , 've trained the new one , the new the newest one , to , , use the visual from the channel that is gonna be transcribed at any given time . and that 's just amazingly helpful . because what happens then , is you scan across the signal and once in while you 'll find blip that didn't show up in the pre - segmentation . and that 'll be something like it 's ver it 's interesting .
F: see what you mean .
A: once in while it 's backchannel . sometimes it seems to be , , similar to the ones that are being picked up . and they 're rare events , but you can really go through meeting very quickly . you just you just , , yo you you scroll from screen to screen , looking for blips . and , that we 're gonna end up with , better coverage of the backchannels , but at the same time we 're benefitting tremendously from the pre - segmentation because there are huge places where there is just no activity . and , , the audio quality is so good
B: so they can they can , , scroll through that pretty quick ? that 's great .
A: so that 's gonna , also , , speed the efficiency of this part of the process .
D: so let 's talk about the digits , since they 're not here yet .
F: so , we have whole bunch of digits that we 've read and we have the forms and so on , but only small number of that ha only subset of that has been transcribed . and so we need to decide what we wanna do . and , , liz and andreas actually they 're not here , but , they did say at one point that they thought they could do pretty good job of just doing forced alignment . and , again , don't think we 'll be able to do with that alone , because , , sometimes people correct themselves and things like that . so , was just wondering what people thought about how automated can we make the process of finding where the people read the digits , doing forced alignment , and doing the timing .
D: forced alignment would be one thing . what about just actually doing recognition ?
F: we they read , because we have the forms .
D: no , they make mistakes .
F: but , that we wanna get set of clean digits .
B: you 're talking about as pre - processing step . right , morgan ? is that what you 're ?
D: 'm 'm not quite what 'm talking about . , we 're talking about digits now . and and so , , there 's bunch of that hasn't been marked yet . and , , there 's the issue that they we was said , but do we ? because people make mistakes and . was just asking , just out of curiosity , if with , , the sri recognizer getting one percent word error , would we would we do better ? so , if you do forced alignment but the force but the but the transcription you have is wrong because they actually made mistakes , , or false starts , it 's it 's much less it 's much less common than one percent ?
F: but that 's pretty uncommon . if we could really get one percent on
D: we should be able to .
F: , if we segmented it , we could get one percent on digits .
D: so that 's just my question . 'm not saying it should be one way or the other , but it 's if
F: there 're couple different of doing it . we could use the tools 've already developed and transcribe it . hire some people , or use the transcribers to do it . we could let ibm transcribe it . they 're doing it anyway , and unless we tell them different , they 're gonna transcribe it . or we could try some automated methods . and my tendency right now is , , if ibm comes back with this meeting and the transcript is good , just let them do it .
D: it 's you raised point , , , euphemistically but , , maybe it is serious problem . ho - what will they do when they go hear "" beep seven beep seven three five two "" you think they 'll we 'll get ?
F: it 's pretty distinct . the beeps are pre - recorded .
B: it 'll only be problem for for mine .
A: it , it 'd be preceded by "" 'm reading transcript so - and - so "" ? so , if they 're processing it at
F: it 'll be it will be in the midst of digit string . there might be place where it 's "" beep seven beep eight beep eight beep "" . but , , they 're they 're gonna macros for inserting the beep marks . and so , don't 'll be problem . we 'll have to see , but don't 's gonna be problem .
D: that 's if they are going to transcribe these things , , certainly any process that we 'd have to correct them , or whatever is needs to be much less elaborate for digits than for other . so , why not ? that was it ?
F: that was it . just , what do we do with digits ? we have so many of them , and it 'd be to actually do something with them .
D: we we wanna have them .
I: you mean there 're more than ten ?
F: your mike is little low there .
D: in berkeley , . so , you you have to go little early ,
I: stay till about , , three forty .
D: so le let 's make we do the ones that , , saved you . so there was some in in adam 's agenda list , he had something from you about segmentation this last recognition ?
I: so this is just partly to inform everybody , , and to get , , input . so , {nonvocalsound} , we had discussion don and liz and had discussion last week about how to proceed with , , , with don 's work , and and , , one of the obvious things that occur to us was that we 're since we now have thilo 's segmenter and it works , , amazingly , , we should actually re - evaluate the recognition , , results using , without cheating on the segmentations . and , that should be fairly
E: and how do we find the transcripts for those so that ? the references for those segments ?
I: so , there 's actually
E: it 's not that
I: why do you ask ? no , actually , , nist has , fairly sophisticated scoring program that you can give , time , you just give two time - marked sequences of words , and it computes the the , , the th
B: it does all the work for you .
I: it does all the work for you . so , it we just and we use that actually in hub - five to do the scoring . so what we 've been using so far was simplified version of the scoring . and we can we can handle the the type of problem we have here .
E: so , you give some time constraints for the references and for the hypothesis ,
I: so , we ha
G: maybe the start of your speech and the end of it , or like that .
I: it does time - constrained word - alignment . so that should be possible . that shouldn't be problem . so that was the one thing , and the other was that , what was the other problem ? that thilo wanted to use the recognizer alignments to train up his , , speech detector . so that we could use , there wouldn't be so much hand labelling needed to , to generate training data for the speech detector .
E: 'm just in progress of doing that .
I: and you 're in the process of doing that . so , you can you can
B: it 'll give you lot more data , too .
E: so , it 's eight meetings which 'm using , and , it 's before it was twenty minutes of one meeting . so should be little bit better .
I: that won't be perfect the alignments aren't perfect , but , , it 's probably still better to have all this extra data , than
E: we 'll see that .
G: actually , had question about that . if you find that you can lower the false alarms that you get where there 's no speech , that would be useful for us to know .
E: there were the false alarms .
G: so , right now you get fal , false , , speech regions when it 's just like , , breath like that , and 'd be interested to know the wha if you retrain do those actually go down or not ?
E: 'll can make an can , like , make comparison of the old system to the to the new one ,
G: just to see if by doing nothing in the modeling of just having that training data wh what happens .
D: another one that we had on adam 's agenda that definitely involved you was something about smartkom ?
F: so , rob porzel and the , porzel and the , , smartkom group are collecting some dialogues . they have one person sitting in here , looking at picture , and wizard sitting in another room somewhere . and , , they 're doing travel task . and , , it involves starting believe starting with it 's it 's always the wizard , but it starts where the wizard is pretending to be computer and it goes through , , speech generation system .
E: actually , it 's changed to synthesis for the first part now .
F: and then , it goes to real wizard and they 're evaluating that . and they wanted to use this equipment , and so the question came up , is here 's some more data . should this be part of the corpus or not ? and my attitude was yes , because there might be people who are using this corpus for acoustics , as opposed to just for language . or also for dialogue of various sorts . so it 's not meeting . because it 's two people and they 're not face to face .
D: so , wanted to understand it , cuz 'm , hadn't quite followed this process . so , it 's wizard in the sen usual sense that the person who is asking the questions doesn't know that it 's , , machi not machine ?
F: at the beginning .
I: actually actually , the we do this who came up with it , but it 's really clever idea . we simulate computer breakdown halfway through the session , and so then after that , the person 's told that they 're now talking to , to human .
E: it 's human operator .
F: but they that it 's the same person both times .
I: so , we collect we collect both human - computer and human - human data , essentially , in the same session .
D: you might wanna try collecting it the other way around sometime , saying that th the computer isn't up yet and then so then you can separate it out whether it 's the beginning or end effects .
I: that 's an idea .
A: that 's good idea .
F: "" have to go now . you can talk to the computer . ""
B: it 's lot more believable , too ,
F: "" no ! ""
B: if you tell them that they 're the computer part is running on windows machine . and the whole breakdown thing kinda makes sense .
I: just just reboot it .
F: abort , retry , fail ?
G: so did they actually save the far - field data ?
F: this was this was the question .
G: cuz at first they weren't they weren't sa
F: so so they were saying they were not going to , and said , "" that 's silly , if we 're gonna try to do it for corpus , there might be people who are interested in acoustics . ""
E: projector we were not saying we are not doing it . we wer we just wanted to do
I: no , the question is do we save one or two far - field channels or all of them ?
F: see no reason not to do all of them . that that if we have someone who is doing acoustic studies , , it 's to have the same for every recording .
D: so , what is the purpose of this recording ? this is to get acoustic and language model training data for smartkom .
I: it 's to be traini to training data and development data for the smartkom system .
E: the english system ?
B: where does this ?
G: maybe we can have him vary the microphones , too , or they 're different speakers .
F: so so for their usage , they don't need anything .
D: so why not ?
E: but but 'm not about the legal aspect of that . is is there some contract with smartkom about the data ? or , is that our data which we are collecting here ,
D: we 've never signed anything that said that we couldn't use anything that we did .
I: we weren't supposed to collect any data .
E: so . , th that was the question .
D: no that 's not problem . look , it seems to me that if we 're doing it anyway and we 're doing it for these purposes that we have , and we have these distant mikes , we definitely should re should save it all as long as we 've got disk space , and disk is pretty cheap . so should we save it ? so we save it because it 's it 's potentially useful . and now , what do we do with it is separate question . anybody who 's training something up could choose to put it , to include this or not . would not say it was part of the meetings corpus . but it 's some other data we have , and if somebody doing experiment wants to train up including that then they can .
F: so it 's it it it the begs the question of what is the meeting corpus . so if , at uw they start recording two - person hallway conversations is that part of the meeting corpus ?
D: it 's th think the idea of two or more people conversing with one another is key .
F: this has two or more people conversing with each other . they 're just not face to face .
G: what if we just give it name like we give these meetings name ?
D: no , it doesn't .
F: that was my intention .
G: and then later on some people will consider it meeting and some people won't ,
F: that was my intention . so so so part of the reason that wanted to bring this up is , do we wanna handle it as special case or do we wanna fold it in ,
G: just give it title .
F: we give everyone who 's involved as their own user id , give it session ds , let all the tools that handle meeting recorder handle it , or do we wanna special case it ? and if we were gonna special case it , who 's gonna do that ?
I: it makes sense to handle it with the same infrastructure , since we don't want to duplicate things unnecessarily . but as far as distributing it , we shouldn't label it as part of this meeting corpus . we should let it be its own corp
A: it 's it , because
F: don't see why not . it 's just different topic .
A: ha have an extra point , which is the naturalness issue . because we have , like , meetings that have reason . that 's one of the reasons that we were talking about this . and and those and this sounds like it 's more of an experimental setup . it 's got different purpose .
D: it 's scenario - based , it 's it 's human - computer interface it 's really pretty different . but have no problem with somebody folding it in for some experiment they 're gonna do , but don't it doesn't match anything that we 've described about meetings . whereas everything that we talked about them doing at uw and really does . they 're actually talking
F: so so what does that mean for how we are gonna organize things ?
D: you can you can again , as andreas was saying , if you wanna use the same tools and the same conventions , there 's no problem with that . it 's just that it 's , , different directory , it 's called something different , it 's it is different . you can't just fold it in as if it 's digits are different , too .
F: but those are folded in ,
I: it might also be potentially confusing .
F: and it 's just you just mark the transcripts differently . so so one option is you fold it in , and just simply in the file you mark somewhere that this is this type of interaction , rather than another type of interaction .
D: don wouldn't call reading digits "" meetings "" . we we were doing
F: but , put it under the same directory tree . it 's in "" user doctor speech data mr "" .
G: can we just have directory called , like , "" other "" ?
D: don't care what directory tree you have it under .
G: and and just , , store it there .
F: my preference is to have single procedure so that don't have to think too much about things . and , just have marking .
D: - you you can use whatever procedure you want that 's convenient for you .
F: if we do it any other way that means that we need separate procedure , and someone has to do that .
D: all 'm saying is that there 's no way that we 're gonna tell people that reading digits is meetings . and similarly we 're not gonna tell them that someone talking to computer to get travel information is meetings . those aren't meetings . but if it makes it easier for you to pu fold them in the same procedures and have them under the same directory tree , knock yourself out .
B: there 's couple other questions that have too , and one of them is , what about , , consent issues ? and the other one is , what about transcription ?
E: transcription is done in munich .
B: so we don't have to worry about transcribing it ?
F: so , we will hafta worry about format .
I: that 's that 's another argument to keep it separate , because it 's gonna follow the smartkom transcription conventions and not the icsi meeting transcription conventions .
F: didn't realize that . that 's that 's
D: but 'm no one would have problem with our folding it in for some acoustic modeling or some things . do we do we have , , , american - born folk , , reading german , , pla , place names and ?
F: they they even have reading list .
B: bet that sounds good ,
F: it 's pretty funny .
E: you can do that if you want .
B: if you want that .
F: disk might eventually be an issue so we might we might need to , , get some more disk pretty soon .
I: do you wanna be subject ?
D: be pretty good .
F: we 're about we 're about half halfway through our disk right now .
I: that was one of our concerns .
B: are we only half ? we were more than that .
F: we 're probably little more than that because we 're using up some space that we shouldn't be on . so , once everything gets converted over to the disks we 're supposed to be using we 'll be probably , , seventy - five percent .
B: when was looking for space for thilo , found one disk that had , , it was nine gigs and another one had seventeen . and everything else was sorta committed .
F: were those backed - up or non - backed - up ?
B: those were non - backed - up .
E: non - back - up .
F: so that 's different .
B: you 're talking about backed - up .
F: 'm much more concerned about the backed - up . the non - backed - up ,
B: haven't looked to see how much of that we have .
F: if we need to we can buy disk , hang it off , workstation . if it 's not backed - up the sysadmins don't care too much .
D: so , , anytime we need disk , we can get it at the rate that we 're
I: shouldn't be saying this , but , you can just , since the back - ups are every night , you can recycle the backed - up diskspace .
F: but that 's that 's that 's risky .
D: you really shouldn't be saying
I: didn't say that .
F: that 's right .
I: didn't say that .
F: beep that out .
D: da - we had allowed dave to listen to these , , recordings . me and there 's been this conversation going on about getting another file server , and we can do that . we 'll take the opportunity and get another big raft of disk , .
F: it 's really the back - up issue rather than the file server issue .
I: there 's an argument for having , you could use our old file server for disks that have data that is very rarely accessed , and then have fast new file server for data that is , , heavily accessed .
F: my understanding is , the issue isn't really the file server . we could always put more disks on .
I: it 's the back it 's the back - up capaci
F: it 's the back - up system . which is near saturation , .
B: the file server could become an issue as we get whole bunch more new compute machines . and we 've got , , fifty machines trying to access data off of abbott at once .
F: we 're alright for now because the network 's so slow .
I: we 've raised this before and someone said this is not reliable way to do it , what about putting the on , like , - cd - rom or dvd ?
F: that was me . was the one who said it was not reliable . the - they wear out .
I: but they wear out just from sitting on the shelf ? or from being read and read ?
F: read and write don't hurt them too much unless you scratch them . but the the write once , and the read - writes , don't last . so you don't wa you don't wanna put ir un reproduceable data on them .
B: wear out after what amount of time ?
F: year or two .
A: would it be ?
D: year or two ?
I: then you would think you 'd hear much more clamoring about data loss
F: many people who do it on cd . they 're the most fo
D: ldc - all the ldc distributions are on cd - rom .
F: they 're on cd , but they 're not tha that 's not the only source . they have them on disk . and they burn new ones every once in while . but if you go if you go
I: but , , we have
G: but we have like thirty , from ten years ago ?
D: we have all sorts of cd - roms from long time ago .
G: ten years ago . ninety - one , and they 're still all fine .
H: were they burned or were they pressed ?
G: 've burned them and they 're still .
F: the the pressed ones last for they 've been finding even those degrade . but , , the burned ones when say two or three years what 'm saying is that have had disks which are gone in year . on the average , it 'll probably be three or four years . but , you don't want to per have your only copy on media that fails . and they do . if you have them professionally pressed , , they 're good for decades .
I: so how about ? so so how about putting them on that plus , like on on dat or some other medium that isn't risky ?
F: we can already put them on tape . and the tape is hi is very reliable . so the only issue is then if we need access to them . so that 's fine if we don't need access to them .
I: if if you if they last say , they actually last , like , five years , , in the typical case , and occasionally you might need to recreate one , and then you get your tape out , but otherwise you don't . you just put them on ?
H: so you just archive it on the tape , and then put it on cd as ?
F: so you 're just saying put them on ds for normal access . you can do that but that 's pretty annoying , because the ds are so slow .
B: what 'd be is system that re - burned the ds every year .
G: everytime it was "" gonna "" "" gonna die "" .
F: , the ds are an op
I: it 's like dynamic ra dram .
G: just before they be before it goes bad , it burns them in .
F: the the cd is an alternative to tape . icsi already has perfectly good tape system and it 's more reliable . so for archiving , we 'll just use tape .
I: one one thing don't understand is , if you have the data if you if the meeting data is put on disk exactly once , then it 's backed - up once and the back - up system should never have to bother with it , , more than once .
F: first of all there was , , problem with the archive in that was every once in while doing chmod on all the directories an or recursive chmod and chown , because they weren't getting set correctly every once in while , and was just , doing minus star , not realizing that caused it to be re - backed - up . but normally you 're correct . but even without that , the back - up system is becoming saturated .
I: but but this back - up system is smart enough to figure out that something hasn't changed and doesn't need to be backed - up again .
D: the th the at least the once tha that you put it on , it would kill that .
F: but we still have enough changed that the nightly back - ups are starting to take too long .
I: so so then , if so so then , let 's
F: it has nothing to do with the meeting . it 's just the general icsi back - up system is becoming saturated .
I: so , what if we buy , , what do they call these , high density ?
F: why don't you have this have this conversation with dave johnson tha rather than with me ?
I: no , no . because this is maybe something that we can do without involving dave , and , putting more burden on him . how about we buy , , one of these high density tape drives ? and we put the data actually on non - backed - up disks . and we do our own back - up once and for all , and then and we don't have to bother this @ @ up ?
F: actually , , we could do that just with the tape with the current tape .
I: what the these tapes at some point these what tape drive is it ?
F: but it 's an automatic robot so it 's very convenient .
I: is it is ?
D: the the one that we have ?
F: you just run program to restore them .
I: but it might interfere with their back - up schedule ,
D: no , we have we don't we have our own ? something wi th that doesn't that isn't used by the back - up gang ? don't we have something downstairs ?
B: what kinda tape drive ?
F: but andreas 's point is good one . and we don't have to do anything ourselves to do that . they 're already right now on tape . so your point is , and it 's good one , that we could just get more disk and put it there .
I: on an xh , whatever partition .
F: that 's not bad idea .
D: that 's what was gonna say , is that disk is so cheap it 's es essentially , , close to free . and the only thing that costs is the back - up issue , , to first order .
F: so once it 's on tape
D: and we can take care of that by putting it on non - back up drives and just backing it up once onto this tape .
F: that 's good idea .
D: it 's good .
G: so , who 's gonna do these back - ups ? the people that collect it ?
F: 'll talk to dave , and see what th how {nonvocalsound} what the best way of doing that is .
B: it 's probably gonna
F: there 's little utility that will manually burn tape for you , and that 's probably the right way to do it .
B: and we should probably make that part of the procedure for recording the meetings .
G: that 's what 'm wondering ,
F: we 're we 're gonna automate that . my intention is to do script that 'll do everything .
G: you don't have to physically put tape in the drive ?
F: it 's all tape robot , so you just sit down at your computer and you type command .
G: so it 's just
I: but then you 're effectively using the resources of the back - up system . or is that different tape robot ?
G: but not at the same time .
F: but but you would be anyway .
B: no , no . he 's saying get whole different drive .
I: no , no .
F: but there 's no reason to do that . it we already have it there and it 's
I: 'm saying is @ @ if you go to dave , and and ask him "" can use your tape robot ? "" , he will say , "" that 's gonna screw up our back - up operation . ""
F: no , we won't . he 'll say "" if that means that it 's not gonna be backed - up standardly , great . ""
D: he - dave has promoted this in the past . so don't think he 's actually against it .
F: it 's it 's definitely no problem .
G: what about if the times overlap with the normal back - up time ?
F: it 's it 's just utility which queues up . it just queues it up and when it 's available , it will copy it . and then you can tell it to then remove it from the disk or you can , , do it few days later or whatever you wanna do , after you confirm that it 's really backed - up .
A: you saying nw archive ? and if you did that during the day it would never make it to the nightly back - ups .
F: that 's what it is .
A: and then there wouldn't be this extra load .
I: it if he you have to put the data on on non - backed - up disk to begin with .
A: but you can have it nw archive to you can have , , non - backed - up disk nw archived ,
I: so that so that otherwise you don't you
A: and it 'll never show up on the nightly back - ups .
F: and then it never which 'm would make ever the sysadmins very happy . so , that 's good idea . that 's what we should do . so , that means we 'll probably wanna convert all those files filesystems to non - backed - up media .
B: that sounds good .
D: another , thing on the agenda said sri recognition experiments ? what 's that ?
F: that wasn't me .
D: who 's that ?
I: we have lots of them . chuck , do you have any updates ?
B: 'm successfully , , increasing the error rate .
F: that 's good .
G: lift the herve approach .
B: so , 'm just playing with , , the number of gaussians that we use in the recognizer , and
I: you have to sa you have to tell people that you 're you 're doing you 're trying the tandem features .
B: yes , 'm using tandem features .
I: and 'm still tinkering with the plp features .
D: got confused by the results . it sai because , the meeting before , you said "" , we got it down to where they 're they 're within tenth of percent "" .
B: that was on males .
I: that was that was before tried it on the females . see , women are nothi are , trouble .
D: it 's the women are the problem .
I: as we all know .
G: let 's just say that men are simple .
I: so so , when so had ha
F: that was quick response .
I: so , we had reached the point where we had reached the point where , , on the male portion of the development set , the , or one of the development sets , should say the , the male error rate with , , icsi plp features was identical with , , sri features . which are mfcc . so , , then , "" , great . 'll 'll just let 's make everything works on the females . "" and the error rate , there was three percent difference .
G: is there less training data ?
I: no , actually there 's more training data .
G: this is on just digits ?
I: no , no .
B: hub - five .
F: it 's , , swi
I: this is hub - five .
F: hub - five .
I: and the test data is callhome and switchboard . so , so then and plus the vocal tract length normalization didn't actually made things worse . so something 's really wrong .
D: so but you see , now , between the males and the females , there 's certainly much bigger difference in the scaling range , than there is , say , just within the males . and what you were using before was scaling factors that were just from the the sri front - end . and that worked that worked fine .
I: that 's true .
D: but now you 're looking over larger range and it may not be so fine .
I: so the one thing that then tried was to put in the low - pass filter , which we have in the so , most hub - five systems actually band - limit the , at about , , thirty - seven hundred , , hertz . although , , normally , , the channel goes to four thousand . and that actually helped , , little bit . and it didn't hurt on the males either . and 'm now , , trying the and suddenly , also the the vocal tract length normalization only in the test se on the test data . so , you can do vocal tract length normalization on the test data only or on both the training and the test . and you expect it to help little bit if you do it only on the test , and more if you do it on both training and test . and so the it now helps , if you do it only on the test , and 'm currently retraining another set of models where it 's both in the training and the test , and then we 'll we 'll have , hopefully , even better results . it looks like there will still be some difference , maybe between one and two percent , , for the females . and so , , , 'm open to suggestions . and it is true that the , that the , we are using the it can't be just the vtl , because if you don't do vtl in both systems , , , the females are considerably worse in the with the plp features .
F: it 's much worse .
I: so there must be some something else going on .
G: what 's the standard ? so the performance was actually little better on females than males .
F: that 's what , too .
I: that ye overall , yes , but on this particular development test set , they 're actually little worse . but that 's beside the point . we 're looking at the discrepancy between the sri system and the sri system when trained with icsi features .
G: 'm just wondering if that if you have any indication of your standard features ,
F: what 's are the freq ?
G: if that 's also different or in the same direction or not .
D: you 're this is lemme ask more basic que is this , , iterative , baum - welch training ? or is it viterbi training ?
I: it 's baum - welch training .
D: baum - welch training . and how do you determine when to stop iterating ?
I: actually , we just do fixed number of iterations . in this case four . which , we used to do only three , and then we found out we can squeeze and it was , we 're we 're keeping it on the safe side . it might be that one more iteration would help , but it 's
D: or maybe or maybe you 're doing one too many . it 's it 's
I: no , but with baum - welch , there shouldn't be an over - fitting issue , really .
D: , there can be .
F: you can try each one on cross - validation set ,
D: it if you if you remember some years ago bill byrne did thing where he was he was looking at that , and he showed that you could get it .
I: that 's that 's the easy one to check , because we save all the intermediate models
D: and in each case , ho in each case how do you determine , , the usual fudge factors ? the , the , , language , , scaling , acoustic scaling ,
I: 'm actually re - optimizing them . although that hasn't shown to make big difference .
D: and the pru the question he was asking at one point about pruning , remember that one ? he was he 's it looked like the probabil at one point he was looking at the probabilities he was getting out at the likelihoods he was getting out of plp versus mel cepstrum , and they looked pretty different ,
I: pruning in the ?
B: the likelihoods were lower for the plp .
D: and so , , there 's the question
I: you mean did you see this in the sri system ?
B: was just looking through the log files ,
I: , the likelihoods are you can't directly compare them , because , for every set of models you compute new normalization . and so these log probabilities , they aren't directly comparable because you have different normalization constants for each model you train .
D: but , still it 's question if you have some threshold somewhere in terms of beam search ,
B: that 's what was wondering . if you have one threshold that works because the range of your likelihoods is in this area
I: we prune very conservatively . as we saw with the meeting data , we could probably tighten the pruning without really so we we have very open beam .
D: but , you 're only talking about percent or two . here we 're - we 're saying that we there gee , there 's this , there 's this difference here . see cuz , there could be lots of things . but but , , let 's suppose just for second that , , we 've taken out lot of the major differences , , between the two . we 're already using the mel scale and we 're using the same style filter integration , and , , we 're making that low and high
I: actually , there is the difference in that . so , for the plp features we use the triangular filter shapes . and for the in the sri front - end we use the trapezoidal one .
F: and what 's the top frequency of each ?
I: now it 's the same . it 's thirty to seven hundred and sixty hertz .
F: exp - one 's triangular , one 's trapezoidal .
I: no , no .
D: before we th with straight plp , it 's trapezoidal also . but then we had slight difference in the in the scale .
I: since currently the feacalc program doesn't allow me to change the filter shape independently of the scale . and , did the experiment on the sri front - end where tried the where the standard used to be to use trapezoidal filters . you can actually continuously vary it between the two . and so wen swi tried the trap , triangular ones . and it did slightly worse , but it 's really small difference .
D: coup - couple tenths of percent .
F: so it 's not just losing some frequency range .
I: so , it 's not don't think the filter shape by itself will make huge difference .
D: so the oth the other thing that we 've always viewed it , anyway , as the major difference between the two , is actually in the smoothing , that the that the , , plp , and the reason plp has been advantageous in , , slightly noisy situations is because , plp does the smoothing at the end by an auto - regressive model , and mel cepstrum does it by just computing the lower cepstral coefficients . so , - .
I: so one thing haven't done yet is to actually do all of this with much larger with our full training set . so right now , we 're using it 's it 's training set that 's about , , , by factor of four smaller than what we use when we train the full system . so , some of these smoothing issues are over - fitting for that matter . and the baum - welch should be much less of factor , if you go full whole hog . and so , so , just so the strategy is to first treat things with fast turn - around on smaller training set and then , when you 've , narrowed it down , you try it on larger training set . and so , we haven't done that yet .
D: now the other que related question , though , is , , what 's the boot models for these things ?
I: th - th the boot models are trained from scratch . so we compute , so , we start with , , alil alignment that we computed with the the best system we have . and and then we train from scratch . so we com we do , , we collect the , the observations from those alignments under each of the feature sets that we train . and then , from there we do , there 's lot of , actually the way it works , you first train phonetically - tied mixture model . you do total of first you do context - independent ptm model . then you switch to context you do two iterations of that . then you do two iterations of of context - dependent phonetically - tied mixtures . and then from that you do the you go to state - clustered model , and you do four iterations of that . so there 's lot of iterations overall between your original boot models and the final models . we have never seen big differences . once "" , now have these much better models . 'll re - generate my initial alignments . then 'll get much better models at the end . "" made no difference whatsoever . it 's it 's ,
D: mis for making things better .
I: the boot models are recur
D: but , this for making things worse . th - the thought is is possible another possible partial is if the boot models used comple used different feature set , that
I: but there are no boot models , . you you 're not booting from initial models . you 're booting from initial alignments .
D: which you got from different feature set .
I: that 's correct .
D: so , those features look at the data differently , actually . , they will find boundaries little differently , though all th all that thing is actually slightly different . 'd expect it to be minor effect ,
I: but but , what 'm what 'm saying is so , we for long time we had used boot alignments that had been trained with with the same front - end but with acoustic models that were , like , fifteen percent worse than what we use now . and with dict different dictionary with considerably different dictionary , which was much less detailed and much less - suited . and so , then we switched to new boot alignments , which now had the benefit of all these improvements that we 've made over two years in the system . and , the result in the end was no different . so , what 'm saying is , the exact nature of these boot alignments is probably not big factor in the quality of the final models .
D: but it st still see it as , there 's there 's history to this , too , but , don't wanna go into , but th it could be the things that it the data is being viewed in certain way , , that beginning is here rather than there and , because the actual signal - processing you 're doing is slightly different . but , it 's that 's probably not it .
I: anyway , should really reserve , , any conclusions until we 've done it on the large training set , , and until we 've seen the results with the with the vtl in training .
D: at some point you also might wanna take the same thing and try it on , , some broadcast news data else that actually has some noisy components , so we can see if any conclusions we come to holds across different data .
I: and , , with this , have to leave .
D: so , is there something quick about absinthe that you ?
I: with this said .
F: just what we were talking about before , which is that ported blass library to absinthe , and then got it working with fast - forward , and got speedup roughly proportional to the number of processors times the clock cycle . so , that 's pretty good . 'm in the process of doing it for quicknet , but there 's something going wrong and it 's about half the speed that was estimating it should be , and 'm not why . but 'll keep working on it . but the what it means is that it 's likely that for net training and forward passes , we 'll absinthe will be good machine . especially if we get few more processors and upgrade the processors .
I: few more processors ? how many are you shooting for ?
F: there 're five now . it can hold eight .
D: we 'll just go buy them , .
F: and it 's also five - fifty megahertz and you can get gigahertz .
I: can you mix , processors of different speed ?
F: we 'd have to do all
D: probably just throw away the old ones , for the box , and 'll just go buy their process .
I: maybe we can stick them in another system .
F: we 'd have to get almost certainly have to get , , netfinity server . they 're pretty specialized .
D: is is liz coming back , do , they 're having tea out there . so the other thing that we were gonna talk about is , , demo . and , , so , these are the demos for the , july , , meeting and , darpa mee it 's july fifteenth .
A: sixteen to eighteen , .
D: is that it ? sixteenth , eighteenth . so , we talked about getting something together for that , but maybe , maybe we 'll just put that off for now , given that but maybe we should have sub - meeting , , probably , , adam and , , chuck and me should talk about should get together and talk about that sometime soon .
F: over cappuccino tomorrow ?
D: something like that . , , maybe we 'll involve dan ellis at some level as . the the tea is going , so , , suggest we do , , unison .
F: which is gonna be little hard for couple people because we have different digits forms . we have found couple of old ones .
D: that 'll be interesting .
F: have you done digits before ?
C: haven't done it .
F: so , , the idea is just to read each line with short pause between lines , and , , since we 're in hurry , we were just gonna read everyone all at once . so , if you sorta plug your ears and read so first read the transcript number , and then start reading the digits . one , two , three .
D: we 're done .
","This meeting mainly outlines the progress of the meeting recorder project.
In particular , the group discuss their preparation of materials for the transcriptions of digits by IBM , and also the human transcribers who are working towards preparing the set of 20 for the DARPA meeting.
Other discussion focuses on the re-evaluation of recognition without cheating on segmentation , and also how SRI recognition can be improved , especially for the female group.
A number of issues regarding the management of data are addressed by the group:
The inclusion of different data types in the corpus , and the storage and back-up of the group's data.
Progress has been made in naming conventions , with file reorganisation to be done at a later date , however this was not discussed fully due to Chuck's absence.
Finally , Absinthe is now up and running with improved performance.
Discussion of demos for the July DARPA meeting were left to the individuals concerned.
A number of data issues were resolved:
After discussing the human-computer interaction Smartkom data , the group decide that different types of data can be included in the meeting corpus , but that it should be structured into different directories according to data type.
Some of the data storage problems can be overcome by backing up using the NW archive.
However , file reorganisation will be left until just before zero-level back up.
The group decide to use IBM transcription of the digits , in addition to automatic methods.
If IBM methods work , transcribers will check and comment these.
Discussion of demos for the July meeting has been postponed: the individuals concerned will meet independently.
Disk space is an issue for the group , especially in terms of back-up , which is 75% full: DVDs or CDs are unreliable and cannot be used , and although tape is reliable , this creates access issues.
Experimentation with the SRI recognition have shown greater error when using tandem features , with vocal tract normalisation also making results worse.
In particular more error is found with the female group which is 1-2% worse than the males.
Digit and beeps have been re-recorded by Chuck to aid IBM transcription , and enable alignment.
The group discuss the extent to which digits can be automatically transcribed , including their experimentation with forced alignment and speech recognition.
Transcription is progressing well: two transcribers hired and and two more will be hired soon.
Five ""set 2"" meetings are being edited by the head transcriber , and ""set 3"" are being prepared , with the aim of having 20 available for the DARPA demo.
Pre-segmentation is very useful , with visual information desirable for transcription of backchannel behaviour.
Now Thilo's segmenter is working , the group discuss re-evaluation of recognition without cheating on the segmentation , possibly using time-constrained alignment.
Also , they discuss the use of recogniser alignment to train the speech detector.
The group discuss possible ways to improve the SRI recognition error rate , suggestions include use of low-pass filter , or retraining models.
Differences in smoothing are proposed to be mainly responsible for the difference between the male and female results.
File reorganisation was discussed briefly as Chuck was not present , however progress has been made in sharing file naming conventions with UW.
Also , the Absinthe machine is now working well , and has speeded up in proportion to its extra processors.
"
ami_abstractive_summary,Bmr013.txt,"F: so wanted to discuss digits briefly , but that won't take too long .
C: we have digits , what else we got ?
A: new version of the presegmentation .
C: new version of presegmentation .
B: do we wanna say something about the , an update of the , , transcript ?
G: why don't you summarize the
C: update on transcripts .
G: and that includes some the filtering for the , the asi refs , too .
C: filtering for what ?
G: for the references that we need to go from the fancy transcripts to the {nonvocalsound} brain - dead .
B: it 'll it 'll be it 'll be re - cap of meeting that we had jointly this morning .
G: with don , as .
C: anything else more pressing than those things ? so , why don't we just do those . you said yours was brief , so
F: the , as you can see from the numbers on the digits we 're almost done . the digits goes up to about four thousand . and so , , we probably will be done with the ti - digits in , , another couple weeks . , depending on how many we read each time . so there were bunch that we skipped . someone fills out the form and then they 're not at the meeting and so it 's blank . but those are almost all filled in as . and so , once we 're it 's done it would be very to train up recognizer and actually start working with this data .
D: so we 'll have corpus that 's the size of ti - digits ?
F: one particular test set of ti - digits .
D: test set , .
F: so , extracted , ther - there was file sitting around which people have used here as test set . it had been randomized and so on and that 's just what used to generate the order . of these particular ones .
C: so , 'm impressed by what we could do , is take the standard training set for ti - digits , train up with whatever , , great features we think we have , , and then test on this test set . and presumably it should do reasonably on that , and then , presumably , we should go to the distant mike , and it should do poorly . and then we should get really smart over the next year or two , and it that should get better .
F: and inc increase it by one or two percent , . but , in order to do that we need to extract out the actual digits . so that the reason it 's not just transcript is that there 're false starts , and misreads , and miscues and things like that . and so have set of scripts and waves where you just select the portion , hit , it tells you what the next one should be , and you just look for that . so it 'll put on the screen , "" the next set is six nine , nine two "" . and you find that , and , hit the key and it records it in file in particular format . and so the question is , should we have the transcribers do that or should we just do it ? some of us . 've been do 've done , eight meetings , something like that , just by hand . just myself , rather . so it will not take long .
C: what do you think ?
B: my feeling is that we discussed this right before coffee and it 's it 's fine idea partly because , , it 's not un unrelated to their present skill set , but it will add , for them , an extra dimension , it might be an interesting break for them . and also it is contributing to the , , composition of the transcript cuz we can incorporate those numbers directly and it 'll be more complete transcript . so 'm it 's fine , that part .
F: there is there is
C: so you 's fine to have the transcribers do it ?
F: there 's one other small bit , which is just entering the information which at which is at the top of this form , onto the computer , to go along with the where the digits are recorded automatically . and so it 's just , , typing in name , times time , date , and so on . which again either they can do , but it is , , firing up an editor , or , again , do . or someone else can do .
B: and , that , , 'm not , that one 'm not so if it 's into the , things that , , wanted to use the hours for , because the , the time that they 'd be spending doing that they wouldn't be able to be putting more words on . but that 's really your choice , it 's your
D: so are these two separate tasks that can happen ? or do they have to happen at the same time before
F: no they don't have this you have to enter the data before , you do the second task , but they don't have to happen at the same time . so it 's it 's just have file whi which has this information on it , and then when you start using my scripts , for extracting the times , it adds the times at the bottom of the file . and so , , , it 's easy to create the files and leave them blank , and so actually we could do it in either order . it 's it 's to have the same person do it just as double - check , to make you 're entering for the right person . but , either way .
C: just by way of , , order of magnitude , , , we 've been working with this aurora , data set . and , , the best score , on the , nicest part of the data , that is , where you 've got training and test set that are the same kinds of noise and , , is about , the best score was something like five percent , , error , per digit . you 're right . so if you were doing ten digit , , recognition , you would really be in trouble . so the the point there , and this is car noise , things , but real situation , "" real "" , the there 's one microphone that 's close , that they have as this thing , close versus distant . but in car , instead of instead of having projector noise it 's it 's car noise . but it wasn't artificially added to get some artificial signal - to - noise ratio . it was just people driving around in car . so , that 's that 's an indication , that was with , many sites competing , and this was the very best score and , so . more typical numbers like
D: although the models weren't , that good , the models are pretty crappy ?
C: you 're right . that we could have done better on the models , but that we got this is the typical number , for all of the , , things in this task , all of the , , languages . and so we 'd probably the models would be better in some than in others . so , . anyway , just an indication once you get into this realm even if you 're looking at connected digits it can be pretty hard .
B: it 's gonna be fun to see how we , compare at this . very exciting . @ @ .
D: how did we do on the ti - digits ?
F: the prosodics are so much different it 's gonna be , strange . the prosodics are not the same as ti - digits , . so 'm 'm not how much of effect that will have .
G: what do you mean , the prosodics ?
F: just what we were talking about with grouping . that with these , the grouping , there 's no grouping , and so it 's just the only discontinuity you have is at the beginning and the end .
G: so what are they doing in aurora , are they reading actual phone numbers ,
F: what they do in aurora .
G: or , digit at time , or ?
C: no , no it 's connected it 's connected , , digits ,
G: so there 's also the not just the prosody but the cross the cross - word modeling is probably quite different .
F: but in ti - digits , they 're reading things like zip codes and phone numbers and things like that ,
D: do we do on ti - digits ?
F: so it 's gonna be different .
C: we were in the .
F: one and half percent , two percent , something like that ?
C: th no we got under percent , but it was but it 's but . the very best system that saw in the literature was point two five percent that somebody had at bell labs , or . , but . but , , pulling out all the stops .
B: @ @ . it strikes me that there are more each of them is more informative because it 's so , random ,
C: but lot of systems get half percent , or three - quarters percent , and we 're we 're in there somewhere .
F: but that it 's really it 's close - talking mikes , no noise , clean signal , just digits , , every everything is good .
G: it 's the beginning of time in speech recognition .
F: yes , exactly . and we 've only recently got it to anywhere near human .
G: it 's like the , single cell , , it 's the beginning of life ,
D: pre - prehistory .
F: and it 's still like an order of magnitude worse than what humans do .
C: when they 're wide awake , . after coffee , you 're right . not after lunch .
F: so , , what 'll do then is 'll go ahead and enter , this data . and then , hand off to jane , and the transcribers to do the actual extraction of the digits .
C: one question have that , we wouldn't know the answer to now but might , do some guessing , but was talking before about doing some model modeling of arti , marking of articulatory , features , with overlap and so on . and , and , , on some subset . one thought might be to do this , on the digits , or some piece of the digits . it 'd be easier , , and . the only thing is 'm little concerned that maybe the phenomena , in the reason for doing it is because the argument is that certainly with conversational speech , the that we 've looked at here before , , just doing the simple mapping , from , , the phone , to the corresponding features that you could look up in book , , isn't right . it isn't actually right . there 's these overlapping processes where some voicing some up and then some , , some nasality is comes in here , and . and you do this gross thing saying "" it 's this phone starting there "" . so , , that 's the reasoning . but , it could be that when we 're reading digits , because it 's it 's for such limited set , that maybe that phenomenon doesn't occur as much . di - an anybody ? do you have any ? anybody have any opinion about that ,
B: and that people might articulate more , and you that might end up with more closer correspondence .
F: that 's agree . that it 's just it 's would , this corpus really be the right one to even try that on ?
G: it 's definitely true that , when people are , reading , even if they 're - reading what , they had said spontaneously , that they have very different patterns . mitch showed that , and some , dissertations have shown that . so the fact that they 're reading , first of all , whether they 're reading in room of , people , or rea , just the fact that they 're reading will make difference . and , depends what you 're interested in .
C: so , may maybe the thing will be do to take some very small subset , not have big , program , but take small set , , subset of the conversational speech and small subset of the digits , and look and just get feeling for it . just take look . really .
B: that could be an interesting design , too , cuz then you 'd have the com the comparison of the , , predictable speech versus the less predictable speech
C: cuz don't think anybody is , at least , , of anybody , , , the answers .
B: and maybe you 'd find that it worked in , in the , case of the pr of the , , non - predictable .
D: hafta think about , the particular acoustic features to mark , too , because , , some things , they wouldn't be able to mark , like , , , , tense lax . some things are really difficult .
F: we can get ohala in to , give us some advice on that .
B: also you were thinking of much more restricted set of features , that
C: but was , like he said , was gonna bring john in and ask john what he thought . but you want you want it be restrictive but you also want it to to have coverage . you should . it should be such that if you , , if you had , all of the features , determined that you that you were ch have chosen , that would tell you , , in the steady - state case , , the phone .
F: even , with vowels that would be pretty hard , to identify actually , , which one it is ?
B: it would seem to me that the points of articulation would be more , that 's about articulatory features , about , points of articulation , which means , , rather than vowels .
D: points of articulation ? what do you mean ?
B: so , is it , , bilabial or dental or is it , , palatal . which which are all like where your tongue comes to rest .
C: place , place .
D: place of ar place of articulation .
B: what whatev whatever said , that 's really meant place .
C: we got our jargon then , .
G: it 's also , there 's , really difference between , the pronunciation models in the dictionary , and , the pronunciations that people produce . and , so , you get , some of that information from steve 's work on the on the labeling and it really , actually think that data should be used more . that maybe , although the meeting context is great , that he has transcriptions that give you the actual phone sequence . and you can go from not from that to the articulatory features , but that would be better starting point for marking , the gestural features , then , data where you don't have that , because , we you wanna know , both about the way that they 're producing certain sound , and what kinds of , what kinds of , phonemic , differences you get between these , transcribed , sequences and the dictionary ones .
C: you might be right that mi might be the way at getting at , what was talking about , but the particular reason why was interested in doing that was because remember , when that happened , and , john ohala was over here and he was looking at the spectrograms of the more difficult ones . he didn't to say , about , what is the sequence of phones there . they came up with some compromise . because that really wasn't what it look like . it didn't look like sequence of phones it look like this blending thing happening here and here .
F: so you have this feature here , and , overlap , .
D: there was no name for that .
G: but it still is there 's there are two steps . one , one is going from dictionary pronunciation of something , like , "" gonna see you tomorrow "" ,
F: and or "" gonta "" .
G: it could be "" going to "" or "" gonna "" or "" gonta "" . "" gonna see you tomorrow "" , , "" guh see you tomorrow "" . and , that it would be to have these , intermediate , or these some these reduced pronunciations that those transcribers had marked or to have people mark those as . because , it 's not , , that easy to go from the , dictionary , word pronuncia the dictionary phone pronunciation , to the gestural one without this intermediate or syllable level , representation .
F: don't think morgan 's suggesting that we do that , though .
C: do you mean , , 'm jus at the moment we 're just talking about what , to provide as tool for people to do research who have different ideas about how to do it . so , you might have someone who just has wor has words with states , and has , comes from articulatory gestures to that . and someone else , might actually want some phonetic intermediate thing . so it would be best to have all of it if we could .
F: but what 'm imagining is score - like notation , where each line is particular feature . so you would say , , it 's voiced through here , and so you have label here , and you have nas nasal here , and , they could be overlapping in all sorts of bizarre ways that don't correspond to the timing on phones .
C: this is the reason why remember when at one of the switchboard , workshops , that when we talked about doing the transcription project , dave talkin said , "" can't be done "" . he was he was , what he meant was that this isn't , , sequence of phones , and when you actually look at switchboard that 's , not what you see , and , . and . it ,
F: and the inter - annotator agreement was not that good , on the harder ones ?
G: it depends how you look at it , and understand what you 're saying about this , transcription exactly , because 've seen , where does the voicing bar start and . all 'm saying is that , it is useful to have that the transcription of what was really said , and which syllables were reduced . if you 're gonna add the features it 's also useful to have some level of representation which is , is reduced it 's pronunciation variant , that currently the dictionaries don't give you because if you add them to the dictionary and you run recognition , you add confusion . so people purposely don't add them . so it 's useful to know which variant was produced , at least at the phone level .
D: so it would be it would be great if we had , either these , labelings on , the same portion of switchboard that steve marked , or , steve 's type markings on this data , with these .
G: that 's all , .
C: no don't disagree with that .
G: and steve 's type is fairly it 's not that slow , exactly what the , timing was , but .
C: don't disagree with it the on the only thing is that , what you actually will end en end up with is something , it 's all compromised , so , the string that you end up with isn't , actually , what happened . but it 's it 's the best compromise that group of people scratching their heads could come up with to describe what happened .
D: and it 's more accurate than , phone labels .
C: but . and it 's more accurate than the than the dictionary or , if you 've got pronunciation lexicon that has three or four , this might be have been the fifth one that you tr that you pruned or whatever ,
D: so it 's like continuum . it 's you 're going all the way down ,
G: that 's what is an and in some places it would fill in , so the kinds of gestural features are not everywhere . so there are some things that you don't have access to either from your ear or the spectrogram , but what phone it was and that 's about all you can all you can say . and then there are other cases where , nasality , voicing
D: it 's just having , multiple levels of , information and marking , on the signal .
F: the other difference is that the features , are not synchronous , they overlap each other in weird ways . so it 's not strictly one - dimensional signal . so that 's sorta qualitatively different .
G: you can add the features in , , but it 'll be underspecified . th - there 'll be no way for you to actually mark what was said completely by features .
F: not with our current system but you could imagine designing system , that the states were features , rather than phones .
G: and if you 're we 've probably have separate , , discussion of , of whether you can do that .
B: that 's , isn't that that was , but that wasn't that kinda the direction ?
C: so , what where this is , , want would like to have something that 's useful to people other than those who are doing the specific research have in mind , so it should be something broader . but , the but where 'm coming from is , , we 're coming off of that larry saul did with , , , john dalan and muzim rahim in which , , they , , have , , multi - band system that is , , trained through combination of gradient learning an and , to , estimate , , the , , value for for particular feature . and this is part of larger , image that john dalan has about how the human brain does it in which he 's imagining that , individual frequency channels are coming up with their own estimate , of these , these kinds of something like this . might not be , , exact features that , jakobson thought of . but some , something like that . some low - level features , which are not , fully , , phone classification . and the th this particular image , of how thi how it 's done , is that , then given all of these estimates at that level , there 's level above it , then which is making , some sound unit classification such as , , phone and , . you could argue what , what sound unit should be , and . but that 's what was imagining doing , and but it 's still open within that whether you would have an intermediate level in which it was actually phones , or not . you wouldn't necessarily have to . but , again , wouldn't wanna , wouldn't want what we produced to be so , know , local in perspective that it was matched , what we were thinking of doing one week , and and , , what you 're saying is right . that , that if we , can we should put in , , another level of , of description there if we 're gonna get into some of this low - level .
D: , if we 're talking about , having the , annotators annotate these kinds of features , it seems like , the the question is , do they do that on , meeting data ? or do they do that on , switchboard ?
F: that 's what was saying ,
B: it seems like you could do both .
F: maybe meeting data isn't the right corpus .
B: was thinking that it would be interesting , to do it with respect to , parts of switchboard anyway , in terms of , partly to see , if you could , generate first guesses at what the articulatory feature would be , based on the phone representation at that lower level . it might be time gain . but also in terms of comparability of , ,
D: cuz the , and then also , if you did it on switchboard , you would have , the full continuum of transcriptions . you 'd have it , from the lowest level , the ac acoustic features , then you 'd have the , , the phonetic level that steve did ,
G: that 's all was thinking about .
B: and you could tell that
G: it is telephone band , so , the bandwidth might be
D: it 'd be complete , set then .
B: and you get the relative gain up ahead .
C: it 's so it 's little different . so we 'll see wha how much we can , , get the people to do , and how much money we 'll have and all this thing ,
D: but it might be good to do what jane was saying , , seed it , with , guesses about what we think the features are , based on , , the phone or steve 's transcriptions . to make it quicker .
C: might be do both .
F: alright , so based on the phone transcripts they would all be synchronous , but then you could imagine , nudging them here and there .
D: scoot the voicing over little , because
C: what 'm 'm little behind in what they 're doing , now , and , , the they 're doing on switchboard now . but that , steve and the gang are doing , something with an automatic system first and then doing some adjustment . as re as recall . so that 's probably the right way to go anyway , is to is to start off with an automatic system with pretty rich pronunciation dictionary that , , , tries , to label it all . and then , people go through and fix it .
B: so in our case you 'd think about us starting with maybe the regular dictionary entry ,
C: regular dictionary , , this is pretty rich dictionary . it 's got , got fair number of pronunciations in it
D: or you could start from the if we were gonna , do the same set , of sentences that steve had , done , we could start with those transcriptions .
G: that 's actually what was thinking , is tha the problem is when you run , , if you run regular dictionary , , even if you have variants , in there , which most people don't , you don't always get , out , the actual pronunciations , so that 's why the human transcriber 's giving you the that pronunciation ,
C: actually maybe they 're using phone recognizers .
G: they that they were
C: is that what they 're doing ?
G: we should catch up on what steve is , that would be good good idea .
C: so that we also don't have , , we 've got good start on it , but we don't have really good , meeting , recorder or recognizer or transcriber or anything yet , so , another way to look at this is to , , do some on switchboard which has all this other , to it . and then , , as we get , further down the road and we can do more things ahead of time , we can , do some of the same things to the meeting data .
B: and 'm and these people might they are , most of them are trained with ipa . they 'd be able to do phonetic - level coding , or articulatory .
D: are they busy for the next couple years , or ?
B: , they , they 're interested in continuing working with us , so , and this would be up their alley , so , we could when the when you meet with , with john ohala and find , what taxonomy you want to apply , then , they 'd be , good to train onto it .
C: anyway , this is , not an urgent thing , just it came up .
D: it 'd be very interesting though , to have that data .
B: so , too .
F: wonder , how would you do forced alignment ? to to , you 'd wanna iterate , somehow . it 's interesting thing to think about . you 'd you 'd want models for spreading .
G: was thinking it might be
D: of the acoustic features ?
G: it might be neat to do some , phonetic , features on these , nonword words . are are these kinds of words that people never the "" ""s and the "" ""s and the "" "" and the these no , 'm serious . there are all these kinds of functional , , elements . what you call them . but not just fill pauses but all kinds of ways of interrupting and . and some of them are , , "" - ""s , and "" ""s , and , "" ! "" "" "" "" "" , "" "" grunts , that might be interesting .
B: he 's got lip lipsmacks .
G: in the meetings .
C: we should move on . new version of , , presegmentation ?
A: , , worked little bit on the on the presegmentation to get another version which does channel - specific , , speech - nonspeech detection . and , what did is used some normalized features which , , look in into the which is normalized energy , , energy normalized by the mean over the channels and by the , minimum over the , other . within each channel . and to , , to , , to normalize also loudness and modified loudness and things and that those special features actually are in my feature vector . and , and , therefore to be able to , , somewhat distinguish between foreground and background speech in the different in each channel . and , , tested it on three or four meetings and it seems to work , , fairly , would say . there are some problems with the lapel mike .
F: that 's great . so understand that 's what you were saying about your problem with , minimum .
A: and had had , , specific problems with .
F: so new use ninetieth quartile , rather than , minimum .
A: then did some some things like that , as there are some problems in , when , in the channel , there they the speaker doesn't doesn't talk much or doesn't talk . then , the , , there are there are some problems with with with normalization , and , then , , there the system doesn't work . so , 'm 'm glad that there is the digit part , where everybody is forced to say something , so , that 's that 's great for my purpose . and , , then the evaluation of the system is little bit hard , as don't have any references .
F: we did the hand the one by hand .
A: that 's the one wh where do the training on so 't do the evaluation on so , can the transcribers perhaps do some , some meetings in terms of speech - nonspeech in the specific channels ?
D: won't you have that from their transcriptions ?
B: , so , now we need
F: no , cuz we need is really tight .
B: might have done what you 're requesting , though did it in the service of different thing . have thirty minutes that 've more tightly transcribed with reference to individual channels .
A: that 's great . for me . , so .
F: hopefully that 's not the same meeting that we did .
B: no , actually it 's different meeting . so , , so the , , we have the , th they transcribe as if it 's one channel with these with the slashes to separate the overlapping parts . and then we run it through then it then 'm gonna edit it and 'm gonna run it through channelize which takes it into dave gelbart 's form format . and then you have , all these things split across according to channel , and then that means that , if person contributed more than once in given , overlap during that time bend that two parts of the utterance end up together , it 's the same channel , and then took his tool , and last night for the first thirty minutes of one of these transcripts , , tightened up the , , boundaries on individual speakers ' channels , cuz his interface allows me to have total flexibility in the time tags across the channels . and , so .
A: so , , that that 's great , but what would be to have some more meetings , not just one meeting to be that , there is system ,
D: so , current this week .
B: might not be what you need .
F: so if we could get couple meetings done with that level of precision that would be good idea .
B: time so the meetings vary in length , what are we talking about in terms of the number of minutes you 'd like to have as your as your training set ?
A: it seems to me that it would be good to have , few minutes from different meetings , but 'm not about how much .
B: now you 're saying different meetings because of different speakers or because of different audio quality or both or ?
A: different different number of speakers , different conditions .
C: we don't have that much variety in meetings yet , we have this meeting and the feature meeting and we have couple others that we have , couple examples of . but but , ,
E: even probably with the gains differently will affect it , you mean
C: poten - potentially .
A: because of the normalization , .
E: cuz you use the normalization ?
G: we can try running we haven't done this yet because , , , andreas an is gonna move over the sri recognizer . ran out of machines at sri , cuz we 're running the evals and don't have machine time there . but , once that 's moved over , , hopefully in couple days , then , we can take , , what jane just told us about as , the presegmented , {nonvocalsound} the segmentations that you did , at level eight or som at some , threshold that jane , tha right , and try doing , forced alignment . , on the word strings .
A: with the recognizer ?
G: and if it 's good , then that will that may give you good boundary . if it 's good , we don't then we 're we 're fine , but , yet whether these , segments that contain lot of pauses around the words , will work or not .
A: would quite like to have some manually transcribed references for the system , as 'm not if it 's really good to compare with some other automatic , found boundaries .
B: no , if we were to start with this and then tweak it manually , would that would be ?
G: they might be . it it really depends on lot of things , but , would have maybe transciber , , look at the result of forced alignment and then adjust those .
A: to adjust them , or ,
G: that might save some time . if they 're horrible it won't help , but they might not be horrible . so but 'll let when we , , have that .
B: how many minutes would you want from we could easily , get section , , like say minute or so , from every meeting that we have so from the newer ones that we 're working on , everyone that we have . should provide this .
A: if it 's not the first minute of the meeting , that 's with me , but , in the first minute , , often there are some strange things going on which aren't really , , for , which aren't re really good . so . what what 'd quite like , perhaps , is , to have , some five minutes of of different meetings ,
B: somewhere not in the very beginning , five minutes , . and , then wanted to ask you just for my inter information , then , would you , be trai cuz don't quite unders so , would you be training then , , the segmenter so that , it could , on the basis of that , segment the rest of the meeting ? so , if give you like five minutes is the idea that this would then be applied to , , to , providing tighter time bands ?
A: could do retraining with that , . that 's but hope that don't need to do it . so , it can be do in an unsupervised way . 'm 'm not , but , for for those three meetings whi which which did , it seems to be , quite , but , there are some as said some problems with the lapel mike , but , perhaps we can do something with cross - correlations to , to get rid of the of those . that 's that 's what that 's my future work . what want to do is to look into cross - correlations for removing those , false overlaps .
G: are the , , wireless , different than the wired , mikes , ? have you noticed any difference ?
A: 'm 'm not , , if there are any wired mikes in those meetings , or , , have to loo have look at them but , 'm there 's no difference between ,
G: so it 's just the lapel versus everything else ?
B: so then , if that 's five minutes per meeting we 've got like twelve minutes , twelve meetings , roughly , that 'm that 've been working with , then
C: of of the meetings that you 're working with , how many of them are different , tha are there any of them that are different than , these two meetings ?
B: wa in terms of the speakers or the conditions or the ? we have different combinations of speakers . just from what 've seen , , there are some where , , you 're present or not present , and , then you have the difference between the networks group and this group
A: know , some of the nsa meetings , .
C: so didn't the group you had if you had so you have the networks meeting ? do you have any of jerry 's meetings in your , pack , er ,
B: you recorded one last week or so . could get that new one in this week get that new one in .
G: we 're gonna be recording them every monday ,
C: cuz he really needs variety , and having as much variety for speaker certainly would be big part of that .
B: then , , if were to include all together samples from twelve meetings that would only take an hour and could get the transcribers to do that what is , that would be an hour sampled , and then they 'd transcribe those that hour , that 's what should do ?
A: that 's that 's .
C: ye - but you 're
B: so they get it into the multi - channel format and then adjust the timebands so it 's precise .
C: so that should be faster than the ten times thing ,
B: did did , , , so , last night did , , last night , did about half an hour in , three hours , which is not , terrific , anyway , it 's an hour and half per
C: that 's probably .
B: 't calculate on my , on my feet .
A: do the transcribers actually start wi with , , transcribing new meetings , or are they ?
B: they 're still working they still have enough to finish that haven't assigned new meeting , but the next , was about to need to assign new meeting and was going to take it from one of the new ones , and could easily give them jerry feldman 's meeting ,
G: so they 're really running out of , data , prett that 's good .
B: that first set .
C: they 're running out of data unless we make the decision that we should go over and start , , transcribing the other set . there the first half .
B: and so was in the process of like editing them but this is wonderful news . we funded the experiment with , also we were thinking maybe applying that to getting the , that 'll be , very useful to getting the overlaps to be more precise all the way through .
C: so this , blends nicely into the update on transcripts .
B: yes , it does . so , , , liz , and don , and met this morning , in the barco room , with the lecture hall ,
G: and this afternoon .
B: and this afternoon , it drifted into the afternoon , , concerning this issue of , , the , there 's the issue of the interplay between the transcript format and the processing that , they need to do for , the sri recognizer . and , , , so , mentioned the process that 'm going through with the data , so , , get the data back from the transcri , , metaphorically , get the data back from the transcriber , and then , check for simple things like spelling errors and things like that . and , , 'm going to be doing more thorough editing , with respect to consistency of the conventions . but they 're they 're generally very good . and , then , run it through , , the channelize program to get it into the multi - channel format , . and the , what we discussed this morning , would summarize as saying that , , these units that result , in particular channel and particular timeband , at that level , , vary in length . and , , {nonvocalsound} their recognizer would prefer that the units not be overly long . but it 's really an empirical question , whether the units we get at this point through , just that process described might be sufficient for them . so , as first pass through , first chance without having to do lot of hand - editing , what we 're gonna do , is , 'll run it through channelize , give them those data after 've done the editing process and be it 's clean . and do that , pretty quickly , with just , that minimal editing , without having to hand - break things . and then we 'll see if the units that we 're getting , , with the at that level , are sufficient . and maybe they don't need to be further broken down . and if they do need to be further broken down then maybe it just be piece - wise , maybe it won't be the whole thing . so , that 's that 's what we were discussing , this morning as far as among also we discussed some adaptational things , so it 's like , hadn't , , incorporated , convention explicitly to handle acronyms , , but if someone says , pzm it would be to have that be directly interpretable from , the transcript what they said , or pi - tcl tcl . it 's and so , , 've 've incorporated also convention , with that but that 's easy to handle at the post editing phase , and 'll mention it to , transcribers for the next phase but that 's . and then , similar conv , convention for numbers . so if they say one - eighty - three versus one eight three . and also 'll be , , encoding , as do my post - editing , the , things that are in curly brackets , which are clarificational material . and to incorporate , , keyword , at the beginning . so , it 's gonna be either gloss or it 's gonna be vocal sound like , laugh or cough , or , . or non - vocal sound like doors door - slam , and that can be easily done with , , just one little additional thing in the , in the general format .
G: we we just needed way to , strip , , all the comments , all the things th the that linguist wants but the recognizer can't do anything with . but to keep things that we mapped to like reject models , or , , , mouth noise , or , cough . and then there 's this interesting issue jane brought up which hadn't thought about before but was , realizing as went through the transcripts , that there are some noises like , the good example was an inbreath , where transcriber working from , the mixed , signal , doesn't know whose breath it is , and they 've been assigning it to someone that may or may not be correct . and what we do is , if it 's breath sound , , sound from the speaker , we map it , to , noise model , like mouth - noise model in the recognizer , and , , it probably doesn't hurt that much once in while to have these , but , if they 're in the wrong channel , that 's , not good idea . and then there 's also , things like door - slams that 's really in no one 's channel , they 're like it 's in the room . and , jane had this , , idea of having , like an extra , couple tiers ,
F: an extra channel .
B: 've been 've been adding that to the ones 've been editing .
G: and we were thinking , that is useful also when there 's uncertainties . so if they hear breath and they who breath it is it 's better to put it in that channel than to put it in the speaker 's channel because maybe it was someone else 's breath , so that 's good you can always clean that up , post - processing . so lot of little details , but we 're , coming to some kinda closure , on that . so the idea is then , , don can take , , jane 's post - processed channelized version , and , with some scripts , , convert that to reference for the recognizer and we can , can run these . so when that 's , ready , as soon as that 's ready , and as soon as the recognizer is here we can get , twelve hours of force - aligned and recognized data . and , , start , working on it , so we 're , coup week or two away would say from , if that process is automatic once we get your post - process , transcript .
B: and that doesn't the amount of editing that it would require is not very much either . 'm just hoping that the units that are provided in that way , {nonvocalsound} will be sufficient cuz would save lot of , , time , dividing things .
G: some of them are quite long . you did one ?
E: saw couple , around twenty seconds , and that was just without looking too hard for it , so , would imagine that there might be some that are longer .
B: would that be single speaker or is that multiple speakers overlapping ?
E: no . no , but if we 're gonna segment it , like if there 's one speaker in there , that says "" "" , right in the middle , it 's gonna have lot of dead time around it ,
G: right . it 's not the it 's not the fact that we can't process twenty second segment , it 's the fact that , there 's twenty seconds in which to place one word in the wrong place
E: so it 's not
G: if someone has very short utterance there , and that 's where , we , might wanna have this individual , , ha have your pre - process input .
B: that 's very important .
A: that perhaps the transcribers could start then from the those mult multi - channel , , speech - nonspeech detections , if they would like to .
G: have to run it .
B: in in doing the hand - marking ? that 's what was thinking , too .
G: so that 's probably what will happen , but we 'll try it this way and see . it 's probably good enough for force - alignment . if it 's not then we 're really then we def definitely but for free recognition 'm it 'll probably not be good enough . we 'll probably get lots of errors because of the cross - talk , and , noises and things .
C: that 's probably our agenda , or starting up there .
B: wanted to ask one thing , the microphones the new microphones , when do we get , ?
F: they said it would take about week .
D: you ordered them already ?
G: so what happens to our old microphones ?
C: they go where old microphones go .
G: do we give them to someone ,
F: the only thing we 're gonna have extra , for now ,
G: we don't have more receivers ,
F: right , we don so the only thing we 'll have extra now is just the lapel . not not the , bodypack , just the lapel .
G: just the lapel itself .
F: and then one of the one of those . since , what decided to do , on morgan 's suggestion , was just get two , new microphones , , and try them out . and then , if we like them we 'll get more . since they 're they 're like two hundred bucks piece , we won't , , at least try them out .
D: so it 's replacement for this headset mike ?
F: and they 're gonna do the wiring for us .
D: what 's the , , style of the headset ?
F: it 's , , it 's by crown , and it 's one of these mount around the ear thingies , and , , when when mentioned that we thought it was uncomfortable he said it was common problem with the sony . and this is how lot of people are getting around it . and checked on the web , and every site went to , raved about this particular mike . it 's comfortable and stays on the head , so we 'll see if it 's any good . but , , it 's promising .
B: you said it was used by aerobics instructors ?
F: , so it was it was advertised for performers
B: that says lot .
C: for the recor for the record adam is not paid employee or consultant of crown . said "" for the record adam is not paid consultant or employee of crown "" .
F: that 's right .
G: however , he may be solicited after these meetings are distributed .
F: we 're using the crown
G: don't worry about finishing your dissertation .
F: the ms are crown ,
C: you bet . you bet .
F: and they work very .
C: so if we go to workshop about all this it 's gonna be meeting about meetings .
F: and then it we have to go to the planning session for that workshop .
C: , what which 'll be the meeting about the meeting .
F: cuz then it would be meeting about the meeting about meetings .
C: just start saying "" four "" .
F: to the fourth .
C: should we do the digits ?
F: go for it . pause between the lines , remember ?
","The Berkeley Meeting Recorder group discussed the collection status for a set of connected digits recordings that are nearly complete and ready to be trained on a recognizer.
Anticipated results were discussed in reference to results obtained for other digits corpora , i.e . Aurora and TI-digits.
The group also considered the prospect of performing fine-grained acoustic-phonetic analyses on a subset of Meeting Recorder digits or Switchboard data.
Pre-segmentation manipulations that allow for the segmentation of channel-specific speech/non-speech portions of the signal and the distinction of foreground versus background speech were discussed.
Finally , speaker fe008 and fe016 reported on new efforts to adapt transcriptions to the needs of the SRI recognizer , including conventions for encoding acronyms , numbers , ambient noise , and unidentified inbreaths.
The group decided to delegate the extraction of digits to the transcriber pool.
A tentative decision was also made to delegate transcribers with the task of labelling a subset of digits or Switchboard data for fine-grained acoustic-phonetic features.
Speaker fe008 will run selected Meeting Recorder data through channelize and determine whether the resulting units are of a sufficient length.
With respect to encoding more fine-grained acoustic information in transcriptions , the question was posed: which features should be marked?
Speaker mn014 reported problems pre-segmenting speech recorded via the lapel microphones.
Normalization of the energy measured across and within channels is problematic when performed for speakers who say little or nothing during meetings.
The evaluation of pre-segmented data is difficult without tightly transcribed time references to the individual channels from which the speech was derived.
The SRI recognizer requires that multi-channel format units not be too large , indicating that some additional pre-processing of unit lengths may be necessary.
A test set of Meeting Recorder digits is nearly complete.
Future work will include training this data on a recognizer , and feeding the recognizer with corresponding far-field microphone data.
It was noted that the results of experiments testing similar digits corpora have yielded high error rates , indicating that similar problems may be expected for the set of Meeting Recoreder digits.
The group discussed the prospect of performing fine-grained acoustic-phonetic analyses on a subset of digits or Switchboard data.
It was suggested that prior to the use of data-driven methods , knowledge-driven approaches should be used to 'seed' the data with sub-phonemic features , either manually , or using a rich pronunciation dictionary.
A new version of the pre-segmentation tool that segments channel-specific speech/non-speech portions of the signal has been developed and tested.
Future pre-segmentation work will include normalizing other features , such as loudness , enabling the distinction of foreground versus background speech.
Speaker mn014 will also look at cross-correlations for removing false overlaps.
New efforts were reported to adapt transcriptions to the needs of the SRI recognizer , including conventions for encoding acronyms , numbers , ambient noise , and unidentified inbreaths.
With the arrival of the SRI recognizer , 12 hours of forced aligned , recognized data can be expected.
"
ami_abstractive_summary,Bro024.txt,"F: and we 're on .
D: might wanna close the door so that , stephane will
F: 'll get it . could you go ahead and turn on , , stephane 's
D: so that 's the virtual stephane over there .
G: do you use pc for recording ?
F: it 's got , , like sixteen channels going into it .
G: the quality is quite good ?
F: so far , it 's been pretty good .
D: the suggestion was to have these guys start to
F: why don't you go ahead , dave ?
C: so , , the this past week 've been main mainly occupied with , , getting some results , from the sri system trained on this short hub - five training set for the mean subtraction method . ran some tests last night . the results are suspicious . it 's , , cuz they 're the baseline results are worse than , , andreas than results andreas got previously . and it could have something to do with ,
F: that 's on digits ?
C: that 's on digits . it it could it could have something to do with , , downsampling . that 's that 's worth looking into . ap apart from that , the main thing have ta have to talk is , , where 'm planning to go over the next week . so 've been working on integrating this mean subtraction approach into the smartkom system . and there 's this question of , , so , , in my tests before with htk found it worked it worked the best with about twelve seconds of data used to estimate the mean , but , we 'll often have less in the smartkom system . so we 'll use as much data as we have at particular time , and we 'll we 'll concatenate utterances together , , to get as much data as we possibly can from the user . but , , there 's question of how to set up the models . so , we could train the models . if we think twelve seconds is ideal we could train the models using twelve seconds to calculate the mean , to mean subtract the training data . or we could , , use some other amount . so like did an experiment where , , was using six seconds in test , but , for tried twelve seconds in train . and tried , , the same in train 'm tried six seconds in train . and six seconds in train was about point three percent better . and , it 's not clear to me yet whether that 's something significant . so wanna do some tests and , , actually make some plots of , for particular amount of data and test what happens if you vary the amount of data in train .
D: guenter , if you followed this but this is , , , long - term long - term window he you talked about it .
G: we spoke about it already ,
D: so what he 's doing .
C: so was actually ran the experiments mostly and was was hoping to have the plots with me today . didn't get to it . wou would be curious about people 's feedback on this cuz 'm @ @ there are some it 's it 's like bit of tricky engineering problem . 'm trying to figure out what 's the optimal way to set this up . so , , 'll try to make the plots and then put some postscript up on my on my web page . and 'll mention it in my status report if people wanna take look .
D: you could clarify something for me . you 're saying point three percent , you take point three percent hit , when the training and testing links are don't match ? is that what it is ?
C: don't 's just for any mismatch you take hit . in some cases it might be better to have mismatch . like saw something like if you only have two seconds in test , or , , maybe it was something like four seconds , you actually do little better if you , , train on six seconds than if you train on four seconds . but the case , with the point three percent hit was using six seconds in test , , comparing train on twelve seconds versus train on six seconds .
D: and which was worse ?
C: the train on twelve seconds .
D: but point three percent , , from what to what ? that 's point three percent
C: on the the accuracies went from it was something vaguely like ninety - five point six accuracy , , improved to ninety - five point nine wh when
D: so four point four to four point one . so about about an eight percent , , seven or eight percent relative ? in , if you were going for an evaluation system you 'd care . but if you were doing live system that people were actually using nobody would notice . it 's , to get something that 's practical , that you could really use .
C: that 's that 's interesting . alright , the , see your point . was thinking of it as , , an interesting research problem . the how to was thinking that for the asru paper we could have section saying , "" for smartkom , we in we tried this approach in , , interactive system "" , which don't think has been done before . and and then there was two research questions from that . and one is the does it still work if you just use the past history ? and the other was this question of , what was just talking about now . so that 's why it was interesting .
D: short - time fft short - time cepstrum calculation , , mean mean calculation work that people have in commercial systems , they do this all the time . they the they calculate it from previous utterances and then use it , . but but , , as you say , there hasn't been that much with this long - time , , spectra work .
C: so that 's that 's standard .
D: no , it is interesting . and the other thing is , , there 's two sides to these really small , , gradations in performance . , on the one hand in practical system if something is , , four point four percent error , four point one percent error , people won't really tell be able to tell the difference . on the other hand , when you 're doing , , research , you may , you might find that the way that you build up change from ninety - five percent accurate system to ninety - eight percent accurate system is through ten or twelve little things that you do that each are point three percent . so so the they it 's don't mean to say that they 're they 're irrelevant . they are relevant . but , , for demo , you won't see it .
C: let 's let 's see . and then there 's , another thing wanna start looking at , , wi is , , the choice of the analysis window length . so 've just been using two seconds just because that 's what carlos did before . wrote to him asking about he chose the two seconds . and it seemed like he chose it bit informally . with the with the htk set - up should be able to do some experiments , on just varying that length , say between one and three seconds , in few different reverberation conditions , say this room and also few of the artificial impulse responses we have for reverberation , just , , making some plots and seeing how they look . with the sampling rate was using , one second or two seconds or four seconds is at power of two , number of samples and , , 'll 'll jus for the ones in between 'll just zero - pad .
D: one thing that might also be an issue , , cuz part of what you 're doing is you 're getting spectrum over bunch of different kinds of speech sounds . and so it might matter how fast someone was talking . if you if there 's lot of phones in one second maybe you 'll get really good sampling of all these different things , and , , on the other hand if someone 's talking slowly maybe you 'd need more . if you have some samples of faster or slower speech but it might make difference .
C: don't don't think the ti - digits data that have , , is would be appropriate for that . but what do you what about if fed it through some , , speech processing algorithm that changed the speech rate ?
D: but then you 'll have the degradation of , , whatever you do , added onto that . maybe if you get something that sounds that 's does pretty job at that .
C: , just if you 's worth looking into .
D: you could imagine that .
C: it is getting little away from reverberation .
D: it 's just that you 're making choice was thinking more from the system aspect , if you 're making choice for smartkom , that that it might be that it 's it the optimal number could be different , depending on
C: and and th the third thing , , , is , , barry explained lda filtering to me yesterday . and so , , mike shire in his thesis , did series of experiments , , training lda filters in on different conditions . and you were interested in having me repeat this for for this mean subtraction approach ? is is that right ? or for these long analysis windows , , is the right way to put it .
D: the the issue was the general issue was bringing up was that if you 're have moving window , , wa set of weights times things that , , move along , shift along in time , that you have linear time invariant filter . and you just happened to have picked particular one by setting all the weights to be equal . and so the issue is what are some other filters that you could use , , in that sense of "" filter "" ? as was saying , the simplest thing to do is not to train anything , but just to do some , , hamming or hanning , , window , thing , just to de - emphasize the jarring . so that would be the first thing to do . but then , , the lda , is interesting because it would say , suppose you actually trained this up to do the best you could by some criterion , what would the filter look like then ? that 's what we 're doing in this aur - aurora . it 's still not clear to me in the long run whether the best thing to do would be to do that or to have some stylized version of the filter that looks like these things you 've trained up , because you always have the problem that it 's trained up for one condition and it isn't quite right for another . that 's why that 's why rasta filter has actually ended up lasting long time , people still using it quite bit , because you don't change it . doesn't get any worse .
C: actually was just thinking about what was asking about earlier , wi which is about having less than say twelve seconds in the smartkom system to do the mean subtraction . you said in systems where you use cepstral mean subtraction , they concatenate utterances and , do how they address this issue of , , testing versus training ?
G: what they do is they do it always on - line , that you just take what you have from the past , that you calculate the mean of this and subtract the mean . and then you can , you can increase your window whi while you get while you are getting more samples .
C: and , , so in tha in that case , wh what do they do when they 're , performing the cepstral mean subtraction on the training data ? so because you 'd have hours and hours of training data . so do they cut it off and start over ?
G: so do you have , you mean you have files which are hours of hours long ? usually you have in the training set you have similar conditions , file lengths are , the same order or in the same size as for test data , or
C: so if someone 's interacting with the system , though , , morgan , morgan said that you would tend to , , chain utterances together
D: what was what was saying was that , , at any given point you are gonna start off with what you had from before . and so if you 're splitting things up into utterances so , , in dialogue system , where you 're gonna be asking , , , th for some information , there 's some initial th something . and , , the first time out you might have some general average . but you you don't have very much information yet . but at after they 've given one utterance you 've got something . you can compute your mean cepstra from that , and then can use it for the next thing that they say , so that , , the performance should be better that second time . and the heuristics of exactly how people handle that and how they handle their training 'm vary from place to place . but the ideally , it seems to me anyway , that you would wanna do the same thing in training as you do in test . but that 's that 's just , , prejudice . and anybody working on this with some particular task would experiment .
C: the question had was , , amount of data was the amount of data that you 'd give it to , update this estimate . because say you if you have say five thousand utterances in your training set , , and you keep the mean from the last utterance , by the time it gets to the five thousandth utterance
D: no , but those are all different people with different , in so , in the in telephone task , these are different phone calls . so you don't wanna @ @ chain it together from from different phone call .
C: so so they would
D: so it 's within speaker , within phone call , if it 's dialogue system , it 's within whatever this characteristic you 're trying to get rid of is expected to be consistent over ,
C: so you 'd you and so in training you would start over at every new phone call or at every new speaker .
D: now , , maybe you 'd use something from the others just because at the beginning of call you anything , and so you might have some general thing that 's your best to start with . lot of these things are proprietary so we 're doing little bit of guesswork here . what do comp what do people do who really face these problems in the field ? and they don't tell other people exactly what they do . but but , when you the hints that you get from what they when they talk about it are that they do they all do something like this .
C: bec - because so this smartkom task first off , it 's this tv and movie information system .
D: but you might have somebody who 's using it and then later you might have somebody else who 's using it . and so you 'd wanna set some
C: was was about to say . so if you ask it "" what what movies are on tv tonight ? "" , if look at my wristwatch when say that it 's about two seconds . the way currently have the mean subtraction , , set up , the analysis window is two seconds . so what you just said , about what do you start with , raises question of what do start with then ?
D: so in that situation , though , th maybe what 's little different there , is you 're talking about there 's only one it it also depends we 're getting little off track here . there 's been some discussion about whether the work we 're doing in that project is gonna be for the kiosk or for the mobile or for both . and for this discussion it matters . if it 's in the kiosk , then the physical situation is the same . it 's gonna , the exact interaction of the microphone 's gonna differ depending on the person and . but at least the basic acoustics are gonna be the same . so if it 's really in one kiosk , then that you could just chain together and , as much as much speech as possible to because what you 're really trying to get at is the is the reverberation characteristic . but in the case of the mobile , , presumably the acoustic 's changing all over the place . and in that case you probably don't wanna have it be endless because you wanna have some it 's not question of how long do you 's you can get an approximation to stationary something , given that it 's not really stationary .
C: and just started thinking of another question , which is , for the very first frame , what do do if 'm if take if use that frame to calculate the mean , then 'm just gonna get nothing . so should probably have some default mean for the first couple of frames ?
D: or subtract nothing .
C: or subtract nothing . and and that 's that 's something that 's people have figured out how to deal with in cepstral mean subtraction as ?
D: people do something . they they , , they have some , , in cepstral mean subtraction , for short - term window analysis windows , as is usually done , you 're trying to get rid of some very general characteristic . and so , , if you have any other information about what general characteristic would be , then you can do it there .
F: you can also reflect the data . so you take , 'm not how many frames you need . but you take that many from the front and flip it around to as the negative value . so you can always
D: the other thing is that and remember doing this , is that if you have multi - pass system , , if the first pass ta it takes most of the computation , the second and the third pass could be very , very quick , just looking at relatively small small , , space of hypotheses . then you can do your first pass without any subtraction . and then your second pass , , eliminates those most of those hypotheses by , by having an improved version of the analysis .
C: so that was all had , for now .
F: do you wanna go , barry ?
A: so for the past , , week an or two , 've been just writing my , , formal thesis proposal . so 'm taking this qualifier exam that 's coming up in two weeks . and finish writing proposal and submit it to the committee . and , should should explain , , more about what 'm proposing to do , and and ?
D: yes , briefly .
A: so briefly , 'm proposing to do new approach to speech recognition using , combination of , , multi - band ideas and ideas , , about the , acoustic phonec phonetic approach to speech recognition . so will be using these graphical models that , that implement the multi - band approach to recognize set of intermediate categories that might involve , , things like phonetic features or other feature things that are more closely related to the acoustic signal itself . and the hope in all of this is that by going multi - band and by going into these , intermediate classifications , that we can get system that 's more robust to unseen noises , and situations like that . some of the research issues involved in this are , , one , what intermediate categories do we need to classify ? another one is , what other types of structures in these multi - band graphical models should we consider in order to , combine evidence from the sub - bands ? and , , the third one is how do we how do we merge all the , , information from the individual , multi - band classifiers to come up with word recognition or phone recognition things . so that 's that 's what 've been doing .
F: so you 've got two weeks , ?
A: got two weeks to brush up on , presentation
D: you were finishing your thesis in two weeks .
F: are you gonna do any dry runs for your thing , or are you just gonna
A: 'm gonna do some . would you be interested ? to help out ?
F: is that it ?
A: that 's it .
F: let 's see . so we 've got forty minutes left , and it seems like there 's lot of material . an - any suggestions about where we where we should go next ?
B: mmm , @ @ .
F: do you wanna go , sunil ? maybe we 'll just start with you .
B: but actually stuck most of this in our last meeting with guenter . so the last week , , showed some results with only speechdat - car which was like some fifty - six percent . and , , didn't found that the results wasn't getting that results on the ti - digit . so was like looking into "" why , what is wrong with the ti - digits ? "" . why why was not getting it . and found that , the noise estimation is reason for the ti - digits to perform worse than the baseline . so , , actually , picked th the first thing did was scaled the noise estimate by factor which is less than one to see if that because found there are lot of zeros in the spectrogram for the ti - digits when used this approach . so the first thing did was scaled the noise estimate . so the results that 've shown here are the complete results using the new the the new technique is nothing but the noise estimate scaled by factor of point five . so it 's just an ad - hoc some intermediate result , because it 's not optimized for anything . so the results the trend the only trend could see from those results was like the the current noise estimation or the , , noise composition scheme is working good for like the car noise type of thing . because 've the only very good result in the ti - digits is the noise car noise condition for their test - , which is like the best could see that for any non - stationary noise like "" babble "" or "" subway "" or any "" street "" , some "" restaurant "" noise , it 's like it 's not performing very . the so that 's the first thing , could make out from this .
G: what is important to see is that there is big difference between the training modes . if you have clean training , you get also fifty percent improvement . but if you have muddy condition training you get only twenty percent .
B: and in that twenty percent @ @ it 's very inconsistent across different noise conditions . so have like forty - five percent for "" car noise "" and then there 's minus five percent for the "" babble "" , and there 's this thirty - three for the "" station "" . and so it 's not it 's not actually very consistent across . the only correlation between the speechdat - car and this performance is the stationarity of the noise that is there in these conditions and the speechdat - car . so the overall result is like in the last page , which is like forty - seven , which is still very imbalanced because there are like fifty - six percent on the speechdat - car and thirty - five percent on the ti - digits . ps the fifty - six percent is like comparable to what the french telecom gets , but the thirty - five percent is way off .
D: 'm looking on the second page , and it says "" fifty percent "" looking in the lower right - hand corner , "" fifty percent relative performance "" .
G: for the clean training . and if you if you look
D: is that fifty percent improvement ?
B: for that 's for the clean training and the noisy testing for the ti - digits .
D: so it 's improvement over the baseline mel cepstrum ? but the baseline mel cepstrum under those training doesn't do as 'm 'm trying to understand why it 's it 's eighty percent that 's an accuracy number , , so that 's not as good as the one up above . but the fifty is better than the one up above , so 'm confused .
B: actually the noise compensation whatever , , we are put in it works very for the high mismatch condition . it 's consistent in the speechdat - car and in the clean training also it gives it but this fifty percent is that the high mismatch performance equivalent to the high mismatch performance in the speech .
F: so so since the high mismatch performance is much worse to begin with , it 's easier to get better relative improvement .
B: so by putting this noise
E: if we look at the figures on the right , we see that the reference system is very bad .
B: the reference drops like very fast
E: like for clean training condition .
D: this is this is ti digits we 're looking at ? this whole page is ti - digits or this is ?
B: it 's not written anywhere . it 's ti - digits . the first spreadsheet is ti - digits .
D: how does clean training do for the , , "" car ""
B: the "" car "" ? still it still , that 's still consistent . get the best performance in the case of "" car "" , which is the third column in the condition .
D: this is added noise . this is ti - digits . in the , , multi - language , , finnish and
G: this is next page .
B: that 's the next spreadsheet , is so that is the performance for italian , finnish and spanish .
D: "" training condition "" so "" clean "" corresponds to "" high mismatch "" . and "" increase "" ,
B: that 's "" percentage increase "" is the percentage improvement over the baseline .
G: it 's it 's
D: which means decrease in word error rate ? so "" percentage increase "" means decrease ?
G: the the there was very long discussion about this on the on the , , amsterdam meeting . how to how to calculate it then .
B: there 's there 's
G: you are using finally this the scheme which they
B: which is there in the spreadsheet . 'm not changing anything in there . so all the hi numbers are very good , in the sense , they are better than what the french telecom gets . but the only number that 's still , which stephane also got in his result was that medium mismatch of the finnish , which is very which is very strange situation where we used the we changed the proto for initializing the this is because it gets stuck in some local minimum in the training . that seventy - five point seven nine in the finnish mismatch which is that the eleven point nine six what we see .
D: so we have to jiggle it somehow ?
B: so we start with that different proto and it becomes eighty - eight , which is like some fifty percent improvement .
D: start with different what ?
B: which is like different initialization for the , , transition probabilities . it 's just that right now , the initialization is to stay more in the current state , which is point four point six , right ? and if it changes to point five , which is equal @ @ for transition and self loop where it becomes eighty - eight percent .
F: but that involves mucking with the back - end ,
B: we can't do it .
F: which is not allowed .
G: it , like , it is known , this medium match condition of the finnish data has some strange effects .
B: it has very few at , actually , , tran , words also . it 's very , very small set , actually .
G: there is there is lot of , there are lot of utterances with music in with music in the background .
B: it has some music also . very horrible music like
D: so maybe for that one you need much smarter vad ? if it 's music .
B: that 's the that 's about the results . the summary is like so there are the other thing what tried was , which explained in the last meeting , is using the channel zero for , , for both dropping and estimating the noise . and that 's like just to get feel of how good it is . the fifty - six percent improvement in the speechdat - car becomes like sixty - seven percent . like ten percent better . but that 's that 's not that 's cheating experiment .
G: but the but the , , forty - seven point nine percent which you have now , that 's already remarkable improvement in comparison to the first proposal .
B: so we had forty - four percent in the first proposal . we have big im so the major improvement that we got was in all the high mismatch cases , because all those numbers were in sixties and seventies because we never had any noise compensations . so that 's where the biggest improvement came up . not much in the match and the medium match and ti - digits also right now . so this is still at three or four percent improvement over the first proposal .
D: so that 's good . then if we can improve the noise estimation , then it should get better .
G: started thinking about also , discovered the same problem when started working on , on this aurora task almost two years ago , that you have the problem with this mulit at the beginning we had only this multi condition training of the ti - digits . and , , found the same problem . just taking , what we were used to use , , , some type of spectral subtraction , you get even worse results than the basis tried to find an explanation for it ,
B: stephane also has the same experience of using the spectral subtraction right ? so here , found that it 's if changed the noise estimate could get an improvement . so that 's so it 's something which actually pursue , is the noise estimate .
G: what you do is in when you have the this multi - condition training mode , then you have then you can train models for the speech , for the words , as as for the pauses where you really have all information about the noise available . at the beginning it was not surprising to me that you get really the best results on doing it this way , in comparison to any type of training on clean data and any type of processing . it seems to be the best what wh what we can do in this moment is multi - condition training . and every when we now start introducing some noise reduction technique we introduce also somehow artificial distortions . and these artificial distortions , have the feeling that they are the reason why we have the problems in this multi - condition training . that means the ms we trained , they are they are based on gaussians , and on modeling gaussians . can move little bit with this ? and if we introduce now this spectral subtraction , or wiener filtering so , usually what you have is maybe , 'm 'm showing now an envelope maybe you 'll for this time . so usually you have maybe in clean condition you have something which looks like this . and if it is noisy it is somewhere here . and then you try to subtract it or wiener filter or whatever . and what you get is you have always these problems , that you have this these zeros in there . and you have to do something if you get these negative values . this is your noise estimate and you somehow subtract it or do whatever . and then you have and then what you do is you introduce some artificial distribution in this in the models . you train it also this way but , somehow there is there is no longer gaussian distribution . it is somehow strange distribution which we introduce with these artificial distortions . and and was thinking that might be the reason why you get these problems in the especially in the multi - condition training mode .
B: th - that 's true . the the models are not complex enough to absorb that additional variability that you 're introducing .
E: also have the feeling that , the reason ye why it doesn't work is , that the models are much are , not complex enough . because actually als always had good experience with spectral subtraction , just straight spectral subtraction algorithm when was using neural networks , big neural networks , which maybe are more able to model strange distributions then tried the same exactly the same spectral subtraction algorithm on these aurora tasks and it simply doesn't work . it 's even it , , hurts even .
D: we probably should at some point here try the tandem the system - two with this , with the spectral subtraction for that reason . cuz again , it should do transformation to domain where it maybe looks more gaussian .
G: just yesterday when was thinking about it what we could try to do , or do about it if you if you get at this in this situation that you get this negative values and you simply set it to zero or to constant or whatever if we would use there somehow , random generator which has certain distribution , not certain , special distribution we should see we have to think about it . and that we , so , introduce again some natural behavior in this trajectory .
B: very different from speech . still , , it shouldn't confuse the
G: , similar to what you see really in the real noisy situation . or in the clean situation . but but somehow natural distribution .
D: but isn't that again the idea of the additive thing , if it as we had in the ? if you have random data , , in the time domain , then when you look at the spectrum it 's gonna be pretty flat . so just add something everywhere rather than just in those places . it 's just constant , right ?
G: it 's it 's just especially in these segments , you introduce , , very artificial behavior .
D: see if you add something everywhere , it has almost no effect up up on top . and it and it has significant effect down there . that was , the idea .
B: the that 's true . that those regions are the for this @ @ those negative values or whatever you get .
G: we could trit , we could think how what we could try . it was just an idea .
D: when it 's noisy people should just speak up .
E: if we look at the france telecom proposal , they use some noise addition . they have random number generator , right ? and they add noise on the trajectory of , , the log energy only , right ?
B: - - zero and log energy also ,
E: but how much effect it this have , but they do that .
G: so it it is somehow similar to what
E: because they have th log energy , and then just generate random number . they have some mean and variance , and they add this number to the log energy simply .
B: the log energy , the after the clean cleaning up . so they add random noise to it .
D: to the just the energy , or to the mel , to the mel filter ?
B: on - only to the log energy .
D: so it cuz , this is most interesting for the mel filters . one or the other .
G: but but they do not apply filtering of the log energy or what
B: no their filter is not domain . so they did filter their time signal and then what @ @
G: and then they calculate from this , the log energy
B: then after that it is almost the same as the baseline prop system . and then the final log energy that they that they get , that to the to that they add some random noise .
D: but again , that 's just log energy as opposed to filter bank energy .
B: so it 's not the mel . it 's not the mel filter bank output . these are log energy computed from the time domain signal , not from the mel filter banks .
E: maybe it 's just way to decrease the importance of this particular parameter in the in the world feature vector cu if you add noise to one of the parameters , you widen the distributions
B: the variance , , reduces ,
E: eee - sss - .
D: so it could reduce the dependence on the amplitude and so on .
F: so is , is that about it ?
B: so the other thing is the 'm just looking at little bit on the delay issue where the delay of the system is like hundred and eighty millisecond . so tried another sk system , another filter which 've like shown at the end . which is very similar to the existing , filter . only , only thing is that the phase is like nonlinear phase because it 's it 's not symmetric filter anymore .
F: this is for the lda ?
B: so this is like so this makes the delay like zero for lda because it 's completely causal . so got actually just the results for the italian for that and that 's like so the fifty - one point nine has become forty - eight point six , which is like three percent relative degradation . so have like the fifty - one point nine it fares for the other conditions . so it 's just like it 's like three percent relative degradation ,
G: but but is there is there problem with the one hundred eighty milliseconds ?
D: th - , this is
G: , talked to , ta , talked , , about it with hynek .
D: so , our position is that , , we shouldn't be unduly constraining the latency at this point because we 're all still experimenting with trying to make the performance better in the presence of noise . there is minority in that group who is arguing who are arguing for , , having further constraining of the latency . so we 're just continuing to keep aware of what the trade - offs are and , , what do we gain from having longer or shorter latencies ? but since we always seem to at least get something out of longer latencies not being so constrained , we 're tending to go with that if we 're not told we can't do it .
F: what where was the , the smallest latency of all the systems last time ?
B: the french telecom .
D: france telecom was was very short latency and they had very good result .
F: what what was it ?
D: it was thirty - five .
G: it was in the order of thirty milliseconds
B: thirty - four .
D: so it 's possible to get very short latency . but , again , we 're the approaches that we 're using are ones that take advantage of
F: was just curious about where we are compared to , , the shortest that people have done .
G: but but this thirty milliseconds they did it did not include the delta calculation . and this is included now ,
B: so if they include the delta , it will be an additional forty millisecond .
G: th they were not using the htk delta ?
B: no , they 're using nine - point window , which is like four on either side ,
G: nine - point .
B: they didn't include that .
E: where does the comprish compression in decoding delay comes from ?
B: that 's the way the the frames are packed , like you have to for one more frame to pack . because it 's the crc is computed for two frames always .
D: that the they would need that forty milliseconds also .
B: they actually changed the compression scheme altogether . so they have their own compression and decoding scheme and they what they have . but they have coded zero delay for that . because they ch know they changed it , they have their own crc , their own error correction mechanism . so they don't have to more than one more frame to know whether the current frame is in error . so they changed the whole thing so that there 's no delay for that compression and part also . even you have reported actually zero delay for the compression . maybe you also have some different
G: no , used this scheme as it was before .
F: we 've got twenty minutes so we should probably try to move along . did you wanna go next , stephane ?
E: we have to take so you have one sheet ? this one is you don't need it , so you have to take the whole the five . there should be five sheets .
D: because left one with dave because was dropping one off and passing the others on . so , no , we 're not .
H: give me one .
D: we need one more over here .
E: maybe there 's not enough for everybody .
F: share with barry .
E: can we look at this ? there are two figures showing actually the , mmm , , performance of the current vad . so it 's neural network based on plp parameters , which estimate silence probabilities , and then put median filtering on this to smooth the probabilities , right ? didn't use the scheme that 's currently in the proposal because don't want to in the system we want to add like speech frame before every word and little bit of , , couple of frames after also . but to estimate the performance of the vad , we don't want to do that , because it would artificially increase the the false alarm rate of speech detection . there is normally figure for the finnish and one for italian . and maybe someone has two for the italian because 'm missing one figure here . so one surprising thing that we can notice first is that the speech miss rate is , higher than the false alarm rate .
G: so so what is the lower curve and the upper curve ?
E: there are two curves . one curve 's for the close - talking microphone , which is the lower curve . and the other one is for the distant microphone which has more noise it 's logical that it performs worse . so as was saying , the miss rate is quite important which means that we tend to label speech as silence . didn't analyze further yet , but it 's it may be due to the fricative sounds which may be in noisy condition maybe label labelled as silence . and it may also be due to the alignment the reference alignment . because right now use an alignment obtained from system trained on channel zero . checked it little bit but there might be alignment errors . like the fact that the models tend to align their first state on silence and their last state on silence also . so the reference alignment would label as speech some silence frame before speech and after speech . this is something that we already noticed before so this cus this could also explain , , the high miss rate maybe .
G: and and this curves are the average over the whole database ,
E: and the different points of the curves are for five , thresholds on the probability from point three to point seven .
B: so the detection threshold is very
E: there first , threshold on the probability @ @ that puts all the values to zero or one . and then the median filtering .
B: so the median filtering is fixed . you just change the threshold ?
E: it 's fixed , so , going from channel zero to channel one , , almost double the error rate . so it 's reference performance that we can , if we want to work on the vad , we can work on this basis
A: is this is this vad mlp ? how how big is it ?
E: it 's very big one .
B: so three hundred and fifty inputs , six thousand hidden nodes and two outputs .
D: middle - sized one .
E: you have questions about that , or suggestions ? it seems the performance seems worse in finnish ,
B: it 's not trained on finnish .
H: it 's worse .
E: it 's not trained on finnish ,
D: what 's it trained on ?
B: the mlp 's not trained on finnish .
D: what 's it trained on ?
B: it 's italian ti - digits .
D: it 's trained on italian ?
B: that 's right .
E: and also there are like funny noises on finnish more than on italian .
B: the , it 's true .
E: we were looking at this . but for most of the noises , noises are if we want to talk about that . the "" car "" noises are below like five hundred hertz . and we were looking at the "" music "" utterances and in this case the noise is more about two thousand hertz . the music energy 's very low . from zero to two thousand hertz . so maybe just looking at this frequency range for from five hundred to two thousand would improve somewhat the vad
B: so there are like some some parameters you wanted to use ?
E: it 's there .
G: so is the is the training is the training based on these labels files which you take as reference here ? wh - when you train the neural net you
E: it 's not . it 's it was trained on some alignment obtained for the italian data , we trained the neural network on with embedded training . so re - estimation of the alignment using the neural network , . that 's right ?
B: we actually trained , , the on the italian training part . we we had another system with
E: so it was phonetic classification system for the italian aurora data .
B: it must be somewhere .
E: for the aurora data that it was trained on , it was different . like , for ti - digits you used previous system that you had , .
B: that 's true .
E: so the alignments from the different database that are used for training came from different system . then we put them tog together . you put them together and trained the vad on them . but did you use channel did you align channel one also ?
B: took their entire italian training part . so it was both channel zero plus channel one .
E: so the alignments might be wrong then on channel one , right ? so we might ,
B: we can do realignment . that 's true .
E: at least want to retrain on these alignments , which should be better because they come from close - talking microphone .
G: the that was my idea . if it ha if it is not the same labeling which is taking the spaces .
B: so the vad was trained on maybe different set of labels for channel zero and channel one was the alignments were were different for certainly different because they were independently trained . we didn't copy the channel zero alignments to channel one . but for the new alignments what you generated , you just copied the channel zero to channel one , right ?
E: actually when we look at the vad , for some utterances it 's almost perfect , it just dropped one frame , the first frame of speech so there are some utterances where it 's almost one hundred percent vad performance . so the next thing is , have the spreadsheet for three different system . but for this you only have to look right now on the speechdat - car performance so didn't test the spectral subtraction on ti - digits yet . so you have three she sheets . one is the proposal - one system . actually , it 's not exe exactly proposal - one . it 's the system that sunil just described . but with , wiener filtering from , france telecom included . so this gives like fifty - seven point seven percent , , , error rate reduction on the speechdat - car data . and then have two sheets where it 's for system where so it 's again the same system . but in this case we have spectral subtraction with maximum overestimation factor of two point five . there is smoothing of the gain trajectory with some , low - pass filter , which has forty milliseconds latency . and then , after subtraction , add constant to the energies and have two cases where the first case is where the constant is twenty - five db below the mean speech energy and the other is thirty db below . and for these two system we have like fifty - five point , , five - percent improvement , and fifty - eight point one . so again , it 's around fifty - six , fifty - seven .
D: cuz notice the ti - digits number is exactly the same for these last two ?
E: for the france telecom , spectral subtraction included in the our system , the ti - digits number are the right one , but not for the other system because didn't test it yet this system , including with spectral subtraction on the ti - digits data . tested it on speechdat - car .
D: so so that means the only thing
G: so so these numbers are simply
E: this , we have to
B: but this number .
D: so you so you just should look at that fifty - eight perc point nine percent and so on .
B: so by , by reducing the noise decent threshold like minus thirty db , it 's like , you are like reducing the floor of the noisy regions , right ?
E: the floor is lower .
D: so when you say minus twenty - five or minus thirty db , with respect to what ?
E: to the average , speech energy which is estimated on the world database .
D: so you 're creating signal - to - noise ratio of twenty - five or thirty db ?
E: but it 's not
G: what you do is this . when when you have this , after you subtracted it , , then you get something with this , , where you set the values to zero and then you simply add an additive constant again . so you shift it somehow . this this whole curve is shifted again .
D: but did you do that before the thresholding to zero ,
E: but , it 's after the thresholding .
D: so you 'd really want to do it before ,
E: maybe we might do it before ,
D: because then the then you would have less of that phenomenon .
E: but still , when you do this and you take the log after that , it reduce the variance .
D: that will reduce the variance . that 'll help . but maybe if you does do it before you get less of these funny - looking things he 's drawing .
B: so before it 's like adding this , col to the exi original
D: right at the point where you 've done the subtraction . essentially you 're adding constant into everything .
G: but the way stephane did it , it is exactly the way have implemented in the phone ,
D: better do it different , then . just you just ta you just set it for particular signal - to - noise ratio that you want ?
G: made similar investigations like stephane did here , just , adding this constant and looking how dependent is it on the value of the constant and then , must choose them somehow to give on average the best results for certain range of the signal - to - noise ratios .
E: it 's clear . should have gi given other results . also it 's clear when you don't add noise , it 's much worse . like , around five percent worse . and if you add too much noise it get worse also . and it seems that right now this is constant that does not depend on anything that you can learn from the utterance . it 's just constant noise addition .
D: then then 'm confused . you 're saying it doesn't depend on the utterance but you were adding an amount that was twenty - five db down from the signal energy .
E: so the way did that , measured the average speech energy of the all the italian data . and then have used this as mean speech energy .
D: it 's just constant amount over all .
E: wha what observed is that for italian and spanish , when you go to thirty and twenty - five db , it 's good . it stays in this range , it 's , , the the performance of the this algorithm is quite good . but for finnish , you have degradation already when you go from thirty - five to thirty and then from thirty to twenty - five . and have the feeling that maybe it 's because just finnish has mean energy that 's lower than the other databases . and due to this the thresholds should be the the noise addition should be lower
D: but in , in the real thing you 're not gonna be able to measure what people are doing over half an hour or an hour , or anything , right ? so you have to come up with this number from something else .
G: but you are not doing it now language dependent ?
E: it 's not . it 's just something that 's fixed .
G: it 's overall .
D: but what he is doing language dependent is measuring what that number reference is that he comes down twenty - five down from .
E: because did it started working on italian . obtained this average energy and then used this one .
B: for all the languages .
D: so it 's arbitrary .
E: so the next thing is to use this as maybe initialization and then use something on - line .
D: something more adaptive ,
E: but and expect improvement at least in finnish because the way for italian and spanish it 's th this value works good but not necessarily for finnish . but unfortunately there is , like , this forty millisecond latency so would try to somewhat reduce this @ @ . already know that if completely remove this latency , so . , it there is three percent hit on italian .
G: your your smoothing was @ @ , over this so to say , the factor of the wiener . and then it 's , what was it ? this smoothing , it was over the subtraction factor , so to say .
E: it 's smoothing over the gain of the subtraction algorithm .
G: and and you are looking into the future , into the past .
E: so , to smooth this thing .
G: and did you try simply to smooth to smooth the to smooth stronger the envelope ? because , it should have similar effect if you you have now several stages of smoothing , so to say . you start up . as far as remember you smooth somehow the envelope , you smooth somehow the noise estimate , and later on you smooth also this subtraction factor .
E: it 's it 's just the gain that 's smoothed actually
B: actually do all the smoothing .
E: but it 's smoothed
G: it it was you .
E: no , in this case it 's just the gain . but the way it 's done is that , for low gain , there is this non nonlinear smoothing actually . for low gains , use the smoothed sm , smoothed version but for high gain @ @ it 's don't smooth .
G: it experience shows you , if you do the the best is to do the smoo smoothing as early as possible . so when you start up . you start up with the somehow with the noisy envelope . and , best is to smooth this somehow .
E: could try this .
B: so , before estimating the snr , @ @ smooth the envelope .
E: then would need to find way to like smooth less also when there is high energy . cuz noticed that it helps little bit to like smooth more during low energy portions and less during speech , because if you smooth then you distort the speech .
G: you could do it in this way that you say , if you if 'm you have somehow noise estimate , and , if you say 'm with my envelope 'm close to this noise estimate , then you have bad signal - to - noise ratio and then you would like to have stronger smoothing . so you could you could base it on your estimation of the signal - to - noise ratio on your actual
B: or some silence probability from the vad if you have
E: but don't trust the current vad .
B: so not right now maybe .
D: the vad later will be much better .
F: so is that it ?
E: fff that 's it .
G: so to summarize the performance of these , speechdat - car results is similar than yours so to say .
B: so the fifty - eight is like the be some fifty - six point
G: you have you have fifty - six point four
B: that 's true .
G: and and dependent on this additive constant , it is better or worse .
E: the condition where it 's better than your approach , it 's it just because maybe it 's better on matched and that the weight on matched is bigger ,
B: you caught up . that 's true .
E: if you don't weigh differently the different condition , you can see that your , the win the two - stage wiener filtering is maybe better it 's better for high mismatch , right ?
B: it 's better for high mismatch .
E: but little bit worse for matched .
B: so over all it gets , , worse for the matched condition ,
F: so we need to combine these two .
B: that 's that 's the best thing , is like the french telecom system is optimized for the matched condition . so they know that the weighting is good for the matched , and so there 's everywhere the matched 's performance is very good for the french telecom . we are we may also have to do something similar @ @ .
D: our tradition here has always been to focus on the mismatched . cuz it 's more interesting .
G: mu - my mine was it too , . before started working on this aurora .
H: only say that the this is , summary of the of all the vts experiments and say that the result in the last , for italian the last experiment for italian , are bad . make mistake when write . up at copy one of the bad result . there . , this . if we put everything , we improve lot the spectral use of the vts but the final result are not still mmm , good like the wiener filter . maybe it 's @ @ it 's possible to have the same result . because have , mmm , worse result in medium mismatch and high mismatch .
B: you you have better you have some results that are good for the high mismatch .
H: someti are more or less similar but are worse . still don't have the result for ti - digits . the program is training . maybe for this weekend will have result ti - digits and complete that like this . one thing that note are not here in this result but are speak are spoken before with sunil improve my result using clean lda filter . if use , , the lda filter that are training with the noisy speech , that hurts the res my results .
D: so what are these numbers here ? are these with the clean or with the noisy ?
H: this is with the clean . with the noise have worse result , that if doesn't use it . but that may be because with this technique we are using really clean speech . the speech the representation that go to the htk is really clean speech because it 's from the dictionary , and maybe from that . because that you did some experiments using the two the two lda filter , clean and noi and noise , and it doesn't matter too much .
E: but it doesn't matter on speechdat - car , but , it matters , , lot on ti - digits .
B: using the clean filter .
H: it 's better to use clean .
E: it 's much better when you we used the clean derived lda filter .
H: maybe you can do also this . to use clean speech .
E: sunil in your result it 's
B: 'll try the cle no , my result is with the noisy lda .
E: it 's with the noisy one .
B: it 's with the noisy . it 's it 's not the clean lda . it 's in in the front sheet , have like the summary .
D: and and your result is with the
E: it 's with the clean lda .
B: this is your results are all with the clean lda result ?
H: with the clean lda .
E: and in your case it 's all noisy ,
H: is that the reason ?
E: but observe my case it 's in , , at least on speechdat - car it doesn't matter but ti - digits it 's like two or three percent absolute , , better .
B: on ti - digits this matters .
D: so you really might wanna try the clean .
B: will have to look at it . that 's true .
D: that could be sizeable right there .
H: and this is everything .
G: maybe you are leaving in about two weeks carmen . so , if if would put it put on the head of project mana manager would say , , there is not so much time left now .
D: be my guest .
G: what would do is would pick @ @ the best consolation , which you think , and create all the results for the whole database that you get to the final number as sunil did it
H: and prepare at the
G: and maybe also to write somehow document where you describe your approach , and what you have done .
H: was thinking to do that next week .
D: 'll 'll borrow the head back and agree .
H: wi will do that next week .
D: that 's that 's actually the , the spanish government , , requires that anyway . they want some report from everybody who 's in the program . and 'd we 'd like to see it too .
F: what 's do you think we , , should do the digits or skip it ? or what are what do you think ?
D: we have them now ? why don why don't we do it ? just just take minute .
F: would you pass those down ? so 'll go ahead .
E: is it the channel , or the mike ? it 's the mike ? it 's not four .
H: this is date and time . on the channel , channel .
G: what is this ?
F: if you could just leave , , your mike on top of your , , digit form fill in any information that 's missing . didn't get chance to fill them out ahead of time . we 're gonna have to fix that . let 's see , it starts with one here , and then goes around and ends with nine here .
A: so 'm eight ,
F: so he 's eight ,
A: you 're seven .
F: you 're seven ,
","Another weekly meeting on ICSI's Meeting Recorder Group at Berkeley , though the members are joined by a visiting researcher.
The groups regulars reported progress on their work on mean subtraction , noise estimation , voice activity detection and the Vector Taylor Series.
While on these topics , related areas discussed included recognition window length , training versus test set sizes , artificial distortion and latency concerns.
Speaker fn002 is soon to be leaving the group , and so she will choose her best setup , run a complete set of experiments , and write up her work , procedure and results for next week.
New filters introduced to reduce latency by mn052  , performed slightly worse than those they replaced.
Whereas mn007 has added some latency to the process which he feels he can reduce.
Speaker me026 has been working on mean subtraction , his most recent results are suspiciously poor , and he is attempting to integrate the method into the SmartKom system.
Speaker mn052 has been looking at noise estimation , because he was getting better results with one data set than another.
Speaker mn007 has been looking at VAD performance , and getting some good results , though nothing that hasn't been produced before.
Speaker fn002 has been running VTS experiments , but her results aren't particularly impressive.
Speaker me006 has been working on the proposal for his thesis and outlined his idea.
"
ami_abstractive_summary,Bmr006.txt,"F: that 's looks strange .
B: now we 're on and it seems to be working .
E: there we go .
C: one two three four five six
A: that is weird .
E: this looks good .
A: it 's like when it 's been sitting for long time .
B: what it is . but all that it seems like every time am up here after meeting , and start it , it works fine . and if 'm up here and start it and we 're all sitting here waiting to have meeting , it gives me that error message and have not yet sat down with been able to get that error message in point where sit down and find out where it 's occurring in the code .
A: next time you get it maybe we should write it down .
B: one of these days .
E: was it pause , or ? was it on "" pause "" ?
D: so so the , the new procedural change that just got suggested , which is good idea is that , we do the digit recordings at the end . and that way , if we 're recording somebody else 's meeting , and number of the participants have to run off to some other meeting and don't have the time , , then they can run off . it 'll mean we 'll get somewhat fewer , sets of digits , but , that way we 'll cut into people 's time , , if someone 's on strict time , less . so , th we should start doing that . so , , let 's see , we were having discussion the other day , maybe we should bring that up , about , the nature of the data that we are collecting . @ @ that , we should have fair amount of data that is , collected for the same meeting , so that we can , wh - what were some of the points again about that ?
F: , , 'll back up . at the previous at last week 's meeting , this meeting was griping about wanting to get more data and talked about this with jane and adam , and was thinking of this mostly just so that we could do research on this data , since we 'll have new this new student di does wanna work with us , th the guy that was at the last meeting . and he 's already funded part - time , so we 'll only be paying him for for half of the normal part - time ,
B: and what 's he interested in , specifically ?
F: he 's comes from signal - processing background , but liked him lot cuz he 's very interested in higher level things , like language , and disfluencies and all kinds of eb maybe prosody , so he 's just getting his feet wet in that . anyway , , maybe we should have enough data so that if he starts he 'd be starting in january , next semester that we 'd have , , enough data to work with . but , , jane and adam brought up lot of good points that just posting note to berkeley people to have them come down here has some problems in that you you need to make that the speakers are who you want and that the meeting type is what you want , and . so , about that and it 's still possible , but 'd rather try to get more regular meetings of types that we know about , and hear , then mish - mosh of bunch of one - time just because it would be very hard to process the data in all senses , both to get the , to figure out what type of meeting it is and to do any higher level work on it , like , was talking to morgan about things like summarization , or what 's this meeting about . it 's very different if you have group that 's just giving report on what they did that week , versus coming to decision and . so . then was , talking to morgan about some new proposed work in this area , separate issue from what the student would be working on where was thinking of doing some summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to hot spots in the meeting , or things where is going on that might be important for someone who didn't attend to listen to . and in that , regard , we definitely will need it 'd it 'd be for us to have bunch of data from few different domains , or few different kinds of meetings . so this meeting is one of them , although 'm not participate if would feel very strange being part of meeting that you were then analysing later for things like summarization . and then there are some others that menti that morgan mentioned , like the front - end meeting and maybe networking group meeting .
B: we 're we 're hoping that they 'll let us start recording regularly .
F: so if that were the case then we 'd have enough . but , for anything where you 're trying to get summarization of some meeting meaning out of the meeting , , it would be too hard to have fifty different kinds of meetings where we didn't really have good grasp on what does it mean to summarize , but rather we should have different meetings by the same group but hopefully that have different summaries . and then we need couple that of we don't wanna just have one group because that might be specific to that particular group , but @ @ three or four different kinds .
B: we have lot of overlap between this meeting and the morning meeting .
F: see , 've never listened to the data for the front - end meeting .
B: we 've only had three .
F: but maybe that 's enough . so , in general , was thinking more data but also data where we hold some parameters constant or fairly similar , like meeting about of people doing certain work where at least half the participants each time are the same .
D: now , let let me just give you the other side to that cuz ca because don't disagree with that , but there is complimentary piece to it too . for other kinds of research , particularly the acoustic oriented research , actually feel the opposite need . 'd like to have lots of different people . as many people here and talking about the thing that you were just talking about it would have too few people from my point of view . 'd like to have many different speakers . so , would also very much like us to have fair amount of really random scattered meetings , of somebody coming down from campus , and , , if we can get more from them , fine , but if we only get one or two from each group , that still could be useful acoustically just because we 'd have close and distant microphones with different people .
F: definitely agree with that .
E: can say about that the issues that adam and raised were more matter of advertising so that you get more native speakers . because if you just say an and in particular , my suggestion was to advertise to linguistics grad students because there you 'd have so people who 'd have proficiency enough in english that , it would be useful for purposes . but , 've been 've gathered data from undergrads at on campus and if you just post randomly to undergrads you 'd get such mixed bag that it would be hard to know how much conversation you 'd have . and and the english you 'd have the language models would be really hard to build because it would not really be it would be an interlanguage rather than
D: , , first place , don't think we 'd just want to have random people come down and talk to one another , there should be meeting that has some goal and point cuz that 's what we 're investigating ,
F: it has to be pre - existing meeting , like meeting that would otherwise happen anyway .
D: so was was thinking more in terms of talking to professors , and and , senior , and , doctoral students who are leading projects and offering to them that they have their hold their meeting down here .
F: that 's what we and agree with .
D: that 's the first point . the second point is that for some time now , going back through berp that we have had speakers that we 've worked with who had non - native accents and th that
E: . 'm not saying accents . the accent 's not the problem . no , it 's more matter of , proficiency , just simply fluency . deal with people on campus who sometimes people , undergraduates in computer science , have language skills that make , that their fluency and writing skills are not so strong .
D: you 're not talking about foreign language .
B: , just talking about .
D: you 're just talking about
B: we all had the same thought .
E: but , it 's like when you get into the graduate level , , no problem . 'm not saying accents .
D: then we 're completely gone .
E: 'm say 'm saying fluency .
D: it 's the the habits are already burnt in .
E: 'm just saying fluency .
B: that , that the only thing we should say in the advertisement is that the meeting should be held in english . and and if it 's pre - existing meeting and it 's held in english , it 's probably if few of the people don't have , particularly good english skills .
E: now can say the other aspect of this from my perspective which is that , there 's there 's this issue , you have corpus out there , it should be used for multiple things cuz it 's so expensive to put together . and if people want to approach the idea of computational linguistics and probabilistic grammars and all may not be the focus of this group , but the idea of language models , which are fund generally speaking , , terms of like the amount of benefit per dollar spent or an hour invested in preparing the data , if you have choice between people who are pr more proficient in {nonvocalsound} , more fluent , more close to being academic english , then it would seem to me to be good thing . because otherwise you don't have the ability to have so if you have bunch of idiolects that 's the worst possible case . if you have people who are using english as as an interlanguage because they don't , they can't speak in their native languages and but their interlanguage isn't really match to any existing , , language model , this is the worst case scenario .
D: that 's what you 're going to have in the networking group . because they most the network group is almost entirely germans and spaniards .
E: but , that these people are of high enough level in their in their language proficiency that and 'm not objecting to accents . 'm 'm just thinking that we have to think at at higher level view , could we have language model , grammar grammar , , that , wo would be possibility . so so if you wanted to bring in model like dan jurafsky 's model , an and do some top - down , it to help th the bottom - up and merge the things or whatever , , it seems like , don't see that there 's an argument 'm what is that why not have the corpus , since it 's so expensive to put together , , useful for the widest range of central corp things that people generally use corpora for and which are , , used in computational linguistics . that 's that 's my point . which which includes both top - down and bottom - up .
C: it 's difficult .
D: , let 's let 's see what we can get . it that if we 're aiming at , groups of graduate students and professors and who are talking about things together , and it 's from the berkeley campus , probably most of it will be ,
E: yes , that 's fine . that 's fine . and my point in in my note to liz was that undergrads are an iff iffy population .
F: definitely agree with that , , for this purpose .
B: not to mention the fact that would be hesitant certainly to take anyone under eighteen , probably even an anyone under twenty - one .
E: grads and professors , fine .
D: you age - ist !
B: what 's that ? age - ist . the "" eighteen "" is because of the consent form .
E: age - ist .
B: we 'd hafta get find their parent to sign for them .
C: "" age - ist "" .
E: that 's true .
F: have , , question . morgan , you were mentioning that mari may not use the equipment from ibm if they found something else , cuz there 's
D: they 're they 're , they 're they 're assessing whether they should do that or do something else , hopefully over the next few weeks .
F: cuz , one remote possibility is that if we st if we inherited that equipment , if she weren't using it , could we set up room in the linguistics department ? and and , there may be lot more or in psych , or in comp wherever , in another building where we could , record people there . we 'd have better chance
B: we 'd need real motivated partner to do that . we 'd need to find someone on campus who was interested in this .
F: but if there were such it 's remote possibility , then , , one of us could , go up there and record the meeting rather than bring all of them down here . so it 's just thought if they end up not using the hardware .
D: the other thing , the other thing that was hoping to do in the first place was to turn it into some portable thing so you could wheel it around . but . , and
B: know that space is really scarce on at least in cs . to actually find room that we could use regularly might actually be very difficult .
F: but you may not need separate room , ,
B: that 's true .
F: the idea is , if they have meeting room and they can guarantee that the equipment will be safe and , and if one of us is up there once week to record the meeting
D: maybe john would let us put it into the phonology lab .
F: it 's not out of the question .
B: it would be interesting because then we could regularly get another meeting . another type of meeting .
C: but you need , , another portable thing another portable equipment to do , , more easier the recording process , , out from icsi . and probably . . if you want to record , , seminar or class , , in the university , you need it - it would be very difficult to put , , lot of , , head phones in different people when you have to record only with , , this , , device .
B: if we if we wanna just record with the tabletop microphones , that 's easy . that 's very easy ,
C: ye - , .
B: but that 's not the corpus that we 're collecting .
D: actually , that 's int that raises an interesting point that came up in our discussion that 's maybe worth repeating . we realized that , , when we were talking about this that , , there 's these different things that we want to do with it . so , , it 's true that we wanna be selective in some ways , , the way that you were speaking about with , , not having an interlingua and , these other issues . but on the other hand , it 's not necessarily true that we need all of the corpus to satisfy all of it . so , as per the example that we wanna have fair amount that 's done with small recorded with small , , typ number of types of meetings but we can also have another part that 's , , just one or two meetings of each of of range of them and that 's too . we realized in discussion that the other thing is , what about this business of distant and close microphones ? we really wanna have substantial amount recorded this way , that 's why we did it . but what about for th for these issues of summarization , lot of these higher level things you don't really need the distant microphone .
B: and you don't really need the close microphone , you mean .
D: you actually don't .
F: yea - , you actually don't really even need any fancy microphone .
E: which one did you mean ?
D: you you don't ne it doesn't you just need some microphone , somewhere .
B: ye - . .
F: you can use found data . you you can .
D: you need some microphone ,
F: use , but that any data that we spend lot of effort {nonvocalsound} to collect , each person who 's interested in , we have cou we have bunch of different , , slants and perspectives on what it 's useful for , , they need to be taking charge of making they 're getting enough of the data that they want . and so in my case , , there there is enough data for some kinds of projects and not enough for others .
B: not enough for others , right .
F: and so {nonvocalsound} 'm looking and thinking , "" 'd be glad to walk over and record people and so {nonvocalsound} forth if it 's to help th in my interest . "" and other people need to do that for themselves , , or at least discuss it so that we can find some optimal
D: right . so that but that 'm raising that cuz it 's relevant exactly for this idea up there that if you think about , "" , gee , we have this really complicated setup to do , "" maybe you don't .
B: for some of it .
D: maybe if if really all you want is to have recording that 's good enough to get , transcription from later , you just need to grab tape recorder and go up and make recording . we could have fairly we could just get dat machine and
F: agree with {nonvocalsound} jane , though , on the other hand that so that might be true , you may say , summarization , that sounds very language oriented . you may say , "" , you just do that from transcripts of radio show . "" you don't even need the speech signal . but what you what was thinking is long term what would be neat is to be able to pick up on suppose you just had distant microphone there and you really wanted to be able to determine this . there 's lots of cues you 're not gonna have . so do think that long term you should always try to satisfy the greatest number of interests and have this parallel information , which is really what makes this corpus powerful . otherwise , , lots of other sites can propose individual studies , so
D: but that the we can't really underestimate the difficulty shouldn't really underestimate the difficulty of getting setup like this up . and so , it took quite while to get that together and to say , "" , we 'll just do it up there , "" if you 're talking about something simple , where you throw away lot of these dimensions , then you can do that right away . talking about something that has all of these different facets that we have here , it won't happen quickly , it won't be easy , and there 's all sorts of issues about th keeping the equipment safe , or else hauling it around , and all sorts of
F: so then maybe we should {nonvocalsound} try to bring people here .
D: the first priority should be to pry to get try to get people to come here .
F: that 's that 's
D: we 're set up for it . the room is really , , underused .
E: the free lunch idea was great idea .
D: free lunch is good .
F: and we can get people to come here , that but the issue is you definitely wanna make that the group you 're getting is the right group so that you don't waste lot of your time {nonvocalsound} and the overhead in bringing people down .
A: no crunchy food .
F: so , it would be lunch afterwards .
B: was thinking , lunch after .
F: and they 'd have to do their digits or they don't get dessert .
D: they have to do their digits or they don't get they don't get their food .
B: had spoke with some people up at haas business school who volunteered . should pursue that ? they they originally they 've decided not to do go into speech . so 'm not whether they 'll still be so willing to volunteer , but 'll send an email and ask .
D: tell them about the free lunch .
B: 'll tell them about the free lunch . and they 'll say there 's no such thing .
F: 'd love to get people that are not linguists or engineers , cuz these are both weird
D: the the the oth the other
F: know , shouldn't say that .
B: that 's alright . no , the they 're very weird .
F: we need wider sampling .
A: "" beep . ""
B: the problem with engineers is "" beep . ""
D: they make funny sounds . the the other the other thing is , , that we talked about is give to them , burn an extra cd - rom .
B: let them have their meeting .
D: and give them so if they want {nonvocalsound} and audio record of their
F: that was he meant , "" give them music cd , "" like they then he said cd of the of their speech and it depends of what audience you 're talking to , but , personally {nonvocalsound} would not want {nonvocalsound} cd of my meeting ,
B: mmm . of the meeting ?
F: but maybe , maybe you 're
D: if you 're having some planning meeting of some sort and you 'd like
F: right . right . right .
A: that 's good idea .
B: it 'd be fun . it would just be fun , , if nothing else , . it 's novelty item .
D: but it als it it also builds up towards the goal . we 're saying , "" look , , you 're gonna get this . is - is isn't that neat . then you 're gonna go home with it . it 's actually it 's probably gonna be pretty useless to you , but you 'll ge appreciate , , where it 's useful and where it 's useless , and then , we 're gonna move this technology , so it 'll become useful . ""
F: no , that 's great idea , actually .
A: what if you could tell them that you 'll give them the transcripts when they come back ?
F: but we might need little more to incentivize them , that 's all .
B: anyone can have the transcripts . so . we could point that out .
F: that 's interesting .
E: hav have to raise little eensy - weensy concern about doing th giving them the cd immediately , because of these issues of , , this , where maybe ?
D: that 's very good point . so we can so we can
E: we could burn it after it 's been cleared with the transcript stage . and then they get cd , but just not the same day .
B: that 's right .
F: if it should be the same cd - rom that we distribute publically ,
B: that 's good point . right , it can't be the internal one .
F: otherwise they 're not allowed to play it for anyone .
E: there we go .
B: that 's right .
E: put . put . so , after the transcript screening phase .
B: that 's true .
E: things have been weeded out .
F: otherwise we 'd need two lawyer stages .
E: that 's right , say "" , , got this cd , and , your honor , ""
F: that 's good point .
D: so that 's so let 's start with haas , and .
F: to have to {nonvocalsound} have to leave .
D: that 's fine .
F: will be here full - time next week .
D: that 's alright . so , let 's see . so that was that topic , and then , another topic would be where are we in the whole disk resources question
B: we are slowly getting to the point where we have enough sp room to record meetings . so did bunch of archiving , and still doing bunch of archiving , 'm in the midst of doing the - files from , broadcast news . and it took eleven hours to do to copy it . and it 'll take another eleven to do the clone .
A: where did you copy it to ?
B: it 's abbott . it 's abbott , so it just but it 's it 's lot of data .
D: sk - it 's copying from one place on abbott to another place on abbott ?
A: on the tape .
B: did an archive . so 'm archiving it , and then 'm gonna delete the files . so that will give us ten gigabytes of free space .
E: the archiving program does take long time .
B: and so one that that will be done , like , in about two hours . and so , at that point we 'll be able to record five more meetings .
E: one thing the good news about that is that once it 's archived , it 's pretty quick to get back . it the other direction is fast , but this direction is really slow .
B: especially because 'm generating clone , also . so . and that takes while .
E: that 's good point .
B: one offsite , one onsite .
E: now , what will is the plan to to so will be saved , it 's just that you 're relocating it ? so we 're gonna get more disk space ?
B: no , the these are the - files from broadcast news , which are regeneratable if we really need to , but we had lot of them . and for the full , , hundred forty hour sets . and so they were two gigabytes per file and we had six of them .
D: we are getting more space . we are getting , , another disk rack and four thirty - six gigabyte disks . so but that 's not gonna happen instantaneously .
B: or maybe six .
D: or maybe six ?
B: the sun , ha , takes more disks than the andatico one did . the sun rack takes th - one took four and one took six , or maybe it was eight and twelve . whatever it was , it was , , fifty percent more .
A: is there difference in price ?
B: what happened is that we bought all our racks and disks from andatico for years , according to dave , and andatico got bought by another company and doubled their prices . and so , , we 're looking into other vendors . "" we "" by "" we "" dave .
A: 've been looking at the , , aurora data and , , first look at it , there were three directories on there that could be moved . one was called aurora , one was spanish , which was carmen 's spanish , and the other one was , , spine . and so , , wrote to dan and he was very concerned that the spine was moving to non - backed - up disk . so , , realized that , probably not all of that should be moved , just the cd - rom type data , the static data . so moved that , and then , asked him to check out and see if it was . before actually deleted the old , , but haven't heard back yet . told him he could delete it if he wanted to , haven't checked today to see if he 's deleted it or not . and then carmen 's , realized that when had copied all of her to xa , had copied there that was dynamic data . and so , had to redo that one and just copy over the static data . and so need to get with her now and delete the old off the disk . and then lo haven't done any of the aurora . have to meet with , , stephane to do that .
D: so , but , you 're figuring you can record another five meetings with the space that you 're clearing up from the broadcast news , but , we have some other disks , some of which you 're using for aurora , but are we do we have some other space now ?
B: so , so , , we have space on the current disk right now , where meeting recorder is , and that 's probably enough for about four meetings .
A: is that the one that has is that dc ?
B: no , no , it 's wherever the meeting recorder currently is . it 's di .
A: but the 'm moving from aurora is on the dc disk that we
B: th - it 's dc - it 's whatever that one is . don't remember , it might be dc . and that has enough for about four more meetings right now . we were at hundred percent and then we dropped down to eighty - six for reasons don't understand . someone deleted something somewhere . and so we have some room again . and then with broadcast news , that 's five or six more meetings , so , , we have couple weeks . so , , we 're , until we get the new disk .
A: so should , one question had for you was , , we need we sh probably should move the aurora an and all that other off of the meeting recorder disk . is there another backed - up disk that of that would ?
B: we should put it onto the broadcast news one . that 's probably the best thing to do . and that way we consolidate meeting recorder onto one disk rather than spreading them out .
A: do what happen to disk that is off ?
B: tell you , off the top of my head .
A: alright , 'll find out from you .
B: but , so we could ' jus just do that at the end of today , once the archive is complete , and 've verified it . cuz that 'll give us plenty of disk .
D: , @ @ so , , then th the last thing 'd had on my agenda was just to hear an update on what jose has been doing ,
C: have , , the result of my work during the last days . for your information because read . , and the last , , days , , work , , in my house , , in lot of ways and thinking , reading , different things about the meeting recording project . and have , , some ideas . this information is very useful . because you have the the distribution , now .
E: 'm glad to hear it . glad to hear it .
C: but for me , is interesting because , , here 's is the demonstration of the overlap , , problem .
B: 've seen it already .
C: it 's real problem , frequently problem , because you have overlapping zones , , all the time .
B: throughout the meeting .
C: by moment have , , nnn , the , , did mark of all the overlapped zones in the meeting recording , with , exact mark .
B: you did that by hand ?
C: heh ? that 's , yet , by by hand by hand because , , "" why . ""
B: can see that ? can get copy ?
C: my my idea is to work do don't @ @ , , if , , it will be possible because haven't lot , enough time to to work . , only just , six months , as , but , , my idea is , , is very interesting to work in the line of , , automatic segmenter . but , in my opinion , we need , reference session to to evaluate the the tool .
B: and so are you planning to do that or have you done that already ?
C: and no , no , with
B: have you done that or are you planning to do that ?
C: no , plan to do that . plan plan , but , the idea is the following . now , , need ehm , to detect all the overlapping zones exactly . will will , talk about , in the in the blackboard about the my ideas . , this information , with , exactly time marks , for the overlapping zones overlapping zone , and , speaker pure speech , speaker zone . zones of speech of , one speaker without any , noise , any acoustic event that , , is not , speech , real speech . and , need true , silence for that , because my idea is to study the nnn the set of parameters , what , , are more more discriminant to , classify . the overlapping zones in cooperation with the speech zones . the idea is to to use , 'm not to yet , but my idea is to use cluster algorithm or , nnn , person strong in neural net algorithm to to study what is the , , the property of the different feat feature , , to classify speech and overlapping speech . and my idea is , it would be interesting to have , control set . and my control set , will be the , silence without , any noise .
E: which means that we 'd still you 'd hear the
C: acoustic with this . with with , , the background .
E: that 's interesting . this is like ground level , with it 's not it 's not total silence .
C: , noise , claps , tape clips , , the difference , event , which , , has , , hard effect of distorti spectral distortion in the in the speech .
B: so so you intend to hand - mark those and exclude them ?
C: have mark in in that not in all in all the file , only , nnn , mmm , have , ehm don't remind what is the the quantity , but , have marked enough speech on over and all the overlapping zones . have , , two hundred and thirty , more or less , overlapping zones , and is similar to this information ,
E: great . great .
C: because with the program , cross the information of , of jane with , my segmentation by hand . and is , mor more similar .
E: glad to hear it .
C: and the idea is , , will use , , want my idea is , , to {nonvocalsound} to classify .
B: should 've got the digital camera .
C: need , the exact , mark of the different , , zones because want to put , , for , each frame label indicating . it 's sup supervised and , , hierarchical clustering process . put , , for each frame {nonvocalsound} label indicating what is th the type , what is the class , , which it belong . , the class you will {nonvocalsound} overlapping speech "" overlapping "" is class , , "" speech "" {nonvocalsound} @ @ the class that 's
A: these will be assigned by hand ?
C: ha put the mark by hand , because , , my idea is , , in the first session , need , , need , , to be that the information , that , , will cluster , is right . because , , if not , , will will , , return to the speech file to analyze , what is the problems ,
B: training , and validation . .
C: and 'd prefer would prefer , the to have , , this labeled automatically , but , , fro th need truth .
A: you need truth . .
B: but this is what you 're starting with .
E: 've gotta ask you . so , , the difference between the top two , so so start at the bottom , so "" silence "" is clear . by "" speech "" do you mean speech by one sp by one person only ? so this is un , and then the top includes people speaking at the same time , or speaker and breath overlapping , someone else 's breath , or clicking , overlapping with speech so , that 's all those possibilities in the top one .
B: one or two or more .
C: one , two , three . no , by th by the moment . . in the first moment , because , , have information , , of the overlapping zones , , information about if the , , overlapping zone is , , from speech , clear speech , from one to two speaker , or three speaker , or is the zone where the breath of speaker , overlaps , onto , speech , another , especially speech .
E: so it 's basi it 's speech wi som with something overlapping , which could be speech but doesn't need to be .
C: no , no , es especially , overlapping speech from , , different , speaker .
D: no , but there 's but , she 's saying "" where do you in these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? "" which category do you put that in ?
E: that 's right . that 's my question .
C: he here put speech from , from , , one speaker without , , any any events more .
D: right , so where do you put speech from one speaker that does have nonspeech event at the same time ?
C: where ? where what is the class ?
D: which catege which category ?
C: no . by the moment , no .
B: , that 's what he was saying before .
C: for for the by the @ @ no , @ @ because want to limit the nnn , the study .
D: so you not marked .
E: so you don't it 's not in that
D: fine . so so
A: so you 're not using all of the data .
B: so that 's what he was saying before , is that he excluded those .
C: the all exactly .
E: so you 're ignoring overlapping events unless they 're speech with speech .
D: that 's fine .
C: what 's the reason ? "" because it 's the first study .
D: no , it 's perfectly sensible way to go . we just wondered trying to understand what you were doing .
E: cuz you 've talked about other overlapping events in the past . so , this is subset .
C: in the in the future , the idea is to extend the class , to consider all the all the information , you mentioned before
D: , don't think we were asking for that .
C: but , the first idea because , what hap what will happen with the study .
D: we were jus just trying to understand
E: we just wanted to the category was here .
A: is your silence category pure silence , or ? what if there was door - slam ?
C: no , no , it 's pure silence . it 's the control set . it 's the control set . it 's pure si pure silence with the machine on the on the roof .
D: what you what you mean is that it 's nonspeech segments that don't have impulsive noises .
B: with the fan .
D: cuz you 're calling what you 're calling "" event "" is somebody coughing or clicking , or rustling paper , or hitting something , which are impulsive noises . but steady - state noises are part of the background . which , are being , included in that .
C: here yet , yet , , there are that some noises that , , don't don't wanted to be in that , , in that control set .
E: so it 's like signal - noise situation .
C: but prefer , prefer at the first , , the silence with , this this the of of noise .
D: right , it 's , it 's "" background "" might be might be better word than "" silence "" . it 's just that the background acoustic
B: right . so fine . go on .
C: and , , with this information the idea is , nnn , have label for each , , frame and , with cluster algorithm and
E: we needed to get the categories , .
C: and am going to prepare test bed , , , , set of feature structure , models . and my idea is
B: "" tone "" , whatever .
C: so on because have pitch extractor yet . have to test , but
A: you have your own ?
C: ha have prepare . is modified version of of pitch tracker , , from , , standar - stanford university from , , , cambridge university .
A: what 's it written in ?
C: , don't remember what is the name of the of the author , because have several have , , , library tools , from , festival and of from edinburgh , from cambridge , , and from our department .
D: - . - .
C: and have to because , in general the pitch tracker , doesn't work very and
B: but , , as feature , it might be . so , we .
C: this this is and th the idea is to , , to obtain , , , , diff , different , no , great number of fec , , , twenty - five , , thirty parameters , , for each one . and in first , nnn , step in the investi in the research in , my idea is try to , , to prove , what is the performance of the difference parameter , to classify the different , , what is the the front - end approach to classify , the different , , frames of each class and what is the , nnn , nnn , , what is the , the error , of the data this is the , first idea and the second is try to , to use some ideas , similar to the linear discriminant analysis . similar , because the idea is to study what is the contribution of , each parameter to the process of classify correctly the different the different parameters .
B: what classifier ar ?
C: the the classifier is nnn by the moment is is , similar , nnn , that the classifier used , in quantifier vectorial quantifier is , used to , some distance to put , vector , in class different . is ? with model , is only to cluster using , @ @ or similarity .
B: so is it just one cluster per
C: another possibility it to use netw neural network . but what 's the what is my idea ? what 's the problem see in in if you use the neural network ? if when this , mmm , cluster , clustering algorithm to can test , to can observe what happened you can't you can't , put up with your hand in the different parameter ,
B: right , you can't analyse it .
C: but if you use neural net is good idea , but you what happened in the interior of the neural net .
D: actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are . it 's hard to what you it 's hard to tell on neural net is what 's going on internally . but it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized .
B: using something simpler first is probably fine .
D: this isn't tru if if you really wonder what different if then decision tree is really good , but here he 's he 's not like he has one , bunch of very distinct variables , like pitch and this he 's talking about , like , all these cepstral coefficients , and , in which case any reasonable classifier is gonna be mess , and it 's gonna be hard to figure out what
C: will include too the the differential de derivates too .
D: the other thing that one , this is , good thing to do , to look at these things at least see what 'd let me tell you what would do . would take just few features . instead of taking all the mfcc 's , or all the plp 's or whatever , would just take couple . like like - one , - two , something like that , so that you can visualize it . and look at these different examples and look at scatter plots . so before you do build up any fancy classifiers , just take look in two dimensions , at how these things are split apart . that will give you lot of insight of what is likely to be useful feature when you put it into more complicated classifier . and the second thing is , once you actually get to the point of building these classifiers , @ @ what this lacks so far is the temporal properties . so if you 're just looking at frame and time , you anything about , , the structure of it over time , and so you may wanna build @ @ build markov model of some sort , or else have features that really are based on on some bigger chunk of time . but this is good place to start . but don't anyway , this is my suggestion , is don't just , , throw in twenty features at it , the deltas , and the delta del and all that into some classifier , even if it 's - nearest - neighbors , you still won't know what it 's doing , even it 's to it 's to have better feeling for what it 's look at som some picture that shows you , "" here 's these things , are offer some separation . "" and , , in lpc , , the thing to particularly look at is , is something like , , the residual
E: it strikes me that there 's another piece of information , that might be useful and that 's simply the transition . so , if you go from transition of silence to overlap versus transition from silence to speech , there 's gonna be big informative area there , it seems to me .
C: . but is my my own vision , of the of the project . the meeting recorder project , for me , has , two , has several parts , several objective because it 's great project . but , at the first , in the acoustic , , parts of the project , you we have two main objective . one one of these is to to detect the change , the acoustic change . and for that , if you don't use , , , speech recognizer , broad class , or not broad class to try to to label the different frames , the ike criterion or bic criterion will be enough to detect the change . and probably . would like to prove . probably . when you have , the transition of speech or silence to overlap zone , this criterion is enough with probably with , , this , the the more use used normal , regular parameter mf - mfcc . you have to to find you can find the mark . you can find the nnn , the acoustic change . but understand that you your objective is to classify , to know that that zone not is only new zone in the in the file , that you have , but you have to to know that this is overlap zone . because in the future you will try to process that zone with non - regular speech recognizer model , suppose . you will pretend to process the overlapping zone with another algorithm because it 's very difficult to to obtain the transcription from using regular , normal speech recognizer . that , , is the idea . and so the , nnn the {nonvocalsound} the system will have two models . model to detect more acc the mor most accurately possible that is , will be possible the , the mark , the change and another model will @ @ or several models , to try but several model robust models , sample models to try to classify the difference class .
B: 'm 'm , didn't understand you what you said . what what model ?
C: the classifiers of the to detect the different class to the different zones before try to recognize , with to transcribe , with speech recognizer . and my idea is to use , , neural net with the information we obtain from this this study of the parameter with the selected parameter to try to to put the class of each frame . for the difference zone you , have obtained in the first , step with the , bic , criterion compare model
D: but , in any event we 're that the first step is because what we had before for , speaker change detection did not include these overlaps . so the first thing is for you to build up something that will detect the overlaps . so again , the first thing to do to detect the overlaps is to look at these , in in again , the things you 've written up there are way too way too big . ? if you 're talking about , say , twelfth - order mfcc 's like that it 's just way too much . you won't be able to look at it . all you 'll be able to do is put it into classifier and see how it does . whereas if you have things if you pick one or two dimensional things , or three of you have some very fancy display , , and look at how the different classes separate themselves out , you 'll have much more insight about what 's going on .
C: it will be enough .
D: you 'll you 'll get feeling for what 's happening , , so if you look at suppose you look at first and second - order cepstral coefficients for some one of these kinds of things and you find that the first - order is much more effective than the second , and then you look at the third and there 's not and not too much there , you may just take first and second - order cepstral coefficients , and with lpc , lpc per se isn't gonna tell you much more than than the other , maybe . and on the other hand , the lpc residual , the energy in the lpc residual , will say how , the low - order lpc model 's fitting it , which should be pretty poorly for two or more people speaking at the same time , and it should be pretty , for for one . and so again , if you take few of these things that are prob promising features and look at them in pairs , , you 'll have much more of sense of "" , now have , doing bunch of these analyses , now have ten likely candidates . "" and then you can do decision trees or whatever to see how they combine .
A: 've got question .
C: but , it is the first way to do that and would like to , your opinion . all this study in the in the first moment , will pretend to do with equalizes speech . the the equalizes speech , the speech , the mixes of speech .
B: right . mixed .
C: the mix , mixed speech .
E: "" mixed "" . .
C: because the spectral distortion is more lot clearer , very much clearer if we compare with the pda . pda speech file is it will be difficult .
E: so it 's messier . the the pda is messier .
C: fff ! because the the noise to sp the signal - to - noise relation is is low .
B: that 's good way to start .
C: that the result of the of the study with with this this speech , the mix speech will work exactly with the pda files .
B: it would be interesting in itself to see . that would be an interesting result .
C: what , , what is the effect of the low ' signal to to noise relation , , with
D: it 's not it 's not unreasonable . it makes sense to start with the simpler signal because if you have features which don't aren't even helpful in the high signal - to - noise ratio , then there 's no point in putting them into the low signal ratio , one would think , anyway . and so , if you can get @ @ again , my prescription would be that you would , with mixed signal , you would take collection of possible , features look at them , look at how these different classes that you 've marked , separate themselves , and then collect , in pairs , and then collect ten of them , and then proceed with bigger classifier . and then if you can get that to work , then you go to the other signal . and then , and , they won't work as , but how , how much and then you can re - optimize , and so on .
B: but it it would be interesting to try couple with both . because it it would be interesting to see if some features work with close mixed , and and don't
D: that 's , the it it 's true that it also , it could be useful to do this exploratory analysis where you 're looking at scatter plots and so on in both cases . .
C: that the parameter we found , worked with both , speech file ,
E: that 's good .
C: but what is the the relation of of the performance when you use the , speech file the pda speech files . but it it will be important . because people , different groups has experience with this problem . is is not easy to solve , because if you have seen the the speech file from pda , and some parts is very difficult because you don't see the spectrum the spectrogram .
B: they 're hidden .
C: is very difficult to apply , parameter to detect change when you don't see .
D: that that 's another reason why very simple features , things like energy , and things like harmonicity , and residual energy are , are better to use than very complex ones because they 'll be more reliable .
B: are probably better , .
C: will put the energy here .
D: ch - chuck was gonna ask something .
C: you have question .
A: maybe this is dumb question , but it would be it would be easier if you used pda because can't you , couldn't you like use beam - forming to detect speaker overlaps ?
B: if you used the array , rather than the signal from just one .
D: no , you 're you 're right that , if we made use of the fact that there are two microphones , you do have some location information . which we don't have with the one and so that 's
A: is that not allowed with this project ?
D: , no , , we don't have any rules , really .
A: but didn't mean given given the goal .
D: it 's it 's it 's an additional interesting question .
A: is that violation of the
D: you wanna know whether you can do it with one , because it 's not necessarily true that every device that you 're trying to do this with will have two . if , on the other hand , we show that there 's huge advantage with two , then that could be real point . but , we don't even know yet what the effect of detecting having the ability to detect overlaps is . maybe it doesn't matter too much . so , this is all pretty early stages . but no , you 're right . that 's good thing to consider .
E: there there is complication though , and that is if person turns their back to the to the pda , then some of the positional information goes away ?
D: it it does , it it does , but the the issue is that
A: no , it 's not it 's not that so much as
E: and then , and if they 're on the access on the axis of it , that was the other thing was thinking . he you mentioned this last time , that if you 're straight down the midline , then the the left - right 's gonna be different ,
B: we hav need to put it on little turntable ,
E: and and in his case , , he 's closer to it anyway . it seems to me that it 's not , , it 's this the topograph the topology of it is little bit complicated .
B: but it 's another source of information .
C: because the distance between the two microph , microphone , , in the pda is very near . but it 's from my opinion , it 's an interesting idea to try to study the binaural problem , with information , because found difference between the speech from each micro , in the pda .
D: it 's timing difference . it - it 's not amplitude ,
E: ! agree ! and we use it ourselves . know that 's very important cue . but 'm just 'm just saying that the way we 're seated around table , is not the same with respect to each to each person with respect to the pda ,
C: no , no .
E: so we 're gonna have lot of differences with ref respect to the speaker .
D: that 's that 's fine .
A: but th don't think that matters , though .
D: that 's so so @ @ the issue is , "" is there clean signal coming from only one direction ? "" if it 's not coming from just one direction , if it if th if there 's broader pattern , it means that it 's more likely there 's multiple people speaking , wherever they are .
A: so it 's like how confused is it about where the beam is .
D: is it is it is there narrow is there narrow beam pattern or is it distributed beam pattern ? so if there 's distributed beam pattern , then it looks more like it 's it 's , multiple people . wherever you are , even if he moves around .
E: , it just it just seemed to me that , that this isn't the ideal type of separation . it 's see the value
D: ideal would be to have the wall filled with them , but but just having two mikes if you looked at that thing on dan 's page , it was when when there were two people speaking , and it looked really different .
A: what looked different ?
D: , basic he was looking at correlation .
B: cross - co cross - correlation .
D: just cross - correlation between two sides .
A: did - , 'm not what dan 's page is that you mean . he was looking at the two
D: so cross - correlation is pretty sensitive .
E: his web page .
D: you take the signal from the two microphones and you cros and you cross - correlate them with different lags .
B: and you find they get peaks .
D: so when one person is speaking , then wherever they happen to be at the point when they 're speaking , then there 's pretty big maximum right around that point in the in the lag . so if at whatever angle you are , at some lag corresponding to the time difference between the two there , you get this boost in the in the cross - correlation value function .
A: so so if there 's two
B: and if there are multiple people talking , you 'll see two peaks .
D: it 's spread out .
E: let me ask you , if both people were over there , it would be less effective than if one was there and one was across , catty - corner ?
D: the - the , 'm , if they 're right next to one another ?
A: if was if was here and morgan was there and we were both talking , it wouldn't work .
E: next next one over over on this side of the pda . there we go . good example , the same one 'm asking . versus you versus , and we 're catty - corner across the table , and 'm farther away from this one and you 're farther away from that one .
B: or or even if , like , if people were sitting right across from each other , you couldn't tell the difference either .
E: it seems like that would be pretty strong . across the same axis , you don't have as much to differentiate .
D: we , we don't have third dimension there . , so it 's
E: and so my point was just that it 's it 's gonna be differentially varia valuable . it 's not to say , certainly 's extremely val and we humans depend on , these binaural cues .
D: but it 's almost but it 's almost what you 're talking about there 's two things .
B: must do . .
D: there 's sensitivity issue , and then there 's pathological error issue . so th the one where someone is just right directly in line is pathological error . if someone just happens to be sitting right there then we won't get good information from it .
E: and and if there so it and if it 's the two of you guys on the same side
D: if they 're if they 're close , it 's just question of the sensitivity . so if the sensitivity is good enough and we just we just don't have enough , , experience with it to know how
E: 'm not 'm not trying to argue against using it , by any means . wanted to point out that weakness , that it 's topo topologically impossible to get it perfect for everybody .
B: and dan is still working on it . so . he actually he wrote me about it little bit ,
E: no , don't mean to discourage that .
D: the other thing you can do , if , we 're assuming that it would be big deal just to get somebody convince somebody to put two microphones in the pda . but if you put third in , you could put in the other axis . and then then you 're , then you could cover
A: once you got two what about just doing it from these mikes ?
C: it will be more interesting to study the pzm because the the separation
D: @ @ but - but that 's , we can we 'll be all of this is there for us to study .
B: then they 're much broader . we can do whatever we want .
D: but but , , one of the at least one of the things was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has pda .
B: whatever you 're interested in .
A: that 's what was asking about , what are the constraints ?
D: that 's that 's the constraint of one question that both adam and were were interested in . but if you can instrument room , this is really minor league compared with what some people are doing , right ? some people at , , at brown and at and at cape ,
B: big micro @ @ arrays .
A: didn't they have something at cape ?
D: they both have these , , big arrays on the wall . and , if you could do that , you 've got microphones all over the place tens of microphones ,
A: ! saw demo .
C: right , , .
D: and if you do that then you can really get very selectivity
B: saw one that was like hundred microphones , ten by ten array .
A: and you could in noisy room , they could have all kinds of noises and you can zoom right in on somebody .
B: and they had very precision .
C: very complex , .
D: ye - . .
B: it was all in software and they and you could pick out an individual beam and listen to it . it was , it was interesting .
D: but , the reason why haven't focused on that as the fir my first concern is because , 'm interested in what happens for people , random people out in some random place where they 're having an impromptu discussion . and you can't just always go , "" , let 's go to this heavily instrumented room that we spent tens of thousands of dollars to se to set up "" .
A: no , what you need to do is you 'd have little fabric thing that you unroll and hang on wall . it has all these mikes and it has plug - in jack to the pda .
D: the other thing actually , that gets at this little bit of something else 'd like to do , is what happens if you have two and they communicate with each other ? and then , they 're in random positions , the likelihood that , there wouldn't be any likely to be any nulls , if you even had two . if you had three or four it 's .
B: that 's on my web pages . all sorts of interesting things you can do with that , not only can you do microphone arrays , but you can do all sorts of multi - band as . so it 's it would be neat .
A: still like my rug on the wall idea , so if anybody patents that , then
E: you could have strips that you stick to your clothing .
B: in terms of the research th research , it 's really it 's whatever the person who is doing the research wants to do . so if jose is interested in that , that 's great . but if he 's not , that 's great too .
D: would actually like us to wind it down , see if we can still get to the end of the , , birthdays thing there .
B: catch some tea ? had couple things that did wanna bring out . one is , do we need to sign new these again ?
E: it 's slightly different . so would say it would be good idea .
A: are they new ?
E: cuz it 's slightly different .
D: this morning we didn't sign anything cuz we said that if anybody had signed it already , we didn't have to .
B: should 've checked with jane first , but the ch the form has changed .
E: it 's slightly different .
B: so we may wanna have everyone sign the new form . had some things wanted to talk about with the thresholding 'm doing .
E: had to make one
B: but , if we 're in hurry , we can put that off . and then also anonymity , how we want to anonymize the data .
E: should have some results to present , but we won't have time to do that this time . but it seems like the anonymization is , is also something that we might wanna discuss in greater length . if if we 're about to wind down , what would prefer is that we , delay the anonymization thing till next week , and would like to present the results that have on the overlaps .
A: we still have to do this , too , right ?
B: no - , we don't have to do digits .
D: so @ @ . @ @ it sounds like , there were there were couple technical things people would like to talk about . why don't we just take couple minutes to briefly do them , and then and then and then we
B: go ahead , jane .
E: 'd , 'd prefer to have more time for my results . could do that next week maybe ? that 's what 'm asking . and the anonymization , if if you want to proceed with that now , think that 's that 's discussion which also really deserves lo , more that just minute . really do think that , because you raised couple of possibilities yourself , you and have discussed it previously , and there are different ways that people approach it , and we should
B: we 're we 're just we 're getting enough data now that 'd like to do it now , before get overwhelmed with once we decide how to do it going and dealing with it .
E: . 'll give you the short version , but do 's an issue that we can't resolve in five minutes . so the short thing is , we have , tape recording , , digitized recor recordings . those we won't be able to change . if someone says "" hey , roger so - and - so "" . so that 's gonna stay that person 's name . now , in terms of like the transcript , the question becomes what symbol are you gonna put in there for everybody 's name , and whether you 're gonna put it in the text where he says "" hey roger "" or are we gonna put that person 's anonymized name in instead ?
B: no , because then that would give you mapping , and you don't wanna have mapping .
E: so first decision is , we 're gonna anonymize the same name for the speaker identifier and also in the text whenever the speaker 's name is mentioned .
B: because that would give you mapping between the speaker 's real name and the tag we 're using , and we don't want
E: don't think you understood what what said . so , so in within the context of an utterance , someone says "" so , roger , what do you think ? "" then , , it seems to me that , maybe it seems to me that if you change the name , the transcript 's gonna disagree with the audio , and you won't be able to use that .
A: right , you don't wanna do that .
B: we don't we wanna we ha we want the transcript to be "" roger "" . because if we made the transcript be the tag that we 're using for roger , someone who had the transcript and the audio would then have mapping between the anonymized name and the real name , and we wanna avoid that .
E: , but then there 's this issue of if we 're gonna use this for discourse type of thing , then and , , liz was mentioning in previous meeting about gaze direction and who 's who 's the addressee and all , then to have "" roger "" be the thing in the utterance and then actually have the speaker identifier who was "" roger "" be "" frank "" , that 's going to be really confusing and make it useless for discourse analysis .
B: that 's good point .
E: now , if you want to , , , in some cases , know that susan ervin - tripp in some of hers , , actually did do , , filter of the signal where the person 's name was mentioned , except
D: once you get to the publication you can certainly do that .
E: and and cer and so , , the question then becomes one level back . how important is it for person to be identified by first name versus full name ? on the one hand , , it 's not full identity , we 're taking all these precautions , and they 'll be taking precautions , which are probably even the more important ones , to they 'll be reviewing the transcripts , to see if there 's something they don't like . so , maybe , , maybe that 's enough protection . on the other hand , this is small this is small pool , and people who say things about topic who are researchers and - known in the field , they 'll be identifiable and simply from the from the first name . however , taking one step further back , they 'd be identifiable anyway , even if we changed all the names . so , is it really , ? now , in terms of like so did some results , which 'll report on next time , which do mention individual speakers by name . now , there , the human subjects committee is very precise . you don't wanna mention subjects by name in published reports . now , it would be very possible for me to take those data put them in in study , and just change everybody 's name for the purpose of the publication . and someone who looked
D: you can go , , , "" "" , . , , , it doesn't , 'm not knowledgeable about this , but it certainly doesn't bother me to have someone 's first name in the in the transcript .
E: that 's the same thing you saw .
D: you don't wanna have their full name to be , listed .
E: and in the form that they sign , it does say "" your first name may arise in the course of the meetings "" .
D: so again , th the issue is if you 're tracking discourse things , , if someone says , , "" frank said this "" and then you wanna connect it to something later , you 've gotta have this part where that 's "" frank colon "" .
E: or "" your name "" . and , even more , immediate than that just being able to , , it just seems like to track from one utterance to the next utterance who 's speaking and who 's speaking to whom , cuz that can be important . "" you raised the point , so - and - so "" , it 's be to be able to know who "" you "" was .
B: 'm thinking too much .
E: and ac and actually you remember furthermore , you remember last time we had this discussion of how , was avoiding mentioning people 's names ,
D: was too . .
E: and it was and we made the decision that was artificial . , if we 're going to step in after the fact and change people 's names in the transcript , we 've done something one step worse .
B: would sug don't wanna change the names in the transcript , but that 's because 'm focused so much on the acoustics instead of on the discourse , and so that 's really good point . you 're right , this is going to require more thought .
D: let me just back up this to make brief comment about the , , what we 're covering in the meeting . realize when you 're doing this that , didn't realize that you had bunch of things that you wanted to talk about . and so , and so was proceeding some somewhat at random , frankly . so what would be helpful would be , and 'll 'll mention this to liz and andreas too , that , before the meeting if anybody could send me , any , , agenda items that they were interested in and 'll 'll take the role of organizing them , into the agenda , but 'd be very pleased to have everyone else completely make up the agenda . 've no desire to make it up , but if no one 's told me things , then 'm just proceeding from my guesses , and , and ye , 'm it ended up with your out your time to , 'm just always asking jose what he 's doing , , and so it 's there 's , there 's other things going on .
E: it 's not problem . not problem . . couldn't do it in two minutes .
B: how will we how would the person who 's doing the transcript even know who they 're talking about ? do what 'm saying ?
A: "" the person who 's doing the transcript "" the ibm people ?
B: so how is that information gonna get labeled anyway ?
E: how do you mean , who what they 're who they 're talking about ?
B: so if 'm saying in meeting , "" and bob , , wanted to do so - and - so "" ,
E: how do you mean ?
A: they 're just gonna write "" bob "" on it or do @ @
B: if you 're doing @ @ they 're just gonna write "" bob "" . and so . if you 're if you 're doing discourse analysis ,
E: they won't be able to change it themselves .
D: what ar how are they gonna do any of this ?
E: 'm betting we 're gonna have huge chunks that are just un untranscribable by them .
D: they 're gonna say speaker - one , or speaker - two or speaker
A: they can't do that .
B: the current one they don't do speaker identity . because in naturallyspeaking , or , excuse me , in viavoice , it 's only one person . and so in their current conventions there are no multiple speaker conventions .
D: so it may just be one long transcript of bunch of words .
E: that my understanding from yen is it yen - ching ? is that how you pronounce her name ?
D: yu - ching , yu - ching . .
E: yu - ching ? yu - ching ?
B: yu - ching .
E: was that , they will that they will adopt the part of the conventions that we discussed , where they put speaker identifier down . but , , they won't know these people , so it 's , they 'll they 'll adopt some convention but we haven't specified to them so they 'll do something like speaker - one , speaker - two , is what bet , but 'm betting there 'll be huge variations in the accuracy of their labeling the speakers . we 'll have to review the transcripts in any case .
D: and it and it may very be , since they 're not going to sit there and and worry ab about , , it being the same speaker , they may very go the the first se the first time it changes to another speaker , that 'll be speaker - two . and the next time it 'll be speaker - three even if it 's actually speaker - one .
E: that would be very practical solution on their part .
C: it 's good idea .
E: and and but then we would need to label it .
B: we can probably regenerate it pretty easily from the close - talking mikes .
E: and that 's . yes , was thinking , the temp the time values of when it changes .
B: so . but that doesn't this doesn't answer the question .
E: that 'd be very efficient .
B: the it 's good point , "" which what do you do for discourse tracking ? ""
C: because you to know , you don't need to what is the iden identification of the of the speakers . you only want to know
B: for for acoustics you don't but for discourse you do .
C: for discourse , . .
D: if if someone says , , "" what is jose doing ? "" and then jose says something , you need to know that was jose responding .
B: ugh , that 's problem .
E: unless we adopt different set of norms which is to not id to make point of not identifying people by name , which then leads you to be more contextually ex explicit .
A: that would be hard .
E: people are very flexible . ? , so when we did this las last week , felt that , now , andreas may , , @ @ , he sometimes people think of something else at the same time and they miss sentence , and because he missed something , then he missed the the initial introduction of who we were talking about , and was unable to do the tracking . but felt like most of us were doing the tracking and knew who we were talking about and we just weren't mentioning the name . so , people are really flexible .
A: but , , like , at the beginning of this meeting or , you said , , or liz , said something about , , "" is mari gonna use the equipment ? "" how would you say that ? you have to really think , , about what you 're saying bef
B: if you wanted to anonymize .
D: "" is who up in where ? "" right ? use the
A: it would be really hard if we made policy where we didn't say names , plus we 'd have to tell everybody else .
B: what was gonna say is that the other option is that we could bleep out the names . but then , again that kills your discourse analysis .
A: the , my own two cents worth is that you don't do anything about what 's in the recordings , you only anonymize to the extent you can , the speakers have signed the forms and all .
E: that 's that 's the issue .
B: but that but that as said , that that works great for the acoustics , but it hurts you lot for trying to do discourse . because you don't have map of who 's talking versus their name that they 're being referred to .
A: we were gonna get it labelled speaker - one , speaker - two
B: but , then you have to know that jose is speaker - one and
A: why do you have to know his name ?
D: so suppose someone says , "" if really heard what , what jose said . "" and then , jose responds . and part of your learning about the dialogue is jose responding to it . but it doesn't say "" jose "" , it says "" speaker - five "" .
A: see , you wanna associated the word "" jose "" in the dialogue with the fact that then he responded .
B: someone who 's doing discourse would wanna do that .
D: and so , if we pass out the data to someone else , and it says "" speaker - five "" there , we also have to pass them this little guide that says that speaker - five is jose ,
B: and that violates our privacy .
D: and if were gonna do that we might as give them "" jose "" say it was "" jose "" .
B: and that violates our privacy issue .
E: now , that we have these two phases in the in the data , which is the one which is our use , university of washington 's use , ibm , sri . and within that , it may be that it 's sufficient to not change the to not incorporate anonymization yet , but always , always in the publications we have to . and also , when we take it that next step and distribute it to the world , we have to . but but don that 's that 's long way from now and it 's matter of between now and then of of deciding how
B: making some decisions ?
E: it , it may be that we 'll need to do something like actually out that part of the the audio , and just put in brackets "" speaker - one "" .
B: for the public one . what we could do also is have more than one version of release . one that 's public and one that requires licensing . and so the licensed one would we could it would be sticky limitation . we can talk about that later .
E: that 's risky . that the public should be the same . that when we do that world release , it should be the same .
D: agree with jane .
E: for bunch of reasons , legal .
D: that we have need to have consistent licensing policy of some sort , and
E: but also think consistent licensing policy is important .
A: one thing to take into consideration is are there any , the people who are funding this work , they want this work to get out and be useful for discourse . if we all of sudden do this and then release it to the public and it 's not longer useful for discourse ,
B: depending on how much editing we do , you might be able to still have it useful . because for discourse you don't need the audio . so you could bleep out the names in the audio . and use the anonymized one through the transcript .
A: but if you release both
E: excuse me . we we do need audio for discourse .
B: but , excuse me , but you could bleep out just the names .
D: no , but she 's saying , from the argument before , she wants to be able to say if someone said "" jose "" in their in their thing , and then connect to so to what he said later , then you need it .
B: but in the transcript , you could say , everywhere they said "" jose "" that you could replace it with "" speaker - seven "" .
E: but also wanna say that people
B: and then it wouldn't meet match the audio anymore . but it would be still useful for the
A: but if both of those are publically available
E: that 's good .
D: and th and the other thing is if if liz were here , what she might say is that she wants to look if things that cut across between the audio and the dialogue ,
E: you see ? so , it 's complicated .
D: and so , ,
E: we have to think about @ @ how . that this can't be decided today .
B: , good point .
E: but it 's but it was good to introduce the thing and we can do it next time .
B: didn't think when wrote you that email wasn't thinking it was big can of worms , but it is .
D: lot of these things are .
E: it discourse , also wanted to make the point that discourse is gonna be more than just looking at transcript . it 's gonna be looking at , and prosod prosodic is involved , and that means you 're going to be listening to the audio , and then you come directly into this confronting this problem .
A: maybe we should just not allow anybody to do research on discourse , and then , we wouldn't have to worry about it .
E: we should just market it to non - english speaking countries .
D: maybe we should only have meetings between people who one another and who are also amnesiacs who their own name .
B: did you read the paper on eurospeech ?
E: we could have little labels . wanna introduce my reservoir dogs solution again , which is everyone has like "" mister white "" , "" mister pink "" , "" mister blue "" .
B: did you read the paper few years ago where they were reversing the syllables ? they were di they had the utterances . and they would extract out the syllables and they would play them backwards .
A: but so , the syllables were in the same order , with respect to each other , but the acous
B: everything was in the same order , but they were the individual syll syllables were played backwards . and you could listen to it , and it would sound the same .
A: what did it sound like ?
B: people had no difficulty in interpreting it . so what we need is something that 's the reverse , that speech recognizer works exactly the same on it but people can't understand it .
D: that 's there 's an easy way to do that . jus - jus just play it all backwards .
B: right . the speech recognizer 's symmetric , isn't it .
D: what , what does the speech recognizer care ?
E: do we do digits ? or ? what do we do ?
B: we 'll quickly do digits .
D: let 's do digits . we we already missed the party .
E: or do we just quit ?
B: go off here .
A: it would be fun sometime to read them with different intonations . like as if you were talking like , "" nine eight six eight seven ? ""
E: , in the in the one transcribed , did find couple instances found one instance of contrastive stress , where it was like the string had li so it was like "" nine eight two four , nine two four "" .
A: so they were like looking ahead ,
E: at that session did feel like they did it more as sentences . but , , sometimes people do it as phone numbers . , 've am interested in and sometimes , , and never know . when do it , ask myself what 'm doing each time .
A: was thinking that it must get boring for the people who are gonna have to transcribe this they may as throw in some interesting intonations .
E: like your question intonation . that 's very funny . haven't heard that one .
B: we have the transcript . we have the actual numbers they 're reading , so we 're not necessarily depending on that . 'm gonna go off .
","The Berkeley Meeting Recorder group discussed research aims and corresponding concerns for future data collection.
It was agreed that a substantial amount of meeting data is required from different domains , and comprising several speakers , to perform the types of discourse and acoustic analyses desired.
Ongoing efforts by speaker mn005 to automatically  detect regions of speaker overlap were considered.
It was suggested that speaker mn005 focus on a small set of acoustic parameters , e.g . energy and harmonics-related features , to distinguish regions of overlap from those containing the speech of just one speaker.
Disk space issues were discussed.
And , finally , the problem of speaker anonymization was explored.
Recordings must be of existing meetings that are conducted in English.
Participants should ideally consist of professors and doctoral students , but no undergraduate students , who are willing to record their meetings at ICSI.
The Meeting Recorder corpus should comprise data from a large number of speakers representing different domains.
Attempts should also be made to optimize the speaker population for generating good language models.
Speaker me011 will pursue volunteers from the Haas Business School to record their weekly meetings at ICSI.
A tentative decision was made to offer participants a recorded version of their meeting on a cd rom once the transcript screening phase is complete for that meeting.
Non-native speakers with a low proficiency in English are problematic for language modelling.
The prospect of creating another recording setup requires the elimination certain more complicated dimensions of the existing setup , e.g . the use of close-talking and far-field microphones.
Speaker anonymization poses problems for the transcription proccess , and also discourse analysis , as it makes it more difficult to track who is speaking and to whom a particular utterance is being addressed.
As the current version of transcriptions does not include speaker identification labels , no multiple speaker transcription conventions are in use.
Research aims and corresponding concerns for future data collection were discussed.
A student researcher will be working with speaker fe016 to investigate different strategies for automatically summarizing meetings , and identifying discussional 'hotspots'.
Efforts by speaker mn005 are ongoing to detect regions of speaker overlap in the signal.
A total of 230 regions of overlapping speech have been manually transcribed for a subset of meeting data.
Supervised clustering and neural networks are being considered as means for classifying overlap.
It was suggested that speaker mn005 focus on a small set of acoustic parameters , e.g . energy and harmonics-related features , to use the mixed signal to distinguish regions of overlap from those containing the speech of just one speaker.
Future work may also involve focussing on additional signals , and using a Markov model to analyze acoustic parameters over larger time frames.
Beam-forming was suggested as an alternate method of detecting overlapping speech.
Efforts are ongoing to select an optimal method for anonymizing speakers.
More disk space is gradually being made available for the storage of new Meeting Recorder data.
"
ami_abstractive_summary,Bro013.txt,"A: we 're going ? sh - close your door on door on the way out ? probably wanna get this other door , too . what are we talking about today ?
E: , first there are perhaps these meeting recorder digits that we tested .
A: . that was interesting . the both the the sri system and the oth and for one thing that shows the difference between having lot of training data or not , the the best number we have on the english on near microphone only is three or four percent . and it 's significantly better than that , using fairly simple front - ends on the , with the sri system . so th that the but that 's that 's using pretty huge amount of data , mostly not digits , , mostly not digits for the actual training the ms whereas in this case we 're just using digits for training the did anybody mention about whether the sri system is is doing the digits the wor as word model or as sub sub - phone states ?
E: it 's it 's allophone models , because it 's their very huge , their huge system . so . there is one difference the sri system the result for the sri system that are represented here are with adaptation . it 's their complete system and including on - line unsupervised adaptation .
A: that 's true .
E: and if you don't use adaptation , the error rate is around fifty percent worse , , if remember .
A: it 's tha it 's that much , ?
E: it 's quite significant .
A: but but what 'd be interested to do given that , is that we should take that somebody 's gonna do this , is to take some of these tandem things and feed it into the sri system ,
E: we can do something like that . but the main point is the data because our back - end is fairly simple but until now , , the attempts to improve it or have fail , what chuck tried to to do
A: but he 's doing it with the same data , right ? so to so there 's there 's two things being affected . one is that , , there 's something simple that 's wrong with the back - end . we 've been playing number of states if he got to the point of playing with the number of gaussians yet but , , so far he hadn't gotten any big improvement , but that 's all with the same amount of data which is pretty small .
E: so , , we could retrain some of these tandem on huge
A: you could do that , but 'm saying even with it not with that part not retrained , just using having the ms much better
E: for the models .
A: but just train those ms using different features , the features coming from our aurora .
E: but what would be interesting to see also is what perhaps it 's not related , the amount of data but the recording conditions . because it 's probably not problem of noise , because our features are supposed to be robust to noise . it 's not problem of channel , because there is normalization with respect to the channel .
A: what what is the problem that you 're trying to explain ?
E: the the fact that the result with the tandem and aurora system are so much worse .
A: so much worse ? but 'm 'm almost certain that it , that it has to do with the amount of training data . it it 's orders of magnitude off .
E: but we train only on digits and it 's it 's digit task ,
A: but but having huge if if you look at what commercial places do , they use huge amount of data . this is modest amount of data . so . , ordinarily you would say "" , given that you have enough occurrences of the digits , you can just train with digits rather than with , "" but , if you have huge in other words , do word models but if you have huge amount of data then you 're going to have many occurrences of similar allophones . and that 's just huge amount of training for it . so it 's it has to be that , because , as you say , this is , , this is near - microphone , it 's really pretty clean data . now , some of it could be the fact that let 's see , in the in these multi - train things did we include noisy data in the training ? that could be hurting us actually , for the clean case .
E: actually we see that the clean train for the aurora proposals are better than the multi - train ,
A: cuz this is clean data , and so that 's not too surprising .
E: let 's say if we if we add enough data to train on the on the meeting recorder digits , we could have better results than this . what is that perhaps we can learn something from this , what 's what 's wrong what is different between ti - digits and these digits
A: what numbers are we getting on ti - digits ?
E: it 's point eight percent , four - fourier .
A: so in the actual ti - digits database we 're getting point eight percent , and here we 're getting three or four three , let 's see , three for this ? point eight percent is something like double or triple what people have gotten who 've worked very hard at doing that . and and also , as you point out , there 's adaptation in these numbers also . so if you , , put the ad adap take the adaptation off , then it for the english - near you get something like two percent . and here you had , , something like three point four . and could easily see that difference coming from this huge amount of data that it was trained on . don't think there 's anything magical here . it 's , , we used simple htk system with modest amount of data . and this is , , modern system has lot of points to it . so . , the htk is an older htk , even . it 's not that surprising . but to me it just it just meant practical point that if we want to publish results on digits that people pay attention to we probably should cuz we 've had the problem before that you get show some improvement on something that 's that 's , it seems like too large number , and people don't necessarily take it so . so the three point four percent for this is so why is it it 's an interesting question though , still . why is why is it three point four percent for the the digits recorded in this environment as opposed to the point eight percent for for the original ti - digits database ?
E: th that 's th that 's my point
A: given given the same so ignore ignoring the the sri system for moment , just looking at the ti - di the tandem system , if we 're getting point eight percent , which , yes , it 's high . it 's , , it 's not awfully high , but it 's , it 's high . why is it four times as high , or more ? there 's even though it 's close - miked there 's still there really is background noise . and suspect when the ti - digits were recorded if somebody fumbled or said something wrong that they probably made them take it over . it was not there was no attempt to have it be realistic in any in any sense .
E: and acoustically , it 's it 's it 's quite different . ti - digit is it 's very , very clean and it 's like studio recording whereas these meeting recorder digits sometimes you have breath noise it 's {nonvocalsound} not controlled , .
A: it 's it 's so . yes . it 's it 's it 's the indication it 's harder . , , that 's true either way . so take look at the , the sri results . they 're much better , but still you 're getting something like one point three percent for things that are same data as in ti - digits the same text . and , 'm the same system would get , , point three or point four on the actual ti - digits . so this , on both systems the these digits are showing up as harder . which find interesting this is closer to it 's still read . but still 's much closer to what people actually face , when they 're they 're dealing with people saying digits over the telephone . 'm they wouldn't release the numbers , but don't think that the companies that do telephone speech get anything like point four percent on their digits . 'm 'm they get , for one thing people do phone up who don't have middle america accents and it 's we it 's it 's us . it has many people who sound in many different ways . that was that topic . what else we got ? did we end up giving up on , any eurospeech submissions , know thilo and dan ellis are submitting something ,
E: the only thing with these the meeting recorder and , , so , , we gave up .
A: now , actually for the for the aur - we do have for aurora , right ? because because we have ano an extra month .
E: for we will do something for the special session .
A: that 's fine . so th so we have couple couple little things on meeting recorder and we have we don't we don't have to flood it with papers . we 're not trying to prove anything to anybody . that 's fine .
E: perhaps that we 've been working on is , we have put the the good vad in the system and it really makes huge difference . , this is perhaps one of the reason why our system was not the best , because with the new vad , it 's very the results are similar to the france telecom results and perhaps even better sometimes . so there is this point . the problem is that it 's very big and we still have to think how to where to put it and we if we put it on the server side , it doesn't work , because on the server side features you already have lda applied from the from the terminal side and so you accumulate the delay so the vad should be before the lda which means perhaps on the terminal side and then smaller and
A: so wha where did this good vad come from ?
E: it 's from ogi . so it 's the network trained it 's the network with the huge amounts on hidden of hidden units , and nine input frames compared to the vad that was in the proposal which has very small amount of hidden units and fewer inputs .
A: this is the one they had originally ? but they had to get rid of it because of the space ,
E: but the abso assumption is that we will be able to make vad that 's small and that works fine . and . so we can
A: so that 's problem . but the other thing is to use different vad entirely . if there 's if what the thinking was amongst the the etsi folk but if everybody let 's use this vad and take that out of there
E: they just want , they don't want to fix the vad because they think there is some interaction between feature extraction and vad or frame dropping but they still want to just to give some requirement for this vad because it 's it will not be part of they don't want it to be part of the standard . so . so it must be at least somewhat fixed but not completely . so there just will be some requirements that are still not not yet ready .
A: but was thinking that "" , there may be some interaction , but don't think we need to be stuck on using our or ogi 's vad . we could use somebody else 's if it 's smaller as long as it did the job . so that 's good .
E: so there is this thing . designed new new filter because when designed other filters with shorter delay from the lda filters , there was one filter with fif sixty millisecond delay and the other with ten milliseconds and hynek suggested that both could have sixty - five sixty - it 's sixty - five . both should have sixty - five because
A: you didn't gain anything , right ?
E: and . so did that and it 's running . so , let 's see what will happen . but the filter is closer to the reference filter .
A: so that means logically , in principle , it should be better . so probably it 'll be worse . or in the basic perverse nature of reality .
E: and then we 've started to work with this of voiced - unvoiced . and next week we will perhaps try to have new system with msg stream also see what happens . so , something that 's similar to the proposal too , but with msg stream .
D: no , begin to play with matlab and to found some parameter robust for voiced - unvoiced decision . but only to play . and we they we found that maybe is classical parameter , the sq the variance between the fft of the signal and the small spectrum of time we after the mel filter bank . and , , is more or less robust . is good for clean speech . is quite good for noisy speech . but we must to have bigger statistic with timit , and is not ready yet to use on ,
E: so , we wa want to look at something like the ex excitation signal and which are the variance of it and
D: have here for one signal , for one frame . the the mix of the two , noise and unnoise , and the signal is this . clean , and this noise . these are the two the mixed , the big signal is for clean .
A: none of these axes are labeled , what 's this axis ?
D: this is this axis is nnn , "" frame "" .
A: and what 's th what this ?
D: this is energy , log - energy of the spectrum . this is the variance , the difference {nonvocalsound} between the spectrum of the signal and fft of each frame of the signal and this mouth spectrum of time after the may fit for the two ,
A: for this one .
D: this big , to here , they are to signal . this is for clean and this is for noise .
A: there 's two things on the same graph .
D: that have another graph , but 'm not .
A: so which is clean and which is noise ?
E: the lower one is noise .
D: the lower is noise and the height is clean .
A: so it 's harder to distinguish
D: it 's height .
A: but it but it
D: must to have . pity , but don't have two different
A: and presumably when there 's
E: so this should the the voiced portions .
D: it is the height is voiced portion .
E: the the peaks should be voiced portion .
D: and this is the noise portion . and this is more or less like this . but to have see @ @ two the picture . this is , , for one frame . the spectrum of the signal . and this is the small version of the spectrum after ml mel filter bank .
A: and this is the difference ?
D: this is not the different . this is trying to obtain with lpc model the spectrum but using matlab without going factor and
A: no pre - emphasis ?
D: not pre - emphasis .
A: doesn't do too there .
D: that this is good . this is quite similar . this is this is another frame . ho how obtained the envelope , {nonvocalsound} this envelope , with the mel filter bank .
A: do you want to know you want to get at something orthogonal from what you get with the smooth spectrum but if you were to really try and get voiced - unvoiced , do you do you want to ignore that ? do you do you clearly very big very big cues for voiced - unvoiced come from spectral slope and so on ,
E: this would be this would be perhaps an additional parameter ,
D: because when did noise clear {nonvocalsound} in these section is clear if @ @ {nonvocalsound} val value is indicative that is voice frame and it 's low values
A: certainly if you want to do good voiced - unvoiced detection , you need few features . each each feature is by itself not enough . but , , people look at slope and first auto - correlation coefficient , divided by power . we prob probably don't have enough computation to do simple pitch detector ? with pitch detector you could have have an estimate of what the or maybe you could you just do it going through the fft 's figuring out some probable harmonic structure .
D: you have read up and you have paper , the paper that you give me yesterday . they say that yesterday they are some {nonvocalsound} problem
E: but it 's not it 's it 's another problem .
D: is another problem .
E: there is th this fact actually . if you look at this spectrum , what 's this again ? is it the mel - filters ?
D: of kind like this .
E: so the envelope here is the output of the mel - filters and what we clearly see is that in some cases , and it clearly appears here , and the harmonics are resolved by the there are still appear after mel - filtering , and it happens for high pitched voice because the width of the lower frequency mel - filters is sometimes even smaller than the pitch . it 's around one hundred , one hundred and fifty hertz nnn . and so what happens is that this , add additional variability to this envelope so we were thinking to modify the mel - spectrum to have something that 's smoother on low frequencies .
A: that 's as separate thing .
E: this is separate thing .
A: what was talking about was just , starting with the fft you could you could do very rough thing to estimate pitch . and , given , given that , you could come up with some estimate of how much of the low frequency energy was explained by those harmonics . it 's variant on what you 're what you 're doing . the , the the mel does give smooth thing . but as you say it 's not that smooth here . and and so if you if you just subtracted off your of the harmonics then something like this would end up with quite bit lower energy in the first fifteen hundred hertz or so and our first kilohertz , even . and if was noisy , the proportion that it would go down would be if it was if it was unvoiced . so you oughta be able to pick out voiced segments . at least it should be another cue . so . anyway . that 's what 's going on . what 's up with you ?
B: our went to talk with mike jordan this week {nonvocalsound} and shared with him the ideas about extending the larry saul work and asked him some questions about factorial so like later down the line when we 've come up with these feature detectors , how do we how do we , model the time series that happens and we talked little bit about factorial ms and how when you 're doing inference or when you 're doing recognition , there 's like simple viterbi that you can do for these and the the great advantages that lot of times the factorial ms don't don't over - alert the problem there they have limited number of parameters and they focus directly on the sub - problems at hand so you can imagine five or so parallel features transitioning independently and then at the end you couple these factorial ms with with undirected links based on based on some more data . so he seemed he seemed like really interested in in this and said this is this is something very do - able and can learn lot 've just been continue reading about certain things . thinking of maybe using modulation spectrum to as features also in the in the sub - bands because it seems like the modulation spectrum tells you lot about the intelligibility of certain words and that 's about it .
C: so 've been looking at avendano 's work 'll try to write up in my next stat status report description of what he 's doing , but it 's it 's an approach to deal with reverberation or that the aspect of his work that 'm interested in the idea is that normally an analysis frames are too short to encompass reverberation effects in full . you miss most of the reverberation tail in ten millisecond window and so you 'd like it to be that the reverberation responses simply convolved in , but it 's not really with these ten millisecond frames but if you take , say , two millisecond window then in room like this , most of the reverberation response is included in the window and the then it then things are more linear . it is it is more like the reverberation response is simply convolved and and you can use channel normalization techniques like in his thesis he 's assuming that the reverberation response is fixed . he just does mean subtraction , which is like removing the dc component of the modulation spectrum and that 's supposed to deal deal pretty with the reverberation and the neat thing is you can't take these two second frames and feed them to speech recognizer so he does this method training trading the the spectral resolution for time resolution and come ca synthesizes new representation which is with say ten second frames but lower frequency resolution . so don't really know the theory . it 's these are called "" time frequency representations "" and he 's making the time sh finer grained and the frequency resolution less fine grained . so 'm my first stab actually in continuing his work is to re - implement this thing which changes the time and frequency resolutions cuz he doesn't have code for me . so that 'll take some reading about the theory . don't really know the theory . and , another first step is so the way want to extend his work is make it able to deal with time varying reverberation response we don't really know how fast the the reverberation response is varying the meeting recorder data so we have this block least squares imp echo canceller implementation and want to try finding the response , say , between near mike and the table mike for someone using the echo canceller and looking at the echo canceller taps and then see how fast that varies from block to block . that should give an idea of how fast the reverberation response is changing .
A: we 're done . so let 's read our digits and go home .
C: you do you read some of the zeros as 's and some as zeros . is there particular way we 're supposed to read them ?
E: there are only zeros here .
A: no . "" "" "" "" "" "" "" "" and "" zero "" are two ways that we say that digit .
E: perhaps in the sheets there should be another sign for the if we want to the guy to say "" ""
A: people will do what they say . in digit recognition we 've done before , you have you have two pronunciations for that value , "" "" and "" zero "" .
E: but it 's perhaps more difficult for the people to prepare the database then , if because here you only have zeros
A: no , they just write
E: and people pronounce "" "" or zero
A: they write down . or they write down zero and they and they each have their own pronunciation .
E: but if the sh the sheet was prepared with different sign for the "" "" .
A: but people wouldn't that wa there is no convention for it . see . , you 'd have to tell them "" when we write this , say it tha "" , and you just they just want people to read the digits as you ordinarily would and people say it different ways .
C: is this change from the last batch of forms ? because in the last batch it was spelled out which one you should read .
E: it was orthographic ,
A: that 's right . it was it was spelled out , and they decided they wanted to get at more the way people would really say things . that 's also why they 're they 're bunched together in these different groups . so so it 's so it 's it 's everything 's fine . actually , let me just since you brought it up , was just it was hard not to be self - conscious about that when it after we since we just discussed it . but realized that when 'm talking on the phone , certainly , and saying these numbers , almost always say zero . and cuz because it 's two syllables . it 's it 's more likely they 'll understand what said . so that that 's the habit 'm in , but some people say "" "" and
B: normally say "" "" cuz it 's easier to say .
A: it 's shorter . so it 's so . so . now , don't think about it . we 're done .
","The Main purpose of the meeting of ICSI's Meeting Recorder Group at Berkeley was to discuss the recent progress of it's members.
This includes reports on the progress of the groups main digit recogniser project , with interest on voice-activity detectors and voiced/unvoiced detection , work on acoustic feature detection , and research into dealing with reverberation.
There was also talk of comparing different recognition systems and training datasets , and a discussion of the pronunciation of the digit zero for the recording at the end of the meeting.
In his next status report , me026 will summarise the work he has been researching.
The digit recognition system is still not working well enough , they must get better results if they want to publish and be noticed.
They have not really made many improvements , which may be due to their comparatively small training set , or the conditions the data is recorded under.
The new VAD is quite a large network , and adds a delay to the process.
This caused OGI to drop it , though speaker mn007 is assuming that a smaller and equally effective system can be developed.
The alternative is to get yet another VAD form somewhere else , though it's not clear if they will even be required in the final system.
There are some problems with the voiced/unvoiced feature detection , because some pitches are slipping through the filtering.
The group have been comparing their recognition system to a few others , and theirs has not come off favourably.
There could be many reasons for this , including smaller training set , more realistic data , or older technology.
Speaker mn007 has put the best voice activity detector into the system , to great improvements along with designing new filters that run at the correct latency.
Speaker fn002 has started to find parameters for voiced/unvoiced feature detection , and has found some classic ones , although there are other things she wishes to look at.
Me013 offers a few ideas of simple things she may want to try , as he is not confident with everything she is trying.
Speaker me006 is continuing with the idea of extending work on acoustic feature detection.
He is continuing to read , and has discussed the suitability of factorial HMMs with a colleague.
Speaker me026 has been learning more about previous work on reverberation , and is ready to start with a re-implementation of the theory.
From there he wants to extend the work to look at time-varying reverb.
"
ami_abstractive_summary,Bro008.txt,"D: you can fill those out , after , actually , so , got , these results from , , stephane . also , , that , we might hear later today , about other results . that , , there were some other very good results that we 're gonna wanna compare to . but , our results from other places , got this from you and then sent note to sunil about the cuz he has been running some other systems other than the icsi ogi one . so , wan wanna see what that is . but , , , so we 'll see what it is comparatively later . but it looks like , most of the time , even even though it 's true that the overall number for danish we didn't improve it if you look at it individually , what it really says is that there 's , , looks like out of the six cases , between the different kinds of , , matching conditions out of the six cases , there 's , , couple where it stays about the same , three where it gets better , and one where it gets worse .
A: actually , , , for the danish , there 's still some mystery because , , when we use the straight features , we are not able to get these number with the icsi ogi one , . we don't have this ninety - three seventy - eight , we have
E: eighty - nine forty - four .
A: so , , that 's probably something wrong with the features that we get from ogi . and sunil is working on trying to check everything .
D: and we have little time on that and actually we have little bit of time on that , actually . we have day or so , when when do you folks leave ? until saturday midnight , , we have we have time , that would be good . that 'd be good . and , , when whenever anybody figures it out they should also , for , email hynek because hynek will be over there telling people what we did , so he should know . so , we 'll we 'll hold off on that little bit . even with these results as they are , it 's it 's really not that bad . but but , , and it looks like the overall result as they are now , even without , , any bugs being fixed is that , , on the other tasks , we had this average of , , forty nine percent , or so , improvement . and here we have somewhat better than that than the danish , and somewhat worse than that on the german , but , it sounds like , , one way or another , the methods that we 're doing can reduce the error rate from mel ceptrum down by , fourth of them to , , half of them . somewhere in there , depending on the exact case . so that 's good . that , , one of the things that hynek was talking about was understanding what was in the other really good proposals and trying to see if what should ultimately be proposed is some , , combination of things . cuz there 's things that they are doing there that we certainly are not doing . and there 's things that we 're doing that they 're not doing . and and they all seem like good things .
C: how much how much better was the best system than ours ?
D: , first place , there 's still this thing to work out , and second place second thing is that the only results that we have so far from before were really development set results . so , in this community that 's of interest . it 's not like everything is being pinned on the evaluation set . but , , for the development set , our best result was little bit short of fifty percent . and the best result of any system was about fifty - four , where these numbers are the , , relative , , reduction in , , word error rate . and , , the other systems were , , somewhat lower than that . there was actually there was much less of huge range than there was in aurora one . in aurora one there were there were systems that ba didn't improve things . and here the worst system still reduced the error rate by thirty - three percent , , in development set . so so , , everybody is doing things between , , roughly third of the errors , and half the errors being eliminated , , and varying on different test sets and . it 's probably good time to look at what 's really going on and seeing if there 's there 's way to combine the best ideas while at the same time not blowing up the amount of , , resources used , cuz that 's that 's critical for this test .
C: do we know anything about who 's was it that had the lowest on the dev set ?
D: , the there were two systems that were put forth by combination of , , french telecom and alcatel . and , they differed in some respects , but they one was called the french telecom alcatel system the other was called the alcatel french telecom system , , which is the biggest difference , . but but there 're there 're some other differences , too . and , , they both did very , so , , my impression is they also did very on the , , evaluation set , but , , we haven't seen you 've - you haven't seen any final results for that
C: and they used the main thing that they used was spectral subtraction ?
D: there is couple pieces to it . there 's spectral subtraction style piece it was , , wiener filtering . and then there was some some modification of the cepstral parameters , where they
A: actually , something that 's close to cepstral mean subtraction . but , , the way the mean is adapted , it 's signal dependent . so , , the mean is adapted during speech and not during silence . but it 's very close to cepstral mean subtraction .
D: but some people have done exactly that thing , of and the it 's not to to look in speech only , to try to to measure these things during speech , that 's that 's not that uncommon . but it so it looks like they did some , , reasonable things , and they 're not things that we did , precisely . we did unreasonable things , which because we like to try strange things , and , , and our things worked too . and so , , it 's possible that some combination of these different things that were done would be the best thing to do . but the only caveat to that is that everybody 's being real conscious of how much memory and how much cpu they 're using because these , , standards are supposed to go on cell phones with moderate resources in both respects .
C: did anybody , , do anything with the models as an experiment ?
D: they didn't report it , if they did .
C: nobody reported it ?
D: everybody was focused elsewhere . now , one of the things that 's about what we did is , we do have , filtering , which leads to , reduction in the bandwidth in the modulation spectrum , which allows us to downsample . so , , as result of that we have reduced , , transmission rate for the bits . that was misreported the first time out . it it said the same amount because for convenience sake in the particular way that this is being tested , , they were repeating the packets . so it was they were they had twenty - four hundred bits per second , but they were literally creating forty - eight hundred bits per second , , even though it was just repeated . so , , in practice
C: so you could 've had repeat count in there .
D: , this was just ph phoney thing just to fit into the software that was testing the errors channel errors and so on . so in reality , if you put this system in into , , the field , it would be twenty - four hundred bits per second , not forty - eight hundred . so that 's feature of what we did . but , , , we still have to see how it all comes out . and then there 's the whole standards process , which is another thing altogether .
C: when is the development set , the , , test set results due ? like the day before you leave ?
D: probably the day after they leave , but we 'll have to we 'll have to stop it the day before we leave . tha the meeting is on the thirteenth . and the , , results are due like the day before the meeting . th they are , so , since we have bit farther to travel than some of the others , , we 'll have to get done little quicker . but , , , it 's just tracing down these bugs . just exactly this thing of , , why these features seem to be behaving differently , , in california than in oregon . might have something to do with electricity shortage . we didn't we didn't have enough electrons here , , the main reason for having it only takes to run the two test sets in just in computer time is just day or so ,
A: it 's very short interval .
D: so , the who the whole reason for having as long as we have , which was like week and half , is because of bugs like that . so , we 're gonna end up with these same sheets that have the percentages and so on just for the
A: so there are two more columns in the sheets ,
D: it 's the same sheets ,
A: it 's the same sheets ,
D: just with the missing columns filled in . that 'll be good . so , 'll dis 'll disregard these numbers . that 's that 's good .
A: so , hynek will try to push for trying to combine , , different things ?
D: the question is "" is there is there some advantage ? "" you could just take the best system and say that 's the standard . but that if different systems are getting at good things , , again within the constraint of the resources , if there 's something simple that you can do now , , it 's , , very reasonable to have standard for the terminal 's side and then for the server 's side say , "" here 's number of things that could be done . "" so , , everything that we did could probably just be added on to what alcatel did , and it 'd probably work pretty with them , too . , that 's one aspect of it . and then on the terminal 's side , how much , , memory and cpu it takes , but it seems like the filtering , the vad they both had , and , , so and they both had some on - line normalization , so , it seems like the main different there is the is the , , filtering . and the filtering if you can shouldn't take lot of memory to do that , and also wouldn't think the cpu , , would be much either for that part . so , if you can if you can add those in then , , you can cut the data rate in half . so it seems like the right thing to do is to on the terminal 's side , take what they did , if it if it does seem to generalize to german and danish , take what they did add in filter , and add in some on the server 's side and and that 's probably reasonable standard .
A: they are working on this already ? because , su - sunil told me that he was trying already to put some , , filtering in the france telecom .
D: so that 's that 's what that would be ideal would be is that they could , , they could actually show that , , combination of some sort , , would work even better than what any of the systems had . and , , then it would it would , be something to discuss in the meeting . but , , not clear what will go on . , on the one hand , , sometimes people are just anxious to get standard out there . you can always have another standard after that , but this process has gone on for while on already and people might just wanna pick something and say , "" , this is it . "" and then , that 's standard . standards are always optional . it 's just that , , if you disobey them , then you risk not being able to sell your product , and people often work on new standards while an old standard is in place and so on . so it 's not final even if they declared standard . the other hand , they might just say they just enough yet to declare standard . you you will be you will become experts on this and know more far more than me about the tha this particular standards process once you go to this meeting . be interested in hearing . so , , 'd be , , interested in hearing , , your thoughts now you 're almost done . you 're done in the sense that , , you may be able to get some new features from sunil , and we 'll re - run it . but other than that , you 're you 're done , so , , 'm interested in hearing your thoughts about where you think we should go from this . we tried lot of things in hurry , and , , if we can back off from this now and take our time with something , and not have doing things quickly be quite so much the constraint , what you think would be the best thing to do .
A: first , , to really have look at the speech from these databases because , , we tried several thing , but we did not really look at what 's happening , and where is the noise , and
D: it 's novel idea . look at the data . or more generally , , what is causing the degradation .
A: actually , there is one thing that , generally we think that most of the errors are within phoneme classes , so it could be interesting to see if it don't 's still true when we add noise , and so we have the confusion ma the confusion matrices are very different when we have noise , and when it 's clean speech . and probably , there is much more between classes errors for noisy speech . so perhaps we could have large gain , , just by looking at improving the , , recognition , not of phonemes , but of phoneme classes , simply . and which is simpler problem , perhaps , but which is perhaps important for noisy speech .
D: the other thing that strikes me , just looking at these numbers is , just taking the best cases , some of these , , even with all of our wonderful processing , still are horrible kinds of numbers . but just take the best case , the - matched , german case after er - matched danish after we the numbers we 're getting are about eight or nine percent error per digit . this is not usable , if you have ten digits for phone number , every now and then you 'll get it right . it 's it 's , , so , , the other thing is that , and and and also , part of what 's about this is that this is , , realistic almost realistic database . it 's still not people who are really trying to accomplish something , but , , within the artificial setup , it isn't noise artificially added , , simulated , , additive noise . it 's real noise condition . and , , the training the training , , is always done on the close talking
A: actually the - matched condition is still quite di still quite difficult . it 's they have all these data from the close mike and from the distant mike , from different driving condition , open window , closed window , and they take all of this and they take seventy percent , , for training and thirty percent for testing . so , training is done on different conditions and different microphones , and testing also is done on different microphone and conditions . so , probably if we only take the close microphones , the results should be much better than this .
D: that explains it partially . wha - what about
A: so there is this , the mismatched is , the same thing , but the driving conditions , the speed and the road , is different for training and testing , is that right ? and the last condition is close microphone for training and distant for testing .
D: so the high so the right so the highly mismatched case is in some sense good model for what we 've been , , typically talking about when we talk about additive noise in and so and it does correspond to realistic situation in the sense that , , people might really be trying to , , call out telephone numbers or some like that , in their cars and they 're trying to connect to something .
A: actually , , it 's very close to clean speech training because , , because the close microphone and noisy speech testing ,
D: and the - matched condition is what you might imagine that you might be able to approach , if that this is the application . you 're gonna record bunch on people in cars and , and do these training . and then , , when you sell it to somebody , they will be different person with different car , and so on . so it 's this is an optim somewhat optimistic view on it , so , , the real thing is somewhere in between the two .
A: but the , the th
D: even the optimistic one is
A: it doesn't work .
D: it doesn't work . so , in way , that 's , , that 's the dominant thing is that even , say on the development set that we saw , the , , the numbers that , , that alcatel was getting when choosing out the best single numbers , it was just , it wasn't good enough for for real system . so , , we still have to do . so , looking at the data , where , what 's the what 's th what 's characteristic that 's that 's good thing . does any you have any thoughts about what else you 're thinking that you didn't get to that you would like to do if you had more time ?
E: lot of thing . because we trying lot of thing , and we doesn't work , we remove these . maybe we trying again with the articulatory feature . because we tried we some one experiment that doesn't work . forgot it , something exactly because , tsk maybe do better some step the general , , diagram . exactly to think what we can improve .
D: cuz lot of time it 's true , there were lot of times when we 've tried something and it didn't work right away , even though we had an intuition that there should be something there . and so then we would just stop it . and , , one of the things don't remember the details on , but remember at some point , when you were working with second stream , and you tried low - pass filtering to cepstrum , in some case you got but it was an msg - like thing , but it wasn't msg , you in some case you got some little improvement , but it was , , small improvement , and it was big added complication , so you dropped it . but , , that was just one try , you just took one filter , threw it there , and it seems to me that , , if that is an important idea , which , , might be , that one could work at it for while , as you 're saying . and you had , , you had the multi - band things also , and , , there was issue of that . barry 's going to be , , continuing working on multi - band things as . we were just talking about , , some , , some work that we 're interested in . inspired by the by larry saul with the , , learning articulatory feature in , in the case of his paper with sonorance based on , , multi - band information where you have combination of gradient learning an and , , . so , that , , this is , this is neat data set . and then , , as we mentioned before , we also have the new , , digit set coming up from recordings in this room . so , there 's lot of things to work with . what like about it , in way , is that , , the results are still so terrible . they 're much better than they were , . we 're talking about thirty to sixty percent , , error rate reduction . that 's that 's really great to do that in relatively short time . but even after that it 's still , , so poor that , , no one could really use it . that 's great that because and also because again , it 's not something sometimes we 've gotten terrible results by taking some data , and artificially , , convolving it with some room response , at one point , , brian and went downstairs into the basement where it was it was in hallway where it was very reverberant and we made some recordings there . and then we , , made simulation of the of the room acoustics there and applied it to other things , but it was all pretty artificial , and , , how often would you really try to have your most crucial conversations in this very reverberant hallway ? this is what 's about the aurora data and the data here , is that is that it 's realistic room situation , acoustics acoustic situation , both terms in noise and reflections , and so on and and , , with something that 's still relatively realistic , it 's still very hard to do very .
A: actually , this is tha that 's why we it 's different data . we 're not we 're not used to work with this data . that 's why we should have loo more closer look at what 's going on . so this would be the first thing , and then , , try to , debug what was wrong , , when we do aurora test on the msg particularly , and on the multi - band .
D: no , there 's lots of lots of good things to do with this . you were gonna say something else ? what do you think ?
C: about other experiments ? now , 'm interested in , , looking at the experiments where you use , , data from multiple languages to train the neural net . and how far , or if you guys even had chance to try that , but that would be some it 'd be interesting to me .
A: again , it 's the thing that , , we were thin thinking that it would work , but it didn't work . and , , so there is not bug , but something wrong in what we are doing , perhaps . something wrong , perhaps in the just in the fact that the labels are what worked best is the hand - labeled data . if we can get some hand - labeled data from other languages . it 's not so easy to find . but that would be something interesting to see .
D: also , , , there was just the whole notion of having multiple nets that were trained on different data . so one form of different data was is from different languages , but the other , , in those experiments it wasn't so much combining multiple nets , it was single net that had different so , first thing is would it be better if they were multiple nets , for some reason ? second thing is , never mind the different languages , just having acoustic conditions rather than training them all up in one , would it be helpful to have different ones ? that was question that was raised by mike shire 's thesis , and on in that case in terms of reverberation . that that sometimes it might be better to do that . but , , don't think we know for . so , next week , we , , won't meet because you 'll be in europe . whe - when are you two getting back ?
A: you on friday or on saturday
E: because it 's it 's less expensive , the price the price the ticket .
D: that 's right . you 've gotta have saturday overnight ,
A: 'll be back on tuesday .
C: where where 's the meeting ?
D: so , we 'll skip next week , and we 'll meet two weeks from now . and , , the main topic will be , , you telling us what happened . if we don't have an anything else to discuss , we should , , turn off the machine and then say the real nasty things .
C: should we do digits first ?
D: why don't you go ahead .
","The Berkley Meeting Recorder Group discussed the most recent progress with their current project , a digit recognition system for use in cell phones.
This included some discussion of results , comparing various other groups' systems , issues involving the set up , and plans for future work.
Results are required for an upcoming meeting , but since some group members will be away , results need to be in sooner.
Although error rates have been greatly reduced , current rates are still unusable in a practical situation.
There is a problem replicating some results found by partner OGI , but it is unclear why.
mn007 and fn002 have been working with the new Danish and German databases , making improvements , though more so with results on the Danish.
The results are reasonable , but still not good enough.
However , it has not been possible to compare results to the best , as still development system.
There are a number of things that the group wishes to consider for looking for further improvements.
There are various techniques that various groups have tried , and they should all be considered for possible combinations of systems.
One suitable candidate for combination is the group's own filtering which reduces bandwidth to half bit transmission rate.
"
ami_abstractive_summary,Bro003.txt,"F: so you think we 're going now , so we 're gonna go around as before , and do our digits . transcript one three one dash one three zero . three two three four seven six five three one six two four one six seven eight nine zero nine four zero three zero one five eight one seven three five three two six eight zero three six two four three zero seven four five zero six nine four seven four eight five seven nine six one five seven eight two zero nine six zero four zero one two , you don't actually need to say the name .
C: this is barry chen and am reading transcript
F: that 'll probably be bleeped out . that 's if these are anonymized , not that there 's anything defamatory about eight five seven or anything , so here 's what have for was just jotting down things th that we should do today . this is what have for an agenda so far we should talk little bit about the plans for the the field trip next week . number of us are doing field trip to ogi and mostly first though about the logistics for it . then maybe later on in the meeting we should talk about what we actually , might accomplish . in and go around see what people have been doing talk about that , progress report . , essentially . and then another topic had was that dave here had said "" give me something to do . "" and have have failed so far in doing that . and so maybe we can discuss that little bit . if we find some holes in some things that someone could use some help with , he 's he 's volunteering to help .
A: 've got to move bunch of furniture .
F: always count on serious comment from that corner . and , then , talk little bit about disks and resource issues that 's starting to get worked out . and then , anything else anybody has that isn't in that list ?
D: was just wondering , does this mean the battery 's dying and should change it ?
F: that means the battery 's .
A: let me see . that 's good . you 're alright ?
D: cuz it 's full .
F: it looks full of electrons . plenty of electrons left there . so , , wanted to start this with this mundane thing . it was my bright idea to have us take plane that leaves at seven twenty in the morning .
C: , that 's right .
F: this is the reason did it was because otherwise for those of us who have to come back the same day it is really not much of of visit . so the issue is how how would we ever accomplish that ? what what part of town do you live in ?
C: live in , , the corner of campus . the , , southeast corner .
F: so would it be easier those of you who are not , , used to this area , it can be very tricky to get to the airport at , , six thirty . so . would it be easier for you if you came here and drove you ? so if everybody can get here at six . 'm afraid we need to do that to get there on time .
A: will that be enough time ?
F: so 'll just pull up in front at six and just be out front . and , , and , that 'll be plenty of time . it 'll take it won't be bad traffic that time of day
A: once you get past the bridge that would be the worst .
F: going to oakland .
A: once you get past the turnoff to the bay bridge .
F: the turnoff to the bridge won't even do that . just go down martin luther king . and then martin luther king to nine - eighty to eight - eighty , and it 's it 'd take us , tops thirty minutes to get there . so that leaves us fifty minutes before the plane it 's , it 's still not going to be really easy but particularly for for barry and me , we 're not we 're not staying overnight so we don't need to bring anything particularly except for pad of paper and so , and , you , two have to bring little bit but , don't don't bring footlocker and we 'll be you 're staying overnight . figured you wouldn't need great big suitcase , that 's one night .
C: so , six am , in front .
F: six am in front . 'll be here . 'll 'll give you my phone number , if 'm not here for few after few minutes then
C: wake you up .
F: nah , 'll be fine . it for me it just means getting up half an hour earlier than usually do . not not lot , that was the real important . figured maybe on the potential goals for the meeting until we talk about wh what 's been going on . so , , what 's been going on ? why don't we start over here .
G: , preparation of the french test data actually . so , it means that , it is , , digit french database of microphone speech , downsampled to eight kilohertz and 've added noise to one part , with the actually the aurora - two noises . and , @ @ so this is training part . and then the remaining part , use for testing and with other noises . so this is almost ready . 'm preparing the htk baseline for this task .
F: so the htk base lines so this is using mel cepstra and so on , the the plan is , , to then given this what 's the plan again ?
G: the plan with these data ?
F: so does remind me of what you were going to do with the what 's you just described what you 've been doing . so if you could remind me of what you 're going to be doing .
C: tell him about the cube .
G: should tell him about the cube ?
F: ! cube . .
E: fill in the cube .
G: we actually we want to , mmm , , , analyze three dimensions , the feature dimension , the training data dimension , and the test data dimension . what we want to do is first we have number for each task . so we have the , ti - digit task , the italian task , the french task and the finnish task . so we have numbers with systems neural networks trained on the task data . and then to have systems with neural networks trained on , , data from the same language , if possible , with , , using more generic database , which is phonetically balanced ,
F: so - so we had talked we had talked at one point about maybe , the language id corpus ? is that possibility for that ?
G: ye - , but , these corpus , there is callhome and callfriend also , the callfriend is for language ind identification . anyway , these corpus are all telephone speech . so , . this could be problem for why ? because , the speechdat databases are not telephone speech . they are downsampled to eight kilohertz but they are not with telephone bandwidth .
F: that 's really funny cuz th this whole thing is for developing new standards for the telephone .
G: but the idea is to compute the feature before the before sending them to the you don't do not send speech , you send features , computed on th the device ,
F: so your point is that it 's it 's the features are computed locally , and so they aren't necessarily telephone bandwidth , or telephone distortions .
A: did you happen to find out anything about the ogi multilingual database ?
F: that 's wh that 's what . said @ @ , there 's there 's an ogi language id , not the not the , the callfriend is is , , ldc thing , right ?
G: yea - , there are also two other databases . one they call the multi - language database , and another one is twenty - two language , something like that . but it 's also telephone speech .
F: we ' the bandwidth shouldn't be such an issue because this is downsampled and filtered , so it 's just the fact that it 's not telephone . and there are so many other differences between these different databases . some of this 's recorded in the car , and some of it 's there 's there 's many different acoustic differences . so 'm not if . , unless we 're going to include bunch of car recordings in the in the training database , 'm not if it 's completely rules it out if our if we if our major goal is to have phonetic context and you figure that there 's gonna be mismatch in acoustic conditions does it make it much worse to add another mismatch , if you will . the question is how important is it to for us to get multiple languages , in there .
G: but - . . actually , for the moment if we do not want to use these phone databases , we already have english , spanish and french , with microphone speech .
F: so that 's what you 're thinking of using is the multi the equivalent of the multiple ?
G: for the multilingual part we were thinking of using these three databases .
F: and for the difference in phonetic context that you ? provide that .
G: actually , these three databases are generic databases . so for italian , which is close to spanish , french and , , ti - digits we have both , digits training data and also more general training data . so . mmm .
F: we also have this broadcast news that we were talking about taking off the disk , which is microphone data for english .
G: perhaps , there is also timit . we could use timit .
F: so there 's plenty of around . so anyway , th the basic plan is to , , test this cube .
E: to fill in the cube .
F: to fill fill it in ,
G: and perhaps , we were thinking that perhaps the cross - language issue is not , , so big of issue . we perhaps we should not focus too much on that cross - language . , training net on language and testing for another language . mmm . perhaps the most important is to have neural networks trained on the target languages . but , , with general database general databases . so that th , the guy who has to develop an application with one language can use the net trained on that language , or generic net ,
F: depen it depends how you mean "" using the net "" .
G: but not trained on
F: so , if you 're talking about for producing these discriminative features that we 're talking about you can't do that . because because the what they 're asking for is feature set . and so , , we 're the ones who have been weird by doing this training . but if we say , "" no , you have to have different feature set for each language , "" this is ver gonna be very bad . , in principle , conceptually , it 's like they want re @ @ , they want replacement for mel cepstra . so , we say "" , this is the year two thousand , we 've got something much better than mel cepstra . it 's , , gobbledy - gook . "" ? and so we give them these gobbledy - gook features but these gobbledy - gook features are supposed to be good for any language . cuz you who 's gonna call , and , so it 's it 's , , how do what language it is ? somebody picks up the phone . so thi this is their image . someone picks up the phone , right ? and and he picks up the ph
G: but the application is there is target language for the application .
F: but , no but , you pick up the phone , you talk on the phone , and it sends features out . so the phone doesn't what your language is .
G: if it 's th in the phone ,
F: but that 's the image that they have .
G: it that could be th at the server 's side ,
F: it could be ,
G: and , . mmm , .
F: but that 's the image they have , so that 's that 's one could argue all over the place about how things really will be in ten years . but the particular image that the cellular industry has right now is that it 's distributed speech recognition , where the , , probabilistic part , and semantics and are all on the servers , and you compute features of the , on the phone . so that 's that 's what we 're involved in . we might or might not agree that 's the way it will be in ten years , but that 's that 's what they 're asking for . so so that th it is an important issue whether it works cross - language . now , it 's the ogi , , folks ' perspective right now that probably that 's not the biggest deal . and that the biggest deal is the , envir acoustic - environment mismatch . and they may very be right , but was hoping we could just do test and determine if that was true . if that 's true , we don't need to worry so much . maybe maybe we have couple languages in the training set and that gives us enough breadth , that that the rest doesn't matter . the other thing is , , this notion of training to which they 're starting to look at up there , training to something more like articulatory features . and if you have something that 's just good for distinguishing different articulatory features that should just be good across , , wide range of languages . so don't th know unfortunately don't see what you 're comi where you 're coming from , , but don't think we can ignore it .
G: so we really have to do test with real cross - language . tr training on english and testing on italian , or or we can train or else , , can we train net on , , range of languages and which can include the test the test @ @ the target language ,
C: test on an unseen .
F: there 's there 's , this is complex . so , ultimately , , as was saying , it doesn't fit within their image that you switch nets based on language . now , can you include , , the target language ? from purist 's standpoint it 'd be not to because then you can say when because surely someone is going to say at some point , "" , so you put in the german and the finnish . now , what do you do , , when somebody has portuguese ? "" and , however , you aren't it isn't actually constraint in this evaluation . so would say if it looks like there 's big difference to put it in , then we 'd make note of it , and then we probably put in the other , because we have so many other problems in trying to get things to work here that , , it 's not so bad as long as we note it and say , "" look , we did do this "" .
A: and so , ideally , what you 'd wanna do is you 'd wanna run it with and without the target language and the training set for wide range of languages . and that way you can say , "" , "" , "" we 're gonna build it for what we think are the most common ones "" , but if that somebody uses it with different language , , "" here 's what 's you 're here 's what 's likely to happen . ""
F: cuz the truth is , is that it 's it 's not like there are , al although there are thousands of languages , , from , the point of view of cellular companies , there aren't . there 's , there 's fifty , an and they aren't , with the exception of finnish , which it 's pretty different from most things . it 's it 's , most of them are like at least some of the others . and so , our that spanish is like italian , and so on . finnish is is little bit like hungarian , supposedly ,
A: anything about finnish .
F: kn , know that , , 'm not linguist , but hungarian and finnish and one of the one of the languages from the former soviet union are in this same family . but they 're just these , , countries that are pretty far apart from one another , have , people rode in on horses and brought their
C: let 's see , spent the last week , , looking over stephane 's shoulder . and and understanding some of the data . re - installed , , htk , the free version , so , , everybody 's now using three point , which is the same version that , , ogi is using . without any licensing big deals , or anything like that . and , , so we 've been talking about this , , cube thing , and it 's beginning more and more looking like the , , the borge cube thing . it 's really gargantuan .
F: so are you going to be assimilated ?
A: resistance is futile .
C: , so 've been looking at , , timit . the that we 've been working on with timit , trying to get , labels file so we can , , train up train up net on timit and test , , the difference between this net trained on timit and net trained on digits alone . and seeing if it hurts or helps .
F: when just to clarify , when you 're talking about training up net , you 're talking about training up net for tandem approach ? and and the inputs are plp and delta and that thing ,
C: the inputs are one dimension of the cube , which , , we 've talked about it being , , plp , , cs , , - jrasta , jrasta - lda
F: but your initial things you 're making one choice there , which is plp , ?
C: haven't haven't decided on the initial thing . probably probably something like plp .
F: so you take plp and you , , do it , you , , use htk with it with the transformed features using neural net that 's trained . and the training could either be from digits itself or from timit . and that 's the and , and th and then the testing would be these other things which which might be foreign language . get in the picture about the cube . those listening to this will not have picture either , so , , 'm 'm not any worse off . but at some point somebody should just show me the cube . get get the general idea of it ,
A: so , when you said that you were getting the labels for timit , , are what do you mean by that ?
C: 'm just 'm just , , transforming them from the , , the standard timit transcriptions into long huge - file to do training .
A: were the digits , , hand - labeled for phones ? or were they those labels automatically derived ?
C: those were those were automatically derived by dan using , , embedded training and alignment .
F: but which dan ?
A: was just wondering because that test you 're you 're doing this test because you want to determine whether or not , , having general speech performs as as having specific speech .
C: that 's right .
F: especially when you go over the different languages again , because you 'd the different languages have different words for the different digits ,
A: so was just wondering if the fact that timit you 're using the hand - labeled from timit might be confuse the results that you get .
F: but on the other hand it might be better .
A: right , but if it 's better , it may be better because it was hand - labeled .
F: but still @ @ probably use it . 'm sounding cavalier , but , you have , , bunch of labels and they 're han hand hand - marked . , actually , timit was not entirely hand - marked . it was automatically first , and then hand - corrected . but but , , , it , , it might be better source . so , it 's you 're right . it would be another interesting scientific question to ask , "" is it because it 's broad source or because it was , , carefully ? "" and that 's something you could ask , but given limited time , the main thing is if it 's better thing for going across languages on this training tandem system , then it 's probably
A: what about the differences in the phone sets ? no , between timit and the digits .
C: there 's mapping from the sixty - one phonemes in timit to fifty - six , the icsi fifty - six .
E: sixty - one .
C: and then the digits phonemes , , there 's about twenty - two or twenty - four of them ? is that right ?
A: out of that fifty - six ?
C: out of that fifty - six . it 's it 's definitely broader ,
G: but , actually , the issue of phoneti phon phone phoneme mappings will arise when we will do severa use several languages because you , some phonemes are not , , in every languages , and so we plan to develop subset of the phonemes , , that includes , , all the phonemes of our training languages , and use network with one hundred outputs like that .
F: you mean superset , .
E: th looks the sampa phone . sampa phone ? for english american english , and the the language who have more phone are the english . of the these language . but , in spain , the spanish have several phone that doesn't appear in the english and we thought to complete . but for that , it needs we must do lot of work because we need to generate new tran transcription for the database that we have .
B: other than the language , is there reason not to use the timit phone set ? cuz it 's larger ? as opposed to the icsi phone set ?
C: you mean why map the sixty - one to the fifty - six ?
F: forget if that happened starting with you , or was it or if it was eric , afterwards who did that . but , , there were several of the phones that were just hardly ever there .
A: and some of them , they were making distinctions between silence at the end and silence at the beginning , when really they 're both silence . th it was things like that got it mapped down to fifty - six .
F: especially in system like ours , which is discriminative system . you 're really asking this net to learn . it 's it 's hard .
A: there 's not much difference , really . and the ones that are gone , are there was they also in timit had like glottal stop , which was short period of silence ,
B: we have that now , too , right ?
F: it 's actually pretty common that lot of the recognition systems people use have things like , say thirty - nine , phone symbols , and then they get the variety by bringing in the context , the phonetic context . so we actually have an unusually large number in what we tend to use here . so , actually maybe now you 've got me intrigued . can you describe what 's on the cube ?
C: th that 's good idea to talk about the whole cube and maybe we could sections in the cube for people to work on . do you wanna do it ?
F: so even though the meeting recorder doesn't doesn't , and since you 're not running video camera we won't get this , but if you use board it 'll help us anyway . point out one of the limitations of this medium , but you 've got the wireless on ,
C: have the wireless .
F: so you can walk around .
C: can can you walk around too ?
F: he can't , actually ,
C: the cube will have three dimensions .
F: he 's tethered .
C: the first dimension is the features that we 're going to use . and the second dimension , , is the training corpus . and that 's the training on the discriminant neural net . the last dimension happens to be
F: so the training for htk is always that 's always set up for the individual test , that there 's some training data and some test data . so that 's different than this .
C: right , right . this is this is for ann only . and , , the training for the htk models is always , , fixed for whatever language you 're testing on . and then , there 's the testing corpus . so , then it 's probably instructive to go and and show you the features that we were talking about . so , let 's see . help me out with
G: and jrasta - lda .
C: jrasta - lda .
G: multi - band .
C: multi - band .
G: so there would be multi - band before , before our network , .
C: just the multi - band features , right ?
G: so , something like , , tct within bands and then multi - band after networks . meaning that we would have , , neural networks , , discriminant neural networks for each band . and using the outputs of these networks or the linear outputs like that .
A: what about mel cepstrum ? you don't include that because it 's part of the base ?
F: you do have baseline system that 's that 's mel cepstra ,
G: not for the ann . we could we could add mfcc also .
F: at least at least conceptually , , it doesn't meant you actually have to do it , conceptually it makes sense as as base line .
A: it 'd be an interesting test just to have just to do mfcc with the neural net and everything else the same . compare that with just - mfcc without the net .
C: dan did some of that . in his previous aurora experiments . and with the net it 's it 's wonderful . without the net it 's just baseline .
F: ogi folks have been doing that , too . because that for bunch of their experiments they used , , mel cepstra , actually . that 's there and this is here and so on .
C: for the training corpus , , we have , , the digits {nonvocalsound} from the various languages . what else do we have ?
G: and the finnish .
A: where did th where did that come from ?
E: no , italian no .
A: is that was that distributed with aurora ,
C: one or two 's ?
A: where did that ?
F: the newer one .
G: so english , , finnish and italian are aurora . and spanish and french is something that we can use in addition to aurora .
F: so carmen brought the spanish , and stephane brought the french . is it french or belgian french ?
G: it 's , , french .
E: like mexican spain and spain . that is more important ,
B: swiss - german .
F: herve always insists that belgian is is pure french , has nothing to do with but he says those those parisians talk funny .
G: they have an accent .
F: they do , . but then he likes belgian fries too ,
C: and then we have , , , broader corpus , , like timit . timit so far ,
E: and spanish too . albayzin is the name .
A: what about ti - digits ?
C: all these aurora data data is from is derived from ti - digits . , they corrupted it with , , different kinds of noises at different snr levels .
F: and stephane was saying there 's there 's some broader material in the french also ?
G: we cou we could use the french data .
C: sp - not spanish stories ?
B: did the aurora people actually corrupt it themselves , or just specify the signal and the signal -
C: they they corrupted it , , themselves , but they also included the noise files for us , so we can go ahead and corrupt other things .
F: 'm just curious , carmen couldn't tell if you were joking or is it is it mexican spanish , it 's it 's spanish from spain , spanish .
E: spanish from spain .
F: spanish from spain . we 're really covered there and the french from france .
G: the no , the french is , from , , paris ,
C: and timit 's from lots of different places .
F: from it 's from texas . so may maybe it 's
B: from the deep south .
F: so - so it 's not really from the us either . is that ? .
C: with within the training corporas , we 're , , thinking about , , training with noise . incorporating the same kinds of noises that , , aurora is in incorporating in their , in their training corpus . don't think we 're given the , the unseen noise conditions , though ,
F: what they were saying was that , , for this next test there 's gonna be some of the cases where they have the same type of noise as you were given before hand and some cases where you 're not . so , presumably , that 'll be part of the topic of analysis of the test results , is how you do when it 's matching noise and how you do where it 's not . that 's right .
C: so , we can't train on the unseen noise conditions .
F: not if it 's not seen ,
C: if not if it 's unseen .
F: , it does seem to me that lot of times when you train with something that 's at least little bit noisy it can it can help you out in other kinds of noise even if it 's not matching just because there 's some more variance that you 've built into things . but , but , , exactly how it will work will depend on how near it is to what you had ahead of time . so . , so that 's your training corpus , and then your testing corpus ?
C: the testing corporas are , , just , , the same ones as aurora testing . and , that includes , , the english spa - , italian . finnish . we ' we 're gonna get german , ge - at the final test will have german .
F: the final test , on , is supposed to be german and danish ,
G: the spanish , perhaps ,
C: we can we can test on spanish .
G: we will have . but the aurora spanish , .
F: there 's there 's spanish testing in the aurora ?
G: but , , , ,
E: it 's preparing .
G: pre they are preparing it ,
E: they are preparing .
G: according to hynek it will be we will have this at the end of november ,
F: something like seven things in each , each column . so that 's , , three hundred and forty - three , , different systems that are going to be developed . there 's three of you .
C: one hundred each , about .
F: hundred and hundred and fourteen each .
D: what what about noise conditions ? don't we need to put in the column for noise conditions ?
F: are you just trying to be difficult ?
C: when put these testings on there , 'm assumi
F: 'm just kidding .
C: there - there 's three tests . type - , type - , and type - . and they 're all they 're all gonna be test tested , , with one training of the htk system . there 's script that tests all three different types of noise conditions . test - is like matched noise . test - is is slightly mismatched . and test - is , , mismatched channel .
D: and do we do all our training on clean data ?
C: no , no ,
E: also , we can clean that .
C: we 're we 're gonna be , , training on the noise files that we do have .
F: so the question is how long does it take to do training ? it 's not crazy these are lot of these are built - in things and we know we have programs that compute plp , we have msg , lot of these things will just happen , won't take huge amount of development , it 's just trying it out . so , we actually can do quite few experiments . but how long does it take , do we think , for one of these trainings ?
C: that 's good question .
A: what about combinations of things ?
F: that 's right . so , , the major advantage of msg major advantage of msg , see , th that we 've seen in the past is combined with plp .
C: now , this is turning into four - dimensional cube ?
A: you just select multiple things on the one dimension .
B: or you just add it to the features .
F: you don't wanna , let 's see , seven choose two would be , , twenty - one different combinations .
B: it 's not complete set of combinations , though , it 's not complete set of combinations , though ,
F: so plp and msg we definitely wanna try cuz we 've had lot of good experience with putting those together .
A: when you do that , you 're increasing the size of the inputs to the net . do you have to reduce the hidden layer , ?
F: so it doesn't increase the number of trainings .
A: no , no , 'm 'm just wondering about number of parameters in the net . do you have to worry about keeping that the same ,
B: there 's computation limit , though ,
F: it 's just more compu
B: isn't there like limit on the computation load , or latency , like that for aurora task ?
F: we haven't talked about any of that , so , there 's not really limit . what it is that there 's there 's , it 's just penalty , that that if you 're using , , megabyte , then they 'll say that 's very , but , , it will never go on cheap cell phone . the computation isn't so much of problem . it 's more the memory . and , expensive cell phones , exa expensive hand - helds , and , are gonna have lots of memory . so it 's just that , , these people see the cheap cell phones as being still the biggest market , was just realizing that , actually , it doesn't explode out , it 's not really two to the seventh . but it 's but it doesn't really explode out the number of trainings cuz these were all trained individually . if you have all of these nets trained some place , then , , you can combine their outputs and do the kl transformation and so , what it blows out is the number of testings . and , and the number of times you do that last part . but that last part , , is so has gotta be pretty quick , it 's just running the data through
A: but wh what about net that 's trained on multiple languages , though ?
F: you gotta do the kl transformation ,
A: is that just separate nets for each language then combined , or is that actually one net trained on ?
E: necessary to put in .
G: probably one net .
F: one would think one net , but we 've don't think we 've tested that .
G: so , in the broader training corpus we can we can use , , the three , or , combination of two languages .
A: in one net .
F: so , the first thing is if if we know how much how long training takes , if we can train up all these combinations , , then we can start working on testing of them individually , and in combination . because the putting them in combination , , is not as much computationally as the training of the nets in the first place . so you do have to compute the kl transformation . which is little bit , but it 's not too much .
G: it 's not too much , but there is the testing also , which implies training , , the htk models
E: the htk model .
F: so if you do have lots of combinations , it 's
G: but it 's it 's not so long .
F: how long does it take for an , , htk training ?
G: it 's around six hours , .
E: it depends on the
G: for training and testing ,
E: more than six hours . for the italian , maybe one day .
F: running on what ? ru running on what machine ? what ravioli is . is it is it an ultra - five , or is it ?
E: who is that ?
B: what ravioli is . we can check really quickly ,
G: it 's - it 's not so long because , , the ti - digits test data is about , how many hours ? th , thirty hours of speech , ,
F: it 's few hours .
G: something like that .
F: clearly , there 's no way we can even begin to do an any significant amount here unless we use multiple machines .
G: it 's six hours .
F: there 's plenty of machines here and they 're they 're often not in great deal of use . so , , it 's it 's key that the that you look at , , , what machines are fast , what machines are used lot are we still using - make ?
C: how how we would - make this , though .
F: once you get the basic thing set up , you have just all the , all these combinations , it 's it 's let 's say it 's six hours or eight hours , for the training of htk . how long is it for training of , , the neural net ?
C: the neural net ?
G: would say two days .
A: depends on the corpuses , right ?
B: it also depends on the net .
E: depends on the corpus .
B: how big is the net ?
E: for albayzin trained on neural network , was , , one day also .
F: but on what machine ?
C: on spert board .
E: the neural net spert .
C: you did you did it on spert board .
F: again , we do have bunch of spert boards . and there there 's you folks are probably go the ones using them right now .
A: is it faster to do it on the spert ,
C: it 's it 's still little faster on the
F: used to be .
C: ad - adam did some testing . or either adam or dan did some testing and they found that the spert board 's still faster . and the benefits is that , , you run out of spert and then you can do other things on your computer ,
F: so you could be we have quite few spert boards . you could set up , , , ten different jobs , , to run on spert different spert boards and have ten other jobs running on different computers . so , it 's got to take that thing , or we 're not going to get through any significant number of these . like this because what it no , what like about it is we we do have problem that we have very limited time . so , with very limited time , we actually have really quite quite bit of computational resource available if you , , get look across the institute and how little things are being used . on the other hand , almost anything that really , is new , where we 're saying , "" , let 's look at , like we were talking before about , , voiced - unvoiced - silence detection features and all those sort "" that 's it 's great thing to go to . but if it 's new , then we have this development and and learning process to go through on top of just the all the work . so , don't see how we 'd do it . so what like about this is you have listed all the things that we already know how to do . and and all the kinds of data that we , at this point , already have . and , , you 're just saying let 's look at the outer product of all of these things and see if we can calculate them . am am interpreting this correctly ? is this what you 're thinking of doing in the short term ? so so then it 's just the missing piece is that you need to , , , talk to talk to , , chuck , talk to , , adam , sort out about , , what 's the best way to really , , attack this as as mass problem in terms of using many machines . and , then , , set it up in terms of scripts and , and , in kind some structured way . and , , when we go to , , ogi next week , , we can then present to them , , what it is that we 're doing . and , , we can pull things out of this list that we think they are doing sufficiently , that , , we 're not we won't be contributing that much . then , , like , we 're there .
B: how big are the nets you 're using ?
C: for the for nets trained on digits , , we have been using , , four hundred order hidden units . and , , for the broader class nets we 're we 're going to increase that because the , , the digits nets only correspond to about twenty phonemes . the broader training corpus nets
F: it 's not actually broader class , it 's actually finer class , but you mean you mean more classes .
C: right , right . that 's what .
F: carmen , did you do you have something else to add ? we you haven't talked too much ,
E: begin to work with the italian database to nnn , to with the front - end and with the htk program and the @ @ . and trained , with the spanish two neural network with plp and with lograsta plp . exactly what is better if lograsta or jrasta .
F: , jrasta has the potential to do better , but it doesn't always . it 's jrasta is more complicated . it 's it 's , instead of doing rasta with log , you 're doing rasta with log - like function that varies depending on parameter , which is supposed to be sensitive to the amount of noise there is . so , it 's like the right transformation to do the filtering in , is dependent on how much noise there is . and so in jrasta you attempt to do that . it 's little complicated because once you do that , you end up in some funny domain and you end up having to do transformation afterwards , which requires some tables . so it 's it 's little messier , there 's more ways that it can go wrong , but if if you 're careful with it , it can do better .
E: it 's bit 'll do better .
F: so , it 's
E: and to to recognize the italian digits with the neural netw spanish neural network , and also to train another neural network with the spanish digits , the database of spanish digits . and working that . but prepa to prepare the database are difficult . was for me , it was difficult work last week with the labels because the program with the label obtained that have , the albayzin , is different to the label to train the neural network . and that is another work that we must to do , to change . albayzin database was labeled automatically with htk . it 's not hand it 's not labels by hand .
F: "" labeled "" . have had problem with the pronunciation . so let 's start over . so , ti timi timit 's hand - labeled , and you 're saying about the spanish ?
E: the spanish labels ? that was in different format , that the format for the the program to train the neural network . necessary to convert .
A: so you 're just having problem converting the labels .
E: it 's it 's because they have one program , feacalc , but no , labecut , labecut , but don't doesn't , , include the htk format to convert . ask even ask to dan ellis what do that , and they he say me that he does doesn't any any form to do that . and at the end , that with labecut transfer to ascii format , and htk is an ascii format . and do another , , one program to put ascii format of htk to ase ay ac ascii format to exceed and they used labcut to pass . actually that was complicated , but , know how we can did that do that .
F: so it 's just usual sometimes say housekeeping , to get these get these things sorted out . so it seems like there 's there 's some peculiarities of the , of each of these dimensions that are getting sorted out . and then , , if you work on getting the , , assembly lines together , and then the pieces get ready to go into the assembly line and gradually can start , , start turning the crank , more or less . we have lot more computational capability here than they do at ogi , what 's what 's great about this is it sets it up in very systematic way , so that , , once these all of these , , mundane but real problems get sorted out , we can just start turning the crank and push all of us through , and then finally figure out what 's best .
C: was thinking two things . the first thing was , we actually had thought of this as like , not in stages , but more along the time axis . just like one stream at time , je - je - je check out the results and go that way .
F: no , 'm just saying , 'm just thinking of it like loops , and so , if you had three nested loops , that you have choice for this , and choice for that , and you 're going through them all . that that 's what . and , , that once you get better handle on how much you can realistically do , , , concurrently on different machines , different sperts , and , , and you see how long it takes on what machine and , you can stand back from it and say , "" , if we look these combinations we 're talking about , and combinations of combinations , and , "" you 'll probably find you can't do it all . so then at that point , , we should sort out which ones do we throw away . which of the combinations across , what are the most likely ones , still think we could do lot of them . it wouldn't surprise me if we could do hundred of them . but , probably when you include all the combinations , you 're actually talking about thousand of them , and that 's probably more than we can do . but hundred is lot . and and , ,
C: and the second thing was about scratch space . and you sent an email about , , scratch space for people to work on . and know that , , stephane 's working from an nt machine , so his home directory exists somewhere else .
F: his his is somewhere else , for bring it back to that . my th want to clarify my point about that that chuck repeated in his note . we 're over the next year or two , we 're gonna be upgrading the networks in this place , but right now they 're still all te all ten megabit lines . and we have reached the this the machines are getting faster and faster . so , it actually has reached the point where it 's significant drag on the time to move the data from one place to another . so , you don't especially in something with repetitive computation where you 're going over it multiple times , you do don't want to have the data that you 're working on distant from where it 's being where the computation 's being done if you can help it . now , we are getting more disk for the central file server , which , since it 's not computational server , would seem to be contradiction to what said . but the idea is that , , suppose you 're working with , , this big bunch of multi multilingual databases . you put them all in the central ser at the cen central file server . then , when you 're working with something and accessing it many times , you copy the piece of it that you 're working with over to some place that 's close to where the computation is and then do all the work there . and then that way you won't have the network you won't be clogging the network for yourself and others . that 's the idea . so , , it 's gonna take us it may be too late for this , , precise crunch we 're in now , it 's gonna take us couple weeks at least to get the , , the amount of disk we 're gonna be getting . we 're actually gonna get , four more , , thirty - six gigabyte drives and , , put them on another disk rack . we ran out of space on the disk rack that we had , so we 're getting another disk rack and four more drives to share between , primarily between this project and the meetings project . we 've put another there 's another eighteen gigabytes that 's that 's in there now to help us with the immediate crunch . so where you 're stephane , where you 're doing your computations . if so , you 're on an nt machine , so you 're using some external machine
G: it 's nutmeg and mustard , ,
F: do these yet ? are these are these , , computational servers , ? 'm 've been out of it . unfortunately , these days my idea of running comput of computa doing computation is running spread sheet . haven't been haven't been doing much computing personally , so those are computational servers . so the other question is what disk there space there is there on the computational servers .
A: 'm not what 's available on and what was the other one ?
F: you 're the you 're the disk czar now .
A: right , right . 'll check on that .
F: so , , chuck will be the one who will be sorting out what disk needs to be where , and so on , and 'll be the one who says , "" , spend the money . "" so . which , , these days , , if you 're talking about scratch space , it doesn't increase the , , need for backup , and , , it 's not that big and the disks themselves are not that expensive . right now it 's
A: what you can do , when you 're on that machine , is , , just go to the slash - scratch directory , and do df minus , and it 'll tell you if there 's space available . and if there is then ,
F: but wasn't it , dave was saying that he preferred that people didn't put in slash - scratch . it 's more putting in xa or xb or ,
A: there 's different there , , there 's so there 's the slash - - whatever disks , and then there 's slash - scratch . and both of those two kinds are not backed up . and if it 's called "" slash - scratch "" , it means it 's probably an internal disk to the machine . and so that 's the thing where , like if , , if you don't have an nt , but you have unix workstation , and they attach an external disk , it 'll be called "" slash - - something "" , if it 's not backed up and it 'll be "" slash - - something "" if it is backed up . and if it 's inside the machine on the desk , it 's called "" slash - scratch "" . but the problem is , if you ever get new machine , they take your machine away . it 's easy to unhook the external disks , put them back on the new machine , but then your slash - scratch is gone . so , you don't wanna put anything in slash - scratch that you wanna keep around for long period of time . but if it 's copy of , say , some data that 's on server , you can put it on slash - scratch because , , first of all it 's not backed up , and second it doesn't matter if that machine disappears and you get new machine because you just recopy it to slash - scratch . so tha that 's why was saying you could check slash - scratch on those on , , mustard and nutmeg to see if there 's space that you could use there . you could also use slash - - whatever disks on mustard and nutmeg . and we do have it 's better to have things local if you 're gonna run over them lots of times so you don't have to go to the network .
F: so es so especially if you 're right , if you 're if you 're taking some piece of the training corpus , which usually resides in where chuck is putting it all on the on the , , file server , , then , , it 's fine if it 's not backed up because if it gets wiped out , it is backed up on the other disk .
A: so , one of the things that need to 've started looking at is this the appropriate time to talk about the disk space ? 've started looking at , , disk space . dan david , , put new , , drive onto abbott , that 's an disk , which means it 's not backed up . 've been going through and copying data that is , , some corpus usually , that we 've got on cd - rom , onto that new disk to free up space on other disks . and , , so far , , 've copied couple of carmen 's , , databases over there . we haven't deleted them off of the slash - dc disk that they 're on right now in abbott , but we would like to go through sit down with you about some of these other ones and see if we can move them onto , , this new disk also . there 's there 's lot more space there , and it 'll free up more space for doing the experiments and things . so , anything that you don't need backed up , we can put on this new disk . but if it 's experiments and you 're creating files and things that you 're gonna need , you probably wanna have those on disk that 's backed up , just in case something goes wrong . so far 've 've copied couple of things , but haven't deleted anything off of the old disk to make room yet . and haven't looked at the any of the aurora , except for the spanish . so 'll need to get together with you and see what data we can move onto the new disk .
F: an another question occurred to me is what were you folks planning to do about normalization ?
G: we were thinking about using this systematically for all the experiments . so that this could be another dimension , but we think perhaps we can use the best , , , , normalization scheme as ogi is using , so , with parameters that they use there ,
F: that 's good idea . it 's we seem to have enough dimensions as it is . so probably if we take their probably the on - line normalization because then it 's if we do anything else , we 're gonna end up having to do on - line normalization too , so we may as just do on - line normalization . so that it 's plausible for the final thing . th the other topic maybe we 're already there , or almost there , is goals for the for next week 's meeting . it seems to me that we wanna do is flush out what you put on the board here . maybe , have it be somewhat visual , little bit .
C: like like slide ?
F: so we can say what we 're doing , and , , also , if you have sorted out , , this information about how long roughly how long it takes to do on what and , , what we can how many of these trainings , , and testings and that we can realistically do , , then one of the big goals of going there next week would be to actually settle on which of them we 're gonna do . and , , when we come back we can charge in and do it . actually started out this field trip started off with , , stephane talking to hynek , so you may have you may have had other goals , , for going up , and any anything else you can think of would be we should think about accomplishing ? 'm just saying this because maybe there 's things we need to do in preparation .
G: , this is this is ,
F: and and the other the last topic had here was , , dave 's fine offer to , , do something on this . he 's doing he 's working on other things , but to do something on this project . so the question is , "" where where could we , , most use dave 's help ? ""
G: was thinking perhaps if , , additionally to all these experiments , which is not really research , it 's , , running programs and , , trying to have closer look at the perhaps the , , speech , , noise detection or , , voiced - sound - unvoiced - sound detection and which could be important in for noise
A: that would be that 's big deal . because the , the thing that sunil was talking about , , with the labels , , labeling the database when it got to the noisy ? the that that really throws things off . having the noise all of sudden , your , , speech detector , what was it ? what was happening with his thing ? he was running through these models very quickly . he was getting lots of , insertions , is what it was , in his recognitions .
F: maybe that 's the right thing the only problem have with it is exactly the same reason why you thought it 'd be good thing to do . let 's fall back to that . but the first responsibility is to figure out if there 's something that , , an additional that 's good thing you remove the mike . what an additional clever person could help with when we 're really in crunch for time . cuz dave 's gonna be around for long time , he 's he 's gonna be here for years . and so , , over years , if he 's if he 's interested in , , voiced - unvoiced - silence , he could do lot . but if there if there 's something else that he could be doing , that would help us when we 're we 're strapped for time we have we 've , , only , , another month or two to , with the holidays in the middle of it , , to get lot done . if we can think of something some piece of this that 's going to be the very fact that it is just work , and and it 's running programs and , is exactly why it 's possible that it some piece of could be handed to someone to do , because it 's not so that 's the question . and we don't have to solve it right this second , but if we could think of some piece that 's that 's defined , that he could help with , he 's expressing will willingness to do that .
A: what about training up , , multilingual net ?
E: maybe to , mmm , put together the label the labels between timit and spanish like that .
G: so defining the superset , and , , joining the data
F: that 's something that needs to be done in any event . so what we were just saying is that , was arguing for , if possible , coming up with something that really was development and wasn't research because we 're we have time crunch . and so , , if there 's something that would save some time that someone else could do on some other piece , then we should think of that first . see the thing with voiced - unvoiced - silence is really think that it 's to do poor job is pretty quick , or , , so - so job . you can you can throw in couple fea we kinds of features help with it . you can throw something in . you can do pretty . but remember , , when you were working on that , and you worked on for few months , as recall , and you got to , say ninety - three percent , and getting to ninety - four really hard . and th the other tricky thing is , since we are , even though we 're not we don't have strict prohibition on memory size , and computational complexity , , clearly there 's some limitation to it . so if we have to if we say we have to have pitch detector , say , if we if we 're trying to incorporate pitch information , or at least some harmonic harmonicity , , this is another whole thing , take while to develop . anyway , it 's very interesting topic . one one of the lot of people would say , and dan would also , , that one of the things wrong with current speech recognition is that we really do throw away all the harmonicity information . we try to get spectral envelopes . reason for doing that is that most of the information about the phonetic identity is in the spectral envelopes are not in the harmonic detail . but the harmonic detail does tell you something . like the fact that there is harmonic detail is real important . so wh that so the other suggestion that just came up was , what about having him work on the , , multilingual super superset thing . coming up with that and then , , training it training net on that , say , , from , from timit . is that or , for multiple databases . what what would you would wh what would this task consist of ?
G: it would consist in , , creating the superset , and , , modifying the lab labels for matching the superset .
F: creating superset from looking at the multiple languages ,
G: creating the mappings , actually .
F: and then creating changing labels on timit ? or on or on multiple language multiple languages ?
E: the multiple language .
G: with the @ @ three languages ,
E: maybe for the other language because timit have more phone .
A: so you 'd have to create mapping from each language to the superset .
G: from each language to the superset ,
C: carmen was talking about this sampa thing , and it 's , , it 's an effort by linguists to come up with , , machine readable ipa , , thing , and , , they have web site that stephane was showing us that has , has all the english phonemes and their sampa correspondent , , phoneme , and then , , they have spanish , they have german , they have all sorts of languages , , mapping to the sampa phonemes ,
E: the tr the transcription , though , for albayzin is the transcription are of sampa the same , , how you say , symbol that sampa appear .
B: what does "" sampa "" mean ?
E: but if timit how is timit .
B: was gonna say , does that mean ipa is not really international ?
C: no , it 's it 's saying
A: it uses special diacritics and , which you can't do with ascii characters .
C: can't print on ascii .
A: so the sampa 's just mapping those .
F: has ogi done anything about this issue ? do they have do they have any superset that they already have ?
G: they they 're going actually the other way , defining , phoneme clusters , .
F: that 's right . and that 's an interesting way to go too .
A: so they just throw the speech from all different languages together , then cluster it into sixty or fifty or whatever clusters ?
G: they 've not done it , , doing , , multiple language yet , but what they did is to training , , english nets with all the phonemes , and then training it in english nets with , , seventeen , it was seventeen , , broad classes .
A: automatically derived broad classes , or ?
G: and the result was that , when testing on cross - language it was better . but hynek didn't add didn't have all the results when he showed me that ,
F: so that does make an interesting question , though . is there 's some way that we should tie into that with this . if that is better thing to do , should we leverage that , rather than doing , , our own . so , if if they we have we have the trainings with our own categories . and now we 're saying , "" , how do we handle cross - language ? "" and one way is to come up with superset , but they are als they 're trying coming up with clustered , and do we think there 's something wrong with that ?
G: that there 's something wrong for the moment we are testing on digits , and perhaps using broad phoneme classes , it 's it 's for , classifying the digits , but as soon as you will have more words , words can differ with only single phoneme , and which could be the same , , class .
F: although , you are not using this for the you 're using this for the feature generation , though , not the
G: but you will ask the net to put one for th the phoneme class
A: so you 're saying that there may not be enough information coming out of the net to help you discriminate the words ?
B: fact , most confusions are within the phone classes , right ? , larry was saying like obstruents are only confused with other obstruents , et cetera .
C: so so , maybe we could look at articulatory type ,
F: but that 's what they were gonna did they not do that ,
G: they were talking about , perhaps ,
F: they 're talking about it , but that 's question whether they did because that 's that 's the other route to go . instead of this , instead of the the superclass thing , which is to take so suppose you don't really mark arti to really mark articulatory features , you really wanna look at the acoustics and see where everything is , and we 're not gonna do that . the second class way of doing it is to look at the , , phones that are labeled and translate them into acoustic , articulatory , , features . so it won't really be right . you won't really have these overlapping things and ,
A: so the targets of the net are these ? but that implies that you can have more than one on at time ?
F: that 's right . you either do that or you have multiple nets . if our software this if the qu versions of the quicknet that we 're using allows for that . multiple targets being one ?
C: we have gotten soft targets to work .
F: so that 'll work , that 's another thing that could be done is that we could we could , , just translate instead of translating to superset , just translate to articulatory features , some set of articulatory features and train with that . now the fact even though it 's smaller number , it 's still fine because you have the , , combinations . so , , it has every , it had has every distinction in it that you would have the other way . but it should go across languages better .
A: we could do an interesting cheating experiment with that too . we could , if you had the phone labels , you could replace them by their articulatory features and then feed in vector with those , things turned on based on what they 're supposed to be for each phone to see if it if you get big win . do what 'm saying ? if your net is gonna be outputting , , vector of of it 's gonna have probabilities , but let 's say that they were ones and zeros , then and for each , if this for your testing data , but if for your test data , , what the string of phones is and you have them aligned , then you can just instead of going through the net , just create the vector for each phone and feed that in to see if that data helps . , what made me think about this is , was talking with hynek and he said that there was guy at - andt who spent eighteen months working on single feature . and because they had done some cheating experiments
F: this was the guy that we were just talking that we saw on campus . so , this was larry saul who did this did this . he used sonorants . was what he was doing .
A: and they had done cheating experiment , right ?
F: he he di he didn't mention that part .
A: hynek said that , before they had him work on this , they had done some experiment where if they could get that one feature right , it dramatically improved the result . so was thinking , it made me think about this , that if it 'd be an interesting experiment just to see , , if you did get all of those right .
F: because if you get all of them in there , that defines all of the phones . so that 's that 's equivalent to saying that you 've got all the phones right . so , if that doesn't help , there 's although , , it would be make an interesting cheating experiment because we are using it in this funny way , where we 're converting it into features .
A: and then you also what error they 've got on the htk side . it gives you your the best you could hope for , .
B: the soft training of the nets still requires the vector to sum to one , though ,
C: to sum up to one .
B: so you can't really feed it , like , two articulatory features that are on at the same time with ones cuz it 'll normalize them down to one half like that , .
G: but perhaps you have the choice of the final nonl is it always softmax
C: it 's actually sigmoid -
G: so if you choose sigmoid it 's it 's ?
F: did we just run out of disk ,
B: why don't you just choose linear ?
C: what 's that ?
B: isn't that what you 'll want ? if you 're gonna do kl transform on it .
C: right , right . but during the training , we would train on sigmoid - and then at the end just chop off the final nonlinearity .
F: so , we 're we 're off the air , about to be off the air .
","The main topics discussed were arrangements and objectives of an
upcoming field trip to visit research partners OGI; a number of
members reported their progress to date; if there are any tasks that
one member can help others with; an overall description of the Cube
project , a multi-lingual speech recognition system for use by the
cellular phone industry , along with consideration of some of the
issues therein , specifically disk and resource issues.
Essentially the cube consists of three dimension: input features;
training corpus; and test corpus.
Most important concerns are which
combinations of features to use , and what combinations of languages
and broad/specific corpora to use for the training
The group will meet at the building at 6am to go to the airport for
their field trip together.
Speaker me018 needs to discuss files that can be moved with speaker
mn007.
For the OGI meeting they need to take a clear description of the cube
project , and an estimate of how long the entire process should take.
At the meeting they should discuss what they will ultimately put
through the system.
People are to consider what me034 could do on the project to speed
things up , though creating the phoneme superset is a possibility.
Speaker me018 is to look into the machines that mn007 has been running
data on to find out what they are.
Rather than consider level of normalization as a further dimension to
the project , whatever OGI finds the best will be used systematically.
Need to use multiple machines and SPERT boards to run processes on
because they take so long.
They will consider looking at articulatory features rather than
straight phonemes , though it wouldn't be perfect.
It is not clear what combinations of dimensions , which features,
should be run in the cube project.
It is important to know because
the processes are going to be large and processor and memory hungry.
To bear in mind is the fact that the cellular industry has an image of
speech recognition in that's what they are after.
Must be careful if using a broad training source that is carefully
hand marked , because it would be unclear which is the reason for
improvement.
Memory is of concern , because final product needs to run potentially
one cheaper cell phones , which have limited memory capacity.
OGI doesn't have a phoneme superset ready prepared , for they are
working with clusters , which may be good enough for digits , but not
for discriminating words.
Speaker mn007 has been preparing the French digit database.
Training
and testing with varying noise.
speaker me006 has installed updated software for everyone.
Working on
label files from TIMIT for training neural nets.
Trying to figure out
what the input to the cube should be.
speaker fn002 has been testing the Italian database on a net trained
on Spanish.
She has had problems with incompatible labels though.
Within the next year , the network is to be upgraded , and in a couple
of weeks , the group should have access to 4 new 36 gigabyte file
servers.
Me018 has been copying some corpus stuff to a non-backed up
system , but not yet deleted originals.
Current plan is to use a superset of phones for the cube project
derived from the various training languages.
HTK training currently takes 6 hours to a day , and the neural net
takes 1-2 days.
"
ami_abstractive_summary,Bro025.txt,"A: alright . we 're on .
B: test , . test , test . that 's me . there 's two sheets of paper in front of us .
A: what are these ?
B: this is the arm wrestling ?
C: , we formed coalition actually . we already made it into one .
B: that 's the best thing . so , tell me about it .
E: so it 's , it 's spectral subtraction or wiener filtering , depending on if we put if we square the transfer function or not . and then with over - estimation of the noise , depending on the , the snr , with smoothing along time , smoothing along frequency . it 's very simple , smoothing things . and , , the best result is when we apply this procedure on fft bins , , with wiener filter . and there is no noise addition after that . so it 's good because it 's difficult when we have to add noise to to find the right level .
A: are you looking at one in particular of these two ?
E: so the sh it 's the sheet that gives fifty - three point sixty - six . the second sheet is abo , about the same . it 's the same , , idea but it 's working on mel bands , and it 's spectral subtraction instead of wiener filter , and there is also noise addition after , , cleaning up the mel bins . the results are similar .
B: , it 's it 's actually , , very similar . if you look at databases , the , , one that has the smallest smaller overall number is actually better on the finnish and spanish , but it is , , worse on the , , aurora
E: it 's worse on
B: on the , , ti - digits ,
E: on the multi - condition in ti - digits . .
B: so , it probably doesn't matter that much either way . but , , when you say , unified do you mean , , it 's one piece of software now ,
E: so now we are , , setting up the software . it should be ready , , very soon .
A: so what 's what 's happened ? 've missed something .
B: maybe you weren't around when when hynek and guenther and ?
C: hynek was here .
B: . so , let 's summarize . and then if summarize somebody can tell me if 'm wrong , which will also be possibly helpful . what did press here ? hope this is still working . we , we looked at , {nonvocalsound} anyway we after coming back from qualcomm we had , , very strong feedback and , , it was hynek and guenter 's and my opinion also that , , , we spread out to look at number of different ways of doing noise suppression . but given the limited time , , it was time to choose one . and so , , th the vector taylor series hadn't really worked out that much . the subspace , , had not been worked with so much . so it came down to spectral subtraction versus wiener filtering . we had long discussion about how they were the same and how they were , completely different . and , , , fundamentally they 're the same thing but the math is little different so that there 's there 's an exponent difference in the index what 's the ideal filtering , and depending on how you construct the problem . and , , it 's sort , after that meeting it made more sense to me because , if you 're dealing with power spectra then how are you gonna choose your error ? and typically you 'll do choose something like variance . and so that means it 'll be something like the square of the power spectra . whereas when you 're when you 're doing the , , , looking at it the other way , you 're gonna be dealing with signals and you 're gonna end up looking at power , noise power that you 're trying to reduce . and so , so there should be difference of , conceptually of , , factor of two in the exponent . but there 're so many different little factors that you adjust in terms of , , , over - subtraction and and , that arguably , you 're and and the choice of do you do you operate on the mel bands or do you operate on the fft beforehand . there 're so many other choices to make that are almost , if not independent , certainly in addition to the choice of whether you , , do spectral subtraction or wiener filtering , that , , @ @ again we felt the gang should just figure out which it is they wanna do and then let 's pick it , go forward with it . so that 's that was last week . and and , , we said , , take week , go arm wrestle , figure it out . and th the joke there was that each of them had specialized in one of them . and and so they so instead they went to yosemite and bonded , and they came out with single piece of software . so it 's another victory for international collaboration .
A: so so you guys have combined or you 're going to be combining the software ?
C: the piece of software has , like , plenty of options , like you can parse command - line arguments . so depending on that , it becomes either spectral subtraction or wiener filtering .
A: they 're close enough .
B: that 's fine , but the important thing is that there is piece of software that you that we all will be using now .
C: there 's just one piece of software .
E: need to allow it to do everything and even more than this . if we want to , like , optimize different parameters of we can do it later . but , still so , there will be piece of software with , , will give this system , the fifty - three point sixty - six , by default
A: how how is how good is that ? don't have sense of
E: it 's just one percent off of the best proposal . it 's between we are second actually if we take this system .
A: compared to the last evaluation numbers ? .
B: which we were before but we were considerably far behind . and , this doesn't have neural net in yet . so it so , , it 's it 's not using our full bal bag of tricks , if you will . and , , and it is , , very close in performance to the best thing that was there before . but , , looking at it another way , maybe more importantly , , we didn't have any explicit noise , , handling we didn't explicitly have anything to deal with stationary noise . and now we do .
A: so will the neural net operate on the output from either the wiener filtering or the spectral subtraction ? or will it operate on the original ?
B: so so argu arguably , , what we should do gather you have it sounds like you have few more days of nailing things down with the software and so on . but and then but , , arguably what we should do is , even though the software can do many things , we should for now pick set of things , th these things would , and not change that . and then focus on everything that 's left . and , , that our goal should be by next week , when hynek comes back , , to , really just to have firm path , , for the , for the time he 's gone , of , , what things will be attacked . but would would thought think that what we would wanna do is not futz with this for while because what 'll happen is we 'll change many other things in the system , and then we 'll probably wanna come back to this and possibly make some other choices .
A: but just conceptually , where does the neural net go ? do do you wanna run it on the output of the spectrally subtracted ?
B: depending on its size one question is , is it on the , , server side or is it on the terminal side ? if it 's on the server side , it you probably don't have to worry too much about size . so that 's an argument for that . we do still , however , have to consider its latency . so the issue is , , , could we have neural net that only looked at the past ? what we 've done in in the past is to use the neural net , , to transform , , all of the features that we use . so this is done early on . this is essentially , , it 's it 's more or less like spee speech enhancement technique here where we 're just creating new if not new speech at least new fft 's that have , which could be turned into speech that have some of the noise removed . after that we still do mess of other things to produce bunch of features . and then those features are not now currently transformed by the neural net . and then the way that we had it in our proposal - two before , we had the neural net transformed features and we had the untransformed features , which you actually did linearly transform with the klt , but , to orthogonalize them but they were not , , processed through neural net . and stephane 's idea with that , as recall , was that you 'd have one part of the feature vector that was very discriminant and another part that wasn't , which would smooth things bit for those occasions when , , the testing set was quite different than what you 'd trained your discriminant features for . so , , all of that is , still seems like good idea . now we know some other constraints . we can't have unlimited amounts of latency . , that 's still being debated by the by people in europe but , , no matter how they end up there , it 's not going to be unlimited amounts , so we have to be little conscious of that . so there 's the neural net issue . there 's the vad issue . and , , there 's the second stream thing . and those that we last time we that those are the three things that have to get , , focused on .
A: what was the issue with the vad ?
B: better ones are good .
A: and so the the default , , boundaries that they provide are they 're , but they 're not all that great ?
B: they still allow two hundred milliseconds on either side or some ? is that what the deal is ?
E: so th , they keep two hundred milliseconds at the beginning and end of speech . and they keep all the
A: outside the beginnings and end .
E: and all the speech pauses , which is sometimes on the speechdat - car you have pauses that are more than one or two seconds . more than one second for . and , , it seems to us that this way of just dropping the beginning and end is not we cou we can do better , , because , , with this way of dropping the frames they improve over the baseline by fourteen percent and sunil already showed that with our current vad we can improve by more than twenty percent .
A: on top of the vad that they provide ?
E: just using either their vad or our current vad . so , our current vad is more than twenty percent , while their is fourteen .
A: theirs is fourteen ?
E: and another thing that we did also is that we have all this training data for let 's say , for speechdat - car . we have channel zero which is clean , channel one which is far - field microphone . if we just take only the , , vad probabilities computed on the clean signal and apply them on the far - field , , test utterances , then results are much better . in some cases it divides the error rate by two . so it means that there are stim still
A: how how much latency does the , does our vad add ?
E: if if we can have good vad , , it would be great .
A: is it significant ,
E: right now it 's , , neural net with nine frames . so it 's forty milliseconds plus , , the rank ordering , which , , should be
C: like another ten frames .
E: so , right now it 's one hundred and forty milliseconds .
B: with the rank ordering ?
C: the the smoothing the the filtering of the probabilities .
E: it 's not median filtering . it 's just we don't take the median value . we take something so we have eleven , , frames .
B: this is for the vad .
E: for the vad , and we take th the third .
B: so , was just noticing on this that it makes reference to delay . so what 's the ? if you ignore the vad is in parallel , isn't isn't it , with the ? , it isn't additive with the , , lda and the wiener filtering , and .
C: so so what happened right now , we removed the delay of the lda . so we , if so if we if so which is like if we reduce the delay of va so , the the final delay 's now ba is determined by the delay of the vad , because the lda doesn't have any delay . so if we re if we reduce the delay of the vad , , it 's like effectively reducing the delay .
A: how how much , , delay was there on the lda ?
C: so the lda and the vad both had hundred millisecond delay . so and they were in parallel , so which means you pick either one of them the biggest , whatever . so , right now the lda delays are more .
B: and there didn't seem to be any , , penalty for that ? there didn't seem to be any penalty for making it causal ?
C: no . it actually made it , like , point one percent better , actually .
B: may as , then . and he says wiener filter is forty milliseconds delay . so is it ?
C: so that 's the one which stephane was discussing , like the you smooth it and then delay the decision by
B: so that 's that 's really not bad . so we may we 'll see what they decide . we may have , , the , , latency time available for to have neural net . sounds like we probably will . that 'd be good . cuz cuz it certainly always helped us before .
A: what amount of latency are you thinking about when you say that ?
B: they 're , they 're disputing it . they 're saying , one group is saying hundred and thirty milliseconds and another group is saying two hundred and fifty milliseconds . two hundred and fifty is what it was before actually . some people are lobbying to make it shorter .
A: were you thinking of the two - fifty or the one - thirty when you said we should have enough for the neural net ?
B: it just it when we find that out it might change exactly how we do it , is all . how much effort do we put into making it causal ? the neural net will probably do better if it looks at little bit of the future . but , , it will probably work to some extent to look only at the past . and we ha , limited machine and human time , and effort . and , , how much time should we put into that ? so it 'd be helpful if we find out from the standards folks whether , , they 're gonna restrict that or not . but , , at this point our major concern is making the performance better and , , if , , something has to take little longer in latency in order to do it that 's , secondary issue . but if we get told otherwise then , , we may have to clamp down bit more .
C: so , the one one difference is that was there is like we tried computing the delta and then doing the frame - dropping . the earlier system was do the frame - dropping and then compute the delta on the
A: which could be funny delta .
B: so that 's fixed in this . we talked about that .
C: so we have no delta . and then so the frame - dropping is the last thing that we do . so , , what we do is we compute the silence probability , convert it to that binary flag , and then in the end you up upsample it to match the final features number of
A: did that help then ?
C: it seems to be helping on the - matched condition . so that 's why this improvement got from the last result . so . and it actually reduced little bit on the high mismatch , so in the final weightage it 's better because the - matched is still weighted more than
B: so , @ @ , you were doing lot of changes . did you happen to notice how much , , the change was due to just this frame - dropping problem ? what about this ?
C: you had something on it .
E: just the frame - dropping problem . but it 's it 's difficult . sometime we change two things together and but it 's around maybe it 's less than one percent .
B: but like we 're saying , if there 's four or five things like that then pretty sho soon you 're talking real improvement .
E: and then we have to be careful with that also with the neural net because in the proposal the neural net was also , , working on after frame - dropping .
B: that 's real good point .
E: so . , we 'll have to be to do the same correction .
B: it might be hard if it 's at the server side .
E: mmm . , we can do the frame - dropping on the server side or we can just be careful at the terminal side to send couple of more frames before and after ,
A: maybe don't quite understand how this works , but , , couldn't you just send all of the frames , but mark the ones that are supposed to be dropped ? cuz you have bunch more bandwidth .
B: , it always seemed to us that it would be to in addition to , , reducing insertions , actually use up less bandwidth . but nobody seems to have cared about that in this evaluation .
A: and that way the net could use if the net 's on the server side then it could use all of the frames .
C: yes , it could be . it 's , like , you mean you just transferred everything and then finally drop the frames after the neural net . that 's that 's one thing which
A: but you could even mark them , before they get to the server .
C: right now we are right now what wha what we did is , like , we just mark we just have this additional bit which goes around the features , saying it 's currently it 's speech or nonspeech . so there is no frame - dropping till the final features , like , including the deltas are computed . and after the deltas are computed , you just pick up the ones that are marked silence and then drop them .
B: so it would be more or less the same thing with the neural net , , actually .
C: so . , that 's what that 's what , , this is doing right now .
B: what 's , ? that 's that 's good set of work that ,
C: just one more thing . like , should we do something more for the noise estimation , because we still ?
B: was wondering about that . that was had written that down there .
E: so , we , actually did the first experiment . this is with just fifteen frames . we take the first fifteen frame of each utterance to it , and average their power spectra . tried just plugging the , , , guenter noise estimation on this system , and it , it got worse . but didn't play with it . didn't do much more for noise estimation . tried this ,
B: . , it 's not surprising it 'd be worse the first time . it does seem like , , some compromise between always depending on the first fifteen frames and always depending on pause is is good idea . maybe you have to weight the estimate from the first - teen fifteen frames more heavily than was done in your first attempt . do you have any way of assessing how or how poorly the noise estimation is currently doing ?
E: mmm . no , we don't . we don't have nothing that
C: is there was there any experiment with ? did the only experiment where tried was used the channel zero vad for the noise estimation and frame - dropping . so don't have don't have split , like which one helped more . so . it it was the best result could get . so , that 's the
B: so that 's something you could do with , , this final system . just do this everything that is in this final system except , , use the channel zero .
C: for the noise estimation . we can try something .
B: and then see how much better it gets . if it 's , , essentially not better , then it 's probably not worth
C: but the guenter 's argument is slightly different . it 's , like , ev even if use channel zero vad , 'm just averaging the power spectrum . but the guenter 's argument is , like , if it is non - stationary segment , then he doesn't update the noise spectrum . so he 's , like he tries to capture only the stationary part in it . so the averaging is , like , different from updating the noise spectrum only during stationary segments . so , th the guenter was arguing that , , even if you have very good vad , averaging it , like , over the whole thing is not good idea . because you 're averaging the stationary and the non - stationary , and finally you end up getting something which is not really the because , you anyway , you can't remove the stationary part fr , non - stationary part from the signal .
B: not using these methods anyway . .
C: so you just update only doing or update only the stationary components . so , that 's so that 's still slight difference from what guenter is trying
B: . and and also there 's just the fact that , , , although we 're trying to do very on this evaluation , , we actually would like to have something that worked in general . and , , relying on having fifteen frames at the front is pretty you might not . it 'd certainly be more robust to different kinds of input if you had at least some updates . what what do you , what do you guys see as being what you would be doing in the next week , given wha what 's happened ?
C: cure the vad ?
A: what was that ?
E: so , should we keep the same ? we might try to keep the same idea of having neural network , but training it on more data and adding better features , , but because the current network is just plp features . it 's trained on noisy plp
C: just the cepstra .
E: plp features computed on noisy speech . but there is no nothing particularly robust in these features . there 's no rasta , no
A: so , , don't remember what you said the answer to my , , question earlier . will you will you train the net on after you 've done the spectral subtraction or the wiener filtering ?
B: this is different net .
C: so we have vad which is like neur that 's neural net .
A: you 're talking about the vad net .
C: so that vad was trained on the noisy features . so , right now we have , like , we have the cleaned - up features , so we can have better vad by training the net on the cleaned - up speech .
A: see . see .
C: but we need vad for noise estimation also . so it 's , like , where do we want to put the vad ?
A: can you use the same net to do both , can you use the same net that you that was talking about to do the vad ?
C: it actually comes at at the very end . so the net the final net , which is the feature net so that actually comes after chain of , like , lda plus everything . so it 's , like , it takes long time to get decision out of it . and and you can actually do it for final frame - dropping , but not for the va - noise estimation .
B: you see , the idea is that the , , initial decision to that you 're in silence or speech happens pretty quickly .
A: cuz that 's used by some of these other ?
B: and that 's fed forward , and you say "" , flush everything , it 's not speech anymore "" .
A: that was only used for doing frame - dropping later on .
B: it is used , it 's only used , it 's used for frame - dropping . it 's used for end of utterance because , , there 's if you have more than five hundred milliseconds of of nonspeech then you figure it 's end of utterance like that .
E: and it seems important for , like , the on - line normalization . we don't want to update the mean and variance during silen long silence portions . so it has to be done before this mean and variance normalization .
B: so probably the vad and maybe testing out the noise estimation little bit . keeping the same method but , , seeing if you cou but , noise estimation could be improved . those are related issues . it probably makes sense to move from there . and then , , later on in the month we wanna start including the neural net at the end .
E: the half dome was great .
B: you didn't didn't fall . that 's good . our our effort would have been devastated if you guys had run into problems .
A: so , hynek is coming back next week , you said ?
B: that 's the plan . the week after he 'll be , , going back to europe , and so we wanna
A: is he in europe right now or is he up at ?
B: no , no . he 's he 's dropped into the us . . the idea was that , , we 'd we 'd sort out where we were going next with this with this work before he , , left on this next trip . good . , barry , you just got through your quals , so if you have much to say .
D: no , just , , looking into some of the things that , , , john ohala and hynek , , gave as feedback , as starting point for the project . in in my proposal , was thinking about starting from set of , , phonological features , or subset of them . but that might not be necessarily good idea according to , , john . he said , , , these phonological features are figments of imagination also .
B: in conversational speech in particular . you can you can put them in pretty reliably in synthetic speech . but we don't have too much trouble recognizing synthetic speech since we create it in the first place . so , it 's
D: so , , better way would be something more data - driven , just looking at the data and seeing what 's similar and what 's not similar . so , 'm 'm , , taking look at some of , , sangita 's work on traps . she did something where , where the traps learn she clustered the temporal patterns of , , certain phonemes in averaged over many , many contexts . and , , some things tended to cluster . right ? , like stop consonants clustered really . silence was by its own self . and , , , vocalic was clustered . and , , so , those are interesting things to
A: so you 're now you 're looking to try to gather set of these types of features ?
D: just to see where could start off from , set of small features and continue to iterate and find , , better set .
B: , short meeting . so next week hopefully we 'll can get hynek here to join us
A: should we do digits ?
B: digits , digits .
A: go ahead , morgan . you can start .
B: alright . let me get my glasses on so see them .
A: and we 're off .
","ICSI's Meeting Recorder Group have returned from a meeting with some important decisions to make.
They have developed a piece of software which allows them to implement their two main approaches to dealing with noise.
The base rate is currently set at the second best rate as of the last project evaluation , and it does not yet include everything the group have been working on.
With this in mind , they have decided to set most things , and concentrate on studying only a few key aspects , the neural network , the voice activity detector , and the noise estimation.
By the time a senior member of their research partners OGI returns , they want to have a firm plan of what they will be doing.
System latency is still an issue , but limits have still not been set by the project heads.
The group have encountered problems with frame-dropping , and will need to bear that in mind since their neural network would come after that stage.
While deciding which of two approaches to finally adopt , the group put together one piece of software for all to use that implements both spectral subtraction and wiener filtering.
Speaker me026 has done his quals , and is looking at some of the feedback he received.
"
ami_abstractive_summary,Bmr009.txt,"D: that 's different thing .
C: it starts with . forget the word for it , but it 's it 's typically when you 're ab starting around forty for most people , it starts to harden and then it 's just harder for the lens to shift things and th the symptom is typically that you have to hold further away to see it . my brother 's gerontological psychologist and he came up with an body age test which gets down to only three measurements that are good enough st statistical predictors of all the rest of it . and one of them is the distance that you have to hold it at .
D: give someone piece of paper and then they .
A: we 're we 're live , so we 've got good intro here
C: about how old am .
A: we can edit that out if you want .
D: that 's optional .
C: no , that 's .
A: so . this time the form discussion should be very short ,
C: it also should be later . because jane is not here yet . and she 'll be most interested in that . she 's probably least involved in the signal - processing so maybe we can just , don't think we should go though an elaborate thing , but jose and were just talking about the {nonvocalsound} , speech energy thing , we didn't talk about the derivatives . but , , the if if you don't mind my speaking for you for bit , . right now , that he 's not really showing any distinction , but but we discussed couple of the possible things that he can look at . and one is that this is all in log energy and log energy is compressing the distances between things . another is that he needs to play with the different temporal sizes . he was he was taking everything over two hundred milliseconds and he 's going to vary that number and also look at moving windows , as we discussed before . and and the other thing is that the doing the subtracting off the mean and the variance in the and dividing it by the standard deviation in the log domain , may not be the right thing to do .
A: we just started . could you take that mike there ?
D: are these the long term means ? like , over the whole the means of what ? all the frames in the conversation ? or of things that
C: it 's between the pauses for some segment . and so his he 's making the constraint it has to be at least two hundred milliseconds . and so you take that . and then he 's he 's measuring at the frame level still at the frame level , of what and then and then just normalizing with that larger amount . and but one thing he was pointing out is when he looked at bunch of examples in log domain , it is actually pretty hard to see the change . and you can see that , because of of just putting it on the board that if you have log - plus log - , that 's the log of plus the log of two
D: maybe it 's not log distributed .
C: and it 's just , , it diminishes the effect of having two of them .
D: but you could do like there instead ? we that the distribution here is normally .
C: yes , right . so what was suggesting to him is that
D: so just some simple
C: actually , pdf . but , , but , either way .
D: something like that where it 's data driven .
C: but also good first indicator is when the the researcher looks at examples of the data and can not see change in how big the signal is , when the two speaker then , that 's problem right there . so . you should at least be able , doing casual looking and can get the sense , "" hey , there 's something there . "" and then you can play around with the measures . and when he 's looking in the log domain he 's not really seeing it . and when he 's looking in straight energy he is , so that 's good place to start . so that was that was the discussion we just had . actually we ca had question for adam in this . when you did the sampling ? over the speech segments or or sampling over the individual channels in order to do the the amplitude equalization , did you do it over just the entire everything in the mike channels ? you didn't try to find speech ?
A: no , took over the entire entire channel sampled ten minutes randomly .
C: so then that means that someone who didn't speak very much would be largely represented by silence . and someone who would who would be so the normalization factor probably is is
A: this was quite quick and dirty , and it was just for listening . and for listening it seems to work really . but , it 's not not good measure .
C: so there there 's good chance then given that different people do talk different amounts that there is there is still lot more to be gained from gain norm normalization with some sort if we can figure out way to do it . but we were that in addition to that there should be related to pitch and harmonics and . so we didn't talk about the other derivatives , but again just looking at liz has very good point , that it would be much more graphic just to show actually , you do have some distributions here , for these cases . you have some histograms , and , they don't look very separate .
E: this is the first derivate of log of frame energy without any normalization . these the these are the first experiments with comment
A: except that it 's hard to judge this because the they 're not normalized . it 's just number of frames . but , even so .
D: what is , even if you use linear , , raw measures , like raw energy or whatever , maybe we shouldn't make any assumptions about the distribution 's shape , and just use , use the distribution to model the mean , or what , rather than the mean take some
C: but and so in these he 's got that . he 's got some pictures . but he doesn't he doesn't in the he just in derivatives , but not in the but he but he doesn't doesn't
D: right . so , we what they look like on the , tsk for the raw .
C: but he didn't have it for the energy . he had it for the derivatives .
D: there might be something there .
C: that that 's good
E: in no haven't the result
C: did you have this thing , for just the just the the unnormalized log energy ? so she 's right .
E: but it 's the the following .
D: it might be just good to it looks like .
C: that 's that 's cuz 'd mentioned scatter plots before but she 's right , even before you get the scatter plots , just looking at single feature , looking at the distribution , is good thing to do .
E: catal - combining the different possibilities of the parameters . the the scatter plot combining different two combination .
C: but what she 's saying is , which is right , is le
E: combination of two , of energy and derivate
C: let 's start with the before we get complicated , let 's start with the most basic wh thing , which is we 're arguing that if you take energy if you look at the energy , that , when two people are speaking at the same time , usually there 'll be more energy than when one is that 's that hypothesis .
E: that 's right .
C: and the first way you 'd look at that , she 's , , right , is that you would just take look at the distribution of those two things , much as you 've plotted them here , but just but just do it in this case you have three . you have the silence , and that 's fine . so , with three colors or three shades or whatever , just look at those distributions . and then , given that as base , you can see if that gets improved , , or or worsened by the looking at regular energy , looking at log energy , we were just proposing that maybe it 's , it 's harder to see with the log energy , and also these different normalizations , does particular choice of normalization make it better ? but had maybe made it too complicated by suggesting early on , that you look at scatter plots because that 's looking at distribution in two dimensions . let 's start off just in one , , with this feature . that 's probably the most basic thing , before anything very complicated . and then we we 're that pitch - related things are are going to be really likely candidate to help . but since your intuition from looking at some of the data , is that when you looked at the regular energy , that it did usually go up , when two people were talking , that 's , you should be able to come up with measure which will match your intuition . and she 's right , that that having having this table , with whole bunch of things , with the standard deviation , the variance and , it 's it 's harder to interpret than just looking at the same picture you have here .
E: but it it 's curious but found it in the in the mixed file , in one channel that in several several times you have an speaker talking alone with high level of energy in the middle zone of overlapping with mmm less energy and come with another speaker with high energy and the overlapping zone has less energy .
C: so there 'll be some cases for which
E: because there reach very many
C: but , the qu so they 'll be this is want to point to visual things , but they there 'll be time there 'll be overlap between the distributions , but the question is , "" if it 's reasonable feature , there 's some separation . ""
D: so . locally .
E: just locally , .
A: and was just going to say that right now we 're just exploring .
D: and the other thing is
A: what you would imagine eventually , is that you 'll feed all of these features into some discriminative system . and so even if one of the features does good job at one type of overlap , another feature might do good job at another type of overlap .
C: right . the reason had suggested the scatter features is used to do this lot , when we had thirteen or fifteen or twenty features to look at . because something is good feature by itself , you don't really know how it 'll behave in combination and so it 's to have as many as many together at the same time as possible in in some reasonable visual form . there 's graphic things people have had sometimes to put together three or four in some funny way . but it 's true that you shouldn't do any of that unless that the individual ones , at least , have some some hope
D: especially for normalizing . it 's really important to pick normalization that matches the distribution for that feature . and it may not be the same for all the types of overlaps or the windows may not be the same . actually , was wondering , right now you 're taking all of the speech , from the whole meeting , and you 're trying to find points of overlap , but we don't really know which speaker is overlapping with which speaker , so another way would just be to take the speech from just , say , morgan , and just jane and then just their overlaps , like but by hand , and looking at , if you can detect something that way , because if we can't do it that way , there 's no good way that we 're going to be able to do it . that , there might be something helpful and cleaner about looking at just individuals and then that combination alone . plus , it has more elegant the the right model will be easier to see that way . so if , if you go through and you find adam , cuz he has lot of overlaps and some other speaker who also has enough speech and just look at those three cases of adam and the other person and the overlaps , and just look at the distributions , maybe there is clear pattern but we just can't see it because there 's too many combinations of people that can overlap .
B: had the same intuition last last week .
D: just seems complex .
B: it 's to start with it 's your idea of simplifying , starting with something that you can see without the extra layers of
D: cuz if energy doesn't matter there , like don't think this is true , but what if
E: to study individual ? to study individual ?
B: you you don't have to study everybody individually
D: to study the simplest case to get rid of extra
E: the the but consider
B: but just simple case and the one that has the lot of data associated with it .
D: cuz what if it 's the case and don't think this is true
A: that was great overlap .
D: what if it 's the case that when two people overlap they equate their , there 's conservation of energy and everybody both people talk more softly ? don't think this happens .
B: or or what if the equipment what if the equipment adjusts somehow ,
D: or they get louder .
B: there 's some equalizing in there ?
C: no we don't have that .
A: but but that 's what was saying about different types of overlap .
D: there are there are different types , and within those types , like as jose was saying , that sounded like backchannel overlap , meaning the kind that 's friendly encouragement , like "" - . "" , "" great ! "" , and it doesn't take you don't take the floor . but , some of those , as you showed , can be discriminated by the duration of the overlap . it actually the new student , don , who adam has met , and he was at one of our meetings he 's getting his feet wet and then he 'll be starting again in mid - january . he 's interested in trying to distinguish the types of overlap . if he 's talked with you yet . but in honing in on these different types
E: don't consi now don't consider that possibility . this is general studio of the overlapping we 're studying the
C: would actually still recommend that he do the overall thing
D: so it might be something that we can help by categorizing some of them and then , , look at that .
C: because it would be the quickest thing for him to do . he could you see , he already has all his in place , he has the histogram mechanism , he has the that subtracts out and all he has to do is change it from log to plain energy and plot the histogram and look at it . and then he should go on and do the other bec but but this will
D: no . didn't mean that for you to do that , but was thinking if don and are trying to get categories and we label some data for you , and we say this is what we going so you don't have to worry about it . and here 's the three types of overlaps . and we 'll we 'll do the labelling for you .
E: consider different class of overlap ?
D: that we would be working on anyway .
E: if there 's time .
D: then maybe you can try some different things for those three cases , and see if that helps , or
E: this is the thing comment with you before , that we have great variation of th situation of overlapping . and the behavior for energy is , log energy , is not the same all the time .
C: but was just saying that right now from the means that you gave , don't have any sense of whether even , , there are any significant number of cases for which there is distinct and would imagine there should be some , there should be the distributions should be somewhat separated . and would still that if they are not separated , that there 's some there 's most likely something wrong in the way that we 're measuring it . but , wouldn't expect that it was very common overall , that when two people were talking at the same time , that it would that it really was lower , although sometimes , as you say , it would . so . so .
D: no , that was that was jok or , case where you would never know that unless you actually go and look at two individuals .
C: it could it probably does happen sometimes .
A: mind if turned that light off ? the flickering is annoying me .
D: it might the case , though , that the significant energy , just as jose was saying , comes in the non - backchannel cases . because in back most people when they 're talking don't change their own energy when they get backchannel , cuz they 're not really predicting the backchannel . and sometimes it 's nod and sometimes it 's an "" - "" . and the "" - "" is really usually very low energy . so maybe those don't actually have much difference in energy . but all the other cases might .
C: what they what difference there was would be lost in taking the log ,
D: and the backchannels are easy to spot in terms of their words or just listen to it . it would be lost no matter what you do .
C: mmm , no , if it 's if if it 's it won't be as big .
D: even if you take the log , you can your model just has more sensitive measures .
A: but tone might be very you 're "" - "" tone is going to be very different .
D: right . right .
A: you could imagine doing specialized ones for different types of backchannels , if you could if you had good model for it . your "" - "" detector .
C: if if you 're my point is , if you 're doing essentially linear separation , taking the log first does make it harder to separate . so it 's so , if you so if there if there close to things it does it 's nonlinear operation that does change the distinction . if you 're doing non if you 're doing some fancy thing then and right now we 're essentially doing this linear thing by looking across here and saying we 're going to cut it here . and that 's the indicator that we 're getting . but anyway , , we 're not disagreeing on any of this , we should look at it more more finely , but that this often happens , you do fairly complicated things , and then you stand back from them and you realize that you haven't done something simple . so , if you generated something like that just for the energy and see , and then , as liz says , when they have smaller , more coherent groups to look at , that would be another interesting thing later . and then that should give us some indication between those , should give us some indication of whether there 's anything to be achieved from energy . and then you can move on to the more {nonvocalsound} pitch related .
E: this is good idea . not consider the log energy .
C: have you started looking at the pitch related , harmonicity and so on ?
E: 'm preparing the program but don't don't begin because saw your email and agree with you it 's better to suppose it 's better to consider the energy this parameter bef
C: that 's not what . no , no . we certainly should see this but that the harm certainly wasn't saying this was better than the harmonicity and pitch related things
E: go on with the with the pitch , understood that had to finish by the moment with the and concentrate my energy in that problem .
C: but , like , all these derivatives and second derivatives and all these other very fancy things , would just look at the energy and then get into the harmonicity as suggestion .
E: go on with the pitch .
C: so maybe since we 're trying to compress the meeting , know adam had some form he wanted to talk about and did you have some ?
B: wanted to ask just something on the end of this top topic . so , when presented my results about the distribution of overlaps and the speakers and the profiles of the speakers , at the bottom of that did have proposal , and had plan to go through with it , of co coding the types of overlaps that people were involved in just with reference to speaker style so , , with reference and said that on my in my summary ,
D: that 'd be great .
B: that so it 's like people may have different amounts of being overlapped with or overlapping but that in itself is not informative without knowing what types of overlaps they 're involved in so was planning to do taxonomy of types overlaps with reference to that .
D: that would be great .
B: so , but it it 's like it sounds like you also have something in that direction .
D: that would be really great . , we got his environment set up . he 's he 's double - . so . it 's mostly that , if we had to label it ourselves , we would or we 'd have to , to get started , but if it it would be much better if you can do it . you 'd be much better at doing it also because , 'm not don't have good feel for how they should be sorted out , and really didn't wanna go into that if didn't have to . so if if you 're willing to do that or
A: it would be interesting , though , to talk , maybe not at the meeting , but at some other time about what are the classes .
D: that 's research effort in and of itself ,
A: it would be interesting .
D: because you can read the literature , but how it 'll turn out and , , it 's always an interesting question .
B: it seems like we also with reference to purpose , too , that we 'd want to have them coded .
E: would 's interesting , .
D: that 'd be great . that 'd be really great . and we 'd still have some funding for this project , like probably , if we had to hire some like an undergrad , because don is being covered half time on something else he we 're not paying him the full ra - ship for all the time . so . if we got it to where we wanted we needed someone to do that don't think there 's really enough data where
B: see this as prototype , to use the only the already transcribed meeting as just prototype .
E: another parameter we we can consider is the duration . another besides the class of overlap , the duration . because is possible some some classes has type of duration , duration very short when we have we have overlapping with speech .
B: maybe it may be correlated .
E: is possible to have . and it 's interesting , , to consider the window of normalization , because if we have type of , overlap , backchannel overlap , with short duration , is possible to normali that if we normalize with consider only the window by the left ri side on the right side overlapping with very small window the if the fit of normalization is mmm bigger in that overlapping zone very short
D: that 's true . the window shouldn't be larger than the backchannel .
E: that you have you have backchannel , you have overlapping zone very short and you consider all the channel to normalize this very short "" mmm - "" and the energy is not height if you consider all the channel to normalize and the channel is mmm bigger compared with the with the overlapping duration , the effect is mmm stronger that the effect of the normalization with the mean and the and the variance is different that if you consider only window compared with the the duration of overlapping .
C: you you want it around the overlapping part . you want it to include something that 's not in overlapping
D: it 's sliding window , so if you take the measure in the center of the overlapped piece , , there 'd better be some something . but if your window is really huge then you 're right
E: this is the this is the idea , to consider only the small window near near the overlapping zone .
D: the portion of the of the backchannel won't won't effect anything . you shouldn't be more than like you should definitely not be three times as big as your backchannel . then you 're gonna have wash . and hopefully it 's more like on the order of
C: 'm not that 's necessarily true .
B: it is an empirical question , it seems like .
C: because because it because again if you 're just compensating for the gain , the fact that this gain thing was crude , and the gain wh if someone is speaking relatively at consistent level , just to give an extreme example , all you 're doing is compensating for that . and then you still and then if you look at the frame with respect to that , it still should change
D: it depends how different your normalization is , as you slide your window across . that 's something we .
B: it 's possible to try it both ways ,
A: we 're also talking about couple of different things . one is your analysis window and then the other is any normalization that you 're doing .
D: was talking about the normalization window .
A: and the and they could be quite different .
C: this was where we were last week .
D: that 's true . .
C: but , anyway we we 'll have to look at some core things .
D: but that 'd be great if you 're marking those but it is definitely true that we need to have the time marks , and was assuming that will be inherited because , if you have the words and they 're roughly aligned in time via forced alignment or whatever we end up using , then , this student and would be looking at the time marks
B: coming off of the other
D: and classifying all the frames inside those as whatever labels jane gave
B: so , it wouldn't be wasn't planning to label the time marks .
E: give you my transcription file ,
B: was thinking that would come from the engineering side ,
D: don't think you need to . that should be linked to the words which are linked to time somehow ,
B: there you go .
A: we 're not any time soon going to get forced alignment . if it 's not hand - marked then we 're not going to get the times .
D: it 's something that we wouldn't be able to do any work without forced alignment anyway , so somehow if once he gets going we 're gonna hafta come up with one
A: we could do very bad one with broadcast news .
B: good . good .
D: so whatever you would label would be attached to the words , .
B: good , good .
C: again for the close mike , we could come up take take the switchboard system ,
A: that might be good enough . it 'd be worth try . it would be interesting to see what we get .
C: just , , low - pass filter the speech and
D: cuz there 's there 's lot of work you can't do without that , you 'd have to go in and measure every start and stop point next to word
B: it would be very inefficient .
D: is if you 're interested in anything to do with words . anyway so that 'd be great .
C: there 's something we should talk about later but maybe not just now . but , , should talk about our options as far as the transcription but . , but we 'll do that later .
D: do we hafta turn
B: let 's do that later .
D: are we supposed to keep recording here ?
C: we 'll talk about it later . "" forms "" .
A: forms next iteration of forms .
C: you had something on forms .
B: how so it 's two pages per person ?
A: one 's digit form , one 's speaker form . so one is one time only speaker form and the other is the digits .
E: it 's the same . is is new is .
A: so don't fill these out . this is just the suggestion for what the new forms would look like . so , they incorporate the changes that we talked about .
B: date and time . why did you switch the order of the date and time fields ? this is rather low - level , but
A: on which one ?
B: on on the new one , time comes first and then date ,
A: you mean on the digit form ?
B: this is this is rather low level question , but it used to be date came first .
A: because the user fills out the first three fields and fill out the rest . so it was intentional .
B: how would the how would the user know the time if they didn't know the date ?
A: it 's an interesting observation , but it was intentional . because the date is when you actually read the digits and the time and , the time is when you actually read the digits , but 'm filling out the date beforehand . if you look at the form in front of you ? that you 're going to fill out when you read the digits ? you 'll see 've already filled in the date but not the time .
B: so the time is supposed to be pretty exact , because 've just been taking beginning time of the meeting .
A: 've noticed that in the forms . the the reason put the time in , is so that the person who 's extracting the digits , meaning me , will know where to look in the meeting , to try to find the digits .
B: we 've been we 've been messing up your forms .
E: but am put am putting the beginning of the meeting .
D: so you should call it , like , "" digits start time "" . or .
A: and haven't said anything .
E: in on there .
C: why what what were you putting in ?
B: , was saying if we started the meeting at two thirty , 'd put two thirty , and everyone was putting two thirty ,
A: no , it 's about fifty .
B: and didn't realize there was "" 'm about to read this and should ""
A: actually it 's about one third each . about one third of them are blank , about one third of them are when the digits are read , and about one third of them are when the meeting starts .
B: this would be radical suggestion but
A: could put instructions ?
B: ei - either that or maybe you could maybe write down when people start reading digits on that particular session .
A: but if 'm not at the meeting , 't do that .
B: that 's good point .
C: he 's been setting up and going away . so .
B: good point good point .
C: for some reason he doesn't want to sit through every meeting that 's
A: but that is the reason name , email and time are where they are . and then the others are later on .
E: and the seat is this number ?
B: seat and session .
D: "" for official use only "" that 's , he 's very professional .
E: "" use only ""
B: that does raise another question , which is why is the "" professional use only "" line not higher ? why doesn't it come in at the point of date and seat ? because we 're filling in other things . because if your professional use , you 're gonna already have the date , and the
A: what which form are you talking about ?
B: 'm comparing the new one with the old one . this is the digit form .
A: you 're talking about the digit form .
C: digit . digit form .
A: the digit form doesn't the digit
B: ! wasn't supposed to
A: no , that 's alright . the digit form doesn't have "" for official use only "" line . it just has line , which is what you 're supposed to read . so on the digits form , everything above the line is fill - in form and everything below the line is digits that the user reads .
B: alright but didn't mean to derail our discussion here , so you really wanted to start with this other form .
A: no , either way is fine you just started talking about something , and didn't know which form you were referring to .
B: alright , was comparing so th this is so was looking at the change first . so it 's like we started with this and now we 've got new version of it wi with reference to this . so the digit form , we had one already . now the the fields are slightly different .
C: so the main thing that the person fills out is the name and email and time ? you do the rest ?
A: just as as have for all the others .
B: what and there 's an addition of the native language , which is bit redundant . this one has native language and this one does too .
A: that 's because the one , the digit form that has native language is the old form not the new form .
B: ! . , . there we go . 'll catch up here .
C: "" south midland , north midland ""
B: that 's the old and that 's the new .
A: this was the problem with these categories , picked those categories from timit . what those are .
D: actually , the only way from working with the database and having to figure it out .
A: so , was gonna ask
C: so is south midland like kansas ? and north midland like illinois , or ?
A: so so what accent are we speaking ?
E: and for simple for me ?
D: probably western , .
E: is mean my native language spanish ? the original is the center of spain and the beca
A: you could call it whatever you want . for the foreign language we couldn't classify every single one . so left it blank and you can put whatever you want .
E: because is different , the span - the spanish language from the north of spain , of the south , of the west and the
A: so 'm not what to do about the region field for english variety . when wrote was writing those down , was thinking , "" , these are great if you 're linguist "" . but how to how to categorize them .
D: actually even if you
C: if you 're if if
D: this wasn't developed by th these regions weren't
C: if you 're ti or mit from nineteen eighty - five .
A: so my only question was if you were south midland speaking region , person ? would it ? is that what you would call yourself ?
C: if you 're talking if you 're thinking in terms of places , as opposed to names different peop names people have given to different ways of talking , would think north midwest , and south midwest would be more common than saying midland ,
D: maybe we can give them li like little map ? with the regions and they just no , 'm serious .
B: no , that 's not bad .
D: because it takes less time , and it 's cute
E: at this in that side in that side of the paper .
D: there 's no figure . it doesn't have all the detail ,
C: but what if you moved five times and
B: was thinking you could have ma multiple ones and then the amount of time
D: no , but you 're categorized . that 's the same
B: so , roughly . so . you could say , "" ten years on the east coast , five years on the west coast "" or other .
A: we we don't want to get that level of detail at this form . that 's alright if we want to follow up .
C: we don't really know .
D: as said , don't think there 's huge benefit to this region thing . the problem is that for some things it 's really clear and usually listening to it you can tell right away if it 's new york or boston accent , but new york and boston are two they have the nyc , but new england has bunch of very different dialects and so does so do other places .
A: so picked these regions cuz we had talked about timit , and those are right from timit .
D: and so these would be satisfying like speech research community if we released the database , but as to whether subjects know where they 're from , 'm not because know that they had to fill this out for switchboard . this is almost exactly the same as switchboard regions or very close . and how they filled that out . but th if midland midland is the one that 's difficult . also northwest you 've got oreg - washington and oregon now which people if it 's western or northern .
A: was saying don't even speak .
D: it 's like northwest
A: am speaking am speaking western ?
C: what is northern ? and what and what 's northern ?
D: originally it was north northwest
A: so this is real problem . what to do about it .
B: wouldn't know how to characterize mine either . and and so would would say , 've 've got mix of california and ohio .
A: at the first level , , we speak the same . our dialects or whatever you region are the same . but what it is .
D: you have like techno - speak accent .
A: techno - speak accent ?
D: it 's you can identify it it 's it 's not that 's
E: is different . is different .
D: but maybe that maybe we could leave this and see what people see what people choose and then let them just fill in if they don't what else we can do , cuz that 's north midland .
B: 'm wondering about question like , "" where are you from mostly ? ""
C: but 'm 'm now that you mentioned it though , am really am confused by "" northern "" .
B: agree . agree .
C: if you 're in new england , that 's north . if you 're if you 're
B: scandinavian , the minnesota area 's north .
C: but that 's also north midland ,
B: @ @ . .
C: and and oregon and washington are western , but they 're also northern .
D: that 's very different from , like , michigan , or there are hardly any subjects from idaho .
B: just rule them out .
D: there 's only few people in idaho .
A: there are hardly any subjects from "" beep ""
C: maybe we maybe we should put little map and say "" put an on where you 're from "" ,
D: no , that 's
E: and is in those
D: we could ask where they 're from .
E: and if you put
B: it 'd be pretty simple , .
D: but - we went back to that .
E: if you put the state ?
B: where are you from mostly ?
D: we we went around this and then lot of people ended up saying that it
E: - . - .
A: like the idea of asking "" what variety of english do you speak "" as opposed to where you 're from because th if we start asking where we 're from , again you have to start saying , "" , is that the language you speak or is that just where you 're from ? ""
D: right . right . it gives us good information on where they 're from , but that doesn't tell us anything
C: we could always ask them if they 're from
A: so so would say germany am speaking with german accent
B: see , 'm thinking "" where are you from mostly "" because , , then you have some subjective amount of time factored into it .
A: could try to put squeeze in little map . there 's not lot of of room
C: 'd say , , "" boston , new york city , the south and regular "" .
A: of those , northern is the only one that don't even they 're meaning .
E: and and usually here people here is their mmm lang english language ?
C: that 's joke .
D: so let 's make it up . we can make up our own so we can say "" northwest "" , "" rest of west "" .
A: don't think the northwest people speak any differently than do .
D: that 's not really region .
C: "" do you come from the louisiana purchase ? ""
D: so we could take out "" north "" "" northern "" .
A: exactly what we 're arguing about .
E: here is easy for people to know ?
D: it 's in it 's it 's harder in america anywhere else , .
A: some of them are very obvious . if you if you talk to someone speaking with southern drawl , . or boston , .
B: 't do it , but
D: and those people , if you ask them to self - identify their accent they know . they know very .
B: agree . agree .
D: they know they don't speak the same as the
A: but is boston new england ?
B: and they 're proud of it . it 's identity thing .
D: and they 're glad to tell you . depends who you ask , suppose .
A: that 's the problem with these categories .
D: but that 's why they have new york city but
B: we ca , why can't we just say characterize something like char characterize your accent
C: boston 's @ @ , too .
D: "" characterize your accent if you can . ""
B: and so would say , "" "" .
D: right , which probably means you have very
B: but someone from boston with really strong coloration would know . and so would an - less maine ,
D: and that 's actually good . was was thinking of something along that line because if you , then , , ruling out the fact that you 're inept , if somebody doesn't know , it probably means their accent isn't very strong compared to the midwest standard .
C: , it wasn't that long ago that we had somebody here who was from texas who was that he didn't have any accent left . and and had he had pretty noticeable drawl .
A: so . propose , take out northern add , .
B: . would say more sweepingly , "" how would you characterize your accent ? ""
A: so you want to change the instructions also not just say region ?
B: this discussion has made me think that 's something to consider .
A: if if read this form , they 're going to ask it they 're going to answer the same way if you say , "" what 's variety of english do you speak ? as if you say "" what variety of region do you speak ? characterize your accent ? "" they 're going to answer the same way .
B: so . was suggesting not having the options ,
A: what we talked about with that is so that they would understand the granularity .
B: yes , but if , as liz is suggesting , people who have strong accents know that they do
A: that 's what had before , and you told me to list the regions to list them .
D: each each one has pros and cons
B: that 's true .
C: last week last week was arguing for having it wide open , but then everybody said "" , no , but then it will be hard to interpret because some people will say cincinnati and some will say ohio "" .
A: had it wide open last week and you said timit .
D: what if we put in both ?
A: that 's what the "" other "" is for .
D: no , what if we put in both ways of asking them ? so . one is region and the another one is "" if you had to characterize yourself your accent , what would you say ? ""
A: won't they answer the same thing ?
D: they might only answer only one of the questions
B: that 's fine . they might say "" other "" for region because they what category to use but they might have something because it is easier to have it open ended .
D: it just and we we might learn from what they say , as to which one 's better way to ask it .
C: this is just small thing
D: but cuz really .
C: but it says "" variety "" and then it gives things that have american as one of the choices . but then it says "" region "" , but region actually just applies to , us ,
A: that 's why put the "" other "" in .
B: we thought about it . we just we thought , "" yes , "" at the last meeting , my recollection was that we felt people would have less that there are so many types and varieties of these other languages and we are not going to have that many subjects from these different language groups and that it 's huge waste of space .
A: so , the way had it last time was region was blank ,
B: that 's what .
A: it just said region colon . and and that 's the best way to do it , because of the problems we 're talking about but what we said last week , was no , put in list , so put in list . so should we go back to
D: maybe we can make the list little smaller .
A: certainly dropping "" northern "" is right , because none of us that is .
D: and keeping "" other "" , and then maybe this north midland , we call it "" north midwest "" . south midwest , or just
C: yes so . .
D: does that make sense ? that would help me
C: unless you 're from midland , kansas . there 's or midland
A: is "" midwest "" one word ?
C: is it midland midland , texas or midland , kansas ? but there 's town . forget what it is @ @ .
B: don't think that 's what they mean .
D: so . kansas would be south midland .
C: and colorado , right across the border , would be north midland .
D: so , th 'm from kansas , actually . and then , the dropping north , so it would be western . it 's just one big shebang , where , , you have huge variation in dialects ,
A: but that 's true of new england too .
C: but you do in the others , too . so .
D: but so do you
A: so . only one shouldn't say that . have no clue . was going to say the only one that doesn't have huge variety is new york city . but have no idea whether it does or not .
B: would think that these categories would be more would be easier for an analyst to put in rather than the subject himself .
A: that was what happened with timit , was that it was an analyst .
C: where does where does where 's where does new york west of west of new york city and pennsylvania and
D: how it came from . so . that 's new england .
C: no , it 's not .
B: they were part of the one of the midlands .
C: no , no . no .
A: "" other "" , it goes under "" other "" , definitely under "" other "" .
D: , pennsylvania has pretty strong dialect and it 's different than
C: pennsylvania is not new england . and new jersey is not new england and maryland is not new england and none of those are the south .
A: rather than have circle fill in forms , say "" region , open paren , southern comma western comma close paren colon . ""
B: fine by me , fine by me .
C: that 's good . we 're all sufficiently tired of this that we 're agreeing with you .
D: and we 'll see what we get .
B: be easier on the subjects . that 's fine . like that . like that .
C: you like it ?
A: actually , maybe we do one non - english one as . southern , cockney ? is that real accent ? how do you spell it ?
B: that 's fine .
D: you could say liverpool . actually , liverpool doesn't it 's 'm ha
A: we 'll do it that way . actually , like that lot . because that get 's at both of the things we were trying to do , the granularity , and the person can just self - assess and we don't have to argue about what these regions are .
B: that 's right . and it 's easy on the subjects . now have one suggestion on the next section . so you have native language , you have region , and then you have time spent in english speaking country . now , wonder if it might be useful to have another open field saying "" which one parenthesis paren closed parenthesis "" . cuz if they spent time in britain and america it doesn't have to be ex all exact , just in the same open field format that you have .
A: just which one . that 's fine .
B: sss , optional .
C: we we done ?
B: that 's good .
C: any any other open mike topics or should we go right to the digits ?
A: did you guys get my email on the multitrans ?
B: isn't that wonderful !
A: so . have version also which actually displays all the channels .
D: it 's really great .
A: but it 's hideously slow .
B: so you this is dan 's patches , dan ellis 's patches .
A: the what the ones applied , that you can actually do are dan 's , because it doesn't slow it down . just uses lot of memory .
D: so when you say "" slow "" , does that mean to
A: no , the one that 's installed is fine . it 's not slow . wrote another version . which , instead of having the one pane with the one view , it has multiple panes with the views . but the problem with it is the drawing of those waveforms is so slow that every time you do anything it just crawls . it 's really bad .
D: it 's so , it 's the redrawing of the
B: that 's consideration .
D: as you move .
A: as you play , as you move , as you scroll . just about anything , and it was so slow it was not usable . so that 's why didn't install it and didn't pursue it .
B: and this 'll be hav having the multiwave will be big help cuz in terms of like disentangling overlaps and things , that 'll be big help .
A: so . that the one dan has is usable enough . it doesn't display the others . it displays just the mixed signal . but you can listen to any of them .
B: that 's excellent . he also has version control which is another so you the patches that you
A: no , he suggested that , but he didn't it 's not installed .
B: it was in one of those patches .
A: no . no .
D: so is there any hope for actually displaying the wave form ?
A: not if we 're going to use tcl - tk at least not if we 're going to use snack . you would have to do something ourselves .
B: or use the one that crawls .
D: 'm probably would be trying to use the whatever 's there . and it 's useful to have the
A: why don't we see how dan 's works and if it if we really need the display
D: wonder 'm just wondering if we can display things other than the wave form . so . suppose we have feature feature stream . and it 's just , , uni - dimensional feature , varying in time . and we want to plot that , instead of the whole wave form . that might be faster .
A: we we could do that but that would mean changing the code . this isn't program we wrote . this is program that we got from someone else , and we 've done patches on .
D: , 'll talk to you about it and we can see but it 's definitely great to have the other one .
C: if there was some is there some way to have someone write patches in something faster and link it in , ?
A: yes we could do that . you could you can write widgets in . and try to do it that way but don't let 's try it with dan 's and if that isn't enough , we can do it otherwise . it is , cuz when was playing with it , the mixed signal has it all in there . and so it 's really it 's not too bad to find places in the in the stream where things are happening . so don't 'll be bad .
B: and it 's also the case that this multi - wave thing is proposed to the so . dan proposed it to the transcriber central people , and it 's likely that so . and and they responded favorably looks as though it will be incorporated in the future version . they said that the only reason they hadn't had the multi the parallel stream one before was simply that they hadn't had time to do it . and so it 's likely that this may be entered into the ch this central @ @ .
C: they may have not had much demand for it .
B: that 's that 's true , too . this is useful thing for us .
D: so . you mean they could they could do it and it would be fast enough if they do it ?
A: depends on how much work they did .
B: no . mean mean that it 's that his so . this one that we now have does have the status of potentially being incorporated likely being incorporated into the central code . now , tha now , if we develop further then , , don't
A: if if one of us sat down and coded it , so that it could be displayed fast enough 'm they would be quite willing to incorporate it .
B: it 's it 's feature to have it set that way .
A: but it 's not trivial task .
B: like the idea of it being something that 's , , tied back into the original , so that other people can benefit from it . however . also understand that you can have widgets that are very useful for their purpose and that you don't need to always go that route .
A: anyway , shall we do digits ?
C: let 's do digits , and then we 'll turn off the mikes , and then have one other thing to discuss .
D: actually have to leave . so . . had to leave at three thirty , so , for the digits but 't stay for the discussion
A: you want to go first ? or .
D: have to make call .
B: should we should we switch off the
C: we 'll talk to you about it
A: do you wanna go do digits or do you wanna just skip digits ?
D: no , do digits if but don't wanna butt in , .
A: then alright . you go ahead .
D: but if there 's something on the rest of the 'm 'll be around just have to make call before quarter of . or we can talk about it .
A: why don't you read the digits ?
C: why don't you read the digits and then you can go .
D: this is the new one .
A: don't don't read the old one .
D: the and the time is .
B: turn it off .
","The Berkely Meeting Recorder group discussed efforts by speaker mn005 to measure energy levels in cases of speaker overlap in which the time window analyzed was 200 milliseconds or greater.
Preliminary results were presented showing that log domain analyses did not reveal a significant difference in mean energy levels for windows of overlapping versus non-overlapping speech.
In contrast , raw energy analyses were successful in showing the two groups to be distinct.
Participants discussed alternate strategies for examining energy and the importance of categorizing types of speaker overlap.
Participants also reviewed the latest iteration of speaker forms , and discussed recent changes to the Transcriber tool.
Continuing efforts by speaker mn005 to measure energy levels in cases of speaker overlap will not include additional log energy analyses , but rather an analysis of raw energy for normalized speaker dataacross windows of varying duration , followed by an examination of pitch- and harmonicity-related features.
Speakers fe008 and fe016 discussed plans to categorize and produce a taxonomy of types of speaker overlap.
Time marks for transcribed or force-aligned data are needed to analyze types of speaker overlap.
With respect to speaker forms , the group discussed problems associated with categorizing regional dialects of American English.
The new version of Transcriber does not feature the waveform , as re-drawing of this window is too slow using Snack.
The latest iteration of speaker forms was presented.
New mutitrans patches were added to the Transcriber tool to enable it to run with fewer delays , still allowing users to open multiple panes and listen to different channels of the mixed signal.
"
ami_abstractive_summary,Bmr020.txt,"A: we 're recording .
F: we can say the word "" zero "" all we want ,
B: that 's not allowed , .
C: cur - curly brackets .
E: is that voiced or unvoiced ?
F: correction for transcribers .
G: mmm ! gar - darn !
A: do we use square brackets for anything ?
E: these poor transcribers .
C: not ri not right now .
D: there 's gonna be some zeros from this morning 's meeting because noticed that barry , maybe you turned your mike off before the digits were was it during digits ? so it doesn't matter .
A: it 's still not good idea .
B: so it 's not it 's not that bad if it 's at the end , but it 's in the beginning , it 's bad .
A: you wanna you wanna keep them on so you get good noise through the whole meeting .
C: that 's interesting .
F: probably just should have left it on . did have to run ,
E: is there any way to change that in the software ?
A: change what in the software ?
E: where like you just don't like if you if it starts catching zeros , like in the driver in the card , or somewhere in the hardware where if you start seeing zeros on across one channel , you just add some random , @ @ noise floor like small noise floor .
A: certainly we could do that , but don't think that 's good idea . we can do that in post - processing if the application needs it .
B: manual post - processing .
F: actually what the default is anymore as to how we 're using the front - end but for when we use the icsi front - end ,
A: as an argument .
F: there is an there is an an option in rasta , in when first put it in , , back in the days when actually wrote things , , did actually put in random bit or so that was in it , but then realized that putting in random bit was equivalent to adding adding flat spectrum , and it was lot faster to just add constant to the to the spectrum . so then started doing that instead of calling "" rand "" , so it it does that . gee ! here we all are !
A: so the only agenda items were jane was jane wanted to talk about some of the ibm transcription process .
F: there 's an agenda ?
A: condensed the three things you said into that . and then just only have like , this afternoon and maybe tomorrow morning to get anything done before go to japan for ten days . so if there 's anything that , desperately needs to be done , you should let me know now .
F: and you just sent off eurospeech paper ,
G: hope they accept it . both actu as submission and , as paper .
A: you sent it in late .
F: you first you have to do the first one ,
G: we actually exceeded the delayed deadline by another day ,
F: they had some extension that they announced ?
G: liz had sent them note saying "" could we have another "" , "" three days "" , and they said yes .
D: and then she said "" did say three ?
A: that was the other thing dave gelbart sent me email , he sent it to you too , that , there 's special topic , section in si in eurospeech on new , corp corpors corpora . and it 's not due until like may fifteenth .
F: this isn't the aurora one ? it 's another one ?
A: it 's different one .
B: got this mail from
A: forwarded it to jane as being the most relevant person . so , it was highly relevant have you did you look at the url ?
C: haven't gotten over to there yet , but what our discussion yesterday , really wanna submit one .
B: was this smartkom message ? christoph draxler sent this ,
C: and , you offered to join me , if you want me to .
A: but 't , really do , most of it ,
C: that 's right .
G: several people sent this ,
A: but any help you need certainly provide .
F: that 's that 's great idea .
G: there were some interesting results in this paper , though . that morgan , accounted for fifty - six percent of the robustness meetings in terms of number of words .
C: in in terms of what ?
G: number of words .
A: that 's just cuz he talks really fast .
C: do you mean , is it partly , , correctly identified words ? or just overall volume ?
G: no . , according to the transcripts .
A: but re regardless . it 's he 's in all of them ,
G: we didn't mention morgan by name
A: and he talks lot .
F: we have now ,
G: we we something about
A: did you identify him as senior member ?
G: we as identify him as the person dominating the conversation .
F: get these aarp things , but 'm not se really senior yet , but , other than that delightful result , what was the rest of the paper about ?
G: it was about it had three sections
F: you sent it to me but haven't seen it yet .
G: three kinds of results , if you will . the one was that the just the amount of overlap
A: the good , the bad , and the ugly .
G: in terms of in terms of number of words and also we computed something called "" spurt "" , which is essentially stretch of speech with , no pauses exceeding five hundred milliseconds . and we computed how many overlapped spurts there were and how many overlapped words there were . , for four different corpora , the meeting recorder meetings , and , found and compared the numbers . and found that the , as you might expect the meeting recorder meetings had the most overlap but next were switchboard and callhome , which both had roughly the same , and the robustness meetings were had the least , one unexpected result there is that two - party telephone conversations have about the same amount of overlap , in gen order of magnitude - wise as , as face - to - face meetings with multiple
A: have had better start changing all my slides !
G: also , in the levinson , the pragmatics book , in , , textbook , there 's found this great quote where he says , how people it talks about how how people are so good at turn taking , and so they 're so good that generally , the overlapped speech does not is less than five percent .
C: that 's interesting .
G: this is way more than five percent .
E: did he mean face like face - to - face ?
G: in real conversations , it 's what these conversation analysts have been studying for years and years there .
C: , no , it doesn't necessarily go against what he said , cuz he said "" generally speaking "" . in order to go against that claim you 'd have to big canvassing .
F: we have pretty limited sample here .
B: five percent of time or five percent of what ?
A: was gonna ask that too .
G: it 's time .
C: it 's it 's not against his conclusion , it just says that it 's bi bell curve , and that , you have something that has range , in your sampling .
G: so there are slight there are differences in how you measure it , but still it 's , the difference between between that number and what we have in meetings , which is more like , , close to in meetings like these , , close to twenty percent .
F: but what was it like , say , in the robustness meeting , ?
G: it was about half of the so , in terms of number of words , it 's like seventeen or eigh eighteen percent for the meeting recorder meetings and about half that for , , the robustness .
F: maybe ten percent ?
A: but if that 's really fair way of comparing between , multi - party , conversations and two - party conversations .
B: then then you have to
A: that 's just something
D: wonder if you have to normalize by the numbers of speakers .
B: then , then normalize by something like that ,
C: that 's good point .
G: we didn't get to look at that , but this obvious thing to see if there 's dependence on the number of participants .
A: bet there 's weak dependence . 'm it 's it 's not real strong one .
D: cuz not everybody talks .
A: you have lot of lot of two - party , subsets within the meeting . it 's an interesting result regardless .
C: yes , that 's right .
G: and and then and we also computed this both with and without backchannels , so you might think that backchannels have special status because they 're essentially just
A: so , did we all said "" - "" and nodded at the same time ,
G: but , even if you take out all the backchannels so you treat backchannels as nonspeech , as pauses , you still have significant overlap . it goes down from maybe for switchboard it goes down from fourteen percent of the words to maybe , eleven percent it 's it 's not dramatic change , that was that was one set of results , and then the second one was just the we had in the in the hlt paper on how overlaps effect the recognition performance . and we rescored things , little bit more carefully . we also fixed the transcripts in numerous ways . but mostly we added one number , which was what if you , score ignoring all so so the conjecture from the hlt results was that most of the added recognition error is from insertions due to background speech . so , we scored all the recognition results , , in such way that the
A: who 's on channel four ? you 're getting lot of breath .
B: was just wondering .
E: that 's me .
G: don 's been working hard .
E: that 's right .
G: so if you have the foreground speaker speaking here , and then there 's some background speech , may be overlapping it somehow , and this is the time bin that we used , then you 're gonna get insertion errors here and here . so we scored everything , and must say the nist scoring tools are pretty for this , where you just ignore everything outside of the , , region that was deemed to be foreground speech . and where that was we had to use the forced alignment , , results from for that 's somewhat that 's somewhat subject to error , but still we , don did some ha hand - checking and we think that based on that , we think that the results are , valid , although , some error is gonna be in there . but what we found is after we take out these regions so we only score the regions that were certified as foreground speech , the recognition error went down to almost , the level of the non - overlapped speech . so that means that even if you do have background speech , if you can somehow separate out or find where it is , , the recognizer does good job ,
A: that 's great .
G: even though there is this back
A: that doesn't surprise me , because , with the close - talking mikes , the signal will be so much stronger . what what normalization do you do ?
G: , we just @ @ we do , vit
A: in you recognizer , in the sri recognizer .
G: we do , vtl vocal tract length normalization , and we , we , make all the features have zero mean and unit variance .
A: over an entire utterance ?
G: over over the entire over the entire channel . now we didn't re - align the recognizer for this . we just took the old so this is actually sub - optimal way of doing it , so we took the old recognition output and we just scored it differently . so the recognizer didn't have the benefit of knowing where the foreground speech start
F: were you including the lapel in this ? and did the did the la did the problems with the lapel go away also ? fray for insertions ?
G: it not per , not completely , so we have to should bring the should bring the table with results . maybe we can look at it monday .
F: would presume that you still would have somewhat higher error with the lapel for insertions than
G: it 's it 's
F: cuz again , looking forward to the non - close miked case , that we still
A: 'm not looking forward to it .
F: it 's the high signal - to - noise ratio here that helps you .
G: so that was number that was the second set of , the second section . and then , the third thing was , we looked at , , what we call "" interrupts "" , although that 's that may be misnomer , but we looked at cases where so we used the punctuation from the original transcripts and we inferred the beginnings and ends of sentences .
C: di - did you use upper - lower case also , or not ? upper lower case or no ?
G: we only used , , periods , , question marks and exclamation . and we know that there 's th that 's not very we miss lot of them ,
C: comma also or not ?
G: and then we looked at locations where , if you have overlapping speech and someone else starts sentence , , where do these where do other people start their turns not turns really , but , sentences , so we only looked at cases where there was foreground speaker and then at the to at the so the foreground speaker started into their sentence and then someone else started later .
B: somewhere in between the start and the end ? somewhere in between the start and the end of the foreground ?
G: so that such that there was overlap between the two sentences . so , the question was how can we what can we say about the places where the second or actually , several second speakers , start their "" interrupts "" , as we call them .
D: three words from the end .
A: at pause boundaries .
G: and we looked at this in terms of
A: on - closures , only .
G: so so we had we had to for the purposes of this analysis , we tagged the word sequences , and we time - aligned them . and we considered it interrupt if it occurred in the middle of word , we , considered that to be interrupt as if it were at the beginning of the word . so that , if any part of the word was overlapped , it was considered an interrupted word . and then we looked at the locatio the , , , the features that the tags because we had tagged these word strings , , that occurred right before these , interrupt locations . and the tags we looked at are the spurt tag , end of spurt . so whether there was pause essentially here , because spurts are defined as being , five hundred milliseconds or longer pauses , and then we had things like discourse markers , so disfluen the 's are for , , the interruption points of disfluency , so , where you hesitate , or where you start the repair there . what else do we had . repeated , repeated words is another of that disfluencies and . so we had both the beginnings and ends of these so , the end of filled pause and the end of discourse marker . and we just eyeballed we didn't really hand - tag all of these things . we just looked at the distribution of words , and so every "" so "" , and "" "" , , and "" - "" were the were deemed to be backchannels and "" "" and "" so "" and "" right "" , were not "" right "" . "" right "" is backchannel . but so , we just based on the lexical , identity of the words , we tagged them as one of these things . and the the interruption points we got from the original transcripts . and then we looked at the disti so we looked at the distribution of these different kinds of tags , overall and and particularly at the interruption points . and , we found that there is marked difference so at the end after discourse marker or after backchannel or after filled pause , you 're much more likely to be interrupted than before . and also after spurt ends , which means in inside pauses . so pauses are always an opportunity for so we have this little histogram which shows these distributions it 's it 's not no big surprises , but it is interesting from
A: it 's to actually measure it though .
D: wonder about the and effect there . in other words if you weren't going to pause you will because you 're being interrupted .
G: there 's no statement about and effect .
D: no , no .
G: this is just statistical correlation ,
F: but he , he 's he 's right , you weren't intending to pause , but you were intending to stop for fifty - seven milliseconds , but then chuck came in and so you paused for second
G: anyway . so , and that was it . and and we so we wrote this and then , we found we were at six pages , and then we started cutting furiously and threw out half of the material again , and played with the latex
A: made the font smaller and the narrows longer .
G: and until it fi no , no . you couldn't really make everything smaller
B: put the abstract end .
G: but we we put
A: took out white space .
G: the gap between the two columns is like ten millimeters , so shrunk it to eight millimeters and that helped some . and like that .
D: wasn't there wasn't there some result , andreas maybe liz presented this at some conference while ago about , backchannels and that they tend to happen when the pitch drops . you get falling pitch . and so that 's when people tend to backchannel . - do you rem
G: we didn't talk about , , prosodic , , properties ,
D: right . right .
G: although that 's take it that 's something that don will look at
E: we 're gonna be looking at that .
G: now that we have the data and we have the alignment , this is purely based on the words
C: have reference for that though .
D: so am recalling correctly ?
G: anyway , so .
C: didn't know about liz 's finding on that , but know of another paper that talks about something
E: 'd like to see that reference too .
D: it made me think about little device that could be built to handle those people that call you on the phone and just like to talk and talk . and you just have this little detector that listens for these drops in pitch and gives them the backchannel . and so then you hook that to the phone and go off and do the do whatever you wanna do , while that thing keeps them busy .
G: there 's actually there 's this former student of here from berkeley , he did system , in he lives in japan now , and he did this backchanneling , automatic backchanneling system . so , exactly what you describe , but for japanese . and it 's for japa - in japanese it 's really important that you backchannel . it 's really impolite if you don't ,
F: actually for lot of these people you could just backchannel continuously and it would be fine .
D: it wouldn't matter ?
E: that 's that 's what do .
A: there was there was monty python sketch with that . where the barber who was afraid of scissors was playing tape of clipping sounds , and saying "" - "" , "" how about them sports teams ? ""
G: so the paper 's on - line cc ' ed message to meeting recorder with the url so you can get it .
A: printed it out , haven't read it yet .
G: one more thing . so 'm actually about to send brian kingbury an email saying where he can find the the the material he wanted for the for the speech recognition experiment , but haven't sent it out yet because actually my desktop locked up , like 't type anything . so if there 's any suggestions you have for that was just gonna send him the
D: is it the same directory that you had suggested ?
C: he still has his unix account here , . and he and he 's
G: but but he has to
C: 'd hafta add him to meeting recorder , ,
G: he prefe he said he would prefer ftp and also , , the other person that wants it there is one person at sri who wants to look at the , , the the data we have so far , and so figured that ftp is the best approach . so what did is @ @ made new directory after chuck said that would that was gonna be good thing . so it 's "" ftp pub what is it again ?
A: ask dan ellis .
G: the same the same as the mailing list ,
F: the no vowels .
G: and then under there actually and this directory , is not readable . it 's only , accessible . so , in other words , to access anything under there , you have to be told what the name is . so that 's quick and dirty way of doing access control . and the directory for this call it "" asr zero point one "" because it 's meant for recognition .
F: so anyone who hears this meeting now knows the
G: and then in there have file that lists all the other files , so that someone can get that file and then know the file names and therefore download them . if you the file names you can't
F: is that dash or dot in there ?
A: don't don't say .
G: so all all was gonna do there was stick the transcripts after we the way that we munged them for scoring , because that 's what he cares about , and also and then the waveforms that don segmented . just tar them all up for each meeting tar them all into one tar file and - zip them and stick them there .
A: put digits in my own home directory home ftp directory , but 'll probably move them there as .
D: so we could point mari to this also for her march - one request ?
G: march - one .
D: you remember she was
G: she wanted that also ?
D: she was saying that it would be if we had they had or was she talking she was saying it would be if they had the same set , so that when they did experiments they could compare .
G: but they don't have recognizer even . we can send cc mari on this so that she knows
D: so , for the thing that
C: that 's good .
D: we need to give brian the beeps file , so was gonna probably put it
A: we can put it in the same place . just put in another directory .
D: 'll make another directory .
G: make ano make another directory .
E: and , andreas , , sampled ? so either we should regenerate the original versions , or , we should just make note of it .
G: because in one directory there 's two versions .
E: that 's the first meeting cut both versions . just to check which if there is significant difference .
G: so but for the other meetings it 's the downsampled version that you have .
E: they 're all downsampled ,
G: that 's th important to know , we should probably give them the non - downsampled versions . alright , then 'll hold off on that and 'll for you
E: 'll send you an email .
G: definitely they should have the full bandwidth version ,
E: because liz decided to go ahead with the downsampled versions cuz we can there was no like , significant difference .
G: it takes it takes up less disk space , for one thing .
E: it does take up less disk space , and it did even better than the original versions , which , is just , probably random .
G: it was small difference
E: but , they probably want the originals .
G: it 's good thing that
A: we 're losing , don and andreas at three - thirty ,
E: hey mon hafta booga .
F: that 's why it was good to have andreas , say these things so , we should probably talk about the ibm transcription process that
C: so , that adam created , script to generate the beep file ? to then create something to send to ibm . you should probably talk about that . but but you were gonna to use the originally transcribed file because tightened the time bins and that 's also the one that they had already in trying to debug the first stage of this . my understanding was that , haven't haven't listened to it yet , but it sounded very good and understand that you guys were going to have meeting today , before this meeting .
A: it was just to talk about how to generate it . just so that while 'm gone , you can regenerate it if you decide to do it different way . so , chuck and thilo should , now more or less know how to generate the file and , the other thing chuck pointed out is that , , since this one is hand - marked , there are discourse boundaries . so so when one person is speaking , there 's breaks . whereas thilo 's won't have that . so what we 're probably gonna do is just write script , that if two , chunks are very close to each other on the same channel we 'll just merge them . so , , and that will get around the problem of , the , "" one word beep , one word beep , one word beep "" .
D: after our meeting , this morning thilo came in and said that , there could be other differences between the already transcribed meeting with the beeps in it and one that has just been run through his process .
C: and that 's the purpose .
D: so tomorrow , when we go to make the , chunked file for ibm , we 're going to actually compare the two . so he 's gonna run his process on that same meeting , and then we 're gonna do the beep - ify on both , and listen to them and see if we notice any real differences .
G: beep - ify !
C: now one thing that prevented us from apply you from applying so that is the training meeting .
D: and we know that . wel - we just wanna if there 're any major differences between doing it on the hand
G: so this training meeting , un is that some data where we have very , , accurate time marks ? for
C: went back and hand - marked the ba the bins , ment mentioned that last week .
D: but the but there 's , but there is this one issue with them in that there 're there are time boundaries in there that occur in the middle of speech . like when we went to when was listening to the original file that adam had , it 's like you hear word then you hear beep and then you hear the continuation of what is the same sentence .
A: that 's on the other channel . that 's because of channel overlap .
D: and so the th so there are these chunks that look like that have
A: that 's not gonna be true of the foreground speaker . that 'll only be if it 's the background speaker .
D: so you 'll you 'll have chunk of , , channel which starts at zero and ends at ten , and then the same channel starting at eleven , ending at fifteen , and then again , starting at sixteen , ending at twenty . so that 's three chunks where actually we can just make one chunk out of that which is , zero , twenty .
A: that 's what said ,
D: so wanted to make that it was clear . so if you were to use these , you have to be careful not to pull out these individual
G: what would was interested in is having se having time marks for the beginnings and ends of speech by each speaker .
A: that 's definitely problem .
G: because we could use that to fine tune our alignment process to make it more accurate . it don't care that , there 's actually abutting segments that we have to join together . that 's fine . but what we do care about is that the beginnings and ends are actually close to the speech inside of that
D: jane tightened these up by hand .
G: so what is the how tight are they ?
F: it looks much better .
C: they were , , reasonably tight , but not excruciatingly tight . that would 've taken more time . wanted to get it so tha so that if you have like "" "" in swimming in big bin , then it 's
G: no , no !
A: let me make note on yours .
G: because we don't want to th that 's perfectly fine . it 's good . you always want to have little bit of pause or nonspeech around the speech , say for recognition purposes . but just get an id wanted to have an idea of the of how much extra you allowed so that interpret the numbers if compared that with forced alignment segmentation .
C: 't answer that , but my main goal was , in these areas where you have three - way overlap and one of the overlaps involves "" "" , and it 's swimming in this huge bin , wanted to get it so that it was clo more closely localized .
G: but are we talking about , , tenth of second ? how how much extra would you allow at most
C: wanted it to be able to he be heard normally , so that if you if you play back that bin and have it in the mode where it stops at the boundary , it sounds like normal word . it doesn't sound like the person it sounds normal . it 's as if the person could 've stopped there . and it wouldn't have been an awkward place to stop . now sometimes , it 's these are involved in places where there was no time . and so , there wouldn't be gap afterwards because some cases , there 're some people , who have very long segments of discourse where , , they 'll they 'll breath and then put break . but other than that , it 's really pretty continuous and this includes things like going from one sentence into the one utterance into the next , one sentence into the next , without really stopping . in writing you have this two spaces and big gap but but some people are planning and , , , lot we always are planning what we 're going to say next . but , in which case , the gap between these two complete syntactic units , , which spoken things are not always complete syntactically , but it would be shorter shorter break than maybe you might like . but the goal there was to not have the text be so crudely parsed in time bin . because from discourse purpose it 's it 's more useful to be able to see and also , from speech recognition purpose my impression is that if you have too long unit , it 's it doesn't help you very much either , cuz of the memory .
G: that 's fine .
C: so , that means that the amount of time after something is variable depending partly on context , but my general goal when there was sufficient space , room , pause after it to have it be natural feeling gap . which what it would be quantified as . wally chafe says that , in producing narratives , the spurts that people use tend to be , , that the what would be pause might be something like two seconds . and , that would be , one speaker . the discourse the people who look at turn taking often do use was interested that you chose , , the that you use cuz that 's unit that would be more consistent with sociolinguistics .
G: we chose , , half second because if you go much larger , you have , your statement about how much overlap there is becomes less , , precise , because you include more of actual pause time into what you consider overlap speech . it 's compromise ,
B: , also used something around zero point five seconds for the speech - nonspeech detector
G: and it 's also based liz suggested that value based on the distribution of pause times that you see in switchboard and other corpora .
B: for the minimum silence length .
C: in any case , this , meeting that hand hand - adjusted two of them and sent sent email ,
G: so so at some point we will try to fine - tune our forced alignment
C: and sent the path .
G: maybe using those as references because , what you would do is you would play with different parameters . and to get an object you need an objective measure of how closely you can align the models to the actual speech . and that 's where your data would be very important to have .
B: and hopefully the new meetings which will start from the channelized version will have better time boundaries and alignments .
C: but like this idea of , for our purposes for the for the ibm preparation , , having these joined together , it makes lot of sense . and in terms of transcription , it would be easy to do it that way . the way that they have with the longer units , not having to fuss with adding these units at this time .
B: whi - which could have one drawback . if there is backchannel in between those three things , the the backchannel will occur at the end of those three . and and in the in the previous version where in the which is used now , there , the backchannel would be in - between there somewhere , that would be more natural
C: that 's that 's right , but , thi this brings me to the other stage of this which discussed with you earlier today , which is the second stage is , what to do in terms of the transcribers adjustment of these data . discussed this with you too . so the idea initially was , we would get , for the new meetings , so the edu meetings , that thilo ha has now presegmented all of them for us , on channel by channel basis . so , 've assigned 've assigned them to our transcribers so far 've discussed it with one , and had about an hour discussion with her about this yesterday , we went through edu - one , at some extent . and it occurred to me that that what we have in this format is you could consider it as staggered mixed file , we had some discussion over the weekend about at this other meeting that we were all at about whether the tran the ibm transcribers should hear single channel audio , or mixed channel audio . and , in way , by having this chunk and then the backchannel after it , it 's like stagal staggered mixed channel . and , it occurred to me in my discussion with her yesterday that , the the maximal gain , it 's from the ibm people , may be in long stretches of connected speech . so it 's whole bunch of words which they can really do , because of the continuity within that person 's turn . so , what 'm thinking , and it may be that not all meetings will be good for this , but what 'm thinking is that in the edu meetings , they tend to be driven by couple of dominant speakers . and , if the chunked files focused on the dominant speakers , then , when it got patched together when it comes back from ibm , we can add the backchannels . it seems to me that , , the backchannels per - se wouldn't be so hard , but then there 's this question of the time @ @ , marking , and whether the beeps would be and 'm not exactly how that how that would work with the with the backchannels . and certainly things that are intrusions of multiple words , taken out of context and displaced in time from where they occurred , that would be hard . so , my thought is 'm having this transcriber go through the edu - one meeting , and indicate start time {nonvocalsound} for each dominant speaker , endpoi end time for each dominant speaker , and the idea that these units would be generated for the dominant speakers , and maybe not for the other channels .
A: the only , , disadvantage of that is , then it 's hard to use an automatic method to do that . the advantage is that it 's probably faster to do that than it is to use the automated method and correct it . we 'll just have to see .
C: , the original plan was that the transcriber would adjust the the boundaries , and all that for all the channels but , , that is so time - consuming , and since we have bottleneck here , we want to get ibm things that are usable as soon as possible , then this seemed to me it 'd be way of gett to get them flood of data , which would be useful when it comes back to us . also , at the same time she when she goes through this , she 'll be if there 's anything that was encoded as pause , but really has something transcribable in it , then she 's going to , make mark so , so that bin would be marked as it as double dots and she 'll just add an . and in the other in the other case , if it 's marked as speech , and really there 's nothing transcribable in it , then she 's going to put dash , and 'll go through and it and , , with with substitution command , get it so that it 's clear that those are the other category . 'll just , , recode them . but , , the transcribable events that , 'm considering in this , , continue to be laugh , as as speech , and cough and things like that , so 'm not stripping out anything , just , being very lenient in what 's considered speech .
D: in terms of the this new procedure you 're suggesting , , what is the
A: it 's not that different .
D: so 'm little confused , because how do we know where to put beeps ? is it is it
A: transcriber will do it .
C: so what it what it involves is really , , the original pr procedure , but only applied to , certain strategically chosen aspect of the data .
A: we pick the easy parts of the data , and transcriber marks it by hand .
C: you got it .
D: but after we 've done thilo 's thing .
A: didn't didn't understand that .
B: 'm @ @ now 'm confused .
C: we start with your presegmented version
G: and 'm leaving .
E: have to go as .
A: leave the mikes on , and just put them on the table .
C: we start with the presegmented version
A: let me mark you as no digits .
B: you start with the presegmentation ,
C: and then , the transcriber , instead of going painstakingly through all the channels and moving the boundaries around , and deciding if it 's speech or not , but not transcribing anything . instead of doing that , which was our original plan , the tra they focus on the dominant speaker
D: they just do that on the main channels .
C: so what they do is they identify who 's the di dominant speaker , and when the speaker starts . so , you 're still gonna it 's based on your se presegmentation , that 's the basic thing .
B: and you just use the the segments of the dominant speaker then ? for for sending to ibm
D: so , now jane , my question is when they 're all done adjusting the time boundaries for the dominant speaker , have they then also erased the time boundaries for the other ones ?
C: no . no , no .
D: so how will we know who
C: that 's that 's why she 's notating the start and end points of the dominant speakers . so , on , so in edu - one , as far as listened to it , you start off with section by jerry . so jerry starts at minute so - and - so , and goes until minute so - and - so . and then mark paskin comes in . and he starts at minute such - and - such , and goes on till minute so - and - so . and then meanwhile , she 's listening to both of these guys ' channels , determining if there 're any cases of misclassification of speech as nothing , and nothing as speech , and and adding tag if that happens .
D: so she does the adjustments on those guys ?
C: but , wanted to say , his segmentation is so good , that , the part that listened to with her yesterday didn't need any adjustments of the bins .
B: on that meeting .
C: so far we haven't . so this is not gonna be major part of the process , at least not in not on ones that really
D: so if you don't have to adjust the bins , why not just do what it for all the channels ? why not just throw all the channels to ibm ?
C: there 's the question of whether she it 's question of how much time we want our transcriber to invest here when she 's gonna have to invest that when it comes back from ibm anyway . so if it 's only inserting "" - ""s here and there , then , wouldn't that be something that would be just as efficient to do at this end , instead of having it go through , then be patched together , then be double checked here .
B: but then we could just use the output of the detector , and do the beeping on it , and send it to
D: without having her check anything .
A: we just we just have to listen to it and see how good they are .
B: for some meetings , 'm 'm it
C: 'm 'm open to that ,
F: if it 's working ,
B: that 's and some on some meetings it 's good .
F: that sounds like good idea since as you say you have to do with the other end anyway .
C: the detector , this
D: we have to fix it when it comes back anyhow .
C: now , you were saying that they differ in how they work depending on channel sys systems and .
B: so we should perhaps just select meetings on which the speech - nonspeech detection works ,
C: but edu is great .
B: and just use , those meetings to to send to ibm and , do the other ones .
A: release to begin with .
F: what 's the problem the forget . is the problem the lapel ,
B: it really depends . my my impression is that it 's better for meetings with fewer speakers , and it 's better for meetings where nobody is breathing .
F: the dead meetings .
B: that 's it .
D: so this might suggest an alternative hybrid between these two things .
A: no , the undead meeting ,
D: so the one suggestion is we run thilo 's thing and then we have somebody go and adjust all the time boundaries and we send it to ibm . the other one is we just run his thing and send it to ibm . there 's another possibility if we find that there are some problems , and that is if we go ahead and we just run his , and we generate the beeps file , then we have somebody listen beeps file . and they listen to each section and say "" yes , no "" whether that section is intelligible or not . and it just , there 's little interface which will for all the "" yes "" - es it then that will be the final beep file .
C: that 's interesting ! cuz that 's that 's directly related to the end task .
D: it wouldn't be that much fun for transcriber to sit there , hear it , beep , yes or no . but it would be quick .
F: it would be quick but they 're still listening to everything .
D: but there 's no adjusting . and that 's what 's slow . there 's no adjusting of time boundaries .
C: , listening does take time too .
F: 'm 'm really tending towards
A: one and half times real time .
F: what 's the worst that happens ? as long as th on the other end they can say there 's there 's something conventions so that they say "" ? "" and then we can flag those later .
D: that 's true . we can just catch it at the catch everything at this side . maybe that 's the best way to go ,
A: it just depends on how
C: so was gonna say , edu - one is good enough , maybe we could include it in this in this set of , this we send .
B: there 's there are some meetings where it would it 's possible like this .
A: we won't know until we generate bunch of beep files automatically , listen to them and see how bad they are .
D: we won't be able to include it with this first thing , because there 's part of the process of the beep file which requires knowing the normalization coefficients .
A: that 's not hard to do . just it takes , it just takes five minutes rather than , taking second . so . hand hard - coded it .
D: except don't think that the the instructions for doing that was in that directory , didn't see where you had gener
A: no , but it 's easy enough to do .
B: doing the gain ? it 's no problem . adjusting the gain ?
D: no , getting the coefficients , for each channel .
B: that 's no problem .
D: so we just run that one
A: there are lots of ways to do it .
B: we can do that .
A: have one program that 'll do it . you can find other programs .
D: we just run that - sound - stat ? .
A: minus , capital .
F: but have another suggestion on that , which is , since , really what this is , is is trying to in the large , send the right thing to them and there is gonna be this post - processing step , why don't we check through bunch of things by sampling it ? in other words , rather than , , , saying we 're gonna listen to everything
A: didn't mean listen to everything , just see if they 're any good .
F: so you do bunch of meetings , you listen to little bit here and there , if it sounds like it 's almost always right and there 's not any big problem you send it to them .
D: send it to them .
F: and , , then they 'll send us back what we what they send back to us ,
C: that 'd be great .
F: and we 'll we 'll fix things up and some meetings will cost more time to fix up than others .
A: and we should just double - check with brian on few simple conventions on how they should mark things .
D: when they when there 's either no speech in there , they don't understand , things like that .
A: cuz @ @ what had originally said to brian was they 'll have to mark , when they can't distinguish between the foreground and background , because that was gonna be the most prevalent . but if we send them without editing , then we 're also gonna hafta have , notations for words that are cut off , and other sorts of , , acoustic problems .
C: they do already .
D: and they may just at what those cut - off words are , but we 're gonna adjust everything when we come back
A: but what we would like them to do is be conservative so that they should only write down the transcript if they 're . and otherwise they should mark it so that we can check .
C: we have the unintelligibility convention . and actually they have one also ,
F: maybe have an order of it 's probably in your paper that haven't looked at lately , an order of magnitude notion of how on good meeting , how often , do you get segments that come in the middle of words and , and in bad meeting how often ?
C: was is it in what is the
F: he 's saying , , that the edu meeting was good meeting ,
C: in good meeting ,
F: and so so it was almost it was almost always doing the right thing . so wanted to get some sense of what almost always meant . and then , in bad meeting , or some meetings where he said he 's had some problems , what does that mean ? so does one of the does it mean one percent and ten percent ? or does it mean five percent and fifty percent ? or maybe percentage isn't the right word , but how many how many per minute ,
B: the problem is that , nnn , the numbers ian gave in the paper is just , some frame error rate . so that 's that 's not really what will be effective for the transcribers , is they have to , in they have to insure that 's real spurt . and but , the numbers let me think . so the speech the amount of speech that is missed by the detector , for good meeting , th is around or under one percent , would say . but there can be but there can be more there 's there 's more amount speech the detector says there is speech , but there is none . so that can be lot when it 's really breathy channel .
F: but that 's less of problem . they 'll just listen . it 's just wasted time . and th and that 's for good meeting . now what about in meeting that you said we 've you 've had some more trouble with ?
B: 't really hhh , tsk . don't have really representative numbers , . did this on four meetings and only five minutes of every meet of these meetings so , it 's not that representative , it 's perhaps , it 's perhaps then it 's perhaps five percent of something , which the frames speech frames which are which are missed , but , 't can't really tell .
F: so so sometime , we might wanna go back and look at it more in terms of how many times is there spurt that 's that 's , interrupted ? something like that ?
C: the other problem is , that when it when it on the breathy ones , where you get breathing , , inti indicated as speech . and we could just indicate to the transcribers not to encode that if they we could still do the beep file .
F: again that is probably less of problem because if you 're if there 's if if word is split , then they might have to listen to it few times to really understand that they can't quite get it . whereas if they listen {nonvocalsound} to it and there 's don't hear any speech they 'd probably just listen to it once . so there 'd you 'd think there 'd be factor of three or four in , , cost function ,
B: so but that 's that really doesn't happen very often that that word is cut in the middle . that 's that 's really not normal .
F: so so what you 're saying is that nearly always what happens when there 's problem is that is that , there 's some , nonspeech that that is interpreted as speech .
B: that is marked as speech .
F: then , we really should just send the .
C: that would be great .
F: because that doesn't do any harm . if they hear , dog bark and they say what was the word ,
B: also thought of there are really some channels where it is almost , only bre breathing in it . and to re - run 's . . 've got - method with loops into the cross - correlation with the pzm mike , and then to reject everything which seems to be breath . so , could run this on those breathy channels , and perhaps throw out
A: that 's good idea .
C: that 's great idea .
F: but th again , that that would be good , and what that 'll do is just cut the time little further . but none of this is that really needs somebody doing these , explicit markings .
C: 'd be delighted with that , was very impressed with the with the result .
F: cuz the other thing that was concerning me about it was that it seemed specialized to the edu meeting , and that then when you get meeting like this , and you have bunch of different dominant speakers how are you gonna handle it . whereas this sounds like more general solution
C: pr much prefer this , was just trying to find way cuz don't think the staggered mixed channel is awfully good as way of handling overlaps .
D: that that really simplifies thing then . and we can just , , get the meeting , put the beeps file , send it off to ibm . with very little work on our side .
B: hear into it . listen to it ,
A: or at least sample it .
F: would just use some samples , make you don't send them three hours of "" bzzz "" .
B: that won't be good .
D: that would be very good . and then we can that 'll oughta be good way to get the pipeline going .
C: 'd be delighted .
B: and there 's there 's one point which , which we covered when when listened to one of the edu meetings , and that 's that somebody is playing sound from his laptop . and the speech - nonspeech detector just assigns randomly the speech to one of the channels , - haven't - didn't think of of this before ,
A: what can you do ?
B: but what shall we do about things like this ?
C: you were suggesting you suggested maybe just not sending that part of the meeting .
B: sometimes the the laptop is in the background and some somebody is talking , and , that 's really little bit confusing ,
A: it 's little bit confusing .
F: that 's life .
A: what 're we gonna do ? even hand - transcription would hand - transcriber would have trouble with that .
B: that 's that 's second question , "" what will different transcribers do with the laptop sound ? ""
F: what was the what was the laptop sound ? was it speech ,
B: it 's speech .
C: so my standard approach has been if it 's not someone close - miked , then , they don't end up on one of the close - miked channels . they end up on different channel . and we have any number of channels available , it 's an infinite number of channels . so just put them on some other channel .
B: when thi when this is sent to the - , transcribers , if they can tell that 's really
C: that 's right .
A: cuz there will be no channel on which it is foreground .
C: they have convention , in their own procedures , which is for background sound .
A: right , but , , in general don't think we want them transcribing the background , cuz that would be too much work . because in the overlap sections , then they 'll
D: don't think jane 's saying they 're gonna transcribe it , but they 'll just mark it as being there 's some background there ,
A: but that 's gonna be all over the place . how how will they tell the difference between that background and the dormal normal background of two people talking at once ?
C: it 'd be easy to say "" background laptop "" .
A: how would they know that ?
D: why would they treat them differently ?
C: because one of them
A: because otherwise it 's gonna be too much work for them to mark it . they 'll be marking it all over the place .
C: background laptop or , background lt wouldn't take any time .
A: but how are they gonna tell bet the difference between that and two people just talking at the same time ?
C: you can tell . acoustically , can't you tell ?
B: it 's really good sound ,
F: isn't there category something like , "" sounds for someone for whom there is no close mike "" ?
B: that would be very important ,
A: but how do we how do we do that for the folks ? how can they tell that ?
D: we may just have to do it when it gets back here .
A: that 's my opinion as . so we don't do anything for it with it .
C: that sounds good .
A: and they 'll just mark it however they mark it ,
C: that sounds good .
A: and we 'll correct it when it comes back .
B: there was category for @ @ speech .
A: no , not default .
C: as it comes back , we have when we can use the channelized interface for encoding it , then it 'll be easy for us to handle . but but if out of context , they can't tell if it 's channeled speak , , close - miked speaker or not , then that would be confusing to them . either way would be fine with me , don't really care .
F: shall we , do digits and get out of here ?
C: have have one question . do you think we should send the that whole meeting to them and not worry about pre - processing it ? what is we should leave the part with the audio in the , beep file that we send to ibm for that one , or should we start after the that part of the meeting is over in what we send . so , the part where they 're using sounds from their from their laptops .
B: with the laptop sound ,
C: if we have speech from the laptop should we just , excise that from what we send to ibm , or should we give it to them and let them do with it what they can ?
D: it 's gonna be too much work if we hafta worry about that .
C: that 'd be to have uniform procedure .
D: if we just send it all to them .
A: worry about it when we get back .
C: and see how they do .
D: worry about it when we get back in .
C: and give them freedom to indicate if it 's just not workable .
F: cuz , wouldn't don't think we would mind having that transcribed , if they did it .
A: as say , we 'll just have to listen to it and see how horrible it is . sample it , rather .
B: that will be little bit of problem
C: that 's great .
B: as it really switches around between two different channels , .
A: and they 're very it 's very audible ? on the close - talking channels ? it 's the same problem as the lapel mike .
F: let 's do digits .
C: so we read the transcript number first ,
A: are we gonna do it altogether or separately ?
B: what time is it ?
F: why don't we do it together ,
C: quarter to four .
F: that 's that 's fast way to do it . one , two , three ,
C: it 's interesting if there 're any more errors in these , than we had the first set .
A: there probably will be .
D: do you guys plug your ears when you do it ?
C: didn't this time .
D: how can you do that ?
B: perhaps there are lots of errors in it
A: total concentration . are you guys ready ?
D: you hate to have your ears plugged ?
","The main topics of the agenda were a paper submitted to Eurospeech and the organising of the recording transcriptions to be done by IBM.
The results presented in the former show a significant percentage of overlapping speech even without counting in backchanneling.
Additionally , the high error rate in the recognition of such overlapping speech by the SRI recogniser was minimised simply by changing the scoring method used.
Finally , a strong correlation between pauses and interruptions was confirmed.
All these measurements were based on the sample of available transcripts.
Other features , like prosody , will be studied in the near future.
An FTP directory containing such experimental data is being set up for the benefit of other researchers.
Regarding the transcriptions to be carried out by IBM , the discussion mainly concerned the format of the recordings that should be sent to them.
Suggestions included sending only the channels with the dominant speakers for transcription , but it was finally agreed on sending the original files with minimal modifications , as there will be extensive in-house post-processing.
Within this discussion , the rationale behind the coding of the time bins according to the flow of discourse was also explained.
The files made available in the FTP directory will be the original ones ( before down-sampling ) , as these seem to be wanted by other parties.
Moreover , as files may have been modified through different processing , tests will be carried out in order to ensure the generation of beep files in a consistent way.
Also towards this goal , some of the time bins will need to be merged.
On the other hand , the two meetings where time bins have been hand-coded in detail will be used to fine-tune the forced alignments.
Recordings will be sent to IBM for transcription.
Before that , the files will be automatically pre-segmented into speech/non-speech bins and the beeps will be inserted.
In order to make things easier for the transcribers , breathy channels , which are erroneously marked as speech , will be re-classified correctly with other methods.
All this pre-processing will have to be evaluated first by checking a sample of the output files.
Other issues , like whether and how synthesised speech off a laptop needs be transcribed , will be resolved during the in-house post-processing of the transcriptions.
There is a slight worry about the acceptance of the paper submitted to Eurospeech as the deadline was exceeded.
As to the content of the paper , the overlap statistics have not been normalised against the number of participants in the conversation , although the dependency is probably going to be a weak one.
Additionally , the correlation between pauses in speech and interruptions does not provide a cause-and-effect link for these phenomena.
The preparation of files for transcription by IBM is facing some minor difficulties , as some features ( hand-coded time boundaries , multiplicity of channels etc ) may complicate the generation of beep files.
Besides this , the automatic pre-segmentation has been deemed to be good , but there are still no specific measurements to verify this.
The pre-segmentation tool also classifies synthesised speech used in a recording as ""normal speech"" and assigns a random channel to it.
The transcribers at IBM may not be able to differentiate between the two.
A paper has been submitted to Eurospeech , which also includes a section on new corpora.
The statistics in the paper are based on the transcripts of two meeting and two telephone conversation corpora.
In the first two , the overlapped words vary between 9% and 18%.
The telephone conversation results were in-between and very similar to each other.
On the other hand , the automatic recognition errors affected by overlaps were reduced dramatically by focusing on regions with the foreground speech.
Furthermore , it was shown that after spurts , backchannels , disfluencies and discourse markers , the likelihood of interruption by other speakers was much higher.
Files with the recordings , as well as some experimental data will be available for other researchers in an FTP directory that is being set up.
Parts of the recordings will have to be beeped out by a script that has already been developed.
Finally , EDU meetings already recorded have now been pre-segmented and assigned to the transcribers at ICSI.
"
ami_abstractive_summary,Bed006.txt,"G: are you fey ?
B: what day is today ?
G: we 've met before , like , remember talking to you about aspect like that at some point or other .
F: it 's the twenty nineteenth .
D: that 's right , and you were my gsi briefly , until dropped the class .
B: right , right .
G: that 's right .
C: some in some introductions are in order .
G: getting ahead of myself .
C: everyone knows me , this is great . apart from that , the old gang , johno and bhaskara have been with us from day one and they 're engaged in various activities , some of which you will hear about today . ami is our counselor and spiritual guidance and also interested in problems concerning reference of the more complex type , and he sits in as interested participant and helper . is that good characterization ?
A: that 's pretty good , .
C: keith is not technically one of us yet , ha - ha . but it 's too late for him now .
G: "" one of us . ""
E: 've got the headset on after all .
C: officially he will be joining us in the summer . and hopefully it is by means of keith that we will be able to get better formal and better semantic idea of what construction is and how we can make it work for us . additionally his interest surpasses english because it also entails german , an extra capability of speaking and writing and understanding and reading that language . and , is there anyone who doesn't know nancy ? do you do nancy ?
B: made that joke already , nancy , sadly . the "" myself "" joke . before you came in .
G: about me or you ?
A: you could do it about you .
G: didn't mean to be humor copying , yes , know myself .
C: and fey is with us as of six days ago officially ? but in reality already much longer and next to some more or less bureaucratic with the data collection she 's also the wizard in the data collection
D: it 's very exciting .
C: we 're sticking with the term "" wizard "" ,
G: not witch - like . didn't take vote ?
C: , why don't we get started on that subject anyways . so we 're about to collect data and the the following things have happened since we last met . when will we three meet again ?
G: more than three of us .
C: what happened is that , "" "" , there was some confusion between you and jerry with the that leading to your talking to catherine snow , and he was he completely that some something confusing happened . his idea was to get the the lists of mayors of the department , it it 's exactly how you interpreted it ,
E: the list of majors in the department ?
C: ma - majors , majors . "" mayors "" .
G: the department has many mayors .
C: and just sending the little write - up that we did on to those email lists
D: so it was really carol snow who was confused , not me and not jerry .
C: so , that is
D: that 's good . so should still do that . and using the thing that you wrote up .
C: and we have little description of asking peop subjects to contact fey for recruiting them for our thing and there was some confusion as to the consent form , which is that what you just signed and since we have one already
G: did jerry talk to you about maybe using our class ? the students in the undergrad class that he 's teaching ?
C: he said we definitely "" yes "" , however there is always more people in in facul in department than are just taking his class or anybody else 's class at the moment and one should reach out and try and get them all .
G: but th it 's that people in his class cover different set is the cogsci department that you were talking about ? reaching out to ?
D: that 's what suggested to him , that people like jerry and george and et cetera just
G: cuz we have people from other areas advertise in their classes as .
D: or even could could do the actual
G: cuz know how to contact our students ,
D: that 's generally the way it 's done .
G: so if there 's something that you 're sending out you can also send me copy , me or bhaskara could either of us could post it to if it 's general solicitation that is just contact you then we can pro post it to the news group so you 'll send it
D: 'll send it ,
G: you can send it to me . we this doesn't concern you anymore , robert .
C: how however suggest that if you if you look at your email carefully you may think you may find that you already have it .
G: it 's fine .
C: we 'll see .
G: don't remember getting anything .
C: also we will talk about linguistics and computer science . and then , secondly , we had , you may remember , the problem with the re - phrasing , that subject always re - phrase the task that we gave them , and so we had meeting on friday talking about how to avoid that , and it proved finally fruitful in the sense that we came up with new scenario for how to get the subject to really have intentions and to act upon those , there the idea is now that next actually we need to hire one more person to actually do that job because it 's getting more complicated . so if anyone interested in what 'm about to describe , tell that person to write mail to me or jerry soon , the idea now is to come up with high level of abstract tasks "" go shopping "" "" take in batch of art "" do some sightseeing "" blah - blah - blah , analogous to what fey has started in in compiling here and already she has already gone to the trouble of anchoring it with specific entities and real world places you will find in heidelberg . so out of these these high level categories the subject can pick couple , such as if there is cop category in emptying your roll of film , the person can then decide "" , wanna do that at this place "" , make up their own itinerary and tasks and the person is not allowed to take this high level category list with them , the person is able to take notes on map that we will give him and the map will be tourist 's schematic representation with symbols for the objects . and so , the person can maybe make mental note that "" wanted to go shopping here "" and "" wanted to maybe take picture of that "" and "" maybe eat here "" and then goes in and solves the task with the system , and we 're gonna try out that
G: so you 'll have those say somewhere what their intention was so you still have the thing about having data where what the actual intention was ? there 's nothing that says "" these are the things you want to do "" so they 'll say "" these are the things want to do "" so they 'll have little bit more natural interaction ?
F: so they 'll be given this map , which means that they won't have to like ask the system for in for like high level information about where things are ?
C: it 's schematic tourist map . so it 'll be it 'll still require the that information
G: it it doesn't have like streets on it that would allow them to figure out their way
C: not not really the street network .
E: so you 're just saying like what part of town the things are in or whatever ?
C: the map is more means for them to have the buildings and their names and maybe some ma major streets and their names and we want to maybe ask them , if you have get it isolated street the , whatever , "" river street "" , and they know that they have decided that , yes , that 's where they want to do this action that they have it with them and they can actually read them or have the label for the object because it 's too hard to memorize all these st strange german names . and then we 're going to have another we 're gonna have another trial run ie the first with that new setup tomorrow at two and we have real interesting subject which is ron for who those who know him , he 's the founder of ici . so he 'll he 's around seven seventy years old , .
G: didn't know he was the founder .
C: and he also approached me and he offered to help our project and he was more thinking about some high level thinking tasks and said "" we need help you can come in as subject "" and he said "" "" . so that 's what 's gonna happen , tomorrow ,
G: using this new plan ,
C: new new set up . which 'll hopefully scrape together but , to fey , we already have blueprint and work with that . comments on that ? if not , we can move on . no more questions ?
E: 'm not understand this
G: so what 's the this is what you made , fey ?
E: 'm not understand everything that 's being talked about
G: like so so it 's just based on like the materials you had about heidelberg .
C: are you familiar with the with the very rough setup of the data ?
E: but imagine 'll just catch on .
D: based on the web site ,
G: there 's web site and then you could like figure out what the cate
D: it 's tourist information web site ,
E: this is where they 're supposed to
C: talk to machine and it breaks down and then the human comes on . the question is just how do we get the tasks in their head that they have an intention of doing something and have need to ask the system without giving them clear wording or phrasing of the task . because what will happen then is that people repeat , or as much as they can , of that phrasing .
G: are you worried about being able to identify the goals that we 've you guys have been talking about are this these identifying which of three modes their question concerns . so it 's like the enter versus view
C: we we will get protocol of the prior interaction , that 's where the instructor , the person we are going to hire , and the subjects sit down together with these high level things th the first question for the subject is , "" so these are things , , we thought tourist can do . is there anything that interests you ? "" and the person can say "" , sh this is something would do . would go shopping "" . and then we can this instructor can say "" , then you may want to find out how to get over here because this is where the shopping district is "" .
G: so the interaction beforehand will give them hints about how specific or how whatever though the kinds of questions that are going to ask during the actual session ?
C: just , what what would you like to buy and then there you wanna buy whatever cuckoos clocks and the there is store there . so the task then for that person is finding out how to get there , that 's what 's left . and we know that the intention is to enter because we know that the person wants to buy cuckoos clock .
G: so like those tasks are all gonna be unambiguous about which of the three modes .
A: so the idea is to try to get the actual phrasing that they might use and try to interfere as little as possible with their choice of words .
G: that they 'll be here ?
C: yes . in sense that 's exactly the the idea , which is never possible in in in lab situation ,
A: the one experiment th that that 've read somewhere , it was they used pictures . so to actually specify the tasks .
C: we had exactly that on our list of possible way things so we even made silly thing how that could work , how you control you are here you want to know how to get someplace , and this is the place and it 's museum and you want to do some and and there 's person looking at pictures . so , , this is exactly getting someplace with the intention of entering and looking at pictures . however , not only was the common census were among all participants of friday 's meeting was it 's gonna be very laborious to make these drawings for each different things , all the different actions , if possible , and also people will get caught up in the pictures . so all of sudden we 'll get descriptions of pictures in there . and people talking about pictures and pictorial representations would would still be willing to try it .
A: 'm 'm not saying it 's necessary but you might be able to combine text and some picture and also it will be good idea to show them the text and chew the task and then take the test away the the text away so that they are not guided by what you wrote , but can come up with their with their own
C: they will have no more linguistic matter in front of them when they enter this room . then suggest we move on to the to we have the edu project , let me make one more general remark , has two side actions , its action items that we 're do dealing with , one is modifying the smartkom parser and the other one is modifying the smartkom natural language generation module . and this is not too complicated but 'm just mentioning it put it in the framework because this is something we will talk about now . have some news from the generation , do you have news from the parser ?
F: yes , , would really it would be better if talked about it on friday . if that 's .
C: did you run into problems or did you run into not having time ?
F: but not any time part .
C: so that 's good . that 's better than running into problems . and do have some good news for the natural language generation however . and the good news is it 's done . meaning that tilman becker , who does the german one , actually took out some time and already did it in english for us . and so the version he 's sending us is already producing the english that 's needed to get by in version one point one .
F: so take it that was similar to the what we did for the parsing ?
C: it even though the generator is little bit more complex and it would have been , not changing one hundred words but maybe four hundred words , but it would have been but this is good news , and the the time do have it here ? the time is now fixed . it 's the last week of april until the fourth of may so it 's twenty - sixth through fourth . that they 'll be here . so it 's it 's extremely important that the two of you are also present in this town during that time .
B: what are the days ? april twenty - sixth to the may fourth ?
C: something like that .
B: 'll probably be here .
E: you will be here .
C: isn't finals coming up then after that ?
F: finals was that .
G: it doesn't really have much meaning to grad students but final projects might .
F: actually , that 's true .
C: anyway , so this is
B: 'll be here working on something . it 's just will be here , , in 'll be here too actually
C: no it 's just they 're coming for us so that we can bug them and ask them more questions and sit down together and write sensible code and they can give some talks and .
B: but it 's not like we need to be with them twenty - four hours day for the seven days that they 're here .
C: not not unless you really want to .
E: they 're very dependent
C: not unless you really want to . and they 're both guys so you may want to . that much from the parser and generator side , unless there are more questions on that .
G: so , no sample generator output yet ?
C: it just mail that , , he 's sending me the the soon
G: this is being sent ,
C: and was completely flabbergasted here and and that 's also it 's it 's going to produce the concept - to - speech blah - blah information for necessary for one point one in english based on the english , was like "" ,
E: we 're done .
C: we 're done ! ""
G: so that was like one of the first , the first task was getting it working for english . so that 's over now . is that right ? so the basic requirement fulfilled .
C: the basic requirement is fulfilled almost . when andreas stolcke and his gang , when they have changed the language model of the recognizer and the dictionary , then we can actually put it all together
G: so the speech recognizer also works .
C: you can speak into it and ask for tv and movie information if something actually happens and some answers come out , then we 're done .
G: if and they 're correct .
E: so it 's not done .
G: and they are correct .
E: perhaps if the answers have something to do with the questions .
G: it 's not just like anything . and they 're mostly in english . are they is it using the database ? the german tv movie . so all the actual data might be german names ? or are they all like american tv programs ?
E: want to see "" die dukes von hazard ""
C: so you how the german dialogue the german the demo dialogue actually works . the first thing is what 's , , showing on tv , and then the person is presented with what 's running on tv in germany on that day , on that evening and so you take one look at it and then you say "" that 's really nothing there 's nothing for me there "" "" what 's running in the cinemas ? "" so maybe there 's something better happening there . and then you get you 're shown what movies play which films , and it 's gonna be all the heidelberg movies and what films they are actually showing . and most of them are going to be hollywood movies . so , "" american beauty "" is "" american beauty "" ,
G: but they 're shown like on screen . it 's so would the generator , like the english language sentence of it is "" these are the follow the following films are being shown "" like that ?
C: but it in that sense it doesn't make in that case it doesn't really make sense to read them out loud . if you 're displaying them .
G: so it 'll just display
C: but it 'll tell you that this is what 's showing in heidelberg and there you go .
G: so we don't have to worry about
C: and the presentation agent will go "" hhh ! "" nuh ? like that the avatar . and then you pick movie and and it show shows you the times and you pick time and you pick seats and all of this . but it 's so this time we are at an advantage because it was problem for the german system to incorporate all these english movie titles . but in english , that 's not really problem , unless we get some topical german movies that have just come out and that are in their database . so the person may select "" huehner rennen "" or whatever .
E: "" chicken run "" .
C: then on to the modeling . there it is .
E: what 's the next thing ?
C: this is very rough but this is what johno and managed to come up with . the idea here is that
B: this is the the schema of the xml here , not an example like that .
C: this is not an xml this is towards an schema , the idea is , so , imagine we have library of schema such as the source - path - goal and then we have forced motion , we have cost action , we have whole library of schemas . and they 're gonna be , , fleshed out in their real ugly detail , source - path - goal , and there 's gonna be lot of on the goal and blah - blah , that goal can be and . and all the names could should be taken "" cum grano salis "" . the fact that we 're calling this "" action schema "" right now should not entail that we are going to continue calling this "" action schema "" . but what that means is we have here first of all on the in the first iteration stupid list of source - path - goal actions
B: actions that can be categorized with or that are related to source - path - goal .
C: and we will have forced motion and cost action actions .
B: and then those actions can be in multiple categories at the same time if necessary .
C: so push may be in in both push in this or this
G: forced motion and caused action ,
C: also , these things may or may not get their own structure in the future . so this is something that , , may also be res as result of your work in the future , we may find out that , , there 're really these subtle differences between even within the domain of entering in the light of source - path - goal schema , that we need to put in fill in additional structure up there . but it gives us handle . so with this we can slaughter the cow any anyway we want . it it is it was it gave us some headache , how do we avoid writing down that we have the enter source - path - goal that this but this gets the job done in that respect and maybe it is even conceptually somewhat adequate in sense that we 're talking about two different things . we 're talking more on the intention level , up there , and more on the this is the your basic bone schema , down there .
B: one question , robert . when you point at the screen is it your shadow that 'm supposed to look at ?
G: it 's the shadow .
B: whereas keep looking where your hand is ,
C: that wouldn't have helped you .
B: what this is that there 's an interface between what we are doing and the action planner
E: spit right here .
B: and right now the way the interface is "" action go "" and then they have the what the person claimed was the source and the person claimed as the goal passed on . and the problem is , is that the current system does not distinguish between goes of type "" going into "" , goes of type "" want to go to place where take picture of "" , et cetera .
C: so this is what it looks like now , some simple "" go "" action from it from an object named "" peter 's kirche "" of the type "" church "" to an object named "" powder - tower "" of the type "" tower "" .
G: this is the what the action planner uses ?
B: right . currently .
G: and is that and tha that 's changeable ? like are we adapting to it ?
C: we this is the output , , of the natural language understanding , the input into the action planning , as it is now . and what we are going to do , and you can see here , for johno focus the shadow , here you have the action and the domain object
G: what did you think he was doing ?
E: laser pointer would be most appropriate here .
B: robert likes to be abstract and that 's what thought he was doing .
G: you look up here .
C: between here and here , so as you can see this is on one level and we are going to add another "" struct "" , if you want , ie rich action description on that level . so in the future
G: so it 's just an additional information
C: in the future though , the content of hypothesis will not only be an object and an action and domain object but an action , domain object , and rich action description ,
G: that doesn't hurt the current way .
B: which which we 're abbreviating as "" rad "" .
F: so you had like an action schema and source - path - goal schema , so how does this source - path - goal schema fit into the action schema ? like is it one of the tags there ?
G: can you go back to that one ?
B: so the source - path - goal schema in this case , 've if understand how we described we set this up , cuz we 've been arguing about it all week , but we 'll hold the in this case it will hold the the features . 'm not it 's hard for me to exactly so that will store the object that is the source will store the object that we 're going from , the goal will store the
G: so the fillers of the role source .
B: we 'll fill those in fill those roles in , the action - schemas have extra see we so those are schemas exist because in case we need extra information instead of just making it an attribute and which is just one thing we decided to make it 's own entity so that we could explode it out later on in case there is some structure that we need to exploit .
G: this is just xml mo notational but the fact that it 's action schema and then slash action schema that 's whole entit
B: that 's block ,
G: that 's block , whereas source is just an attribute ?
C: no , no . source is just not spelled out here . source meaning source will be will have name , type , maybe dimensionality ,
G: - , - . could it could also be blocked out then as
C: source it will be , we know lot about sources so we 'll put all of that in source . but it 's independent whether we are using the spg schema in an enter , view , or approach mode , this is just properties of the spg schema . we can talk about paths being the fastest , the quickest , the nicest and , or and the trajector should be coming in there as . and then the same about goals .
G: so the question is when you actually fill one of these out , it 'll be under action schema ? it 's gonna be one you 'll pick one of those for these are this is just layout of the possible that could go play that role .
B: right , so the the roles will be filled in with the schema and then what actual action is chosen is will be in the in the action schema section .
G: so one question . this was in this case it 's all clear , obvious , but you can think of the enter , view and approach as each having their roles , the it 's it 's implicit that the person that 's moving is doing entering viewing and approaching , but the usual thing is we have bindings between they 're like action specific roles and the more general source - path - goal specific roles . so are we worrying about that or not for now ?
C: yes , yes . since you bring it up now , we will worry about it . tell us more about it . what do you what do you
G: what 's that ? may be just reading this and interpreting it into my head in the way that 've always viewed things and that may or may not be what you guys intended . but if it is , then the top block is like , you have to list exactly what - schema or in this action schema , there 'll be certain one , that has its own structure and maybe it has about that specific to entering or viewing or approaching , but those could include roles like the thing that you 're viewing , the thing that you 're entering , the thing that you 're
E: so very specific role names are "" viewed thing "" , "" entered thing ""
G: think of enter , view and approach as frames and they have frame - specific parameters and roles and you can also describe them in general way as source - path - goal schema and maybe there 's other image schemas that you could add after this that , how do they work in terms of force dynamics
C: - , - .
G: or how do they work in terms of other things . so all of those have either specific frame specific roles or more general frame specific roles that might have binding . so the question is are how to represent when things are linked in certain way . so we know for enter that there 's container potentially involved and it 's not if you wanna have in the same level as the action schema spg schema it 's somewhere in there that you need to represent that there is some container and the interior of it corresponds to some part of the source - path - goal goal goal in this case . so is there an easy way in this notation to show when there 's identity between things and di if that 's something we need to invent
B: wa wasn't there supposed to be link in the if this answers your question , was just staring at this while you were talking , link between the action schema , field in the in the schema for the image schemas that would link us to which action schema we were supposed to use
C: that 's that 's one thing is that we can link up , think also that we can have one or as many as we want links from the schema up to the action description of it . but the notion got from nancy 's idea was that we may find concepts floating around in the action description of the action "" enter "" frame up there that are , when you talk about the real world , actually identical to the goal of the source - path - goal schema ,
G: right , right .
C: and do we have means of telling it within that and the answer is . the way we have those means that are even part of the - three - api , meaning we can reference .
G: that 's exactly what is necessary .
C: this referencing thing however is of temporary nature because sooner or later the - three - will be finished with their - path , , , specification and then it 's going to be even much nicer . then we have real means of pointing at an individual instantiation of one of our elements here and link it to another one , and this not only within document but also via documents , and all in very easy homogenous framework .
G: so happen to know how what "" sooner or later "" means like in practice ?
C: but it 's soon . so it 's it 's the spec is there and it 's gonna part of the - three - ap api filed by the end of this year so that this means we can start using it now . but this is technical detail .
G: so pointer way to really say pointers .
B: references from the roles in the schema the bottom schemas to the action schemas is wha 'm assuming .
C: personally , 'm looking even more forward to the day when we 're going to have forms , which is form of notation where it allows you to say that if the spg action up there is enter , then the goal type can never be statue .
G: so you have constraints that are dependent on the actual specific filler , , of some attribute .
C: this , , does not make sense in light of the statue of liberty , however it is these things are imaginable .
F: so , like are you gonna have similar schemas for fm
G: or the gateway arch in st .
F: like forced motion and caused action and like you have for spg ? and if so like can are you able to enforce that if it 's if it 's spg action then you have that schema , if it 's forced motion then you have the other schema present in the
C: we have no means of enforcing that , so it would be considered valid if we have an spg action "" enter "" and no spg schema , but forced action schema .
G: whi - which is not bad , because , that there 's multiple sens that particular case , there 's mult there 's forced side of that verb as .
C: it maybe it means we had nothing to say about the source - path - goal . what 's also , and for for me in my mind it 's it 's crucially necessary , is that we can have multiple schemas and multiple action schemas in parallel . and we started thinking about going through our bakery questions , so when say "" is there bakery here ? "" do ultimately want our module to be able to first of all tell the rest of the system "" hey this person actually wants to go there "" and "" "" , that person actually wants to buy something to eat there . and if these are two different schemas , ie the source - path - goal schema of getting there and then the buying snacks schema ,
G: would they both be listed here in under so under action schema there 's list that can include both things .
C: ye , they would both schemas would appear , so what is the is there "" buying snacks "" schema ?
G: that 's interesting .
C: what is the have the buying snack schema ?
D: buying buying his food
E: 'm there 's commercial event schema in there somewhere .
C: "" commercial event "" . so so we would we would instantiate the spg schema with source - path - goal blah - blah and the buying event at which however that looks like , the place thing to buy .
G: would you say that the like you could have flat structure and just say these are two independent things , but there 's also this like causal , so one is really facilitating the other and it 's part of compound action of some kind , which has structure .
C: now it 's technically possible that you can fit schema within schema , and schema within schemata
G: that 's nicer for lot of reasons but might be pain
C: for me it seems that
G: there are truly times when you have two independent goals that they might express at once , but in this case it 's really like there 's purpo means that for achieving some other purpose .
C: if 'm if 'm recipient of such message and get source - path - goal where the goal is bakery and then get commercial action which takes place in bakery , and and they are , via identifiers , identified to be the same thing here .
G: see that bothers me that they 're the same thing .
C: no , no , just the
G: because they 're two different things one of which is you could think of one sub pru whatever pre - condition for the second . so there 's like levels of granularity . so there 's there 's single event of which they are both part . and they 're independently they are events which have very different characters as far as source - path - goal whatever . so when you identify source - path - goal and whatever , there 's gonna to be desire , whatever , eating , hunger , whatever other frames you have involved , they have to match up in ways . so it seems like each of them has its own internal structure and mapping to these schemas but that 's just that 's just me .
C: we 're gonna hit lot of interesting problems and as prefaced it this is the result of one week of arguing about it
E: still am not entirely that really fully grasp the syntax of this .
B: it 's not it 's not actually very actually , it doesn't actually
C: it occur it occurs to me that ne
E: or the intended interpretation of this .
C: should have we should have added an ano an xml example , or some xml examples
G: that would be that would be .
C: and this is on on my list of things until next week . it 's also question of the recursiveness and hier hierarchy in there . do we want the schemas just blump ? it 's if we can actually get it so that we can , out of one utterance , activate more than one schema , , then we 're already pretty good ,
A: you have to be careful with that thing because many actions presuppose some almost infinitely many other actions . so if you go to bakery you have general intention of not being hungry . you have specific intentions to cross the traffic light to get there . you have further specific intentions to left to lift your right foot and so you really have to focus on on and decide the level of abstraction that you aim at it zero in on that , and more or less ignore the rest , unless there is some implications that you want to constant draw from sub - tasks that are relevant but very difficult .
G: the other thing that thought of is that you could want to go to the bakery because you 're supposed to meet your friend there or som so you like being able to infer the second thing is very useful and probably often right .
B: the the utterance was "" is there bakery around here ? "" ,
G: but having them separate
B: not "" want to go to bakery . ""
G: maybe their friend said they were going to meet them in bakery around the area . and 'm , 'm inventing contexts which are maybe unlikely , but it 's still the case that you could you could override that default by giving extra information which is to me reason why you would keep the inference of that separate from the knowledge of "" they really want to there 's bakery around here "" , which is direct .
C: there there should never be hard coded shortcut from the bakery question to the double schema thing , and , , when have traveled with my friends we make these exactly these kinds of appointments .
G: it 's met someone at the bakery in the victoria station train station london before ,
A: have question about the slot of the spg action . so the enter - view - approach the the eva , those are fixed slots in this particular action . every action of this kind will have choice . or or will it just
E: every spg every spg action either is an enter or view or an approach ,
A: right , right . so so for each particular action that you may want to characterize you would have some number of slots that define in some way what this action is all about . it can be either , or . so is it fixed number or do you leave it open it could be between one and fifteen it 's it 's flexible .
C: it depends on if you actually write down the schema then you have to say it 's either one of them or it can be none , or it can be any of them . however the it seems to be sensible to me to to view them as mutually exclusive maybe even not .
G: do you mean within the source - path - goal actions ?
C: and how where is the end ?
A: no , no . there actually by my question is simpler than that , so you have an spg action and it has three different aspects because you can either enter building or view it or approach it and touch it . now you define another action , it 's it 's called - one
C: forced action or forced motion .
A: different action . and this action - two would have various variable possibilities of interpreting what you would like to do . and in way similar to either enter - view - approach you may want to send letter , read letter , or dictate letter , let 's say .
B: if 'm gonna answer your question or not with this , but the categories inside of action schemas , so , spg action is category . although what we 're specifying here is this is category where the actions "" enter , view and approach "" would fall into because they have related source - path - goal schema in our tourist domain . cuz viewing in tourist domain is going up to it and or actually going from one place to another to take picture , in this in
A: so it 's automatic derived fr from the structure that is built elsewhere .
E: this is cate this category structure here , what are some types of action schemas ? one of the types of action schemas is source - path - goal action . and what are some types of that ? and an enter , view , an approach . those are all source - path - goal actions .
B: inside of enter there will be roles that can be filled . so if want to go from outside to inside then you 'd have the roles that need to filled , where you 'd have source - path - goal set of roles . so you 'd the source would be outside and path is to the door or whatever , so if you wanted to have new type of action you 'd create new type of category . then this category would we would put it we would put new action in the in the categories that in which it has the every action has set of related schemas like source - path - goal or force , whatever , so we would put "" write letter "" in the categories that in which it had it had schemas
E: there could be communication event action like that
B: schemas that of that type .
E: and you could write it .
B: and then later , , there the we have communication event action where we 'd define it down there as
G: so there 's bit redundancy , in which the things that go into particular you have categories at the top under action schema and the things that go under particular category are supposed to have corresponding schema definition for that type . so what 's the function of having it up there too ? 'm wondering whether you could just have under action schema you could just say whatever it 's gonna be enter , view or approach or whatever number of things and pos partly because you need to know somewhere that those things fall into some categories . and it may be multiple categories as you say which is the reason why it gets little messy but if it has if it 's supposed to be categorized in category then the corresponding schema will be among the structures that follow .
B: this is one of things we were arguing about .
C: th this is this this is this is more this is probably the way that th that 's the way that seemed more intuitive to johno
G: you didn't tell me to
C: also for while for
G: but now you guys have seen the light .
C: no , no . we have not we have not seen the light .
B: the the reason one reason we 're doing it this way is in case there 's extra structure that 's in the enter action that 's not captured by the schemas ,
G: it 's easy to go back and forth which is why would think you would say enter and then just say all the things that are relevant specifically to enter . and then the things that are abstract will be in the abstract things as . and that 's why the bindings become useful .
E: ri - you 'd like so you 're saying you could practically turn this structure inside out ?
G: ye - see what you mean by that , but don't if would would need to have have that .
C: get get rid of the spg slash something or the sub - actions category , because what does that tell us ? and agree that this is something we need to discuss ,
G: what you could say is for enter , you could say "" here , list all the kinds of schemas that on the category that
E: list all the parent categories .
G: list all the parent categories "" . it 's just like frame hierarchy , like you have these blended frames . so you would say enter and you 'd say my parent frames are such - and - such , and then those are the ones that actually you then actually define and say how the roles bind to your specific roles which will probably be richer and fuller and have other in there .
E: this sounds like paper 've read around here recently in terms of
G: it could be not coincidence . like said , 'm 'm just hitting everything with hammer that developed , 'm just telling you what , you just hit the button and it 's like
E: but there 's good question here . like , do you when do you need damn this headset ! when you this , that 's all recorded .
G: "" damn this project . "" no just kidding .
E: how do how do come at this question ? don't see why you would who uses this this data structure ? ? like , do you say "" alright 'm going to do an spg action "" . and then somebody ne either the computer or the user says "" alright , , want to do source - path - goal action so what are my choices among that ? "" and "" , , so do an enter - view - approach "" . it 's not like that , it 's more like you say "" want to , want to do an enter . "" and then you 're more interested in knowing what the parent categories are of that . so that the the representation that you were just talking about seems more relevant to the kinds of things you would have to do ?
B: 'm not if understand your question . only one of those things are gonna be lit up when we pass this on . so only enter will be if we if our module decided that enter is the case , view and approach will not be there .
C: it 's it came into my mind that sometimes even two could be on , and would be interesting .
E: mayb - maybe 'm not understanding where this comes from and where this goes to .
B: in that case , we can't we can't if
C: let 's let 's not
B: if that 's the case we our don't think our system can handle that currently .
E: what are we doing with this ?
C: no , not .
G: "" approach and then enter . ""
C: the the in some sense we ex get the task done extremely because this is exactly the discussion we need . no more qualifiers than that .
G: no , this is the useful ,
C: and and th hope let 's make sharper claim . we will not end this discussion anytime soon . and it 's gonna get more and more complex the complexer and larger our domains get . and we will have all of our points in writing pretty soon . so this is about being recorded also .
D: that 's true .
B: the the in terms of why is it 's laid out like this versus some other that 's contentious point between the two of us but this is one wa so this is way to link the way these roles are filled out to the action .
E: in my view .
B: because if we know that enter is is an spg action , we know to look for an spg schema and put the appropriate fill in the appropriate roles later on .
G: and you could have also indicated that by saying "" enter , what are the kinds of action am ? "" so there 's just like reverse organization , so like unless @ @ are there reasons why one is better than the other that come from other sources ?
C: yes because nobod no the modules don't this is this is schema that defines xml messages that are passed from one module to another , mainly meaning from the natural language understanding , or from the deep language understanding to the action planner . now the reason for not using this approach is because you always will have to go back , each module will try have to go back to look up which entity can have which , , entity can have which parents , so you always need the whole body of your model to figure out what belongs to what . or you always send it along with it , so you always send up "" here am am this person , and have these parents "" in every message .
G: so it 's just like pain to have to send it .
C: it may or may not be just pain it 's it 's 'm completely willing to to throw all of this away and completely redo it , and and it after some iterations we may just do that .
E: would just like to ask like , if it could happen for next time , just beca cuz 'm new and don't really just what to make of this and what this is for , and like that , , so if someone could make an example of what would actually be in it , like first of all what modules are talking to each other using this ,
C: we will promise for the next time to have fleshed out xml examples for run through and see how this then translates , and how this can come about , including the "" miracle occurs here "" part . is there more to be said ? in principle what that this approach does , and whether or not we take the enter - view and we all throw up the ladder wha how do how does professor peter call that ? the hhh , silence su sublimination ? throwing somebody up the stairs ? have you never read the peter 's principle
F: people reach their level of max their level of at which they 're incompetent or whatever .
A: right , right .
C: and then you can throw them up the stairs so we can promote enter - view all up bit and get rid of the blah - - blah asterisk sub - action item altogether . no no problem with that and we we will play around with all of them but the principal distinction between having the pure schema and their instantiations on the one hand , and adding some whatever , more intention oriented specification on parallel to that this approach seems to be workable to me . if you all share that opinion then that made my day much happier .
B: this is simple way to link roles to actions .
G: . that 's fine .
B: that 's the that was the intent of it , .
G: that 's true .
B: so do 'm 'm not
C: 'm 'm never happy when he uses the word "" roles "" ,
E: you meant pastries , then ?
B: pastries is what 'm talking about .
G: ba the bak bakery example .
E: this is the bakery example . got it . alright .
G: 'll agree to that , then .
C: that 's all have for today . there 's one more issue . bhaskara brought that one up . meeting time rescheduling .
G: didn't you say something about friday ,
C: so it looks like you have not been partaking , the monday at three ' clock time has turned out to be not good anymore . so people have been thinking about an alternative time and the one we came up with is friday two - thirty ? what was it ?
B: you have class until two , so if we don't want him if we don't want him to run over here
C: two - th two - thirty - ish or three or friday at three around that time .
B: two thirty - ish or three is
G: that would be good .
A: that 's fine .
C: and know that you have until three you 're busy ?
G: so three is sounds good ? 'll be free by then .
E: could do that . earlier on friday is better but three if it were three or three thirty time then would take the three or whatever , but three is fine .
C: and you can always make it shortly after three probably .
D: and don't need to be here particularly deeply .
C: no , but , you are more than welcome if you think that this discussion gets you anywhere in your life then you 're free to
D: it 's fascinating .
G: "" that 's the right answer . ""
D: 'm just glad that don't have to work it out 'm just glad that don't have to work it out myself , that 'm not involved in the working out of it
C: but you 're linguist .
D: that 's why 'm glad that 'm not involved in working it out .
A: so it 's at friday at three ?
E: so already again this week ,
C: how diligent do we feel ? do feel that we have done our chores for this week
F: so clearly there 's talk about the the parser changes on friday at least ,
C: bhaskara will do the big show on friday .
G: and you guys will argue some more ?
B: and between now and then .
E: between now and then .
G: and have some ? and we 'll get the summary like , this the , short version ,
A: an - and would like to second keith 's request . an example wo would be to have detailed example .
C: yes . 've 've 'm on record for promising that now .
G: like have it we 'll have it in writing . or , better , speech .
B: the other good thing about it is jerry can be on here on friday and he can weigh in as .
C: and if you can get that binding point also maybe with example that would be helpful for johno and me .
G: let 's they 're
E: you 've got one on hand ,
G: have several in my head , always thinking about binding .
C: the the binding is technically no problem but it 's it for me it seems to be conceptually important that we find out if we can if there if there are things in there that are general nature , we should distill them out and put them where the schemas are . if there are things that are intention - specific , then we should put them up somewhere ,
G: so , in general they 'll be bindings across both intentions and the actions .
C: that 's wonderful .
G: so it 's gen it 's general across all of these things it 's like shastri would say binding is like an essential cognitive process . so don't will be isolated to one or the two , but you can definitely figure out where sometimes things belong and so actually 'm not would be curious to see how separate the intention part and the action part are in the system . like know the whole thing is like intention lattice , like that , so is the ri right now are the ideas the rich the rad or whatever is one potential block inside intention . it 's still it 's still mainly intention hypothesis and then that 's just one way to describe the action part of it .
B: it 's an attempt to refine it .
C: it 's an it 's
G: not just that you want to go from here to here , it 's that the action is what you intend and this action consists of all com complicated modules and image schemas and whatever .
C: and and there will be relatively high level of redundancy in the sense that ultimately one so th so that if we want to get really cocky we will say "" if you really look at it , you just need our rad . "" you can throw the rest away , because you 're not gonna get anymore information out of the action as you find it there in the domain object . but then again in this case , the domain object may contain information that we don't really care about either . but we 'll see that then , and how it evolves . if people really like our rad , what might happen is that they will get rid of that action thing completely , and leave it up for us to get the parser input
G: mmm . we know the things that make use of this thing so that we can just change them so that they make use of rad .
D: you don't have to use the acronym .
G: 't believe we 're using this term . so 'm like rad ! like every time say it , it 's horrible . see what you mean .
B: rad 's great term .
G: but what is the "" why "" ?
E: it 's rad , even ! it happened to be what it stands for .
B: it just happened to be the acronym .
G: that 's doesn't make it great term . it 's just like those jokes where you have to work on both levels .
D: just think of it as "" wheel "" in german .
C: but if you if you work in th in that xml community it is great acronym
G: do you see what ?
C: because it evokes whatever rdf rdf is the biggest thing that 's the rich "" resource description framework ""
E: "" rich de ""
C: so , description , having the word term "" description "" in there is wonderful , "" rich "" is also great ,
B: who doesn't like to be
E: everybody likes action . plus it 's hip . the kids 'll like it .
G: but what if it 's not an action ?
C: it 's it 's rad ,
D: all the kids 'll love it .
G: and intentions will be "" rid "" ? are the are the sample data that you guys showed sometime ago maybe you 're gonna run trial tomorrow . 'm just wondering whether the ac some the actual sentences from this domain will be available . cuz it 'd be for me to like look if 'm thinking about examples 'm mostly looking at child language which will have some overlap but not total with the kinds of things that you guys are getting . so you showed some in this here before and maybe you 've posted it before but where would look if want to see ?
C: you want audio ? or do you want transcript ?
G: no just transcript .
C: just transcript is just not available because nobody has transcribed it yet . 'll transcribe it though .
G: take that back then .
C: it 's no problem .
G: don't don't make it high priority if you just tell me like like two examples the the representational problems are 'm , will be there , like enough for me to think about .
C: whoever wants and comes , and can . the big parser show . now you can all turn off your
","The data collection script has been slightly modified , so that it encourages more natural dialogue between the subjects and the ""wizard"".
Another trial run will take place , while a call to recruit subjects is being emailed to students.
Meanwhile , the translation of the TV and cinema information system to english is almost complete.
This was the basic requirement of the project.
On the other hand , there was a presentation of the model that offers more elaborate action planning for SmartKom , of which Enter/View/Approach ( EVA ) modes are a part.
These modes will form categories of complete XML schemas with information filled in from the language understanding in a more elaborate way than the current Object-""Go Action""-Object model.
These categories will , in turn , be linked with action schemas , one of which is Source-Path-Goal ( SPG ).
Categories and action schemas can have -in theory- any number of blocks depending on the expansion of the domain.
The notation provides for linking and referencing between different schemas.
The model also allows for multiple action schemas to be triggered in parallel.
However , the structure of the model is open for discussion , since its use was to elicit discussion and highlight issues.
As the data collection is about to start , a call for the recruitment of subjects is going to be sent out.
The main pool of subjects is going to be the student community in the institute.
Along with the ""wizard"" , who is going to be an integral part of the experiments , another person needs to be hired as the instructor for the tasks involved in them.
Meetings were rescheduled and are now going to take place on Fridays.
For the next meeting , there is going to be a presentation of the modifications in the parser module of the basic system.
Additionally , the proposed XML model will be put to the test with concrete data.
Similarly , such examples will clarify issues relating to the binding and redundancy of features with common characteristics amongst the shcemas ( eg ""Container"" for Enter and ""Goal"" for SPG ).
Subjects in the trial runs of the experiment were given detailed descriptions of the tasks , which led to the subsequent dialogue being a re-iteration or re-phrasing of the instructions.
Using pictures instead would be one way to deal with the problem , however , it was deemed too laborious and it would divert the focus of the experiment.
As the original action planner of the SmartKom system only included a generic SPG schema , a new module was presented that allows for variety in the user intentions to be included.
This being only a model , there are several issues that will need to be clarified in the future.
How the model deals with redundancy of information among categories and action schemas , and whether a flat or a hierarchical model would be preferable are two of them.
What is also clear is that as the domain of research broadens beyond the study of EVA modes , the complexity of the model will also increase.
Another trial run of the data collection experiment is to take place , while subjects are being recruited.
There have been some adjustments in the script.
The prior description of tasks the subjects are going to be given is now going to be more schematic , although the intentions are still going to be clear.
The lack of detailed , written explanation will hopefully encourage more natural and varied dialogue between subjects and ""wizard"".
On the other hand , the generator module of the system has been translated from german.
Eventually , a user is going to be able to request and receive TV- and cinema-related information in english.
This will satisfy the basic project requirements.
The model of a new module for SmartKom was presented.
It is an interface between the language understanding and the action planning modules.
One layer of XML schemas creates a richer representation of the linguistic analysis , which is subsequently used to trigger one or more action schemas.
The model keeps the concept of XML messages being sent between the modules of the system , although it is open-ended as to the number of schemas involved.
"
ami_abstractive_summary,Bed011.txt,"C: now can you give me the remote ?
D: so eva , co could you read your numbers ?
A: go ahead and read .
D: let 's get started . hopefully nancy will come , if not , she won't .
B: robert , do you have any way to turn off your screensaver on there so that it 's not going off every , it seems to have about at two minute
C: 've it 's not that didn't try . and told it to stay on forever and ever , but if it 's not plugged in it just doesn't obey my commands . it has mind . but , keep on wiggling .
E: wants to conserve .
C: but we 'll just be working on it at intensity so it doesn't happen . we 'll see . should we plunge right into it ? so , would you like to so what 've tried to do here is list all the decision nodes that we have identified on this side . commented and what they 're about and the properties we may give them . and here are the tasks to be implemented via our data collection . so all of these tasks the reading is out of these tasks more or less imply that the user wants to go there , sometime or the other . and analogously , here we have our eva intention . and these are the data tasks where we can assume the person would like to enter , view or just approach the thing . analogously the same on the object information we can see that , , we have created these tasks before we came up with our decision nodes so there 's lot of things where we have no analogous tasks , and that may or may not be problem . we can change the tasks slightly if we feel that we should have data for for every decision node so trying to im implant the intention of going to place now , going to place later on the same tour , or trying to plant the intention of going sometime on the next tour , or the next day or whenever .
D: right , right .
C: but that might be overdoing it little .
D: so let me pop up level . and make that we 're all oriented the same . so what we 're gonna do today is two related things . one of them is to work on the semantics of the belief - net which is going to be the main inference engine for thi the system making decisions . and decisions are going to turn out to be parameter choices for calls on other modules . so the natural language understanding thing is , we think gonna only have to choose parameters , but , fairly large set of parameters . so to do that , we need to do two things . one of which is figure out wh the choices are , which we 've done fair amount . then we need to figure out what influences its choices and finally we have to do some technical work on the actual belief relations and presumably estimates of the probabilities and . but we aren't gonna do the probability today . technical we 'll do another day . probably next week . but we are gonna worry about all the decisions and the things that pert that contribute to them . and we 're also , in the same process , going to work with fey on what there should be in the dialogues . so one of the steps that 's coming up real soon is to actually get subjects in here , and have them actually record like this . record dialogues more or less . and depending on what fey provokes them to say , we 'll get information on different things .
C: how people phrase different intentions more or less ,
D: fo - people with the phrase them and so for , , keith and people worrying about what constructions people use , we have some we have some ways to affect that the dialogues go . so what robert kindly did , is to lay out table of the kinds of things that might come up , and , the kinds of decisions . so the on the left are decision nodes , and discreet values . so if we 're right , you can get by with just this middle column worth of decisions , and it 's not all that many , and it 's perfectly feasible technically to build belief - nets that will do that . and he has handout .
C: maybe it was too fast plunging in there , because we have two updates . you can look at this if you want , these are what our subject 's going to have to fill out . any comments still be made and the changes will be put in correspondingly . let me summarize in two sentences , mainly for eva 's benefit , who probably has not heard about the data collection , . or have you heard about it ? we were gonna put this in front of people . they give us some information on themselves . then then they will read task where lots of german words are thrown in between . and and they have to read isolated proper names no , this is not the release form . this is the speaker information form . the release form is over there in that box .
D: alright , fair enough .
C: and and then they gonna have to choose from one of these tasks , which are listed here . they they pick couple , say three six . six different things they think they would do if they were in heidelberg or traveling someplace and and they have map . very sketchy , simplified map . and they can take notes on that map . and then they call this computer system that works perfectly , and understands everything .
B: this is fictional system ,
C: the comp , the computer system sits right in front of you , that 's fey .
E: 've understand everything .
D: and she does know everything .
C: and she has way of making this machine talk . so she can copy sentences into window , or type really fast and this machine will use speech synthesis to produce that . so if you ask "" how do get to the castle "" then several seconds later it 'll come out of here "" in order to get to the castle you do "" and and then after three tasks the system breaks down . and fey comes on the phone as human operator . and says "" the system broke down but let 's continue . "" and we get the idea what people do when they think they speak to machine and what people say when they think they speak to human , or know , or assume they speak to human . that 's the data collection . and and fey has some thirty subjects lined up ? and and they 're ready to roll .
E: and more and more every day .
C: and we 're gonna start tomorrow at three ?
E: because we whether that person is coming or not ,
C: around four - ish . and we 're still looking for room on the sixth floor because they stole away that conference room . behind our backs .
D: see , we have to it 's tricky . we 'll let 's let we 'll do that off - line , .
C: but it 's happening . david and jane and lila are working on that as we speak . that was the the data collection in nutshell . and report so did this but also tried to do this so if click on here , isn't this wonderful ? we get to the belief - net just focusing on the go - there node . analogously this would be the reason node and the timing node and . and what what happened is that design - wise 'd noticed that we can we still get lot of errors from lot of points to one of these sub go - there user go - there situation nodes . so came up with couple of additional nodes here where whether the user is thrifty or not , and what his budget is currently like , is going to result in some financial state of the user . how much will he is he willing to spend ? or can spend . being the same at this just the money available , which may influence us , whether he wants to go there if it is charging tons of dollars for admission or its gonna cost lot of twenty - two million to fly to international space station , . just not all people can do that . so , and this actually turned out to be pretty key , because having specified these this intermediate level and noticing that everything that happens here let 's go to our favorite endpoint one is again more or less we have then the situation nodes contributing to the endpoint situation node , which contributes to the endpoint and . now draw straight lines from these to here , meaning it goes where the sub - everything that comes from situation , everything that comes from user goes with the sub - , and whatever we specify for the so - called "" keith node "" , or the discourse , what comes from the parser , construction parser , will contribute to the and the ontology to the sub - node . and one just has to watch which also final decision node so it doesn't make sense to figure out whether he wants to enter , view or approach an object if he never wants to go there in the first place . but this makes the design thing fairly simple . and now all that 's left to do then is the cpg 's , the conditional probabilities , for the likelihood of person having enough money , actually wanting to go place if it costs , this or that . and once bhaskara has finished his classwork that 's where we 're gonna end up doing . you get involved in that process too . and and for now the question is "" how much of these decisions do we want to build in explicitly into our data collection ? "" so , one could think of we could call the see or , people who visit the zoo we could call it "" visit the zoo tomorrow "" , so we have an intention of seeing something , but not now but later .
D: so let 's see th that from one point of view , , , all these places are the same , so that that , in terms of the linguistics and , there may be few different kinds of places , so th it seems to me that we ought to decide , what things are are actually going to matter to us . and , so the zoo , and the university and the castle , et cetera . are all big - ish things that have different parts to them , and one of them might be fine .
C: the the reason why we did it that way , as as reminder , is no person is gonna do all of them . they 're just gonna select , according to their preferences . "" , , usually visit zoos , or usually visit castles , or usually "" and then you pick that one .
D: right , no , but th point is to to build system that 's got everything in it that might happen you do one thing .
E: they 're redundant .
D: to build system that had the most data on relatively confined set of things , you do something else . and the speech people , , are gonna do better if they if things come up repeatedly . now , , if everybody says exactly the same thing then it 's not interesting . so , all 'm saying is th there 's there 's question of what we 're trying to accomplish . and my temptation for the data gathering would be to , and each person is only gonna do it once , so you don't have to worry about them being bored , so if it 's one service , one luxury item , , one big - ish place , and and so on , then my is that the data is going to be easier to handle . now you have this possible danger that somehow there 're certain constructions that people use when talking about museum that they wouldn't talk about with university and , but 'm my temptation is to go for simpler . but what other people think about this in terms of
B: so don't exactly understand like we 're trying to limit the detail of our ontology or types of places that someone could go , but who is it that has to care about this , or what component of the system ?
D: th there are two places where it comes up . one is in the th these people who are gonna take this and try to do speech with it . lots of pronunciations of th of the same thing are going to give you better data than , few pronunciations of lots more things . that 's one .
B: so we would rather just ask have bunch of people talk about the zoo , and assume that will that the constructions that they use there will give us everything we need to know about these zoo , castle , whatever type things , these bigger places .
D: thi this is question for
B: and that way you get the speech data of people saying "" zoo "" over and over again or whatever too .
D: so this is question for you , and , , if we if we do , and we probably will , actually try to build prototype , probably we could get by with the prototype only handling few of them anyway .
C: the this was these are all different activities . but got the point and like it . we can do put them in more hierarchical fashion . so , "" go to place "" and then give them choice , either they 're the symphony type or opera type or the tourist site guide type or the nightclub disco type person and they say "" this is on that "" go to big - ish place "" , this is what would do . "" and then we have the "" fix "" thing , and then maybe "" do something the other day "" thing , so . my question is to some extent , we should we just have to try it out and see if it works . it would be challenging , in sense , to try to make it so complex that they even really should schedule , or to plan it , , more complex thing in terms of they should get the feeling that there are these six things they have to do and they sh can be done maybe in two days . so they make these decisions , "" can go there tomorrow ? ""
D: it 's easy enough to set that up if that 's your expectation . so , the system could say , "" , we 'd like to set up your program for two days in heidelberg , let 's first think about all the things you might like to do . so there th in in th 'm that if that 's what you did then they would start telling you about that , and then you could get into various things about ordering , if you wanted .
C: but this is part of the instructor 's job . and that can be done , to say , "" now we 've picked these six tasks . "" "" now you have you can call the system and you have two days . ""
D: no , we have to help we have to decide . fey will carry out whatever we decide . but we have to decide , what is the appropriate scenario . that 's what we 're gonna talk about .
F: but these are two different scenarios entirely . one is planner the other , it give you instructions on the spot
C: but th the don't 'm not really interested in "" phase planning "" capabilities . but it 's more the how do people phrase these planning requests ? so are we gonna masquerade the system as this as you said simple response system , "" have one question get one response "" , or should we allow for certain level of complexity . and think the data would be nicer if we get temporal references .
D: so keith , what do you think ?
B: off the top of my head it kinda seems like you would probably just want , , richer data , more complex going on , people trying to do more complex sets of things . if our goal is to really be able to handle whole bunch of different , then throwing harder situations at people will get them to do more linguistic more interesting linguistic . but 'm not really because don't fully understand like what our choices are of ways to do this here yet .
C: we have tested this and have you heard listen to the first two or th the second person is is was faced with exactly this setup .
B: started to listen to one and it was just like , , , depressing . 'd just listen to the beginning part and the person was just reading off her script .
C: that was the first subject .
D: first one wasn't very good .
C: it is already with this it got pretty with this setup and that particular subject it got pretty complex . maybe suggest we make some fine tuning of these , get run through ten or so subjects and then take breather , and see whether we wanna make it more complex or not , depending on what results we 're getting .
B: it , , am just today , next couple days gonna start really diving into this data . 've looked at one of the files you gave me those dozens of files and looked at one of them which was about ten sentences , found fifteen , twenty different construction types that we would have to look for and so on and like , "" alright , , let 's start here . "" so haven't really gone into the , looked of the that 's going on . right , , once start doing that 'll have more to say about this thing .
D: but th but you did say something important , which is that you can probably keep yourself fairly occupied with the simple cases for quite while . although , th so that sa does suggest that now , have looked the data , and it 's pre it 's actually at least to an amateur , quite redundant . that that it was it was very stylized , and quite lot of people said more or less the same thing .
B: did scan it at first and noticed that , and then looked in detail at one of them . but , noticed that , too .
D: so , we we wanna do more than that .
C: and with this we 're getting more . do we wanna get going beyond more , which is the
D: , so let 's let 's take let 's your suggestion is good , which is we 'll do batch . fey , how long is it gonna be till you have ten subjects ? or thr week ? or don't have feel for th
E: can probably schedule ten people , , whenever .
D: it 's it 's up to you , we don't have any huge time pressure . it 's just when you have
E: how long will it be ? would say maybe two weeks .
D: so let 's do this . let 's plan next monday , , to have review of what we have so far .
C: this means audio , but
D: no , we won't have the transcriptions , but what we should be able to do and if , fey , if you will have time to do this , but it would be great if you could , , not transcribe it all , but pick out , some . we could lis just sit here and listen to it all . are you gonna have the audio on the web site ?
C: until we reach the gigabyte thing and david johnson ki kills me . and we 're gonna put it on the web site . .
D: you can buy another disk for two hundred dollars , it 's it 's not like so , we 'll take care of david johnson .
C: no , he , he has been solving all our problems or is wonderful ,
E: take care of him .
D: so we 'll buy disk . but anyway , so , , if you if you can think of way to , point us to th to interesting things , as you 're doing this make your make notes that this is , , something worth looking at . and other than that , we 'll just have to , listen although it 's only ten minutes each ,
E: 'm not how long it 's actually going to take .
C: the reading task is lot shorter . that was cut by fifty percent . and the reading , nobody 's interested in that except for the speech people .
D: no , we don't care about that .
C: it 's actually like five minutes dialogue .
D: my is it 's gonna be ten .
C: ten minutes is long .
E: it feels like long time
C: it feels like forever when you 're doing it , but then it turns out to be three minutes and forty five seconds .
D: was thinking people would , , hesitate and whatever . whatever it is we 'll we 'll deal with it .
C: and it 's fun .
D: so that 'll be on the web page . that 's great . but anyway , so it 's good idea to start with the relatively straight forward res just response system . and then if we want to get them to start doing multiple step planning with whole bunch of things and then organize them tell them which things are near each other any of that . "" which things would you like to do tuesday morning ? "" so th that seems pretty straight forward .
E: but were you saying that
C: need those back .
D: 'm , fey , what ?
E: that maybe one thing we should do is go through this list and select things that are categories and then offer only one member of that category ?
D: that 's what was suggesting for the first round , .
B: so rather than having zoo and castle .
E: and then , , they could be alternate versions of the same if you wanted data on different constructions .
D: they could , but tha they
E: like one person gets the version with the zoo as choice , and the other person gets the
D: but but in the short run ,
C: no , th the per the person don't get it . this is why we did it , because when we gave them just three tasks for part - and three tasks for part -
E: no , they could still choose . they just wouldn't be able to choose both zoo and say , touring the castle .
C: this is limiting the choices , but . but this approach will very work , but the person was able to look at it and say "" , this is what would actually do . ""
E: he was vicious .
C: we gotta we gotta disallow traveling to zoos and castles at the same time ,
E: there they are significantly different , but .
C: but no , they 're they 're this is where tour becomes tourists maybe bit different and , , these are just places where you enter , much like here .
D: if if you use the right verb for each in common , like at , "" attend theater , symphony or opera "" is group , and "" tour the university , castle or zoo "" , all of these do have this "" tour "" aspect about the way you would go to them . and , the movie theater is probably also is "" attend "" et cetera . so it may turn out to be not so many different kinds of things , and then , what one would expect is that the sentence types would their responses would tend to be grouped according to the activity , you would expect .
F: but it seem that there is difference between going to see something , and things like "" exchange money "" or "" dine out "" @ @ function , .
C: th the function is definitely different and the getting information or . but this is open . so since people gonna still pick something , we 're not gonna get any significant amount of redundancy . and for reasons , we don't want it , really , in that sense . and we would be ultimately more interested in getting all the possible ways of people asking , , for different things with or with computer . and so if you can think of any other high level tasks tourist may do just always just mail them to us and we 'll sneak them into the collection . we 're not gonna do much statistical with it .
D: we don't have enough .
C: but it seems like since we since we are getting towards subject fifty subjects and if we can keep it up to five four - ish per week rate , we may even reach the one hundred before fey takes off to chicago .
E: that means that one hundred people have to be interested .
D: , these are all people off campus from campus so far , so we we how many we can get next door at the shelter . for ten bucks , probably quite few .
B: that 's right .
D: so , alright , so let 's go let 's go back then , to the chart with all the decisions and , and see how we 're doing . do do people think that , this is gonna cover what we need , or should we be thinking about more ?
C: in terms of decision nodes ? go - there is yes or no . 'm also interested in th in this "" property "" line here , so if you look at , look at that timing was have these three . do we need final differentiation there ? now , later on the same tour , sometimes on the next tour .
B: what 's this idea of "" next tour "" ?
C: it 's next day , so you 're doing something now and you have planned to do these three four things , and you can do something immediately , you could tag it on to that tour or you can say this is something would do wanna do sometime in my life , .
B: so so this tour is just like th the idea of current round of touristness or whatever ,
D: probably between stops back at the hotel . if you if you wanted precise about it , , and that 's the way tourists do organize their lives . "" , we 'll go back to the hotel and then we 'll go off
F: so all tours tour happens only within one day ? so the next tour will be tomorrow ?
B: just to be clear .
C: my visit to prague there were some nights where never went back to the hotel , so whether that counts as two - day tour or not we 'll have to think .
B: you just spend the whole time at fleku ,
D: we will we will not ask you more .
E: that 's enough .
C: what is the the english co cognate if you want , for "" sankt nimmerlandstag "" ? "" we 'll do it on when you say on that day it means it 'll never happen . do you have an expression ?
B: not that know of actually .
C: when hell , we 'll do it when hell freezes over . so maybe that should be another property in there . the reason why do we go there in the first place ie it 's either for sightseeing , for meeting people , for running errands , or doing business . entertainment is good one in there , .
B: so , business is supposed to , be it like professional type ,
C: this this is an old johno thing . he had it in there . "" who is the tour is the person ? "" so it might be tourist , it might be business man who 's using the system , who wants to go to some
B: like my father is about to travel to prague . he 'll be there for two weeks . he is going to he 's there to teach course at the business school but he also is touring around and so he may have some mixture of these things .
F: what ab what do you have in mind in terms of socializing ?
C: just meeting people , . "" want to meet someone somewhere "" , which be puts very heavy constraint on the "" eva "" because then if you 're meeting somebody at the town hall , you 're not entering it usually , you 're just want to approach it .
B: so , does this capture , like , where do you put "" exchange money "" is an errand , so , like "" go to movie "" is now entertainment , "" dine out "" is
D: let , we 'll put it somewhere , would say that if "" dine out "" is special if you 're doing it for that purpose then it 's entertainment . and we 'll also as as you 'll further along we 'll get into business about "" , you 're this is going over meal time , do you wanna stop for meal or pick up food ? "" and that 's different . that 's that 's part of th that 's not destination reason , that 's "" en passant , "" right .
C: that goes with the "" energy depletion "" function , blech . "" endpoint "" .
B: "" tourist needs food , badly ""
C: "" endpoint "" is pretty clear . "" mode "" , have found three , "" drive there "" , "" walk there "" or "" be driven "" , which means bus , taxi , bart .
D: taxis are very different than buses , but on the other hand the system doesn't have any public transport this the planner system doesn't have any public transport in it yet .
C: so this granularity would suffice , if we say the person probably , based on the utterance we on the situation we can conclude wants to drive there , walk there , or use some other form of transportation .
B: how much of heidelberg can you get around by public transport ? in terms of the interesting bits . there 's lots of bits where you don't really 've only ev was there ten years ago , for day , so don't remember , but . like the the tourist - bits
D: you can't get to the philosophers ' way very , there are hikes that you can't get to , but other things you can , if remember right .
A: so is like "" biking there "" part of like "" driving there "" ,
C: we actually biking should be should be separate point because we have very strong bicycle planning component .
E: mmm that 's good .
D: put it in .
C: bicycles should be in there , will we have bic is this realistic ?
D: we can leave it out , .
C: we can we can , drive
B: would would lump it with "" walk "" because hills matter . things like that .
C: "" length "" is , you wanna get this over with as fast as possible , you wanna use some part of what of the time you have . but we should just make decision whether we feel that they want to use some substantial or some fraction of their time . they wanna do it so badly that they are willing to spend the necessary and plus time . and , if we feel that they wanna do nothing but that thing then , , we should point out that to the planner , that they probably want to use all the time they have . so , stretch out that visit for that .
B: it seems like this would be really hard to . on the part of the system . it seems like it you 're you 're talking about rather than having the user decide this you 're supposed we 're supposed to figure it out ?
C: th - the user can always say it , but it 's just we hand over these parameters if we make if we have feeling that they are important . and that we can actually infer them to significant de degree , or we ask .
D: and par , and part of the system design is that if it looks to be important and you can't figure it out , then you ask . but hopefully you don't ask , all these things all the time . or so , but there 's th but definitely back - off position to asking .
C: and if no part of the system ever comes up with the idea that this could be important , no planner is ever gonna ask for it . so and like the idea that , , jerry pushed this idea from the very beginning , that it 's part of the understanding business to make good question of what 's important in this general picture , what you need if you wanna simulate it , , what parameters would you need for the simulation ? and , timing , , length would definitely be part of it , "" costs "" , "" little money , some money , lots of money "" ? actually , maybe so ,
B: you could say "" some "" in there .
F: must say that thi this one looks bit strange to me . maybe it seems like appropriate if go to las vegas . but decide how much money 'm willing to lose . but as tourist , 'll just paying what 's what 's more or less is required .
D: there are there 're different things where you have ch choice , this interacts with "" do am do are you willing to take taxi ? "" or , , if you 're going to the opera are you gonna look for the best seats or the peanut gallery
F: the best seat or right .
D: so there are variety of things in which tour - tourists really do have different styles eating .
F: right , that 's true .
C: the what my sentiment is they 're once had to write charter , carter for student organization . and they had wanted me to define what the quorum is going to be . and looked at the other ones and they always said ten percent of the student body has to be present at their general meeting otherwise it 's not and wrote in there "" en - enough "" people have to be there . and it was hotly debated , but people with me that everybody probably has good feeling whether it was farce , joke , or whether there were enough people . and if you go to turkey , you will find when people go shopping , they will say "" how much cheese do you want ? "" and they say "" , enough . "" and the and the this used all over the place . because the person selling the cheese knows , , that person has two kids and , husband that dislikes cheese , so this is enough . and so the middle part is always the golden way , so you can you can be really make it as cheap as possible , or you can say "" want , er , , don't care ""
B: money is no object .
C: money is no object , or you say "" want to spend enough "" . or the sufficient , or the appropriate amount . but , then again , this may turn out to be insufficient for our purposes . but , this is my first , in much the same way as how should the route be ? should it be the easiest route , even if it 's little bit longer ? no steep inclinations ? go the normal way ? whatever that again means , er or do you does the person wanna rough it ?
B: th so there 's couple of different ways you can interpret these things "" want to go there and don't care if it 's really hard . "" or if you 're an extreme sport person , . "" wanna go there and insist on it being the hard way . "" so assume we 're going for the first interpretation , it 's different from thing to
D: no , he was going for the second one ar actually . anyway , we 'll sort th , we 'll sort that out .
C: this is all , top of my head . no no research behind that . "" object information "" , "" do do wanna know anything about that object ? "" is either true or false . and . if care about it being open , accessible or not , don't think there 's any middle ground there . either wanna know where it is or not , wanna know about it 's history or not , or , wanna know about what it 's good for or not . maybe one could put scales in there , too . so wanna know lot about it .
D: what were you gonna say ?
C: one could put scales in there . so wanna know lot about the history ,
D: so "" object "" becomes "" entity "" ,
C: that 's true .
D: but we don't have to do it now .
C: that was the wrong shortcut anyhow .
D: and we think that 's it , interestingly enough , that , , th or very close to it is going to be going to be enough . alright , so so the order of things is that , robert will clean this up little bit , although it looks pretty good .
C: this is the part that this is the part that needs the work .
D: so so , in parallel , three things are going to happen . robert and eva and bhaskara are gonna actually build belief - net that , , has cpt 's and , , tries to infer this from various kinds of information . and fey is going to start collecting data , and we 're gonna start thinking about what constructions we want to elicit . and then go it may iterate on , further data collection to elicit
B: do you mean do you mean eliciting particular constructions ? or do you mean like what kinds of things we want to get people talking about ? semantically speaking , ?
D: and though for us , constructions are primarily semantic ,
B: from my point of view 'm 'm trying to care about the syntax , so
D: but if th if we in if we , make that we get them talking about temporal order . that would be great and if th if they use prepositional phrases or subordinate clauses or whatever , whatever form they use is fine . but that probably we 're gonna try to look at it as , what semantic constructions do we do we want them to do direc , "" caused motion "" , something like that . but , - this is actually conversation you and have to have about your thesis fantasies , and how all this fits into that .
C: will tell you the german tourist data . because have not been able to dig out all the out of the ta thirty
B: is that roughly the equivalent of what 've seen in english or is it
C: no , not . wizard of oz .
B: like what what have got now ? have what 'm loo what those files that you sent me are the user side of some interaction with fey ?
C: little bit of data ,
B: is that what it is ? or ? just talking into box and not hearing anything back .
D: no , no .
C: some data collected in couple weeks for training recognizers and email way back when . nothing to write home about . see this ontology node is probably something that will try to expand . once we have the full ontology api , what can we expect to get from the ontology ? and hopefully you can also try to find out , , sooner or later in the course of the summer what we can expect to get from the discourse that might , or the not the discourse , the utterance as it were , ,
D: right , but we 're not expecting keith to actually build parser .
B: right , right .
C: no , no , no .
D: we are expecting johno to build parser ,
C: this is yes .
B: by the end of the summer , too .
D: he 's he 's hoping to do this for his masters ' thesis by year from now .
C: but it 's it 's
B: still , pretty formidable actually .
D: , the idea is , the hope is that the parser itself is , , pretty robust . but it 's not popular it 's only only
B: right , right . existence proof , . set up the infrastructure ,
D: it 's only popula
B: sometime , have to talk to some subset of the people in this group , at least about what constructions 'm looking for . like just again , looking at this one thing , , saw things from as general as argument structure constructions . , have to do verb phrase . have to do unbounded dependencies , which have variety of constructions in on the other hand have to have , , there 's particular , fixed expressions , or semi - fixed expressions like "" get "" plus path expression for , , "" how ho how do get there ? "" , "" how do get in ? "" , "" how do get away ? "" and all that . so there 's variety of different sorts of constructions and it it 's it 's like anything goes .
D: so this is we 're gonna mainly work on with george . let me th say what is so the idea is first of all misspoke when said we thought you should do the constructions . for linguist that means to do completely and perfectly . so what , , so what was "" do first cut at "" .
B: er that 's what
D: because we do wanna get them perfectly but we 're gonna have to do first cut at lot of them to see how they interact .
B: right , exactly . now it we talked about this before , and me it would be completely out of the question to really do more than , say , like , , ten , over the summer , but , but we need to get general view of what things look like ,
D: so the idea is going to be to do like nancy did in some of the er these papers where you do enough of them so you can go from top to bottom so you can do , have complete story ov of of some piece of dialogue . and that 's gonna be much more useful than having all of the clausal constructions and nothing else , or like that . so that the trick is going to be to take this and pick some lattice of constructions , so some lexical and some phrasal , and , , whatever you need in order to , be able to then , , by hand , , explain , some fraction of the utterances . and so , exactly which ones will partly depend on your research interests and bunch of other things .
B: but in terms of the th level of of analysis , these don't necessarily have to be more complex than like the "" out of "" construction in the bcp paper where it 's just like , , half page on each one .
D: half page is what we 'd like . and if there 's something that really requires lot more than that then it does and we have to do it ,
B: for the first cut , that should be fine , .
C: we could sit down and think of the ideal speaker utterances , and two or three that follow each other , so , where we can also , once we have everything up and running , show the tremendous , insane inferencing capabilities of our system . so , , as the smartkom people have . this is their standard demo dialogue , which is , , what the system survives and nothing but that . we could also sor have the analogen of our sample sentences , the ideal sentences where we have complete construction coverage and , , they match nicely . so the "" how do get to ? "" , that 's definitely gonna be , major one .
B: that 's about six times in this little one here , so , .
C: "" where is ? "" might be another one which is not too complicated . and "" tell me something about . "" and hey , that 's that 's already covering eighty percent of the system 's functionality .
D: ye - right , but it 's not covering eighty percent of the intellectual interest .
C: no , we can throw in an "" out of film "" construction if you want to ,
D: no , no . the th there 's lot that needs to be done to get this right .
C: have one bit of news . the action planner guy has wrote has written lengthy proposal on how he wants to do the action planning . and responded to him , also rather lengthy , how he should do the action planning .
D: "" action planning "" meaning "" discourse modeling "" ?
C: and tacked on little paragraph about the fact that the whole world calls that module dis disc dialogue manager , and wouldn't it make sense to do this here too ? and also rainer malaka is going to be visiting us shortly , most likely in the beginning of june .
D: 'll be gone .
C: he - he 's just in conference somewhere and he is just swinging through town . and making me incapable of going to naacl , for which had funding . but . no , no pittsburg this year . when is the santa barbara ? who is going to ? should lot of people . that 's something will would enjoy .
D: probably should go . that was that 's one you should probably go to .
B: how much does it cost ? haven't planned to go .
D: probably we can pay for it . student rate shouldn't be very high . so , if we all decide it 's good idea for you to go then you 'll we 'll pay for it .
E: then you can go .
D: don't have feeling one way or the other at the moment , but it probably is .
","The main focus of the meeting was firstly on the structure of the belief-net , its decision nodes and the parameters that influence them , and secondly , on the design of the data collection tasks.
For the latter , there are already 30 subjects lined up and more are expected to be recruited off campus.
It was agreed that making subjects select from categories of tasks , such as ""big place"" , ""service"" , etc . could provide a better range of data.
The duration of each dialogue will probably be no more than 10 minutes.
On the other hand , the organisation of the intermediate nodes of the belief-net and their properties is almost complete , although no conditional probabilities have been inserted yet.
These nodes represent decisions that will function as parameters to action calls in the system.
Their values will either be inferred from the user-system interaction , or -as a last resort- requested directly from the user.
Finally , as to the semantic and syntactic constructions , work will start with more general and brief descriptions , before moving to exhaustive analysis of at least a subset.
Similarly , the construction parser that is to be built within a year is expected to be relatively basic , yet robust.
As the data collection is ready to start , it was agreed that for the first ten subjects the interaction with the system/instructor will be along the lines of a basic response system.
Tasks will be divided in categories ( ""tour"" , ""attend"" etc ) and subjects are going to be asked to choose no more than one task out of each category .
This first run will probably take a couple of weeks , but the first results ( audio files and selected highlights ) will be discussed shortly , in order to decide whether more detail ( complex spatial relationships , temporal planning etc ) should be included in the design or particular constructions be elicited.
Regarding the completion of the belief-net , the remaining details , mainly the properties of the ontology and discourse nodes , should be added.
After building in the conditional probability tables , a working prototype of the net will be ready.
Finally , the initial work on constructions should focus on a general overview of the dialogues with brief descriptions.
Further analysis will follow from there in a top-down fashion.
Although there is an effort to include some of the key features of the belief-net in the design of the data gathering , not all of them can be built in.
The tasks that the subjects will have to carry out will be categorised in ways that will indicate EVA intentions , however , this approach may limit the variety of possible constructions used within a single category of entities.
On the other hand , generating more diverse dialogues may have an adverse effect from a speech recognition perspective.
A minor problem has arisen with the laboratory where recordings are supposed to take place , but this is currently being sorted out.
As regards the completion of the belief-net , no work has been done on the CPT's yet.
Finally , it was noted that although a general overview of the pertinent constructions is attainable , no more than ten of them can be analysed in detail with the summer months.
A detailed diagram of the EVA belief-net was presented and some of the intermediate nodes and their properties were discussed in depth.
Some of the key features and properties are: ""Go-there"" , which is binary , and defined by the user , situation , ontology and discourse models; ""timing"" ( current/next tour ); ""reason"" ( business , sight-seeing , socialising ); ""transport""; ""length of tour""; ""costs""; ""entity"" ( open , accessible ) etc.
The data collection that will provide relevant dialogues is moving along , with thirty subjects already lined up.
They will be given a reading task , which will include some german proper names , and a series of tasks from the tourist domain to choose from.
In order to get directions , they will then communicate with a computer system and a human operator , using a sketchy map as an aid.
A different set of data are already available from the SmartKom system and similar sources.
A preliminary study using this data has shown that a large number of syntactic and semantic constructions can be derived from a small sample.
"
ami_abstractive_summary,Bro004.txt,"C: hello , hello , hello .
F: wh - what causes the crash ?
A: did you fix something ?
E: five , five .
C: hello , hello .
F: maybe it 's the turning off and turning on of the mike ,
B: you think that 's you ?
C: aaa - aaa .
F: , mine 's working .
C: that 's me .
B: so , we are gonna do the digits at the end .
D: channel channel three ,
E: mmm , channel five ?
B: that 's the mike number there , , mike number five , and channel four .
A: is it written on her sheet , believe .
E: era el cuatro .
F: that 's me .
B: this is you . and 'm channel two ,
C: 'm channel two .
B: 'm channel must be channel one .
E: channel decided to talk about that .
B: so also copied the results that we all got in the mail from from ogi and we 'll go through them also . so where are we on our runs ?
D: so . we so as was already said , we mainly focused on four features . the plp , the plp with jrasta , the msg , and the mfcc from the baseline aurora . and we focused for the test part on the english and the italian . we 've trained several neural networks on so on the ti - digits english and on the italian data and also on the broad english french and spanish databases . mmm , so there 's our result tables here , for the tandem approach , and , actually what we @ @ observed is that if the network is trained on the task data it works pretty .
B: our our there 's we 're pausing for photo
C: chicken on the grill . try that corner .
A: how about over th from the front of the room ?
C: it 's longer .
B: we 're pausing for photo opportunity here .
C: get out of the
F: let me give you black screen .
B: he 's facing this way . this would be good section for our silence detection .
F: musical chairs everybody !
B: so , you were saying about the training data
D: so if the network is trained on the task data tandem works pretty . and actually we have , results are similar only on ,
A: do you mean if it 's trained only on on data from just that task ,
D: just that task . but actually we didn't train network on both types of data phonetically balanced data and task data . we only did either task data or broad data .
B: clearly it 's gonna be good then
A: so what 's th
B: but the question is how much worse is it if you have broad data ? from what saw from the earlier results , last week , was that , if you trained on one language and tested on another , say , that the results were relatively poor . but but the question is if you train on one language but you have broad coverage and then test in another , does that is that improve things in comparison ?
D: if we use the same language ?
B: no , no . so if you train on ti - digits and test on italian digits , you do poorly , let 's say . don't have the numbers in front of me ,
D: but but did not do that .
B: so 'm just imagining . so , you didn't train on timit and test on italian digits , say ?
D: we no , we did four testing , actually . the first testing is with task data so , with nets trained on task data . so for italian on the italian speech @ @ . the second test is trained on single language with broad database , but the same language as the task data . but for italian we choose spanish which we assume is close to italian . the third test is by using , the three language database and the fourth is
B: it has three languages . that 's including the the the one that it 's
D: but not digits .
A: the three languages is not digits , it 's the broad data .
D: and the fourth test is excluding from these three languages the language that is the task language .
B: so , that is what wanted to know . wasn't saying it very , .
D: so for ti - digits for ins example when we go from ti - digits training to timit training we lose around ten percent , the error rate increase of of ten percent , relative . so this is not so bad . and then when we jump to the multilingual data it 's it become worse and , around , let 's say , twenty perc twenty percent further .
B: ab - about how much ? twenty percent further ?
D: twenty to thirty percent further .
A: and so , remind me , the multilingual is just the broad data . it 's not the digits . so it 's the combination of two things there . it 's removing the task specific training and it 's adding other languages .
D: but the first step is al already removing the task specific from
A: so they were building here ?
D: so , when it 's trained on the multilingual broad data or number our error rates with the baseline error rate is around one point one .
B: yes . and it 's something like one point three of the if you compare everything to the first case at the baseline , you get something like one point one for the for the using the same language but different task , and something like one point three for three languages broad .
D: same language we are at for at english at point eight . so it improves , compared to the baseline . le - let me . tas - task data
B: something different by baseline so let me let me let 's let 's use the conventional meaning of baseline . by baseline here using the task specific data . but , because that 's what you were just doing with this ten percent . so was just trying to understand that . so if we call factor of just one , just normalized to one , the word error rate that you have for using ti - digits as training and ti - digits as test , different words , 'm , but , the same task and so on . if we call that "" one "" , then what you 're saying is that the word error rate for the same language but using different training data than you 're testing on , say timit and , it 's one point one .
D: it 's around one point one .
B: and if it 's you do go to three languages including the english , it 's something like one point three . that 's what you were just saying , .
A: one point four ? so , it 's an additional thirty percent .
D: what would you say ? around one point four
B: and if you exclude english , from this combination , what 's that ?
D: if we exclude english , there is not much difference with the data
B: that 's interesting . that 's interesting . do you see ? because , so no , that 's important . so what it 's saying here is just that there is reduction in performance , when you don't have the when you don't have no , actually it 's interesting . so it 's so when you go to different task , there 's actually not so different . it 's when you went to these so what 's the difference between two and three ? between the one point one case and the one point four case ?
A: it 's multilingual .
D: the only difference it 's is that it 's multilingual
B: cuz in both in both of those cases , you don't have the same task . so is the training data for the for this one point four case does it include the training data for the one point one case ?
F: fraction of it .
D: part of it ,
B: how how much bigger is it ?
D: it 's two times , the english data no , the multilingual databases are two times the broad english data . we just wanted to keep this , , not too huge .
B: so it 's two times , but it includes the but it includes the broad english data . and the broad english data is what you got this one point one with . so that 's timit so it 's band - limited timit . this is all eight kilohertz sampling . so you have band - limited timit , gave you almost as good as result as using ti - digits on ti - digits test . but , when you add in more training data but keep the neural net the same size , it performs worse on the ti - digits . now all of this is this is noisy ti - digits , assume ? both training and test ? . we we may just need to so it 's interesting that going to different task didn't seem to hurt us that much , and going to different language it doesn't seem to matter the difference between three and four is not particularly great , so that means that whether you have the language in or not is not such big deal . it sounds like we may need to have more of things that are similar to target language or . you have the same number of parameters in the neural net , you haven't increased the size of the neural net , and maybe there 's just not enough complexity to it to represent the variab increased variability in the in the training set . that that could be . so , what about so these are results with th that you 're describing now , that they are pretty similar for the different features or
D: let me check . so . this was for the plp , for the plp with jrasta the we this is quite the same tendency , with slight increase of the error rate , if we go to timit . and then it 's it gets worse with the multilingual . there there is difference actually with between plp and jrasta is that jrasta seems to perform better with the highly mismatched condition but slightly worse for the matched condition .
B: have suggestion , actually , even though it 'll delay us slightly , would you mind running into the other room and making copies of this ? cuz we 're all if we if we could look at it , while we 're talking , it 'd be 'll 'll sing song or dance while you do it , too .
A: while you 're gone 'll ask some of my questions .
B: this way and just slightly to the left ,
A: the what was was this number forty or it was roughly the same as this one , he said ? when you had the two language versus the three language ?
B: that 's what he was saying .
A: that 's where he removed english ,
F: it sometimes , actually , depends on what features you 're using .
B: but but it sounds like
F: but he - .
B: because it seems like what it 's saying is not so much that you got hurt because you didn't have so much representation of english , because in the other case you don't get hurt any more , at least when it seemed like it might simply be case that you have something that is just much more diverse , but you have the same number of parameters representing it .
A: were all three of these nets using the same output ? this multi - language labelling ?
F: he was using sixty - four phonemes from sampa .
A: so this would from this you would say , "" , it doesn't really matter if we put finnish into the training of the neural net , if there 's gonna be , , finnish in the test data . ""
B: it 's it sounds , we have to be careful , cuz we haven't gotten good result yet . and comparing different bad results can be tricky . but it does suggest that it 's not so much cross language as cross type of speech . it 's it 's the other thing was asking him , though , is that that in the case you do have to be careful because of com compounded results . we got some earlier results in which you trained on one language and tested on another and you didn't have three , but you just had one language . so you trained on one type of digits and tested on another . didn - wasn't there something of that ? where you , say , trained on spanish and tested on ti - digits , or the other way around ? something like that ? there was something like that , that he showed me last week . we 'll have to till
A: that would be interesting .
B: this may have been what was asking before , stephane , but , , wasn't there something that you did , where you trained on one language and tested on another ? no mixture but just
F: 'll get it for you .
B: we 've never just trained on one lang
D: training on single language , you mean , and testing on the other one ? so the only task that 's similar to this is the training on two languages ,
B: but we 've done bunch of things where we just trained on one language . you haven't you haven't done all your tests on multiple languages .
D: either thi this is test with the same language but from the broad data , or it 's test with different languages also from the broad data , so , it 's it 's three or three and four .
E: the early experiment that
A: did you do different languages from digits ?
D: you mean training digits on one language and using the net to recognize on the other ?
A: digits on another language ?
B: see , you showed me something like that last week . you had you had little
D: no , don't .
C: these numbers are ratio to baseline ?
B: so , wha what 's the this this chart this table that we 're looking at is , show is all testing for ti - digits ,
F: bigger is worse .
D: so you have two parts .
F: this is error rate , . no . no .
D: the upper part is for ti - digits and it 's divided in three rows of four rows each . and the first four rows is - matched , then the the second group of four rows is mismatched , and finally highly mismatched . and then the lower part is for italian and it 's the same the same thing .
A: so , so the upper part is training ti - digits ?
D: so . it 's it 's the htk results , . so it 's htk training testings with different features and what appears in the left column is the networks that are used for doing this .
B: what was is that what was it that you had done last week when you showed do you remember ? wh - when you showed me the your table last week ?
D: it - it was part of these results .
A: so where is the baseline for the ti - digits located in here ?
D: you mean the htk aurora baseline ? it 's the one hundred number . it 's , , all these numbers are the ratio with respect to the baseline .
B: so this is word error rate , so high number is bad .
D: this is word error rate ratio . so , seventy point two means that we reduced the error rate by thirty percent .
B: so if we take plp with on - line normalization and delta - del so that 's this thing you have circled here in the second column , and "" multi - english "" refers to what ?
D: then you have mf , ms and me which are for french , spanish and english . actually forgot to say that the multilingual net are trained on features without the derivatives but with increased frame numbers . and we can we can see on the first line of the table that it it 's slightly worse when we don't use delta but it 's not that much .
B: so so , 'm . missed that . what 's mf , ms and me ?
A: multi - french ,
D: so . multi - french , multi - spanish , and multi - english .
B: so , it 's broader vocabulary . so what 'm what saw in your smaller chart that was thinking of was there were some numbers saw , , that included these multiple languages and it and was seeing that it got worse . that was all it was . you had some very limited results that at that point which showed having in these other languages . it might have been just this last category , having two languages broad that were where english was removed . so that was cross language and the and the result was quite poor . what we hadn't seen yet was that if you added in the english , it 's still poor . now , what 's the noise condition of the training data this is what you were explaining . the noise condition is the same it 's the same aurora noises , in all these cases for the training . so there 's not statistical sta strong st statistically different noise characteristic between the training and test
D: no these are the same noises ,
B: and yet we 're seeing some effect
D: at least at least for the first for the - matched ,
B: so there 's some an effect from having these this broader coverage now what we should try doing with this is try testing these on this same thing you probably must have this lined up to do . to try the same with the exact same training , do testing on the other languages . you have this here , for the italian . that 's right . so , so .
D: so for the italian the results are stranger so what appears is that perhaps spanish is not very close to italian because , , when using the network trained only on spanish it 's the error rate is almost twice the baseline error rate .
B: , let 's see . is there any difference in so it 's in the so you 're saying that when you train on english and and test on no , you don't have training on english testing
D: there there is another difference , is that the noise the noises are different .
B: in in what ?
D: for for the italian part the the networks are trained with noise from aurora ti - digits ,
E: aurora - two .
B: and the noise is different in th
D: and perhaps the noise are quite different from the noises in the speech that italian .
B: do we have any test sets in any other language that have the same noise as in the aurora ?
E: mmm , no .
A: can ask something real quick ? in in the upper part in the english , it looks like the very best number is sixty point nine ? and that 's in the the third section in the upper part under plp jrasta , the middle column ? is that noisy condition ? so that 's matched training ? is that what that is ?
D: the third part , so it 's highly mismatched . so . training and test noise are different .
A: so why do you get your best number in wouldn't you get your best number in the clean case ?
C: it 's relative to the baseline mismatching
A: so these are not alright , see . and then so , in the in the in the non - mismatched clean case , your best one was under mfcc ? that sixty - one point four ?
D: but it 's not clean case . it 's noisy case but training and test noises are the same .
A: ! so this upper third ? that 's still noisy ?
D: so it 's always noisy , and , , the
B: this will take some looking at , thinking about . but , what is what is currently running , that 's , that just filling in the holes here
D: no we don't plan to fill the holes but actually there is something important , is that we made lot of assumption concerning the on - line normalization and we just noticed recently that the approach that we were using was not leading to very good results when we used the straight features to htk . so if you look at the at the left of the table , the first row , with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for italian with straight mmm , plp features using on - line normalization . mmm . and the , mmm what 's in the table , just at the left of the plp twelve on - line normalization column , so , the numbers seventy - nine , fifty - four and forty - two are the results obtained by pratibha with his on - line normalization her on - line normalization approach .
A: where is that ? seventy - nine , fifty
B: it 's just sitting right on the the column line .
E: fifty - one ?
D: so these are the results of ogi with on - line normalization and straight features to htk . and the previous result , eighty - six and so on , are with our features straight to htk . so what we see that is there is that the way we were doing this was not correct , but still the networks are very good . when we use the networks our number are better that pratibha results .
B: so , do what was wrong with the on - line normalization , or ?
D: there were diff there were different things and , the first thing is the mmm , alpha value . so , the recursion part . used point five percent , which was the default value in the in the programs here . and pratibha used five percent . so it adapts more quickly assume that this was not important because previous results from dan and show that the both values give the same results . it was true on ti - digits but it 's not true on italian . second thing is the initialization of the . actually , what we were doing is to start the recursion from the beginning of the utterance . and using initial values that are the global mean and variances measured across the whole database . and pratibha did something different is that he she initialed the values of the mean and variance by computing this on the twenty - five first frames of each utterance . mmm . there were other minor differences , the fact that she used fifteen dissities instead instead of thirteen , and that she used - zero instead of log energy . but the main differences concerns the recursion . so . , changed the code and now we have baseline that 's similar to the ogi baseline . we it it 's slightly different because don't exactly initialize the same way she does . actually start , mmm , don't to fifteen twenty - five frames before computing mean and the variance to to start the recursion . use the on - line scheme and only start the re recursion after the twenty - five twenty - fifth frame . but , it 's similar . so retrained the networks with these the the networks are retaining with these new features . so what expect is that these numbers will little bit go down but perhaps not so much because the neural networks learn perhaps to even if the features are not normalized . it it will learn how to normalize
B: but that given the pressure of time we probably want to draw because of that especially , we wanna draw some conclusions from this , do some reductions in what we 're looking at , and make some strong decisions for what we 're gonna do testing on before next week . so do you are you did you have something going on , on the side , with multi - band or on this ,
D: we plan to start this so , act actually we have discussed @ @ , these what we could do more as as research and we were thinking perhaps that the way we use the tandem is not , there is perhaps flaw in the in the because we trained the networks if we trained the networks on the on language and or specific task , what we ask is to the network is to put the bound the decision boundaries somewhere in the space . and mmm and ask the network to put one , at one side of the for particular phoneme at one side of the boundary decision boundary and one for another phoneme at the other side . and so there is reduction of the information there that 's not correct because if we change task and if the phonemes are not in the same context in the new task , the decision boundaries are not should not be at the same place . but the way the feature gives the the way the network gives the features is that it reduce completely the it removes completely the information lot of information from the features by placing the decision boundaries at optimal places for one data but this is not the case for another data .
B: it 's trade - off , any - anyway go ahead .
D: so what we were thinking about is perhaps one way to solve this problem is increase the number of outputs of the neural networks . doing something like , phonemes within context and , context dependent phonemes .
B: you could make the same argument , it 'd be just as legitimate , for hybrid systems as .
D: but , we know that
B: and , th things get better with context dependent versions .
D: ye - but here it 's something different . we want to have features
B: but it 's still true that what you 're doing is you 're you 're coming up with something to represent , whether it 's distribution , probability distribution or features , you 're coming up with set of variables that are representing , things that vary over context . and you 're putting it all together , ignoring the differences in context . that that 's true for the hybrid system , it 's true for tandem system . so , for that reason , when you in hybrid system , when you incorporate context one way or another , you do get better scores . but it 's big deal to get that . and once you the other thing is that once you represent start representing more and more context it is much more specific to particular task in language . so , the acoustics associated with particular context , you may have some kinds of contexts that will never occur in one language and will occur frequently in the other , the issue of getting enough training for particular context becomes harder . we already actually don't have huge amount of training data
D: but mmm , , the the way we do it now is that we have neural network and the net network is trained almost to give binary decisions . and binary decisions about phonemes .
B: but it it does give distribution . it 's and it is true that if there 's two phones that are very similar , that the it may prefer one but it will give reasonably high value to the other , too .
D: so it 's almost binary decisions and the idea of using more classes is to get something that 's less binary decisions .
B: but it would still be even more of binary decision . it it 'd be even more of one . because then you would say that in that this phone in this context is one , but the same phone in slightly different context is zero . that would be even more distinct of binary decision . actually would have thought you 'd wanna go the other way and have fewer classes . , the thing was arguing for before , but again which don't think we have time to try , is something in which you would modify the code so you could train to have several outputs on and use articulatory features cuz then that would that would go that would be much broader and cover many different situations . but if you go to very fine categories , it 's very binary .
D: perhaps you 're right , but you have more classes so you have more information in your features . so , you have more information in the but still the information is relevant because it 's it 's information that helps to discriminate , if it 's possible to be able to discriminate among the phonemes in context .
B: it 's it 's an interesting thought . we could disagree about it at length but the real thing is if you 're interested in it you 'll probably try it and we 'll see . but but what 'm more concerned with now , as an operational level , is , , what do we do in four or five days ? and so we have to be concerned with are we gonna look at any combinations of things , once the nets get retrained so you have this problem out of it . are we going to look at multi - band ? are we gonna look at combinations of things ? what questions are we gonna ask , we should probably turn shortly to this note . how are we going to combine with what they 've been focusing on ? we haven't been doing any of the rasta thing . and they , although they don't talk about it in this note , there 's , the issue of the mu law business versus the logarithm , so what what is going on right now ? you 've got nets retraining , are there is there are there any trainings testings going on ?
E: 'm trying the htk with , plp twelve on - line delta - delta and msg filter together . the combination , . but haven't result at this moment .
B: msg and plp . and is this with the revised on - line normalization ?
E: ye - , with the old older ,
B: so it 's using all the nets for that but again we have the hope that it we have the hope that it maybe it 's not making too much difference ,
D: so there is this combination , working on combination . will start work on multi - band . and we plan to work also on the idea of using both features and net outputs . and we think that with this approach perhaps we could reduce the number of outputs of the neural network . so , get simpler networks , because we still have the features . so we have come up with different broad phonetic categories . and we have we have three types of broad phonetic classes . something using place of articulation which leads to nine , , broad classes . another which is based on manner , which is also something like nine classes . and then , something that combine both , and we have twenty twenty - five ?
F: twenty - seven .
D: twenty - seven broad classes . so like , , like back vowels , front vowels .
B: so what you do
D: for the moments we do not don't have nets ,
B: so you have two net or three nets ? how many how many nets do you have ?
D: it 's just were we just changing the labels to retrain nets with fewer out outputs .
E: begin to work in this . we are @ @ .
B: but but didn't understand the software currently just has allows for , the one hot output . so you 're having multiple nets and combining them , how are you how are you coming up with if you say if you have place characteristic and manner characteristic , how do you
D: it - it 's the single net ,
A: they have one output .
B: it 's just one net .
D: it 's one net with twenty - seven outputs if we have twenty - seven classes , so it 's , it 's standard net with fewer classes .
B: so you 're going the other way of what you were saying bit ago
D: including the features , .
F: but including the features .
D: don't think this will work alone . it will get worse because , believe the effect that of too reducing too much the information is what happens
B: but you you include that plus the other features ,
D: because there is perhaps one important thing that the net brings , and ogi show showed that , is the distinction between sp speech and silence because these nets are trained on - controlled condition . the labels are obtained on clean speech , and we add noise after . so this is one thing but perhaps , something intermediary using also some broad classes could bring so much more information .
B: so so again then we have these broad classes and , somewhat broad . it 's twenty - seven instead of sixty - four , . and you have the original features . which are plp , . and then , just to remind me , all of that goes into , th of that is transformed by , - kl , or ?
D: there will probably be , one single kl to transform everything
E: and only transform the other
D: this is still something that
B: so there 's question of whether you would
E: two @ @ it 's one .
B: whether you would transform together or just one . might wanna try it both ways . but that 's interesting . so that 's something that you 're you haven't trained yet but are preparing to train , and so hynek will be here monday . monday or tuesday . so , , we need to choose the experiments carefully , so we can get key questions answered before then and leave other ones aside even if it leaves incomplete tables someplace , it 's it 's really time to time to choose . let me pass this out , . did did interrupt you ? were there other things that you wanted to
D: no . don't .
B: ! . , we have lots of them .
E: we have one .
B: so , something asked so they 're they 're doing the vad they mean voice activity detection so again , it 's the silence so they 've just trained up net which has two outputs , believe . haven't talked to sunil asked hynek whether they compared that to just taking the nets we already had and summing up the probabilities . to get the speech voice activity detection , or else just using the silence , if there 's only one silence output . and , he didn't think they had , but on the other hand , maybe they can get by with smaller net and maybe sometimes you don't run the other , maybe there 's computational advantage to having separate net , anyway . so their the results look pretty good . , not uniformly . there 's an example or two that you can find , where it made it slightly worse , but in all but couple examples .
E: but they have question of the result . how are trained the lda filter ? how obtained the lda filter ?
B: don't understand your question .
E: the lda filter needs some training set to obtain the filter . exactly how they are obtained .
B: it 's on training .
E: training , with the training test of each you understand me ? lda filter need set of set of training to obtain the filter . and maybe for the italian , for the td te on for finnish , these filter are obtained with their own training set .
B: that 's that 's so that 's that 's very good question , then now that it understand it . it 's where does the lda come from ? "" in the in earlier experiments , they had taken lda from completely different database ,
E: because maybe it the same situation that the neural network training with their own
B: so that 's good question . where does it come from ? but to tell you the truth , wasn't actually looking at the lda so much when was looking at it was mostly thinking about the vad . and , it ap it ap what does what does asp ? it says "" baseline asp "" .
E: is what is the difference between asp and baseline over ?
C: there it is .
B: cuz there 's "" baseline aurora "" above it . and it 's this is mostly better than baseline , although in some cases it 's little worse , in couple cases .
C: it says baseline asp is twenty - three mill minus thirteen .
B: it says what it is . but don't how that 's different from
C: from the baseline . .
B: this was this is the same point we were at when we were up in oregon .
D: it 's the - zero using - zero instead of log energy . it 's this . it should be that ,
A: they they say in here that the vad is not used as an additional feature . does does anybody know how they 're using it ?
B: so so what they 're doing here is , if you look down at the block diagram , , they estimate they get they get an estimate of whether it 's speech or silence , and then they have median filter of it . and so , they 're trying to find stretches . the median filter is enforcing it having some continuity . you find stretches where the combination of the frame wise vad and the median filter say that there 's stretch of silence . and then it 's going through and just throwing the data away .
A: so it 's it 's you mean it 's throwing out frames ?
B: it 's throwing out chunks of frames , . there 's the median filter is enforcing that it 's not gonna be single cases of frames , or isolated frames . so it 's throwing out frames and , what don't understand is how they 're doing this with
A: that 's what was just gonna ask . how can you just throw out frames ?
B: it stretches again . for single frames it would be pretty hard . but if you say speech starts here , speech ends there .
D: you can remove the frames from the feature files .
B: so in the in the in the decoding , you 're saying that we 're gonna decode from here to here . they 're they 're treating it , , like it 's not isolated word ,
A: in the text they say that this is tentative block diagram of possible configuration we could think of . so that sounds like they 're not doing that yet .
B: no they have numbers though , so they 're they 're doing something like that . that they 're they 're what by tha that is they 're trying to come up with block diagram that 's plausible for the standard . in other words , it 's from the point of view of reducing the number of bits you have to transmit it 's not bad idea to detect silence anyway .
A: 'm just wondering what exactly did they do up in this table if it wasn't this .
B: but it 's it 's that that 's certainly it would be tricky about it intrans in transmitting voice , for listening to , is that these kinds of things cut speech off lot .
A: plus it 's gonna introduce delays .
B: it does introduce delays but they 're claiming that it 's it 's within the boundaries of it . and the lda introduces delays , and what he 's suggesting this here is parallel path so that it doesn't introduce , any more delay . it introduces two hundred milliseconds of delay but at the same time the lda down here what 's the difference between tlda and slda ?
C: temporal and spectral .
B: you would know that . so . the temporal lda does include the same so that he , by saying this is tentative block di diagram means if you construct it this way , this delay would work in that way and then it 'd be . they they clearly did actually remove silent sections in order because they got these word error rate results . so that it 's it 's to do that in this because , it 's gonna give better word error result and therefore will help within an evaluation . whereas to whether this would actually be in final standard , . , as , part of the problem with evaluation right now is that the word models are pretty bad and nobody wants has approached improving them . so it 's possible that lot of the problems with so many insertions and would go away if they were better word models to begin with . so this might just be temporary thing . but , on the other hand , and maybe it 's decent idea . so the question we 're gonna wanna go through next week when hynek shows up is given that we 've been if you look at what we 've been trying , we 're looking at , by then , combinations of features and multi - band and we 've been looking at cross - language , cross task issues . and they 've been not so much looking at the cross task multiple language issues . but they 've been looking at at these issues . at the on - line normalization and the voice activity detection . and when he comes here we 're gonna have to start deciding about what do we choose from what we 've looked at to blend with some group of things in what they 've looked at and once we choose that , how do we split up the effort ? because we still have even once we choose , we 've still got another month or so , there 's holidays in the way , but the evaluation data comes january thirty - first so there 's still fair amount of time to do things together it 's just that they probably should be somewhat more coherent between the two sites in that amount of time .
A: when they removed the silence frames , did they insert some marker so that the recognizer knows it 's knows when it 's time to back trace ?
B: the specifics of how they 're doing it . they 're they 're getting around the way the recognizer works because they 're not allowed to , change the scripts for the recognizer , believe .
A: maybe they 're just inserting some nummy frames ?
B: , that 's what had thought . but don't don't think they are . that 's what the way had imagined would happen is that on the other side , you put some low level noise . probably don't want all zeros . most recognizers don't like zeros but , put some epsilon in or some rand epsilon random variable in .
A: some constant vector .
B: maybe not constant but it doesn't , don't like to divide by the variance of that ,
A: that 's right . what is something that is very distinguishable from speech . so that the silence model in htk will always pick it up .
B: so that 's what they would do . or else , maybe there is some indicator to tell it to start and stop , but whatever they did , they have to play within the rules of this specific evaluation . we we can find out .
A: cuz you gotta do something . otherwise , if it 's just bunch of speech , stuck together
B: it would do badly and it didn't so badly , so they did something . so this brings me up to date bit . it hopefully brings other people up to date bit . and , wanna look at these numbers off - line little bit and think about it and talk with everybody , outside of this meeting . no it sounds like there are the usual number of little problems and bugs and but it sounds like they 're getting ironed out . and now we 're seem to be in position to actually , look at and and compare things . so that 's that 's pretty good . one of the things wonder about , coming back to the first results you talked about , is how much , things could be helped by more parameters . and and how many more parameters we can afford to have , in terms of the computational limits . because anyway when we go to twice as much data and have the same number of parameters , particularly when it 's twice as much data and it 's quite diverse , wonder if having twice as many parameters would help . just have bigger hidden layer . doubt it would help by forty per cent . how are we doing on the resources ?
D: we 're alright , not much problems with that . this table took more than five days to get back .
B: are were you folks using gin ? that 's that just died ,
D: mmm , no . you were using gin perhaps ,
B: that 's good .
F: it just died .
B: we 're gonna get replacement server that 'll be faster server , actually . that 'll be it 's seven hundred fifty megahertz sun but it won't be installed for little while .
G: do we do we have that big new ibm machine the , in th
B: we have the little tiny ibm machine that might someday grow up to be big ibm machine . it 's got slots for eight , ibm was donating five , we only got two so far , we had originally hoped we were getting eight hundred megahertz processors . they ended up being five fifty . so instead of having eight processors that were eight hundred megahertz , we ended up with two that are five hundred and fifty megahertz . and more are supposed to come soon and there 's only moderate amount of dat of memory . so don't think anybody has been sufficiently excited by it to spend much time with it , but hopefully , they 'll get us some more parts , soon , that 'll be once we get it populated , that 'll be machine . we will ultimately get eight processors in there . and and amount of memory . so it 'll be pr pretty fast linux machine .
G: and if we can do things on linux , some of the machines we have going already , like swede ? it seems pretty fast . but fudge is pretty fast too .
B: you can check with dave johnson . it 's the machine is just sitting there . and it does have two processors , and somebody could do , , check out the multi - threading libraries . and it 's possible that the the prudent thing to do would be for somebody to do the work on getting our code running on that machine with two processors even though there aren't five or eight . there 's there 's gonna be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful . but . notice how said somebody and turned my head your direction . that 's one thing you don't get in these recordings . you don't get the don't get the visuals
G: is it mostly the neural network trainings that are slowing us down or the htk runs that are slowing us down ?
B: isn't that right ? you 're you 're held up by both , if the if the neural net trainings were hundred times faster you still wouldn't be anything running through these hundred times faster because you 'd be stuck by the htk trainings , but if the htk they 're both it sounded like they were roughly equal ? is that about right ?
G: because , that 'll be running linux , and sw - swede and fudge are already running linux so , could try to get the train the neural network trainings or the htk running under linux , and to start with 'm wondering which one should pick first .
B: probably the neural net cuz it 's probably it 's it 's htk we use for this aurora it 's not clear yet what we 're gonna use for trainings there 's the trainings is it the training that takes the time , or the decoding ? is it about equal between the two ? for for aurora ? for the aurora ?
D: training is longer .
B: do we have htk source ? you would think that would fairly trivially the training would , anyway , th the testing don't think would parallelize all that . but that you could certainly do , distributed , , no , it 's the each individual sentence is pretty tricky to parallelize . but you could split up the sentences in test set .
A: they have they have thing for doing that and th they have for awhile , in and you can parallelize the training . and run it on several machines and it just keeps counts . and there 's something final thing that you run and it accumulates all the counts together . don't what their scripts are set up to do for the aurora ,
B: something that we haven't really settled on yet is other than this aurora , what do we do , large vocabulary training slash testing for tandem systems . cuz we hadn't really done much with tandem systems for larger . cuz we had this one collaboration with cmu and we used sphinx . we 're also gonna be collaborating with sri and we have their have theirs . so the advantage of going with the neural net thing is that we 're gonna use the neural net trainings , no matter what , for lot of the things we 're doing , whereas , exactly which gaussian - mixture - based thing we use is gonna depend so with that , maybe we should go to our {nonvocalsound} digit recitation task . and , it 's about eleven fifty . start over here . could you give adam call . he 's at two nine seven . we can @ @ herve 's coming tomorrow , herve will be giving talk , , talk at eleven . did , did everybody sign these consent er everybody has everyone signed consent form before , on previous meetings ? you don't have to do it again each time
","The meeting was dominated by a discussion of the first results coming
in.
There have been four types of test , in which the training data
varies , and a variety of input features have been tried.
The process
and results were explained to the group , the implications of the
results discussed , and plans for moving forward were made.
There was also discussion of some of the work being conducted by
research partners OGI , including how the two groups should best work
together.
The group also briefly touched upon resource issues.
Speaker mn007 would like to investigate increasing the context of the
phonemes.
speaker mn013 does agree with mn007s assessment of the
outcome , and points out the lack of data , but acknowledges that if
mn007 is interested he will go ahead with it.
Must be careful in choosing which experiments to perform as an
important visitor is coming soon.
Also need to come up with a
stronger plan for collaboration with OGI.
Must decide what from both
can be brought together , and how then can the work be divided.
Someone ( implied with gestures in the meeting ) must speak to a person
outside the group with regards to using a multiprocessor Linux machine
that is available.
Debugging the process while there are just two
processors bodes well for when they have 8 to multi-thread.
Speaker mn026 volunteers to get some training running under Linux.
It
is agreed that he should start with the neural net training , then work
on HTK.
Incorrect assumptions were made when considering the on-line
normalization for the main task .  members used different values to a
previous study , and whilst it was believed not to make a difference,
it does , so networks are being retrained.
Currently working with noise conditions being the same in training and
test data , but there is nothing which matches the noise on the Italian
test data.
In fact no other language matches the noise from Aurora
data.
Spanish was being used to train for Italian as it was assumed they
were the most similar , but that may not be as close a match as
thought.
OGI have an interesting approach to Voice Activation Detection for
removing blocks of silence , that shows good results , but currently the
word model being used is too poor to make good use of this and no one
is working on improving it.
Speakers mn007 and fn002 have been running experiments.
Looking at
different features , under different training conditions.
Moving from
training with task data to broad data increases error rate by 10% , and
moving to multiple languages increases a further 20-30%.
PLP with
JRASTA better than just PLP on mismatched conditions , but slightly
worse on well matched.
Speaker fn002 is also looking at the HTK training , but does not yet
have results.
Speaker mn007 is going to start work on creating broad phonetic
categories based on various features , and combine this with original
features like PLP.
As yet unsure how to combine the data however.
"
ami_abstractive_summary,Bed005.txt,"A: got my mike on . let 's see .
B: ami , do yours then we 'll open it and it 'll be enough .
A: mmm doesn't , it should be the other way . now it 's on .
B: so , we all switched on ?
A: we are all switched on , .
B: anyway . so , , before we get started with the , , technical part , want to review what is happening with the our data collection .
F: we are all switched on .
B: so , probably after today , that shouldn't come up in this meeting . th - this is should be im it isn't there 's another thing going on of gathering data , and that 's independent of this . but , , want to make we 're all together on this . what we gonna happen is that , , in parallel starting about now we 're gonna get fey to , where you 're working with me and robert , draft note that we 're gonna send out to various cogsci and other classes saying , "" here 's an opportunity to be subject . contact fey . "" and then there 'll be certain number of , hours during the week which she will be available and we 'll bring in people . roughly how many , robert ? we do we know ?
C: fifty was our our first
B: so , we 're looking for total of fifty people , not necessarily by any means all students but we 'll we 'll start with that . in parallel with that , we 're gonna need to actually do the script . and , so , there 's plan to have meeting friday afternoon , with , jane , and maybe liz and whoever , on actually getting the script worked out . but what 'd like to do , if it 's , is to to , as say , start the recruiting in parallel and possibly start running subjects next week . the week after that 's spring break , and maybe we 'll look for them some subjects next door
C: also , fey will not be here during spring break .
B: , then we won't do it . so that 's easy . so , is is that make sense to everybody ?
C: also , , both fey and will , , do something of which may , kindly ask you to do the same thing , which is we gonna check out our social infrastructures for possible subjects . meaning , , kid children 's gymnastic classes , pre - school parents and . they also sometimes have flexible schedules . so , if you happen to be in non - student social setting , and people who may be interested in being subjects we also considered using the berkeley high school and their teachers , maybe , and get them interested in .
B: that 's good idea .
C: so that 's as far as our brainstorming was concerned .
B: . the high school 's great idea .
C: but will just make first draft of the , , note , the "" write - up "" note , send it to you and fey
B: and why don't you also copy jane on it ?
C: are we have we concurred that , , these forms are sufficient for us , and necessary ?
B: th they 're necessary . this the permission form . there has to be one , and we 're just gonna use it as it is ,
C: you happy with that ?
B: there 's one tricky part about , they have the right the last paragraph "" if you agree to participate you have the opportunity to have anything excised which you would prefer not to have included in the data set . "" now that , we had to be included for this other one which might have , , meetings , , about something . in this case , it doesn't really make sense . so what 'd like to do is also have our subjects sign waiver saying "" don't want to see the final transcript "" . and if they don't if they say "" no , 'm not willing to sign that "" , then we 'll show them the final transcript . so we might actually , jane may say that , "" , you can't do this "" , "" on the same form , we need separate form . "" but anyway . 'd 'd like to , , add an little thi thing for them to initial , saying "" nah , do don't want to see the final transcript . "" but other than that , that 's one 's been approved , this really is the same project , so we just go with it .
C: so much for the data , except that with munich everything is fine now . they 're gonna transcribe . they 're also gonna translate the , , german data from the tv and cinema for andreas . they 're they all seem to be happy now , with that . sh should we move on to the technical sides ? the good news of last week was the parser . bhaskara and started working on the parser . then bhaskara went to class and once he came back , , it was finished . it , didn't measure it , but it was about an hour and ten minutes . and , and now it 's we have complete english parser that does everything the german parser does .
D: something like that .
B: which is not lot .
D: that 's the , , point .
C: the , that 's not lot .
E: what did you end up having to do ? wha was there anything interesting about it ?
D: we 'll show you .
B: we can show us ,
E: or are we gonna see that ?
C: we the first we did is we tried to do change the "" laufen "" into "" run "" , or "" running "" , or "" runs "" . and we noticed that whatever we tried to do , it no effect . and we were puzzled . and , , the reason was that the parser completely ignores the verb . so this sentence is parses the the same output ,
E: interesting parser property .
C: even if you leave out , , all of this . so it 's feature film and tv . that 's what you need . if if you 'd add today and evening , it 'll add time or not .
E: and the and the time , right ?
C: so it it does look at that . but all the rest is simply frosting on the cake , and it 's optional for that parser .
B: so , you can sho you you are are you gonna show us the little templates ?
C: we ar we can sh er show you the templates . also have it running here ,
E: the former end ""
C: so if do this now , , you can see that it parsed the wonderful english sentence , "" which films are on the cinema today evening ? "" do don't worry about it . it could be "" this evening , which films are on the cinema "" , or "" running in the cinema , "" today evening "" , "" is anything happening in the cinema this evening ? ""
E: key words , .
C: ge - elaborate , or , more or less ,
B: actually , it 's little tricky , in that there 's some allowable german orders which aren't allowable english orders and . and it is order - based . so it doe it these these optional elements , it 's it 's actually set ,
C: we were was afraid that ,
E: so it really is key word matching , .
C: , these sentences are just silly . , these were not the ones we actually did it . what 's an idiomatic of phrasing this ? which films are showing ?
D: are pl playing at the cinema ? changed that file , actually , where it 's on my account .
E: this this evening ?
F: actually , you would say , "" which films are on tonight ? ""
D: you want to get it ? or is di was it easy to get it ?
C: have no net here . so . wonderful parse , except that we we don't have this , , time information here now , this are the reserve . anyways . so . these are the the ten different sentence types that the the parser was able to do . and it still is , now in english . you have already to make it little bit more elaborate , right ?
D: changed those sentences to make it , , more , , idiomatic . and , , you can have many variations in those sentences , they will still parse fine . so , in sense it 's pretty broad .
C: so , if you want to look at the templates , they 're conveniently located in file , "" template "" . and this is what had to do . had to change , @ @ "" spielfilm "" to "" film "" , "" film "" to "" movie "" , cinem "" kino "" to "" cinema "" to "" today "" heu "" heute "" to "" today "" , evening "" abend "" to "" evening ""
D: one thing was wondering , was , those functions there , are those things that modify the - three - ?
C: and that 's that 's the next step , but we 'll get to that in second . and so this means , , "" this "" and "" see "" are not optional . "" want like "" is all maybe in there , but may also not be in there .
B: so so , , if it says "" this "" and "" see "" , it also will work in "" see "" and "" this "" ? in the other order ? with those two key words ?
C: should we try it ?
B: "" this is the one want to see ""
C: "" action watch "" , nothing was specialfi specified . except that it has some references to audio - visual media here . where it gets that from it 's correct , but where it gets it from .
D: "" see "" .
C: "" see "" . and "" see this "" is exactly the same thing .
B: so it is set - based .
D: one thing was wondering was , those percentage signs , right ? so , , why do we even have them ? because if you didn't have them
C: 'll tell you why . because it gives you score . and the value of the score is , assume , , the more of these optional things that are actually in there , the higher the score it is .
D: so that 's the main purpose . alright .
E: it 's match .
C: so we shouldn't belittle it too much . it 's doing something , and it 's very flexible . 've just tried to
B: no , no . , flexible it is .
C: , let 's hope that the generation will not be more difficult , even though the generator is little bit more complex . that means we may need two hours and twenty minutes rather than an hour ten minutes , and the next thing would like to be able to do , and it seems like this would not be too difficult either , is to say , "" let 's now pretend we actually wanted to not only change the mapping of , , words to the - three - but we also wanted to change add new sentence type and make up some new - three - ""
B: that 'd be great . it would be good exercise to just see whether one can get that to run .
D: so , that 's
C: that 's shouldn't be too tough .
D: so where are those those functions "" action "" , "" goodbye "" , and so on , right ? are they actually , , are they going to be called ? are they present in the code for the parser ?
C: what it does , it it does something fancy . it has these style sheets and also the , , schemata . so what it probably does , is it takes the , is this where it is ? this is already the xml ? this is where it takes its own , , syntax , and converts it somehow .
D: what are you looking for ?
C: where it actually produces the xml out of the , , parsed . no , this is not it . 't find it now . you mean , where the where the act how the action "" goodbye "" maps into something
A: where are those constructors defined ?
D: no , that 's not it .
C: this is what happens . this is what you would need to change to get the , , xml changed . so when it encounts encounters "" day "" , it will , , activate those classes in the in the xml saw those actions , the "" goodbye "" somewhere .
A: grep for it ?
C: let 's do that .
D: - three - dot dtd ? that 's just specification for the xml format .
C: we 'll find that out . so whatever this does this is , , looks to me like function call , right ? so , whenever it encounters "" goodbye "" , which we can make it do in second , here
A: that function automatically generates an initialized xml structure ?
D: each of those functions act on the current xml structure , and change it in some way , , by adding field to it , .
B: they also seem to affect state , there were other actions , that seemed to step state variables somewhere , like the "" discourse status confirm "" . so that 's going to be call on the discourse and confirm that it 's
D: you mean that 's not going to actually modify the tree ,
B: that 's right .
D: but it 's going to change the event .
B: it 's actually that looks like it 's state modification .
C: there is feature called "" discourse - status "" ,
D: when there 's feature .
C: and so whenever say , "" write "" , it will it will put this in here .
B: so it always just is it so it go back , then , cuz it may be th those th things , while they look like function calls , are just way of adding exactly that to the xml . 'm not 'm not .
C: we 'll see , when we say , let 's test something , "" goodbye "" , causes it to to create an "" action goodbye - end - action "" . which is means of telling the system to shut down . now , if we know that "" write "" produces "" feature discourse - status confirm discourse - status "" . so if now say "" write , goodbye , "" it should do that . it sho it creates this , "" confirm goodbye "" .
D: but there is some function call , because how does it know to put goodbye in content , but , , confirm in features ?
C: it it that 's because
D: so , it 's not just that it 's adding that field .
B: it 's it 's the it 's under what sub - type you 're doing it .
A: it 's mystery functions .
C: sometimes it sometimes ,
D: they 're defined somewhere , presumably .
B: so that 's funny . you bury the the state in the function
A: it just automatically initializes things that are common , right ? so it 's just shorthand .
C: this is german . so , now , this , it cannot do anymore . nothing comes out of here .
A: "" not number "" is value . awesome .
C: so , it doesn't speak german anymore , but it does speak english . and there is , here , reference so , this tells us that whatever is has the id "" zero "" is referenced here by @ @ the restriction seed and this is exa "" want "" what was the sentence ?
B: "" want two seats here . ""
C: "" need two seats here . "" nuh . "" and where is it playing ? "" there should also be reference to something , maybe . our this is re here , we change and so , we here we add something to the discourse - status , that the user wants to change something that was done before and that , whatever is being changed has something to do with the cinema .
A: so then , whatever takes this - three - is what actually changes the state ,
B: no , right , the discourse maintainer , and it and it runs around looking for discourse status tags , and doing whatever it does with them . and other people ignore those tags . so , . definitely 's it 's worth the exercise of trying to actually add something that isn't there .
C: get complete understanding of the whole thing .
B: kid understanding what 's going on . then the next thing we talked about is actually , , figuring out how to add our own tags , and like that .
C: point number two . got the , , - three - for the routes today . so got some more . it 's just going up , it 's not going back down . so , this is , what got today is the new - three - for , the maps , and with some examples so , this is the xml and this is what it will look like later on , even though it you can't see it on this resolution . and this is what it is the structure of map requests , also not very interesting , and here is the more interesting for us , is the routes , and , again , as we thought it 's really simple . this is the , , , parameters . we have @ @ simple "" from objects "" and "" to objects "" and , points of interest along the way asked them whether or not we could , first of all , was little bit it seemed to me that this way of doing it is stack step backwards from the way we 've done it before . it seems to me that some notions were missing . so these are these are
B: so these are these are your friends back at eml .
C: who are doing this .
B: so this is not complicated negotiation . there 's there 's not seven committees , or anything , right ?
C: no , this is very straightforward .
B: so this is just trying to it 's design thing , not political thing . once we 've we can just agree on what oughta be done .
C: however , the , so that you understand , it is really simple . you you have route , and you cut it up in different pieces . and every element of that of that every segment we call "" route element "" . and so , from to we cut up in three different steps , and every step has "" from object "" where you start , "" to object "" where where you end , and some points of interest along the way . what was missing here , and , maybe it was just me being too stupid , is , didn't get the notion of the global goal of the whole route . really , was not straightforward visibly for me . and some other . and suggested that they should be , kind enough to do two things for us , is one , , also allocating , , some tags for our action schema enter - vista - approach , and also , , since you had suggested that , , we figure out if we ever , for demo reason , wanted to shortcut directly to the gis and the planner , of how we can do it . now , what 's the state of the art of getting to entrances , what 's the syntax for that , how get getting to vista points and calculating those on the spot . and the approach mode , anyhow , is the default . that 's all they do it these days . wherever you 'll find route planner it does nothing but get to the closest point where the street network is at minimal distance to the geometric center .
B: so , , let now , this is important . let , want again , outside of almost managerial point , you 're in the midst of this , but it seems to me it 's probably good idea to li minimize the number of , change requests we make of them . so it seemed to me , what we ought to do is get our story together . and think about it some , internally , before asking them to make changes . does this does this make sense to you guys ? it you 're you 're doing the interaction but it seemed to me that what we ought to do is come up with , something where you , and who 's mok working most closely on it . take what they have , send it to everybody saying "" this is what they have , this is what we think we should add "" , and then have an iteration within our group saying "" , "" and get our best idea of what we should add . and then go back to them . does this make sense to you ?
C: especially if we want what my feeling was we reserved something that has an label . that 's th that was my th first step . no matter how we want to call it , this is our playground . and if we get something in there that is structure elaborate and and complex enough to to maybe enable whole simulation , one of these days , that would be the perfect goal .
B: that 's right . the problem isn't the short ra range optimization . it 's the one or two year thing . what are the thl class of things we think we might try to do in year or two ? how how would we try to characterize those and what do we want to request now that 's leave enough space to do all that ? and that re that requires some thought . and so that sounds like great thing to do as the priority item as soon as we can do it . so so you guys will send to the rest of us version of , this , and the , description
A: with sugge , suggested improvements
B: so , the not everyone , reads german , so if you 'd tu , tur change the description to , , english then , with some sug suggestions about where do we go from here ? this and this , , was just the action end . at some point we 're going to have to worry about the language end . but for the moment just , for this class of things , we might want to try to encompass .
A: then the scope of this is beyond approach and vis - or vista .
B: this is this is everything that , , , we might want to do in the next couple years . we don't , that 's an issue . we what , entirely .
A: this xml here just has to do with source - path - goal type , in terms of traveling through heidelberg . or travel , specifically . so , but this is the domain greater than that ?
B: the the idea is that it 's beyond source - path - goal , but we don't need to get beyond it @ @ tourists in heidelberg . it seems to me we can get all the complexity we want in actions and in language without going outside of tourists in heidelberg . but , depending on what people are interested in , one could have , , tours , one could have , explanations of why something is , , why was this done , no there 's no end to the complexity you can build into the , what tourist in heidelberg might ask . so , at least unless somebody else wants to suggest otherwise the general domain we don't have to , broaden . that is , tourists in heidelberg . and if there 's something somebody comes up with that can't be done that way , then , . we 'll we 'll look at that , 'd be 'd be surprised at if there 's any important issue that if you want to , push us into reference problems , that would be great . so this is his specialty is reference , and , what are these things referring to ? not only anaphora , but , , more generally the , this whole issue of , , referring expressions , and , what is it that they 're actually dealing with in the world ? and , again , this is li in the databa this is also pretty formed because there is an ontology , and the database , and . so it isn't like , , , the evening star or like that . all the entities do have concrete reference . although th the to get at them from language may not be trivial . there aren't really deep mysteries about , what what things the system knows about .
F: and you have both proper names and descriptions
B: all those things .
F: and and you can ask for it .
B: you have proper names , and descriptions . and and lot and anaphora , and pronouns , and all those things .
C: now , we hav the whole unfortunately , the whole database is , , in german . we have just commissioned someone to translate some bits of it , ie the the shortest the more general descriptions of all the objects and , , persons and events . so , it 's relational database with persons , events , and , , objects . and it 's it 's quite , , there . but did there will be great because the reference problem really is not trivial , even if you have such - defined world . - he you are not , , throwing , carrying owls to athens .
A: could you give me an example of reference problem ? so make it more concrete ?
C: how do get to the powder - tower ? we think that our bit in this problem is interesting , but , just to get from powder - tower to an object id in database is also not really trivial .
F: or or if you take something even more scary , , "" how do get to the third building after the tower ? the ple - powder - tower ? "" you need some mechanism for
B: or , , the church across from city hall ,
A: or the re the restaurant where they wear lederhosen ?
B: that would be fine .
C: or tower , or this tower , or that building , or
B: or you can say "" how "" , "" how do get back ? "" and , again , it 's just question of which of these things , , people want to dive into . what , , 'm gonna try to do , and , pwww ! let 's say that by the end of spring break , 'll try to come up with some general story about , , construction grammar , and what constructions we 'd use and how all this might fit together . there 's this whole framework problem that 'm feeling really uncomfortable about . and haven't had chance to think about it . but want to want to do that early , rather than late . and you and will probably have to talk about this some .
C: that 's what strikes me , that we the de , small something , , maybe we should address one of these days , is to that most of the work people actually always do is look at some statements , and analyze those . whether it 's abstracts or newspapers and like this . but the whole is it is it really relevant that we are dealing mostly with , , questions ? and this is it seems to me that we should maybe at least spend session or brainstorm little bit about whether that this is special case in that sense . did we ever find metaphorical use in questions in that sense , really ? and how soon ,
B: , we could take all the standard metaphor examples and make question versions of them .
C: "" who got kicked out of france ? ""
B: or , . "" wh - why is he why is he pushing for promotion ? "" or , "" who 's pushing proof "" er , just pick any of them and just do the so don't don't think , , it 's difficult , to convert them to question forms that really exist and people say all the time , and we how to handle them , too . we how to handle the declarative forms , @ @ really , and , then , the interrogative forms , - . nancy , it looked like you were
E: it 's just that the goals are very different to cases so we had this problem last year when we first thought about this domain , actually , was that most of the things we talked about are our story understanding . we 're gonna have short discourse and the person talking is trying to , , give you statement and tell you something . and here , it 's th
C: help you create mental model , blah - blah .
E: yea - , so . and then here , you are , the person is getting information and they or may not be following some larger plan , , that we have to recognize or , , infer . and th the their discourse patterns probably {nonvocalsound} don't follo follow quite as many logical connec
B: right . no , that 's one of things that 's interesting , is in this over - arching story we worked it out for th as you say , this the storytelling scenario . and it 's really worth thinking through what it looks like . what is the simspec mean , et cetera .
E: right . cuz for while we were thinking , "" , how can we change the , , data to illicit tha illicit , , actions that are more like what we are used to ? "" but we would rather , , try to figure out what 's what 's ,
B: maybe that 's what we 'll do is we can do anything we want with it . once we have fulfilled these requirements , and the one for next , summer is just half done and then the other half is this , , "" generation thing "" which we sn't much different . so once that 's done , then all the rest of it is , , , , what we want to do for the research . and we can we can do all sorts of things that don't fit into their framework . th - there 's no reason why we 're we 're constrained to do that . if we can use all the , , execution engines , then we can , , really {nonvocalsound} try things that would be too much pain to do ourselves . but there 's no obligation on any of this . so , if we want to turn it into understan standing stories about heidelberg , we can do that . that would just be
C: or , , we need and if we ' take ten year perspective , we need to do that , assuming we have this , , we ta in that case we actually do have these wonderful stories , and historical anecdotes , and knights jumping out of windows , and - and tons of . so , th the database is huge , and if we want to answer question on that , we actually have to go one step before that , and understand that . in order to do sensible information extraction .
B: you might , .
C: this has been deep map research issue that was is part of the unresolved , and to - do 's , and something for the future , is how can we run our text , our content , through machine that will enable us , later , to retrieve or answer questions more sensibly ?
B: who 's going ?
F: so , so , , was just going to ask , what is the basic thing that you are , , obligated to do , , , by the summer before we can move
B: so , what happened is , there 's this , , the there 's two packages there 's , , quote parser , there 's particular piece of this big system , which , in german , , takes these sentence templates and produces xml structures . and one of our jobs was to make the english equivalent of that . that , these guys did in in day . the other thing is , at the other end , roughly at the same level , there 's something that takes , , structures , produces an output xml structure which is instructions for the generator . and then there 's language generator , and then after that synthesizer that goes from an xml structure to , , language generation , to actual specifications for synthesizer . but again , there 's one module in which there 's one piece that we have to convert to english . and that but as say , this is all along was viewed as minor thing , necessary , but not and much more interesting is the fact that , as part of doing this , we are , , inheriting this system that does all these other things .
F: that 's great !
B: not precisely what we want , and that 's that 's wh where it gets difficult . and don't pretend to understand yet what we really ought to do .
C: so , enough of that , but , , , the , johno and will take up that responsibility , and , , get first draft of that . now , we have just , two more short things . you guys started fighting , , on the bayes - net "" noisy - or "" front ?
D: should , , talk little bit about that , because that might be good , , architecture to have , in general for , , problems with , , multiple inputs to node .
B: and what 's the other one ? so that just we the agenda is ?
C: the wu paper ,
B: 've got couple new wu papers as . so 've been in contact with wu , so , probably let 's put that off till till understand better , , what he 's doing . it 's just little embarrassing all this was in his thesis and was on his thesis committee , and , so , really knew this at one time . but , it 's not only is part of what haven't figured out yet is how all this goes together . so 'll dig up some more from dekai . and so why don't we just do the ,
D: should is there white board here that use ? or shall use this ?
B: it 's probably just as easy .
A: you can put the microphone in your pocket . was envying you and your pocket don't have one .
E: it was quick one , ?
B: that 's why they invented "" pocket 's "" .
E: they have clips !
D: so , recall that , , we want to have this structure in our bayes - nets . namely , that , you have these nodes that have several bands , right ? the typical example is that , , these are all bunch of cues , and this is certain effect that we 'd like to conclude . like , let 's just look at the case when , , this is actually the final action , right ? so this is like , , , touch , - eva , right ? enter , view , approach , right ?
F: what was this ? it ehhh , ehhh .
B: wri - write it out for
D: so , this is so , , we 'd like to take all these various cues , right ?
F: like the army .
D: so this one might be , say , let me pick random one
E: haven't heard that before .
D: it could be , like this isn't the way it really is , but let me say that , suppose someone mentioned , , admission fees it takes too long . try let me just say "" landmark "" . if landmark , , then there 's another thing that says if if it 's closed or not , at the moment . alright , so you have nodes . and the , , problem that we were having was that , , given - nodes , there 's "" two to the "" given - nodes , and furthermore , the fact that there 's three things here , we need to specify "" three times "" , , "" two to the "" probabilities . that 's assuming these are all binary , which they may not be . they could be "" time of day "" , in which case we could , , say , , "" morning , afternoon , evening , night "" . so , this could be more so , it 's lot , anyway . and , that 's lot of probabilities to put here , which is pain . so noisy - ors are way to , , deal with this . where should put this ? so , the idea is that , , let 's call these , , - one , - two , - three , and - four , and , for and effect , . the idea is to have these intermediate nodes . actually , the idea , first of all , is that each of these things has quote - unquote distinguished state , which means that this is the state in which we don't really know anything about it . so , , if we don't really landmark or not , or , if that just doesn't seem relevant , then that would be th the disting - the distinguish state . it 's really , , if there is something for the person talking about the admission fee , if they didn't talk about it , that would be the distinguish state .
C: so , this is fanciful way of saying "" default "" ?
D: that 's just what they the word they used in that paper . so , the idea is that , , you have these intermediate nodes , right ? - one , - two , - three and - four ?
B: so , this is the heckerman paper you 're working with ?
D: so the idea is that , each of these ei is represents what this would be if all the other ones were in the distinguish state . right ? so , , suppose that the person , suppose the thing that they talked about is landmark . but none of the other cues really apply . then , this would be the this would just represent the probability distribution of this , assuming that this cue is turned on and the other ones just didn't apply ? so , , if it is landmark , and no none of the other things really ap applicable , then this would represent the probability distribution . so maybe in this case maybe we just maybe we decide that , if the thing 's landmark and we anything else , then we 're gonna conclude that , they want to view it with probability , , point four . they want to enter it with probability , with probability point five and they want to approach it probability point one , say so we come up with these little tables for each of those and the final thing is that , this is deterministic function of these , so we don't need to specify any probabilities . we just have to , , say what function this is , right ? so we can let this be , of - one comma - two . - three , - four . right ? and our example would be , , majority vote ?
B: , so th so the important point is not what the function is . the important point is that there is general idea of shortcutting the full cpt . th - the full conditional probability table with some function . which you choose appropriately for each case . so , depending on what your situation is , there are different functions which are most appropriate . so gave bhaskara copy of this , "" ninety - two "" paper . and you got one , robert . who else has seen it .
D: it 's heckerman and breese .
B: it 's short . it 's short . so , , yo you have you read it yet ?
D: you can , you should take look at it , .
B: so you should take look . nancy , 'm you read it at some point in life . and so , you other guys can decide how interested anyway . so the paper isn't th isn't real hard . one of the questions just come at bhaskara is , "" how much of this does javabayes support ? ""
D: it 's good question . {nonvocalsound} the so what we want , is javabayes to support deterministic , , functions . and , in sense it sup we can make it supported by , , manually , , entering , , probabilities that are one and zeros , right ?
B: right . so the little handout that the little thing that sent sent message saying , , here is way to take one thing you could do , which is in way , stupid , is take this deterministic function , and use it to build the cpt . so , if ba - javabayes won't do it for you , that you can convert all that into what the cpt would be . and , what sent out about week ago , was an idea of how to do that , for , , evidence combination . so one of one function that you could use as your "" function "" is an evidence - combining . so you just take the , if each of th if each of the ones has its own little table like that , then you could take the , , strength of each of those , times its little table , and you 'd add up the total evidence for "" "" , "" "" , and "" "" .
D: don't think you can do this , because is function from that to that . so there 's no numbers . there 's just quadruplets of , - duplets of , , vs .
B: no , no but 'm saying is there is if if you decide what 's what is appropriate , is probablistic evidence combination , you can write function that does it . it 's pui it 's actually one of the examples he 's got in there . but , anyway , skipping the question of exactly which functions now is it clear that you might like to be able to shortcut the whole conditional probability table .
C: in some it seems very plausible in some sense , where we will be likely to not be observe some of the . cuz we don't have the access to the information .
B: that 's one of the problems , is , is is , where would th where would it all come from ?
D: would not be ab able to observe
C: if it 's discar discourse initial phrase , we will have nothing in the discourse history . so , if we ever want to wonder what was mention
D: are you saying that we 'll not be able to observe certain nodes ? that 's fine . that is orthogonal thing .
B: so there 's there 's two separate things , robert . the the the bayes - nets in general are quite good at saying , "" if you have no current information about this variable just take the prior for that . "" ? th - that 's what they 're real good at . so , if you don't have any information about the discourse , you just use your priors of whatever the discourse whatever it 's probabilistically , whatever it would be . and it 's it 's not great estimate , but it 's the best one you have , so that , they 're good at . but the other problem is , how do you fill in all these numbers ? and that 's the one he was getting at .
D: so , specifically in this case you have to have this many numbers , whereas in this case you just have to have three for this , three for this . right ? so you have to have just three ? so , this is much smaller than that .
E: so , you don't need da data enough to cover , nearly as much .
A: so , really , what noisy - or seems to "" neural - net - acize "" these bayes - nets ?
B: no , no . so , "" noisy - or "" is funny way of referring to this , because the noisy - or is only one instance .
D: this isn't noisy - or anymore .
B: that one actually isn't noisy - or . so we 'll have to think of way
D: it 's noisy - arg - max or noisy - whatever .
A: my point was more that we just with the neural net , right , , things come in , you have function that combines them
B: it tha - that 's true . it is is also more neural - net - like , although , it isn't necessarily sum , , sum of weights or anything like that . you could have , like the noisy - or function , really is one that 's essentially says , , take the max .
D: the "" or "" . right . you 're right .
B: and , thi that 's the standard way people get around the there are couple other ones . there are ways of breaking this up into to subnets and like that . we definitely it 's great idea tha to pursue that .
C: wha - still leaves one question . it you can always see easily that 'm not grasping everything correctly , but what seemed attractive to me in im in the last discussion we had , was that we find out means of getting these point four , point five , point one , of - four , not because , , is landmark or not , but we we label this whatever object type , and if it 's garden , it 's point three , point four , point two . if it 's castle , it 's point eight , point one . if it 's , , town hall , it 's point two , point three , point five . and we don't want to write this down necessarily every time let 's see .
D: it 'll be students where else would it be stored ? that 's the question .
C: in the beginning , we 'll write up flat file . we know we have twenty object types and we 'll write it down in flat file .
B: let me say something , guys , cuz there 's not there 's pretty point about this we might as get in right now . which is the hierarchy that comes with the ontology is just what you want for this . so that , if about it let 's say , particular town hall that , it 's one that is monument , then , that would be stored there . if you don't , you look up the hierarchy , so , you you may or so , then you 'd have this little vector of , , , approach mode or eva mode . let 's , so we have the eva vector for various kinds of landmarks . if it for specific landmark you put it there . if you don't , you just go up the hierarchy to the first place you find one .
D: so , is the idea to put it in the ontology ?
B: or , link to but in any case view it logically as being in the ontology . it 's part of what about an object , is its eva vector . and , if yo as say , if about specific object , you put it there . this is part of what dekai was doing . so , when we get to wu , the - we 'll see what he says about that . and , then if you if it isn't there , it 's higher , and if you anything except that it 's it 's it 's building , then up at the highest thing , you have the pr what amounts to prior . if you anything else about building , , you just take whatever your crude approximation is up at that level , which might be equal , or whatever it is . so , that 's very pretty relationship between these local vectors and the ontology . and it seems to me the obvious thing to do , unless we find reason to do something different . does this make sense to you ?
D: so , we are but we 're not doing the ontology , so we have to get to whoever is doing the ultimately ,
B: so , that 's another thing we 're gonna need to do , is , to , either
D: we have to get them to
B: we 're gonna need some way to either get tag in the ontology , or add fields , or some way to associate or , it may be th we can do is , , some of our own hash tables that it th - the th , there 's always way to do that . it 's just question of
A: hash on object name to , , , the probabilities or whatever .
B: and , so ,
C: but it 's , , it strikes me as what for if we get the mechanism , that will be the wonderful part . and then , how to make it work is the second part , in the sense that , the guy who was doing the ontology , ap apologized that it will take him another through two to three days because they 're having really trouble getting the upper level straight , the reason is , given the craw bet , the the projects th carry their own taxonomy and , on all history , they 're really trying to build one top level ontology ft that covers all the eml projects , and that 's , , tough cookie , little bit tougher than they figured . could have told them so . but , nevertheless , it 's going to be there by by , , next monday and will show you what 's what some examples from that for towers , and . what don't ever going to be in the ontology , is , , the likelihood of , , people entering town halls , and looking at town halls , and approaching town halls , especially since we are dealing with case - based , not an instance - based ontology . so , there will be nothing on that town hall , or on the berkeley town hall , or on the heidelberg town hall , it 'll just be information on town halls .
B: they how ar what are they gonna do with instances ?
C: that 's that 's al different question . th the first , they had to make design question , "" do we take ontologies that have instances ? or just one that does not , that just has the types ? "" and , so , since the decision was on types , on simply type - based , we now have to hook it up to instances .
B: but what what is smartkom gonna do about that ? cuz , they have instances all the time .
C: but the ontology is really not smartkom thing , in and of itself . that 's more something that kicked loose in eml . so it 's completely eml thing .
B: but smartkom 's gonna need an ontology .
C: yes , lot of people are aware of that .
B: understand , but is anybody doing anything about it ? it 's political problem . we won't worry about it .
C: no , but th the th still think that there is enough information in there . so , th it will know about the twenty object types there are in the world . let 's assume there are only twenty object types in this world . and it will any of those have institutional meanings . so , in sense , "" "" used as institutions for some in some sense or the other . which makes them enterable . right ?
B: anyway . so we may have to this is with the whole thing , we may have to build another data stru conceptually , we should be done . when we see what people have done , it may turn out that the easiest thing to do is to build separate thing that just pools like , it may be , that , the instance that we have to build our own instance , , things , that , with their types ,
D: right , we can just assume
B: and then it goes off to the ontology once you have its type . so we build little data structure and so what we would do in that case , is , in our instance gadget have our and if we there isn't one we 'd get the type and then have the as for the type . so we 'd have our own little , , eva tree . and then , for other , , vectors that we need . so , we 'd have our own little things so that whenever we needed one , we 'd just use the ontology to get the type , and then would hash or whatever we do to say , "" ! if it 's that type of thing , and we want its eva vector , pppt - pppt ! it 's that . "" so , we can handle that . and then but , the combination functions , and whether we can put those in java bayes , and all that , is , is the bigger deal . that 's where we have to get technically clever .
A: we could just steal the classes in javabayes and then interface to them with our own code .
B: me ye {nonvocalsound} , , the
D: that requires understanding the classes in javabayes , . @ @ .
B: , it 's , , cute . you 've been around enough to there 's this huge package which may or may not be consistent but , , we could look at it . it 's an inter it it 's an interpreter and it expects its data structures to be in given form , and if you say , "" hey , we 're gonna make different data structure to stick in there ""
A: no , but that just means there 's protocol ,
B: it may or may not . that 's the question is "" to what extent does it allow us to put in these functions ? ""
A: no , but what the so you could have four different bayes - nets that you 're running , and then run your own write your own function that would take the output of those four , and make your own "" function "" , is what was saying .
B: if it 's if it comes only at the end . but suppose you want it embedded ?
A: then you 'd have to break all of your bayes - nets into smaller bayes - nets ,
B: that 's truly horrible way to do it . , , you bet . but , at that point you may say , "" hey , java bayes isn't the only package in town . let 's see if there 's another package that 's , , more civilized about this . "" now , srini is worth talking to on this , cuz he said that he actually did hack some combining functions into but he doesn't remember at least when talked to him , he didn't remember whether it was an an easy thing , natural thing , or whether he had to do some violence to it to make it work . but he did do it .
D: don't see why the , , combining functions have to be directly hacked into they 're used to create tables so we can just make our own little functions that create tables in xml .
B: say that 's one way to do it , is to just convert it int into into that you zip it 's blown up , and is it 's , it 's huge , but it doesn't require any data fitting or complication .
D: don't think , the fact that it blown blows up is huge issue in the sense that so say it blows up , right ? so there 's , like , the , ten , ten , fifteen , , things . it 's gonna be like , two to the that , which isn't so bad .
B: 'm just saying tha that that was wi that was my note . the little note sent said that . it said , "" here 's the way you 'd take the logical function and turn it into cpt . "" that the max - the evidence - combining function . so we could do that . and maybe that 's what we 'll do . so , will , before next week , , @ @ push some more on this that dekai wu did , and try to understand it . you 'll make couple of more copies of the heckerman paper to give to people ?
F: would like copy ,
C: and 'll 'll think through this , , getting eva vectors dynamically out of ontologies one more time because 'm not quite whether we all think of the same thing or not , here .
B: you and should talk about it . alright , great ! and , robert , for coming in under he he 's been sick ,
A: was thinking maybe we should just cough into the microphone and see if they can't th see if they can handle it .
","The data collection running in parallel with the project can start shortly with recruiting subjects.
Meanwhile , the german parser now works with english sentences.
The parser's output modifies the XML used by the system to initiate actions and generate responses.
The XML for Map requests also comprise a route , route elements and points of interest along the way.
It is at this level that Enter/Vista/Approach tags will be added as action modes.
As the project evolves , further enrichment of the ontology ( actions , linguistic features ) will be necessary.
Similarly , object representations will include an EVA vector.
This can be incorporated in the database entry for a particular building or inherited from the ontology of the building type.
These elements will constitute only a small part of the inputs of the Bayes-net that determines the action mode.
The actual number of the inputs can create a combinatorial explosion when setting the probabilities.
Noisy-OR's can help avoid this by simplifying the probability tables and applying a deterministic function to produce their complete version.
In any case , further to fulfilling the basic requirements ( translating the parser and the generator into english ) , the project is entirely open-ended in terms of focus of research.
As the data collection is about to begin , there are some minor changes to be done in the design of the experiment , the script and the permission forms.
Subjects can be recruited either from within the university or through other social circles.
As to the system design , the next step is the translation of the generator into english.
Moreover , it is important to test the system and its internal workings by adding new sentence types and modifying the parser.
All further research will use the existing domain ( ""tourists in Heidelberg"" ) , as this provides enough diversity for the purposes of the project.
The german partners for the project will realise all the necessary changes in the ontology.
It is therefore preferable for the group to exercise foresight and agree on the set of new tags they will need in the long run , so that they limit the number of change requests.
Finally , on a more technical note , Noisy-OR's were discussed and considered a sensible approach to deal with the potential problems with the setting the conditional probabilities of the Bayes-nets.
Although the parser has been modified to work with english , the details of its internal workings ( calling functions , setting discourse variables , generating actions ) are not yet clear.
Understanding the parsed data is helped by the database of objects , people and events accompanying the system , but the mapping of referring expressions to database objects can still be a hurdle.
On a different level , the Bayes-net used to generate the different action modes can easily become unmanageable as the number of features to be taken into account increases.
This can be tackled with the use of the Noisy-OR technique.
The deterministic functions this requires cannot be introduced directly into JavaBayes , although some runaround ways can be implemented.
A final , high-level issue , that has not been dealt with yet , is the definition of the constructions and the construction grammar framework analysis behind the whole enterprise.
The preparation for the data collection is almost finished and expected to start experiments within a couple of weeks.
There is some additional TV and cinema data currently being translated from german.
The german parser has been translated and it can now be used for a range of sentence types in english.
On the other hand , the translation of some parts of the relational database accompanying the system has also been commissioned.
EML have provided the structure for Map requests , the basic representation of the navigational goals upon which further action modes are going to be built.
The same people are also creating a general , top-level XML object ontology that will include all types of buildings.
"
ami_abstractive_summary,Bro027.txt,"A: we 're going .
C: eight , eight ?
D: this is three .
B: let 's see . move it bit . it 's alright . let 's see . barry 's not here and dave 's not here . say about just just quickly to get through it , that dave and submitted this asru . it 's it 's interesting . we 're dealing with rever reverberation , and , , when we deal with pure reverberation , the technique he 's using works really , really . and when they had the reverberation here , , we 'll measure the signal - to - noise ratio and it 's , , about nine db .
A: you mean , from the actual , , recordings ? it 's nine db ?
B: and actually it brought up question which may be relevant to the aurora too . know that when you figured out the filters that we 're using for the mel scale , there was some experimentation that went on at , at ogi . but one of the differences that we found between the two systems that we were using , the aurora htk system baseline system and the system that we were the , other system we were using , the , the sri system , was that the sri system had maybe , , hundred hertz high - pass . and the , , aurora htk , it was like twenty .
D: sixty - four . sixty - four .
B: sixty - four ?
D: if you 're using the baseline .
B: is that the ba band center ? the edge is really , , sixty - four ? for some reason , , dave thought it was twenty ,
D: so the , , center would be somewhere around like hundred and hundred and maybe it 's like fi hundred hertz .
B: but do , , how far down it would be at twenty hertz ? what the how much rejection would there be at twenty hertz , let 's say ?
D: at twenty hertz .
B: any idea what the curve looks like ?
D: it 's it 's zero at twenty hertz , right ?
C: yea - actually , the left edge of the first filter is at sixty - four .
D: sixt - sixty - four . so anything less than sixty - four is zero .
B: it 's actually set to zero ? what filter is that ? is this , from the from
C: this is the filter bank in the frequency domain that starts at sixty - four .
B: so you , so you really set it to zero , the fft ?
D: so it 's it 's weight on the ball spectrum .
B: so that 's that 's little different than dave thought , . still , it 's possible that we 're getting in some more noise . so wonder , is it @ @ was there their experimentation with , , say , throwing away that filter ?
D: throwing away the first ? we 've tried including the full bank . from zero to four . and that 's always worse than using sixty - four hertz .
B: but the question is , whether sixty - four hertz is , , too , , low .
D: make it hundred or so ? 've tried hundred and it was more or less the same , or slightly worse .
B: on what test set ?
D: on the same , , speechdat - car ,
B: it was on the speechdat - car .
D: so tried hundred to four .
B: and on and on the , , ti - digits also ?
D: no , no . tried it on speechdat - car .
B: that 'd be something to look at sometime because what , , , he was looking at was performance in this room . would that be more like you 'd think that 'd be more like speechdat - car , in terms of the noise . the speechdat - car is more , , roughly stationary , lot of it . and and ti - digits maybe is not so much as maybe it 's not big deal . anyway , that was just something we wondered about . certainly lot of the noise , , is , , below hundred hertz . the signal - to - noise ratio , , looks fair amount better if you if you high - pass filter it from this room . but it 's still pretty noisy . even even for hundred hertz up , it 's it 's still fairly noisy . the signal - to - noise ratio is is actually still pretty bad .
A: so that 's on th that 's on the the far field ones though , right ?
B: that 's on the far field . the near field 's pretty good .
A: so wha what is , what 's causing that ?
B: we got video projector in here , and , which we keep on during every session we record , which , , we were aware of but we thought it wasn't bad thing . that 's noise source . and there 's also the , , air conditioning . which , , , is pretty low frequency thing . so , those are those are major components , , for the stationary . maybe said this last week too but it it really became apparent to us that we need to take account of noise . so when he gets done with his prelim study one of the next things we 'd want to do is to take this , , noise , , processing and , , synthesize some speech from it .
A: when are his prelims ?
B: in about , , little less than two weeks . it might even be sooner . let 's see , this is the sixteenth , if he 's before it might even be in week .
A: ed that they were gonna do it some time during the semester
B: week and half .
A: but they 'll do it any time , ?
B: they seem to be the semester actually is starting up .
A: is it already ?
B: the semester 's late august they start here . so they do it right at the beginning of the semester . the overall results seemed to be first place in in the case of either , , artificial reverberation or modest sized training set . either way , , , it helped lot . and but if you had really big training set , recognizer , , system that was capable of taking advantage of really large training set that one thing with the htk is that is has the as we 're using the configuration we 're using is is being bound by the terms of aurora , we have all those parameters just set as they are . so even if we had hundred times as much data , we wouldn't go out to , , ten or or hundred times as many gaussians or anything . it 's hard to take advantage of of big chunks of data . whereas the other one does expand as you have more training data . it does it automatically , actually . that one really benefited from the larger set . and it was also diverse set with different noises and . that , that seemed to be so , if you have that better recognizer that can that can build up more parameters , and if you , , have the natural room , which in this case has pretty bad signal - to - noise ratio , then in that case , , the right thing to do is just do use speaker adaptation . and and not bother with this acoustic , , processing . but that would not be true if we did some explicit noise - processing as as , , the convolutional things we were doing . that 's what we found .
A: , started working on the mississippi state recognizer . so , got in touch with joe and , , from your email and things like that . and , , they added me to the list the mailing list . and he gave me all of the pointers and everything that needed . and so downloaded the , there were two things , , that they had to download . one was the , , the software . and another wad was , , like sample sample run . so downloaded the software and compiled all of that . and it compiled fine . and , , grabbed the sample but haven't , , compiled it .
D: that sample was released only yesterday or the day before , right ?
A: haven't grabbed that one yet . so there 's two .
D: there is another short sample set
A: there was another short one , and so haven't grabbed the latest one that he just , , put out yet . but , the software seemed to compile fine and everything ,
B: is there any word yet about the issues about , , adjustments for different feature sets or anything ?
A: you asked me to write to him and forgot to ask him about that . or if did ask him , he didn't reply . don't remember yet . 'll 'll 'll double check that and ask him again .
B: it 's like that could turn out to be an important issue for us .
D: cuz they have it
A: maybe 'll send it to the list .
D: cuz they have , , already frozen those in insertion penalties and all those is what feel . because they have this document explaining the recognizer . and they have these tables with , , various language model weights , insertion penalties .
A: haven't seen that one yet .
D: it 's th it 's there on that web . and , , on that , , they have run some experiments using various insertion penalties and all those
A: and so they 've picked the values .
D: they picked the values from
B: for what test set ?
D: the one that they have reported is nist evaluation , wall street journal .
B: but that has nothing to do with what we 're testing on , right ?
D: so they 're , like so they are actually trying to , , fix that those values using the clean , , training part of the wall street journal . aurora has clean subset . they want to train it and then this they 're going to run some evaluations .
B: so they 're set they 're setting it based on that ? so now , we may come back to the situation where we may be looking for modification of the features to account for the fact that we can't modify these parameters . but it 's still worth , , just since , just chatting with joe about the issue .
A: do you think that 's something should just send to him or do you should send it to this there 's an mailing list .
B: it 's not secret . we 're , , certainly willing to talk about it with everybody , but that , , it 's probably best to start talking with him just to @ @ , it 's dialogue between two of you about what , what does he think about this and what what could be done about it . if you get ten people in involved in it there 'll be lot of perspectives based on , , how but , , it all should come up eventually , but if if there is any , , way to move in way that would that would , , be more open to different kinds of features . but if , if there isn't , and it 's just shut down and then also there 's probably not worthwhile bringing it into larger forum where political issues will come in .
D: so this is now it 's compiled under solaris ? because he there was some mail saying that it 's may not be stable for linux and all those .
A: that was particular version . susi or whatever it was but we don't have that .
D: that 's fine .
A: it compiled fine actually . no no errors .
B: this is slightly off topic
D: that 's good .
B: noticed , just glancing at the , , hopkins workshop , , web site that , , one of the thing , we 'll see how much they accomplish , but one of the things that they were trying to do in the graphical models thing was to put together , , tool kit for doing , , arbitrary graphical models for , , speech recognition . so and jeff , the two jeffs were
A: who 's the second jeff ?
B: , do geoff zweig ? he , he was here for couple years and he , got his phd . and he 's , , been at ibm for the last couple years .
A: that would be neat .
B: so he did he did his phd on dynamic bayes - nets , for speech recognition . he had some continuity built into the model , presumably to handle some , , inertia in the in the production system ,
C: 've been playing with , first , the , , vad . so it 's exactly the same approach , but the features that the vad neural network use are , , mfcc after noise compensation . have the results .
B: what was it using before ?
C: before it was just
D: it was just the noisy features .
C: this is what we get after this so , actually , we , , here the features are noise compensated and there is also the lda filter . and then it 's pretty small neural network which use , , nine frames of six features from - zero to - fives , plus the first derivatives . and it has one hundred hidden units .
A: is that nine frames , centered around the current frame ? or
B: so , 'm 'm , there 's there 's how many how many inputs ?
C: so it 's twelve times nine .
B: twelve times nine inputs , and hundred , , hidden . so about eleven thousand parameters , which actually shouldn't be problem , even in small phones . .
A: so what is different between this and what you
C: it should be . so the previous syst it 's based on the system that has fifty - three point sixty - six percent improvement . it 's the same system . the only thing that changed is the es the estimation of the silence probabilities . which now is based on , , cleaned features .
B: and , it 's it 's lot better . that 's great .
C: so it 's it 's not bad , but the problem is still that the latency is too large .
B: what 's the latency ?
C: the latency of the vad is two hundred and twenty milliseconds . and , , the vad is used , for on - line normalization , and it 's used before the delta computation . so if you add these components it goes to hundred and seventy ,
B: you started off with two - twenty and you ended up with one - seventy ?
C: with two an two hundred and seventy .
B: two - seventy .
C: if you add the delta comp delta computation which is done afterwards .
B: so it 's two - twenty . the is this are these twenty - millisecond frames ? is that why ? is it after downsampling ?
C: the two - twenty is one hundred milliseconds for the no , it 's forty milliseconds for for the , , cleaning of the speech . then there is , , the neural network which use nine frames . so it adds forty milliseconds . after that , , you have the , filtering of the silence probabilities . which is million filter and it creates one hundred milliseconds delay .
D: plus there is delta at the input .
C: and there is the delta at the input
B: one hundred milliseconds for smoothing .
C: so it 's @ @
D: it 's like forty plus forty plus
C: this forty plus twenty , plus one hundred .
D: so it 's two hundred actually .
C: there are twenty that comes from there is ten that comes from the lda filters also . so it 's two hundred and ten ,
D: if you are using
C: plus the frame ,
D: if you are using three frames
C: so it 's two - twenty .
D: if you are phrasing using three frames , it is thirty here for delta .
C: it 's it 's five frames ,
D: so five frames , that 's twenty . so it 's who un two hundred and ten .
B: it 's forty for the for the cleaning of the speech , forty for the ann , hundred for the smoothing . but at ten ,
C: twenty for the delta .
B: twenty for delta .
D: at th {nonvocalsound} at the input . that 's at the input to the net .
B: delta at input to net ?
D: so it 's like five , six cepstrum plus delta at nine frames of
B: and then ten milliseconds for
D: fi - there 's an lda filter .
B: ten milliseconds for lda filter , and and ten another ten milliseconds you said for the frame ?
C: for the frame . computed two - twenty it 's for the fr the
B: and then there 's delta besides that ?
C: so this is the features that are used by our network and then afterwards , you have to compute the delta on the , , main feature stream , which is , delta and double - deltas , which is fifty milliseconds .
B: no , , the after the noise part , the forty the other hundred and eighty some of this is , is in parallel , isn't it ? you have the lda as part of the - , vad ?
C: the vad use , , lda filtered features also .
B: so in that case there isn't too much in parallel .
C: there is , , just downsampling , upsampling , and the lda .
B: so the delta at the end is how much ?
C: it 's fifty . but , we could probably put the delta , , before on - line normalization . it should not that make big difference ,
A: what if you used smaller window for the delta ? could that help little bit ? there 's lot of things you could do to
B: so if you if you put the delta before the , , ana on - line if then it could go in parallel . and then then you don't have that additive
C: cuz the time constant of the on - line normalization is pretty long compared to the delta window , it should not make
B: and you ought to be able to shove tw , sh pull off twenty milliseconds from somewhere else to get it under two hundred ,
A: is two hundred the
B: mill hundred milliseconds for smoothing is an arbitrary amount . it could be eighty and probably do @ @
A: wh - what 's the baseline you need to be under ?
B: they 're still arguing about it . if it 's two if it 's , if it 's two - fifty , then we could keep the delta where it is if we shaved off twenty . if it 's two hundred , if we shaved off twenty , we could we could , , meet it by moving the delta back .
A: so , how do that what you have is too much if they 're still deciding ?
B: but it 's just the main thing is that since that we got burned last time , and , by not worrying about it very much , we 're just staying conscious of it . and so , th if if week before we have to be done someone says , "" , you have to have fifty milliseconds less than you have now "" , it would be pretty frantic around here .
A: but still , that 's that 's pretty big , , win . and it doesn't seem like you 're in terms of your delay , you 're , , that
B: he added bit on , because before we were had were able to have the noise , , , , and the lva be in parallel . and now he 's he 's requiring it to be done first .
C: but the main thing , maybe , is the cleaning of the speech , which takes forty milliseconds or so .
B: let 's say ten milliseconds seconds for the lda .
C: and but the lda is , , pretty short right now .
B: and then forty for the other .
D: the lda we , is , like is it very crucial for the features , right ?
C: this is the first try . maybe the lda 's not very useful then .
B: so you could start pulling back , you have twenty for delta computation which now you 're doing twice , but yo were you doing that before ?
C: in the proposal , , the input of the vad network were just three frames , .
D: on the in the just the static , no delta .
B: so , what you have now is fort , forty for the noise , twenty for the delta , and ten for the lda . that 's seventy milliseconds of which was formerly in parallel , that 's that 's the difference as far as the timing , and you could experiment with cutting various pieces of these back bit , we 're we 're not we 're not in terrible shape .
A: that 's what it seems like to me . it 's pretty good .
B: it 's it 's not like it 's adding up to four hundred milliseconds .
A: where where is this fifty - seven point two in comparison to the last evaluation ?
B: it 's it 's better than anything , , anybody got .
A: is that right ?
C: the best was fifty - four point five . and our system was forty - nine , but with the neural network .
A: so this is almost ten percent .
B: with the with the neural net .
D: so this is this is like the first proposal . the proposal - one . it was forty - four , actually .
B: and we still don't have the neural net in . so so it 's we 're we 're doing better .
A: this is this is really good .
B: we 're getting better recognition . 'm other people working on this are not sitting still either , the important thing is that we learn how to do this better , so , our , you can see the numbers that we 're having , say , on speechdat - car which is hard task , cuz it 's really , it 's just reasonable numbers , starting to be . it 's still terri
C: even for - matched case it 's sixty percent error rate reduction , so actually , this is in between what we had with the previous vad and what sunil did with an idl vad . which gave sixty - two percent improvement , right ?
D: it 's almost that . it 's almost an average
A: what was that ? say that last part again ?
C: so , if you use , like , an idl vad , , for dropping the frames ,
D: or the best we can get .
C: the best that we can get that means that we estimate the silence probability on the clean version of the utterances . then you can go up to sixty - two percent error rate reduction , globally .
A: so that would be even that wouldn't change this number down here to sixty - two ?
B: so you were get
C: if you add good very good vad , that works as as vad working on clean speech , then you wou you would go
A: so that 's the best you could hope for .
B: so fi si fifty - three is what you were getting with the old vad . and sixty - two with the , , quote , unquote , cheating vad . and fifty - seven is what you got with the real vad . that 's great .
C: , the next thing is , started to play don't want to worry too much about the delay , maybe it 's better to from the committee . but started to play with the , , , tandem neural network . did the configuration that 's very similar to what we did for the february proposal . so . there is first feature stream that use straight mfcc features . these features actually . and the other stream is the output of neural network , using as input , also , these , , cleaned mfcc .
A: those are th those are th what is going into the tandem net ?
C: don't have the comp so there is just this feature stream , the fifteen mfcc plus delta and double - delta . so it 's makes forty - five features that are used as input to the htk . and then , there is there are more inputs that comes from the tandem mlp .
B: he likes to use them both , cuz then it has one part that 's discriminative , one part that 's not .
C: right now it seems that tested on speechdat - car while the experiment are running on your on ti - digits . it improves on the - matched and the mismatched conditions , but it get worse on the highly mismatched .
A: compared to these numbers ?
C: compared to these numbers , . like , on the - match and medium mismatch , the gain is around five percent relative , but it goes down lot more , like fifteen percent on the hm case .
B: you 're just using the full ninety features ? you have ninety features ?
C: from the networks , it 's twenty - eight .
B: and from the other side it 's forty - five .
C: so , it 's forty - five .
B: so it 's you have seventy - three features , and you 're just feeding them like that . there isn't any klt or anything ?
C: there 's klt after the neural network , as before .
A: that 's how you get down to twenty - eight ? why twenty - eight ?
C: it 's it 's because it 's what we did for the first proposal . we tested , , trying to go down
B: it 's multiple of seven .
C: wanted to do something very similar to the proposal as first try .
A: that makes sense .
C: but we have to for , we have to go down , because the limit is now sixty features . we have to find way to decrease the number of features .
A: so , it seems funny that , maybe don't quite understand everything , but that adding features if you 're keeping the back - end fixed . maybe that 's it . because it seems like just adding information shouldn't give worse results . but if you 're keeping the number of gaussians fixed in the recognizer , then
B: but , , just in general , adding information suppose the information you added , , was really terrible feature and all it brought in was noise . or or suppose it wasn't completely terrible , but it was completely equivalent to another one feature that you had , except it was noisier . in that case you wouldn't necessarily expect it to be better .
A: , wasn't necessarily saying it should be better . 'm just surprised that you 're getting fifteen percent relative worse on the wel
C: but it 's worse .
B: on the highly mismatched condition .
A: on the highly mismatch .
B: so , "" highly mismatched condition "" means that your training is bad estimate of your test . so having , , greater number of features , if they aren't maybe the right features that you use , certainly can can easily , , make things worse . you 're right . if you have if you have , , lots and lots of data , and you have and your your training is representative of your test , then getting more sources of information should just help . but but it 's it doesn't necessarily work that way . what 's your what 's your thought about what to do next with it ?
C: because expected the neural net to help more when there is more mismatch , as it was the case for the
D: so , was the training set same as the the february proposal ?
C: it 's the same training set , so it 's timit with the ti - digits ' , , noises , , added .
B: we might , we might have to experiment with , better training sets . the other thing is , , before you found that was the best configuration , but you might have to retest those things now that we have different the rest of it is different , what 's the effect of just putting the neural net on without the other path ? what the straight features do . that gives you this . what it does in combination .
A: what if you did the would it make sense to do the klt on the full set of combined features ? instead of just on the
C: the reason did it this ways is that in february , it we tested different things like that , so , having two klt , having just klt for network , or having global klt .
A: so you tried the global klt before and it didn't really
C: and , , th the differences between these configurations were not huge , but it was marginally better with this configuration .
B: but , , that 's another thing to try , since things are things are different . so all of these seventy - three features are going into , , the , the . and is are are any deltas being computed of tha of them ?
C: of the straight features , . but th the , , tandem features are used as they are . maybe we can add some context from these features also as dan did in his last work .
B: but the other thing was thinking was , now lost track of what was thinking .
A: you said there was limit of sixty features ? what 's the relation between that limit and the , , forty - eight , forty eight hundred bits per second ?
B: was gonna say .
C: not no relation .
A: so don't understand ,
C: the the forty - eight hundred bits is for transmission of some features .
A: if you 're only using
C: and generally , it allows you to transmit like , fifteen , , cepstrum .
B: the issue was that , , this is supposed to be standard that 's then gonna be fed to somebody 's recognizer somewhere which might be , , it might be concern how many parameters are use used and . they felt they wanted to set limit . so they chose sixty . some people wanted to use hundreds of parameters and that bothered some other people . they just chose that . it 's arbitrary too . but but that 's that 's what was chosen . remembered what was going to say . what was going to say is that , , maybe with the noise removal , , these things are now more correlated . so you have two sets of things that are uncorrelated , , within themselves , but they 're pretty correlated with one another . they 're being fed into these , , variants , only gaussians and , so maybe it would be better idea now than it was before to , , have , , one klt over everything , to de - correlate it .
D: what are the rs in the training set , timit ?
C: it 's , , ranging from zero to clean ? from zero to clean .
B: so we found this , this macrophone data , and , that we were using for these other experiments , to be pretty good . so that 's after you explore these other alternatives , that might be another way to start looking , is just improving the training set . we were getting , , lots better recognition using that , than you do have the problem that , , we are not able to increase the number of gaussians , , or anything to , , to match anything . so we 're only improving the training of our feature set , but that 's still probably something .
A: so you 're saying , add the macrophone data to the training of the neural net ? the tandem net ?
B: that 's the only place that we can train . we can't train the other with anything other than the standard amount ,
A: what what was it trained on again ? the one that you used ?
C: it 's timit with noise . so , , it 's rather small
B: how big is the net , ?
C: it 's , , five hundred hidden units .
B: you did experiments back then where you made it bigger and it and that was that was the threshold point . much less than that , it was worse , much more than that , it wasn't much better .
D: so is it is it though the performance , big relation in the high ma high mismatch has something to do with the , , cleaning up that you that is done on the timit after adding noise ? it 's all the noises are from the ti - digits , it 's like the high mismatch of the speechdat - car after cleaning up , maybe having more noise than the training set of timit after clean after you do the noise clean - up . earlier you never had any compensation , you just trained it straight away . so it had like all these different conditions of rs , actually in their training set of neural net . but after cleaning up you have now different set of rs , right ? for the training of the neural net . is it something to do with the mismatch that 's created after the cleaning up , like the high mismatch
C: you mean the most noisy occurrences on speechdat - car might be lot more noisy than
D: the snr after the noise compensation of the speechdat - car .
B: so the training the neural net is being trained with noise compensated . which makes sense , but , , you 're saying , the noisier ones are still going to be , even after our noise compensation , are still gonna be pretty noisy .
D: so now the after - noise compensation the neural net is seeing different set of rs than that was originally there in the training set . of timit . because in the timit it was zero to some clean . so the net saw all the snr @ @ conditions . now after cleaning up it 's different set of snr . and that snr may not be , like , com covering the whole set of rs that you 're getting in the speechdat - car .
B: but the speechdat - car data that you 're seeing is also reduced in noise by the noise compensation .
D: but , 'm saying , there could be some issues of
C: if the initial range of snr is different , we the problem was already there before .
B: , it depends on whether you believe that the noise compensation is equally reducing the noise on the test set and the training set .
D: on the test set , .
B: you 're saying there 's mismatch in noise that wasn't there before , but if they were both the same before , then if they were both reduic reduced equally , then , there would not be mismatch . heaven forbid , this noise compensation process may be imperfect , so maybe it 's treating some things differently .
D: that could be seen from the ti - digits , , testing condition because , , the noises are from the ti - digits , right ? so cleaning up the ti - digits and if the performance goes down in the ti - digits mismatch high mismatch like this
C: clean training , .
D: on clean training , or zero db testing .
C: we 'll so we 'll see .
D: then it 's something to do .
B: one of the things about the macrophone data , , , , it was recorded over many different telephones . so , there 's lots of different kinds of acoustic conditions . it 's not artificially added noise or anything . so it 's not the same . don't think there 's anybody recording over car from car , but it 's it 's varied enough that if doing this adjustments , , and playing around with it doesn't , , make it better , the most , it seems like the most obvious thing to do is to improve the training set . the condition it it gave us an enormous amount of improvement in what we were doing with meeting recorder digits , even though there , again , these macrophone digits were very , very different from , , what we were going on here . we weren't talking over telephone here . but it was just just having variation in acoustic conditions was just good thing .
C: actually to , what observed in the hm case is that the number of deletion dramatically increases . it it doubles .
B: number of deletions .
C: when added the num the neural network it doubles the number of deletions . so don't how to interpret that ,
A: and and did an other numbers stay the same ? insertion substitutions stay the same ?
C: they stayed the same , they maybe they are little bit , lower . they are little bit better .
B: did they increase the number of deletions even for the cases that got better ? say , for the , it
C: no , it doesn't .
B: so it 's only the highly mismatched ? and it remind me again , the "" highly mismatched "" means that the
C: it 's clean training close microphone training and distant microphone , , high speed , . the most noisy cases are the distant microphone for testing .
B: maybe the noise subtraction is subtracting off speech .
C: but without the neural network it 's , it 's better . it 's just when we add the neural networks . the feature are the same except that
B: that 's right .
A: that says that , , the , the models in , , the recognizer are really paying attention to the neural net features .
B: actually {nonvocalsound} the timit noises are range of noises and they 're not so much the stationary driving noises , right ? it 's it 's pretty different .
C: there is car noise . so there are just four noises . "" car "" , , "" babble "" ,
D: "" babble . ""
C: "" subway "" , right ?
D: "" street "" or "" airport "" .
C: and "" street "" isn't
D: or "" train station "" .
C: "" train station "" , . so it 's mostly , "" car "" is stationary , "" babble "" , it 's stationary background plus some voices , some speech over it . and the other two are rather stationary also .
B: that if you run it actually , you maybe you remember this . when you in the old experiments when you ran with the neural net only , and didn't have this side path , , , with the pure features as , did it make things better to have the neural net ? was it about the same ?
C: it was little bit worse . than just the features ,
B: until you put the second path in with the pure features , the neural net wasn't helping . that 's interesting .
C: it was helping , , if the features are were bad , just plain ps or as soon as we added lda on - line normalization , and all these things , then
B: they were doing similar enough things . still would be interesting to see what would happen if you just had the neural net without the side thing . and and the thing have in mind is , , maybe you 'll see that the results are not just little bit worse . maybe that they 're lot worse . but if on the ha other hand , , it 's , say , somewhere in between what you 're seeing now and and , , what you 'd have with just the pure features , then maybe there is some problem of of , , combination of these things , or correlation between them somehow . if it really is that the net is hurting you at the moment , then the issue is to focus on , , improving the net . so what 's the overall effe you haven't done all the experiments but you said it was somewhat better , say , five percent better , for the first two conditions , and fifteen percent worse for the other one ? but it 's but that one 's weighted lower , so wonder what the net effect is .
C: it 's it was one or two percent . that 's not that bad , but it was like two percent relative worse on speechdat - car . have to check that .
D: it will overall it will be still better even if it is fifteen percent worse , because the fifteen percent worse is given like twenty - five point two five eight .
B: so the so the worst it could be , if the others were exactly the same , is four , and , , since the others are somewhat better
D: so it 's four . so either it 'll get cancelled out , or you 'll get , like , almost the same .
C: it was it was slightly worse .
B: it should be pretty close to cancelled out .
A: 've been wondering about something . in the , lot of the , the hub - five systems , , recently have been using lda . and they , they run lda on the features right before they train the models . so there 's the lda is right there before the so , you guys are using lda but it seems like it 's pretty far back in the process .
D: this lda is different from the lda that you are talking about . the lda that you saying is , like , you take block of features , like nine frames , and then do an lda on it , and then reduce the dimensionality to something like twenty - four like that .
A: you you can .
D: and then feed it to .
A: it 's , you 're just
D: so this is like two two dimensional tile .
A: you 're shifting the feature space .
D: so this is two dimensional tile . and the lda that we are applying is only in time , high cost frequency . so it 's like more like filtering in time ,
A: so what what about , what if this is good idea or not , but what if you put ran the other lda , , on your features right before they go into the ?
C: no , actually , what do we do with the ann is something like that except that it 's not linear . but it 's it 's like nonlinear discriminant analysis .
A: it 's the it 's so it 's like the tandem is like nonlinear lda . but , but the other features that you have , , th the non - tandem ones ,
C: in the proposal , they were transformed using pca , it might be that lda could be better .
B: the the argument is in and it 's not like we really know , but the argument anyway is that , , , we always have the prob discriminative things are good . lda , neural nets , they 're good . they 're good because you you learn to distinguish between these categories that you want to be good at distinguishing between . and pca doesn't do that . it pac - pca low - order pca throws away pieces that are , maybe not gonna be helpful just because they 're small , . but , , the problem is , training sets aren't perfect and testing sets are different . so you you face the potential problem with discriminative , be it lda or neural nets , that you are training to discriminate between categories in one space but what you 're really gonna be getting is something else . and so , , stephane 's idea was , , let 's feed , , both this discriminatively trained thing and something that 's not . so you have good set of features that everybody 's worked really hard to make , and then , , you discriminately train it , but you also take the path that doesn't have that , and putting those in together . so it 's like combination of the , what , , dan has been calling , , feature , , feature combination versus posterior combination . it 's it 's , , you have the posterior combination but then you get the features from that and use them as feature combination with these other things . and that seemed , at least in the last one , as he was just saying , he when he only did discriminative , it actually was it didn't help in this particular case . there was enough of difference , , between the testing and training . but by having them both there the fact is some of the time , the discriminative is gonna help you . and some of the time it 's going to hurt you , and by combining two information sources if , if
A: so you wouldn't necessarily then want to do lda on the non - tandem features because now you 're doing something to them that
B: that 's counter to that idea . now , again , it 's we 're just trying these different things . we don't really 's gonna work best . but if that 's the hypothesis , at least it would be counter to that hypothesis to do that . and in principle you would think that the neural net would do better at the discriminant part than lda . though , maybe not .
A: we , we were getting ready to do the tandem , , for the hub - five system , and , , andreas and talked about it , and the idea the thought was , "" , , , that th the neural net should be better , but we should at least have , number , , to show that we did try the lda in place of the neural net , so that we can , show clear path . that you have it without it , then you have the lda , then you have the neural net , and you can see , theoretically .
B: that 's good idea . did did you do that or tha that 's
A: that 's what that 's what we 're gonna do next as soon as finish this other thing .
B: no , , that 's good idea .
A: we just want to show . it everybody believes it , but , we just
B: no , no , but it might not even be true . it 's it 's it 's great idea . one of the things that always disturbed me , , in the resurgence of neural nets that happened in the eighties was that , , lot of people because neural nets were pretty easy to use lot of people were just using them for all sorts of things without , , looking into the linear , , versions of them . and , , people were doing recurrent nets but not looking at iir filters , and , , , so , , it 's definitely good idea to try it .
A: and everybody 's putting that on their systems now , that 's what made me wonder about this ,
B: they 've been putting them in their systems off and on for ten years , but but , ,
A: what is it 's it 's like in the hub - five evaluations , , and you read the system descriptions and everybody 's got , , lda on their features .
B: and now they all have that .
C: it 's the transformation they 're estimating on they are trained on the same data as the final are .
A: so it 's different . cuz they don't have these , , mismatches that you guys have . so that 's why was wondering if maybe it 's not even good idea . enough about it ,
B: part of why you were getting into the klt you were describing to me at one point that you wanted to see if , , , getting good orthogonal features was and combining the different temporal ranges was the key thing that was happening or whether it was this discriminant thing , right ? so you were just trying this is it doesn't have the lda aspect but th as far as the orthogonalizing transformation , you were trying that at one point , right ? it doesn't work as .
D: 've been exploring parallel vad without neural network with , like , less latency using snr and energy , , after the cleaning up . so what 'd been trying was , , after the after the noise compensation , was trying to find feature based on the ratio of the energies , that is , cl after clean and before clean . so that if they are , like , pretty close to one , which means it 's speech . and if it is if it is close to zero , which is so it 's like scale @ @ probability value . so was trying , , with full band and multiple bands , ps separating them to different frequency bands and deriving separate decisions on each bands , and trying to combine them . the advantage being like it doesn't have the latency of the neural net if it if it can and it gave me like , , one point one more than one percent relative improvement . so , from fifty - three point six it went to fifty four point eight . so it 's , like , only slightly more than percent improvement , which means that it 's it 's doing slightly better job than the previous vad , at lower delay .
B: does it still have the median filter ?
D: it still has the median filter .
B: so it still has most of the delay ,
D: so with the delay , that 's gone is the input , which is the sixty millisecond . the forty plus twenty . at the input of the neural net you have this , , nine frames of context plus the delta .
B: plus the delta ,
D: so that delay , plus the lda . so the delay is only the forty millisecond of the noise cleaning , plus the hundred millisecond smoothing at the output . so the di the biggest the problem for me was to find consistent threshold that works across the different databases , because try to make it work on tr speechdat - car and it fails on ti - digits , or if try to make it work on that it 's just the italian , it doesn't work on the finnish . so there are there was , like , some problem in balancing the deletions and insertions when try different thresholds . 'm still trying to make it better by using some other features from the after the clean up maybe , some , , correlation auto - correlation or some additional features of to mainly the improvement of the vad . 've been trying .
B: now this this , , "" before and after clean "" , it sounds like you think that 's good feature . that that , it you th think that the , the it appears to be good feature , right ? what about using it in the neural net ?
C: eventually we could just
D: so that 's the so we 've been thinking about putting it into the neural net also . because they did that itself
C: then you don't have to worry about the thresholds and
D: so that 's ,
B: so if we if we can live with the latency or cut the latencies elsewhere , then that would be , , good thing . anybody has anybody you guys or naren , , somebody , tried the , , , second th second stream thing ?
D: put the second stream in place and , ran one experiment , but just like just to know that everything is fine . so it was like , , forty - five cepstrum plus twenty - three mel log mel . and and , just , like , it gave me the baseline performance of the aurora , which is like zero improvement . so tried it on italian just to know that everything is but didn't export anything out of it because it was , like , weird feature set .
B: what , , would be more what you 'd want to do is is , , put it into another neural net . we 're we 're not quite there yet . so we have to figure out the neural nets , .
D: the , other thing was wondering was , , if the neural net , , has any because of the different noise con unseen noise conditions for the neural net , where , like , you train it on those four noise conditions , while you are feeding it with , like , additional some four plus some few more conditions which it hasn't seen , actually , from the while testing . instead of just having , those cleaned up cepstrum , sh should we feed some additional information , like the the we have the vad flag . should we feed the vad flag , also , at the input so that it has some additional discriminating information at the input ?
B: wh - , the vad what ?
D: we have the vad information also available at the back - end . so if it is something the neural net is not able to discriminate the classes because most of it is sil we have dropped some silence we have dropped so silence frames ? no , we haven't dropped silence frames still . the biggest classification would be the speech and silence . so , by having an additional , , feature which says "" this is speech and this is nonspeech "" , , it certainly helps in some unseen noise conditions for the neural net .
A: do do you have that feature available for the test data ?
D: , we have we are transferring the vad to the back - end feature to the back - end . because we are dropping it at the back - end after everything all the features are computed . so that is coming from separate neural net or some vad . which is which is certainly giving
A: so you 're saying , feed that , also , into the neural net .
D: so it 's an additional discriminating information .
B: you could feed it into the neural net . the other thing you could do is just , , modify the , , output probabilities of the of the , , , neural net , tandem neural net , based on the fact that you have silence probability . so you have an independent estimator of what the silence probability is , and you could multiply the two things , and renormalize . , you 'd have to do the nonlinearity part and deal with that . , go backwards from what the nonlinearity would , would be .
D: through to the soft max .
C: maybe , , when
A: but in principle wouldn't it be better to feed it in ? and let the net do that ?
B: let 's put it this way . you have this complicated system with thousands and thousand parameters and you can tell it , , "" learn this thing . "" or you can say , "" it 's silence ! go away ! "" the second one sounds lot more direct .
A: so , what if you then , since this , what if you only use the neural net on the speech portions ? that 's the same . that 's similar .
B: you 'd have to actually run it continuously ,
A: but , train the net only on
B: but it 's @ @ you want to train on the nonspeech also , because that 's part of what you 're learning in it , to to generate , that it 's it has to distinguish between .
A: but , if you 're gonna if you 're going to multiply the output of the net by this other decision , , would then you don't care about whether the net makes that distinction , right ?
B: but this other thing isn't perfect . so that you bring in some information from the net itself .
A: that 's good point .
B: now the only thing that bothers me about all this is that the the fact it 's bothersome that you 're getting more deletions .
C: so might maybe look at , is it due to the fact that , the probability of the silence at the output of the network , is ,
B: is too high .
C: if it 's the case , then multiplying it again by by something ?
D: it may not be it it may be too it 's too high in sense , like , everything is more like , , flat probability .
C: - eee - hhh .
D: so , like , it 's not really doing any distinction between speech and nonspeech or , , different among classes .
A: be interesting to look at the wonder if you could do this . but if you look at the , , highly mism high mismat the output of the net on the high mismatch case and just look at , , the distribution versus the other ones , do you do you see more peaks ?
C: like the entropy of the output , it it seems that the vad network doesn't , it doesn't drop , , too many frames because the dele the number of deletion is reasonable . but it 's just when we add the tandem , the final mlp , and then
B: now the only problem is you don't want to ta for the output of the vad before you can put something into the other system , cuz that 'll shoot up the latency lot , am missing something here ? so that 's maybe problem with what was just saying .
A: but if you were gonna put it in as feature it means you already have it by the time you get to the tandem net ,
D: we we don't have it , actually , because it 's it has high rate energy
B: it 's done in some of the things are , not in parallel , but certainly , it would be in parallel with the with tandem net . so maybe , if that doesn't work , but it would be interesting to see if that was the problem , anyway . and and then another alternative would be to take the feature that you 're feeding into the vad , and feeding it into the other one as . and then maybe it would just learn it better . that 's an interesting thing to try to see , if what 's going on is that in the highly mismatched condition , it 's , , causing deletions by having this silence probability up too high , at some point where the vad is saying it 's actually speech . which is probably true . if the vad said since the vad is is right lot , we just started working with it . but these are these are some good ideas .
C: and the other thing there are other issues maybe for the tandem , like , , , do we want to , do we want to work on the targets ? or , like , instead of using phonemes , using more context dependent units ?
A: for the tandem net you mean ?
C: 'm thinking , also , about dan 's work where he trained network , not on phoneme targets but on the state targets . it was giving slightly better results .
B: problem is , if you are going to run this on different test sets , including large vocabulary ,
C: was just thinking maybe about , like , generalized diphones , and come up with reasonable , not too large , set of context dependent units , and then anyway we would have to reduce this with the klt .
B: but it it 's all worth looking at , but it sounds to me like , , looking at the relationship between this and the speech noise is is probably key thing . that and the correlation between .
A: if the , , high mismatch case had been more like the , , the other two cases in terms of giving you just better performance , how would this number have changed ?
C: around five percent better , .
B: we what 's it 's gonna be the ti - digits yet . he hasn't got the results back yet .
C: if you extrapolate the speechdat - car - matched and medium - mismatch , it 's around , , maybe five .
A: so this would be sixty - two ?
B: sixty - two .
C: sixty - two ,
D: somewhere around sixty , must be .
C: it 's around five percent , because it 's if everything is five percent .
A: all the other ones were five percent ,
C: have the speechdat - car right now , it shou we should have the results today during the afternoon ,
B: so won't be here for
A: when do you leave ?
B: 'm leaving next wednesday . may or may not be in the morning . leave in the afternoon .
A: you 're not gonna be around this afternoon ?
B: 'm talking about next week . 'm leaving next wednesday . for the meeting meeting ? that 's just cuz of something on campus . so next week won't , and the week after won't , cuz 'll be in finland . and the week after that won't . by that time you 'll be , you 'll both be gone from here . so there 'll be no definitely no meeting on september sixth .
A: what 's september sixth ?
B: that 's during eurospeech . so , , sunil will be in oregon . stephane and will be in denmark . so it 'll be few weeks , really , before we have meeting of the same cast of characters . you guys should probably meet . and maybe barry will be around . and then , we 'll start up again with dave and dave and barry and stephane and us on the , , twentieth .
A: you 're gonna be gone for the next three weeks ?
B: 'm gone for two and half weeks starting next wed - late next wednesday .
A: so that 's you won't be at the next three of these meetings . is that right ?
B: it 's probably four because of is it three ? let 's see , twenty - third , that 's right , and the third one won't probably won't be meeting , cuz , , su - sunil , stephane , and will all not be here . mmm . so it 's just , , the next two where there will be there , , may as be meetings , but won't be at them . and then starting up on the thirteenth , {nonvocalsound} , we 'll have meetings again but we 'll have to do without sunil here somehow .
A: when do you go back ?
D: thirty - first , august .
A: when is the evaluation ?
B: it was supposed to be november fifteenth . has anybody heard anything different ?
C: the meeting in is the five and six of december .
D: it 's like , it 's tentatively all full . that 's proposed date , .
C: so the evaluation should be on week before
B: but , no , this is good progress .
A: should we do digits ?
B: we 're done . it 's wrap .
","ICSI's Meeting Recorder Group at Berkeley meets to discuss , for the most part , progress on the Aurora Project.
The main areas being worked on were the voice activity detector and the tandem data streams.
The group discussed possible further investigations that arose from these areas , including better linking the two.
They also consider how aspects of an absent member's work might be applied to the current project.
The meeting closed with a discussion of upcoming absences , and how meetings would continue.
Speaker me018 must confirm what is needed to work with the new software in terms of adjustments with someone further up the project chain.
The system at it's current stage employs the neural networks and second stream , but the group leader would like the network investigated separately , incase it is hurting performance.
There are worries regarding the need to make adjustments so the new software can handle the group's different feature set.
The system , whilst improved , also has increased latency , and while the limit has not been set , the group need to reduce it.
Likewise the number of features the use in their system , since this has been set at an arbitrarily low value.
There has been an increase in the number of deletion in the errors , which is of some concern.
Speaker mn007 has been implementing a new voice activity detector on noise compensated data , and it performs much better.
He has also been working on the tandem neural network.
Speaker me013 , along with a student , submitted work on reverberation for a speech workshop.
Speaker me018 has downloaded and compiled the software he was asked to work with in the previous meeting.
"
ami_abstractive_summary,Bdb001.txt,"C: we had long discussion about how much how easy we want to make it for people to bleep things out . morgan wants to make it hard . did did it ? didn't even check yesterday whether it was moving .
D: it didn't move yesterday either when started it . so if it doesn't like both of us discovered something yesterday on these , , wireless ones . you can tell if it 's picking up breath noise and .
C: it has little indicator on it on the af .
D: if you breathe under breathe and then you see af go off , then it 's picking up your mouth noise .
F: that 's good . cuz we have lot of breath noises . if you listen to just the channels of people not talking , it 's like "" @ @ "" . it 's very disgust
C: did you see hannibal recently ?
F: it 's very disconcerting . was gonna try to get out of here , like , in half an hour , cuz really appreciate people coming , and the main thing that was gonna ask people to help with today is to give input on what kinds of database format we should use in starting to link up things like word transcripts and annotations of word transcripts , so anything that transcribers or discourse coders or whatever put in the signal , with time - marks for , like , words and phone boundaries and all the we get out of the forced alignments and the recognizer . so , we have this , starting point is clearly the channelized output of dave gelbart 's program , which don brought copy of ,
C: 'm 'm familiar with that . we already have developed an xml format for this .
D: can see it ?
C: and so the only question is it the thing that you want to use or not ? have you looked at that ? had web page up .
F: actually mostly need to be able to link up , or it 's it 's question both of what the representation is and
C: you mean , this am gonna be standing up and drawing on the board .
F: so you should , definitely .
C: so it definitely had that as concept . so tha it has single time - line , and then you can have lots of different sections , each of which have ds attached to it , and then you can refer from other sections to those ds , if you want to . so that you start with time - line tag . "" time - line "" . and then you have bunch of times . don't don't remember exactly what my notation was ,
A: remember seeing an example of this .
C: "" equals one point three two "" , and then also had optional things like accuracy , and then "" id equals one , , one seven "" . and then , {nonvocalsound} also wanted to be to be able to not specify specifically what the time was and just have stamp . so these are arbitrary , assigned by program , not by user . so you have whole bunch of those . and then somewhere la further down you might have something like an utterance tag which has "" start equals - seventeen , end equals - eighteen "" . so what that 's saying is , we starts at this particular time . we when it ends . but it ends at this - eighteen , which may be somewhere else . we say there 's another utterance . we what the time actually is but we know that it 's the same time as this end time . thirty - eight , whatever you want .
A: so you 're essentially defining lattice .
C: and then , and then these also have ds . so you could you could have some other tag later in the file that would be something like , , , , , {nonvocalsound} "" noise - type equals {nonvocalsound} door - slam "" . and then , , {nonvocalsound} you could either say "" time equals particular time - mark "" or you could do other sorts of references . so or you might have prosody right ? ? ?
F: it 's an instead of an , but the is good .
C: you like the ? that 's good . so you could have some type here , and then you could have , the utterance that it 's referring to could be - seventeen like that .
F: that seems that seems great for all of the encoding of things with time my question is more , , what what do you do with , say , forced alignment ? you 've got all these phone labels , and what do you do if you just conceptually , if you get , , transcriptions where the words are staying but the time boundaries are changing , cuz you 've got new recognition output , or what 's the , , sequence of going from the waveforms that stay the same , the transcripts that may or may not change , and then the utterance which where the time boundaries that may or may not change ?
A: that 's actually very nicely handled here because you could all you 'd have to change is the , , time - stamps in the time - line without , , changing the ds .
F: and you 'd be able to propagate all of the information ?
C: that 's , the who that 's why you do that extra level of indirection . so that you can just change the time - line .
A: except the time - line is gonna be huge . suppose you have phone - level alignment .
F: especially at the phone - level .
A: you 'd have you 'd have
F: the we have phone - level backtraces .
C: don't would do this for phone - level . for phone - level you want to use some binary representation because it 'll be too dense otherwise .
F: so , if you were doing that and you had this companion , , thing that gets called up for phone - level , , what would that look like ?
C: would use just an existing an existing way of doing it .
F: how would you ?
A: but but why not use it for phone - level ? it 's just matter of it 's just matter of it being bigger . but if you have barring memory limitations , or this is still the
C: it 's parsing limitations . don't want to have this text file that you have to read in the whole thing to do something very simple for .
A: you would use it only for purposes where you actually want the phone - level information , 'd imagine .
F: so you could have some file that configures how much information you want in your in your xml .
C: am imagining you 'd have multiple versions of this depending on the information that you want .
F: cuz th it does get very bush with
C: what 'm wondering is whether for word - level , this would be . for word - level , it 's alright . for lower than word - level , you 're talking about so much data that .
F: so , one thing that don is doing , is we 're we 're running for every frame , you get pitch value ,
D: lattices are big , too .
F: and not only one pitch value but different kinds of pitch values
C: , like that would use - file or any frame - level would use - file . that 's , like it . it 's ics , icsi has format for frame - level representation of features .
F: that you could call that you would tie into this representation with like an id .
C: or or there 's there 's particular way in xml to refer to external resources . so you would say "" refer to this external file "" . so that external file wouldn't be in
F: so that might that might work .
D: but what 's the advantage of doing that versus just putting it into this format ?
C: which is better . if you did it at this
F: these are long meetings and with for every frame ,
C: you don't want to do it with that anything at frame - level you had better encode binary or it 's gonna be really painful .
A: or you just compre like text formats . you can always , , - zip them , and , , , decompress them on the fly if if space is really concern .
D: was thinking the advantage is that we can share this with other people .
C: but if you 're talking about one per frame , you 're talking about gigabyte - size files . you 're gonna actually run out of space in your filesystem for one file .
F: these are big files .
C: because you have two - gigabyte limit on most ss .
A: so frame - level is probably not good idea . but for phone - level it 's perfectly
F: and th it 's
A: like phones , or syllables , or anything like that .
F: phones are every five frames though ,
A: but but most of the frames are actually not speech . look at it , words times the average the average number of phones in an english word is , , five maybe ? so , look at it , number of words times five . that 's not that not
F: so you mean pause phones take up lot of the long pause phones . that 's true . but you do have to keep them in there .
C: so it 's debatable whether you want to do phone - level in the same thing . but , anything at frame - level , even - file , is too verbose . would use something tighter than - files .
F: do you are you familiar with it ? haven't seen this particular format ,
A: 've 've used them . what their structure is . 've forgot what the str
D: but , minute , - file for each frame is storing vector of cepstral or plp values ,
C: it 's whatever you want , actually . so that what 's about the - file it built into it is the concept of frames , utterances , sentences , that thing , that structure . and then also attached to it is an arbitrary vector of values . and it can take different types . so it th they don't all have to be floats . you can have integers and you can have doubles , and all that .
F: so that sounds that sounds about what
C: and it has header it has header format that describes it to some extent . the only problem with it is it 's actually storing the utterance numbers and the frame numbers in the file , even though they 're always sequential . and so it does waste lot of space . but it 's still lot tighter than ascii . and we have lot of tools already to deal with it .
F: is there some documentation on this somewhere ?
C: there 's ton of it . man - pages and , , source code , and me .
F: that sounds good . 'm not database person , but something standard enough that , , if we start using this we can give it out , other people can work on it ,
C: it 's not standard .
F: or is it ?
C: it 's something that we developed at icsi .
F: but it 's been used here
C: but it 's been used here and , , we have - configured system that you can distribute for free ,
D: it must be the equivalent of whatever you guys used to store feat your computed features in , right ?
A: actually , we use generalization of the sphere format . so there is something like that but it 's , , probably not as sophist
C: what does do for features ? or does it even have concept of features ?
A: they ha it has its own entropic has their own feature format that 's called , like , - sd or some so sf like that .
C: 'm just wondering , would it be worth while to use that instead ?
F: th - this is exactly the decision it 's just whatever
D: but , , people don't typically share this , right ?
C: they generate their own .
F: actually , , we 've done this on prosodics and three or four places have asked for those prosodic files , and we just have an ascii , , output of frame - by - frame . which is fine , but it gets unwieldy to go in and query these files with really huge files . we could do it . was just thinking if there 's something that where all the frame values are
C: and , if you have if you have two - hour - long meeting , that 's gonna
F: they 're they 're fair they 're quite large .
C: , they 'd be emo enormous .
F: and these are for ten - minute switchboard conversations , so it 's doable , it 's just that you can only store feature vector at frame - by - frame and it doesn't have any ,
D: is is the sharing part of this pretty important consideration or does that just , thing to have ?
F: enough about what we 're gonna do with the data . but it would be good to get something that we can that other people can use or adopt for their own kinds of encoding . and just , we have to use some we have to make some decision about what to do . and especially for the prosody work , what it ends up being is you get features from the signal , and those change every time your alignments change . so you re - run recognizer , you want to recompute your features , , and then keep the database up to date . or you change word , or you change utterance boundary segment , which is gonna happen lot . and so wanted something where all of this can be done in elegant way and that if somebody wants to try something or compute something else , that it can be done flexibly . it doesn't have to be pretty , it just has to be , , easy to use , and
C: we should look at atlas , the nist thing , and see if they have anything at that level . 'm not what to do about this with atlas , because they chose different route . th - there are two choices . your your file format can know about know that you 're talking about language and speech , which is what chose , and time , or your file format can just be graph representation . and then the application has to impose the structure on top . so what it looked like atlas chose is , they chose the other way , which was their file format is just nodes and links , and you have to interpret what they mean yourself .
F: and why did you not choose that type of approach ?
C: because knew that we were doing speech , and it was better if you 're looking at raw file to be for the tags to say "" it 's an utterance "" , as opposed to the tag to say "" it 's link "" .
F: but other than that , are they compatible ?
C: they 're reasonably compatible .
D: you could probably translate between them .
C: the other thing is if we choose to use atlas , which maybe we should just do , we should just throw this out before we invest lot of time in it .
F: so this is what the meeting 's about , cuz we need to come up with database like this just to do our work . and actually don't care , as long as it 's something useful to other people , what we choose . so maybe it 's maybe oth , if you have any idea of how to choose , cuz don't .
A: do they already have tools ?
C: chose this for couple reasons . one of them is that it 's easy to parse . you don't need full xml parser . it 's very easy to just write perl script to parse it .
A: as long as each tag is on one line .
C: which always do .
F: and you can have as much information in the tag as you want ,
C: have it structured . so each type tag has only particular items that it can take .
F: can you but you can add to those structures if you
C: if you have more information . so what what nist would say is that instead of doing this , you would say something like "" link {nonvocalsound} start equals , , , some node id , end equals some other node id "" , and then "" type "" would be "" utterance "" . so it 's very similar .
F: so why would it be waste to do it this way if it 's similar enough that we can always translate it ?
D: it probably wouldn't be waste . it would mean that at some point if we wanted to switch , we 'd just have to translate everything .
C: since they are developing big
F: but it but that sounds
D: don't think that 's big deal .
F: as long as it is
C: they 're developing big infrastructure . and so it seems to me that if we want to use that , we might as go directly to what they 're doing , rather than
A: if we want to do they already have something that 's that would be useful for us in place ?
D: see , that 's the question . how stable is their are they ready to go ,
C: the looked at it the last time looked at it was while ago , probably year ago , when we first started talking about this . and at that time at least it was still not very complete . and so , specifically they didn't have any external format representation at that time . they just had the conceptual node , annotated transcription graph , which really liked . and that 's exactly what this is based on . since then , they 've developed their own external file format , which is , , , this this thing . and they 've also developed lot of tools , but haven't looked at them .
A: we should we should find out .
F: would the tools would the tools run on something like this , if you can translate them anyway ?
C: th what would what would worry me is that maybe we might miss little detail
F: that it 's question that
C: that would make it very difficult to translate from one to the other .
A: if it 's conceptually close , and they already have or will have tools that everybody else will be using , , it would be crazy to do something , separate that
C: we might as . so 'll 'll take closer look at it .
F: that would really be the question , is just what you would feel is in the long run the best thing . cuz once we start , , doing this don't we don't actually have enough time to probably have to rehash it out again
C: the other thing the other way that established this was as easy translation to and from the transcriber format .
F: this is intuitively easy to actually read , as easy it could as it could be . suppose that as long as they have type here that specifies "" utt "" ,
C: it 's almost the same .
F: it 's , close enough that
C: the with this , though , is that you can't really add any supplementary information . so if you suddenly decide that you want
F: you have to make different type .
C: you 'd have to make different type .
F: if you look at it in my mind enough jane would know better , about the types of annotations and but imagine that those are things that would , you guys mentioned this , that could span any it could be in its own channel , it could span time boundaries of any type , it could be instantaneous , things like that . and then from the recognition side we have backtraces at the phone - level . if if it can handle that , it could handle states or whatever . and then at the prosody - level we have frame like cepstral feature files , like these - files or anything like that . and that 's the world of things that and then we have the aligned channels , ,
A: it seems to me you want to keep the frame - level separate .
F: and wanted to find actually nicer format or maybe more compact format than what we used before . just cuz you 've got ten channels or whatever and two hours of meeting . it 's it 's lot of
A: now now how would you how would you represent , , multiple speakers in this framework ? were you would just represent them as you would have like speaker tag ?
C: there 's spea speaker tag up at the top which identifies them and then each utt the way had it is each turn or each utterance , don't even remember now , had speaker id tag attached to it . and in this format you would have different tag , which would , , be linked to the link . so so somewhere else you would have another thing that would be , let 's see , would it be node or link ? and so this one would have , , an id is link seventy - four like that . and then somewhere up here you would have link that , , , was referencing - seventy - four and had speaker adam .
F: actually , it 's the channel , , that
A: channel or speaker or whatever .
F: channel is what the channelized output out
C: this isn't quite right . have to look at it again .
A: but but so how in the nist format do we express hierarchical relationship between , , say , an utterance and the words within it ? so how do you tell that these are the words that belong to that utterance ?
C: you would have another structure lower down than this that would be saying they 're all belonging to this id .
D: so each thing refers to the utterance that it belongs to .
C: and then each utterance could refer to turn ,
D: so it 's it 's not hi it 's bottom - up .
C: and each turn could refer to something higher up .
F: and what if you actually have so right now what you have as utterance , , the closest thing that comes out of the channelized is the between the segment boundaries that the transcribers put in or that thilo put in , which may or may not actually be , like , it 's usually not , the beginning and end of sentence , say .
C: that 's why didn't call it "" sentence "" .
F: so it 's like segment . assume this is possible , that if you have someone annotates the punctuation or whatever when they transcribe , you can say , , from for from the beginning of the sentence to the end of the sentence , from the annotations , this is unit , even though it never actually it 's only unit by virtue of the annotations at the word - level .
C: so you would you would have yet another tag .
F: and then that would get tag somehow .
C: you 'd have another tag which says this is of type "" sentence "" .
F: but it 's just not overtly in the cuz this is exactly the that should be possible as long as the but , , what don't understand is where the where in this type of file that would be expressed .
C: you would have another tag somewhere . it 's , there 're two ways of doing it .
F: so it would just be floating before the sentence or floating after the sentence without time - mark .
C: you could have some link type type equals "" sentence "" , and id is "" - whatever "" . and then lower down you could have an utterance . so the type is "" utterance "" equals "" utt "" . and you could either say that
A: so here 's the thing .
C: take that back . can you can you say that this is part of this ,
F: see , cuz it 's
D: you would just have
C: or do you say this is part of this ?
D: you would refer up to the sentence .
F: they 're actually overlapping each other , .
A: that some something may be part of one thing for one purpose and another thing of another purpose .
F: you have to have another type then , .
A: let 's let 's ta so let 's
C: 'm had better look at it again
A: so @ @ sup
C: there 's one level there 's one more level of indirection that 'm forgetting .
A: suppose you have word sequence and you have two different segmentations of that same word sequence . say , one segmentation is in terms of , , , , sentences . and another segmentation is in terms of , , , prosodic phrases . and let 's say that they don't nest . so , , prosodic phrase may cross two sentences . if that 's true or not but let 's as
F: it 's definitely true with the segment . that 's what exactly what by the utterances versus the sentence could be
A: so , you want to be you want to say this word is part of that sentence and this prosodic phrase . but the phrase is not part of the sentence and neither is the sentence part of the phrase .
C: 'm pretty that you can do that , but 'm forgetting the exact level of nesting .
A: so , you would have to have two different pointers from the word up one level up , one to the sent
C: so so what you would end up having is tag saying "" here 's word , and it starts here and it ends here "" . and then lower down you would say "" here 's prosodic boundary and it has these words in it "" . and lower down you 'd have "" here 's sentence ,
F: an - right .
C: and it has these words in it "" .
F: so you would be able to go in and say , , "" give me all the words in the bound in the prosodic phrase and give me all the words in the ""
C: so that 's that would wor let me look at it again .
A: the the the other issue that you had was , how do you actually efficiently extract , find and extract information in structure of this type ?
F: that 's good .
A: so you gave some examples like
F: and , , you guys might if this is premature because suppose once you get the representation you can do this , but the kinds of things was worried about is ,
A: no , that 's not clear . , you you can do it , but can you do it , it
F: 't do it ,
A: you gotta you gotta do this you 're gonna want to do this very quickly or else you 'll spend all your time searching through very complex data structures
F: you 'd need paradigm for how to do it . but an example would be "" find all the cases in which adam started to talk while andreas was talking and his pitch was rising , andreas 's pitch "" .
C: that 's gonna be is the rising pitch feature , or is it gonna be in the same file ?
F: the rising pitch will never be hand - annotated . so the all the prosodic features are going to be automatically
C: that 's gonna be hard regardless ,
F: so they 're gonna be in those
C: because you 're gonna have to write program that goes through your feature file and looks for rising pitches .
F: so normally what we would do is we would say "" what do we wanna assign rising pitch to ? "" are we gonna assign it to words ? are we gonna just assign it to when it 's rising we have begin - end rise representation ? but suppose we dump out this file and we say , , for every word we just classify it as , , rise or fall or neither ?
C: in that case you would add that to this format
F: so we would be , , taking the format and enriching it with things that we wanna query in relation to the words that are already in the file , and then querying it .
A: you want grep that 's that works at the structural on the structural representation .
C: you have that . there 's standard again in xml , specifically for searching xml documents structured - xml documents , where you can specify both the content and the structural position .
A: but it 's it 's not clear that 's that 's relative to the structure of the xml document , not to the structure of what you 're representing in the document .
C: you use it as tool . you use it as tool , not an end - user . it 's not an end - user thing . it 's it 's you would use that to build your tool to do that search .
A: because here you 're specifying lattice . so the underlying that 's the underlying data structure . and you want to be able to search in that lattice .
F: but as long as the
C: it 's graph ,
A: that 's different from searching through the text .
F: but it seems like as long as the features that
C: no , no . the whole point is that the text and the lattice are isomorphic . they represent each other completely .
F: that 's true if the features from your acoustics or whatever that are not explicitly in this are at the level of these types . that that if you can do that
C: but that 's gonna be the trouble no matter what . no matter what format you choose , you 're gonna have the trou you 're gonna have the difficulty of relating the frame - level features
F: that 's right . that 's true . that 's why was trying to figure out what 's the best format for this representation . and it 's still gonna be it 's still gonna be , , not direct . or another example was , , , where in the language where in the word sequence are people interrupting ? that one 's actually easier .
D: what about , , the idea of using relational database to , , store the information from the xml ? so you would have you could use the xml to put the data in , and then when you get data out , you put it back in xml . so use xml as the transfer format , but then you store the data in the database , which allows you to do all kinds of good search things in there .
C: one of the things that atlas is doing is they 're trying to define an api which is independent of the back store , so that , , you could define single api and the storage could be flat xml files or database . my opinion on that is for the that we 're doing , suspect it 's overkill to do full relational database , that , , just flat file and , , search tools bet will be enough . but that 's the advantage of atlas , is that if we actually take decide to go that route completely and we program to their api , then if we wanted to add database later it would be pretty easy .
F: it seems like the thing you 'd do if , if people start adding all kinds of bells and whistles to the data . and so that might be it 'd be good for us to know to use format where we know we can easily , , input that to some database if other people are using it . something like that .
C: 'm just little hesitant to try to go whole hog on the whole framework that nist is talking about , with atlas and database and all that , cuz it 's big learning curve , just to get going . whereas if we just do flat file format , , it may not be as efficient but everyone can program in perl and use it . so , as opposed to
A: 'm still , , not convinced that you can do much on the text on the flat file that , the text representation . because the text representation is gonna be , , not reflecting the structure of your words and annotations . it 's just it 's
C: if it 's not representing it , then how do you recover it ? it 's representing it .
A: you you have to what you have to do is you have to
C: that 's the whole point .
A: you can use perl to read it in and construct internal representation that is essentially lattice .
C: that was different point . so what was saying is that
A: but that 's what you 'll have to do .
C: for perl if you want to just do perl . if you wanted to use the structured xml query language , that 's different thing . and it 's set of tools that let you specify given the - ddt dtd of the document , , what sorts of structural searches you want to do . so you want to say that , , you 're looking for , , tag within particular tag that has this particular text in it , , and , , refers to particular value . and so the point isn't that an end - user , who is looking for query like you specified , wouldn't program it in this language . what you would do is , someone would build tool that used that as library . so that they so that you wouldn't have to construct the internal representations yourself .
F: see , the kinds of questions , at least in the next to the end of this year , are there may be lot of different ones , but they 'll all have similar nature . they 'll be looking at either word - level prosodic , , an value , like continuous value , like the slope of something . we 'll do something where we some data reduction where the prosodic features are sort , either at the word - level or at the segment - level , they 're not gonna be at the phone - level and they 're no not gonna be at the frame - level when we get done with giving them simpler shapes and things . and so the main thing is just being able , the two goals . one that chuck mentioned is starting out with something that we don't have to start over , that we don't have to throw away if other people want to extend it for other kinds of questions , and being able to at least get enough , , information out on where we condition the location of features on information that 's in the file that you put up there . and that would that would do it ,
C: that there are quick and dirty solutions , and then there are long - term , big - infrastructure solutions . and so we want to try to pick something that lets us do little bit of both .
F: in the between , and especially that the representation doesn't have to be thrown away , even if your tools change .
C: and so it seems to me that have to look at it again to see whether it can really do what we want , but if we use the atlas external file representation , , it seems like it 's rich enough that you could do quick tools just as said in perl , and then later on if we choose to go up the learning curve , we can use the whole atlas inter infrastructure ,
F: that sounds good to me .
C: which has all that built in .
F: if you would look at that and let us you think . we 're guinea pigs , cuz want to get the prosody work done but don't want to waste time , , getting the
C: wouldn't for the formats , because anything you pick we 'll be able to translate to another form .
A: maybe you should actually look at it yourself too to get sense of what it is you 'll you 'll be dealing with , because , , , adam might have one opinion but you might have another , the more eyes look at this the better .
F: especially if there 's , , if someone can help with at least the setup of the right
C: hi , jane .
F: the right representation , then , , hope it won't we don't actually need the whole full - blown thing to be ready , so maybe if you guys can look at it and see what , we 're we 're we 're actually just
C: we 're about done .
F: it 's short meeting , is there anything else , that helps me lot ,
C: the other thing we might want to look at is alternatives to - file . th the reason like - file is 'm already familiar with it , we have expertise here , and so if we pick something else , there 's the learning - curve problem . but , , it is just something we developed at icsi .
A: is there an is there an ip - api ?
C: there 's an api for it .
A: there used to be problem that they get too large ,
C: bunch of libraries , - file utilities .
A: and so the the filesystem wouldn't
C: that 's gonna be problem no matter what . you have the two - gigabyte limit on the filesystem size . and we definitely hit that with broadcast news .
A: maybe you could extend the api to , , support , , like splitting up , , conceptually one file into smaller files on disk so that you can essentially , , have arbitrarily long
C: most of the tools can handle that . we didn't do it at the api - level . we did it at the tool - level . that that most many of them can you can specify several - files and they 'll just be done sequentially .
F: if you and don can if you can show him the - file and see . so this would be like for the - zero
C: if you do "" man - file "" or "" apropos - file "" , you 'll see lot .
B: 've used the - file , . 've looked at it at least , briefly , when we were doing something .
A: what does the stand for anyway ?
C: have no idea . didn't de didn't develop it . it was it was dave johnson . so it 's all part of the quicknet library . it has all the utilities for it .
A: no , - files were around way before quicknet . - files were around when with , , rap .
F: it 's like the history of icsi .
A: you worked with - files . worked with - files .
D: don't remember what the "" "" is , though .
C: but there are ni they 're the quicknet library has bunch of things in it to handle - files , so it works pretty .
F: and that isn't really , , as important as the main what you call it , the main word - level
D: probably stands for "" phil "" .
C: it 's phil file ?
D: that 's my .
F: that 's really useful . this is exactly the thing that wanted to settle .
C: 've been meaning to look at the atlas again anyway . so , just keep
F: it 's also political deci if you feel like that 's community that would be good to tie into anyway , then it 's sounds like it 's worth doing .
C: and , , as said , what did with this based it on theirs . it 's just they hadn't actually come up with an external format yet . so now that they have come up with format , it doesn't it seems pretty reasonable to use it . but let me look at it again . as said , that
F: cuz we actually can start
C: there 's one level there 's one more level of indirection and 'm just blanking on exactly how it works . gotta look at it again .
F: we can start with , , , this input from dave 's , which you had printed out , the channelized input . cuz he has all of the channels , with the channels in the tag and like that .
C: 've seen it .
F: so that would be directly ,
C: easy easy to map .
F: and so then it would just be matter of getting making to handle the annotations that are , , not at the word - level and , , to import the
B: where are those annotations coming from ?
F: right now , jane would
E: are you talking about the overlap annotations ?
F: any annotation that , like , isn't already there . , anything you can envision .
E: so what was imagining was , so dave says we can have unlimited numbers of green ribbons . and so put , , green ribbon on for an overlap code . and since we we it 's important to remain flexible regarding the time bins for now . and so it 's to have however , , you want to have it , , time , located in the discourse . if we if we tie the overlap code to the first word in the overlap , then you 'll have time - marking . it won't it 'll be independent of the time bins , however these evolve , shrink , or whatever , also , you could have different time bins for different purposes . and having it tied to the first word in an overlap segment is unique , , , anchored , clear . and it would just end up on separate ribbon . so the overlap coding is gonna be easy with respect to that . you look puzzled .
D: don't quite understand what these things are .
E: what , the codes themselves ?
D: th overlap codes . 'm not what that @ @ it probably doesn't matter .
E: we don't have to go into the codes . we don't have to go into the codes .
C: that not for the topic of this meeting .
E: but let me just the idea is just to have separate green ribbon , and and let 's say that this is time bin . there 's word here . this is the first word of an overlapping segment of any length , overlapping with any other , , word , segment of any length . then you can indicate that this here was perhaps ch backchannel , or you can say that it was , , usurping of the turn , or you can , any number of categories . but the fact is , you have it time - tagged in way that 's independent of the , , sp particular time bin that the word ends up in . if it 's large unit or small unit , or we sh change the boundaries of the units , it 's still unique and , , fits with the format , flexible , all that .
A: gr this is regarding , it 's related but not directly germane to the topic of discussion , but , when it comes to annotations , , you often find yourself in the situation where you have different annotations of the same , say , word sequence . and sometimes the word sequences even differ slightly because they were edited at one place but not the other . so , once this data gets out there , some people might start annotating this for , , dialogue acts or , , , topics or what the heck . there 's zillion things that people might annotate this for . and the only thing that is really common among all the versi the various versions of this data is the word sequence ,
F: or the time .
A: or the times . but , see , if you 'd annotate dialogue acts , you don't necessarily want to or topics you don't really want to be dealing with time - marks . you 'd it 's much more efficient for them to just see the word sequence , right ? most people aren't as sophisticated as we are here with , , , time alignments and .
C: should should we mention some names on the people who are ?
A: the my point is that you 're gonna end up with , , word sequences that are differently annotated . and you want some tool , , that is able to merge these different annotations back into single , , version . and we had this problem very massively , , at sri when we worked , , while back on , , on dialogue acts as as , , , what was it ?
F: all the switchboard in it .
A: there 's , , automatic , , punctuation and like that . because we had one set of annotations that were based on , , one version of the transcripts with particular segmentation , and then we had another version that was based on , , different slightly edited version of the transcripts with different segmentation . so , we had these two different versions which were , you could tell they were from the same source but they weren't identical . so it was extremely hard to reliably merge these two back together to correlate the information from the different annotations .
C: don't see any way that file formats are gonna help us with that . it 's it 's all question of semantic .
A: but once you have file format , imagine writing not personally , but someone writing tool that is essentially an alignment tool , , that mediates between various versions , and , like th , , you have this thing in unix where you have , , diff .
F: - diff or diff .
A: there 's the , , diff that actually tries to reconcile different two diffs based on the same original .
E: is it - diff ?
A: something like that , but operating on these lattices that are really what 's behind this , this annotation format .
C: there 's actually diff library you can use to do things like that so you have different formats .
F: you could definitely do that with the
A: so somewhere in the api you would like to have like merge or some function that merges two versions .
C: it 's gonna be very hard . any structured anything when you try to merge is really , really hard the hard part isn't the file format . the hard part is specifying what you mean by "" merge "" . and that 's very difficult .
F: but the one thing that would work here actually for that is more reliable than the utterances is the speaker ons and offs . so if you have good ,
C: but this is exactly what , is that the problem
F: you just have to know wha what to tie it to .
C: the problem is saying "" what are the semantics , what do you mean by "" merge "" ? ""
F: right , right .
A: so so just to let what we where we kluged it by , , doing , by doing hhh . both were based on words , so , bo we have two versions of the same words intersp , sprinkled with different tags for annotations .
C: and then you did diff .
A: and we did diff .
C: that 's just what .
A: and that 's how
C: that 's just wh how would have done it .
A: but , , it had lots of errors and things would end up in the wrong order , and . if you had more because it was reducing everything to , , to textual alignment .
F: isn't that something where whoever if the people who are making changes , say in the transcripts , cuz this all happened when the transcripts were different ye , if they tie it to something , like if they tied it to the acoustic segment if they then or if they tied it to an acoustic segment and we had the time - marks , that would help . but the problem is exactly as adam said , that you get , , you don't have that information or it 's lost in the merge somehow ,
E: can ask one question ? it it seems to me that , , we will have an official version of the corpus , which will be only one version in terms of the words where the words are concerned . we 'd still have the merging issue maybe if coding were done independently of the
A: and you 're gonna get that because if the data gets out , people will do all kinds of things to it . and , , , several years from now you might want to look into , , the prosody of referring expressions . and someone at the university of who knows where has annotated the referring expressions . so you want to get that annotation and bring it back in line with your data .
C: but unfortunately they 've also hand - edited it .
F: but they 've also and so that 's exactly what we should somehow when you distribute the data , say that , that have some way of knowing how to merge it back in and asking people to try to do that .
D: what 's what 's wrong with doing times ?
E: that was what was wondering .
F: , time is the
E: time is unique . you were saying that you didn't think we should
F: time is passing !
A: time time times are ephemeral .
C: what if they haven't notated with them , times ?
F: he he 's language modeling person , though .
C: his example is good one . imagine that this person who developed the corpus of the referring expressions didn't include time . he included references to words . he said that at this word is when it happened .
E: but then couldn't you just indirectly figure out the time tied to the word ?
C: but what if what if they change the words ?
E: but you 'd have some anchoring point . he couldn't have changed all the words .
D: but can they change the words without changing the time of the word ?
C: but they could have changed it little . the , that they may have annotated it off word transcript that isn't the same as our word transcript , so how do you merge it back in ? understand what you 're saying . and the answer is , , it 's gonna be different every time . it 's it 's just gonna be it 's exactly what said before ,
F: you only know the boundaries of the
C: which is that "" what do you mean by "" merge "" ? "" so in this case where you have the words and you don't have the times , , what do you mean by "" merge "" ? if you tell me what you mean , write program to do it .
F: you can merge at the level of the representation that the other person preserved and that 's it .
C: and that 's about all you can do .
F: and beyond that , all is relative ordering and sometimes even that is wrong .
C: so so in this one you would have to do best match between the word sequences , extract the times from the best match of theirs to yours , and use that .
F: and then infer that their time - marks are somewhere in between .
E: but it could be that they just , , it could be that they chunked they lost certain utterances and all that ,
C: so it could get very , very ugly .
E: that 's interesting .
F: , didn't want to keep people too long and adam wanted people 'll read the digits . if anyone else offers to , that 'd be great .
A: for th for the {nonvocalsound} for the benefit of science we 'll read the digits .
C: more digits , the better .
F: it 's really helpful . adam and don {nonvocalsound} will meet and that 's great .
","Two main options were discussed as to the organisation of the collected data.
On the one hand , a bespoke XML structure that connects transcriptions and annotations ( down to the word-level ) to a common timeline.
Its advantages are that it is easier to read , parse , map onto the Transcriber format and to expand with extra features.
Phone-level analysis can be included in the same structure , or in a separate , linked file.
The respective frame-level representation can be handled by P-files , a technology developed at ICSI , which also comes with a library of tools.
Separation of levels of analysis makes files more compact and manageable.
XML standards offer libraries that can be used for the development of search tools.
On the other hand , the ATLAS ( NIST ) technology offers a very similar , but more generic organisational scheme based on nodes and links.
These are labeled with domain specific types , like ""utterance"" or ""speaker"".
This option offer well-developed infrastructure and flexibility as to the type of data storage ( flat XML files or relational database ).
In either case , it is important for the chosen format to allow for fast searches , flexible updates and , if possible , be reusable in future work.
In order to confirm the suitability of the data format provided by the ATLAS project , its current state of development will be investigated.
More specifically , the issues that have to be ascertained are , firstly , whether the external file representation offers a format that would be appropriate for speech data , and , secondly , how the linking between the different annotations ( eg , between word-level representations and prosodic-feature structures ) can be achieved.
Regardless of the actual format , however , there was consensus that keeping levels of analysis ( words , phones , frames , etc ) on separate , inter-linked files can make their management easier.
Choosing a project-specific format for the representation of the data might not be optimal for future work.
On the other hand , it is not yet clear whether a more standardised , but generic technology , like that of the ATLAS project , can accommodate all the requirements of speech analysis.
Regardless of the particular format , including all annotations ( sentences , words , phones , frames , etc ) in one file could result in unmanageable file sizes.
Searching , updating or simply parsing a file for a simple task can become an unwieldy process.
Even P-files , which are only for frame-level annotation , may be too verbose for the amount of data resulting from hour-long recordings.
The actual mapping of word-level transcriptions to frame-level representations is expected to be problematic anyway.
Likewise , problems will arise if , in the future , slightly different transcripts of the same data are annotated in formats that do not include time-marks.
Trying to merge such annotations later will not be easy , because of the combination of transcription discrepancies with the loss of the underlying connection offered by the time-marks.
An XML scheme to build representations of the data is already available.
It incorporates information regarding utterances , sentences , speakers , words , etc.
All these features are linked together via time-marks that slot into a single , common timeline.
This format also allows for linking to different levels of representation of the same data.
For the frame-level representation , P-files is a readily available technology , developed at ICSI.
Besides the appropriate format , P-files come with a library of tools and the respective documentation.
"
ami_abstractive_summary,Bmr012.txt,"B: let 's see , should be
E: as close to your mouth as you can get it .
D: high as you can get .
B: is this channel one ?
G: on your upper lip .
E: so for for people wearing the wireless mikes , like this one , find the easiest way to wear it is sorta this sorta like that .
H: this is chan channel one two three
F: channel five , channel five .
B: - . what do you do ,
E: it 's actually lot more comfortable then if you try to put it over your temples ,
F: test , test .
B: you do it higher ?
D: adam 's just trying to generate good data for the recognizer there .
G: we 're supposed to that 's right .
E: and then also , for all of them , if your boom is adjustable , the boom should be towards the corner of your mouth ,
A: there was bug . it wasn't using the proper
E: and about thumb to thumb and half distance away from your mouth ,
A: it wasn't adapting anything .
E: so about like 'm wearing it now .
D: that 's interesting . so why didn't you get the same results and the unadapted ?
E: so jane , you could actually do even little closer to your mouth ,
H: it 's not always possible .
D: why didn't you get the same results and the unadapted ?
G: could can this be adjuste like this ?
A: because when it estimates the transformer pro produces like single matrix .
G: is that @ @ ? ,
F: adam , 'm not looks kinda low on channel five
D: see , see .
E: channel five , speak again .
A: there were no counts
E: that 's alright . we could we could up the gain slightly if you wanted to .
D: see what you mean .
C: who 's channel ?
E: channel is probably liz .
H: channel am channel .
B: you wanna close this ,
G: channel eight , eight .
H: no , channel .
A: hello , hello .
C: you 're channel . so can you talk bit ? it might be too
H: channel , one two three four five .
E: it 's alright . so , the gain isn't real good .
B: we 're recording ,
E: so we are recording . everyone should have at least two forms possibly three in front of you depending on who you are . we 're doing new speaker form and you only have to spea fill out the speaker form once but everyone does need to do it . and so that 's the name , sex , email , et cetera . we we had lot of discussion about the variety of english and so on so if you what to put just leave it blank . designed the form and what to put for my own region ,
A: may make one suggestion ? instead of age put date of year of birth because age will change , but the year of birth changes , , stays the same , usually .
C: actually , minute , shouldn't it be the other way around ?
D: not for me .
G: course on the other on the other hand you could you view it as the age at the time of the
C: on the other side ,
A: if ten years from now you look at this form knowing that
G: yes , but what we care about is the age at the recording date rather than the
D: but there 's no other date on the form .
C: we don't care how they old they really are .
G: yes . unless we wanna send them card .
E: it depends on how long the corpus is gonna be collected for .
G: that 's true .
C: still don't see the problem .
E: and then there will be attached to this point or two these forms so that you 'll be able to extract the date off that so , anyway . and so then you also have digits form which needs to be filled out every time , the speaker form only once , the digit form every time even if you don't read the digits you have to fill out the digits form so that we know that you were at the meeting . and then also if you haven't filled one out already you do have to fill out consent form . and that should just be one person whose name .
F: do you want this adam ?
E: so should we do agenda items ?
B: that 's good idea . shouldn't run the meeting .
E: have wanna talk about new microphones and wireless . and 'm liz and andreas wanna talk about recognition results .
C: what time do we have to leave ?
E: why don't you go first then .
C: sent out an email couple hours ago with andreas ' help andreas put together no frills recognizer which is gender - dependent but like no adaptation , no cross - word models , no trigrams and that 's trained on switchboard which is telephone conversations . and to don 's help wh who don took the first meeting that jane had transcribed and separated used the individual channels we segmented it in into the segments that jane had used and don sampled that so eight and then we ran up to the first twenty minutes , up to synch time of one two zero so is that 's twenty minutes or so ? because there 's some , and don can talk to jane about this , there 's some bug in the actual synch time file that 'm we 're not where it came from but after that was little messier . anyway so it 's twenty minutes and actually
E: was that did that recording have the glitch in the middle ?
G: 'm puzzled by that .
C: there 's there 's
G: there was glitch somewhere .
F: was it twenty minutes in ,
C: if it was twenty minutes in then
G: forgot about that .
A: it was interesting , suddenly the overall error rate when we first ran it was like eighty percent
E: don't remember when it is .
G: but was able to can transcribe
A: but looking at the first sentences looked much better than that and then suddenly it turned very bad and then we noticed that the reference was always one off with the it was actually recognized
F: that might be that might be my fault .
E: so that was just parsing mismatch .
C: no actually it was it was complicated bug because they were sometimes one off and then sometimes random
F: was pretty certain that it worked up until that time ,
G: that 's not good .
C: so that 's what we have but that will be completely gone if this synch time problem
A: so so we have everything recognized but we scored only the first whatever , up to that time to
G: and the only glitch
C: so you guys know .
B: haven't seen the email , what was the score ?
C: so here 's the actual copy of the email
G: we should say something about the glitch . he he can say something about the glitch . cuz it 's it 's it 's it 's very small
C: so does this glitch occur at other
E: there there 's an acoustic glitch that occurs where the channels get slightly asynchronized so the that problem has gone away in the original driver believe it or not when the ssh key gen ran the driver paused for fraction of second and so the channels get little asynchronous and so if you listen to it in the middle there 's little part where it starts doing click sounds .
C: and is it only once that happens ?
E: right once in the middle .
C: there 's the previous page has some more information about what was wrong
B: so un unsurprisingly adam is the golden voice ,
E: but that shouldn't affect anything
C: so that 's actually
B: you see this here ?
C: what happens is it actually affects the script that don if we know about it then it could always be checked for it
E: the acoustic one shouldn't do anything .
F: exactly what affected it but 'll 'll talk to you about it , 'll show you the point .
G: it it had no effect on my transcription , had no trouble hearing it and having time bins
E: do remember seeing once the transcriber produce an incorrect xml file where one of the synch numbers was incorrect .
C: the synch time the synch numbers have more significant digits than they should ,
F: that 's what happened .
E: where where they weren't monotonic .
C: there 's things that are in smaller increments than frame . and so then , you look at that and it 's got more than three significant digits in synch time then that can't be right so anyway it 's it 's just
E: sounds like bug .
C: that 's why we only have twenty minutes but there 's significant amount of
F: non - zero ? there are like more cuz there 's lot of zeros tacked on just because of the way the script ran ,
E: the other one saw was that it
F: but there were there was point .
C: that was fine . that that was .
E: the other one saw was non - monotonic synch times and that definitely indicra indicates bug .
C: that would really be problem , so anyway these are just the ones that are the prebug for one meeting . and what 's which
E: so that 's very encouraging .
C: this is really encouraging cuz this is free recognition , there 's no the language model for switchboard is different so you can see some like this trent lott which these are funny ones ,
D: it 'll get those though .
C: there 's lot of perfect ones and good ones and all the references , you can read them and when we get more results you can look through and see
E: and as said would like to look at the lattices
C: it 's pretty good .
E: because it sounded like even the ones it got wrong it got it right ?
C: so we can generate
A: there are fair number of errors that are , where got the plural wrong or the inflection on the verb wrong .
E: and who cares ? and and there were lots the "" "" - , "" in on "" - "" of "" - .
A: mmm , so if
C: no those are actually lot of the errors are out of vocabulary , so is it like pzm is three words , it 's pzm , there 's no language model for pzm or
E: ri - ri right . did you say there 's no language for pzm ?
C: no language model , those
E: do you mean so every time someone says pzm it 's an error ? maybe we shouldn't say pzm in these meetings .
C: there 's all kinds of other like jimlet
E: that 's right , jimlet .
B: we don't even that means ,
C: so but this is really encouraging because
E: that 's right .
C: so , the bottom line is even though it 's not huge amount of data it should be reasonable to actually run recognition and be like within the scope of reasonable switchboard this is like about how we do on switchboard - two data with the switchboard - one trained mostly trained recognizer and switchboard - two is got different population of speakers and different topic and they 're talking about things in the news that happened after switchboard - one so there was @ @ so that 's great .
B: so we 're in better shape than we were say when we did had the ninety - three workshop and we were all getting like seventy percent error on switchboard .
C: this is really , and to andreas who , this is
E: especially for the very first run , you the first run ran of switchboard got hundred twenty percent word error
C: so and what al also this means is that there 's bunch of things in this note to various people especially with jane that would help for since we have this new data now in order to go from the transcripts more easily to just the words that the recognizer would use for scoring . had to deal with some of it by hand but lot of it can be automated by
B: one thing didn't get so the language model was straight from bigram from switchboard the acoustic models were also from switchboard or so they didn't have anything from this acoustic data in yet ?
G: that 's amazing .
E: so that 's great .
C: and actually we actually used switchboard telephone bandwidth models
G: that 's amazing .
A: that 's those are the only we ones there are ,
D: was just gonna say ,
C: so that 's the on that 's the only acoustic training data that we have lot of so guy at sri said that there 's not huge amount of difference going from it 's it 's not like we probably lose huge amount but we won't know because we don't have any full band models for conversational speech .
D: it 's probably not as bad as going using full band models on telephone band speech
C: right , so it 's so
B: but for broadcast news when we played around between the two there wasn't huge loss .
E: right , it was not big deal .
A: should should say that the language model is not just switchboard
C: so that 's good .
E: although combining worked .
A: there 's actually more data is from broadcast news but with little less weight
C: like trent lott must have been from
A: just for fun we also ran , our complete system starts by doing ge gender detection so just for the heck of it ran that
E: and it said hundred percent male ?
A: and it might be reassuring for everybody to know that it got all the genders right .
G: that 's 'm glad .
E: it got all two genders ?
C: but jane and adam have you kn about equal performance and and that 's interesting cuz the their language models are quite different and 'm pretty from listening to eric that , given the words he was saying and given his pronunciation that the reason that he 's so much worse is the lapel .
G: that makes lot of sense ,
C: so it 's now if we can just eliminate the lapel one when we get new microphones
B: would bet on that too
C: that would be worth it
B: cuz he certainly in that when as as burp user he was he was pretty strong one .
C: he he sounded to me just from he sounded like , what 's it sheep or goat ?
B: sheep is good .
C: right so so the good news is that this is without lot of the bells and whistles that we can do with the sri system and we 'll have more data and we can also start to maybe adapt the language models once we have enough meetings . so this is only twenty minutes of one meeting with no tailoring .
A: clearly there are with just small amount of actual meeting transcriptions thrown into the language model you can probably do quite bit better
C: the voca the vocabulary especially
E: or just dictionary .
A: not that much the vocabulary actually we have to see
C: it 's pretty good
B: have to add pzm and so on
E: and have to try it on the far field mike
C: and then there 's things like for the transcription got when someone has digit in the transcript if they said , one or eleven and if they said tcl or tcl . there 's things like that where , the we 'll probably have to ask the transcribers to indicate some of those kinds of things but in general it was really good and this is this is good news because that means the force alignments should be good and if the force alignments , it 's good news anyway but if the force alignments are good we can get all kinds of information . about , prosodic information and speaker overlaps and directly from the aligned times . so that 'll be something that actually in order to assess the forced alignment we need some linguists or some people to look at it and say are these boundaries in about the right place . because it 's just gonna give us time marks
E: we 've done that for one meeting .
C: for forced alignment . ye - right .
E: 'm just for overlaps is we did it for not for words .
C: so this would be like if you take the words and force align them on all the individual close talk close talking mikes then how good are these in reality and then was thinking it
E: so we might want to take twenty minutes and do closer word level transcription . maybe actually mark the word boundaries .
C: or have someone look at the alignments maybe linguist who can say roughly if these are and how far away they are . but it 's gotta be pretty good because otherwise the word recognition would be really crummy .
E: right , right .
C: it wouldn't necessarily be the other way around , if the wor word recognition was crummy the alignment might be but if the word recognition is this good the alignment should be pretty good . so that 's about it .
D: wonder if this is good thing or bad thing though , if we 're pr
E: that we 're starting so ?
D: if we 're producing database that everybody 's gonna do on
E: don't worry about it that 's the close talking mikes . try it on the ms and
D: so the real value of the database is these ?
B: there 's still just the the percentages and , they 're not as we 've talked about before there 's probably overlaps
C: this is not that good .
B: there 's probably overlaps in in fair number in switchboard as but there 's other phenomena , it 's meeting , it 's different thing and there 's lots of to learn with the close talking mikes certainly 'd like to see as soon as we could , maybe get some of the glitches out of the way but soon as we could how it does with say with the ms or maybe even one of the and see if it 's , is it hundred twenty percent or maybe it 's not maybe if with some adaptation you get this down to fifty percent or forty - five percent and then if for the pzm it 's seventy like that that 's actually something we could work with little bit
C: no it 's really , this way we least have baseline we know that the transcripts are very good so once you can get to the words that the recognizer which is total subset of the things you need to understand the text they 're pretty good so and it 's converting automatically from the xml to the chopping up the wave forms and it 's not the case that the end of one utterance is in the next segment and things like that which we had more problems with in switchboard so that 's good . and let 's see there was one more thing wanted to mention
G: is really great .
C: it was , really didn't do this myself
E: it 's really good .
C: so andreas set up this recognizer and the recognizer all the files 'm moving to sri and running everything there so brought back just these result files and people can look at them
A: we we talked about setting up the sri recognizer here . that 's if there are more machines here plus people can could run their own variants of of the recognition runs
B: certainly if the recognition as opposed to training ,
G: need . need to ask one question . which is so this issue of the legalistic aspects of the pre - sent pre - adapted , so what is the the data that you take into sri , first question , you 're maintaining it in place that wouldn't be publicly readable that ,
C: from the outside world or
G: by people who are not associated with this project .
E: it 's human subjects issues , told you about that .
C: we have no names .
E: that that 's not the issue ,
C: de audio data itself ?
E: it 's just the audio data itself , until people have chance to edit it .
G: - , exactly .
C: so protect my directories through there . right now they 're not they 're in the speech group directories which so will didn't know that actually .
B: so we just have to go through this process of having people approve the transcriptions , say it 's .
G: we had to get them to approve and then cuz the other question was gonna ask is if we 're having it 's but this meeting that you have , no problem cuz speak for myself
E: it 's us .
G: but that we didn't do anything that but anyway so wouldn't be too concerned about it with respect to that although we should clear it with eric and dan but these results are based on data which haven't had the haven't had the chance to be reviewed by the subjects
C: that 's true .
G: and how that stands , if you if you get fantastic results and it 's involving data which later end up being lessened by , certain elisions , then but wanted to raise that issue , that 's all .
B: once we get all this streamlined it may be sh it hopefully it will be fairly quick but we get the transcriptions , people approve them and so on it 's just that we 're
E: we need to work at system for doing that approval so that we can send people the transcripts and get back any bleeps that they want
C: actually the bleeps are also an issue .
B: it 's gonna be rare thing that there 's bleep for the most part .
A: actually had question about the downsampling , who , how this was done but is there are there any issues with downsampling
C: don did this .
A: because know that the recognizer that we use can do it on the fly so we wouldn't have to have it do it explicitly beforehand . and is there any are there other sev is there more than one way to do the downsampling where one might be better than another ?
F: there are lots of there are lots of ways to do the downsampling different filters to put on , like anti - aliasing .
A: so so the th
E: don't think we even know which one assume you 're using syncat to do it ?
F: no , 'm using sn snd are resample .
E: or sound resample ?
C: re - re ref
E: and dan 's archaic acronyms .
C: missing all the vowels . some of the vowels ,
E: not all of them .
C: almost all the vowels , that 's the hard part .
A: so so the other thing we should try is to just take the original wave forms ,
E: and few of the consonants .
A: segment them but not downsample them .
C: we could we could try that and compare
A: and and feed them to feed them to the sri recognizer and see if the sri front - end does something .
E: suspect that 's premature optimization ,
C: we can try it . only downsampled them first cuz was
F: that 's just one line that 's one line of code to comment at
A: right and it doesn't is no more work for for us .
C: they 're just bigger to transfer , that 's why downsampled them before but
A: but they 're only twice as big
C: that was if it 's the same then we can downsample here
A: it 's it 's just
C: but if it 's
F: although those eighty meg files take while to copy into my directories it 's not it wouldn't be problem if you 're interested in it
C: we could try that .
A: it would be it would probably take about minus the transfer time it would it would take ten minutes to try and and
E: it 's about fifty minute drive ,
A: and and if for some reason we see that it works better then we might investigate why
C: it takes more disk space too
A: and , , what
F: in the front - end we could do that .
B: so you just train just different filters and so you 're just wondering whether the filter is
F: imagine it would be
C: so we could try that with this particular twenty minutes of speech and see if there 's any differences .
A: at some point someone might have optimized whatever filtering is done for the actual recognition performance . so in other words
E: it just seems to me that , small changes to the language model and the vocabulary will so swamp that it may be premature to worry about that . so one is half percent better than the other don't think that gives you any information .
C: it 's just as easy to give you the sixteen individual , it was just more disk space for storing them
B: are you are you using mel cepstrum or plp over there ? so probably doesn't matter .
C: we could try .
F: there 's there 's your answer .
B: but but it wouldn't hurt to try ,
A: that 's what would assume but you never know ,
B: no the reason say this plp uses auto - regressive filtering and modeling and so it can be sensitive to the filtering that you 're doing but mel cepstrum might not you wouldn't expect to be so much
C: we can try it if you generate like the same set of files just up to that point where we stopped anyway and just sti stick them somewhere
F: it 's it 's really not problem .
A: actually , no .
C: and 'll rerun it with
A: don't stop at that part because we 're actually using the entire conversation to estimate the speaker parameters , so shouldn't use you should , get
F: 'll have to do is the reference file would stay the same , it 's just the individual segments would be approximately twice as long and could just replace them with the bigger ones in the directory , that 's not problem .
C: hand - edited the whole the whole meeting so that can be run once we get the bug out .
G: one one question which is had the impression from this meeting that that transcribed that that there was already automatic downsampling occurring , that in order to so it was so it 's like there 's already down
E: there 's one level that 's already happening right here .
B: this is being recorded at forty - eight kilohertz . which is more that anybody needs
E: and it gets downsampled to sixteen .
C: and that 's actually said in your meeting , that 's how know that .
G: that 's exactly , and that 's how .
C: it 's like are we downsampling to sixteen ?
B: it 's digital audio orientation for the board it 's in the monitor so it 's
C: thank god it 's not more than that .
E: and have no idea what filter it 's using ,
F: is eight kilohertz is eighty kilohertz generally accepted as like standard for voice ? that 's what was gonna say ,
B: so it 's it 's just that they were operating from switchboard which was completely telephone database and so that was standard for that sixteen
E: so sixteen seems to be pretty typical for with this thing .
B: sixteen is more common for broadband that isn't
E: that isn't music .
B: that isn't music and isn't telephone ,
C: and if you 're comparing like if you wanna run recognition on the pzm you would want you don't want to downsample the wh that
E: why is that ?
C: don if it 's any better
B: no actually would think that you would you would get better you 'd get better high frequencies in the local mike .
E: all the way around 'd think .
B: but who knows ? we do we we wanna find all this out ,
C: we could try it .
E: we 're gonna have plenty of low frequency on the ms with the fans .
C: there was just one more thing wanted to say which is unrelated to the recognition except that chuck fillmore to record meetings but he had too many people in his meetings and that 's too bad cuz they 're very animated and but jerry also so we 're starting on
A: they 're less animated .
C: but he has fewer he won't have more than eight and it 's meeting on even deeper understanding , edu , so that sounds interesting . as compliment to our front - end meeting and so that 's gonna start monday and one of the things that was realizing is it would be really great if anyone has any ideas on some time synchronous way that people in the meeting can make comment to the person whose gonna transcribe it or put push button when they wanna make note about "" boy you should probably erase those last few "" or "" want this not to be recorded now ""
B: weren't we gonna do something with pad at one point ?
G: the cross pads ?
E: we could do it with the cross pads .
C: cuz was thinking if the person who sets up the meeting isn't there and it 's group that we and this came up talking to jerry also that is there any way for them to indicate to make that the qu request that they have that they make explicitly get addressed somehow so if anyone has ideas or you could even write down "" it 's about three twenty five and ""
B: what was just suggesting is we have these this cross pad just for this purpose
E: and use that .
B: and just use that
E: not bad idea .
B: and if we sink it in
C: that would be great .
B: the other thing is
C: that be great .
B: if this or if it 's question for the mail to dan but is this thing of two eight channel boards maximum for this setup or could we go to third board ?
E: 'll send mail to dan and ask . that it 's the maximum we can do without lot of effort because it 's one board with two digital channels .
B: it is one board .
E: so it takes two fibers in to the one board . and so if we wanna do that more than that we 'd have to have two boards , and then you have the synchronization issue .
B: but that 's question because that would if it was possible cuz it is already we have group of people in this room that cannot all be miked and it 's not just cuz we haven't been to the store ,
D: what is the limit on each of those fiber channels , it just it 's eight channels come in , does it have do with the sampling rate ?
E: it 's eight . have no idea . but each fiber channel has eight channels and there are two ch two fibers that go in to the card .
B: it might be hard limitation , one thing is it the whole thing as said is all structured in terms of forty - eight kilohertz sampling so that pushes requirements up bit
D: was just wondering if that could change .
E: then we 'd also have to get another add and another mixer and all that .
D: if we could drop that .
E: so 'll send mail to dan and ask him . are we done with that ? so the oth topic is getting more mikes and different mikes , we can fit we have room for one more wireless and the wireless , this unit here is three fifty three hundred fifty dollars , it didn't realize but we also have to get tuner the receiver the other end , that 's four thirty
C: for for each ? the tuner is four thirty for each .
E: and we just need one more so
B: at least we got the good ones .
E: so that 's something like seven hundred eighty bucks for one more of these . and then also it turns out that the connector that this thing uses is proprietary of sony believe it or not and sony only sells this headset . so if we wanna use different set headset the solution that the guy suggested and they lots of people have done is sony will sell you the jack with just wires coming out the end and then you can buy headset that has pigtail and solder it yourself . and that 's the other solution and so the jacks are forty bucks apiece and the he recommended crown cm three eleven ae headset for two hundred bucks apiece .
B: there isn't this some thing that plugs in , you actually have to go and do the soldering yourself ?
E: becau - the reason is the only thing you can get that will plug into this is this mike or just the connector .
B: the reason ask is these handmade wiring jobs fall apart in use so the other thing is to see if we can get them to do custom job and put it together for this .
E: 'm they would , they would just charge us ,
D: and they 'd probably want quantity too ,
B: no they 'll just charge us more , so it 's this
E: so so my question is should we go ahead and get na nine identical head - mounted crown mikes ?
B: not before having one come here and have some people try it out . because there 's no point in doing that if it 's not gonna be any better .
E: so why don't we get one of these with the crown with different headset ? and and see if that works .
B: and see if it 's preferable and if it is then we 'll get more .
C: cuz the microphones are it 's just the
E: it 's just they 're not comfortable to wear .
C: could make our own handbands and
E: and he said they don't have any of these in stock but they have them in la and so it will take about week to get here . so to just go order ?
B: we 're in this for the long term , just order it .
C: it 's lot of money for handband .
E: and who is the contact if wanna do an invoice cuz that 's how we did it before .
B: we 'll do this off - line , .
F: it 's long time to get from la .
E: and then nine channels is the maximum we can do ,
B: so one is for the daisy chain so that 's fifteen instead of sixteen
E: without getting more .
B: and there 's six on the table so that 's nine .
C: can ask really dumb question ? is is there any way we can have like wireless microphone that you pass around to the people who the extra people for the times they wanna talk that
B: that 's good idea . that 's not dumb question , it 's good idea ,
A: like like jerry springer thing ,
E: 'm just not how we would handle that in the
F: that 's like the conch .
C: but there might be way to say that there are gonna be these different people
F: see , look .
C: and identifying somehow ?
D: so nail the chairs down .
C: was just thinking of jerry springer .
E: it 's not bad idea .
B: if we can't get another board and even if we can have feeling they 'll be some work .
D: the springer mike .
C: for the few times that you might wanna have that .
B: let 's figure that we have eight which are set up and then there 's ninth which is passed around to
E: hand - held ,
B: that 's good idea
C: or also for if people are not
E: we could just hand around the lapel .
C: no not the lapel .
E: do you want handset ? is the is the hand - held really any better ?
D: liz hates the lapel .
C: but know the lapel is really suboptimal .
B: no it depends on the hand - held but hand many hand - helds are built wi with anti - shock things so that it is less susceptible to hand noises . if you hold the lapel mike you just get all sorts of junk .
C: the ones they really pass around must be .
E: so wonder if they have one that will hook up . wonder if they have one that will hook up to this or whether again we 'll have to wire it ourselves .
D: you wouldn't want it to hook there you 'd just want it to hook into the receiver in the other room ,
B: you need transmitter .
D: is th isn't that built into the mike ?
B: get get different radio ,
C: just these ones that they pass around with no wireless
B: but you need ra but it has to correspond to the receiver .
D: have little antenna coming out the bottom .
E: it 's gonna be much easier to get one of these and just plug in mike ,
D: but then the mike has to
A: do you have to hand it around and if you have two pieces of
B: so this is good point , so you have these mikes with little antenna on the end
E: and do you think you would be able to use the same receiver ?
B: you 'll have to check with them ,
E: 'll 'll ask .
B: but that 's that 's great idea
D: it 's just frequency .
B: and then just have that as the and then you can have groups of twenty people or whatever
C: because there 's only as andreas pointed out actually in the large the larger the group the less interaction the less people are talking over each other it just there might be lot of people that speak once or twice
B: off you go ,
E: so people who have to leave can leave and do we have anything else to discuss or should we just do digits ?
G: of some extra couple of extra things 'd like to mention . one of them is to give you status in terms of the transcriptions so far . so as of last night 'd assigned twelve hours and they 'd finished nine and my goal was to have eleven done by the end of the month , that by tomorrow we 'll have ten . so they 're still working .
B: that 's good .
C: and this got this email from jane at like two in the morning
E: that 's good .
C: so it 's really great
G: it 's working out , .
C: it 's really great .
G: and then also an idea for another meeting , which would be to have the transcribers talk about the data it 's little bit little bit
C: that 's great idea .
E: that 'd be very interesting .
C: that 's great idea cuz 'd like to have it recorded so that we can remember all the little things ,
E: 'd love to hear what they have to say .
C: that 's great idea .
D: so if we got them to talk about this meeting , it would be meta meeting .
G: nested several layers ,
B: now you have eight transcribers and there 's ten of us so how do we do this , is the only thing .
C: or just have them talk amongst themselves .
D: have them have their own meeting .
G: that 's what 'm thinking , have them talk about the data and they and they 've made observations to me
C: that would be great .
G: like they say this meeting that we think has so much overlap , it does but there are other groups of similar size that have very little , it 's part of it 's it 's the norm of the group and all that and they have various observations that would be fun , .
C: that 's great idea .
E: 'd like to hear what they say .
B: so maybe we could they could have meeting more or less without us that to do this and we should record it and then maybe one or two of them could come to one of these meetings and could could tell us about it .
E: give us status .
C: it 's they will get to transcribe their own meeting but they also get paid for having break
E: that would be weird .
G: that 's right .
C: and that 's good idea , get them involved . that 's great idea . 'm really have to no have to go as .
G: and then wanted to also say something about the fiscus john fiscus visit tomorrow . and which is to say that it 'll be from nine to one that 'm going to offer the organization allow him to adjust it if he wishes but to be in three parts , the acoustic part coming first which would be the room engineering aspects and he 'll be also presenting what nist is doing number two would be the transcription process so this would be focus on like presegmentation and the modifications to the multitrans interface which allows more refined encoding of the beginnings and ends of the overlapping segments which dave gelbart 's been doing and then and the presegmentation thilo 's been doing and then the third part would he has some that 's relevant with respect to nist and then the third one would be focus on transcription standards so at nist he 's interested in this establishment of global encoding standard would say and want it , see what they 're doing and also present what we 've chosen as ours and discuss that thing . and so but he 's only here until one and actually we 're thinking of noon being lunch time so hoping that we can get as much of this done as possible before noon . and everybody who wants to attend is welcome .
E: where you 're gonna meet ?
G: but 've also reserved the barco room to figure out how that works in terms of like maybe having live demonstration .
B: but the nine ' cl nine ' clock will be be in here .
E: assume we 're not gonna try to record it ?
G: that would be hard , .
B: so maybe do digits and recess ?
E: unless there 's anything else ?
D: do digital ones ?
E: should we make him wear andreas ' mike or would that just be too confusing ?
B: no don't 's confusing . it doesn't confuse me .
G: when we do this in the key in the key it has to indicate that channel change ,
D: does it mess up the forms ?
E: how we would do that , other than free form .
G: have time mark .
D: the on switch is here on the on the top there .
E: and just clip it to your collar .
B: that 's fine .
J: my name is espen eriksen . this is my second semester at berkeley . currently 'm taking my first graduate level courses in dsp and when come back to norway 'm gonna continue with the more of research project work work . so this semester 'm starting up with with small project through dave gelbart which 'm taking course with got in touch with him and he told me about this project . so with the help of dan ellis 'm gonna do small project associated to this . what 'm gonna try to do is use ech echo cancellation to to handle the periods where you have overlapping talk . to try to do something about that . so currently 'm 'm just reading up on echo cancellation , looking into the theory behind that and then hopefully get some results . so it 's it 's project goes over the course of one semester . so 'm just here today to introduce myself . 'll be 'll be working on this .
E: and are you staying at berkeley or is are you just here semester ?
J: this is my second semester and last .
E: second and last ,
B: he 's in the he 's in the cour two five course .
J: 'm in morgan 's course ,
G: then you then you go back to norway ,
F: we were just talking about something like this yesterday yesterday with liz . about doing some of the echo cancellation or possibly the spectroanalysis over the overlaps ,
B: let 's do digits .
","The Berkeley Meeting Recorder group discussed recognition results generated for 20 minutes of close-talking microphone data.
Recognition performance was very good , indicating promising results for forced alignment procedures and the ability to analyze other important signal information , e.g . prosody and overlapping speech.
It was decided that close-talking data should be downsampled and fed to the SRI recognizer to compare recognition performance , and that data from the far-field microphones should be tested on the recognizer as soon as possible.
The group also discussed recording setup and equipment issues.
A decision was made to purchase an additional head-mounted crown microphone.
A tentative decision was also made to integrate the use of a hand-held wireless microphone to help compensate for the lack of available close-talking microphones.
The collection of Meeting Recorder data is ongoing , and will include meetings by the Berkeley Even Deeper Understanding research group and , possibly , an organized discussion by members of the transcriber pool.
Following close-talking microphone recognition procedures , it was decided that data from the far-field microphones ( or PZMs ) should be tested on the recognizer as soon as possible.
Speaker mn017 will compare close-talking microphone recognition results with those obtained for downsampled data.
The SRI recognizer will be set up at ICSI to enable researchers to run their own variants.
The group decided to purchase one additional head-mounted crown microphone.
A tentative decision was also made to acquire a hand-held wireless microphone to pass around to additional meeting participants should the installation of more close-talking microphones prove too difficult.
The suggestion of incorporating the use of cross pads during meeting recordings received favorable comments from participants.
It was also tentatively decided to elicit meeting data from members of the transcriber pool discussing the Meeting Recorder corpus.
During recognition procedures , a fixable acoustic glitch was discovered that causes speech channels to become slightly asynchronized.
Poorer recognition performance was yielded for speech recorded via the use of lapel microphones.
Recognition errors were largely due to misrecogniton of the plural -s and out-of-vocabulary items.
The current recording setup is limited in that not all BMR meeting participants have their own close-talking microphone.
A 'no-frills' recognizer , trained on Switchboard acoustic models and both Switchboard and Broadcast News language models , was used to test data for one transcribed meeting.
Despite a glitch affecting the synchronized output of remaining data , recognition results for the first 20 minutes were very positive.
The recognizer was successful in making accurate gender distinctions among speakers.
It is anticipated that subsequent forced alignment procedures will also generate good results , enabling the group to analyze other types of signal information , such as prosody and overlapping speech segments.
Future work will involve getting assessments of forced aligned data from linguists on the accuracy of time marks.
The collection of Meeting Recorder data is ongoing , and will include meetings by the Berkeley Even Deeper Understanding research group.
Transcriptions are also ongoing , with nearly 10 hours of Meeting Recorder data transcribed so far.
Future work will involve working out a system for getting subjects to approve transcriptions so that confidentiality agreements are upheld and data may be shared with other research groups.
A visiting student from Norway is working with a member of ICSI to conduct a related project on echo cancellation for handling segments of overlapping speech.
Finally , the group is expecting a visit from a representative of NIST.
"
ami_abstractive_summary,Bmr011.txt,"B: are we on ? we 're on .
E: is it on ?
A: why is it so cold in here ?
B: we haven't sent around the agenda . any agenda items anybody has , wants to talk about , what 's going on ?
G: could talk about the meeting .
H: does everyone has everyone met don ?
B: it 's on ? agenda item one , we did that .
A: had just quick question but know there was discussion of it at previous meeting that missed , but just about the wish list item of getting good quality close - talking mikes on every speaker .
B: so let 's so let 's just do agenda building right now . so let 's talk about that bit . @ @ tuss close talking mikes , , we can talk about that . you were gonna starting to say something ?
G: you , , already know about the meeting that 's coming up and if this is appropriate for this . maybe it 's something we should handle outside of the meeting .
B: no , no , that 's . we can so we can ta so nist is nist folks are coming by next week and so we can talk about that .
E: who 's coming ?
B: and , , george doddington will be around as . , so we can talk about that . hear about how things are going with , , the transcriptions . that 's right . that would sorta be an obvious thing to discuss . an - anything else , , strike anybody ?
A: we started running recognition on one conversation but it 's the isn't working yet . but if anyone has the main thing would be if anyone has , , knowledge about ways to , , post - process the wave forms that would give us better recognition , that would be helpful to know about .
H: it sounds like topic of conversation .
E: what about , , is there anything new with the speech , nonspeech ?
C: we 're working more on it but , it 's not finished .
B: alright , that seems like good collection of things . and we 'll undoubtedly think of other things .
G: had thought under my topic that would mention the , , four items that , , put out for being on the agenda on that meeting , which includes like the pre - segmentation and the and the developments in multitrans .
B: under the nist meeting .
G: under the nist thing .
B: alright , why don't we start off with this , the order we brought them up seems fine . so , better quality close talking mikes . so the one issue was that the , , lapel mike , , isn't as good as you would like . and so , , it 'd be better if we had close talking mikes for everybody . is that is that the point ?
A: and actually in addition to that , that the close talking mikes are worn in such way as to best capture the signal . and the reason here is just that for the people doing work not on microphones but on like dialogue and , or and even on prosody , which don is gonna be working on soon , it adds this extra , , vari variable for each speaker to deal with when the microphones aren't similar . so and also talked to mari this morning and she also had strong preference for doing that . and she said that 's useful for them to starting to collect their data too .
B: right , so one th one thing was gonna say was that , , we could get more , , of the head mounted microphones even beyond the number of radio channels we have because whether it 's radio or wire is probably second - order . and the main thing is having the microphone close to you , although , not too close .
H: so , , actually the way jose is wearing his is correct . the good way . so you want to
D: it 's not cor it 's correct ?
H: th that 's good . so it 's towards the corner of your mouth so that breath sounds don't get on it . and then just about , , thumb or thumb and half away from your from your mouth .
A: but we have more than one type of
H: and this one isn't very adjustable , so this about as good as get cuz it 's fixed boom .
D: is fixed . .
A: but if we could actually standardize , , the microphones , , as much as possible that would be really helpful .
B: it doesn't hurt to have few extra microphones around , so why don't we just go out and get an order of if this microphone seems to people , 'd just get half dozen of these things .
H: the onl the only problem with that is right now , , some of the jimlets aren't working . the little the boxes under the table . and so , , 've only been able to find three jacks that are working .
E: can we get these , wireless ?
B: no , but my point is
A: but we could just record these signals separately and time align them with the start of the meeting .
H: 'm not 'm follow . say that again ?
B: right now , we 've got , , two microphones in the room , that are not quote - unquote standard . so why don't we replace those however many we can plug in . if we can plug in three , let 's plug in three . also what we 've talked before about getting another , , radio , and so then that would be , , three more . so , so we should go out to our full complement of whatever we can do , but have them all be the same mike . the original reason that it was done the other way was because , it it was an experimental thing and don't think anybody knew whether people would rather have more variety or , , more uniformity , but @ @ but ,
H: sounds like uniformity wins .
A: for short term research it 's just there 's just so much effort that would have to be done up front , so , uniformity would be great .
E: you you 're saying the for dialogue purposes , so that means that the transcribers are having trouble with those mikes ? is that what you mean ?
A: jane would know more about the transcribers .
G: and that 's true . we did discuss this . so , , , the transcribers notice and there 're some where , there 's it 's the double thing . it 's the equipment and also how it 's worn . and he 's always they just rave about how wonderful adam 's adam 's channel is .
H: what can say .
A: so does the recognizer .
H: 'm not surprised . "" baaah ! ""
A: even if you 're talking on someone else 's mike it 's still you
G: but it 's not just that , it 's also you it 's also like no breathing , it 's like it 's it 's , it 's really {nonvocalsound} it makes big difference from the transcribers ' point of view
H: it 's an advantage when you don't breath .
G: and also from the research point of view .
B: when we 're doing
H: that the point of doing the close talking mike is to get good quality signal . we 're not doing research on close talking mikes . so we might as get it as uniform as we can .
B: now , this is locking the barn door after the horse was stolen . we do have thirty hours , of speech , which is done this way . but , , , for future ones we can get it bit more uniform .
A: great , great .
H: so just do field trip at some point .
B: probably , to the store we talked about
G: and there was some talk about , , maybe the headphones that are uncomfortable for people , to
H: so , as said , we 'll do field trip and see if we can get all of the same mike that 's more comfortable than these things , which are horrible .
A: great , very much .
E: especially for people with big heads .
A: it 's makes our job lot easier .
H: and , , we 're researchers , so we all have big heads .
B: second item was the , , nist visit , and what 's going on there .
G: so , , , jonathan fiscus is coming on the second of february and 've spoken with , , lot of people here , he expressed an interest in seeing the room and in , , seeing demonstration of the modified multitrans , which 'll mention in second , and also , , he was interested in the pre - segmentation and then he 's also interested in the transcription conventions . and , so , , it seems to me in terms of like , so the room , it 's things like the audio and and audi audio and acoustic properties of the room and how it how the recordings are done , and that thing . and , . , in terms of the multi - trans , that 's being modified by dave gelbart to , , handle multi - channel recording .
H: was just thinking should have invited him to this meeting . forgot to do it .
G: that 's , we 'll and it 's and it looks really great . he he has prototype . , @ @ didn't didn't see it , , yesterday but 'm going to see it today . and , , that 's that will enable us to do , tight time marking of the beginning and ending of overlapping segments . at present it 's not possible with limitations of the , , original design of the software . in terms of , like , pre - segmentation , that continues to be , , terrific asset to the to the transcribers . do you know that you 're al also supplementing it further . do you want to mention something about that thilo ,
C: what what 'm doing right now is 'm trying to include some information about which channel , , there 's some speech in . but that 's not working at the moment . 'm just trying to do this by comparing energies , normalizing energies and comparing energies of the different channels . so to give the transcribers some information in which channel there 's there 's speech in addition to the thing we did now which is just , , speech - nonspeech detection on the mixed file . so 'm 'm relying on the segmentation of the mixed file
G: this is good . - .
C: but 'm 'm trying to subdivide the speech portions into different portions if there is some activity in different channels .
G: excellent , so this 'd be like providing also speaker id potentially .
B: something didn't put in the list but , , on that , , same day later on in or maybe it 's no , actually it 's this week , dave gelbart and will be , , visiting with john canny who , is cs professor , who 's interested in ar in array microphones .
H: he 's doing array mikes .
B: and so we wanna see what commonality there is here . maybe they 'd wanna stick an array mike here when we 're doing things
E: that would be .
H: that would be neat .
B: or maybe it 's it 's not specific array microphone they want
E: that would be really neat .
B: but they might wanna just , , , you could imagine them taking the four signals from these table mikes and trying to do something with them so , , we 'll be over there talking with him , , after class on friday . we 'll let what goes with that . also had completely unrelated thing . had , , discussion today with , , birger kollmeier who 's , , german , , scientist who 's got fair sized group doing range of things . it 's auditory related , largely for hearing aids and so on . but , , he does with auditory models and he 's very interested in directionality , and location , and , , head models and microphone things . and so , , he 's he and possibly student , there there 's , , student of his who gave talk here last year , may come here , , in the fall for , , five month , , sabbatical . so he might be around . get him to give some talks and so on . but anyway , he might be interested in this .
E: that that reminds me , had thought of an interesting project that somebody could try to do with the data from here , either using , , the mikes on the table or using signal energies from the head worn mikes , and that is to try to construct map of where people were sitting ,
H: dan had worked on that . dan ellis ,
E: that 's interesting .
H: so that 's the cross - correlation , was doing beam - forming .
E: and so you could plot out who was sitting next to who
B: he didn't do very extreme thing but just it was just
H: he did start on it .
B: given that , the the block of wood with the the two mikes on either side , if 'm speaking , or if you 're speaking , or someone over there is speaking , it if you look at cross - correlation functions , you end up with if someone who was on the axis between the two is talking , then you get big peak there . and if someone 's talking on on , , one side or the other , it goes the other way . and then , , it it even looks different if th if the two people on either side are talking than if one in the middle . it it actually looks somewhat different ,
E: was just thinking , , as was sitting here next to thilo that , when he 's talking , my mike probably picks it up better than your guys 's mikes . so if you just looked at
H: that 's another cl cue ,
E: looked at the energy on my mike and you could get an idea about who 's closest to who .
H: that 's true . or who talks the loudest .
B: you have to the appropriate normalizations are tricky , and and are probably the key .
A: you just search for adam 's voice on each individual microphone , where everybody 's sitting .
B: we 've switched positions recently so you can't so those are just little couple of news items .
G: can ask one thing ? jonathan fiscus expressed an interest in , , microphone arrays . and also want to say , his he can't stay all day . he needs to , leave for , from here to make two forty - five flight
H: so just morning .
G: so it makes the scheduling little bit tight but do you think that , that , , john canny should be involved in this somehow or not . have no idea .
B: but 'll 'll know better after see him this friday what level he wants to get involved .
G: it 's premature .
B: he might be excited to and it might be very appropriate for him to , , or he might have no interest whatsoever .
H: is he involved in ach ! 'm blanking on the name of the project . nist has done big meeting room instrumented meeting room with video and microphone arrays , and very elaborate software . is is he the one working on that ?
B: that 's what they 're starting up . no , , that 's wh this is about . they they haven't done it yet . they wanted to do it
H: had read some papers that looked like they had already done some work .
B: they 've instrumented room but don't think they haven't started recordings yet . they don't have the the transcription standards . they don't have the
E: are they going to do video as ?
H: cuz what had read was , , they had very large amount of software infrastructure for coordinating all this , both in terms of recording and also live room where you 're interacting the participants are interacting with the computer , and with the video , and lots of other .
B: 'm 'm not . all all that they 've been talking to me about project that they 're going to start up recording people meet in meetings . and , , it is related to ours . they were interested in ours . they wanted to get some uniformity with us , , about the transcriptions and so on . and one notable difference actually 't remember whether they were going to routinely collect video or not , but one , , difference from the audio side was that they are interested in using array mikes . so , , , 'll just tell you the party line on that . the reason didn't go for that here was because , , the focus , , both of my interest and of adam 's interest was , in impromptu situations . we 're not recording bunch of impromptu situations but that 's because it 's different to get data for research than to actually apply it . and so , , for scientific reasons we thought it was good to instrument this room as we wanted it . but the thing we ultimately wanted to aim at was situation where you were talking with , , one or more other people , in an impromptu way , where you didn't didn't actually the situation was going to be . and therefore it would not it 'd be highly unlikely that room would be outfitted with some very carefully designed array of microphones . so it was only for that reason . it was just , , yet another piece of research and it seemed like we had enough troubles just
E: so there 's no like portable array of mikes ?
B: no . so there 's , there 's whole range of things there 's whole array of things , that people do on this . the , the big arrays , places , , like , rutgers , and brown , and other places , they have , , big arrays with , , hundred mikes . and so there 's wall of mikes . and you get really , really good beam - forming with that thing . and it 's and , , at one point we had proposal in with rutgers where we were gonna do some of the per channel signal - processing and they were gonna do the multi - channel , but it we ended up not doing it .
E: 've seen demonstrations of the microphone arrays . it 's amazing how they can cut out noise .
B: it 's it 's really neat .
H: and then they have little ones too
B: and then they had the little ones , .
H: but but they don't have our block of wood ,
B: our block of wood is unique . but the but the no , there are these commercial things now you can buy that have four mikes so , , there 's there 's range of things that people do . so if we connected up with somebody who was interested in doing that thing that 's that 's good thing to do . whenever 've described this to other people who are interested on the with the acoustic side that 's invariably the question they ask . just like someone who is interested in the general dialogue thing will always ask "" , are you recording video ? "" and and the acoustic people will always say , "" are you doing , , array microphones ? "" so it 's it 's good thing to do , but it doesn't solve the problem of how do you solve things when there 's one mike or at best two mikes in this imagined pda that we have . so maybe we 'll do some more of it .
G: one thing , . know that having an array of , would imagine it would be more expensive to have an array of microphones . but couldn't you approximate the natural sis situation by just shutting off , channels when you 're later on ? it seems like if the microphones don't effect each other then couldn't you just , , record them with an array and then just not use all the data ?
H: it 's it 's just lot of infrastructure that for our particular purpose we felt we didn't need to set up .
B: if ninety - nine percent of what you 're doing is is shutting off most of the mikes , then going through the but if you get somebody who 's who has that as primary interest then that put then that drives it in that direction .
H: that 's right , if someone if someone came in and said we really want to do it , we don't care . that would be fine ,
E: so to save that data you you have to have one channel recording per mike in the array ?
H: buy more disk space .
B: , at some level at some level .
H: usually do mix .
B: but then , , there 's it there 's
E: what you save , , if you 're going to do research with it .
B: what they 're going to do and how big their array is . if you were gonna save all of those channels for later research you 'd use up lot of space .
H: their software infrastructure had very elaborate design for plugging in filters , and mixers , and all sorts of processing . so that they can do in real time and not save out each channel individually . so it was ,
B: but , , for optimum flexibility later you 'd want to save each channel . but in practical situations you would have some engine of some sort doing some processing to reduce this to some to the equivalent of single microphone that was very directional .
E: , , see . saving the result of the beam - forming .
A: it seems to me that there 's , there are good political reasons for doing this , just getting the data , because there 's number of sites like right now sri is probably gonna invest lot of internal funding into recording meetings also , which is good , but they 'll be recording with video and they 'll be it 'd be if we can have at least , , make use of the data that we 're recording as we go since it 's this is the first site that has really collected these really impromptu meetings , and just have this other information available . so , if we can get the investment in just for the infra infrastructure or have whoever 's interested save that data out , transfer it there , it 'd be it 'd be good to have the recording . .
H: you mean to actually get microphone array and do that ?
A: even if we 're not 'm not about video . that 's an video has little different nature since right right now we 're all being recorded but we 're not being taped . but it definitely in the case of microphone arrays , since if there was community interested in this , then
H: but we need researcher here who 's interested in it . to push it along .
B: see the problem is it took , , it took at least six months for dan to get together the hardware and the software , and debug in the microphones , and in the boxes . and it was really big deal . and so we could get microphone array in here pretty easily and , , have it mixed to one channel of some sort . how we 're gonna decide for for maximum flexibility later you really don't want to end up with just one channel that 's pointed in the direction of the the the person with the maximum energy like that . you want actually to you want actually to have multiple channels being recorded so that you can and to do that , it we 're going to end up greatly increasing the disk space that we use up , we also only have boards that will take up to sixteen channels and in this meeting , we 've got eight people and six mikes . and there we 're already using fourteen .
H: and we actually only have fifteen . one of them 's but fifteen , not sixteen .
A: if there 's way to say time to solve each of these those so suppose you can get an array in because there 's some person at berkeley who 's interested and has some equipment , and suppose we can as we save it we can , , transfer it off to some other place that holds this data , who 's interested , and even if icsi it itself isn't . and it seems like as long as we can time align the beginning , do we need to mix it with the rest ?
B: so you 'd need separate separate set up and the assumption that you could time align the two .
A: it 's just it 's worth considering as
H: and it 'd certainly gets skew .
A: once you make the up front investment and can save it out each time , and not have to worry about the disk space factor , then it mi it might be worth having the data .
B: 'm not so much worried about disk space actually . mentioned that , as practical matter , but the real issue is that , , there is no way to do recording extended to what we have now with low skew . so you would have completely separate set up , which would mean that the sampling times and would be all over the place compared to this . so it would depend on the level of pr processing you were doing later , but if you 're the person who 's doing array processing you actually care about funny little times . and and so you actually wou would want to have completely different set up than we have , one that would go up to thirty - two channels .
H: or hundred thirty - two .
B: so , 'm kinda skeptical , so , , don't think we can share the resource in that way . but what we could do is if there was someone else who 's interested they could have separate set up which they wouldn't be trying to synch with ours which might be useful for them .
A: right , at least they 'd have the data and the transcripts ,
B: and then we can offer up the room , we can offer the meetings , and the physical space , and , the transcripts , and so on .
A: right , , just it 'd be if we have more information on the same data . but it 's if it 's impossible or if it 's lot of effort then you have to just balance the two ,
B: the thing will be , in again , in talking to these other people to see what , what we can do . we 'll see .
E: is there an interest in getting video recordings for these meetings ?
B: right , so we have we
H: yes , . but it 's exactly the same problem , that you have an infrastructure problem , you have problem with people not wanting to be video taped , and you have the problem that no one who 's currently involved in the project is really hot to do it .
E: so there 's not enough interest to overcome all of
A: right . internally , but know there is interest from other places that are interested in looking at meeting data and having the video . so it 's just
G: although have to mention the human subjects problems , that increase with video .
A: right , that 's true .
B: so it 's , , people getting shy about it . there 's this human subjects problem . there 's the fact that then , if 've heard comments about this before , "" why don't you just put on video camera ? "" but , it 's like saying , "" , we 're primarily interested in some dialogue things , but , , why don't we just throw microphone out there . "" , once you actually have serious interest in any of these things then you actually have to put lot of effort in . and , , you really want to do it right . so nist or ldc , or somebody like that is much better shape to do all that . we there will be other meeting recordings . we won't be the only place doing meeting recordings . we are doing what we 're doing . and , , hopefully it 'll be useful .
G: it occurred to me , has don signed human subject 's form ?
H: ! probably not . has don have you did you si you did actually .
F: was , was was here before once .
H: didn't you read digit string ?
E: you were here at meeting before .
G: you were here at meeting before .
H: and you and you signed form .
G: did you sign form ?
H: 'll 'll get another one before the end of the meeting .
G: you don't you don't have to leave for it .
F: can verbally consent ?
H: 'm wired in .
B: we we don't ,
A: you 're on recor you 're being recorded
B: we don't we don't perform electro - shock during these meetings ,
F: you can do whatever you want with it . that 's fine .
G: about there are maybe three aspects of this . so first of all , , 've got eight transcribers . seven of them are linguists . one of them is graduate student in psychology . each gave each of them , , their own data set . two of them have already finished the data sets . and the meetings run , , let 's say an hour . sometimes as man much as an hour and half .
E: how big is the data set ?
G: it 's what is one meeting . each each person got their own meeting . didn't want to have any conflicts of , , of when to stop transcribing this one so wanted to keep it clear whose data were whose , and , , meetings , , that they 're they go as long as almost two hours in some in some cases . so , , that means if we 've got two already finished and they 're working on right now all eight of them have differe , additional data sets . that means potentially as many as ten might be finished by the end of the month . but the pre - segmentation really helps huge amount . and , , also dan ellis 's innovation of the , the multi - channel to here really helped lot in terms of clearing up hearings that involve overlaps . just out of curiosity asked one of them how long it was taking her , one of these two who has already finished her data set . she said it takes about , , sixty minutes transcription for every five minutes of real time . so it 's about twelve to one , which is what we were thinking . it 's in the range .
H: it 's pretty good .
G: , these still , when they 're finished , , that means that they 're finished with their pass through . they still need to be edited and all but but it 's word level , speaker change , the things that were mentioned . now wanted to mention the , , teleconference had with , , jonathan fiscus . we spoke for an hour and half and , , had an awful lot of things in common . he , , he in indicated to me that they 've that he 's been , looking , , spending lot of time with 'm not quite the connection , but spending lot of time with the atlas system . and that , need to read up on that . and there 's web site that has lots of papers . but it looks to me like that 's the name that has developed for the system that bird and liberman developed for the annotated graphs approach . so what he wants me to do and what we what we will do and , is to provide them with the already transcribed meeting for him to be able to experiment with in this atlas system . and they do have some software , at least that 's my impression , related to atlas and that he wants to experiment with taking our data and putting them in that format , and see how that works out . explained to him in detail the , , conventions that we 're using here in this in this word level transcript . explained , , the reasons that we were not coding more elaborately and the focus on reliability . he expressed lot of interest in reliability . it 's like he 's he 's really up on these things . he 's he 's very independently he asked , "" what about reliability ? "" so , he 's interested in the consistency of the encoding and that thing .
A: can you explain what the atlas 'm not familiar with this atlas system .
G: , at this point adam 's read more in more detail than have on this . need to acquaint myself more with it . but , , there is way of viewing whenever you have coding categories , , and you 're dealing with , taxonomy , then you can have branches that have alternative , , choices that you could use for each of them . and it just ends up looking like graphical representation .
H: is atlas the his annotated transcription graph ? don't remember the acronym . the the one the what you 're referring to , they have this concept of an annotated transcription graph representation . and that 's what based the format that did based it on their work almost directly , in combination with the tei . and so it 's very , very similar . and so it 's it 's data representation and set of tools for manipulating transcription graphs of various types .
E: is this the project that 's , , between , , nist and , , couple of other places ?
G: - . then there 's their web site that has lots of papers . and looked through them and they mainly had to do with this , , this , , tree structure , , annotated tree diagram thing . so , and , , in terms of like the conventions that 'm that 've adopted , it there 's no conflict . and he was , , very interested . and , "" , and how 'd you handle this ? "" and said , "" , , this way "" and and and we had really conversation . , now also wanted to say in different different direction is , brian kingsbury . so , , corresponded briefly with him . he still has an account here . told him he could ssh on and use multi - trans , and have look at the already done , , transcription . and he and he did . and what he said was that , , what they 'll be providing is will not be as fine grained in terms of the time information . and , , that 's , , need to get back to him and , , , explore that little bit more and see what they 'll be giving us in specific , but haven't had time yet .
E: the the folks that they 're , , subcontracting out the transcription to , are they like court reporters
G: get the sense they 're like that . like it 's like pool of somewhat , secretarial don't think that they 're court reporters . don't think they have the special keyboards and that and that type of training . get the sense they 're more secretarial . and that , , , what they 're doing is giving them
E: like medical transcriptionist type people
H: nu - it 's mostly it 's for their speech recognition products ,
E: but aren't they 're
H: that they 've hired these people to do .
E: so they 're hiring them , they 're coming . it 's not service they send the tapes out to .
H: they do send it out but my understanding is that 's all this company does is transcriptions for ibm for their speech product . so most of it 's viavoice , people reading their training material for that .
G: up to now it 's been monologues , , as far my understood . and and what they 're doing is brian himself downloaded so , , adam sent them cd and brian himself downloaded cuz , , , we wanted to have it so that they were in familiar terms with what they wanted to do . he downloaded from the cd onto audio tapes . and he did it one channel per audio tape . so each of these people is transcribing from one channel . and then what he 's going to do is check it , before they go be beyond the first one . check it and , , adjust it , and all that .
E: so each person gets one of these channels
B: so if they hear something off in the distance they don't they just go
H: but that 's , because , , you 'll do all them and then combine them .
E: but there could be problems , right ? with that .
G: it would be difficult to do it that way . really
E: if you 're tran if you got that channel right there
H: no , no . we 're talking about close talking , not the not the desktop .
D: no , close talk .
H: it 'd be really foolish to do otherwise .
G: would think that it would be hard to come out with .
A: it 's hard just playing the , just having played the individual files . and , know you . your voice sounds like . 'm familiar with it 's pretty hard to follow , especially there are lot of words that are so reduced phonetically that make sense when what the person was saying before . it depends where you are in
G: and especially since lot of these
H: but we had this we 've had this discussion many times . and the answer is we don't actually know the answer because we haven't tried both ways .
G: except say that my transcribers use the mixed signal mostly unless there 's huge disparity in terms of the volume on the mix . in which case , , they wouldn't be able to catch anything except the prominent channel , then they 'll switch between .
H: that might change if you wanted really fine time markings .
B: but they 're not giving really fine time markings .
A: actually , are th so are they giving any time markings ? in other words , if
G: have to ask him . and that 's that 's my email to him . that needs to be forthcoming . but but the , did want to say that it 's hard to follow one channel of conversation even if the people , and if you 're dealing furthermore with highly abstract network concepts you 've never heard of so , , one of these people was transcribing the , , networks group talk and she said , "" don't really lot of these abbreviations are , "" "" but put them in parentheses cuz that 's the that 's the convention and "" cuz , if you
H: 'd be curious to look at that .
E: just out of curiosity ,
H: they also all have heavy accents . the networks group meetings are all
E: given all of the effort that is going on here in transcribing why do we have doing it ? why not just do it all ourselves ?
B: it 's historical . some point ago we thought that , it "" boy , we 'd really have to ramp up to do that "" , like we just did , and , , here 's , , , , collaborating institution that 's volunteered to do it . so , that was contribution they could make . in terms of time , money , ? and it still might be good thing
E: 'm just wondering now
A: mar - mari asked me the same question as
E: 'm 'm wondering now if it 's
H: we can talk about more details later .
B: we 'll see . , th , they they 've proceeded along bit . let 's see what comes out of it , and , , , have some more discussions with them .
G: it 's very real benefit having brian involved because of his knowledge of what the how the data need to be used and so what 's useful to have in the format .
H: so , , liz , with the sri recognizer , can it make use of some time marks ?
A: so this is , ,
H: what that means .
A: and actually should say this is what don has , he 's already been really helpful in , , chopping up these so so first of all you , for the sri front - end , we really need to chop things up into pieces that are not too huge . but second of all , in general because some of these channels , 'd say , like , , at least half of them probably on average are are ha are have lot of cross - ta some of the segments have lot of cross - talk . it 's good to get short segments if you 're gonna do recognition , especially forced alignment . don has been taking first stab actually using jane 's first the fir the meeting that jane transcribed which we did have some problems with , and thilo , , told me why this was , but that people were switching microphones around in the very beginning ,
C: no , th . no . they they were not switching them but what they were they were adjusting them , and aft after minute or so it 's it 's way better .
A: so we have to normalize the front - end and , and have these small segments . so we 've taken that and chopped it into pieces based always on your , , cuts that you made on the mixed signal . and so that every speaker has the same cuts . and if they have speech in it we run it through . and if they don't have speech in it we don't run it through . and we base that knowledge on the transcription .
H: on just on the marks .
A: the problem is if we have no time marks , then for forced alignment we actually where , in the signal the transcriber heard that word . if it 's whole conversation and we get long , , , par paragraph of talk ,
H: it 's for the length .
A: how they do this . we actually which piece goes where . and , , with
E: you would need to like forced alignment before you did the chopping ,
A: no , we used the fact that so when jane transcribes them the way she has transcribers doing this , whether it 's with the pre - segmentation or not ,
H: it 's already chunked .
A: they have chunk and then they transcribes the words in the chunk . and maybe they choose the chunk or now they use pre - segmentation and then correct it if necessary . but there 's first chunk and then transcription . then chunk , then transcription . that 's great , cuz the recognizer can
H: it 's all pretty good sized for the recognizer also .
A: right , and it helps that it 's made based on heuristics and human ear . th - but there 's going to be real problem , even if we chop up based on speech silence these , , the transcripts from , we don't actually know where the words were , which segment they belonged to . so that 's what 'm worried about right now .
E: why not do forced alignment ?
H: that 's what she 's saying , is that you can't .
A: if you do forced alignment on something really
H: got six sixty minutes of
A: even if you do it on something really long you need to know you can always chop it up but you need to have reference of which words went with which , , chop .
G: now wasn't that one of the proposals was that ibm was going to do an initial forced alignment ,
B: that they are ,
H: we 'll have to talk to brian .
B: and so we have to have dialogue with them about it . it sounds like liz has some concerns
A: maybe they have some , maybe actually there is some , even if they 're not fine grained , maybe the transcribers , maybe it 's saved out in pieces . that would help . it 's just an unknown right now .
G: need to write to him . it 's like got over - taxed with the timing .
A: right . but the it is true that the segments haven't tried the segments that thilo gave you but the segments that in your first meeting are great . that 's that 's good length .
G: was thinking it would be fun to , if you wouldn't mind , to give us pre - segmentation . maybe you have one already of that first of the meeting that , the first transcribed meeting , the one that transcribed . do you have could you generate pre - segmentation ?
C: but that 's the one where we 're , , trai training on , so that 's little bit it 's little bit at odd to
A: and actually as you get transcripts just , , for new meetings , , we can try the more data we have to try the alignments on , , the better . so it 'd be good for just to know as transcriptions are coming through the pipeline from the transcribers , just to we 're playing around with , parameters on the recognizer , cuz that would be helpful . especially as you get , en more voices .
G: excellent , good .
A: the first meeting had just four people ,
G: liz and spoke at some length on tuesday and and was planning to do just preliminary look over of the two that are finished and then give them to you .
B: that 's great . the other thing , 't remember if we discussed this in the meeting but , , know you and talked about this little bit , there was an issue of , , suppose we get in the , , it 's enviable position although maybe it 's just saying where the weak link is in the chain , we have all the data transcribed and we have these transcribers and we were we 're the we 're still bit slow on feeding at that point we 've caught up and the the , , the weak link is recording meetings . two questions come , is what how do we it 's not really problem at the moment cuz we haven't reached that point but how do we step out the recorded meetings ? and the other one is , , , is there some good use that we can make of the transcribers to do other things ? so , , 't remember how much we talked about this in this meeting
H: we had spoken with them about it .
G: and there is one use that also we discussed which was when , , dave finishes the and maybe it 's already finished the modification to multi - trans which will allow fine grained encoding of overlaps . then it would be very these people would be very good to shift over to finer grain encoding of overlaps . it 's just matter of , , providing so if right now you have two overlapping segments in the same time bin , with the improvement in the database in the , , , in the interface , it 'd be possible to , , , just do click and drag thing , and get the , the specific place of each of those , the time tag associated with the beginning and end of each segment .
B: right , so we talking about three level three things . one one was , we had had some discussion in the past about some very high level labelings ,
G: the types of overlaps
B: types of overlaps , and that someone could do . second was , , somewhat lower level just doing these more precise timings . and the third one is , , just completely wild hair brained idea that have which is that , , if , if we have time and people are able to do it , to take some subset of the data and do some very fine grained analysis of the speech . , marking in some overlapping potentially overlapping fashion , , the value of , , ar articulatory features . just say , , it 's voiced from here to here , there 's it 's nasal from here to here , and . as opposed to doing phonetic , , phonemic and the phonetic analysis , and , , assuming , , articulatory feature values for those things . that 's extremely time - consuming .
E: that would be really valuable .
B: we could do it on some small subset .
G: also if you 're dealing with consonants that would be easier than vowels , would think that , , being able to code that there 's fricative extending from here to here would be lot easier than classifying precisely which vowel that was . vowels are harder .
B: but also it 's just the issue that when you look at the when you look at switchboard very close up there are places where whether it 's consonant or vowel you still have trouble calling it particular phone
H: but just saying what the
B: because it 's , there 's this movement from here to here and and it 's
E: you 're saying remove the high level constraints and go bottom - up .
B: now 'm suggesting articulatory features . maybe there 's there 's even better way to do it but it but that 's , , traditional way of describing these things , actually this might be neat thing to talk to
E: acoustic features versus psychological categories .
B: but something thows for overlapping change of these things and then this would give some more ground work for people who were building statistical models thowed for overlapping changes , different timing changes as opposed to just "" click , you 're now in this state , which corresponds to this speech sound "" and so on .
E: - . - .
A: so this is like gestural , these
B: something like that . actually if we get into that it might be good to , , haul john ohala into this and ask his views on it .
A: but is the goal there to have this on meeting data , so that you can do far field studies of those gestures or is it because you think there 's different actual production in meetings that people use ?
B: no , it 's for that purpose 'm just viewing meetings as being neat way to get people talking naturally . and then you have and then and then it 's natural in all senses ,
E: just source of data ?
B: in the sense that you have microphones that are at distance that , one might have , and you have the close mikes , and you have people talking naturally . and the overlap is just indicative of the fact that people are talking naturally , so so that given that it 's that corpus , if it 's gonna be very useful corpus if you say , we 've limited the use by some of our , , censored choices , we don't have the video , we don't and , but there 's lot of use that we could make of it by expanding the annotation choices . and , , most of the things we 've talked about have been fairly high level , and being bottom - up person maybe we 'd , do some of the others .
A: right . , that would be good .
G: it 's balance . that would be really to offer those things with that wide range .
B: and hopefully someone would make use of it . , people have made lot of use of timit and , due to its markings , and then the switchboard transcription thing , has been very useful for lot of people .
A: that 's true . wanted to , , make pitch for trying to collect more meetings . actually talked to chuck fillmore and they 've what , vehemently said no before but this time he wasn't vehement and he said , "" , liz , come to the meeting tomorrow and try to convince people "" . so 'm gonna try . go to their meeting tomorrow and see if we can try , , to convince them
B: cuz they have something like three or four different meetings ,
A: and they have very interesting meetings from the point of view of very different type of talk than we have here and definitely than the front end meeting , probably .
E: you mean in terms of the topic topics ?
A: yes and in terms of the fact that they 're describing abstract things and , , just dialogue - wise , so 'll try . and then the other thing is , if this is useful , but asked lila if maybe go around and talk to the different departments in this building to see if there 's any groups that , for free lunch , if we can still offer that ,
H: you mean non - icsi ?
A: non - icsi , non - academic , like government people ,
H: the problem is so much of their is confidential . it would be very hard for them .
A: is is it in these departments ?
G: also it does seem like it takes us way out of the demographic . it seems like we had this idea before of having like linguistics students brought down for free lunches
H: tha that 's her point .
G: and that 's idea .
A: right , and then we could also we might try advertising again because it 'd be good if we can get few different non - internal types of meetings and just also more data .
E: does does john ohala have weekly phonetics lab meetings ?
H: and , , if we could get
A: so actually wrote to him and he answered , "" great , that sounds really interesting "" . but never heard back because we didn't actually advertise openly . told asked him privately . and it is little bit of trek for campus folks .
H: you might give them free lunch .
A: so it 's still worthwhile .
H: it would be if we got someone other than me who knew how to set it up and could do the recording so didn't have to do it each time .
G: that 's right .
B: he - he 's supposed he 's supposed to be trained to do it .
A: plus we could also get , student .
H: next week you 're going to do it all .
A: and 'm willing to try to learn . 'm would do my best . the other thing is that there was number of things at the transcription side that , , transcribers can do , like dialogue act tagging ,
H: it 's not that hard .
A: things that are in the speech that are actually something we 're working on for language modeling . and mari 's also interested in it , so if you wanna process utterance and the first thing they say is , "" "" , and that "" "" is coded as some interrupt tag . and things like that ,
G: some of that can be li done lexically .
A: lot of it can be done
G: and also they are doing disfluency tagging to some degree already .
A: great . so lot of this there 's second pass and don't really would exist in it . but there 's definitely second pass worth doing to maybe encode some kinds of , , is it question or not , that maybe these transcribers could do .
G: they 'd be really good . they 're they 're very consistent .
A: that 'd be great .
G: wanted to whi while we 're , so , to return just briefly to this question of more meeting data , have two questions . one of them is , , jerry feldman 's group , they , , are they know that they recorded one meeting . are they willing ?
B: they 're open to it . , all these things are we should go beyond , , icsi but , , there 's lot of happening at icsi that we 're not getting now that we could .
A: that we could .
B: so it 's just
A: th these people had said "" no "" twice already . if that 's not the case then
B: no , no . no . so th there was the thing in fillmore 's group but even there he hadn't what he 'd said "" no "" to was for the main meeting . but they have several smaller meetings week , and , , the notion was raised before that could happen . and it just , it just didn't come together
E: and the other thing too is when they originally said "" no "" they didn't know about this post - editing capability thing .
A: right . that was big fear .
G: that 's important .
B: so there 's possibilities there . jerry 's group , yes . there 's there 's , , the networks group , do they still meeting regularly
H: if they meet regularly or not but they are no longer recording .
B: but , ha have they said they don't want to anymore
H: ugh , what was his name ? when with him gone , it sorta trickled off .
B: so they 're down to three or four people
H: they and they stopped
B: but three or four people is .
G: we might be able to get the administration
H: he was my contact , so need to find out who 's running it now .
G: see that lila has luncheon meeting in here periodically .
A: , it one thing that would be and this it sounds bizarre but , 'd really like to look at to get some meetings where there 's little bit of heated discussion , like ar arguments and or emotion , and things like that . and so was thinking if there 's any like berkeley political groups . that 'd be perfect . some group , "" yes , we must ""
H: who 's willing to get recorded and distributed ?
F: don't think the more political argumentative ones would be willing to
B: with with potential use from the defense department .
A: no , but maybe stu student , , groups or , , film - makers , or som something little bit colorful .
B: , th there 's problem there in terms of , , the commercial value of st ,
G: there is this problem though , that if we give them the chance to excise later we might end up with like five minutes out of of one hour
D: film - maker .
A: and don't mean that they 're angry
G: of yes . really .
A: but just something with some more variation in prosodic contours and would be neat . so if anyone has ideas , 'm willing to do the leg work to go try to talk to people but don't really know which groups are worth pursuing .
B: it it turned out to be bit of problem .
G: and had one other one other aspect of this which is , , , jonathan fiscus expressed primar major interest in having meetings which were all english speakers . now he wasn't trying to shape us in terms of what we gather but that 's what he wanted me to show him . so 'm giving him our , our initial meeting because he asked for all english . and we don't have lot of all english meetings right now .
B: of all native speakers .
E: did he mean , did he mean and non - british ?
C: the all native .
G: that 's what , .
H: if he meant and non - british we have zero .
G: he doesn't care . no . , , british is .
E: he said british was ?
H: british is english ?
G: different varieties of english .
C: ooo , ooo .
B: don't don't he didn't say that
G: native speaking . native speaking english .
H: bet he meant native speaking american .
B: bet he did .
H: so , why would he care ?
B: remember wh remember study
A: was thinking , knowing the , , national institute of standards , it is all
B: remember study that bbn did where they trained on this was in wall street journal days , they trained on american english and then they tested on , , different native speakers from different areas . the worst match was people whose native tongue was mandarin chinese . the second worst was british english .
G: that 's funny .
B: so it 's , ,
G: and so that would make sense .
B: the german was much better ,
C: ooo , ooo .
G: didn't have the context of that .
B: so , , if he 's if he 's thinking in terms of recognition technology he would probably want , american english ,
G: all america , .
H: wonder if we have any .
B: it it , unless we 're gonna train with whole bunch of
G: that the feldman 's meetings tend to be more that way , feel like they have
H: and maybe there are few of with us where it was and before jose started coming ,
B: it 's pretty tough , , this group . . so , , what about what about people who involved in some artistic endeavor ? film - making like that .
A: exactly , that 's what was
B: you 'd think like they would be
D: film - maker .
A: something where there is actually discussion where there 's no right or wrong answer but it 's matter of opinion thing . anyway , if you if you have ideas
G: it 's be fun .
H: rasta . plp . rasta . plp .
F: we can just discu we can just have political discussion one day .
E: any department that calls itself science
F: could make that pretty
H: like computer science .
G: we could get julia child .
A: 'm 'm actually serious because , , , we have the set up here
B: know you are .
A: and that has chance to give us some very interesting fun data . if anyone has ideas , if any groups that are ,
H: had asked some of the students at the business school .
A: student groups like clubs , things like that .
B: put little ad up saying , "" come here and argue "" .
A: "" if you 're really angry at someone use our conference room . ""
H: the business school . the business school might be good . actually spoke with some students up there and they they expressed willingness back when they thought they would be doing more with speech . but when they lost interest in speech they also stopped answering my email about other ,
A: or people who are really
B: they could have discussion about te
H: we should probably bleep that out .
B: about tax cuts .
F: heard that at cal tech they have special room someone said that they had special room to get all your frustrations out that you can go to and like throw things and break things .
B: now that is not actually what we
F: so we can like post
H: th - that 's not what we want .
F: no , not to that extent
A: far field mikes can pick up where they threw on the wall .
B: but we don't want them to throw the far field mikes is the thing .
H: that 's right . "" throw everything in that direction . ""
G: it 'd be fun to get like visit from the
H: there was dorm room at tech that , , someone had coated the walls and the ceiling , and , , the floor with mattresses . the entire room .
B: had as my fourth thing here processing of wave forms . what did we mean by that ? remember @ @ ?
H: liz wanted to talk about methods of improving accuracy by doing pre - processing .
G: pre - processing .
B: you already did that .
A: but that , , it would be helpful if stay in the loop somehow with , , people who are doing any post - processing , whether it 's to separate speakers or to improve the signal - to - noise ratio , or both , that we can try out as we 're running recognition . so , is that who else is work dan ellis and you
B: and dave gel - gelbart again , he 's he 's interested we 're look starting to look at some echo cancellation things .
H: am not how much that 's an issue with the close talking mikes , but who knows ?
B: let 's isn't that what you want no , so no , wha what you what you want when you 're saying improving the wave form you want the close talking microphone to be better . and the question is to to what extent is it getting hurt by , by any room acoustics or is it just , given that it 's close it 's not problem ?
A: it doesn't seem like big room acoustics problems to my ear but 'm not an expert . it seems like problem with cross - talk .
H: bet with the lapel mike there 's plenty , , room acoustic
A: that that may be true .
H: but the rest is cross - talk .
A: but how good it can get either by those the those methods that 's true .
H: so it 's just , what you said , cross - talk .
A: all is just that as as this pipeline of research is going on we 're also experimenting with different asr , , techniques . and so it 'd be good to know about it .
E: so the problem is like , , on the microphone of somebody who 's not talking they 're picking up signals from other people and that 's causing problems ?
A: right , although if they 're not talking , using the inhouse transcriptions , were because the no one transcribed any words there and we throw it out . but if they 're talking and they 're not talking the whole time , so you get some speech and then "" - "" , and some more speech , so that whole thing is one chunk . and the person in the middle who said only little bit is picking up the speech around it , that 's where it 's big problem .
G: this does like seem like it would relate to some of what jose 's been working on as , the encoding of the and and he also , he was
A: right . exactly .
G: was was trying to remember , you have this interface where you you ha you showed us one time on your laptop that you had different visual displays as speech and nonspeech events .
D: may only display the different colors for the different situation . but , , for me and for my problems , is is enough . because , , it 's possible , , in simp sample view , , to , nnn , to compare with with the segment , the assessment what happened with the different parameters . and only with different bands of color for the , , few situation , , consider for acoustic event is enough to @ @ . see that , , you are considering now , , very sophisticated , , ehm , , @ @ set of , , graphic , ehm , si symbols to transcribe . because , , before , you are talking about the possibility to include in the transcriber program , , set of symbols , of graphic symbol to to mark the different situations during the transcription during the transcription .
G: you 're saying so , , symbols for differences between laugh , and sigh , and and slam the door and ?
D: . the the symbols , you talk of before .
G: or some other thing ? wouldn't say symbols so much . the the main change that that see in the interface is just that we 'll be able to more finely , time things . but also st there was another aspect of your work that was thinking about when was talking to you which is that it sounded to me , liz , as though you and , , maybe didn't understand this , but it sounded to me as though part of the analysis that you 're doing involves taking segments which are of particular type and putting them together . and th so if you have like , speech from one speaker , then you cut out the part that 's not that speaker , and you combine segments from that same speaker to and run them through the recognizer . is that right ?
A: we try to find as close of start and end time of as we can to the speech from an individual speaker , because then we 're more guaranteed that the recognizer will for the forced alignment which is just to give us the time boundaries , because from those time boundaries then the plan is to compute prosodic features . and the more space you have that isn't the thing you 're trying to align the more errors we have . so , , that it would help to have either pre - processing of signal that creates very good signal - to - noise ratio , which how possible this is for the lapel , or to have very to have closer , , time , synch times , , around the speech that gets transcribed in it , or both . and it 's just open world right now of exploring that . so wanted to see , , on the transcribing end from here things look good . the ibm one is more it 's an open question right now . and then the issue of like global processing of some signal and then , , before we chop it up is yet another way we can improve things in that .
E: what about increasing the flexibility of the alignment ? do you remember that thing that michael finka did ? that experiment he did while back ?
A: right . you can , the problem is just that the acoustic when the signal - to - noise ratio is too low , , you 'll get , an alignment with the wrong duration pattern
E: so that 's the problem , is the signal - to - noise ratio .
A: it 's not the fact that you have like what he did is allow you to have , , words that were in another segment move over to the at the edges of segmentations .
E: or even words inserted that weren't weren't there .
A: right , things near the boundaries where if you got your alignment wrong cuz what they had done there is align and then chop . and this problem is little bit more global . it 's that there are problems even in inside the alignments , because of the fact that there 's enough acoustic signal there for the recognizer to eat , as part of word . and it tends to do that . but we probably will have to do something like that in addition . anyway . so , , bottom line is just wanted to make be aware of whoever 's working on these signal - processing techniques for , , detecting energies , because that 'll really help us .
B: tea has started out there suggest we run through our digits we 're done .
","The Berkeley Meeting Recorder group discussed recording equipment and setup issues , recent developments in the transcription effort , other potential types of tagging to be assigned to transcribers , and the post-processing of waveforms.
The discussion was largely focused on efforts to facilitate transcriptions , including the improvement of strategies for transcribing overlapping speech , and achieving greater uniformity in the type of equipment used during recordings and the manner in which recording devices are worn by speakers.
To achieve greater uniformity in across-speaker recording conditions , the group decided to purchase three additional head-mounted microphones.
Future work will include recording more varied meeting data from non-ICSI discussion groups.
It was proposed by speaker fe016 that better communication be established between researchers involved in post-processing of the waveform and ASR.
Use of dissimilar microphones adds an extra , unwanted variable to individual speaker recordings.
Similarly , differences in the type of recording equipment used and the manner in which microphones are worn by speakers causes problems for the transcription effort.
Setting up a microphone array and performing video recordings ( in a possible collaboration with NIST ) are problematic due to the types of changes in infrastructure they require.
IBM's single-channel approach to transcriptions may pose problems for the post-processing of waveforms and forced alignments , as the group foresees difficulties in referencing chopped segments back to the original times/locations from which they were extracted.
Another post-processing problem involves cross-talk , and , in particular , situations in which a speaker whose contributions to the discussion are relatively sparse but whose microphone picks up signals from the other speakers.
Modifications are being made to multi-trans to enable tight time markings at the boundaries of overlapping speech segments , and facilitate the transcription of such segments.
Pre-segmentation continues to be very beneficial to the transcription effort.
Work by speaker mn014 is in progress to compare the energies of different channels for detecting speech/non-speech portions , facilitating transcriptions,and potentially providing speaker identification information.
Efforts are being developed to create a cross-correlation setup linking recorded data with a map of where individual speakers were seated.
The transcriber pool has been performing within the expected range of work completed per the amount of time spent transcribing.
IBM has a team of people employed to transcribe meeting data , and who are transcribing single versus multiple channels.
The group discussed the potential for assigning additional tasks to ICSI's transcriber pool , including tagging more fine-grained acoustic information , and discourse and disfluency tagging.
"
ami_abstractive_summary,Bro019.txt,"C: is it the twenty - fourth ?
F: now we 're on .
A: chuck , is the mike type wireless
F: for you it is .
C: we we abandoned the lapel because they were not too not too hot , not too cold , they were , they were , far enough away that you got more background noise , , and and but they weren't so close that they got quite the , the really good no , th 'm saying that wrong . they were not so far away that they were really good representative distant mikes , but on the other hand they were not so close that they got rid of all the interference . so it was no didn't seem to be good point to them . on the other hand if you only had to have one mike in some ways you could argue the lapel was good choice , precisely because it 's in the middle . there 's , some kinds of junk that you get with these things that you don't get with the lapel little mouth clicks and breaths and are worse with these than with the lapel , given the choice we there seemed to be very strong opinions for , getting rid of lapels .
A: the mike number is
F: your mike number 's written on the back of that unit there . and then the channel number 's usually one less than that . it - it 's one less than what 's written on the back of your so you should be zero , actually . for your , channel number .
C: and you should do lot of talking so we get lot more of your pronunciations . no , they don't don't have have any indian pronunciations .
F: so what we usually do is , we typically will have our meetings and then at the end of the meetings we 'll read the digits . everybody goes around and reads the digits on the bottom of their forms . we 're this is session - nineteen .
C: if you say so . do we have anything like an agenda ? what 's going on ?
F: sunil 's here for the summer ?
C: sunil 's here for the summer , so , one thing is to talk about kick off meeting and then just , , progress reports individually , and then , plans for where we go between now and then , .
F: could say few words about , some of the , compute that 's happening around here , so that people in the group know .
C: why don't you start with that ?
F: so we just put in an order for about twelve new machines , , to use as compute farm . we ordered , sun - blade - one - hundreds , 'm not exactly how long it 'll take for those to come in , but , , in addition , we 're running so the plan for using these is , , we 're running - make and customs here and andreas has gotten th , fixed up and up to speed . and he 's got number of little utilities that make it very easy to , run things using - make and customs . you don't actually have to write - make scripts and things like that . and send an email around or , maybe should do an faq on the web site about it .
C: how about an email that points to the faq , what 'm saying ? so that you can
F: there 's command , , that you can use called "" run command "" . "" run dash command "" , "" run hyphen command "" . and , if you say that and then some job that you want to execute , , it will find the fastest currently available machine , and export your job to that machine , and and run it there and it 'll duplicate your environment . you can try this as simple test with , the command . so you can say "" run dash command "" , and , , it 'll actually export that ls command to some machine in the institute , and , do an ls on your current directory . so , substitute ls for whatever command you want to run , and and that 's simple way to get started using this . and , so , soon , when we get all the new machines up , , then we 'll have lots more compute to use . now th one of the things is that , each machine that 's part of the - make and customs network has attributes associated with it . attributes like how much memory the machine has , what its speed is , what its operating system , and when you use something like "" run command "" , you can specify those attributes for your program . if you only want your thing to run under linux , you can give it the linux attribute , and then it will find the fastest available linux machine and run it on that . you can control where your jobs go , to certain extent , all the way down to an individual machine . each machine has an attribute which is the name of itself . so you can give that as an attribute and it 'll only run on that . if there 's already job running , on some machine that you 're trying to select , your job will get queued up , and then when that resource , that machine becomes available , your job will get exported there . there 's lot of features to it and it kinda helps to balance the load of the machines right now andreas and have been the main ones using it and we 're . the sri recognizer has all this - make customs built into it .
C: so as understand , , he 's using all the machines and you 're using all the machines , is the rough division of
F: , got started using the recognizer just recently fired off training job , and then fired off recognition job and get this email about midnight from andreas saying , "" , are you running two trainings simultaneously my my jobs are not getting run . "" so had to back off little bit . soon as we get some more machines then then we 'll have more compute available . that 's just quick update about what we 've got .
G: have have question about the , parallelization ? so , , let 's say have like , thousand little jobs to do ? how do do it with "" run command "" ?
F: you could write script , which called run command on each sub - job but you probably wanna be careful with that because , you don't wanna saturate the network . you should you should probably not run more than , say ten jobs yourself at any one time , just because then it would keep other people
G: too much file transfer and .
F: it 's not that so much as that , , with if everybody ran fifty jobs at once then it would just bring everything to halt and , , people 's jobs would get delayed , so it 's sharing thing . so you should try to limit it to somet sometim some number around ten jobs at time . so if you had script that had thousand things it needed to run , , you 'd somehow need to put some logic in there if you were gonna use "" run command "" , , to only have ten of those going at time . and , then , when one of those finished you 'd fire off another one .
C: remember forget whether it was when the rutgers or hopkins workshop , remember one of the workshops was at there were everybody was real excited cuz they got twenty - five machines and there was some - make like thing that sit sent things out . so all twenty - five people were sending things to all twenty - five machines and things were lot less efficient than if you 'd just use your own machine .
F: you have to be little bit careful . but , you can also if you have that level of parallelization , and you don't wanna have to worry about writing the logic in perl script to take care of that , you can use , - make
G: just do - make .
F: and you write make file that , your final job depends on these one thousand things , and when you run - make , , on your make file , you can give it the dash capital and then number , and that number represents how many , machines to use at once . and then it 'll make that it never goes above that . get some documentation .
D: so it 's it 's not systematically queued . all the jobs are running . if you launch twenty jobs , they are all running .
F: if you "" run command "" , that mentioned before , is doesn't know about other things that you might be running . so , it would be possible to run hundred run jobs at once , and they wouldn't know about each other . but if you use - make , then , it knows about all the jobs that it has to run and it can control , , how many it runs simultaneously .
C: so "" run command "" doesn't use - make , or ?
F: it uses "" export "" underlyingly . but , if you it 's meant to be run one job at time ? so you could fire off thousand of those , and it doesn't know any one of those doesn't know about the other ones that are running .
C: so why would one use that rather than - make ?
F: if you have , like , , if you didn't wanna write - make script and you just had , an htk training job that is gonna take , six hours to run , and somebody 's using , , the machine you typically use , you can say "" run command "" and your htk thing and it 'll find another machine , the fastest currently available machine and run your job there .
C: now , does it have the same behavior as - make , which is that , , if you run something on somebody 's machine and they come in and hit key then it
F: so some of the machines at the institute , , have this attribute called "" no evict "" . and if you specify that , in one of your attribute lines , then it 'll go to machine which your job won't be evicted from . but , the machines that don't have that attribute , if job gets fired up on that , which could be somebody 's desktop machine , and they were at lunch , they come back from lunch and they start typing on the console , then your machine will get evicted your job will get evicted from their machine and be restarted on another machine . automatically . so which can you to lose time , if you had two hour job , and it got halfway through and then somebody came back to their machine and it got evicted . so . if you don't want your job to run on machine where it could be evicted , then you give it the minus the attribute , , "" no evict "" , and it 'll pick machine that it can't be evicted from .
C: remember always used to be an issue , maybe it 's not anymore , that if you if something required if your machine required somebody hitting key in order to evict things that are on it so you could work , but if you were logged into it from home ? and you weren't hitting any keys ? cuz you were , home ?
F: 'm not how that works . it seems like andreas did something for that .
C: we can ask him sometime .
F: whether it monitors the keyboard or actually looks at the console tty , so maybe if you echoed something to the , dev console .
C: you probably wouldn't ordinarily , though . you probably wouldn't ordinarily . you 're at home and you 're trying to log in , and it takes forever to even log you in , and you probably go , "" screw this "" ,
F: 'm not about that one .
A: need little orientation about this environment and scr how to run some jobs here because never did anything so far with this emissions maybe 'll ask you after the meeting .
F: and also , stephane 's really good resource for that if you can't find me . especially with regard to the aurora . he he knows that better than do .
C: why don't we , sunil since you 're haven't been at one of these yet , why don't yo you tell us what 's what 's up with you ? wh - what you 've been up to , hopefully .
A: 'll start from the post aurora submission maybe . after the submission the what 've been working on mainly was to take other submissions over their system , what they submitted , because we didn't have any speech enhancement system in ours . and first tried just lda . and then found that if combine it with lda , it gives @ @ improvement over theirs .
F: are are you saying lda ?
A: just the lda filters . plug in take the cepstral coefficients coming from their system and then plug in lda on top of that . but the lda filter that used was different from what we submitted in the proposal . what did was took the lda filter 's design using clean speech , mainly because the speech is already cleaned up after the enhancement so , instead of using this , , narrow band lda filter that we submitted , got new filters . that seems to be giving , improving over their , system . but , not very significantly . and , that was showing any improvement over final by plugging in an lda . so then after that added , on - line normalization also on top of that . and that there also found that have to make some changes to their time constant that used because th it has mean and variance update time constant and which is not suitable for the enhanced speech , and whatever we try it on with proposal - one . didn't didn't play with that time constant lot , found that have to reduce the value have to increase the time constant , or reduce the value of the update value . that 's all found so have to . the other thing what tried was , , , took the baseline and then ran it with the endpoint inf th information , just the aurora baseline , to see that how much the baseline itself improves by just supplying the information of the the speech and nonspeech . found that the baseline itself improves by twenty - two percent by just giving the wuh .
C: can you back up second , my mind wandered . ad - ad when you added the on - line normalization and , things got better again ? or is it ?
A: no , things didn't get better with the same time constant that we used .
C: did it not ? no , no . with different time constant .
A: with the different time constant found that didn't get an improvement over not using on - line normalization , because found that would have change the value of the update factor .
C: no you didn't ,
A: but didn't play it with play quite bit to make it better than . so , it 's still not the on - line normalization didn't give me any improvement . so stopped there with the , speech enhancement . the the other thing what tried was the adding the , endpoint information to the baseline and that itself gives like twenty - two percent because the second the new phase is going to be with the endpointed speech . and just to get feel of how much the baseline itself is going to change by adding this endpoint information , , , use
F: so people won't even have to worry about , , doing speech - nonspeech then .
A: that 's , that 's what the feeling is like . they 're going to give the endpoint information .
C: the issue is that people do that anyway , everybody does that , and they wanted to see , given that you 're doing that , what are the best features that you should use . clearly they 're interact . so that entirely agree with it . but but it might be in some ways it might be better to rather than giving the endpoints , to have standard that everybody uses and then interacts with . but , . it 's it 's still someth reasonable .
F: so , are people supposed to assume that there is are are people not supposed to use any speech outside of those endpoints ? or can you then use speech outside of it for estimating background noise and things ?
A: that is that is where the consensus is . like you will you 'll be given the information about the beginning and the end of speech but the whole speech is available to you .
C: so it should make the spectral subtraction style things work even better , because you don't have the mistakes in it .
A: so that the baseline itself it improves by twenty - two percent . found that in one of the speechdat - car cases , that like , the spanish one improves by just fifty percent by just putting the endpoint . you don't need any further speech enhancement with fifty .
F: so the baseline itself improves by fifty percent .
A: by fifty percent .
C: so it 's it 's gonna be harder to beat that actually .
A: so that is when , the qualification criteria was reduced from fifty percent to something like twenty - five percent for - matched . and they have they have actually changed their qualification criteria now . after that , went home had vacation fo for four weeks .
C: no , that 's that 's good update .
A: and came back and started working on , some other speech enhancement algorithm . so from the submission what found that people have tried spectral subtraction and wiener filtering . these are the main , approaches where people have tried , so just to just to fill the space with some few more speech enhancement algorithms to see whether it improves lot , 've been working on this , signal subspace approach for speech enhancement where you take the noisy signal and then decomposing the signal and the noise subspace and then try to estimate the clean speech from the signal plus noise subspace . so , 've been actually running some so far 've been trying it only on matlab . have to to test whether it works first or not and then 'll port it to and 'll update it with the repository once find it giving any some positive result .
C: so you you so you said one thing want to jump on for second . so so now you 're you 're getting tuned into the repository thing that he has here and so we 'll have single place where the is . so maybe , just briefly , you could remind us about the related experiments . cuz you did some that you talked about last week , where you were also combining something both of you were both combining something from the , french telecom system with the whether it was system one or system two ,
D: it was system one . the main thing that we did is just to take the spectral subtraction from the france telecom , which provide us some speech samples that are , with noise removed .
C: so let me let me just stop you there . so then , one distinction is that , you were taking the actual france telecom features and then applying something to
A: there is slight different . which are extracted at the handset because they had another back - end blind equalization
C: but that 's what . 'm not being 'm not being clear . what was you had something like cepstra , right ? and so one difference is that , you were taking spectra .
D: but it 's the exactly the same thing because on the heads , handset they just applied this wiener filter and then compute cepstral features ,
A: the cepstral the difference is like there may be slight difference in the way because they use exactly the baseline system for converting the cepstrum once you have the speech . if we are using our own code for th that could be the only difference . there is no other difference .
C: but you got some different result . so 'm trying to understand it .
D: we should , have table with all the result because , don't exactly are your results ? but so we did this , and another difference is that we just applied , proposal - one system after this without , with our modification to reduce the delay of the lda filters , there are slight modifications , but it was the full proposal - one . in your case , if you tried just putting lda , then maybe on - line normalization ?
A: af - after that added on - line normalization ,
D: so we just tried directly to just , keep the system as it was when we plug the spectral subtraction it improves , signif significantly . but , what seems clear also is that we have to retune the time constants of the on - line normalization . because if we keep the value that was submitted , it doesn't help . you can remove on - line normalization , or put it , it doesn't change anything . , as long as you have the spectral subtraction . but , you can still find some optimum somewhere , and we where exactly
C: so it sounds like you should look at some tables of results and see where where the where they were different and what we can learn from it .
A: without any change .
B: it 's the new .
D: with with changes , because we change it the system to have
A: the new lda filters .
D: there are other things that we finally were shown to improve also like , the sixty - four hertz cut - off . it doesn't seem to hurt on ti - digits , finally . maybe because of other changes . there are some minor changes , and , right now if we look at the results , it 's , , always better than it seems always better than france telecom for mismatch and high - mismatch . and it 's still slightly worse for - matched . but this is not significant . but , the problem is that it 's not significant , but if you put this in the , mmm , , spreadsheet , it 's still worse . even with very minor even if it 's only slightly worse for - matched . and significantly better for hm . don't 's importa important because when they will change their metric , mainly because of , when you you plug the , frame dropping in the baseline system , it will improve lot hm , and , what will happen . but , the different contribution , , for the different test set will be more even .
A: because the your improvement on hm and will also go down significantly in the spreadsheet but the - matched may still the - matched may be the one which is least affected by adding the endpoint information . and hm are going to be hugely affected by it . but they the everything is like , that 's how they reduce why they reduce the qualification to twenty - five percent or some something on .
C: but are they changing the weighting ?
A: they are going ahead with the same weighting . so there 's nothing on
C: don't understand that . haven't been part of the discussion , it seems to me that the - matched condition is gonna be unusual , in this case . because , , you don't actually have good matches ordinarily for what any @ @ particular person 's car is like , it seems like something like the middle one is more natural . so why the - matched is
A: but actually the - matched the - matched condition is not like , , the one in ti - digits where , you have all the training , , conditions exactly like replicated in the testing condition also . it 's like , this is not calibrated by snr . the - matched has also some mismatch in that which is other than the
C: the wa matched has mismatch ?
A: has also some slight mismatches , unlike the ti - digits where it 's like prefectly matched
F: perfect to match .
A: because it 's artificially added noise . but this is natural recording .
C: so remind me of what - matched meant ?
A: the the - matched is like
C: you 've told me many times .
A: the - matched is defined like it 's seventy percent of the whole database is used for training and thirty percent for testing .
D: so it means that if the database is large enough , it 's matched .
A: it 's it 's
D: in each set you have range of conditions
C: unless they deliberately chose it to be different , which they didn't because they want it to be - matched , so it 's so it 's saying if you
F: it 's it 's not guaranteed though .
C: it 's not guaranteed .
A: because the the main major reason for the the main mismatch is coming from the amount of noise and the silence frames and all those present in the database actually .
C: again , if you have enough if you have enough so it 's it 's saying , so you much as you train your dictation machine for talking into your computer , , you have car , and so you drive it around bunch and record noise conditions , , and then don't think that 's very realistic , they 're saying that if you were company that was selling the commercially , that you would have bunch of people driving around in bunch of cars , and you would have something that was roughly similar and maybe that 's the argument , but 'm not buy it , what else is going on ?
D: we are playing we are also playing , trying to put other spectral subtraction mmm , in the code . it would be very simple spectral subtraction , on the , mel energies which already tested but without the frame dropping actually , and it 's important to have frame dropping if you use spectral subtraction .
F: is it is spectral subtraction typically done on the after the mel , , scaling or is it done on the fft bins ? does it matter ,
D: it 's both , cases can so - some of the proposal , , we 're doing this on the bin on the fft bins , others on the , mel energies . you can do both , but not tell you what 's which one might be better
A: if you want to reconstruct the speech , it may be good idea to do it on fft bins . but for speech recognition , it may not . it may not be very different if you do it on mel warped or whether you do it on fft . so you 're going to do linear weighting anyway after that . so , it may not be really big different .
D: it gives something different , but what are the , pros and cons of both .
A: the other thing is like when you 're putting in speech enhancement technique , is it like one stage speech enhancement ? because everybody seems to have mod two stages of speech enhancement in all the proposals , which is really giving them some improvement . they just do the same thing again once more . and so , there 's something that is good about doing it to cleaning it up once more .
D: it might be . so maybe in my implementation should also try to inspire me from this thing
C: the other thing would be to combine what you 're doing . maybe one or one or the other of the things that you 're doing would benefit from the other happening first . so he 's doing signal subspace thing , maybe it would work better if you 'd already done some simple spectral subtraction , or maybe vi maybe the other way around ,
A: so 've been thinking about combining the wiener filtering with signal subspace , just to see all some such permutation combination to see whether it really helps or not .
C: 'm ignorant about this , since wiener filter also assumes that you 're that you 're adding together the two signals , how is how is that differ from signal subspace ?
A: the signal subspace ? the signal subspace approach has actually an in - built wiener filtering in it . it is like kl transform followed by wiener filter . is the signal is signal substrate .
C: so the difference is the kl .
A: so , the different the the advantage of combining two things is mainly coming from the signal subspace approach doesn't work very if the snr is very bad . it works very poorly with the poor snr conditions , and in colored noise .
C: so essentially you could do simple spectral subtraction , followed by kl transform , followed by
A: it 's it 's cascade of two
C: in general , you don't you don't wanna othorg orthogonalize if the things are noisy . that was something that , herve and were talking about with , the multi - band , that if you 're converting things to from , bands , groups of bands into cepstral coef , local local cepstral coefficients that it 's not that great to do it if it 's noisy .
A: so that 's one reason maybe we could combine some something to improve snr little bit , first stage , and then do something in the second stage which could take it further .
D: what was your point about colored noise there ?
A: the colored noise the the signal subspace approach has , it actually depends on inverting the matrices . the covariance matrix of the noise . so if it is not positive definite , it has it 's it doesn't behave very if it is not positive definite it works very with white noise because we know for that it has positive definite .
C: so you should do spectral subtraction and then add noise .
A: so the way they get around is like they do an inverse filtering , first of the colo colored noise and then make the noise white , and then finally when you reconstruct the speech back , you do this filtering again .
C: was only half kidding . if you you do the spectral subtraction , that also gets rid and then you then add little bit noise addition that what jrasta does , in way . if you look at what jrasta doing essentially it 's equivalent to adding little adding little noise , in order to get rid of the effects of noise .
D: so there is this . we find some people so that , agree to maybe work with us , and they have implementation of vts techniques so it 's , vector taylor series that are used to mmm , to model the transformation between clean cepstra and noisy cepstra . if you take the standard model of channel plus noise , , it 's it 's nonlinear , transformation in the cepstral domain . there is way to approximate this using , first - order or second - order taylor series it can be used for , getting rid of the noise and the channel effect .
C: who is doing this ?
D: working in the cepstral domain ? so there is one guy in grenada ,
B: one of my friend .
D: and another in , lucent that met at icassp .
C: who 's the guy in grenada ?
B: jose carlos segura .
A: this vts has been proposed by cmu ? is it is it the cmu ?
B: originally the idea was from cmu .
D: it 's again different thing that could be tried .
C: so at any rate , you 're looking general , , standing back from it , looking at ways to combine one form or another of , noise removal , , with these other things we have , looks like worthy thing to do here .
D: but for there 's required to that requires to re - check everything else , and re - optimize the other things for the on - line normalization may be the lda filter .
C: one of the seems like one of the things to go through next week when hari 's here , cuz hari 'll have his own ideas too or not next week , week and half , will be go through these alternatives , what we 've seen so far , and come up with some game plans . so , one way would he here are some alternate visions . one would be , you look at few things very quickly , you pick on something that looks like it 's promising and then everybody works really hard on the same different aspects of the same thing . another thing would be to have to pick two pol two plausible things , and , have two working things for while until we figure out what 's better , he 'll have some ideas on that too .
A: the other thing is to , most of the speech enhancement techniques have reported results on small vocabulary tasks . but we going to address this wall street journal in our next stage , which is also going to be noisy task so very few people have reported something on using some continuous speech . so , there are some was looking at some literature on speech enhancement applied to large vocabulary tasks spectral subtraction doesn't seems to be the thing to do for large vocabulary tasks . always people have shown improvement with wiener filtering and maybe subspace approach over spectral subtraction everywhere . but if we if we have to use simple spectral subtraction , we may have to do some optimization to make it work @ @ .
C: so they 're making there somebody 's generating wall street journal with additive artificially added noise ? like what they did with ti - digits , and ?
A: guenter hirsch is in charge of that . guenter hirsch and ti . roger , maybe in charge of .
C: and then they 're they 're , generating htk scripts to
A: there are they have there is no if they are converging on htk or are using some mississippi state ,
C: mis - mississippi state maybe ,
A: 'm not about that .
C: so that 'll be little task in itself . it 's true for the additive noise , artificially added noise we 've always used small vocabulary too . but for there 's been noisy speech this larv large vocabulary that we 've worked with in broadcast news . so we did the broadcast news evaluation and some of the focus conditions were noisy but we but we didn't do spectral subtraction . we were doing our funny , right ? we were doing multi , multi - stream and . but it , , we di we did helped . it , did something . now we have this , meeting data . like the we 're recording right now , that we have , for the , the quote - unquote noisy data there is just noisy and reverberant actually . it 's the far field mike . and , we have , the digits that we do at the end of these things . and that 's what most again , most of our work has been done with that , with , connected digits . but , we have recognition now with some of the continuous speech , large vocabulary continuous speech , using switchboard , switchboard recognizer , no training , from this , just plain using the switchboard .
A: you just take the switchboard trained ?
C: that 's that 's what we 're doing , now there are some adaptation though , that , andreas has been playing with , but we 're hop actually , dave and were just talking earlier today about maybe at some point not that distant future , trying some of the techniques that we 've talked about on , , some of the large vocabulary data . no one had done yet done test one on the distant mike using , the sri recognizer
F: not that know of .
C: cuz everybody 's scared . you 'll see little smoke coming up from the cpu trying to do it , but , you 're right that that 's real good point , that , we , , , what if any of these ta that 's why they 're pushing that in the in the evaluation . anything else going on ? at you guys ' end ,
B: don't have good result , with the inc including the new parameters , don't have good result . are similar or little bit worse .
A: with what other new new parameter ?
G: you 're talking about your voicing ?
C: so maybe you probably need to back up bit seeing as how sunil ,
B: tried to include another new parameter to the traditional parameter , the coe the cepstrum coefficient , that , like , the auto - correlation , the - zero and - one over - zero and another estimation of the var the variance of the difference for of the spec si , spectrum of the signal and the spectrum of time after filt mel filter bank .
A: didn't get it .
B: the first you have the sp the spectrum of the signal , and you have the on the other side you have the output of the mel filter bank . you can extend the coefficient of the mel filter bank and obtain an approximation of the spectrum of the signal . found difference at the variance of this different because , suppose we think that if the variance is high , maybe you have , noise . and if the variance is small , maybe you have , speech . the idea is to found another feature for discriminate between voice sound and unvoice sound . and we try to use this new feature . need to change to obtain this new feature need to change the size the window size . of the of the analysis window size , to have more information .
A: make it longer .
B: sixty - two point five milliseconds . do did two type of experiment to include this feature directly with the with the other feature and to train neural network to select it voice - unvoice - silence and to concat this new feature . but the result are with the neural network have more or less the same result .
A: as using just the cepstrum ,
B: sometime it 's worse , sometime it 's little bit better , but not significantly .
A: is it with ti - digits , or with ?
B: no , work with , italian and spanish . and if don't use the neural network , and use directly the feature the results are worse . but doesn't help .
C: really wonder though . we 've had these discussions before , and one of the things that struck me was that , about this line of thought that was particularly interesting to me was that we whenever you condense things , , in an irreversible way , , you throw away some information . and , that 's mostly viewed on as good thing , in the way we use it , because we wanna suppress things that will variability for particular , , phonetic units . but , you 'll do throw something away . and so the question is , , can we figure out if there 's something we 've thrown away that we shouldn't have . when they were looking at the difference between the filter bank and the fft that was going into the filter bank , was thinking "" , , so they 're picking on something they 're looking on it to figure out noise , or voice voiced property whatever . "" so that 's interesting . maybe that helps to drive the thought process of coming up with the features . but for me the interesting thing was , "" , but is there just something in that difference which is useful ? "" so another way of doing it , maybe , would be just to take the fft , power spectrum , and feed it into neural network , and then use it , , in combination , or alone , or whatever
F: wi - with what targets ?
A: voiced , unvoiced is like
C: the just the same way we 're using , the same way that we 're using the filter bank . exact way the same way we 're using the filter bank . the filter bank is good for all the reasons that we say it 's good . but it 's different . and , , maybe if it 's used in combination , it will get at something that we 're missing . and maybe , , using , orth , klt , or , , adding probabilities , , all th all the different ways that we 've been playing with , that we would let the essentially let the neural network determine what is it that 's useful , that we 're missing here .
D: but there is so much variability in the power spectrum .
C: that 's probably why it would be unlikely to work as by itself , but it might help in combination . but have to tell you , 't remember the conference , but , , it 's about ten years ago , remember going to one of the speech conferences saw within very short distance of one another couple different posters that showed about the wonders of some auditory inspired front - end , and couple posters away it was somebody who compared one to , just putting in the fft and the fft did slightly better . so the it 's true there 's lots of variability , but again we have these wonderful statistical mechanisms for quantifying that that variability , and , doing something reasonable with it . it - it 's same , , argument that 's gone both ways about , , we have these data driven filters , in lda , and on the other hand , if it 's data driven it means it 's driven by things that have lots of variability , and that are necessarily not necessarily gonna be the same in training and test , so , in some ways it 's good to have data driven things , and in some ways it 's bad to have data driven things . part of what we 're discovering , is ways to combine things that are data driven than are not . so anyway , it 's just thought , that if we if we had that maybe it 's just baseline which would show us "" , what are we really getting out of the filters "" , probably not by itself , but in combination , maybe there 's something to be gained from it , but , , you 've only worked with us for short time , maybe in year or two you you will actually come up with the right set of things to extract from this information . but , maybe the neural net and the ms could figure it out quicker than you . it 's just thought .
B: will try to do that .
A: what one one thing is like what before we started using this vad in this aurora , the th what we did was like , most of about this , adding this additional speech - silence bit to the cepstrum and training the on that . that is just binary feature and that seems to be improving lot on the speechdat - car where there is lot of noise but not much on the ti - digits . so , adding an additional feature to distin to discriminate between speech and nonspeech was helping . that 's it . we actually added an additional binary feature to the cepstrum , just the baseline .
B: you did some experiment .
A: in the case of ti - digits it didn't actually give us anything , because there wasn't any anything to discriminate between speech , and it was very short . but italian was like very it was huge improvement on italian .
D: but anyway the question is even more , is within speech , can we get some features ? are we drop dropping information that can might be useful within speech , to maybe to distinguish between voice sound and unvoiced sounds ?
C: and it 's particularly more relevant now since we 're gonna be given the endpoints .
A: there was paper in icassp this icassp over the extracting some higher - order , information from the cepstral coefficients and forgot the name . some is some harmonics pull that paper out from icassp . it wa it was taking the , it was about finding the higher - order moments of and 'm not about whether it is the higher - order moments , or maybe higher - order cumulants it was it was he was showing up some something on noisy speech , some improvement on the noisy speech . some small vocabulary tasks . so it was on plp derived cepstral coefficients .
C: but again you could argue that th that 's exactly what the neural network does . so neural network , is in some sense equivalent to computing , , higher - order moments of what you it doesn't do it very specifically , anything on your end you want to talk about ?
G: nothing wanna really talk about . just , , share little bit sunil hasn't hasn't heard about , what 've been doing . told you was was getting prepared to take this qualifier exam . so that 's just , , trying to propose , , your next your following years of your phd work , trying to find project to define and to work on . so , 've been , , looking into , , doing something about , speech recognition using acoustic events . the idea is you have all these different events , or noise , , frication , building robust , primary detectors for these acoustic events , and using the outputs of these robust detectors to do speech recognition . and , , these primary detectors , , will be , , inspired by , , multi - band techniques , , doing things , , similar to larry saul 's work on , , graphical models to detect these , , acoustic events . and , , so been been thinking about that and some of the issues that 've been running into are , , exactly what acoustic events need , what , what acoustic events will provide good enough coverage to in order to do the later recognition steps . and , also , , once decide set of acoustic events , , how do how do get labels ? training data for these acoustic events . and , then later on down the line , start playing with the models themselves , the primary detectors . kinda see like , after building the primary detectors see , myself taking the outputs and feeding them in , sorta tandem style into , gaussian mixtures back - end , , and doing recognition . so , that 's that 's just generally what 've been looking at .
C: by , , the voiced - unvoiced version of that could tie right in to what carmen was looking at . , if you if multi - band approach was helpful as it is , it seems to be helpful for determining voiced - unvoiced , that one might be another thing .
G: were you gonna say something ? and so , this past week , 've been , looking little bit into , traps , and doing traps on these events too , just , , seeing if that 's possible . other than that , , was kicked out of - house for living there for four years .
C: so you live in cardboard box in the street now or , no ?
G: , som something like that . that 's it .
C: suni - ' you did did you find place ? is that out of the way ?
A: yesterday called up lady who ha who will have vacant room from may thirtieth and she said she 's interviewing two more people . and she would get back to me on monday . so that 's that 's only thing have and diane has few more houses . she 's going to take some pictures and send me after go back . so it 's that 's
F: so you 're not down here permanently yet ?
A: 'm going back to ogi today .
C: and then , you 're coming back
A: , plan to be here on thirty - first .
C: thirty - first ,
A: if there 's house available or place to
G: thirty - first .
C: they 're available , and they 'll be able to get you something , so worst comes to worst we 'll put you up in hotel for for while
A: so , in that case , 'm going to be here on thirty - first definitely .
E: if you 're in desperate situation and you need place to stay , you could stay with me for while . 've got spare bedroom right now .
A: that is of you . so , it may be he needs more than me .
G: no , no . my my cardboard box is actually spacious two bedroom apartment .
C: so two bedroom cardboard box . th - that 's great . do wanna say anything about you you actually been last week you were doing this with pierre , you were you were mentioning . is that something worth talking about ,
E: , it don't directly relates . , so , was helping speech researcher named pierre divenyi and he 's int he wanted to , look at , how people respond to formant changes , . so he created lot of synthetic audio files of vowel - to - vowel transitions , and then he wanted psycho - acoustic , spectrum . and he wanted to look at , how the energy is moving over time in that spectrum and compare that to the to the listener tests . so , gave him plp spectrum . and to he wanted to track the peaks so he could look at how they 're moving . so took the , plp lpc coefficients and , found the roots . this was something that stephane suggested . found the roots of the , lpc polynomial to , , track the peaks in the , , plp lpc spectra .
A: there is aligned spectral pairs , is like the is that the aligned
C: it 's root lpc , , of some sort .
A: instead of the log you took the root square , cubic root . what di didn't get that .
C: no , no . it 's it 's taking the finding the roots of the lpc polynomial .
A: is that the line spectral
C: so it 's like line spectral pairs .
A: it 's like line sp
C: except what they call line spectral pairs they push it towards the unit circle , but what we 'd used to do when did synthesis at national semiconductor twenty years ago , the technique we were playing with initially was taking the lpc polynomial and , finding the roots . it wasn't plp cuz hynek hadn't invented it yet , but it was just lpc , and , we found the roots of the polynomial , and th when you do that , sometimes they 're they 're what most people call formants , sometimes they 're not . so it 's it 's little , formant tracking with it can be little tricky cuz you get these funny values in real speech ,
F: so you just you typically just get few roots ? two or three ,
C: you get these complex pairs .
F: something like that ?
C: and it depends on the order that you 're doing ,
E: if @ @ every root that 's since it 's real signal , the lpc polynomial 's gonna have real coefficients . so that means that every root that is not real root is gonna be complex pair , of complex value and its conjugate . and if you look at that on the unit circle , , one of these one of the members of the pair will be positive frequency , one will be negative frequency , . for the 'm using an eighth - order polynomial and 'll get three or four of these pairs which give me which gives me three or four peak positions .
C: this is from synthetic speech ,
E: it 's right .
C: so if it 's from synthetic speech then maybe it 'll be cleaner . for real speech in real then what you end up having is , like say , funny little things that are don't exactly fit your notion of formants all that . but but mostly they are . mostly they do . and and what in what we were doing , which was not so much looking at things , it was because it was just question of quantization . we were just , storing it was we were doing , , stored speech , , quantization . but but , in your case
D: actually you have peaks that are not at the formant 's positions , but they are lower in energy
E: but there 's some of that ,
D: and they are much lower .
F: if this is synthetic speech can't you just get the formants directly ? how is the speech created ?
E: it was created from synthesizer ,
F: wasn't formant synthesizer was it ?
C: bet it might have may have been but maybe he didn't have control over it ?
E: in we could get , , formant frequencies out of the synthesizer , as . one thing that the , , lpc approach will hopefully give me in addition , , is that might be able to find the the bandwidths of these humps as . stephane suggested looking at each complex pair as like se second - order iir filter . but don't think there 's really good reason not to , get the formant frequencies from the synthesizer instead . except that you don't have the psycho - acoustic modeling in that .
C: so you 're not getting the actual formants per se . you 're getting the again , you 're getting the , you 're getting something that is , af strongly affected by the plp model . and so it 's more psycho - acoustic . so it 's little it 's it 's different thing .
F: that 's the point .
C: ordinarily , in formant synthesizer , the bandwidths as as the ban , formant centers are that 's somewhere in the synthesizer that was put in , you view each complex pair as essentially second - order section , which has , , band center and band width , you 're going back today and then back in week ,
F: we should do digits quickly .
C: almost forgot that . almost forgot our daily digits .
F: you wanna go ahead ?
","The ICSI Meeting Recorder Group at Berkley have a temporary new member on loan from research partner OGI.
He began the meeting by reporting his recent activities , which included looking at the new baseline system.
The other members of the group also reported their recent progress in areas such as spectral subtraction and voicing detection.
They also explained some of their projects to their guest.
The group shall soon be taking delivery of more machines for a computation farm , and they discussed some software tools for running large processes.
Speaker me018 will construct an FAQ about the new computing tools and setup , and email details.
Fn002 agrees to try an alternative approach to her new feature for voicing detection.
Speaker mn007 has taken the spectral subtraction from another groups system , and is trying it with their own , with mixed results.
He is also looking into alternative methods of removing noise.
Fn002 is still working on voicing detection , and has run experiments with her new feature with disappointing results.
Though not directly related to the groups work , speaker me006 has been putting together his proposal or a PhD , and me026 has been helping another researcher with his work on formants.
"
ami_abstractive_summary,Bro028.txt,"A: we should be going .
B: so ne next week we 'll have , , both birger and , , mike michael and birger kollmeier will join us . and you 're you 're probably gonna go up in couple three weeks or so ? when when are you thinking of going up to , , ogi ?
D: like , , not next week but maybe the week after .
B: good . so at least we 'll have one meeting with yo with you still around , that 's good .
D: , maybe we can start with this .
B: all today , ?
D: so there was this conference call this morning , and the only topic on the agenda was just to discuss and to come at , to get decision about this latency problem .
B: no , this 'm , this is conference call between different aurora people
D: . it 's the conference call between the aurora , , group .
B: it 's the main conference call .
D: . there were like two hours of discussions , and then suddenly , , people were tired , , and they decided on {nonvocalsound} number , two hundred and twenty , included including everything . it means that it 's like eighty milliseconds less than before .
B: and what are we sitting at currently ?
D: so , currently , we have system that has two hundred and thirty . so , that 's fine . so that 's the system that 's described on the second point of this document .
B: we have to reduce it by ten milliseconds somehow .
D: that 's not problem , .
B: it 's it 's primary primarily determined by the vad at this point , so we can make the vad little shorter .
D: at this point ,
B: we probably should do that pretty soon so that we don't get used to it being certain way . was hari on the on the phone ?
D: it was mainly discussion between hari and david , . so , the second thing is the system that we have currently . yes . we have , like , system that gives sixty - two percent improvement , but if you want to stick to the this latency it has latency of two thirty , but if you want also to stick to the number of features that limit it to sixty , then we go little bit down but it 's still sixty - one percent . and if we drop the tandem network , then we have fifty - seven percent .
B: but th the two th two thirty includes the tandem network ? and is the tandem network , , small enough that it will fit on the terminal size in terms of ?
D: no , don't . it 's still in terms of computation , if we use , like , their way of computing the maps the mips , it fits , but it 's , , mainly problem of memory . and how much this can be discussed or not , because it 's it could be in rom , so it 's maybe not that expensive .
B: ho - how much memory ? how many ?
D: don't kn remember exactly , have to check that .
B: 'd like to see that , cuz maybe could think little bit about it , cuz we maybe we could make it little smaller or , it 'd be it 'd be neat if we could fit it all . 'd like to see how far off we are . but it 's still within their rules to have it on the , , , server side . and this is still ? , you 're saying here . should just let you go on .
D: there were small tricks to make this tandem network work . and one of the trick was to , , use some hierarchical structure where the silence probability is not computed by the final tandem network but by the vad network . so it looks better when , , we use the silence probability from the vad network and we re - scale the other probabilities by one minus the silence probability . so it 's some hierarchical thing , , that sunil also tried , , on spine and it helps little bit also . the reason why we did that with the silence probability was that ,
B: could ? , , 'm 'm really . can you repeat what you were saying about the silence probability ? my mind was some
D: so there is the tandem network that estimates the phone probabilities and the silence probabilities also . and things get better when , instead of using the silence probability computed by the tandem network , we use the silence probability , , given by the vad network ,
B: the vad network is ?
D: which is smaller , so we have network for the vad which has one hundred hidden units , and the tandem network has five hundred . so it 's smaller but th the silence probability from this network seems , , better . it looks strange , maybe it 's has something to do to the fact that we don't have infinite training data so , things are not optimal
E: are you were going to say why what made you wh what led you to do that .
D: , there was problem that we observed , , that there was there were , like , many insertions in the in the system . actually plugging in the tandem network was increasing , , the number of insertions . so it looked strange and then just using the other silence probability helps . the next thing we will do is train this tandem on more data .
B: so , , in way what it might it 's it 's little bit like combining knowledge sources . because the fact that you have these two nets that are different sizes means they behave little differently , they find different things . if you have , the distribution that you have from , , speech sounds is one source of knowledge . and rather than just taking one minus that to get the other , which is essentially what 's happening , you have this other source of knowledge that you 're putting in there . so you make use of both of them in what you 're ending up with . maybe it 's better . anyway , you can probably justify anything if what 's use
D: and and the features are different also . the vad doesn't use the same features there are .
B: that might be the key , actually . cuz you were really thinking about speech versus nonspeech for that . that 's good point .
D: , there are other things that we should do but , , it requires time and we have ideas , like so , these things are like hav having better vad . we have some ideas about that . it would probably implies working little bit on features that are more suited to voice activity detection . working on the second stream . we have ideas on this also , but we need to try different things but their noise estimation ,
B: back on the second stream , that 's something we 've talked about for while . {nonvocalsound} that 's certainly high hope . so we have this default idea about just using some purely spectral thing ? for second stream ?
D: but , , we did first try with this , and it clearly hurts .
B: but , , how was the stream combined ?
D: it was it was just combined , , by the acoustic model . so there was , no neural network for the moment .
B: right . so , , if you just had second stream that was just spectral and had another neural net and combined there , that , , might be good .
D: and the other thing , that noise estimation and th , maybe try to train , the training data for the tandem network , right now , is like is using the noises from the aurora task and that people might , , try to argue about that because then in some cases we have the same noises in for training the network than the noises that are used for testing , so we have , to try to get rid of these this problem .
B: maybe you just put in some other noise , something that 's different . it 's probably helpful to have little noise there . but it may be something else th at least you could say it was . and then if it doesn't hurt too much , though . that 's good idea .
D: the last thing is that we are getting close to human performance . that 's something would like to investigate further , did , like , did , , listen to the most noisy utterances of the speechdat - car italian and tried to transcribe them .
B: so this is particular human . this is this this is stephane .
D: so that 's that 's
E: st - stephane .
D: that 's the flaw of the experiment . this is just it 's just one subject , but still , , what happens is that , , the digit error rate on this is around one percent , while our system is currently at seven percent . but what happens also is that if listen to the , {nonvocalsound} re - synthesized version of the speech and re - synthesized this using white noise that 's filtered by lpc , , filter you can argue , that , that this is not speech , so the ear is not trained to recognize this . but actually it sound like whispering ,
B: there 's two problems there . so the first is that by doing lpc - twelve with synthesized speech like you 're saying , , it 's you 're you 're adding other degradation . so it 's not just the noise but you 're adding some degradation because it 's only an approximation . and the second thing is which is maybe more interesting is that , , if you do it with whispered speech , you get this number . what if you had done analysis re - synthesis and taken the pitch as ? so now you put the pitch in . what would the percentage be then ? see , that 's the question . so , you see , if it 's if it 's , let 's say it 's back down to one percent again . that would say at least for people , having the pitch is really , really important , which would be interesting in itself . if on the other hand , if it stayed up near five percent , then 'd say "" boy , lpc twelve is pretty crummy "" . so 'm not 'm not how we can conclude from this anything about that our system is close to the human performance .
D: , that ey that , , what what listened to when re - synthesized the lp - the lpc - twelve spectrum is in way what the system , , is hearing , cuz @ @ all the all the , , excitation all the the excitation is not taken into account . that 's what we do with our system .
B: you 're not doing the lpc so what if you did
D: it 's not lpc , ,
B: what if you did lpc - twenty ? th lpc is not really great representation of speech . so , all 'm saying is that you have in addition to the the , , removal of pitch , you also are doing , , particular parameterization , so , let 's see , how would you do ? so , fo
D: but that 's that 's what we do with our systems .
B: no . actually , we we don't , because we do we do , , , mel filter bank , .
D: but is it that is it that different , ?
B: what mel , , based synthesis would sound like , but certainly the spectra are quite different .
A: couldn't you couldn't you , , test the human performance on just the original audio ?
D: this is the one percent number .
B: it 's one percent . he 's trying to remove the pitch information and make it closer to what to what we 're seeing as the feature vectors .
A: so , , your performance was one percent , and then when you re - synthesize with lpc - twelve it went to five .
B: we were we were it it 's little bit still apples and oranges because we are choosing these features in order to be the best for recognition . if you listen to them they still might not be very even if you made something closer to what we 're gonna it might not sound very good . and the degradation from that might actually make it even harder , , to understand than the lpc - twelve . so all 'm saying is that the lpc - twelve puts in synthesis puts in some degradation that 's not what we 're used to hearing , it 's not it 's not just question of how much information is there , as if you will always take maximum advantage of any information that 's presented to you . you hear some things better than others . and so it isn't but , agree that it says that , , the information that we 're feeding it is probably , , little bit , , minimal . there 's definitely some things that we 've thrown away . and that 's why was saying it might be interesting if you an interesting test of this would be if you if you actually put the pitch back in . so , you just extract it from the actual speech and put it back in , and see does that is that does that make the difference ? if that if that takes it down to one percent again , then you 'd say "" , it 's it 's having , , not just the spectral envelope but also the also the pitch that , , @ @ has the information that people can use , anyway . ""
A: but from this it 's pretty safe to say that the system is with either two to seven percent away from the performance of human . so it 's somewhere in that range .
B: or it 's it 's
A: two two to six percent .
B: it 's it 's one point four times , , to , , seven times the error ,
D: to seven times , .
B: do don't wanna take you away from other things . but that 's that 's what that 's the first thing that would be curious about , is , , when you we
D: but the signal itself is like mix of , of periodic sound and , @ @ , unvoiced sound , and the noise which is mostly , , noise . so , what do you mean exactly by putting back the pitch in ?
A: in the lpc synthesis ?
B: you did lpc re - synthesis pc re - synthesis . so , and you did it with noise source , rather than with periodic source . so if you actually did real re - synthesis like you do in an lpc synthesizer , where it 's unvoiced you use noise , where it 's voiced you use , , periodic pulses .
D: but it 's neither purely voiced or purely unvoiced . esp - especially because there is noise .
B: it might be hard to do it but it but that if you , if you detect that there 's periodic strong periodic components , then you can use voiced voice thing . , it 's probably not worth your time . it 's it 's side thing and and there 's lot to do . but 'm 'm just saying , at least as thought experiment , that 's what would wanna test . wan would wanna drive it with two - source system rather than than one - source system . and then that would tell you whether it 's cuz we 've talked about , like , this harmonic tunneling or other things that people have done based on pitch , maybe that 's really key element . maybe maybe , , , without that , it 's it 's not possible to do whole lot better than we 're doing . that that could be .
D: that 's what was thinking by doing this es experiment ,
B: but , , other than that , don't 's other than the pitch de information , it 's hard to imagine that there 's whole lot more in the signal that , that we 're throwing away that 's important .
D: - . , right .
B: right ? , we 're using fair number of filters in the filter bank
D: that 's it .
B: that 's that 's , one percent is what would would figure . if somebody was paying really close attention , you might get would actually think that if , you looked at people on various times of the day and different amounts of attention , you might actually get up to three or four percent error on digits . we 're not we 're not incredibly far off . on the other hand , with any of these numbers except maybe the one percent , it 's st it 's not actually usable in commercial system with full telephone number .
D: at these noise levels . . these numbers , .
B: while we 're still on aurora maybe you can talk little about the status with the , , wall street journal things for it .
A: so 've , , downloaded , , couple of things from mississippi state . one is their software their , , lvcsr system . downloaded the latest version of that . got it compiled and everything . downloaded the scripts . they wrote some scripts that make it easy to run the system on the wall street journal , , data . so haven't run the scripts yet . 'm waiting there was one problem with part of it and wrote note to joe asking him about it . so 'm waiting to hear from him . but , , did print something out just to give you an idea about where the system is . they on their web site they , , did this little table of where their system performs relative to other systems that have done this task . and , , the mississippi state system using bigram grammar , , is at about eight point two percent . other comparable systems from , were getting from , , like six point nine , six point eight percent .
B: this is on clean test set ?
A: this is on clean on clean . . they they 've started table where they 're showing their results on various different noise conditions but they don't have whole lot of it filled in and didn't notice until after 'd printed it out that , , they don't say here what these different testing conditions are . you actually have to click on it on the web site to see them . so what those numbers really mean .
B: what numbers are they getting on these on the test conditions ?
A: see , was little confused because on this table , 'm the they 're showing word error rate . but on this one , if these are word error rates because they 're really big . so , under condition one here it 's ten percent . then under three it goes to sixty - four point six percent .
B: that 's probably aurora .
A: so maybe they 're error rates but they 're , they 're really high .
B: don't find that surpri what 's what 's some of the lower error rates on , some of the higher error rates on , , some of these , highly mismatched difficult conditions ?
D: , it 's around fifteen to twenty percent . and the baseline , twenty percent error rate ,
B: so twenty percent error rate on digits .
A: , on digits .
B: so if you 're doing so if you 're doing ,
D: and this is so still the baseline .
B: and if you 're saying sixty - thousand word recognition , getting sixty percent error on some of these noise condition not surprising .
D: the baseline is sixty percent also on digits , on the more mismatched conditions .
A: so , , that 's probably what it is then . so they have lot of different conditions that they 're gonna be filling out .
B: it 's bad sign when you looking at the numbers , you can't tell whether it 's accuracy or error rate .
A: it 's it 's gonna be hard . they 're 'm still waiting for them to release the , , multi - cpu version of their scripts , cuz right now their script only handles processing on single cpu , which will take really long time to run .
B: this is for the training ?
A: yes , for the training also . and , , they 're supposed to be coming out with it any time , the multi - cpu one . so , as soon as they get that , then 'll 'll grab those too
B: cuz we have to get started , cuz it 's cuz , ,
A: 'll go ahead and try to run it though with just the single cpu one , and they , , released like smaller data set that you can use that only takes like sixteen hours to train and . so run it on that just to make that the thing works and everything .
B: the actual evaluation will be in six weeks . is that about right you think ?
D: we yet , .
B: really , we ?
A: it wasn't on the conference call this morning ? did they say anything on the conference call about , , how the wall street journal part of the test was going to be run ? because remembered hearing that some sites were saying that they didn't have the compute to be able to run the wall street journal at their place , so there was some talk about having mississippi state run the systems for them . did did that come up ?
D: this first , this was not the point of this the meeting today because didn't read also the most recent mails about the large - vocabulary task . but , , did you do you still , , get the mails ? you 're not on the mailing list or what ?
A: the only , , mail get is from mississippi state
D: . so we should have look at this .
A: about their system . don't get any mail about
B: have to say , there 's something funny - sounding about saying that one of these big companies doesn't have enough cup compute power do that , so they 're having to have it done by mississippi state . it just sounds funny .
A: 'm 'm wondering about that because there 's this whole issue about , , simple tuning parameters , like word insertion penalties . and whether or not those are going to be tuned or not , it makes big difference . if you change your front - end , , the scale is completely can be completely different , it seems reasonable that at least should be tweaked to match the front - end .
D: you didn't get any answer from joe ?
A: but joe said , , "" what you 're saying makes sense so he doesn't the answer is . that 's th we had this back and forth little bit about , , are sites gonna are you gonna run this data for different sites ? and , , if mississippi state runs it , then maybe they 'll do little optimization on that parameter , but then he wasn't asked to run it for anybody . so it 's it 's just not clear yet what 's gonna happen . he 's been putting this out on their web site and for people to grab but haven't heard too much about what 's happening .
B: so it could be , chuck and had actually talked about this couple times , and over some lunches , , that , , one thing that we might wanna do the - there 's this question about , , what do you wanna scale ? suppose you can't adjust these word insertion penalties and , so you have to do everything at the level of the features . what could you do ? and , , one thing had suggested at an earlier time was maybe some scaling , some root of the , , , features . but the problem with that is that isn't quite the same , it occurred to me later , because what you really want to do is scale the , , @ @ the range of the likelihoods rather than
D: nnn , the dist
B: but , what might get at something similar , it just occurred to me , is an intermediate thing is because we do this strange thing that we do with the tandem system , at least in that system what you could do is take the , , , values that come out of the net , which are something like log probabilities , and scale those . and then , , then at least those things would have the right values or the right the right range . and then that goes into the rest of it and then that 's used as observations . so it 's it 's , , another way to do it .
D: but , these values are not directly used as probabilities anyway .
B: know they 're not .
D: so there are there is
B: know they 're not . so because what we 're doing is pretty strange and complicated , we don't really the effect is at the other end . so , , my thought was maybe they 're not used as probabilities , but the log probabilities we 're taking advantage of the fact that something like log probabilities has more of gaussian shape than gaus - than probabilities , and so we can model them better . so , in way we 're taking advantage of the fact that they 're probabilities , because they 're this quantity that looks gaussian when you take it 's log . so , , maybe it would have reasonable effect to do that . but , , we still haven't had ruling back on this . and we may end up being in situation where we just really can't change the word insertion penalty . but the other thing we could do is also we could this may not help us , , in the evaluation but it might help us in our understanding at least . we might , just run it with different insper insertion penalties , and show that , , "" , , not changing it , playing the rules the way you wanted , we did this . but if we did that , it made big difference . ""
A: wonder if it might be possible to , , simulate the back - end with some other system . so we get our front - end features , as part of the process of figuring out the scaling of these features , , if we 're gonna take it to root or to power , we have some back - end that we attach onto our features that simulates what would be happening .
B: and just adjust it until it 's the best number ?
A: and just adjust it until that our version of the back - end , , decides that
B: we can probably use the real thing , and then jus just , , use it on reduced test set .
A: that 's true . and then we just use that to determine some scaling factor that we use .
B: so , that 's reasonable thing to do and the only question is what 's the actual knob that we use ? and the knob that we use should unfortunately , like say , the analytic solution to this cuz what we really want to do is change the scale of the likelihoods , not the cha not the scale of the observations .
E: out of curiosity , what recognizer is the one from mississippi state ?
A: what do you mean when you say "" what kind "" ?
E: is it like gaussian mixture model ?
A: gaussian mixture model . it 's the same system that they use when they participate in the hub - five evals . it 's , came out of , , looking lot like htk . they started off with , when they were building their system they were always comparing to htk to make they were getting similar results . and so , it 's gaussian mixture system ,
B: do they have the same mix - down procedure , where they start off with small number of some things
A: and then divide the mixtures in half . if they do that . 'm not really .
B: do what tying they use ? are they some bunch of gaussians that they share across everything ? or or if it 's ?
A: th have don't have it up here but have the whole system description , that describes exactly what their system is and 'm not . it 's some mixture of gaussians and , , clustering they 're they 're trying to put in all of the standard features that people use nowadays .
B: so the other , , aurora thing maybe is if any of this is gonna come in time to be relevant , but , , we had talked about , , guenter playing around , , over in germany and , @ @ , possibly coming up with something that would , , , fit in later . saw that other mail where he said that he , it wasn't going to work for him to do cvs .
D: so now he has version of the software .
B: so he just has it all sitting there . so if he 'll he might work on improving the noise estimate or on some histogram things , we we didn't talk about it at our meeting but saw the just read the paper . someone , forget the name , and ney , , about histogram equalization ? did you see that one ?
D: it was poster .
B: , read the paper . didn't see the poster .
D: it was something similar to on - line normalization finally in the idea of normalizing
B: but it 's little more it 's little finer , so they had like ten quantiles and they adjust the distribution . so you have the distributions from the training set , so this is just histogram of the amplitudes , . and then , people do this in image processing some . you have this histogram of levels of brightness or whatever . and and then , when you get new thing that you want to adjust to be better in some way , you adjust it so that the histogram of the new data looks like the old data . you do this piece - wise linear or , , some piece - wise approximation . they did one version that was piece - wise linear and another that had power law thing between them between the points . they said they they see it in way as for the speech case as being generalization of spectral subtraction in way , because , , in spectral subtraction you 're trying to get rid of this excess energy . , it 's not supposed to be there . this is adjusting it for lot of different levels . and then they have they have some , , floor , so if it gets too low you don't don't do it . and they claimed very results ,
A: so is this histogram across different frequency bins ?
B: don't remember that . do you remember ?
D: they have , , different histograms . something like one per frequency band ,
A: so , one histogram per frequency bin .
D: but should read the paper . went through the poster quickly ,
B: and don't remember whether it was filter bank things or whether it was fft bins
A: and and that , , histogram represents the different energy levels that have been seen at that frequency ?
B: don't remember that . and how often they you 've seen them . . and they do they said that they could do it for the test so you don't have to change the training . you just do measurement over the training . and then , , for testing , , you can do it for one per utterance . even relatively short utterances . and they claim it works pretty .
A: is the idea that you run test utterance through some histogram generation thing and then you compare the histograms and that tells you what to do to the utterance to make it more like ?
B: didn't read carefully how they actually implemented it , whether it was some , , on - line thing , or whether it was second pass , or what . but but they that that was the idea . so that seemed , , different . we 're curious about , , what are some things that are , , @ @ conceptually quite different from what we 've done . cuz we , one thing that that , stephane and sunil seemed to find , , was , , they could actually make unified piece of software that handled range of different things that people were talking about , and it was really just setting of different constants . and it would turn , , one thing into another . it 'd turn wiener filtering into spectral subtraction , or whatever . but there 's other things that we 're not doing . so , we 're not making any use of pitch , which again , might be important , because the between the harmonics is probably schmutz . and and the , , transcribers will have fun with that . the , , at the harmonics isn't so much . and we there 's this overall idea of really matching the hi distributions somehow . not just subtracting off your estimate of the noise . so , , guenter 's gonna play around with some of these things now over this next period ,
D: don't have feedback from him , he 's gonna , maybe
B: he 's got it anyway , so he can . so potentially if he came up with something that was useful , like diff better noise estimation module , he could ship it to you guys up there we could put it in .
D: - . - .
B: that 's good . so , why don't we just , , starting couple weeks from now , especially if you 're not gonna be around for while , we 'll we 'll be shifting more over to some other territory . but , , , not so much in this meeting about aurora , maybe just , , quickly today about maybe you could just say little bit about what you 've been talking about with michael . and then barry can say something about what we 're talking about .
C: so michael kleinschmidt , who 's phd student from germany , showed up this week . he 'll be here for about six months . and he 's done some work using an auditory model of , , human hearing , and using that , to generate speech recognition features . and he did work back in germany with , , toy recognition system using , , isolated digit recognition as the task . it was actually just single - layer neural network that classified words classified digits , . and he tried that on on some aurora data and got results that he thought seemed respectable . he he 's coming here to use it on , real speech recognition system . so 'll be working with him on that . maybe should say little more about these features , although don't understand them that . the it 's two - stage idea . and , , the first stage of these features correspond to what 's called the peripheral auditory system . and that is like filter bank with compressive nonlinearity . and 'm - 'm not what we have @ @ in there that isn't already modeled in something like , , plp . should learn more about that . and then the second stage is , , the most different thing , , from what we usually do . it 's , it computes features which are , , based on like based on diffe different , wavelet basis functions used to analyze the input . so th he uses analysis functions called gabor functions , which have certain extent , , in time and in frequency . and the idea is these are used to sample , , the signal in represented as time - frequency representation . so you 're sampling some piece of this time - frequency plane . and , , that , , is interesting , cuz , @ @ for one thing , you could use it , , in multi - scale way . you could have these instead of having everything like we use twenty - five millisecond or so analysis window , typically , and that 's our time scale for features , but you could using this , , basis function idea , you could have some basis functions which have lot longer time scale and , , some which have lot shorter , and so it would be like set of multi - scale features . so he 's interested in , th - this is because it 's , there are these different parameters for the shape of these basis functions , there are lot of different possible basis functions . and so he actually does an optimization procedure to choose an optimal set of basis functions out of all the possible ones .
A: what does he do to choose those ?
C: the method he uses is funny is , , he starts with he has set of of them . he and then he uses that to classify he he tries , , using just minus one of them . so there are possible subsets of this length - vector . he tries classifying , using each of the possible sub - vectors . whichever sub - vector , , works the best , , he says the fe feature that didn't use was the most useless feature ,
B: gets thrown out .
C: so we 'll throw it out and we 're gonna randomly select another feature from the set of possible basis functions .
B: so so it 's actuall
A: it 's little bit like genetic algorithm in way .
B: it 's it 's much simpler .
E: it 's like greedy
B: but it 's but it 's , it 's there 's lot number of things like about it , let me just say . so , first thing , , you 're right . {nonvocalsound} in truth , both pieces of this are have their analogies in we already do . but it 's different take at how to approach it and potentially one that 's maybe bit more systematic than what we 've done , and bit more inspiration from auditory things . so it 's so it 's neat thing to try . the primary features , , are essentially , it 's it 's , , , plp or mel cepstrum , like that . you 've you 've got some , , compression . we always have some compression . we always have some , the the filter bank with quasi - log scaling . if you put in if you also include the rasta in it rasta the filtering being done in the log domain has an agc - like , , characteristic , which , , people typi typically put in these , , , , auditory front - ends . so it 's very , very similar , but it 's not exactly the same . would agree that the second one is somewhat more different but , , it 's mainly different in that the things that we have been doing like that have been , had different motivation and have ended up with different kinds of constraints . so , , if you look at the lda rasta , , what they do is they look at the different eigenvectors out of the lda and they form filters out of it . right ? and those filters have different , , kinds of temporal extents and temporal characteristics . and so they 're multi - scale . but , they 're not systematically multi - scale , like "" let 's start here and go to there , and go to there "" , and . it 's more like , you run it on this , you do discriminant analysis , and you find out what 's helpful .
C: it 's multi - scale because you use several of these in parallel ,
B: they use several of them .
C: is that right ?
B: , you don't have to but but , , hynek has . but it 's also , hyn - when hynek 's had people do this lda analysis , they 've done it on frequency direction and they 've done it on the time direction . he may have had people sometimes doing it on both simultaneously and that would be the closest to these gabor function things . but don't think they 've done that much of that . and , , the other thing that 's interesting the , the feature selection thing , it 's simple method , but kinda like it . there 's old , old method for feature selection . , , remember people referring to it as old when was playing with it twenty years ago , so 's pretty old , called stepwise linear discriminant analysis in which you which it 's used in social sciences lot . so , you you pick the best feature . and then you take you find the next feature that 's the best in combination with it . and then so on and so on . and what michael 's describing seems to me much , much better , because the problem with the stepwise discriminant analysis is that you that , if you 've picked the right set of features . just because something 's good feature doesn't mean that you should be adding it . so , , , here at least you 're starting off with all of them , and you 're throwing out useless features . that 's that seems , that seems like lot better idea . you 're always looking at things in combination with other features . so the only thing is , , there 's this artificial question of , , exactly how you how you how you assess it and if your order had been different in throwing them out . it still isn't necessarily really optimal , but it seems like pretty good heuristic . so th it 's it 's kinda neat . and and , , the thing that wanted to add to it also was to have us use this in multi - stream way . so that , , when you come up with these different things , and these different functions , you don't necessarily just put them all into one huge vector , but perhaps you have some of them in one stream and some of them in another stream , and . and we 've also talked little bit about , , , shihab shamma 's , in which you the way you look at it is that there 's these different mappings and some of them emphasize , , upward moving , , energy and fre and frequency . and some are emphasizing downward and fast things and slow things and . so there 's bunch of to look at . but , , we 're sorta gonna start off with what he , , came here with and branch out branch out from there . and his advisor is here , too , at the same time . he 'll be another interesting source of wisdom .
E: as as we were talking about this was thinking , , whether there 's relationship between , between michael 's approach to , , some optimal brain damage or optimal brain surgeon on the neural nets . so , like , if we have , we have our we have our rasta features and and presumably the neural nets are learning some nonlinear mapping , , from the the features to this probability posterior space . and , and each of the hidden units is learning some some pattern . and it could be , like these , these auditory patterns that michael is looking at . and then when you 're looking at the , , , the best features , , you can take out you can do the do this , , brain surgery by taking out , , hidden units that don't really help .
B: or the or features .
E: and this is sorta like
B: actually , you make me think very important point here is that , , if we again try to look at how is this different from what we 're already doing , , there 's , nasty argument that could be made th that it 's it 's not different , because , if you ignore the selection part because we are going into very powerful , , nonlinearity that , , is combining over time and frequency , and is coming up with its own , better than gabor functions its , , neural net functions , its whatever it finds to be best . so you could argue that it but don't actually believe that argument because know that , , you can , computing features is useful , even though in principle you haven't added anything you subtracted something , from the original waveform , if you 've you 've processed it in some way you 've typically lost something some information . and so , you 've lost information and yet it does better with features than it does with the waveform . know that sometimes it 's useful to constrain things . so that 's why it really seems like the constraint in all this it 's the constraints that are actually what matters . because if it wasn't the constraints that mattered , then we would 've completely solved this problem long ago , because long ago we already knew how to put waveforms into powerful statistical mechanisms .
D: , if we had infinite processing power and data , , using the waveform could
B: then it would work . there 's the problem .
D: so , that 's
B: then it would work . but but , , it 's with finite of those things , we have done experiments where we literally have put waveforms in and and , , we kept the number of parameters the same and , and it used lot of training data . and it and it , but lot , and then compared to the number parameters and it , it just doesn't do nearly as . so , anyway that you want to suppress it 's not just having the maximum information , you want to suppress , , the aspects of the input signal that are not helpful for the discrimination you 're trying to make . so maybe just briefly ,
E: that segues into what 'm doing . so , , the big picture is , come up with set of , , intermediate categories , then build intermediate category classifiers , then do recognition , and , , improve speech recognition in that way . so right now 'm in the phase where 'm looking at , , deciding on initial set of intermediate categories . and 'm looking for data - driven methods that can help me find , , set of intermediate categories of speech that , , will help me to discriminate later down the line . and one of the ideas , , that was to take take neural net train an ordinary neural net to , to learn the posterior probabilities of phones . at the end of the day you have this neural net and it has hidden units . and each of these hidden units is , is learning some pattern . and so , , what are these patterns ? and 'm gonna to try to look at those patterns to see , , from those patterns presumably those are important patterns for discriminating between phone classes . and maybe some , , intermediate categories can come from just looking at the patterns of , that the neural net learns .
B: be - before you get on the next part let me just point out that there 's there 's pretty relationship between what you 're talking about doing and what you 're talking about doing there . right ? so , it seems to me that , , if you take away the the difference of this primary features , and , say , you use as we had talked about maybe doing you use - rasta - plp for the primary features , , then this feature discovery , , thing is just what he 's talking about doing , too , except that he 's talking about doing them in order to discover intermediate categories that correspond to these , what these sub - features are are showing you . and , , the other difference is that , , he 's doing this in in multi - band setting , which means that he 's constraining himself to look across time in some relatively limited , , spectral extent . right ? and whereas in this case you 're saying "" let 's just do it unconstrained "" . so they 're they 're really pretty related and maybe they 'll be at some point where we 'll see the connections little better and connect them .
E: so that 's the that 's the first part , one of the ideas to get at some patterns of intermediate categories . the other one was , , to , , come up with model , graphical model , that treats the intermediate categories as hidden variables , latent variables , that we anything about , but that through , , statistical training and the algorithm , , at the end of the day , we have , we have learned something about these latent , latent variables which happen to correspond to intermediate categories . {nonvocalsound} , and so those are the two directions that 'm 'm looking into right now . and , , . that 's that 's it .
B: should we do our digits and get ou get our treats ? it 's like , , the little rats with the little thing dropping down to them . we do the digits and then we get our treats .
","ICSI's Meeting Recorder Group met to discuss their progress in various aspects of the Aurora Project , but also to hear more about other developments relevant to the group.
On the Aurora Project , there were reports on a project conference call , the status of the tandem neural networks , and progress with the Mississippi State recognizer.
The latency limit has been set , and the group's system is performing very well , but is a little over.
On the larger vocabulary task , there are still a few issues to resolve before work can really get started.
The group heard of the plan of one of it's member's work into intermediate classifiers , and also of how a visiting research student's work into auditory models can be applied to their work.
Speaker me013 wants to know how much memory the tandem network takes up.
It is only a minor problem that the latency limit has been set below the current systems level , and also keeping the number of features within limits only drops performance a little.
A more significant problem is that the tandem approach may not fit in the memory space allowed , and removing it drops performance more.
Some of the group had issues with mn007's approach to human performance testing , but this was considered more of a side issue.
Speaker mn007 has been working on the tandem network approach , and the current results are good.
He has found a good way of calculating the silence probabilities , that does not increase insertions.
He also attempted to transcribe data himself , to establish a human performance level.
Speaker me018 is working on Mississippi Sate recognizer for dealing with the Wall Street Journal Data.
"
ami_abstractive_summary,Bro010.txt,"A: we 're on .
C: what are we talking about today ?
B: do you have news from the conference talk ? that was programmed for yesterday .
D: yesterday morning on video conference .
C: know now you 're talking about . no , nobody 's told me anything .
A: this was the , , talk where they were supposed to try to decide
B: to to decide what to do ,
C: no , that would have been good thing to find out before this meeting , no , have no have no idea . let 's let 's assume for right now that we 're just plugging on ahead , because even if they tell us that , , the rules are different , , we 're still interested in doing what we 're doing . so what are you doing ?
B: , we 've little bit worked on trying to see , , what were the bugs and the problem with the latencies . we took first we took the lda filters and , , we designed new filters , using recursive filters actually .
C: so when you say "" we "" , is that something sunil is doing or is that ? who is doing that ?
B: so we took the filters the fir filters and we designed , , iir filters that have the same frequency response . similar , but that have shorter delays . so they had two filters , one for the low frequency bands and another for the high frequency bands . and so we redesigned two filters . and the low frequency band has sixty - four milliseconds of delay , and the high frequency band filter has something like eleven milliseconds compared to the two hundred milliseconds of the iir filters . but it 's not yet test . so we have the filters but we still have to implement routine that does recursive filtering
C: you you had discussion with sunil about this though ? you should talk with him . no , , because the the whole problem that happened before was coordination , so so you need to discuss with him what we 're doing , cuz they could be doing the same thing and .
B: if th that 's what they were trying to they were trying to do something different like taking , , using filter that takes only past this is just little bit different . but will send him an email and tell him exactly what we are doing ,
C: we just we just have to be in contact more . that the fact that we did that with had that thing with the latencies was indicative of the fact that there wasn't enough communication .
B: there is one , , remark about these filters , that they don't have linear phase . perhaps it perhaps it doesn't hurt because the phase is almost linear and so , , for the delay gave you here , it 's it 's , , computed on the five hertz modulation frequency , which is the mmm , , the most important for speech this is the first thing .
C: so that would be , , reduction of hundred and thirty - six milliseconds , what was the total we ended up with through the whole system ?
B: three hundred and thirty .
C: so that would be within ?
B: but there are other points actually , which will perhaps add some more delay . is that some other in the process were perhaps not very perf , not very correct , like the downsampling which was simply dropping frames . so we will try also to add downsampling low - pass filter at twenty - five hertz . because wh when we look at the lda filters , , they are low - pass but they leave lot of what 's above twenty - five hertz . and so , , this will be another filter which would add ten milliseconds again . and then there 's third thing , is that , , the way on - line normalization was done , is just using this recursion on the , on the feature stream , and but this is filter , so it has also delay . and when we look at this filter actually it has delay of eighty - five milliseconds .
C: eighty - five .
B: if we want to be very correct , so if we want to the estimation of the mean to be , the right estimation of the mean , we have to to take eighty - five milliseconds in the future .
C: that 's little bit of problem .
B: but , , when we add up everything it 's it will be alright . we would be at six so , sixty - five , plus ten , plus for the downsampling , plus eighty - five for the on - line normalization . plus eighty for the neural net and pca .
C: but then there 's
B: so it would be around two hundred and forty
C: just just barely in there .
B: plus the frames , but it 's .
A: what 's the allowable ?
C: two - fifty , unless they changed the rules . which there is there 's some discussion of .
A: what were they thinking of changing it to ?
C: the people who had very low latency want it to be low , very narrow , , latency bound . and the people who have longer latency don't . unfortunately we 're the main ones with long latency ,
B: and the best proposal had something like thirty or forty milliseconds of latency .
C: they were more or less trading computation for performance and we were , , trading latency for performance . and they were dealing with noise explicitly and we weren't , and so of it as complementary , that if we can put the
A: think of it as what ?
C: so , , everything that we did in way it was it was just adamantly insisting on going in with brain damaged system , which is something actually , we 've done lot over the last thirteen years . which is we say , this is the way we should do it . and then we do it . and then someone else does something that 's straight forward . so , th this was test that largely had additive noise and we did we adde did nothing explicitly to handle ad additive noise . we just , , , trained up systems to be more discriminant . and , , we did this , , rasta - like filtering which was done in the log domain and was tending to handle convolutional noise . we did we actually did nothing about additive noise . the , , spectral sub subtraction schemes couple places did seem to do job . we 're talking about putting some of that in while still keeping some of our . you should be able to end up with system that 's better than both but clearly the way that we 're operating for this other does involved some latency to get rid of most of that latency . to get down to forty or fifty milliseconds we 'd have to throw out most of what we 're doing . and and , , don't think there 's any good reason for it in the application actually . you 're you 're speaking to recognizer on remote server and , , having quarter second for some processing to clean it up . it doesn't seem like it 's that big deal . these aren't large vocabulary things so the decoder shouldn't take really long time , and .
A: and don't think anybody 's gonna notice the difference between quarter of second of latency and thirty milliseconds of latency .
C: what what does wa was your experience when you were doing this with , , the the surgical , , microscopes and . how long was it from when somebody , , finished an utterance to when , , something started happening ?
A: we had silence detector , we would look for the end of an utterance based on the silence detector . and 't remember now off the top of my head how many frames of silence we had to detect before we would declare it to be the end of an utterance . but it was , would say it was probably around the order of two hundred and fifty milliseconds .
C: and that 's when you 'd start doing things .
A: we did the back trace at that point to get the answer .
C: that didn't take too long at that point .
A: no it was pretty quick .
C: so you so you had so you had quarter second delay before , , plus some little processing time , and then the microscope would start moving . and there 's physical inertia there , so probably the motion itself was all
A: and it felt to , , the users that it was instantaneous . as fast as talking to person . it th don't think anybody ever complained about the delay .
C: so you would think as long as it 's under half second . 'm not an expert on that
A: don't remember the exact numbers it was something like that . don't think you can really tell . person don't think person can tell the difference between , , , quarter of second and hundred milliseconds , 'm not even if we can tell the difference between quarter of second and half second . it just it feels so quick .
C: if you , if you said , , , "" what 's the , what 's the shortest route to the opera ? "" and it took half second to get back to you , it might even be too abrupt . you might have to put in delay .
A: it may feel different than talking to person because when we talk to each other we tend to step on each other 's utterances . so like if 'm asking you question , you may start answering before 'm even done . so it would probably feel different but don't would feel slow .
C: we could cut we else , we could cut down on the neural net time by , , playing around little bit , going more into the past , we we talked about that .
A: so is the latency from the neural net caused by how far ahead you 're looking ?
C: and there 's also there 's the neural net and there 's also this , , multi - frame , , klt .
A: was it in the , , recurrent neural nets where they weren't looking ahead ?
C: they weren't looking ahead much . they they looked ahead little bit . you could do this with recurrent net . but you also could just , , we haven't experimented with this but imagine you could , , , predict , , label , , from more in the past than in than in the future . we 've we 've done some with that before .
A: we 've always had usually we used the symmetric windows
C: but we 've but we played little bit with asymmetric , guys . you can do it . so , that 's what that 's what you 're busy with , messing around with this ,
D: also we were thinking to , , apply the , spectral subtraction from ericsson and to change the contextual klt for lda .
A: change the what ?
D: the contextual klt .
A: 'm missing that last word .
D: to change and use lda discriminative .
A: what is the advantage of that ?
B: it 's that by the for the moment we have , , something that 's discriminant and nonlinear . and the other is linear but it 's not discriminant . it 's linear transformation , that
C: so at least just to understand maybe what the difference was between how much you were getting from just putting the frames together and how much you 're getting from the discriminative , what the nonlinearity does for you or doesn't do for you . just to understand it little better .
B: actually what we want to do , perhaps it 's to replace to have something that 's discriminant but linear , also . and to see if it if it improves ov over the non - discriminant linear transformation . and if the neural net is better than this
C: , that 's what , is to see whether it having the neural net really buys you anything . , it doe did look like it buys you something over just the klt . but maybe it 's just the discrimination and maybe , maybe the nonlinear discrimination isn't necessary . good good to know . but the other part you were saying was the spectral subtraction , so you just , at what stage do you do that ? do you 're doing that ,
B: so it would be on the on the mel frequency bands , be before everything .
C: so just do that on the mel
D: we we was thinking to do before after vad we exactly when it 's better .
C: so so that that the way that they 're one thing that would be no good to find out about from this conference call is that what they were talking about , what they 're proposing doing , was having third party , , run good vad , and determine boundaries . and then given those boundaries , then have everybody do the recognition .
D: begin to work .
C: the reason for that was that , , if some one one group put in the vad and another didn't , or one had better vad than the other since that they 're not viewing that as being part of the task , and that any manufacturer would put bunch of effort into having some good speech - silence detection . it still wouldn't be perfect the argument was "" let 's not have that be part of this test . "" "" let 's let 's separate that out . "" they argued about that yesterday but we should find out . 'm we 'll find out soon what they , what they decided . so there 's the question of the vad but otherwise it 's it 's on the , the mel fil filter bank , , energies ? you do doing the ? and you 're you 're subtracting in the in the it 's power domain , or magnitude domain . probably power domain , right ?
B: it 's power domain , . don't remember exactly . so it 's before everything else ,
C: if you look at the theory , it 's it should be in the power domain but , , 've seen implementations where people do it in the magnitude domain have asked people why and they shrug their shoulders and say , "" , it works . "" and there 's this there 's this mysterious people who do this lot have developed little tricks of the trade . there 's there 's this , you don't just subtract the estimate of the noise spectrum . you subtract th that times or or less ,
B: and generated this , so you have the estimation of the power spectra of the noise , and you multiply this by factor which is depend dependent on the snr . when the speech lev when the signal level is more important , compared to this noise level , the coefficient is small , and around one . but when the power le the signal level is small compared to the noise level , the coefficient is more important . and this reduce actually the music musical noise , which is more important during silence portions , when the the energy 's small . so there are tricks like this but , mmm .
A: is the estimate of the noise spectrum running estimate ?
C: that 's , that 's what differs from different tasks and different , spectral subtraction methods . if you have , , fair assurance that , , the noise is quite stationary , then the smartest thing to do is use as much data as possible to estimate the noise , get much better estimate , and subtract it off . but if it 's varying , which is gonna be the case for almost any real situation , you have to do it on - line , , with some forgetting factor .
A: so do you is there some long window that extends into the past over which you calculate the average ?
C: there 's lot of different ways of computing the noise spectrum . so one of the things that , , hans - guenter hirsch did , and pas and other people actually , he 's he wasn't the only one , was to , , take some period of of speech and in each band , , develop histogram . so , to get decent histogram of these energies takes at least few seconds really . but , you can do it with smaller amount but it 's pretty rough . and , , the nist standard method of determining signal - to - noise ratio is based on this . no , no , it 's based on this method , this histogram method . so you have histogram . now , if you have signal and you have noise , you have these two bumps in the histogram , which you could approximate as two gaussians .
A: but wh don't they overlap sometimes ?
C: so you have mixture of two gaussians . and you can use to figure out what it is . . so so now you have this mixture of two gaussians , you they are , you estimate what they are , so this gives you what the signal is and what the noise energy is in that band in the spectrum . and then you look over the whole thing and now you have noise spectrum . so , , hans - guenter hirsch and others have used that method . and the other thing to do is which is more trivial and obvious is to , , determine through magical means that , , there 's no speech in some period , and then see what the spectrum is . it 's that 's tricky to do . it has mistakes . and if you 've got enough time , , this other method appears to be somewhat more reliable . variant on that for just determining signal - to - noise ratio is to just , you can do an iterative thing , - like thing , to determine means only . it is still , but just determine the means only . don't worry about the variances . and then you just use those mean values as being the , signal - to - noise ratio in that band .
A: but what is the it seems like this thing could add to the latency . depending on where the window was that you used to calculate the signal - to - noise ratio .
C: cuz if you don't look into the future ,
A: that that was my question ,
C: at the beginning you have some it 's an interesting question . wonder how they did do it ?
B: actually , it 's mmm if - if you want to have good estimation on non - stationary noise you have to look in the in the future . if you take your window and build your histogram in this window , , what you can expect is to have an estimation of th of the noise in the middle of the window , not at the end .
C: but what does what does alcatel do ? and and france telecom .
B: they just look in the past . it works because the noise are , pret , almost stationary
C: , you 're talking about non - stationary noise but that spectral subtraction is rarely is not gonna work really for non - stationary noise ,
B: if if you have good estimation of the noise , it has to work .
C: but it 's hard to but that 's hard to do .
B: that 's hard to do .
C: so so that what is wh what 's more common is that you 're going to be helped with slowly varying or stationary noise . that 's what spectral subtraction will help with , practically speaking . if it varies lot , to get if if to get good estimate you need few seconds of speech , even if it 's centered , if you need few seconds to get decent estimate but it 's changed lot in few seconds , then it , , it 's problem . imagine five hertz is the middle of the of the speech modulation spectrum , so imagine jack hammer going at five hertz .
B: so in this case , , , you cannot but , hirsch does experiment with windows of like between five hundred milliseconds and one second . five hundred wa was not so bad . and he worked on non - stationary noises , like noise modulated with , wi with amplitude modulations things like that ,
A: were his , , windows centered around the
B: in the paper he showed that actually the estimation of the noise is delayed . it 's there is you have to center the window ,
C: no , understand it 's better to do but think that , , for real noises wh what 's most likely to happen is that there 'll be some things that are relatively stationary where you can use one or another spectral subtraction thing and other things where it 's not so stationary you can always pick something that falls between your methods , but if , , if sinusoidally , , modul amplitude modulated noise is big problem in practice .
A: we could probably get really good estimate of the noise if we just went to the noise files , and built the averages from them .
B: what do you mean ?
C: you 're saying , cheat .
B: but if the if the noise is stationary perhaps you don't even need some noise estimation algorithm . we just take th the beginning of the utterance know if people tried this for aurora .
D: it 's the same .
B: everybody seems to use some adaptive , , scheme is it very useful
A: very slow adaptation .
C: the word "" stationary "" is has very precise statistical meaning . but , , in signal - processing really what we 're talking about is things that change slowly , , compared with our processing techniques . so if you 're driving along in car would think that most of the time the nature of the noise is going to change relatively slowly . it 's not gonna stay absolute the same . if you if you check it out , , five minutes later you may be in different part of the road using the local characteristics in time , is probably going to work pretty . but you could get hurt lot if you just took some something from the beginning of all the speech , of , , an hour of speech so they may be , may be overly , , complicated for this test but what you 're saying , , makes sense , though . if possible you shouldn't you should make it , , the center of the center of the window . we 're already having problems with these delay , delay issues . we 'll have to figure ways without it .
A: if they 're going to provide , , voice activity detector that will tell you the boundaries of the speech , then , couldn't you just go outside those boundaries and do your estimate there ?
C: so imagine that 's what they 're doing , they 're probably looking in nonspeech sections and getting some ,
B: they have some threshold on the previous estimate , , ericsson used this threshold . , so , they they have an estimate of the noise level and they put threshold like six or ten db above , what 's under this threshold is used to update the estimate . is is that right so it 's it 's
D: have not here the proposal .
B: it 's like saying what 's under the threshold is silence ,
C: does france telecom do this does france telecom do th do the same thing ? more or less ?
D: do have not here the proposal .
C: if we 're we 're done with that , let 's see . maybe we can talk about couple other things briefly , just , , things that we 've been chatting about but haven't made it into these meetings yet . so you 're coming up with your quals proposal , and , wanna just give two three minute summary of what you 're planning on doing ?
E: two , three , it can be shorter than that . 've 've talked to some of you already . but 'm , , looking into extending the work done by larry saul and john allen and mazin rahim . they have system that 's , , multi - band , , system but their multi - band is little different than the way that we 've been doing multi - band in the past , where where we 've been @ @ taking sub - band features and training up these neural nets and on phonetic targets , and then combining them some somehow down the line , they 're they 're taking sub - band features and , , training up detector that detects for , , these phonetic features , he presents , , detector to detect sonorance . and so what it is , it 's there 's at the lowest level , there it 's an or ga , it 's an and gate . so , , on each sub - band you have several independent tests , to test whether , there 's the existence of sonorance in sub - band . and then , , it it 's combined by soft and gate . and at the at the higher level , for every if , the higher level there 's soft or gate . so if this detector detects , the presence of sonorance in any of the sub - bands , then the detect , the or gate at the top says , "" , this frame has evidence of sonorance . ""
A: what are what are some of the low level detectors that they use ?
E: and these are all the low level detectors are logistic regressions .
C: so that , , is is one of the units in our in our neural network . so that 's all it is . it 's sig it 's sigmoid , with weighted sum at the input , which you train by gradient descent .
E: so he uses , , an algorithm to train up these parameters for the logistic regression .
C: so was using to get the targets . so so you have this this and gate what we were calling an and gate , but it 's product rule thing at the output . and then he uses , , and then feeding into that are there 's it 's an or at the output , isn't it ? so that 's the product . then he has each of these and things . so they 're little neural units . they have to have targets . and so the targets come from .
A: and so are each of these , low level detectors are they , are these something that you decide ahead of time , like "" 'm going to look for this particular feature or 'm going to look at this frequency , "" what what are they looking at ? what are their inputs ?
E: so at each for each sub - band there are , , several measures of snr and correlation . and he said there 's like twenty of these per sub - band . and for every every sub - band , you just pick ahead of time , , "" 'm going to have like five independent logistic tests . "" and you initialize these parameters , , in some way and use to come up with your training targets for for the low - level detectors . and then , once you get that done , you you train the whole thing on maximum likelihood . and he shows that using this method to detect sonorance is it 's very robust compared to , to typical , , full - band gaussian mixtures estimations of sonorance . so that 's just that 's just one detector . so you can imagine building many of these detectors on different features . you get enough of these detectors together , , then you have enough information to do , , higher level discrimination , and then you keep working your way up until you build full recognizer . so , , that 's that 's the direction which 'm 'm thinking about going in my quals .
C: it has number of properties that really liked . one is the going towards , , using narrow band information for , , ph phonetic features of some sort rather than just , , immediately going for the typical sound units . another thing like about it is that you this thing is going to be trained explicitly trained for product of errors rule , which is what , , allen keeps pointing out that fletcher observed in the twenties , for people listening to narrow band . that 's friday 's talk , . and then , , the third thing like about it is , and we 've played around with this in different way little bit but it hasn't been our dominant way of operating anything , this issue of where the targets come from . so in our case when we 've been training it multi - band things , the way we get the targets for the individual bands is , , that we get the phonetic label for the sound there and we say , "" , we train every "" what this is saying is , , that 's maybe what our ultimate goal is or not ultimate but penultimate goal is getting these small sound units . but but , , along the way how much should we , what should we be training these intermediate things for ? because , , we , that this is particularly good feature . there 's no way , someone in the audience yesterday was asking , "" couldn't you have people go through and mark the individual bands and say where the where it was sonorant or not ? "" but , , having bunch of people listening to critical band wide , , chunks of speech trying to determine whether it 'd be impossible . it 's all gonna sound like sine waves to you , more or less . it 's very hard for someone to person to make that determination . we don't really know how those should be labeled . it could sh be that you should , , not be paying that much attention to , , certain bands for certain sounds , , in order to get the best result . so , , what we have been doing there , just mixing it all together , is certainly much cruder than that . we trained these things up on the on the , the final label . now we have done experiments you 've probably done where you have , , done separate , , viterbis on the different
E: forced alignment on the sub - band labels ?
C: you 've done that . did did that help ?
E: it helps for one or one iteration but , anything after that it doesn't help .
C: so so that may or may it that aspect of what he 's doing may or may not be helpful because in sense that 's the same thing . you 're taking global information and determining what you how you should but this is this is , , th little more direct .
A: how did they measure the performance of their detector ?
C: he 's look he 's just actually looking at , , the confusions between sonorant and non - sonorant . so he hasn't applied it to recognition or if he did he didn't talk about it . it 's it 's just and one of the concerns in the audience , actually , was that , , the , , he did comparison to , , , our old foil , the nasty old standard recognizer with mel filter bank at the front , and ms , and . and , , it didn't do nearly as , especially in noise . one of the good questions in the audience was , , , but that wasn't trained for that . this use of very smooth , , spectral envelope is something that , , has evolved as being generally good thing for speech recognition but if you knew that what you were gonna do is detect sonorants or not so sonorants and non - sonorants is is almost like voiced - unvoiced , except that the voiced stops are also called "" obstruents "" . it 's , but with the exception of the stops it 's the same as voiced - unvoiced , if you knew you were doing that , if you were doing something say for , vocoder , you wouldn't use the same features . you would use something that was sensitive to the periodicity and not just the envelope . and so in that sense it was an unfair test . so that the questioner was right . it it was in that sense an unfair test . nonetheless , it was one that was interesting because , , this is what we are actually using for speech recognition , these smooth envelopes . and this says that perhaps even , , trying to use them in the best way that we can , that that we ordinarily do , with , , gaussian mixtures and ms and , you don't , , actually do that on determining whether something is sonorant or not . which means you 're gonna make errors between similar sounds that are son sonorant or obstruent .
A: didn't they also do some an oracle experiment where they said "" if we could detect the sonorants perfectly and then show how it would improve speech recognition ? remember hearing about an experiment like that .
C: the - these same people ? don't remember that . that would that 's you 're right , that 's exactly the question to follow up this discussion , is suppose you did that , , got that right .
B: what could be the other low level detectors , , for other features , in addition to detecting sonorants th - that 's what you want to to go for also
E: build other detectors on different phonetic features ?
B: other low level detectors ?
E: let 's see , easiest thing would be to go do some voicing but that 's very similar to sonorance .
A: when we when we talked with john ohala the other day we made list of some of the things that
C: so there 's half dozen like that are now this was coming at it from different angle but maybe it 's good way to start . these are things which , , john felt that , human annotator would be able to reliably mark . so the things he felt would be difficult for human annotator to reliably mark would be tongue position kinds of things .
A: there 's also things like stress . you can look at stress .
C: but stress doesn't , , fit in this thing of coming up with features that will distinguish words from one another , it 's it 's good thing to mark and will probably help us ultimate with recognition
A: there 's few cases where it can like permit and permit . but that 's not very common in english . in other languages it 's more , important .
C: but either case you 'd write permit , so you 'd get the word right .
A: no , 'm saying , you were saying that stress doesn't help you distinguish between words . see what you 're saying . as long as you get the sequence ,
C: we 're if we 're doing if we 're talking about transcription as opposed to something else
A: so where it could help is maybe at higher level .
E: like understanding application .
C: but that 's this afternoon 's meeting . we don't understand anything in this meeting . that 's , , neat thing
E: so , , ohala 's going to help do these , transcriptions of the meeting data ?
A: we we didn't get that far . we just talked about some possible features that could be marked by humans because of having maybe some extra transcriber time we thought we could go through and mark some portion of the data for that .
C: that 's not an immediate problem , that we don't immediately have lot of extra transcriber time . but but , , in the long term chuck is gonna continue the dialogue with john and , we 'll we 'll end up doing some .
A: 'm definitely interested in this area , too ,
C: it 's an interesting way to go . say it like "" said - int "" . it has number of good things . so , , you want to talk maybe two or three minutes about what we 've been talking about today and other days ?
F: we 're interested in , , methods for far mike speech recognition , mainly , , methods that deal with the reverberation in the far mike signal . one approach would be , , say msg and plp , like was used in aurora one and , , there are other approaches which actually attempt to remove the reverberation , instead of being robust to it like msg . and so we 're interested in , , comparing the performance of , robust approach like msg with these , , speech enhancement or de - reverber de - reverberation approaches . and , , it looks like we 're gonna use the meeting recorder digits data for that .
B: and the de - reverberation algorithm , do you have can you give some more details on this or ? does it use one microphone ?
F: there was something that was done by , , guy named carlos , forget his last name , who worked with hynek , who , , it was like rasta in the sense that of it was , , de - convolution by filtering except he used longer time window , like second maybe . and the reason for that is rasta 's time window is too short to , include the whole , , reverberation what you call it the reverberation response . if you see wh if you see what . the reverberation filter from my mouth to that mike is like it 's got it 's too long in the in the time domain for the for the rasta filtering to take care of it . then there are couple of other speech enhancement approaches which haven't been tried for speech recognition yet but have just been tried for enhancement , which , , have the assumption that , you can do lpc analysis of th of the signal you get at the far microphone and the , , all pole filter that you get out of that should be good . it 's just the , , excitation signal that is going to be distorted by the reverberation and so you can try and reconstruct better excitation signal and , , feed that through the , all pole filter and get enhanced speech with reverberation reduced .
C: there 's also this , , , , echo cancellation that we 've been chasing , and when we 're saying these digits now we do have close microphone signal and then there 's the distant microphone signal . and you could as baseline say , "" , given that we have both of these , , we should be able to do , , cancellation . "" so that , , , we , , essentially identify the system in between the linear time invariant system between the microphones and and re and invert it , or cancel it out to some reasonable approximation through one method or another . that 's not practical thing , if you have distant mike , you don't have close mike ordinarily , but we thought that might make also might make good baseline . it still won't be perfect because there 's noise . and then there are , there are single microphone methods that people have done for , for this de - reverberation . do do any references to any ? cuz was lead him down bad path on that .
B: when people are working with single microphones , they are more trying to do there is the avendano work , but also trying to mmm , trying to find the de - convolution filter not in the time domain but in the the stream of features . @ @ there 's someone working on this on in mons we should try to he 's working on this , on re reverberation ,
C: the first paper on this is gonna have great references , it 's always good to have references , especially when reviewers read it or one of the authors and , feel they 'll "" you 're , you 've you cited me . ""
B: he did echo cancellation and he did some fancier things like , , , training different network on different reverberation conditions and then trying to find the best one ,
C: the oth the other thing , , that dave was talking about earlier was , , multiple mike things , where they 're all distant . so , , , there 's there 's all this work on arrays , but the other thing is , , what can we do that 's cleverer that can take some advantage of only two mikes , particularly if there 's an obstruction between them , as we as we have over there .
B: if there is ?
C: an obstruction between them . which is helpful . it 's part of why you have such good directionality with , with two ears even though they 're not several feet apart . for most for most people 's heads .
A: that could help though .
C: the head , in the way , is really that 's what it 's for .
A: that 's what the head 's for ? to separate the ears ?
C: it 's to separate the ears . that 's right , , that 's that 's all we have this week . and , , it 's digit time .
A: actually the , for some reason the digit forms are blank . th that may be due to the fact that adam ran out of digits , , and didn't have time to regenerate any .
C: there 's no real reason to write our names on here then ,
A: if you want to put your credit card numbers and ,
C: or do did any do we need the names for the other ,
A: do need your names and the time , and all that , cuz we put that into the "" key "" files . that 's why we have the forms , even if there are no digits .
C: didn't notice this . and was was about to read them too . it 's , , blank sheet of paper .
A: so we 're we 're done .
C: 'll do my credit card number later .
","The Berkeley Meeting Recorder Group discussed the progress of several of their members.
The progress being made on the group's main project , a speech recogniser for the cellular industry was reported.
The group also touched upon matters that had broader implications for the work , such as the work of other groups on the same project.
There were also some progress reports from group members working on other projects.
No one from the group attended a recent video conference about their main project , but they need to find out what was discussed in it.
Until they do , they will continue on , assuming nothing major has been changed.
Need to discuss any new investigation with partners to make sure work is not repeated.
There was a recent video conference meeting discussing the cellular project , but no one from the group attended and so do not know if it has any implications for their work , if any important decisions were made.
This includes decisions on the desired latency for the system , since the group is currently at the limit.
Spectral subtraction , which the group is currently investigating as a method of dealing with noise , may add to the delay time , but also it is hard to do with non-linear noise.
Speakers mn007 and fn002 have been working on the groups main project , looking for bugs in the system , and trying to improve latency.
The group's work currently has the highest latency on the project , and they are looking for ways to cut the delays.
These include replacing FIR filters with IIR , and investigating spectral subtraction methods which do not require taking the future into account.
Speaker me006 has put together a proposal to extend work on a multiband system using low-level detectors , and applying it to recognition.
Speaker me026 has been looking at method for recognition using far mics , trying to deal with reverberation and echo-cancellation.
"
ami_abstractive_summary,Bro005.txt,"A: mike . mike - one ?
D: we 're on ? we 're testing noise robustness but let 's not get silly . so , , you 've got some , , xerox things to pass out ?
A: 'm for the table , but as it grows in size , , it .
D: so for th the last column we use our imagination .
B: do you want @ @ .
D: this one 's , though . this has big font .
C: let 's see .
D: when you get older you have these different perspectives . lowering the word hour rate is fine , but having big font !
A: next time we will put colors .
D: that 's what 's it 's mostly big font .
A: so there is summary of what has been done it 's this . summary of experiments since , , since last week and also since the we 've started to run work on this . so since last week we 've started to fill the column with features with nets trained on plp with on - line normalization but with delta also , because the column was not completely
D: - . - .
A: it 's still not completely filled , but we have more results to compare with network using without plp and finally , hhh , ehhh pl - delta seems very important . if you take , let 's say , anyway aurora - two - , so , the next the second , , part of the table , when we use the large training set using french , spanish , and english , you have one hundred and six without delta and eighty - nine with the delta .
D: all of these numbers are with hundred percent being , , the baseline performance ,
A: on the baseline , .
D: but with mel cepstra system going straight into the htk ?
A: so now we see that the gap between the different training set is much much smaller
C: it 's out of the way .
A: but , actually , , for english training on timit is still better than the other languages . and also for italian , actually . if you take the second set of experiment for italian , so , the mismatched condition , when we use the training on timit so , it 's multi - english , we have ninety - one number , and training with other languages is little bit worse .
D: down near the bottom of this sheet .
A: and , , and here the gap is still more important between using delta and not using delta . if if take the training the large training set , it 's we have one hundred and seventy - two , and one hundred and four when we use delta . even if the contexts used is quite the same , because without delta we use seventeenths seventeen frames . , so the second point is that we have no single cross - language experiments , , that we did not have last week . so this is training the net on french only , or on english only , and testing on italian . and training the net on french only and testing on , ti - digits . what we see is that these nets are not as good , except for the multi - english , which is always one of the best . then we started to work on large dat database containing , , sentences from the french , from the spanish , from the timit , from spine , from english digits , and from italian digits . so this is the another line another set of lines in the table . @ @ with spine and , actually we did this before knowing the result of all the data , so we have to redo the the experiment training the net with , plp , but with delta . this net performed quite . it 's it 's better than the net using french , spanish , and english only . we have also started feature combination experiments . many experiments using features and net outputs together . and this is the results are on the other document . we can discuss this after , perhaps , just , @ @ . so there are four systems . the first one , , is combining , , two feature streams , using and each feature stream has its own mpl . so it 's the similar to the tandem that was proposed for the first . the multi - stream tandem for the first proposal . the second is using features and klt transformed mlp outputs . and the third one is to use single klt trans transform features as as mlp outputs . you can you can comment these results ,
B: would like to say that , , , mmm , if we doesn't use the delta - delta , we have an improve when we use some combination .
A: we ju just to be clear , the numbers here are recognition accuracy .
B: this , this number recognition acc
A: so it 's not the again we switch to another
B: yes , and the baseline the baseline have is eighty - two .
D: baseline is eighty - two .
A: so it 's experiment only on the italian mismatched for the moment for this .
D: this is italian mismatched .
B: by the moment . and first in the experiment - one do use different mlp , and is that the multi - english mlp is the better . for the ne rest of experiment use multi - english , only multi - english . and try to combine different type of feature , but the result is that the msg - three feature doesn't work for the italian database because never help to increase the accuracy .
A: , actually , if we look at the table , the huge table , we see that for ti - digits msg perform as as the plp , but this is not the case for italian what where the error rate is is almost twice the error rate of plp . so , , , don't think this is bug but this is something in probably in the msg process that perhaps the fact that the there 's no low - pass filter , or no pre - emp pre - emphasis filter and that there is some dc offset in the italian , something simple like that . but that we need to sort out if want to get improvement by combining plp and msg because for the moment msg do doesn't bring much information . and as carmen said , if we combine the two , we have the result , , of plp .
D: the , baseline system when you said the baseline system was , eighty - two percent , that was trained on what and tested on what ? that was , italian mismatched , digits , , is the testing , and the training is italian digits ? so the "" mismatch "" just refers to the noise and , microphone and , so , did we have so would that then correspond to the first line here of where the training is the italian digits ?
B: the train the training of the htk ? th - yes .
D: training of the net , so , so what that says is that in matched condition , we end up with fair amount worse putting in the plp . now would do we have number , suppose for the matched don't mean matched , but use of italian training in italian digits for plp only ?
A: so this is this is in the table . so the number is fifty - two ,
D: fifty - two percent .
A: fift - so no , it 's it 's the
D: no , fifty - two percent of eighty - two ?
A: so it 's it 's error rate , .
B: it 's plus six .
A: it 's er error rate ratio .
D: this is accuracy !
A: so we have nine let 's say ninety percent . which is what we have also if use plp and msg together , eighty - nine point seven .
D: so even just plp , , it is not , in the matched condition wonder if it 's difference between plp and mel cepstra , or whether it 's that the net half , for some reason , is not helping .
A: - plp and mel cepstra give the same results . we have these results . do you have this result with plp alone , fee feeding htk ? that 's what you mean ? just plp at the input of htk .
B: at the first and the
D: eighty - eight point six . but that 's , that 's without the neural net ,
A: that 's without the neural net and that 's the result that ogi has also with the mfcc with on - line normalization .
D: but she had said eighty - two .
A: this is the , but this is without on - line normalization .
D: this the eighty - two .
A: eighty - two is the it 's the aurora baseline , then we can use ogi , they use mfcc th the baseline mfcc plus on - line normalization
D: because this is accuracy . alright . so this is was thinking all this was worse . so this is all better
B: yes , better .
D: because eighty - nine is bigger than eighty - two . 'm 'm all better now .
A: so what happ what happens is that when we apply on - line normalization we jump to almost ninety percent . when we apply neural network , is the same . we jump to ninety percent .
B: nnn , we exactly .
A: whatever the normalization , actually . if we use neural network , even if the features are not correctly normalized , we jump to ninety percent .
D: so we go from eighty - si eighty - eight point six to ninety , .
A: it 's around eighty - nine , eighty - eight .
D: eighty - nine .
A: there are minor differences .
D: and then adding the msg does nothing , .
A: for italian , .
D: for this case , right ? so , so actually , the answer for experiments with one is that adding msg , if you does not help in that case . the other ones , we 'd have to look at it , and the multi - english , does so if we think of this in error rates , we start off with , eighteen percent error rate , roughly . and we almost , cut that in half by putting in the on - line normalization and the neural net . and the msg doesn't however particularly affect things . and we cut off , about twenty - five percent of the error . no , not quite that , two point six out of eighteen . about , sixteen percent of the error , , if we use multi - english instead of the matching condition . not matching condition , but , the , italian training .
B: we select these these tasks because it 's the more difficult .
D: yes , good . so then you 're assuming multi - english is closer to the thing that you could use since you 're not gonna have matching , , data for the for the new for the other languages and . one qu thing is that , asked you this before , but wanna double check . when you say "" me "" in these other tests , that 's the multi - english ,
A: that 's it 's part it 's
D: but it is not all of the multi - english , it is some piece of part of it .
A: or , one million frames .
D: and the multi - english is how much ?
B: you have here the information .
A: it 's one million and half .
D: so you used almost all you used two thirds of it , so , it 's still it hurts you seems to hurt you fair amount to add in this french and spanish .
C: stephane was saying that they weren't hand - labeled , the french and the spanish .
B: maybe for that .
D: alright , go ahead .
B: mmm , with the experiment type - two , first tried to combine , nnn , some feature from the mlp and other feature and we we can first the feature are without delta and delta - delta , and we can see that in the situation , , the msg - three , the same help nothing . and then do the same but with the delta and delta - delta plp delta and delta - delta . and they all but they all put off the mlp is it without delta and delta - delta . and we have little bit less result than the the baseline plp with delta and delta - delta . maybe if when we have the new neural network trained with plp delta and delta - delta , maybe the final result must be better .
A: actually , just to be some more this number , this eighty - seven point one number , has to be compared with the
D: yes , , it can't be compared with the other cuz this is , with multi - english , , training . so you have to compare it with the one over that you 've got in box , which is that , the eighty - four point six .
A: but in this case for the eighty - seven point one we used mlp outputs for the plp net and straight features with delta - delta . and straight features with delta - delta gives you what 's on the first sheet . it 's eight eighty - eight point six .
D: tr no . no . not trained with multi - english .
A: , but th this is the second configuration .
B: no , but they feature @ @ without
A: so we use feature out , net outputs together with features . this is not perhaps not clear here but in this table , the first column is for mlp and the second for the features .
D: so you 're saying so asking the question , "" what what has adding the mlp done to improve over the ,
A: so , actually it it decreased the accuracy . because we have eighty - eight point six . and even the mlp alone what gives the mlp alone ? multi - english plp . it gives eighty - three point six . so we have our eighty - three point six and now eighty - eighty point six , that gives eighty - seven point one .
D: eighty - three point six and eighty - eight point six .
A: eighty - three point six . is th is that right ?
B: but maybe if we have the neural network trained with the plp delta and delta - delta , maybe tha this can help .
D: that 's that 's one thing , but see the other thing is that , it 's good to take the difficult case , but let 's let 's consider what that means . what what we 're saying is that one one of the things that my interpretation of your original suggestion is something like this , as motivation . when we train on data that is in one sense or another , similar to the testing data , then we get win by having discriminant training . when we train on something that 's quite different , we have potential to have some problems . and , , if we get something that helps us when it 's somewhat similar , and doesn't hurt us too much when it when it 's quite different , that 's maybe not so bad . so the question is , if you took the same combination , and you tried it out on , on say digits ,
A: on ti - digits ?
D: was that experiment done ?
A: no , not yet .
D: then does that , maybe with similar noise conditions and , does it does it then look much better ? and so what is the range over these different kinds of of tests ? so , an anyway .
B: and , with this type of configuration which do on experiment using the new neural net with name broad klatt twenty - seven , have found more or less the same result .
A: so , it 's slightly better ,
B: little bit better ? slightly bet better . yes , is better .
D: and maybe if you use the , , delta there , , you would bring it up to where it was , at least about the same for difficult case .
B: maybe . maybe .
A: so perhaps let 's let 's jump at the last experiment . it 's either less information from the neural network if we use only the silence output . it 's again better . so it 's eighty - nine point one .
B: and we have only forty feature because in this situation we have one hundred and three feature . and then with the first configuration , am found that work , , doesn't work but is better , the second configuration . because for the del engli - plp delta and delta - delta , here have eighty - five point three accuracy , and with the second configuration have eighty - seven point one .
D: , there is another , , suggestion that would apply , , to the second configuration , which , , was made , , by , , hari . and that was that , , if you have feed two streams into htk , , and you , , change the , variances if you scale the variances associated with , these streams , you can effectively scale the streams . so , , , without changing the scripts for htk , which is the rule here , , you can still change the variances which would effectively change the scale of these , , two streams that come in . and , , so , , if you do that , it may be the case that , , the mlp should not be considered as strongly , . and , , so this is just setting them to be , of equal weight . maybe it shouldn't be equal weight . right ? , 'm to say that gives more experiments if we wanted to look at that , but , , , on the other hand it 's just experiments at the level of the htk recognition . it 's not even the htk , you have to do the htk training also .
B: so this is what we decided to do .
D: let me think . maybe you don't . you have to change the no , you can just do it in as once you 've done the training
C: and then you can vary it .
D: the training is just coming up with the variances so you could you could just scale them all .
A: is it th the htk models are diagonal covariances ,
D: that 's , exactly the point , , that if you change , change what they are it 's diagonal covariance matrices , but you say what those variances are . so , that , it 's diagonal , but the diagonal means th that then you 're gonna it 's gonna internally multiply it and , , it im implicitly exponentiated to get probabilities , and so it 's it 's gonna it 's going to affect the range of things if you change the change the variances of some of the features . so , it 's precisely given that model you can very simply affect , , the the strength that you apply the features . that was that was , , hari 's suggestion . so it could just be that treating them equally , tea treating two streams equally is just not the right thing to do . it 's potentially opening can of worms because , , maybe it should be different number for each test set , , so the other thing is to take if one were to take , , , couple of the most successful of these ,
A: and test across everything .
D: try all these different tests .
A: so , the next point , we 've had some discussion with steve and shawn , about their , , articulatory , so we 'll perhaps start something next week . discussion with hynek , sunil and pratibha for trying to plug in their our networks with their within their block diagram , where to plug in the network , , after the feature , before as as plugin or as anoth another path , discussion about multi - band and traps , actually hynek would like to see , perhaps if you remember the block diagram there is , , temporal lda followed by spectral lda for each critical band . and he would like to replace these by network which would , , make the system look like trap . , it would be trap system . this is trap system trap system , , but where the neural network are replaced by lda . and about multi - band , started multi - band mlp trainings , mmh actually , hhh prefer to do exactly what did when was in belgium . so take exactly the same configurations , seven bands with nine frames of context , and we just train on timit , and on the large database , so , with spine and everything . mmm , 'm starting to train also , networks with larger contexts . so , this would be something between traps and multi - band because we still have quite large bands , and but with lot of context also . we still have to work on finnish , , to make decision on which mlp can be the best across the different languages . for the moment it 's the timit network , and perhaps the network trained on everything . so . now we can test these two networks on with delta and large networks . test them also on finnish and see which one is the the best . , the next part of the document is , , , summary of what everything that has been done . so . we have seventy - nine ps trained on one , two , three , four , , three , four , five , six , seven ten on ten different databases . the number of frames is bad also , so we have one million and half for some , three million for other , and six million for the last one . ! as we mentioned , timit is the only that 's hand - labeled , and perhaps this is what makes the difference . the other are just viterbi - aligned . so these seventy - nine mlp differ on different things . first , with respect to the on - line normalization , there are that use bad on - line normalization , and other good on - line normalization . with respect to the features , with respect to the use of delta with respect to the hidden layer size and to the targets . but we don't have all the combination of these different parameters what 's this ? we only have two hundred eighty six different tests and no not two thousand .
D: ugh ! was impressed
B: say this morning that @ @ thought it was the
D: alright , now 'm just slightly impressed ,
A: the observation is what we discussed already . the msg problem , the fact that the mlp trained on target task decreased the error rate . but when the - mlp is trained on the is not trained on the target task , it increased the error rate compared to using straight features . except if the features are bad actually except if the features are not correctly on - line normalized . in this case the tandem is still better even if it 's trained on not on the target digits .
D: so it sounds like , the net corrects some of the problems with some poor normalization . but if you can do good normalization it 's it 's .
A: so the fourth point is , , the timit plus noise seems to be the training set that gives better the best network .
D: so - let me bef before you go on to the possible issues . so , on the msg problem that in the , in the short time solution that is , , trying to figure out what we can proceed forward with to make the greatest progress , much as said with jrasta , even though really like jrasta and really like msg , it 's in category that it 's , it may be complicated . and it might be if someone 's interested in it , , certainly encourage anybody to look into it in the longer term , once we get out of this particular rush for results . but in the short term , unless you have some strong idea of what 's wrong ,
A: but 've perhaps have the feeling that it 's something that 's quite simple or just like nnn , no high - pass filter
D: there 's supposed to msg is supposed to have an on - line normalization though ,
A: it 's there is , , an agc - agc .
D: but also there 's an on - line norm besides the agc , there 's an on - line normalization that 's supposed to be taking out means and variances and . in fac the on - line normalization that we 're using came from the msg design ,
A: but this was the bad on - line normalization . actually . are your results are still with the bad the bad with the - oln - two ? you have you have oln - two ,
B: with "" two "" , with "" on - line - two "" .
D: "" on - line - two "" is good .
A: so it 's , is the good .
B: it 's good .
D: "" two "" is good ? no , "" two "" is bad .
B: actually , it 's good with the ch with the good .
D: so , agree . it 's probably something simple if someone , , , wants to play with it for little bit . you 're gonna do what you 're gonna do but my would be that it 's something that is simple thing that could take while to find . and the other the results , observations two and three , , is that 's what we 've seen . that 's that what we were concerned about is that if it 's not on the target task if it 's on the target task then it it helps to have the mlp transforming it . if it if it 's not on the target task , then , depending on how different it is , you can get , reduction in performance . and the question is now how to how to get one and not the other ? or how to how to ameliorate the problems . because it certainly does is to have in there , when it when there is something like the training data .
A: so , the reason , the reason is that the perhaps the target the task dependency the language dependency , and the noise dependency
D: so that 's what you say th there .
A: the but this is still not clear don't think we have enough result to talk about the language dependency . the timit network is still the best but there is also an the other difference , the fact that it 's it 's hand - labeled .
D: just you can just sit here . don't think we want to mess with the microphones just , have seat . summary of the first , forty - five minutes is that some work and works , and some doesn't
A: we still have this one of these perhaps ?
D: we can do little better than that but if you if you start off with the other one , actually , that has it in words and then th that has it the associated results . so you 're saying that , although from what we see , yes there 's what you would expect in terms of language dependency and noise dependency . that is , , when the neural net is trained on one of those and tested on something different , we don't do as as in the target thing . but you 're saying that , it is although that general thing is observable so far , there 's something you 're not completely convinced about . and and what is that ? you say "" not clear yet "" . what what do you mean ?
A: mmm , , , that the fact that , for ti - digits the timit net is the best , which is the english net . but the other are slightly worse . but you have two effects , the effect of changing language and the effect of training on something that 's viterbi - aligned instead of hand - labeled .
D: do you think the alignments are bad ? have you looked at the alignments ? what the viterbi alignment 's doing ?
A: did - did you look at the spanish alignments carmen ?
B: mmm , no .
D: might be interesting to look at it . because , , that is just looking but , it 's not clear to me you necessarily would do so badly from viterbi alignment . it depends how good the recognizer is that 's that the engine is that 's doing the alignment .
A: but . but , perhaps it 's not really the alignment that 's bad but the just the ph phoneme string that 's used for the alignment
D: the pronunciation models and
A: it 's single pronunciation , french , phoneme strings were corrected manually so we asked people to listen to the the sentence and we gave the phoneme string and they correct them . there might be errors just in the in the ph string of phonemes . so this is not really the viterbi alignment , the third the third issue is the noise dependency perhaps but , , this is not clear yet because all our nets are trained on the same noises
D: some of the nets were trained with spine and . so it and that has other noise .
A: results are only coming for this net .
D: , just don't just need more results there with that @ @ .
A: so . , from these results we have some questions with answers . what should be the network input ? plp work as as mfcc , . but it seems impor important to use the delta . with respect to the network size , there 's one experiment that 's still running and we should have the result today , comparing network with five hundred and one thousand units . nnn , still no answer actually . the training set , we can , we can tell which training set gives the best result , but we exactly why .
D: right , the multi - english so far is the best . "" multi - multi - english "" just means "" timit "" , so . and and when you add other things in to broaden it , it gets worse typically .
A: then some questions without answers .
D: the training set is both questions , with answers and without answers . it 's , yes it 's mul it 's multi - - purpose .
A: right . so , the training targets actually , the two of the main issues perhaps are still the language dependency and the noise dependency . and perhaps to try to reduce the language dependency , we should focus on finding some other training targets . and labeling labeling seems important because of timit results . for moment you use we use phonetic targets but we could also use articulatory targets , soft targets , and perhaps even , use networks that doesn't do classification so , train to have neural networks that and , com compute features and noit not , nnn , features without noise . , transform the fea noisy features in other features that are not noisy . but continuous features . not , hard targets .
D: that seems like good thing to do , probably , not again short - term thing . one of the things about that is that it 's the ri the major risk you have there of being is being dependent on very dependent on the noise and . but it 's another thing to try .
A: so , this is wa this is one thing , this could be could help perhaps to reduce language dependency and for the noise part we could combine this with other approaches , like , , the kleinschmidt approach . so the the idea of putting all the noise that we can find inside database . kleinschmidt was using more than fifty different noises to train his network , and so this is one approach and the other is multi - band , that is more robust to the noisy changes . so perhaps , something like multi - band trained on lot of noises with , features - based targets could could help .
D: if you it 's interesting thought maybe if you just trained up one fantasy would be you have something like articulatory targets and you have some reasonable database , but then which is copied over many times with range of different noises , and if cuz what you 're trying to do is come up with core , reasonable feature set which is then gonna be used , by the system .
A: the future work is , , try to connect to the to make to plug in the system to the ogi there are still open questions there , where to put the mlp .
D: and , , the the real open question , there 's lots of open questions , but one of the core quote "" open questions "" for that is , if we take the , the best ones here , maybe not just the best one , but the best few you want the most promising group from these other experiments . how do they do over range of these different tests , not just the italian ? and then then see , again , how we know that there 's mis there 's loss in performance when the neural net is trained on conditions that are different than , we 're gonna test on , but , if you look over range of these different tests , how do these different ways of combining the straight features with the mlp features , stand up over that range ? that 's that seems like the the real question . so if you just take plp with , the double - deltas . assume that 's the the feature . look at these different ways of combining it . and , take let 's say , just take multi - english that works pretty for the training . and just look take that case and then look over all the different things . how does that how does that compare between the
A: so all the all the test sets you mean ,
D: all the different test sets , and for and for the couple different ways that you have of of combining them . how do they stand up , over the
A: and perhaps doing this for cha changing the variance of the streams and so on getting different scaling
D: that 's another possibility if you have time ,
A: so thi this sh would be more working on the mlp as an additional path instead of an insert to the to their diagram . perhaps the insert idea is strange because nnn , they make lda and then we will again add network does discriminate anal nnn , that discriminates ,
D: it 's little strange but on the other hand they did it before .
A: and because also perhaps we know that the when we have very good features the mlp doesn't help .
D: the other thing , though , is that so . , we wanna get their path running here , if so , we can add this other . as an additional path
A: the way we want to do
D: cuz they 're doing lda rasta . they 're doing lda rasta ,
A: the way we want to do it perhaps is to just to get the vad labels and the final features . so they will send us the , provide us with the feature files , and with vad , binary labels so that we can , get our mlp features and filter them with the vad and then combine them with their feature stream .
D: so we so . first thing we 'd wanna do there is to make that when we get those labels of final features is that we get the same results as them . without putting in second path .
A: just re retraining retraining the htk ?
D: just th to make that we have we understand properly what things are , our very first thing to do is to is to double check that we get the exact same results as them on htk . , that we need to do we need to retrain we can just take the re their training files also . but . but , just for the testing , jus just make that we get the same results so we can duplicate it before we add in another cuz otherwise , , we won't things mean .
A: so fff , lograsta , if we want to we can try networks with lograsta filtered features .
D: ! , the other thing is when you say comb 'm 'm , 'm interrupting . that , when you 're talking about combining multiple features , suppose we said , "" , we 've got these different features and , but plp seems pretty good . "" if we take the approach that mike did and have one of the situations we have is we have these different conditions . we have different languages , we have different noises , if we have some drastically different conditions and we just train up different ps with them . and put them together . what what what mike found , for the reverberation case at least , who knows if it 'll work for these other ones . that you did have interpolative effects . that is , that yes , if you knew what the reverberation condition was gonna be and you trained for that , then you got the best results . but if you had , say , heavily - reverberation ca heavy - reverberation case and no - reverberation case , , and then you fed the thing , something that was modest amount of reverberation then you 'd get some result in between the two . so it was behaved reasonably . is tha that fair
A: so you 's perhaps better to have several
D: it works better if what ? you were doing some something that was so maybe the analogy isn't quite right . you were doing something that was in way little better behaved . you had reverb for single variable which was re , reverberation . here the problem seems to be is that we don't have hug really huge net with really huge amount of training data . but we have for this task , would think , modest amount . million frames actually isn't that much . we have modest amount of training data from couple different conditions , and then in , that and the real situation is that there 's enormous variability that we anticipate in the test set in terms of language , and , , channel characteristic , all over the map . bunch of different dimensions . and so , 'm just concerned that we don't really have , the data to train up one of the things that we were seeing is that when we added in we still don't have good explanation for this , but we are seeing that we 're adding in , fe few different databases and the performance is getting worse and , when we just take one of those databases that 's pretty good one , it actually is is better . and that says to me , yes , that , , there might be some problems with the pronunciation models that some of the databases we 're adding in like that . but one way or another we don't have , seemingly , the ability to represent , in the neural net of the size that we have , , all of the variability that we 're gonna be covering . so that 'm 'm hoping that this is another take on the efficiency argument you 're making , which is 'm hoping that with moderate size neural nets , , that if we if they look at more constrained conditions they 'll have enough parameters to really represent them .
A: so doing both is not is not right , you mean ,
D: the it 's true that the ogi folk found that using lda rasta , which is lograsta , it 's just that they have the it 's done in the log domain , as recall , and it 's it it 's just that they it 's trained up , that that benefitted from on - line normalization . so they did at least in their case , it did seem to be somewhat complimentary . so will it be in our case , where we 're using the neural net ? they were not using the neural net . so the other things you have here are , trying to improve results from single and cpu memory issues . we 've been ignoring that ,
A: but we have to address the problem of cpu and memory we
D: you you folks have been looking at this more than me . but my impression was that , there was strict constraint on the delay , but beyond that it was that using less memory was better , and using less cpu was better . something like that ,
A: so , , but we 've we have to get some reference point to where we what 's reasonable number ? perhaps be because if it 's if it 's too large or large
D: don't think we 're completely off the wall . that if we if we have the ultimate fall back that we could do we may find that we 're not really gonna worry about the if the mlp ultimately , after all is said and done , doesn't really help then we won't have it in . if the mlp does , we find , help us enough in some conditions , , we might even have more than one mlp . we could simply say that is , done on the , server . we do the other manipulations that we 're doing before that . so , that 's that 's . so the key thing was , this plug into ogi . what are they what are they gonna be working do we they 're gonna be working on while we take their features ,
A: they 're they 're starting to wor work on some multi - band . this that was pratibha . what was he doing , do you remember ? he was doing something new
B: don't re didn't remember . maybe he 's working with neural network .
A: they were also mainly , working little bit of new things , like networks and multi - band , but mainly trying to tune their system as it is now to just trying to get the best from this architecture .
D: so the way it would work is that you 'd get there 'd be some point where you say , "" , this is their version - one "" or whatever , and we get these vad labels and features and for all these test sets from them , and then , , that 's what we work with . we have certain level we try to improve it with this other path and then , , when it gets to be , january we say , "" we have shown that we can improve this , in this way . so now what 's your newest version ? "" and then maybe they 'll have something that 's better and then we 'd combine it . this is always hard . used to work with folks who were trying to improve good , system with with neural net system and , it was common problem that you 'd and this actually , this is true not just for neural nets but just for in general if people were working with , rescoring , - best lists or lattices that come came from , mainstream recognizer . you get something from the other site at one point and you work really hard on making it better with rescoring . but they 're working really hard , too . so by the time you have , improved their score , they have also improved their score and now there isn't any difference , so , , at some point we 'll have to we 're we 're integrated little more tightly than happens in lot of those cases . at the moment they say that they have better thing we can we what takes all the time here is that th we 're trying so many things , presumably , in in day we could turn around taking new set of things from them and rescoring it ,
A: , perhaps we could .
D: no , this is this is good . that the most wide open thing is the issues about the , , different trainings . da training targets and noises and .
A: so we can for we we can forget combining multiple features and mlg perhaps ,
D: that 's wide open .
A: or focus more on the targets and on the training data
D: for right now , th really liked msg . and that , , one of the things liked about it is has such different temporal properties . and , that there is ultimately really good , potential for , , bringing in things with different temporal properties . we only have limited time and there 's lot of other things we have to look at . and it seems like much more core questions are issues about the training set and the training targets , and fitting in what we 're doing with what they 're doing , and , , with limited time . we have to start cutting down . and then , , once we having gone through this process and trying many different things , would imagine that certain things , come up that you are curious about that you 'd not getting to and so when the dust settles from the evaluation , that would time to go back and take whatever intrigued you most , got you most interested and and work with it , , for the next round . as you can tell from these numbers , nothing that any of us is gonna do is actually gonna completely solve the problem . so , there 'll still be plenty to do . barry , you 've been pretty quiet . but that what were you involved in this primarily ?
C: helping out , preparing they 've been running all the experiments and and 've been , doing some work on the preparing all the data for them to , train and to test on . right now , 'm 'm focusing mainly on this final project 'm working on in jordan 's class .
D: what 's what 's that ?
C: so there was paper in icslp about this multi - band , belief - net structure . this guy did it was two ms with with dependency arrow between the two and so wanna try coupling them instead of having an arrow that flows from one sub - band to another sub - band . wanna try having the arrows go both ways . and , 'm just gonna see if that better models , asynchrony in any way
D: that sounds interesting . anything to you wanted to silent partner in the in the meeting . we got laugh out of him , that 's good . everyone must contribute to the our sound files here . so speaking of which , if we don't have anything else that we need you happy with where we are ? know know wher know where we 're going ? you you happy ? you 're happy . everyone should be happy . you don't have to be happy . you 're almost done .
E: al - actually should mention so if , about the linux machine "" swede . "" so it looks like the , neural net tools are installed there . and dan ellis believe knows something about using that machine if people are interested in getting jobs running on that maybe could help with that .
A: but if we really need now lot of machines . we could start computing another huge table
D: , we want different table , at least there 's there 's some different things that we 're trying to get at now . so . , as far as you can tell , you 're actually on - on cpu , for training and so on ?
A: more is always better , don't think we have to train lot of networks , now that we know we just select what works fine and try to improve this
D: and we 're on and we 're on disk ?
A: it 's , . sometimes we have some problems .
B: some problems with the
D: but they 're correctable , problems . 'm familiar with that one , so , since , we didn't ha get channel on for you , you don't have to read any digits but the rest of us will . is it on ? cuz 'm afraid of making the driver crash which it seems to do , pretty easily . so we 'll 'll start off the
A: my battery is low .
D: let 's hope it works . maybe you should go first and see so that you 're .
C: your battery 's going down too . carmen 's battery is going down too .
D: why don't you go next then . we 're done . just finished digits . it 's good . we can turn off our microphones now .
C: just pull the batteries out .
","The main topic for discussion by the Berkeley Meeting Recorder group was progress on the experiments run as part of the groups main project , a speech recogniser for the cellular industry.
This included reporting the results , and making conclusions to shape future work.
Also discussed were the details of the continued collaboration with project partner OGI.
Further investigation into the lack of difference using MSG features makes should not be made while they are on their current short time scale for results.
Same goes for anything else that comes up and looks interesting , leave it for just now.
Really should pick which results are looking the best at this stage , and take only them further.
Someone should look closely at the non-TIMIT databases , their Viterbi alignments , and their phoneme strings to see is that is why TIMIT is better.
Need to get OGI's system from them , and get it running like they do , before integrating into it.
It is unclear if the English TIMIT database is providing the best results because English is the best language or TIMIT is the most accurately labelled dataset because it was hand labelled.
The results table was very large and difficult to follow; it was unclear which of the numbers were error or accuracy rate , and straight rates or percentages of the baseline.
There is very limited training data , over only a few conditions.
Test and real data is likely to encompass much more variability.
Speakers mn007 and fn002 have made further progress into the series of experiments they have been running in previous weeks; results were varied.
The main conclusions include that training on task data is good , and the best broad training data is the English TIMIT database.
Other results show that MSG makes little difference , adding MLP improves when trained on task data , decreases figures when not , while using delta generally improves the situation , as does on-line normalization.
Starting work with a new broad database drawn from English , French , TIMIT , SPINE and English and Italian digits.
mn007 has also started work on multi-band MLP trainings , with large context.
OGI have a block diagram explaining their system , and the group are trying to fit their work into it.
Speaker me006 has been helping prepare data , but is mainly doing work for a class he takes , looking at modelling asynchrony.
"
ami_abstractive_summary,Bmr010.txt,"A: we seem to be recording . so , about not
G: we 're not crashing .
A: not pre - doing everything . the lunch went little later than was expecting ,
B: chuck was telling too many jokes , ?
G: does anybody have an agenda ?
F: 'm sent couple of items . they 're they 're practical .
G: that 's right .
F: if that 's too practical for what we 're focused on .
A: we don't want anything too practical .
G: we only want th useless things . no , why don't we talk about practical things ?
F: , give you an update on the transcription effort . maybe {nonvocalsound} raise the issue of microphone , , procedures with reference to the cleanliness of the recordings .
G: transcription , , microphone issues
F: and then maybe {nonvocalsound} ask , th , these guys . the we have great , , steps forward in terms of the nonspeech - speech pre - segmenting of the signal .
A: we have steps forward .
F: it 's it 's big improvement .
C: would prefer this .
D: we talk about the results of
A: have little bit of iram but 'm not if that 's of general interest or not . iram , bigram ,
D: bi - bigram .
G: let 's let 's see where we are at three - thirty .
B: since , since have to leave as usual at three - thirty , can we do the interesting first ?
F: beg your pardon ?
A: what 's the interesting ?
F: beg your pardon ?
G: th - now you get to tell us what 's the interesting part .
B: , the work that 's been done on segmentation would be most
F: that would be good thing to start with .
G: and , , the other thing , , which 'll just say very briefly that maybe relates to that little bit , which is that , , one of the suggestions that came up in brief meeting had the other day when was in spain with , , manolo pardo and javier , , ferreiros , who was here before , was , , why not start with what they had before but add in the non - silence boundaries . so , in what javier did before when they were doing , he was looking for , , speaker change points . as simplification , he originally did this only using silence as , , putative , , speaker change point . and , , he did not , say , look at points where you were changing broad sp , phonetic class , . and for broadcast news , that was fine . here it 's not . and , , so one of the things that they were pushing in in discussing with me is , , why are you spending so much time , , on the , , feature issue , when perhaps if you deal with what you were using before and then just broadened it bit , instead of just ta using silence as putative change point also ? so then you 've got you already have the super - structure with gaussians and - , simple ms and . so there was there was little bit of difference of opinion because that it was it 's interesting to look at what features are useful . but , , on the other hand saw that the they had good point that , , if we had something that worked for many cases before , maybe starting from there little bit because ultimately we 're gonna end up with some su structure like that , where you have some simple and you 're testing the hypothesis that , , there is change . so anyway , reporting that . so . , why don't we do the speech - nonspeech discussion ?
F: do hear you didn't
C: speech - nonspeech ? so , , what we did so far was using the mixed file to detect speech or nonspeech portions in that . and what did so far is used our old munich system , which is an - ba based system with gaussian mixtures for speech and nonspeech . and it was system which used only one gaussian for silence and one gaussian for speech . and now added , , multi - mixture possibility for speech and nonspeech . and did some training on one dialogue , which was transcribed by we we did nons speech - nonspeech transcription . adam , dave , and , we did , and trained it on that . and did some pre - segmentations for jane . and 'm not how good they are or what the transcribers say . they they can use it
F: they 's terrific improvement . and , , it real it just makes world of difference . and , , you also did some something in addition which was , , for those in which there {nonvocalsound} was , , quiet speakers in the mix .
C: that that was one one thing , why added more mixtures for the speech . so saw that there were loud loudly speaking speakers and quietly speaking speakers . and so did two mixtures , one for the loud speakers and one for the quiet speakers .
A: and did you hand - label who was loud and who was quiet , or did you just ?
C: did that for five minutes of one dialogue and that was enough to train the system . and so it adapts , , on while running .
B: what , , front - end processing did you do ?
C: it 's just our old munich , , loudness - based spectrum on mel scale twenty critical bands and then loudness . and four additional features , which is energy , loudness , modified loudness , and zero crossing rate . so it 's twenty - four twenty - four features .
F: and you also provided me with several different versions , and so you change {nonvocalsound} parameters . do you wanna say something about the parameters {nonvocalsound} that you change ?
C: you can specify the minimum length of speech or and silence portions which you want . and so did some modifications in those parameters , changing the minimum length for for silence to have , er to have more or less , , silence portions in inserted .
A: right . so this would work for , , pauses and utterance boundaries and things like that . but for overlap imagine that doesn't work , that you 'll have plenty of sections that are
C: that 's it .
F: - , - . that 's true . but {nonvocalsound} it saves so much time the {nonvocalsound} transcribers just enormous , enormous savings .
G: that 's great . just qu one quickly , , still on the features . so you have these twenty - four features . lot of them are spectral features . is there transformation , , like principal components transformation ?
A: it was is two .
C: no . we originally we did that but we saw , , when we used it , , for our close - talking microphone , which for our for our recognizer in munich we saw that it 's it 's not so necessary . it it works as with without , , lda .
G: no , was curious . don't 's big deal for this application , but , it 's
F: but then there 's another thing that also thilo 's involved with , and also da - dave gelbart . so there 's this problem of and and so we had this meeting . th - the {nonvocalsound} also adam , before the before you went away . we , regarding the representation {nonvocalsound} of overlaps , because at present , {nonvocalsound} , because {nonvocalsound} of the limitations of th the interface we 're using , overlaps are , , not being {nonvocalsound} encoded by {nonvocalsound} the transcribers in as complete {nonvocalsound} and , , detailed way as it might be , and as might be desired would be desired in the corpus ultimately . so we don't have start and end points {nonvocalsound} at each point where there 's an overlap . we just have the {nonvocalsound} overlaps {nonvocalsound} encoded in simple bin . . so {nonvocalsound} @ @ the limits of the {nonvocalsound} over of the interface are such that we were at this meeting we were entertaining how we might either expand {nonvocalsound} the interface or find other tools which already do what would be useful . because what would ultimately be , , ideal in my view and , had the sense that it was consensus , is that , , thorough - going musical score notation would be {nonvocalsound} the best way to go . because {nonvocalsound} you can have multiple channels , there 's single time - line , it 's very clear , flexible , and all those things . spoke had meeting with dave gelbart on and he had , , excellent ideas on how the interface could be modified to do this representation . but , , he in the meantime you were checking into the existence of already , , existing interfaces which might already have these properties . so , do you wanna say something about that ?
C: talked with , , munich guys from ludwi - ludwig maximilians university , who do lot of transcribing and transliterations . and they said they have they have , , tool they developed themselves and they can't give away , , it 's too error - prone , and had it 's not supported , susanne bur - burger , who is at se cmu , he wa who was formally at in munich and and is now at with cmu , she said she has something which she uses to do eight channels , , trans transliterations , eight channels simultaneously , but it 's running under windows . so 'm not if if we can use it . she said she would give it to us . it wouldn't be problem . and 've got some manual down in my office .
A: maybe we should get it and if it 's good enough we 'll arrange windows machines to be available .
F: - . we could , potentially {nonvocalsound} so . also wanted to be 've 've seen the this is called praat , praat , {nonvocalsound} which spee speech in dutch .
C: but then 'm not that 's the right thing for us .
F: in terms {nonvocalsound} of it being {nonvocalsound} windows {nonvocalsound} versus
A: no , no . praat isn't praat 's multi - platform .
F: but 'm just wondering , is ?
C: no . no , praat
F: so praat may not be
C: that 's not praat . it 's called "" trans transedit "" .
F: it 's different one .
C: the the , the tool from susanne .
G: the other thing , , to keep in mind , we 've been very concerned to get all this rolling so that we would actually have data , but , , our outside sponsor is actually gonna kick in and ultimately that path will be smoothed out . so if we have long - term need to do lots and lots of transcribing . we had very quick need to get something out and we 'd like to be able to do some later because just it 's inter it 's interesting . but as far , , with any luck we 'll be able to wind down the larger project .
A: what our decision was is that we 'll go ahead with what we have with not very fine time scale on the overlaps . and and do what we can later to clean that up if we need to .
F: and and was just thinking that , , if it were possible to bring that in , like , , this week , then {nonvocalsound} when they 're encoding the overlaps {nonvocalsound} it would be for them to be able to specify when , the start points and end points of overlaps . th - they 're {nonvocalsound} making really quick progress .
G: that 's great .
F: and , , so my goal was my charge was to get eleven hours by the end of the month . and it 'll be 'm 'm clear that we 'll be able to do that .
G: that 's great .
A: and did you , , forward morgan brian 's thing ?
F: sent {nonvocalsound} it to , who did send that to ? sent it to list and {nonvocalsound} sent it to {nonvocalsound} the {nonvocalsound} to the local list .
A: so you probably did get that .
F: you saw that ? so brian did tell {nonvocalsound} me that {nonvocalsound} what you said , that , {nonvocalsound} that {nonvocalsound} our that they are making progress and that he 's going that {nonvocalsound} they 're {nonvocalsound} going he 's gonna check the the output of the first transcription
G: it 's it 's all the difference in the world . he 's he 's on it now .
F: this is new development .
G: so so this is so it 'll happen . , it 's just saying that one of our one of our best people is on it , who just doesn't happen to be here anymore . someone else pays him .
B: but about the need for transcription ,
F: isn't that great ?
B: don't we didn't we previously decide that the ibm transcripts would have to be checked anyway and possibly augmented ?
F: yes . that 's true .
B: so , having good tool is worth something no matter what .
G: that 's that 's good point .
A: and dave gelbart did volunteer , and since he 's not here , 'll repeat it to at least modify transcriber , which , if we don't have something else that works , that 's pretty good way of going . and we discussed on some methods to do it . my approach originally , and 've already hacked on it little bit it was too slow because was trying to display all the waveforms . but he pointed out that you don't really have to . that 's good point . that if you just display the mix waveform and then have user interface for editing the different channels , that 's perfectly sufficient .
F: and just keep those {nonvocalsound} things separate . and and , , dan ellis 's hack already allows them to be {nonvocalsound} able to display different {nonvocalsound} waveforms to clarify overlaps and things ,
A: no . they can only display one ,
F: so that 's already
A: but they can listen to different ones .
F: , yes , but {nonvocalsound} what is that , , from the transcriber 's {nonvocalsound} perspective , , those {nonvocalsound} two functions are separate . and dan ellis 's hack handles the , , choice {nonvocalsound} the ability to choose different waveforms from moment to moment .
A: but only to listen to , not to look at . the waveform you 're looking at doesn't change .
F: that 's true . but {nonvocalsound} that 's that 's , cuz they 're they 're , they 're focused on the ear anyway . and then and then the hack to preserve the overlaps {nonvocalsound} better would be one which creates different output files for each channel , which then {nonvocalsound} would also serve liz 's request of having , separable , , cleanly , easily separable , transcript tied to single channel , , audio .
G: have , , folks from nist been in contact with you ?
F: 'm trying to could have gotten it over list .
G: , holidays may have interrupted things , they seem to want to get clear on standards for transcription standards and with us .
F: ! this was from before december .
G: right . because they 're they 're presumably going to start recording next month .
A: we should definitely get with them then , agree upon format . though don't remember email on that . so was not in the loop on that ?
G: , don't mailed anybody . told them to contact jane that , , if they had
F: that 's right .
G: if , that , , as the point person on it .
A: that 's right .
G: so , . maybe 'll , , ping them little bit about it to get that straight .
F: 'm keeping the conventions as simple {nonvocalsound} as possible .
G: so is it cuz with any luck there 'll actually be there 'll be collections at columbia , dan is very interested in doing some other things ,
A: it 's important both for the notation and the machine representation to be the same .
G: and collections at nist .
F: there was also this , {nonvocalsound} , email from dan regarding the speech - non nonspeech segmentation thing . and dan gel - and dave gelbart is interested in pursuing the aspect {nonvocalsound} of using amplitude {nonvocalsound} as as basis for the separation .
A: cross - correlation .
G: . he was talking he was talking , , we he had cross - correlation . had mentioned this couple times before , the the commercial devices that do , , , voice , , active miking , look at the amp at the energy at each of the mikes . and and you compare the energy here to some function of all of the mikes . by doing that , , rather than setting any , , absolute threshold , you actually can do pretty good , , selection of who 's talking . and those systems work very , , so people use them in panel discussions and with sound reinforcement differing in , and , , those if boy , the guy knew who built them , built them like twenty years ago , so they 're it 's the techniques work pretty .
F: cuz there is one thing that we don't have right now and that is the automatic , , channel identifier . that that , , that would help in terms of encoding of overlaps . the the transcribers would have less , , disentangling to do if that were available .
G: so , , you can look at some you have to play around little bit , , to figure out what the right statistic is , but you compare each microphone to some statistic based on the on the overall and we also have these we have the advantage of having distant mikes too . so that , you cou yo
A: using the close - talking would be much better .
G: if was actually working on it , 'd sit there and play around with it , and get feeling for it . you certainly wanna use the close - talking , as at least . if the other would add some other helpful dimension or not .
D: what what are the different , , classes to code , , the overlap , you will use ?
F: so types of overlap ? so {nonvocalsound} at meeting that wasn't transcribed , we worked up typology .
D: look like , , you you explaining in the blackboard ?
F: yes , exactly . that hasn't changed . it {nonvocalsound} the it 's two - tiered structure where the first one is whether {nonvocalsound} the person who 's interrupted continues or not . and then below that there 're {nonvocalsound} subcategories , , that have more to do with , {nonvocalsound} , is it , , simply {nonvocalsound} backchannel or is {nonvocalsound} it , , someone completing someone else 's thought , or is it someone in introducing new thought .
A: and hope that if we do forced alignment with the close - talking mike , that will be enough to recover at least some of the time information of when the overlap occurred .
F: - . , one would that 'd be that 'd be .
B: so who 's gonna do that ? who 's gonna do forced alignment ?
A: , ibm was going to . and imagine they still plan to but , , haven't spoken with them about that recently .
G: , my suggestion now is on all of these things to , , contact brian .
A: 'll do that .
F: this is wonderful {nonvocalsound} to have direct contact like that . th lemme ask {nonvocalsound} you this . it occurs to me one of my transcribers {nonvocalsound} told {nonvocalsound} me today that she 'll {nonvocalsound} be finished with one meeting , , by but then she said {nonvocalsound} , but {nonvocalsound} the , let 's just , , say maybe the day after just to be on the safe side . could send brian the , {nonvocalsound} the {nonvocalsound} transcript . know these {nonvocalsound} are er , , could send him that {nonvocalsound} if {nonvocalsound} it would be possible , {nonvocalsound} or good idea or not , to {nonvocalsound} try {nonvocalsound} to do forced alignment on what we 're on the way we 're encoding overlaps now .
G: just talk to him about it . , he 's he just studies , he 's colleague , they and , , the organization always did wanna help us .
F: super . super .
G: it was just question of getting , , the right people connected in , who had the time .
A: is he on the mailing list ? the meeting recorder mailing li ? we should add him .
E: did something happen , morgan , that he got put on this , or was he already on it ,
G: no , , , it it oc it 's
B: he asked for more work .
G: but he 's on it now .
F: that would be {nonvocalsound} like that 'd be like him . he 's great .
G: where are we ? maybe , , brief let 's why don't we talk about microphone issues ?
F: that 'd be great .
G: that was that was
A: so one thing is that did look on sony 's for replacement for the mikes for the head head - worn ones cuz they 're so uncomfortable . but need someone who knows more about mikes than do , because couldn't find single other model that seemed like it would fit the connector , which seems really unlikely to me . does anyone , like , know stores or know about mikes who would know the right questions to ask ?
G: my knowledge is twenty years out of date but some of it 's still the same . so maybe we we can take look at that .
E: you couldn't you couldn't find the right connector to go into these things ?
A: when looked , they listed one microphone and that 's it as having that type of connector . but my is that sony maybe uses different number for their connector than everyone else does .
G: let 's look at it together
A: it seems it seems really unlikely to me that there 's only one .
F: and there 's no adaptor for it ? seems like there 'd be
A: as said , who knows ?
G: who who are we buying these from ?
A: have it downstairs . don't remember off the top of my head .
G: we we can try and look at that together .
A: just in terms of how you wear them had thought about this before . when when you use product like dragondictate , they have very extensive description about how to wear the microphone and so on . but felt that in real situation we were very seldom gonna get people to really do it and maybe it wasn't worth concentrating on .
G: that 's that 's good back - off position . that 's what was saying earlier , th that , , we are gonna get some recordings that are imperfect and , hey , that 's life . but that it doesn't hurt , , the naturalness of the situation to try to have people wear the microphones properly , if possible , because , , the natural situation is really what we have with the microphones on the table .
A: that 's true .
G: , , in the target applications that we 're talking about , people aren't gonna be wearing head - mounted mikes anyway . so this is just for these head - mounted mikes are just for use with research . and , , it 's gonna make if an - andreas plays around with language modeling , he 's not gonna be wanna be messed up by people breathing into the microphone . so it 's it 's ,
A: 'll dig through the documentation to dragondictate and ste see if they still have the little form .
G: but it does happen .
B: it 's interesting , talked to some ibm guys , , last january , , was there . so people who were working on the on their viavoice dictation product . and they said , , the breathing is really terrible problem for them , to not recognize breathing as speech . so , anything to reduce breathing is is good thing .
A: it seemed to me when was using dragon that it was really microphone placement helped an in , an enormous amount . so you want it enough to the side so that when you exhale through your nose , it doesn't the wind doesn't hit the mike . everyone 's adjusting their microphones , . and then just close enough so that you get good volume . so , wearing it right about here seems to be about the right way to do it .
G: remember when was when used , , , prominent laboratory 's , , speech recognizer about , this was , boy , this was while ago , this was about twelve years ago . they were they were perturbed with me because was breathing in instead of breathing out . and they had models for they had markov models for br breathing out but they didn't have them for breathing in .
F: that 's interesting . what wondered is whether it 's possible to have to maybe use the display at the beginning to be able to judge how correctly have someone do some routine whatever , and then see if when they 're breathing it 's showing .
A: when it 's on , you can see it .
F: if the if it 's
A: you can definitely see it .
F: can you see the breathing ?
A: and so , , 've 've sat here and watched sometimes the breathing , and the bar going up and down , and 'm thinking , could say something , don't want to make people self - conscious .
G: it it 's going to be imperfect . you 're not gonna get it perfect . and you can do some , , , first - order thing about it , which is to have people move it , , away from being just directly in front of the middle but not too far away . and then , , there 's not much because you can't al , interfere you can't fine tune the meeting that much , .
F: that 's true . it just seems like if something simple like that can be tweaked and the quality goes , , , dramatically up , then it might be worth doing .
A: and then also the position of the mike also . if it 's more directly , you 'll get better volume . so so , like , yours is pretty far down below your mouth . .
F: my my feedback from the transcribers is he is always close to crystal clear and just fan fantastic to
A: why that is .
F: , you , . you 're you 're also your volume is greater . but but still , , they say
A: 've been eating lot .
F: it makes their job extremely easy .
G: and then there 's mass .
F: could say something about the what you wanna do . . about the transcribers or anything or ?
B: but , , just to ,
G: why don't we do that ?
B: one more remark , , concerning the sri recognizer . it is useful to transcribe and then ultimately train models for things like breath , and also laughter is very , very frequent and important to model . if you can in your transcripts mark mark very audible breaths and laughter especially ,
F: they 're putting , so in curly brackets they put "" inhale "" or "" breath "" . it they and then in curly brackets they say "" laughter "" . now they 're they 're not being awfully precise , so they 're two types of laughter that are not being distinguished . one is when sometimes someone will start laughing when they 're in the middle of sentence . and and then the other one is when they finish the sentence and then they laugh . so , , did did some double checking to look through you 'd need to have extra extra complications , like time tags indicating the beginning and ending of the laughing through the utterance .
B: it 's not so don't 's ,
F: and that and what they 're doing is in both cases just saying "" curly brackets laughing "" after the unit .
B: as as long as there is an indication that there was laughter somewhere between two words that 's sufficient ,
A: against they could do forced alignment .
B: actually the recognition of laughter once you kn , is pretty good . so as long as you can stick , tag in there that indicates that there was laughter ,
A: didn't know that .
B: that would probably be , , sufficient to train models .
A: that would be really interesting prosodic feature ,
F: and let me ask and gotta ask you one thing about that . if they laugh between two words , you 'd get it in between the two words . but if they laugh across three or four words you get it after those four words . does that matter ?
B: the thing that you is hard to deal with is whe when they speak while laughing . and that 's , don't think that we can do very with that . but , , that 's not as frequent as just laughing between speaking ,
A: so are do you treat breath and laughter as phonetically , or as word models , or what ?
D: it 's frequent in the meeting .
F: he 's right .
B: we tried both . currently , , we use special words . there was there 's actually word for , it 's not just breathing but all kinds of mouth and then laughter is is special word .
A: how would we do that with the hybrid system ? so train phone in the neural net ?
B: you ha . and each of these words has dedicated phone . so the so the mouth noise , , word has just single phone , that is for that .
A: right . so in the hybrid system we could train the net with laughter phone and breath sound phone .
G: it 's it 's always the same thing . you could you could say , let we now think that laughter should have three sub sub - units in the three states , different states . and then you would have three , , it 's
A: do whatever you want .
B: and the pronun the pronunciations the pronunciations are are somewhat non - standard . it 's just single , , , single phone in the pronunciation , but it has self - loop on it ,
A: to go on forever ?
B: can go on forever .
A: and how do you handle it in the language model ?
B: it 's just it 's just word .
A: it 's just word in the language model .
B: we train it like any other word . we also tried , , absorbing these , both laughter and actually also noise , anyway . we also tried absorbing that into the pause model the the model that matches the between words . it didn't work as . so .
A: can you hand me your digit form ? wanna mark that you did not read digits .
G: say hi for me .
F: you you did get me to thinking about 'm not really which is more frequent , it may be an individual thing . some people are more prone to laughing when they 're speaking .
A: was noticing that with dan in the one that we , we hand tran hand - segmented , that th he has these little chuckles as he talks .
G: 'm it 's very individual . one thing that that we 're not doing , , is we 're not claiming to , , get be getting representation of mankind in these recordings . we have this very , very tiny sample of and , right . so , , who knows . why don why don't we just since we 're on this vein , why don't we just continue with , , what you were gonna say about the transcriptions
F: , the 'm really very for 'm extremely fortunate with the people who , , applied and who are transcribing for us . they are , , really perceptive and very , and 'm not just saying that cuz they might be hearing this .
A: cuz they 're gonna be transcribing it in few days .
F: no , they 're super . they 're the they very quick .
E: turn the mikes off and let 's talk .
F: know . am 'm serious . they 're just super . so , , , brought them in and , , trained them in pairs because people can raise questions
A: that 's good idea .
F: the they think about different things and they think of different trained them to , , on about minute or two of the one that was already transcribed . this also gives me sense of use that later , with reference to inter - coder reliability issues . but the main thing was to get them used to the conventions and , , the idea of the th the size of the unit versus how long it takes to play it back so these th calibration issues . and then , , set them loose they all have already background in using computers . they 're , they 're trained in linguistics .
A: is that good or bad ?
F: they 're very perce they 'll so one of them said "" , , he really said "" "" , not really "" and "" , so what should do with that ? "" and said , "" for our purposes , do have convention . if it 's an noncanonical "" that one , we , with eric 's work , figure we can just treat that as variant . but told them if there 's an obvious speech error , , like said in one thing , and gave my example , like said , "" microfon "" in instead of "" microphone "" . knew it when said it . remember thinking "" , that 's not correctly pronounced "" . but it but it 's not worth fixing cuz often when you 're speaking everybody knows what you mean .
A: you 'll self - repair .
F: but have convention that if it 's noncanonical pronunciation speech error with , wi within the realm of resolution that you can tell in this native english american english speaker , that didn't mean to say "" microfon . "" then you 'd put little tick at the beginning of the word , and that just signals that , , this is not standard , and then in curly brackets "" pron {nonvocalsound} error "" . and , , and other than that , it 's word level . but , , the fact that they noticed , , the "" nnn "" . "" he said "" nnn "" , not "" and "" . what shall do with that ? "" they 're very perceptive . and and several of them are trained in ipa . they really could do phonetic transcription if we wanted them to .
G: right . , , it might be something we 'd wanna do with some , , small subset of the whole thing .
A: where were they when we needed them ?
G: we certainly wouldn't wanna do it with everything .
F: and 'm also thinking these people are terrific pool . if , so told them that , , we if this will continue past the end of the month think they know that the data source is limited and may not be able to keep them employed till the end of the month even , although hope to .
G: the other thing we could do , actually , , is , , use them for more detailed analysis of the overlaps .
F: that 'd be so super . they would be so so terrific .
A: this was something that we were talking about . we could get very detailed overlap if they were willing to transcribe each meeting four or five times . one for each participant . so they could by hand
G: that 's one way to do it . but 've been saying the other thing is just go through it for the overlaps .
F: - , that 's right . and with the right in interface
G: given that and do so instead of doing phonetic , , transcription for the whole thing , which we know from the steve 's experience with the switchboard transcription is , , very time - consuming . and and , it took them how many months to do to get four hours . and so that hasn't been really our focus . we can consider it . but , , the other thing is since we 've been spending so much time thinking about overlaps is maybe get much more detailed analysis of the overlaps . but anyway , 'm 'm open to our consideration .
F: that 'd be great .
G: don't wanna say that by fiat . 'm open to every consideration of what are some other kinds of detailed analysis that would be most useful . this year we actually , , can do it . it 's we have due to @ @ variations in funding we have we seem to be doing , , very on money for this year , and next year we may have much less .
A: is you mean two thousand one ?
G: so don't wanna hire , calendar year two thousand one . so it 's , it 's we don't wanna hire bunch of people , long - term staff ,
A: full - time .
G: because the funding that we 've gotten is big chunk for this year . but having temporary people doing some specific thing that we need is actually perfect match to that , , funding .
F: and then school will start in the sixt on the sixteenth . some of them will have to cut back their hours at that point .
E: are they working full - time now ,
F: but {nonvocalsound} some of them are . why do wouldn't say forty - hour weeks . shouldn't say it that way because {nonvocalsound} that does sound like forty - hour weeks . th would say they 're probably {nonvocalsound} they don't have they don't have other things that are taking away their time .
A: don't see how someone could do forty hours week on transcription .
F: but {nonvocalsound} it 's no . you 're right . it 's it would be too taxing . but , , they 're putting {nonvocalsound} in lot of and and checked them over . haven't checked them all , but just spot - checking . they 're fantastic .
G: remember when we were transcribing berp , , , ron , , volunteered to do some of that . and , he was the first he did was transcribing chuck . and he 's saying "" you , always thought chuck spoke really . ""
F: , and also thought , liz has this , , , and do also , this interest in the types of overlaps that are involved . these people would be {nonvocalsound} great choices for doing coding of that type if we wanted ,
A: we 'd have to mark them .
F: whatever . so , .
A: it would also be interesting to have , , couple of the meetings have more than one transcriber do , cuz 'm curious about inter - annotator agreement .
F: th - that 'd be that 's good idea . there 's also , the in my mind , an - andreas was leading to this topic , the idea that , , we haven't yet seen the type of transcript that we get from ibm , and it may just be , , pristine . but on the other hand , given the lesser interface cuz this is , we 've got good interface , we 've got great headphones ,
G: it could be that they will theirs will end up being fir first pass .
F: something like that .
G: maybe an elaborate one , cuz again they probably are gonna do these alignments , which will also clear things up .
F: that 's that 's true . al - although you have to don't you have to start with close enough approximation {nonvocalsound} of the of the verbal part {nonvocalsound} to be able to ?
G: tha that 's that 's debatable . so the so the argument is that if your statistical system is good it will , , clean things up . so it 's got its own objective criterion . and , , so in principle you could start up with something that was rough to give an example of , , something we used to do , , at one point , , back when chuck was here in early times , is we would take , da take word and , , have canonical pronunciation and , , if there was five phones in word , you 'd break up the word , , into five equal - length pieces which is completely gross . th the timing is off all over the place in just about any word . but it 's . you start off with that and the statistical system then aligns things , and eventually you get something that doesn't really look too bad . so so using good aligner , , actually can help lot . they both help each other . if you have if you have better starting point , then it helps the aligner . if you have good alignment , it helps the , , th the human in taking less time to correct things .
F: there 's another aspect , too , this is very possibly different , , topic . but , {nonvocalsound} , just let me say with reference to this idea of , , higher - order organization within meetings . the topics that are covered during meeting with reference to the other , , uses of the data , so being able to find where so - and - so talked about such - and - such , did rough pass {nonvocalsound} on encoding , like , episode - like level things on the , , transcribed meeting already transcribed meeting . where {nonvocalsound} that if that 's something that we wanna do with each meeting , it 's like manifest , when you get box full of , or if that 's , what , level of detail would be most useful . if that 's something that should do when look over it , or if we want someone else to do , or whatever . but this issue of the contents of the meeting in an outline form .
G: meaning really isn't my thing .
A: it just whoever is interested can do that . so if someone wants to use that data
G: we 're running little short here .
F: that 's fine .
G: we , , cou trying to was , , the thing 'm concerned about is we wanted to do these digits and haven't heard , , from jose yet .
D: what do you want ?
A: we could skip the digits . we don't have to read digits each time .
G: it , another bunch of digits . more data is good . so so 'd like to do that . but , do you , maybe , did you prepare some whole thing you wanted us just to see ?
D: it 's it 's prepared .
G: or what was that ?
D: it 's it 's fast , because , , have the results , , of the study of different energy without the law length . in the in the measurement , , the average , , dividing by the by the , , variance . the other , the last , meeting we have problem to with the with the parameter with the representations of parameter , because the valleys and the peaks in the signal , , look like , , it doesn't follow to the to the energy in the signal . and it was problem , , with the scale . and change the scale and we can see the variance .
G: but the bottom line is it 's still not , , separating out very .
D: the distribution the distribution is similar .
G: that 's that 's enough then . no , , that there 's no point in going through all of that if that 's the bottom line , really . so , we have to start , there 's two suggestions , really , which is , what we said before is that , it looks like , at least that you haven't found an obvious way to normalize so that the energy is anything like reliable , , indicator of the overlap . 'm 'm still little think that 's little funny . these things @ @ seems like there should be , but you don't want to keep , keep knocking at it if it 's if you 're not getting any result with that . but , , the other things that we talked about is , , pitch - related things and harmonicity - related things , so which we thought also should be some reasonable indicator . completely different tack on it wou is the one that was suggested , , by your colleagues in spain , which is to say , don't worry so much about the , , features . that is to say , use , , as you 're doing with the speech , , nonspeech , use some very general features . and , , then , , look at it more from the aspect of modeling . have have couple markov models and , , try to indi try to determine , , when is th when are you in an overlap , when are you not in an overlap . and let the , , statistical system determine what 's the right way to look at the data . it would be interesting to find individual features and put them together . that you 'd end up with better system overall . but given the limitation in time and given the fact that javier 's system already exists doing this thing , its main limitation is that , again , it 's only looking at silences which would maybe that 's better place to go .
D: that , , the possibility , , can be that , , thilo , , working , , with new class , not only , , nonspeech and speech , but , , in in the speech class , dividing , , speech , , of from speaker and overlapping , to try to do , , fast fast , , experiment to prove that , nnn , this fea , general feature , , can solve the the problem , nnn , how far is and , have prepared the pitch tracker now . and hope the next week will have , , some results and we will show we will see , , the parameter the pitch , , tracking in with the program .
G: ha - have you ever looked at the , javier 's , , speech segmenter ? maybe you could , you kn show thilo that . cuz again the idea is there the limitation there again was that he was he was only using it to look at silence as as as putative split point between speakers . but if you included , , broadened classes then in principle maybe you can cover the overlap cases .
C: but 'm not too if we can really represent overlap with the detector used up to now , the to speech - nonspeech as
A: that 's right . but javier 's
C: it 's only speech or it 's it 's nonspeech .
A: javier 's might be able to . it doesn't have the same gaus - , modeling , which is drawback .
G: it 's has simple one . it 's just it 's just isn't it just gaussian
A: and then he ch you choose optimal splitting .
G: it doesn't have it doesn't have any temporal , ?
A: maybe 'm misremembering , but did not had markov
G: gues don't remember either . it 's been while .
C: , could have look at it .
D: you mean ja - , javier program ? no , javier di doesn't worked with , , markov he on only train
G: . so he 's just he just computes gaussian over potential
D: it was only gaussian .
G: see . see .
A: and so it would work fine for detecting overlap .
D: this is the idea .
A: it 's just , , that it he has the two - pass issue that what he does is , as first pass he he does , , at where the divisions might be and he overestimates . and that 's just data reduction step , so that you 're not trying at every time interval . and so those are the putative places where he tries . and right now he 's doing that with silence and that doesn't work with the meeting recorder . so if we used another method to get the first pass , it would probably work . it 's good method . as long as the len as long the segments are long enough . that 's the other problem .
G: - . so let me go back to what you had , though . the other thing one could do is couldn't it 's so you have two categories and you have markov models for each . couldn't you have third category ? so you have , you have , , nonspeech , single - person speech , and multiple - person speech ?
F: he has this on his board actually . don't you have , like those several different categories on the board ?
G: and then you have markov model for each ?
C: about , , adding , , another class too . but it 's not too easy , , the transition between the different class , to model them in the system have now . but it it could be possible , ,
G: this is all pretty gross . the th the reason why , , was suggesting originally that we look at features is because , , we 're doing something we haven't done before , we should at least look at the space and understand it seems like if two people two or more people talk at once , it should get louder , and , , there should be some discontinuity in pitch contours ,
C: had the impression .
G: and , , there should overall be , , smaller proportion of the total energy that is explained by any particular harmonic sequence in the spectrum . so those are all things that should be there . so far , , , jose has been was told should be calling you pepe , by your friends , the has , , been exploring , , largely the energy issue as with lot of things , it is not , like this , it 's not as simple as it sounds . and then there 's , is it energy ? is it log energy ? is it lpc residual energy ? is it is it is it , , delta of those things ? what is it no just simple number absolute number isn't gonna work . so it should be with compared to what ? should there be long window for the normalizing factor and short window for what you 're looking at ? or , , how short should they be ? th he 's been playing around with lot of these different things and so far at least has not come up with any combination that really gave you an indicator . still have hunch that there 's it 's in there some place , but it may be given that you have limited time here , it just may not be the best thing to to focus on for the remaining of it .
D: to overrule , .
G: so pitch - related and harmonic - related , 'm somewhat more hopeful for it . but it seems like if we just wanna get something to work , that , , their suggestion of th - they were suggesting going to markov models , but in addition there 's an expansion of what javier did . and one of those things , looking at the statistical component , even if the features that you give it are maybe not ideal for it , it 's just this general filter bank eee it 's in there somewhere probably .
D: but , , what did you think about the possibility of using the javier software ? , the , the bic criterion , the to train the gaussian , using the mark , , by hand , , to distinguish be mmm , to train overlapping zone and speech zone . , that an interesting , , experiment , , could be , th , to prove that , mmm , if we suppose that , , the first step , the classifier were the classifier from javier or classifier from thilo ? what happen with the second step ? what happen with the , the , , clu the , the clu the clustering process ? using the gaussian .
A: you mean javier 's ? what do you mean ?
D: that is enough is enough , , to work , , to , , separate or to distinguish , , between overlapping zone and , , speaker zone ? because th if we , , nnn , develop an classifier and the second step doesn't work , , we have another problem .
A: had tried doing it by hand at one point with very short sample , and it worked pretty , but haven't worked with it lot . so what took hand - segmented sample and added ten times the amount of numbers at random , and it did pick out pretty good boundaries . but this was just very anecdotal thing .
D: but it 's possible with my segmentation by hand that we have information about the overlapping ,
A: right . so if we if we fed the hand - segmentation to javier 's and it doesn't work , then we know something 's wrong .
D: the demonstration by hand . segmentation by hand is the fast experiment .
A: that 's probably worthwhile doing .
D: we can prove that the
A: whether it 'll work or not .
D: this kind emph emphasises parameter and gaussian
A: do where his software is ? have you used it ?
D: have . have .
A: so if you need help let me know .
G: let 's read some digits .
","The Berkeley Meeting Recorder group talked about the ongoing transcription effort and issues related to the Transcriber tool , which despite its limitations for capturing tight time markings for overlapping speech , will continue to remain in use.
Speaker mn014 explained his efforts to pre-segment the signal into speech and non-speech portions for facilitating transcriptions.
Recording equipment and procedures were discussed , with a focus on audible breathing and the need for standards in microphone wear and use.
And , finally , it was determined that speaker mn005's efforts to detect speaker overlap using energy should instead be focussed on pitch- and harmonicity-related features or be guided by a non-featural , statistical approach , i.e . via the use of Markov models.
In the interest of time , it was decided that the group should continue using the existing Transcriber tool and perform a forced alignment on the close-talking microphones that will , it is hoped , help to recover some of the time information indicating where different speaker overlaps occurred in the signal.
A meeting will be arranged with NIST to decide on a common standard and format for doing transcriptions.
One or two meetings will be assigned to multiple transcribers to check for inter-annotator agreement.
To cut down on audible breaths during recordings , the group will institute some level of standards for microphone wear and use.
Speaker mn005 will feed his hand-segmented data into the speech segmenter developed by Javier to train it to identify different types of speech ( i.e . that of single versus multiple speakers ) , as well as focussing on pitch- and harmonicity-related features for identifying overlapping speech.
There is no channel identifier to help in encoding speaker overlaps.
Speech uttered while laughing is problematic for ASR.
So far , speaker mn005's attempts to detect speaker overlap have been unsuccessful , as it has not been possible to normalize energy as a reliable indicator of overlap.
Speaker mn014's efforts to detect speech/non-speech portions in the mixed signal ( using an HMM-based detector with Gaussian mixtures ) have produced pre-segmentations that facilitate the transcription effort.
Speaker mn014 also trained the system to identify speech from loud versus quiet speakers.
Such pre-segmentation modifications allow the experimenter to specify the minimum length of speech and silence portions desired , and also facilitate the identification of pauses and utterance boundaries.
The transcriber pool is making quick progress , and may be used in the future to perform other types of coding , e.g . a more detailed analysis of speaker overlap.
Transcribers are coding non-speech gestures , such as audible breaths and laughter , both of which are useful for improving recognition results.
Recent modifications to the Transcriber tool allow transcribers to listen to speech from different channels , as well as helping to preserve portions of overlapping speech , and enabling the creation of different output files for each channel for a cleaner and more segmentable transcript.
The Praat software package was discussed as an alternative transcription tool capable of representing multiple channels of speech.
Cross-correlation was discussed as a means of enabling speaker identification , and may be integrated into future work.
"
ami_abstractive_summary,Bro022.txt,"B: for two years we were two months , , away from being done .
A: and what was that , morgan ?
B: the , , torrent chip . , we went through it jim and went through old emails at one point and for two years there was this thing saying , , we 're we 're two months away from being done . it was very believable schedules , too . we went through and with the schedules and we
A: it was true for two years .
B: it was very true .
A: so , should we just do the same deal where we go around and do , , status report things ? and when sunil gets here he can do his last .
B: so we probably should for him to come before we do his .
A: that 's good idea . do you want to start , morgan ? do you have anything ,
B: don't do anything . no , , 'm involved in discussions with people about what they 're doing , but they 're since they 're here , they can talk about it themselves .
F: so should go so that , ,
A: why don't you go ahead , barry ?
F: you 're gonna talk about aurora , per se ? this past week 've just been , , getting down and dirty into writing my proposal . finished section on , on talking about these intermediate categories that want to classify , , as as middle step . hope to hope to get this , full rough draft done by , , monday so give it to morgan .
A: when is your , , meeting ?
F: , you mean the quals . the quals are happening in july twenty - fifth .
A: so , is the idea you 're going to do this paper and then you pass it out to everybody ahead of time
F: right , right . so , you write up proposal , and give it to people ahead of time , and you have short presentation . and then , then everybody asks you questions .
A: was just gonna ask , do you want to say any little bit about it ,
F: little bit about ?
A: wh - what you 're what you 're gonna you said you were talking about the , , particular features that you were looking at ,
F: one of the perplexing problems is , for while was thinking that had to come up with complete set of intermediate features in intermediate categories to classify right away . but what 'm thinking now is , would start with reasonable set . something something like , like , , re regular phonetic features , just to just to start off that way . and do some phone recognition . build system that , , classifies these , these feat , these intermediate categories using , , multi - band techniques . combine them and do phon phoneme recognition . then would look at the errors produced in the phoneme recognition and say , , , could probably reduce the errors if included this extra feature or this extra intermediate category . that would that would reduce certain confusions over other confusions . and then and then reiterate . build the intermediate classifiers . do phoneme recognition . look at the errors . and then postulate new or remove , , intermediate categories . and then do it again .
A: so you 're gonna use timit ?
F: for that for that part of the process , , would use timit . after , , , doing timit . that 's that 's , that 's just the ph the phone recognition task . wanted to take look at , , things that could model within word . so , would mov would then shift the focus to , , something like schw - switchboard , where 'd would be able to , to model , , intermediate categories that span across phonemes , not just within the phonemes , themselves , and then do the same process there , , on large vocabulary task like switchboard . for that part would 'd use the sri recognizer since it 's already set up for switchboard . and 'd run some tandem - style processing with , , my intermediate classifiers .
A: so that 's why you were interested in getting your own features into the sri files .
F: that 's why was asking about that . that 's that 's it . any any questions ?
A: so you just have few more weeks , it 's about month from now ?
F: it 's it 's month and week .
A: so , , you want to go next , dave ? and we 'll do
E: last week finally got results from the sri system about this mean subtraction approach . and , , we got an improvement , , in word error rate , training on the ti - digits data set and testing on meeting recorder digits of , , six percent to four point five percent , on the on the far - mike data but , , the near - mike performance worsened , , from one point two percent to two point four percent . wh why would that be , , considering that we actually got an improvement in near - mike performance using htk ? with some input from , , andreas , have theory in two parts . first of all htk , sr - the sri system is doing channel adaptation , and so htk wasn't . this mean subtraction approach will do channel normalization and so that might have given the htk use of it boost that wouldn't have been applied in the sri case . and also , , the andreas pointed out the sri system is using more parameters . it 's got finer - grained acoustic models . so those finer - grained acoustic models could be more sensitive to the artifacts in the re - synthesized audio . and me and barry were listening to the re - synthesized audio and sometimes it seems like you get of bit of an echo of speech in the background . and so that seems like it could be difficult for training , cuz you could have different phones lined up with different foreground phone , , depending on the timing of the echo . 'm gonna try training on larger data set , and then , , the system will have seen more examples of these artifacts and hopefully will be more robust to them . so 'm planning to use the macrophone set of , , read speech ,
B: had another thought just now , which is , , remember we were talking before about we were talking in our meeting about , , this that some of the other that avendano did , where they were , , getting rid of low - energy sections ? if you did high - pass filtering , as hirsch did in late eighties to reduce some of the effects of reverberation , , avendano and hermansky were arguing that , , perhaps one of the reasons for that working was ma may not have even been the filtering so much but the fact that when you filter an all - positive power spectrum you get some negative values , and you gotta figure out what to do with them if you 're gonna continue treating this as power spectrum . so , what hirsch did was , , set them to zero set the negative values to zero . so if you imagine waveform that 's all positive , which is the time trajectory of energy , and , , shifting it downwards , and then getting rid of the negative parts , that 's essentially throwing away the low - energy things . and it 's the low - energy parts of the speech where the reverberation is most audible . you have the reverberation from higher - energy things showing up in so in this case you have some artificially imposed reverberation - like thing . you 're getting rid of some of the other effects of reverberation , but because you have these non - causal windows , you 're getting these funny things coming in , what if you did ? there 's nothing to say that the processing for this re - synthesis has to be restricted to trying to get it back to the original , according to some equation . you also could , , just try to make it nicer . and one of the things you could do is , you could do some vad - like thing and you actually could take very low - energy sections and set them to some , , very low or near zero value . 'm just saying if it turns out that these echoes that you 're hearing are , or pre - echoes , are , , part of what 's causing the problem , you actually could get rid of them . be pretty simple . you do it in pretty conservative way so that if you made mistake you were more likely to keep in an echo than to throw out speech .
G: what is the reverberation time like there ?
E: in thi in this room ?
G: on , , the one what the in the speech that you are you are using like ?
B: so , it 's this room . it 's it 's this room . so it 's these are just microphone this micro close microphone and distant microphone , he 's doing these different tests on . we should do measurement in here . think we never have . it 's would , , point seven , point eight seconds , something like that ? but it 's , it 's this room . but the other thing is , he 's putting in was using the word "" reverberation "" in two ways . he 's also putting in , , he 's taking out some reverberation , but he 's putting in something , because he has averages over multiple windows stretching out to twelve seconds , which are then being subtracted from the speech . and since , , what you subtract , sometimes you 'll be you 'll be subtracting from some larger number and sometimes you won't .
G: - . - .
B: so you can end up with some components in it that are affected by things that are seconds away . and if it 's low energy compo portion , you might actually hear some funny things .
E: one thing , , noticed is that , , the mean subtraction seems to make the pzm signals louder after they 've been re - synthesized . so was wondering , is it possible that one reason it helped with the aurora baseline system is just as gain control ? cuz some of the pzm signals sound pretty quiet if you don't amplify them .
C: don't see why your signal is louder after processing ,
E: why - , , either .
B: don't think just multiplying the signal by two would have any effect . if you really have louder signals , what you mean is that you have better signal - to - noise ratio . so if what you 're doing is improving the signal - to - noise ratio , then it would be better . but just it being bigger if with the same signal - to - noise ratio
E: it it wouldn't affect things .
C: the system is use the absolute energy , so it 's little bit dependent on the signal level . but , not so much , .
B: but it 's trained and tested on the same thing . so if the if you change in both training and test , the absolute level by factor of two , it will have no effect .
A: did you add this data to the training set , for the aurora ? or you just tested on this ? morgan was just saying that , , as long as you do it in both training and testing , it shouldn't have any effect . but was under the impression that you just tested with this data . you didn't train it also .
E: trained on clean ti - digits . did the mean subtraction on clean ti - digits . but didn't 'm not if it made the clean ti ti - digits any louder . only remember noticing it made the , , pzm signal louder .
B: don't understand then .
E: if it 's if it 's like , if it 's trying to find reverberation filter , it could be that this reverberation filter is making things quieter . and then if you take it out that taking it out makes things louder .
B: , there 's there 's nothing inherent about removing if you 're really removing , , then don't see how that would make it louder . so it might be just some
E: so should maybe listen to that again .
B: it might just be some artifact of the processing that , , if you 're
A: wonder if there could be something like , for for the pzm data , , if occasionally , , somebody hits the table , you could get spike . 'm just wondering if there 's something about the , , doing the mean normalization where , , it could you to have better signal - to - noise ratio .
B: , there is this . subtracting the mean log spectrum is is like dividing by the spectrum . so , depending what you divide by , if your if your estimate is off and sometimes you 're you 're getting small number , you could make it bigger . so , it 's it 's just question of there 's it it could be that there 's some normalization that 's missing , you 'd shouldn't be larger , but maybe in practice it is . that 's something to think about .
C: had question about the system the sri system . so , you trained it on ti - digits ? but except this , it 's exactly the same system as the one that was tested before and that was trained on macrophone . so on ti - digits it gives you one point two percent error rate and on macrophone it 's still point eight . but is it exactly the same system ?
E: if you 're talking about the macrophone results that andreas had about , , week and half ago , it 's the same system .
C: so you use vtl - , vocal tract length normalization and , , like mllr transformations also ,
B: was his point eight percent , er , result on testing on macrophone or training ?
C: it was training on macrophone and testing , on meeting digits .
B: so that was done already . and it 's point eight ?
C: 've just been text testing the new aurora front - end with , aurora system actually so front - end and htk , , acoustic models on the meeting digits and it 's little bit better than the previous system . we have have two point seven percent error rate . and before with the system that was proposed , it 's what ? it was three point nine .
B: that 's lot better .
C: we are getting better .
B: so , what ?
G: with the with the htk back - end ? what we have for aurora ?
C: two point seven .
G: the meeting , like
C: on the meeting we have two point seven .
F: that 's with the new iir filters ?
C: we have the new lda filters , maybe didn't look , but one thing that makes difference is this dc offset compensation . do did you have look at the meet , meeting digits , if they have dc component ,
G: no . the dc component could be negligible . if you are recording it through mike . any all of the mikes have the dc removal some capacitor sitting right in that bias it .
B: because , , there 's sample and hold in the - tod and these period these typically do have dc offset . and and they can be surprisingly large . it depends on the electronics .
G: so it is the digital it 's the - tod that introduces the dc in .
B: the microphone isn't gonna pass any dc . actually , there are instrumentation mikes that do pass go down to dc . no , it 's the electronics . then there 's amplification afterwards . and you can get , it was in the wall street journal data that 't remember , one of the darpa things . there was this big dc - dc offset we didn't we didn't know about for while , while we were messing with it . and we were getting these terrible results . and then we were talking to somebody and they said , "" , . didn't ? everybody knows that . there 's all this dc offset in th "" so , yes . you can have dc offset in the data .
A: so was that was that everything , dave ?
E: and also , , did some experiments about normalizing the phase . so came up with web page that people can take look at . the interesting thing that tried was , , adam and morgan had this idea , since my original attempts to , , take the mean of the phase spectra over time and normalize using that , by subtracting that off , didn't work . , so , , that we thought that might be due to , , problems with , , the arithmetic of phases . they they add in this modulo two pi way there 's reason to believe that approach of taking the mean of the phase spectrum wasn't really mathematically correct . so , what did instead is took the mean of the fft spectrum without taking the log or anything , and then took the phase of that , and subtracted that phase off but that , , didn't work either .
B: see , we have different interpretation of this . he says it doesn't work . said , it works magnificently , but just not for the task we intended . it gets rid of the speech .
A: what does it leave ?
F: gets rid of the speech .
B: it leaves , it leaves the junk . it 's it 's tremendous . you see , all he has to do is go back and reverse what he did before , and he 's really got something .
A: could you take what was left over and then subtract that ?
B: ex - exactly . you got it . so , it 's it 's general rule . just listen very carefully to what say and do the opposite . including what said .
E: and , , that 's everything .
A: do you want to go , stephane ?
C: maybe , concerning these still , these meeting digits . 'm more interested in trying to figure out what 's still the difference between the sri system and the aurora system . so , will maybe train , like , gender - dependent models , because this is also one big difference between the two systems . the other differences were the fact that maybe the acoustic models of the sri are more sri system are more complex . but , , chuck , you did some experiments with this
A: it didn't seem to help in the htk system .
C: it was hard to have some exper some improvement with this .
B: it sounds like they also have he 's saying they have all these , , different kinds of adaptation . they have channel adaptation . they have speaker adaptation .
A: there 's also the normalization . like they do , 'm not how they would do it when they 're working with the digits , but , like , in the switchboard data , there 's , conversation - side normalization for the non - - zero
C: this is another difference . their normalization works like on the utterance levels . but we have to do it we have system that does it on - line . so , it might be it might be better with it might be worse if the channel is constant ,
G: and the acoustic models are like - triphone models or is it the whole word ?
C: sri it 's tr it 's triphones .
G: it 's triphone .
B: it 's probably more than that . so they have thin think they use these , , genone things . so there 's there 's these , , pooled models and they can go out to all sorts of dependencies .
G: it 's like the tied state .
B: they have tied states don't real 'm talk 'm just guessing here . but they don't just have triphones . they have range of , , dependencies .
C: the first thing that want to do is just maybe these gender things . and maybe see with andreas if how much it helps , what 's the model .
A: so the on the numbers you got , the two point seven , is that using the same training data that the sri system used and got one point two ?
C: that 's right . so it 's the clean ti - digits training set .
A: so exact same training data ?
C: you used the clean training set .
E: for with the sri system the aurora baseline is set up with these , this version of the clean training set that 's been filtered with this - seven - one - two filter , to train the sri system on digits - andreas used the original ti - digits , under doctor - speech data ti - digits , which don't have this filter . but don't think there 's any other difference .
B: so is that ? , are these results comparable ? so you were getting with the , , aurora baseline something like two point four percent on clean ti - digits , when , , training the sri system with clean tr digits ti - digits . and , so , is your two point seven comparable , where you 're , , using , , the submitted system ? so it 's about the same , maybe little worse .
E: it was one point two with the sri system ,
C: the complete sri system is one point two .
B: you you were htk . that 's right . so the comparable number then , for what you were talking about then , since it was htk , would be the , two point
C: it was four point something . the htk system with , ,
B: right , right .
E: do you mean the ? the baseline aurora - two system , trained on ti - digits , tested on meeting recorder near , we saw in it today , and it was about six point six percent .
B: right . right , right . he 's doing some different things .
C: the only difference is the features , right now ,
B: so they are helping . that 's good to hear .
C: they are helping . and another thing maybe would like to do is to just test the sri system that 's trained on macrophone test it on , , the noisy ti - digits , cuz 'm still wondering where this improvement comes from . when you train on macrophone , it seems better on meeting digits . but wonder if it 's just because maybe macrophone is acoustically closer to the meeting digits than ti - digit is , ti - digits are very clean recorded digits
A: it would also be interesting to see , to do the regular aurora test , but use the sri system instead of htk .
C: that 's what wanted , just , so , just using the sri system , test it on and test it on aurora ti - digits .
A: why not the full aurora , , test ?
C: there is this problem of multilinguality yet .
B: you 'd have to train the sri system with all the different languages .
C: we would have to train on
A: that 's what . so , like , comple
B: it 'd be lot of work . that 's the only thing .
A: the work would be into getting the files in the right formats , . because when you train up the aurora system , you 're , you 're also training on all the data .
C: that 's right . see what you mean .
B: that 's true , but that also when we 've had these meetings week after week , oftentimes people have not done the full arrange of things because on whatever it is they 're trying , because it 's lot of work , even just with the htk . so , it 's it 's good idea , but it seems like it makes sense to do some pruning first with test or two that makes sense for you , and then take the likely candidates and go further .
C: but , just testing on ti - digits would already give us some information about what 's going on . the next thing is this vad problem that , so , 'm just talking about the curves that sent sent you so , whi that shows that when the snr decrease , , the current vad approach doesn't drop much frames for some particular noises , which might be then noises that are closer to speech , , acoustically .
B: to clarify something for me . they were supp supposedly , in the next evaluation , they 're going to be supplying us with boundaries . so does any of this matter ? other than our interest in it .
C: first of all , the boundaries might be , like we would have two hundred milliseconds or before and after speech . so removing more than that might still make difference in the results .
B: do we ? , is there some reason that we think that 's the case ?
C: because we don't didn't looked that much at that . but , still , it 's an interesting problem .
B: but maybe we 'll get some insight on that when , , the gang gets back from crete . because there 's lots of interesting problems , . and then if they really are going to have some means of giving us fairly tight , , boundaries , then that won't be so much the issue .
G: because we were wondering whether that vad is going to be , like , realistic one or is it going to be some manual segmentation . and then , like , if that vad is going to be realistic one , then we can actually use their markers to shift the point around , , the way we want rather than keeping the twenty frames , we can actually move the marker to point which we find more suitable for us . but if that is going to be something like manual , , segmenter , then we can't use that information anymore , because that 's not going to be the one that is used in the final evaluation . so . we what is the type of vad which they 're going to provide .
C: and actually there 's there 's an , it 's still for even for the evaluation , it might still be interesting to work on this because the boundaries that they would provide is just , , starting of speech and end of speech , at the utterance level .
G: with some gap . with some pauses in the center , provided they meet that whatever the hang - over time which they are talking .
C: but when you have like , , five or six frames , both
G: then the they will just fill it up .
B: so if you could get at some of that , although that 'd be hard .
C: it might be useful for , like , noise estimation , and lot of other things that we want to work on . so did started to test putting together two vad which was not much work actually . im re - implemented vad that 's very close to the , , energy - based vad that , , the other aurora guys use . so , which is just putting threshold on the noise energy , and , detect detecting the first group of four frames that have energy that 's above this threshold , from this point , , tagging the frames there as speech . so it removes the first silent portion of each utterance . and it really removes it , still on the noises where our mlp vad doesn't work lot .
B: cuz would have thought that having some spectral information , in the old days people would use energy and zero crossings , , would give you some better performance . cuz you might have low - energy fricatives or , stop consonants , like that .
C: so , your point is will be to use whatever
B: that if you if you use purely energy and don't look at anything spectral , then you don't have good way of distinguishing between low - energy speech components and nonspeech . just as gross generalization , most nonsp many nonspeech noises have low - pass characteristic , and and most , , low - energy speech components that are unvoiced have high - pass characteristic an upward slope . , at the beginning of of an sound , just starting in , it might be pretty low - energy , but it will tend to have this high - frequency component . whereas , lot of rumble , and background noises , and will be predominantly low - frequency . , by itself it 's not enough to tell you , but it plus energy is it plus energy plus timing information is if you look up in rabiner and schafer from like twenty - five years ago , that 's what they were using then . so it 's it 's not
C: it it might be that what did is so , removes like low , , low - energy , , speech frames . because the way do it is combine the two decisions so , the one from the mlp and the one from the energy - based with the and operator . only keep the frames where the two agree that it 's speech . so if the energy - based dropped low - energy speech , mmm , they are they are lost . but still , the way it 's done right now it helps on the noises where it seems to help on the noises where our vad was not very good .
B: one could imagine combining them in different ways . what you 're saying is that the mlp - based one has the spectral information .
C: but the way it 's combined wi is maybe done the way use an "" and "" operator is so , it , the frames that are dropped by the energy - based system are , , dropped , even if the , , mlp decides to keep them .
B: and that might not be optimal , but , in principle what you 'd want to do is have , probability estimated by each one and put them together .
A: something that 've used in the past is , when just looking at the energy , is to look at the derivative . and you make your decision when the derivative is increasing for so many frames . then you say that 's beginning of speech . but , 'm 'm trying to remember if that requires that you keep some amount of speech in buffer . it depends on how you do it . but , that 's that 's been useful thing .
G: , every everywhere has delay associated with it . you still have to always keep buffer , then only make decision because you still need to smooth the decision further . so that 's always there .
C: actually if don't maybe don't want to work too much of on it right now . wanted to see if it 's what observed was the re was caused by this vad problem . and it seems to be the case . the second thing is the this spectral subtraction . which 've just started yesterday to launch bunch of , , {nonvocalsound} twenty - five experiments , with different , , values for the parameters that are used . it 's the makhoul - type spectral subtraction which use an over - estimation factor . so , we substr subtract more , , {nonvocalsound} noise than the noise spectra that is estimated on the noise portion of the , the utterances . so tried several , , over - estimation factors . and after subtraction , also add constant noise , and also try different , , noise , , values and we 'll see what happen . but st still when we look at the , it depends on the parameters that you use , but for moderate over - estimation factors and moderate noise level that you add , you st have lot of musical noise . on the other hand , when you subtract more and when you add more noise , you get rid of this musical noise but maybe you distort lot of speech . it until now , it doesn't seem to help . we 'll see . so the next thing , maybe what will try to do is just to try to smooth mmm , the , to smooth the the result of the subtraction , to get rid of the musical noise , using some filter ,
G: can smooth the snr estimate , also . your filter is function of snr . ?
C: so , to get something that 's would be closer to what you tried to do with wiener filtering .
G: actually , it 's ,
C: that 's it for me .
G: th 've been playing with this wiener filter , like . and there are there were some bugs in the program , so was initially trying to clear them up . because one of the bug was was assuming that always the vad , the initial frames were silence . it always started in the silence state , but it wasn't for some utterances . so the it wasn't estimating the noise initially , and then it never estimated , because assumed that it was always silence .
C: so this is on speechdat - car italian ? so , in some cases there are also
G: speechdat - car italian . there 're few cases , actually , which found later , that there are . so that was one of the bugs that was there in estimating the noise . and , , so once it was cleared , , ran few experiments with different ways of smoothing the estimated clean speech and how estimated the noise and , , smoothing the snr also . and so the trend seems to be like , , smoothing the current estimate of the clean speech for deriving the snr , which is like deriving the wiener filter , seems to be helping . then updating it quite fast using very small time constant . so we 'll have , like , few results where the the more smoothing is helping . but still it 's like it 's still comparable to the baseline . haven't got anything beyond the baseline . but that 's , like , not using any wiener filter . and , , so 'm 'm trying few more experiments with different time constants for smoothing the noise spectrum , and smoothing the clean speech , and smoothing snr . so there are three time constants that have . so , 'm just playing around . so , one is fixed in the line , like smoothing the clean speech is helping , so 'm not going to change it that much . but , the way 'm estimating the noise and the way 'm estimating the snr , 'm just trying little bit . and the other thing is , like , putting floor on the , , snr , some in some cases the clean speech is , like when it 's estimated , it goes to very low values , so the snr is , like , very low . so that actually creates lot of variance in the low - energy region of the speech . so , 'm thinking of , like , putting floor also for the snr so that it doesn't vary lot in the low - energy regions . and , . so . the results are , like so far 've been testing only with the baseline , which is which doesn't have any lda filtering and on - line normalization . want to separate the contributions out . so it 's just vad , plus the wiener filter , plus the baseline system , which is , , just the spectral , the mel sp mel , , frequency coefficients . and the other thing that tried was but took of those , , carlos filters , which hynek had , to see whether it really helps or not . it was just run to see whether it really degrades or it helps . it 's it seems to be like it 's not hurting lot by just blindly picking up one filter which is nothing but four hertz band - pass filter on the cubic root of the power spectrum . so , that was the filter that hy - , carlos had . just just to see whether it really it 's is it worth trying or not . so , it doesn't seems to be degrading lot on that . so there must be something that that can be done with that type of noise compensation also , which would ask carlos about that . how he derived those filters and where if he has any filters which are derived on ogi stories , added with some type of noise which what we are using currently ,
B: this is cubic root of power spectra ?
G: cubic root of power spectrum .
B: so , if you have this band - pass filter , you probably get you get negative values .
G: and 'm , like , floating it to zeros right now . so it has , like the spectrogram has , like it actually , , enhances the onset and offset of , the begin and the end of the speech . so it 's there seems to be , like , deep valleys in the begin and the end of , like , high - energy regions , because the filter has , like , mexican - hat type structure . so , those are the regions where there are , like when look at the spectrogram , there are those deep valleys on the begin and the end of the speech . but the rest of it seems to be , like , pretty . that 's something observe using that filter . because the filter doesn't have really deep negative portion , so that it 's not really creating lot of negative values in the cubic root . 'll 'll may continue with that for some 'll maybe 'll ask carlos little more about how to play with those filters , and but while making this wiener filter better . that that 's it , morgan .
B: last week you were also talking about building up the subspace ?
G: would actually didn't get enough time to work on the subspace last week . it was mostly about finding those bugs th , things , and didn't work much on that .
A: how about you , carmen ?
D: am still working with , , vts . and , one of the things that last week , say here is that maybe the problem was with the diff because the signal have different level of energy . and , maybe , talking with stephane and with sunil , we decide that maybe it was interesting to apply on - line normalization before applying vts . but then we decided that 's it doesn't work , because we modified also the noise . thinking about that , we then we decide that maybe is good idea . didn't do the experiment yet to apply vts in cepstral domain .
B: the other thing is so so , in and - zero would be different so you could do different normalization for - zero than for other things anyway . the other thing was gonna suggest is that you could have two kinds of normalization with , , different time constants . you could do some normalization , before the vts , and then do some other normalization after . but but - zero certainly acts differently than the others do ,
D: we decide to to obtain the new expression if we work in the cepstral domain . am working in that now , but 'm not if that will be usefu useful . it 's it 's it 's quite lot it 's lot of work . it 's not too much , but this it 's work . and want to we have some feeling that the result don't have any feeling if this will work better than apply vts aft in cepstral domain will work better than apply in mel in filter bank domain .
B: , you 're you 're the first one here to work with vts , maybe we could call someone else up who has , ask them their opinion . don't don't have good feeling for it .
C: actually , the vts that you tested before was in the log domain and so the codebook is dependent on the level of the speech signal . so expect it if if you have something that 's independent of this , expect it to it to , , be better model of speech .
B: you you wouldn't even need to switch to cepstra . you can just normalize the
C: we could normali norm , remove the median .
B: and then you have one number which is very dependent on the level cuz it is the level , and the other which isn't .
C: but here also we would have to be careful about removing the mean of speech not of noise . because it 's like first doing general normalization and then noise removal ,
D: was thinking to to estimate the noise with the first frames and then apply the vad , before the on - line normalization . am thinking about that and working about that , but don't have result this week .
B: one of the things we 've talked about maybe it might be star time to start thinking about pretty soon , is as we look at the pros and cons of these different methods , how do they fit in with one another ? because we 've talked about potentially doing some combination of couple of them . maybe maybe pretty soon we 'll have some sense of what their characteristics are , so we can see what should be combined .
A: is that it ?
B: why don't we read some digits ?
A: want to go ahead , morgan ? transcript dash two one five .
","A typical progress report meeting for the ICSI Meeting Recorder Group at Berkeley.
Each of the group reported their most recent progress , and any results they have achieved.
This then prompted discussion about the reasons behind such findings , which were for the most part not as expected.
Topics the group touched upon included spectral subtraction , phase normalization , Voice activity detection , along with comparisons between systems.
*NA*
A couple of issues have arisen that need to be looked into further such as DC-offset and effects of PZM signals.
Speaker Fn002 is worried about running VTS in the cepstral domain , because it requires a lot of work , and it is not clear that it will be much better than running it in the Mel domain.
Similarly , since at the next stage of the project data will have marked boundaries , it is not clear that voice-activity detection is worth pursuing.
Speaker me026 has been trying mean subtraction on the SRI system , with good improvement for the far mike , though worse on near mike.
This contradicts previous findings for HTK , though he has some theories to explain the difference.
Has also been working on different phase normalization techniques , with no luck.
Speaker Mn007 has also been looking at differences , differences between the SRI system and the groups Aurora project , and again , there are a number of possible explanations.
He has also been looking at a problem with the VAD and SNR.
Mn052 has sorted bugs in implementation of wiener filtering , and has been investigating smoothing and also SNR.
Fn002 is ready to run experiment investigating VTS in the cepstral domain.
Speaker me006 is still working on his proposal.
"
ami_abstractive_summary,Bed010.txt,"D: how many batteries do you go through ?
C: so , let 's get started . nancy said she 's coming and that means she will be . my suggestion is that robert and johno give us report on last week 's adventures to start . so everybody knows there were these guys from heidelber - , actually from dfki , part of the german smartkom project , who were here for the week and , got lot done .
E: the we got to the point where we can now speak into the smartkom system , and it 'll go all the way through and then say something like "" roman numeral one , am smarticus . "" it actually says , "" roemisch einz , am smarticus , "" which means it 's just using german sythesis module for english sentences .
C: it doesn't know "" "" .
B: am spartacus . ""
D: "" am sm - am smarticus "" is what it 's saying .
E: the sythesis is just question of , hopefully it 's just question of exchanging couple of files , once we have them . and , , it 's not going to be problem because we decided to stick to the so - called concept to speech approach . so 'm 'm going backwards now , so "" synthesis "" is where you make this , make these sounds , and "" concept to speech "" is feeding into this synthesis module giving it what needs to be said , and the whole syntactic structure so it can pronounce things better , presumably . then , just with text to speech . and , , johno learned how to write xml tags . and did write the tree adjoining grammar for some sentences .
D: so . bu - , the way the , the dialogue manager works is it dumps out what it wants to know , or what it wants to tell the person , to er in xml and there 's conversion system for different , to go from xml to something else . and th so , the knowledge base for the system , that generates the syntasti syntactic structures for the ge generation is , in lisp - like the knowledge base is in lisp - like form . and then the thing that actually builds these syntactic structures is something based on prolog . so , you have , goal and it , , says "" , 'm gonna try to do the greet - the - person goal , so it just starts , it binds some variables and it just decides to , , do some subscold . it just means "" build the tree . "" and then it passes the tree onto , , the ge the generation module .
E: but that that out of the twelve possible utterances that the german system can do , we 've already written the syntax trees for three or four .
D: so , the syntax trees are very simple . it 's like most of the sentences in one tree , and instead of , , breaking down to , like , small units and building back up , they took the sentences , and cut them in half , or , into thirds like that , and made trees out of those . and so , tilman wrote little tool that you could take lisp notation and generate an xml , , tree . , what do ca structure from the from the lisp . and so you just say , , "" noun goes to "" , , er , nah , don't re 've never been good at those . so there 's like the vp goes to and those things in lisp , and it will generate for you .
E: and because we 're sticking to that structure , the synthesis module doesn't need to be changed . so all that fancy , and the texas speech version of it , which is actually the simpler version , is gonna be done in october which is much too late for us . this way we worked around that . the , the system , show you the system . actually want , at least , maybe , you should be able to start it on your own . if you wanna play around with it , in th in the future . right now it 's brittle and you need to ch start it up and then make ts twenty changes on on seventeen modules before they actually can stomach it , anything . and send in couple of side queries on some dummy center set - up program so that it actually works because it 's designed for this seevit thing , where you have the gestural recognition running with this siemens virtual touch screen , which we don't have here . and so we 're doing it via mouse , but the whole system was designed to work with this thing and it was it was lot of engineering . no science in there whatsoever , but it 's working now , and , that 's the good news . so everything else actually did prove to be language independent except for the parsing and the generation .
D: why had did need to chan generate different trees than the german ones , mainly because like , the gerund in german is automatically taken care of with just regular verb ,
E: you have to switch it on .
D: so 'd have to add "" am walking , "" or 'd have to add little stem for the "" am "" , when build the built the tree .
B: noticed that , that some of the examples they had , had , non - english word orders and so on , and then all that good .
C: so it might be worth , keith , you looking at this ,
B: still don't still don't really understand like still don't exactly understand the information flow in this thing , or what the modules are and so on . so , , like just that such - and - such module decides that it wants to achieve the goal of greeting the user , and then magically it how does it know which syntactic structure to pull out , and all that ?
C: so . it 's not worth going over in the group , but when you get free and you have the time either robert or johno or walk you through it . and you can ask all the questions about how this all fits together .
B: that 's fine .
C: it 's eee messy but once you understand it . it 's it 's there 's nothing really complicated about it .
B: and remember one thing that came up in the talk last wednesday . , was this , he talked about the idea of like , he was talking about these lexicalized , tree adjoining grammars where you for each word you ,
D: how to do it ?
B: for each lexical item , the lexical entry says wh the trees are that it can appear in . and , that 's not that 's the opposite of constructional . that 's , , that 's that 's hpsg or whatever .
C: now , we 're we 're not committed for our research to do any of those things . so we are committed for our funding .
B: make our fit to that .
C: no , to just get the dem get the demos they need . so between us all we have to get th the demos they need . if it turns out we can also give them lots more than that by , , tapping into other things we do , that 's great .
D: you should probably move the microphone closer to your face .
C: but it turns out not to be in an any of the contracts
D: there 's like little the twisty thing , you can move it with .
C: and , deliberately . so , the reason 'd like you to understand what 's going on in this demo system is not because it 's important to the research . it 's just for closure . so that if we come up with question of "" could we fit this deeper in there ? "" . what the hell we 're talking about fitting in . so it 's just , in the sam same actually with the rest of us we just need to really understand what 's there . is there anything we can make use of ? is there anything we can give back , beyond th the minimum requirements ? but none of that has short time fuse . so th the demo requirements for this fall are taken care of as of later this week . and then so , it 's probably fifteen months until there 's another serious demo requirement . that doesn't mean we don't think about it for fifteen months , but it means we can not think about it for six months . so . the plan for this summer , really is to step back from the applied project , keep the keep the context open , but actually go after the basic issues . so the idea is there 's this , other subgroup that 's worrying about formalizing the nota getting notation . but in parallel with that , , the hope is tha in particularly you will work on constructions in english ge - and german for this domain , but not worry about parsing them or fitting them into smartkom or any of the other anything lik any other constraints for the time being . it 's hard enough to get it semantically and syntactically right and then and get the constructions in their form and . and , don don't want you feeling that you have to somehow meet all these other constraints . and similarly with the parsing , we 're gonna worry about parsing , the general case construction parser for general constructions . and , if we need cut - down version , or whatever , we 'll worry about that later . so 'd like to , for the summer turn into science mode . and assume that 's also , , your plan as .
B: so , that like the meetings so far that 've been at have been been geared towards this demo , and then that 's going to go away pretty soon .
C: but but we 're swit
B: and then we 'll shift gears fairly substantially ,
E: it 's got . what what is good idea that show to anyone who 's interested , we can even make an internal demo , and show you what do , speak into it and you hear it talk , and walk through the information . so , this is like in half hour or forty - five minutes . and so you when somebody on the streets com comes up to you and asks you what is smartkom so you can , , give sensible answer .
C: so , sh we could set that up as actually an institute wide thing ? just give talk in the big room , and so peo people 's going on ? when you 're ready ? that 's the thing that 's the level at which we can just li invite everybody and say "" this is project that we 've been working on and here 's demo version of it "" and like that .
E: we do wanna have all the bugs out where you have to pipe in extra xml messages from left and right before you 're
C: but any so that it 's clear , then , . actually , roughly starting let 's say , nex next meeting , cuz this meeting we have one other thing to tie up besides the trip report . but starting next meeting we want to flip into this mode where there are lot of issues , what 's the ontology look like , what do the constructions look like , what 's the execution engine look like , mmm lots of things . but , more focused on an idealized version than just getting the demo out . now before we do that , let 's get back in but , it 's still , , useful for you to understand the demo version enough , so that you can see what it is that it might eventually get retro - fitted into . and johno 's already done that , , looked at the dem the looked at the smartkom .
D: what part of th the smartkom ?
C: the parser , and that . so , the trip the report on these the last we interrupted you guys telling us about what happened last week .
B: it 's alright .
E: it was just amazing to see how instable the whole thing is ,
C: maybe you 're done , then .
E: and if you just take the and got the feeling that we are the only ones right now who have running system . what the guys in kaiserslautern have running the version that is , the full version that 's on the server does not work . and you need to do lot of to make it work . and so it 's and even tilman and ralf said "" there never was really working version that did it without th all the shortcuts that they built in for the october @ @ version "" . so we 're actually maybe ahead of the system gruppe by now , the system the integration group . and it was , it was fun to some extent , but the the outcome that is scientific interest is that both ralf and tilman know that they enjoyed it here , and they they liked , , lot of the they saw here , what we have been thinking about , and they 're more than willing to , cooperate , by all means . and , part of my responsibility is to use our internal "" group - ware "" server at eml , make that open to all of us and them , so that whatever we discuss in terms of parsing and generating and constructions we put it in there and they put what they do in there and maybe we can even , get some overlap , get some synergy out of that . if find someone at in eml that is interested in that , may even think that we could look take constructions and generate from them because the tree adjoining grammars that tilman is using is as you said nothing but mathematical formalism . and you can just do anything with it , whether it 's syntactic trees , - like , or whether it 's construction . so if you ever get to the generation side of constructing things and there might be something of interest there , but in the moment we 're definitely focused on the understanding , , pipeline .
C: anyth - any other repo visit reports stories ? we so we now know , what the landscape is like . and so we just push on and , do what we need to do . and one of the things we need to do is the , and this is relatively tight tightly constrained , is to finish up this belief - net . and was going to switch to start talking about that unless there 're other more general questions . so here 's where we are on the belief - net as far as understand it . going back two weeks ago robert had laid out this belief - net , missing only the connections . that is so , he 'd put all th all the dots down , and we went through this , and , , more or less convinced ourselves that at least the vast majority of the nodes that we needed for the demo level we were thinking of , were in there . we may run across one or two more . but the connections weren't . so , bhaskara and went off and looked at some technical questions about were certain operations legitimate belief - net computations and was there some known problem with them or had someone already , solved how to do this and . and so bhaskara tracked that down . the answer seems to be , "" no , no one has done it , but yes it 's perfectly reasonable thing to do if that 's what you set out to do "" . and , so the current state of things is that , again , starting now , we 'd like to actually get running belief - net for this particular subdomain done in the next few weeks . so bhaskara is switching projects as of the first of june , and , he 's gonna leave us an inheritance , which is hopefully belief - net that does these things . and there 're two aspects to it , one of which is , , technical , getting the coding right , and making it run , and like that . and the other is the actual semantics . ? wh , what are the considerations and how and what are the ways in which they relate . so he doe he doesn't need help from this group on the technical aspects or if he does we 'll do that separately . but in terms of what are the decisions and like that , that 's something that we all have to work out . is is that right ? that 's that 's both you guys ' understanding of where we are ?
G: so , , is there like latest version of the belief - net of the proposed belief - net ?
E: , no , we didn't decide . we wanted to look into maybe getting it , the visualization , bit clearer , but if we do it , , paper version of all the nodes and then the connections between them , that should suffice .
G: that should be fine .
C: that 's separate problem . we do in the long run wanna do better visualization and all that . that 's separable ,
D: did look into that , in terms of , , exploding the nodes out and down ag javabayes does not support that . imagine way of hacking at the code to do that . it 'd probably take two weeks or so to actually go through and do it ,
C: not not at this point .
D: and went through all the other packages on murph - kevin murphy 's page , and couldn't find the necessary mix of free and with the gui and , with this thing that we want .
C: we can if it 's if we can pay if it 's paying thousand dollars we can do that . so so don't view free as absolute constraint .
D: so then 'll go back and look at the ones on the list that
C: and you can ask kevin .
G: the one that people seem to use is hugin or whatever ?
C: that 's free .
G: is it free ? because 've seen it advertised in places so it seems to
C: it may be free to academics . have co have copy that downloaded . so , at one point it was free . but yo noticed people do use hugin
D: how do you spell that ?
C: and bhaskara can give you pointer . so then , in any case , if if it 's probably for university , it 's it 's gonna be real cheap anyway . but , , if it 's fifty thousand dollars we aren't gonna do it . 'm mean , we have no need for that .
E: also would suggest not to spend two weeks in in changing the javabayes code .
C: he 's not gonna do that .
E: will send you pointer to java applet that does that , it 's fish - eye . you you have node , and you click on it , and it shows you all the connections , and then if you click on something else that moves away , that goes into the middle . and maybe there is an easy way of interfacing those two . if that doesn't work , it 's not problem we need to solve right now . what 'm what my job is , will , , give you the input in terms of the internal structure . maybe node by node , like this ? or should collect it all
G: just any like rough representation of the entire belief - net is probably best .
E: and you 're gonna be around ? again , always tuesdays and thursdays afternoon - ish ? as usual ? or will that change ?
G: this week , have lot of projects and but after that will generally be more free . so yes , might be around . and , generally if you email me also be around on other days .
C: and this is not crisis that , you do , everybody who 's student should , do their work , get their courses all in good shape and and then we 'll dig dig down on this .
E: no , that 's good . that means have spend this week doing it .
B: how do you go about this process of deciding what these connections are ? know that there 's an issue of how to weight the different things too , and . do you just and see if it
C: there there there 're two different things you do . one is you design and the other is you learn . so what we 're gonna do initially is do design , and , if you will , . that is use your best knowledge of the domain to , hypothesize what the dependencies are and . if it 's done right , and if you have data then , there are techniques for learning the numbers given the structure and there are even techniques for learning the structure , although that takes lot more data , and it 's not as @ @ and and so on . but for the limited amount of we have for this particular exercise we 'll just design it .
E: fo - hopefully as time passes we 'll get more and more data from heidelberg and from people actually using it and . so but this is the long run . but to solve our problems ag mediocre design will do in the beginning .
B: that 's right . , and , speaking of data , , are there could swore , could swear saw it sitting on someone 's desk at some point , but is there transcript of any of the , , initial interactions of people with the with the system ? cuz , 'm still itching to look at what look at the , and see what people are saying .
C: make yourself note . so and , keith would like the german as as the english , so whatever you guys can get . the your native language , you remember that one .
E: that 's important , .
C: so he 'll get you some data .
B: found the , the audio of some of those , and , it sounded like didn't want to trudge through that , . it was just strange ,
E: we probably will not get those to describe because they were trial runs . but that 's th but we have data in english and german already . will send you that .
C: so while we 're still at this top level , anything else that we oughta talk about today ?
E: ho - how was your thingy .
B: , wanted to , , like mention as an issue , , last meeting wasn't here because went to linguistics colloquium on the fictive motion , and that was pretty interesting seems to me that will fairly be of relevance to to what we 're doing here because people are likely to give descriptions like , "" what 's that thing right where you start to go up the hill , "" like that , meaning few feet up the hill or whatever from some reference point and all that so , 'm in terms of , people trying to state locations or , , all that , this is gonna be very relevant . now that was the talk was about english versus japanese , , which the japanese doesn't affect us directly , except that , , some of the construction he 'd what he talked about was that in english we say things like th , "" your bike is parked across the street "" and we use these prepositional phrases , , "" , if you were to move across the street you would be at the bike "" , but in japanese the more conventionalized tendency is to use description of "" where one has crossed to the river , there is tree "" . and , you can actually say things like , , "" there 's tree where one has crossed the river , but no one has ever crossed the river "" , like that . so the idea is that this really is that 's supposed show that 's it 's really fictive and so on . but that construction is also used in english , , like "" right where you start to go up the hill "" , or "" just when you get off the train "" , like that to , to indicate where something is . so we 'll have to think about
C: how much is that used in german ?
E: the wa was on on different sidetrack . the deep map project which is undergoing some renovation at the moment , but this is three language project : german , english , japanese . and , we have , have taken care that we have the japanese generation and . and so looked into spatial description . so we can generate spatial descriptions , how to get from to . and and information on objects , in german , english , and japanese . and there is huge project on spatial descriptions differences in spatial descriptions . if yo if you 're interested in that , it does go all the way down to the conceptual level to some extent .
C: so , where is this huge project ?
E: it 's kleist . it 's the bielefeld generation of spatial descriptions and whatever .
C: that may be another thing that keith wants to look at .
E: but , we should leave japanese constructions maybe outside of the scope for now , but definitely it 's interesting to look at cross the bordered there .
A: are are you going to pay any attention to the relative position of the direction relative to the speaker ? there are some differences between hebrew and english . we can say "" park in front of the car "" as you come beh you drive behind the car . in hebrew it means "" park behind the car "" , because to follow the car is defined as it faces you . while in english , front of the car is the absolute front of the car .
B: right , so the canonical direction of motion determines where the front is .
A: so , is german closer to , , to don't 's related to syntax , though , so it may be entirely different .
C: no , it 's not .
E: did you ever get to look at the rou paper that sent you on the on that problem in english and german ? carroll , ninety - three . there is study on the differences between english and german on exactly that problem . so it 's they actually say "" the monkey in front of the car , where 's the monkey ? "" and , , they found statistically very significant differences in english and german , it might be , since there are only finite number of ways of doing it , that german might be more like hebrew in that respect . the solution they proposed was that it was due to syntactic factors .
A: that but it wasn't was
E: that syntactic facto factors do play role there , wh whether you 're more likely , , to develop , choices that lead you towards using intrinsic versus extrinsic reference frames .
B: it seems to me that you can get both in english depending like , "" in front of the car "" could like , here 's the car sideways to me in between me and the car 's in front of the car , or whatever . could see that , but anyway , so , , this was this was very good talk on those kinds of issues and so on .
E: also give you , pointer to paper of mine which is the ultimate taxonomy of reference frames . 'm the only person in the world who actually knows how it works .
C: no , 've not seen that .
A: what do you mean . . "" reference frames "" ?
E: it 's it 's spatial reference frames . you actually have only if you wanna have should there should be an "" "" , though . actually you have only have two choices . you can either do two - point or three - point which is you you 're familiar with th with the "" origo "" ? where that 's the center "" origo "" is the center of the frame of reference . and then you have the reference object and the object to be localized . in some cases the origo is the same as the reference object .
C: so that would be "" origin "" in english ,
E: "" origo "" is terminus technikus . in that sense , that 's even used in the english literature . "" origo . ""
B: never heard it .
E: and , so , this video tape is in front of me . 'm the origo and 'm also the reference object . those are two - point . and three - point relations is if something has an intrinsic front side like this chair then your shoe is behind the chair . and , reference object and . no , from my point of view your shoe is left of the chair .
B: you you can actually say things like , , "" it 's behind the tree from me "" like that , , in in certain circumstances in english , as "" from where 'm standing it would appear that ""
F: looks little bit like reichenbach for time .
C: it sounds like it ,
F: it 's lot like it .
E: and then and then here you on this scale , you have it either be ego or allocentric . and that 's that 's it . so . egocentric two - point , egocentric three - point , or you can have allocentric . so , "" as seen from the church , the town hall is right of that , fire station "" . aa - it 's hardly ever used but it 's
A: 'd love to see it if you if you have copy .
C: see this is this is getting into ami 's thing . he 's he 's very interested in that . why don't you just put it on the web page ? there 's this edu
E: it 's or just
C: or link to it .
E: it 's also all on my home page at eml . it 's called "" an anatomy of spatial description "" . but 'll send that link .
C: maybe just put link on . there something that didn't know until about week ago or so , is , there are separate brain areas for things within reach , and things that are out of reach . so there 's there 's all this linguistic about , near and far , or yon and . so this is all this is there 's this linguistic facts . but , the . here 's the way the findings go . that , they do mri , and if you 're got something within reach then there 's one of your areas lights up , and if something 's out of reach different one . but here 's the amazing result , , they say . you get someone with with deficit so that they have perfectly normal ability at distance things . so the typical task is subdivision . so there 's line on the wall over there , and you give them laser pointer , and you say , "" where 's the midpoint ? "" and they do fine . if you give them the line , and they have to touch it , there 's just that part of the brain isn't functioning , so they can't do that . here 's the real experiment . the same thing on the wall , you give them laser , "" where is it ? "" , they do it . give them stick , long stick , and say "" do it "" , they can't do it . so there 's remapping of distant space into nearby space .
A: the end the end of this
F: because it 's within reach now ?
C: it 's not within reach and you use the within - reach , mechanism . so 'll 'll dig you up this reference . and so this doe this is , first of all , it explains something that 've always wondered about and 'll do this test on you guys as . how - have had an experience , not often , but certain number of times , when , , 'm working with tool , screwdriver , for long time , start feeling the tip directly . but you actually can feel the tip . and people who are accomplished violinists and like that , claim they also have this thing where you get direct sensation of , physical sensation , of the end affector .
B: what 's going on at the end of the tool ,
A: the ext the the extension ,
B: what 's going on at the end of the tool , or whatever .
A: the extension of your hand , right .
C: have you hav had this ?
A: it 's not exactly the th same thing , but it it 's getting close to that .
F: what does it feel like ?
C: it feels like your as if your neurons had extended themselves out to this tool , and you 're feeling forces on it and and you deal directly with it .
A: once was playing with those devices thow you to manipulate objects when it 's dangerous to get close ? so you can insert your hand something and there 's correspondence between so played with it . after while , you don't feel the difference anymore . very you stop back and suddenly it goes away and you have to work again to recapture it , but .
C: so anyway , so so this was the first actual experimental evidence 'd seen that was consistent with this anecdotal . and it makes lovely def story about why languages , make this distinction . there are behavioral differences too . things you can reach are really quite different than things you can't . but there seems to be an actu really deep embodied neural difference . and this is , so . in addition to the
E: this is more proximal - distal .
C: so in addition to ego and allocentric which appear all over the place , you also have this proximal - distal thing which is very deeply embedded .
E: he does the th the cognitive map world , down in santa barbara . and he always talks about these probably most likely without knowing this evidence is talking about these small scale spaces that you can manipulate versus large scale environmental spaces .
C: there 's there 's been lot of behavioral things on this , but that was the first neur neuro - physiological thing saw . anyway , so we 'll we 'll look at this . and . so , all of these issues now are now starting to come up . so , now we 're now done with demos . we 're starting to do science , and so these issues about , reference , and spatial reference , discourse reference , - - all this , , deixis which is part of what you were talking about , so , all of this is coming up essentially starting now . so we gotta do all this . so there 's that . and then there 's also set of system things that come up . so "" , we 're not using their system . that means we need our system . "" it it follows . and so , , in addition to the business about just getting the linguistics right , and the formalism and , we 're actually gonna build something and , johno is point person on the parser , analyzer , whatever that is , and we 're gonna start on that in parallel with the , the grammar . but to do that we 're gonna need to make some decisions like ontology , so , and so this is another thing where we 're gonna , , have to get involved and make relatively early , make some decisions on , "" is there an ontology api that "" there 's standard way of getting things from ontologies and we build the parser and around that , or is there particular ontology that we 're gonna standardize on , and if so , is there something that we can use there . does either the smartkom project or one of the projects at eml have something that we can just pull out , for that . so there are gonna be some some things like that , which are not science but system . but we aren't gonna ignore those cuz we 're we 're not only going the plan is not only to lay out this thing , but to actually build some of it . and how much we build , and . part of it , if it works right , is wh it looks like we 're now in position that the construction analyzer that we want for this applied project can be the same as the construction analyzer that nancy needs for the child language modeling . so . it 's always been out of phase but it now seems that , there 's good shot at that . so we 've talked about it , and the hope is that we can make these things the same thing , and it 's only in both cases it 's only one piece of bigger system . but it would be if that piece were exactly the same piece . it was just this construction analyzer . and so we think we think we have shot at that . so . the for to to come full circle on that , this formalization task , is trying to get the formalism into shape where it can actually
B: be of use to someone who 's trying to do this ,
C: where it actually is covers the whole range of things . and the the thing that got mark into the worst trouble is he had very ambitious thing he was trying to do , and he insisted on trying to do it with limited set of mechanisms . it turned out , inherently not to cover the space . and it just it was just terribly frustrating for him , and he seemed fully committed to both sides of this irreconcilable thing . johno is much more pragmatic .
B: good to know .
C: is this is true , is it not ? so there 's , , deep , really deep , emotional commitment to certain theory being , complete .
F: you don't have hidden purist streak ?
C: we - it hasn't it certainly hasn't been observed , in any case . now , you do , but that 's . so . for for
B: cuz don't have to implement anything .
F: have problem , then . it 's so . whether do depends on whether 'm talking to him or him probably .
C: why actually , , , you do but , th the thing you have to im implement is so small that .
F: which meeting 'm in . it 's to be purist within that context .
C: and , it 's and still , , , get something done . but to try to do something upscale and purist particularly if what you 're purist about doesn't actually work , is real hard . and then the other thing is while we 're doing this robert 's gonna pick piece of this space ,
A: it 's possible .
C: for his absentee thesis . you all know that you can just , in germany almost just send in your thesis .
B: just drive up . ca - chuk ! there you go .
E: the - th there there 's drive - in thesis sh joint over in saarbruecken .
B: drive through , .
C: it costs lot . the the amount you put in your credit card and as . so , , that 's , also gotta be worked out , hopefully over the next few weeks , so that it becomes clear , what piece , robert wants to jump into . and , while we 're at this level , , there 's at least one new doctoral student in computer science who will be joining the project , either next week or the first of august , depending on the blandishments of microsoft . so , de . and her name is eva . it really is . nobody believed th that
F: it had to be joke , of your part , like "" johno made it up ,
G: is this person someone who 's in first - year this year ,
C: no , first year coming . so , she 's she 's now out here she 's moved , and she 'll be student as of then . and probably she 'll pick up from you on the belief - net , so sh she 'll be chasing you down and like that . against all traditions . and actually talked today to undergraduate who wants to do an honors thesis on this .
F: someone from the class ? we always get these people who are not in the class , who
C: some of th some of them , .
F: it 's interesting .
C: but she 's another one of these ones with three point nine average and and so on . so , , 've give 've given her some things to read . so we 'll see how this goes . there 's yet another one of the incoming first incoming first - year graduate students who 's expressed interest , so we 'll see how that goes . so , as far as this group goes , , it 's certainly worth continuing for the next few weeks to get closure on the belief - net and the ideas that are involved in that , and what are th what are the concepts . we 'll see whether it 's gonna make sense to have this be separate from the other bigger effort with the formalization or not , it partly depends on what your thesis turns out to be and how that goes . so , we 'll see . and then , ami , you can decide , , how much time you wanna put into it and , it 's beginning to take shap shape , you will find that if you want to look technically at some of the your traditional questions in this light , keith , who 's buil building constructions , will be quite happy to see what , , you envision as the issues and the problems and , how they might get reflected in constructions . suspect that 's right .
A: may have to go to switzerland for in june or beginning of july for between two weeks and four weeks , but , after that or before that .
C: and , , if it 's useful we can probably arrange for you to drop by and visit either at heidelberg or at the german ai center , while you 're in the neighborhood .
A: actu actually 'm invited to do some consulting with bank in geneva which has an affiliation with research institute in geneva , which forgot the name of .
C: we 're connected to there 's there 's very significant connection between we 'll we 'll go through this , icsi and epfl , which is the , it 's the fr ge - germany 's got two big technical institutes . there 's one in zurich , and then there 's one , the french speaking one , in lausanne ,
B: so in switzerland .
C: so find out who they are associated with in geneva . probably we 're connected to them .
A: 'll send you email .
C: and so anyway we we can undoubtedly get ami to give talk at eml like that . while he 's in
E: the one you gave here couple of weeks ago would be of interest there , too .
C: lot of interest . actually , either place , dfki or so , and if there is book , that you 'll be building up some audience for it . and you 'll get feedback from these guys . cuz they 've actually these dfki guys have done as much as anyone over the last decade in trying to build them . so we 'll set that up . so , , unless we wanna start digging into the the belief - net and the decisions now , which would be fine , it 's probably
E: it 's probably better if come next week with the version point nine of the structure .
C: so , how about if you two guys between now and next week come up with something that is partially proposal , and partially questions , saying "" here 's what we think we understand , here are the things we think we don't understand "" . and that we as group will try to finish it . what 'd like to do is shoot for finishing all this next monday . "" these are the decisions "" don't think we 're gonna get lots more information . it 's design problem . and let 's come up with first cut at what this should look like . and then finish it up . does that so make sense ?
E: and , the sem semester will be over next week but then you have projects for one more week to come ?
G: no , 'll be done everything by this by the end of this week .
E: same with you ?
D: this , 've have projects , but then the my prof professor of one of my classes also wa has final that he 's giving us . and he 's giving us five days to do it which means it going to be hard .
C: is it take - home final ? who 's doing this ?
D: aikin , alex , .
C: that would have been my . but anyway , .
D: so , the seventeenth will definitely be the last day , like it or not for me .
C: so let 's do this , and then we there 's gonna be some separate co these guys are talking , we have group on the formalization , nancy and johno and are gonna talk about parsers . so there 're various kinds of nothing gets done even in meeting of seven people , so , , two or three people is the size in which actual work gets done . so we 'll do that . the other thing we wanna do is catch up with , ellen and see what she 's doing because the image schemas are going to be , an important pa
B: quite relevant , .
C: we we want those , and we want them formalized and like that . so let me let me make note to do that .
B: 'm actually probably going to be in contact with her pretty soon anyway because of various of us students were going to have reading group about precisely that thing over the summer ,
C: that 's great ! shweta mentioned that , although she said it 's secret . th - the faculty aren't faculty aren't supposed to know .
D: wednesday 's much better for me , .
C: 'm sufficiently clueless that count as
B: it 's as if we didn't tell anyone ,
","The translation of SmartKom to english is in its final stages.
The synthesis module will be the last one to do , after the english syntax trees are completed.
The system is still buggy and unstable , but it will soon be ready for a demonstration.
This is the first of two working demos required for the project.
Further than that , there are no restrictions on the focus of the research or its possible applications.
For example , issues like spatial descriptions could be investigated.
The variety of linguistic conventions seem to develop around an ego/allo-centric and a proximal/distal paradigm.
The latter is also reflected in neuro-physiological data.
From an engineering perspective , the belief-net for the AVE task should be completed within a few weeks.
The majority of the nodes are already there.
This leaves the dependencies between them and the rules of computation to be set.
Since the whole system is going to be re-designed , there are major decisions to be taken regarding the parser and the ontology , as well as what can be re-used from past EML projects.
In parallel , another team is working on formalisation and notation.
Finally , more ideas are expected to come from students and their research.
The final english SmartKom demo will be presented to the whole institute once the system is de-bugged and stabilised.
After the demo , the focus of research can switch towards purely scientific goals , including issues on ontology , deep semantic constructions , execution engines etc.
Moreover , a new system will be designed for the project and at least some parts of it should be built.
Similarly , the construction analyser should be a single , general tool working for both the tourist domain and child language modelling.
The focus for the next meeting will be on the belief-net , of which a working demo should be complete in the next few weeks.
Since there are not enough data , its connections and weights will have to be designed.
Although JavaBayes has been the tool of choice until now , the possibility that Hugin could be a better option should be investigated.
In order to promote the collaboration with EML , the group-ware server there will be updated with all progress being made in the two sites.
A talk on some of the issues will also be organised to take place at DFKI.
The german SmartKom version available on the server does not work.
The english version , although still under development , does work , however , the system is still unstable as -apart from other reasons- it was initially built to work with a touch screen.
De-bugging and cleaning up has to take place before any new modules are added on it.
As regards the belief-net , no connections and dependencies have been built into it.
These will have to be guessed instead of learnt through data , as not enough data is available for such a task.
Finally , it has been noted that the JavaBayes GUI does not satisfy all the presentation requirements for this belief-net and modifying the underlying code would be too time-consuming.
The german SmartKom system has been translated to English up to the speech synthesis level.
The german syntax trees are currently being adapted to English.
These also contribute information to the synthesis module in order to achieve better pronunciation.
The current english version is probably the best working one , since some of the problems with the original system have been corrected.
The design of the belief-net has also progressed significantly: the vast majority of the nodes have been identified and the feasibility of the task from a technical point of view has been confirmed.
"
ami_abstractive_summary,Bmr025.txt,"B: if we can't , we can't . but we 're gonna try to make this an abbreviated meeting cuz the next occupants were pushing for it , agenda is according to this , is transcription status , darpa demos xml tools , disks , backups , et cetera and
H: does anyone have anything to add to the agenda ?
B: should we just go in order ? who 's that 's probably you .
A: do that quickly . hired several more transcribers , they 're making great progress . seve - several , several . 've been finishing up the double checking . hoped to have had that done by today but it 's gonna take one more week .
H: as somewhat segue into the next topic , could get hold of the data even if it 's not really corrected yet just so get the data formats and make the information retrieval is working ?
A: it 's in the same place it 's been .
H: so can you just
A: - . no change .
H: just so , "" transcripts "" is the sub - directory ?
A: yes . - .
H: so 'll 'll probably just make some copies of those rather than use the ones that are there . and then just we 'll have to remember to delete them once the corrections are made .
D: also got anot short remark to the transcription . 've just processed the first five edu meetings and they are chunked up so they would they probably can be sent to ibm whenever they want them .
F: the second one of those
D: it 's already at ibm ,
F: is already at ibm .
D: but the other ones
F: that 's the one that we 're waiting to hear from them on .
A: these are separate from the ones that
F: they 're the ibm set .
H: it 's this one .
F: and so as soon as we hear from brian that this one is
H: is my mike on ?
F: and we get the transcript back and we find out that hopefully there are no problems matching up the transcript with what we gave them , then we 'll be ready to go and we 'll just send them the next four as big batch , and let them work on that .
H: and so we 're doing those as disjoint from the ones we 're transcribing here ?
F: we 're doing things in parallel , that way we can get as much done at once .
H: that 's the right way to do it , especially for the information retrieval . anything else on transcription status ?
A: hm - mmm .
B: we had the submeeting the other day .
H: so 've been working on using the thisl tools to do information retrieval on meeting data and the thisl tools are there 're two sets , there 's back - end and front - end , so the front - end is the user interface and the back - end is the indexing tool and the querying tool . and so 've written some tools to convert everything into the right for file formats . and the command line version of the indexing and the querying is now working . so at least on the one meeting that had the transcript for conveniently you can now do information retrieval on it , do type in string and get back list of start - end times for the meeting ,
F: what what what does that look like ? the string that you type in . what are you are they keywords , or are they ?
H: right ? and so and then it munges it to pass it to the thisl ir which uses an sgml - like format for everything .
B: and then does it play something back or that 's something you 're having to program ?
H: right now , have tool that will do that on command line using our standard tools , but my intention is to do prettier user interface based either so so that 's the other thing wanted to discuss , is what should we do for the user interface ? we have two tools that have already been written . the softsound guys did web - based one , which haven't used , haven't looked at . dan says it 's pretty good but it does mean you need to be running web server . and so it 's pretty big and complex . and it would be difficult to port to windows because it means porting the web server to windows . the other option is dan did the tcl - tk thisl gui front - end for broadcast news which looks great . that 's demo . and that would be much easier to port to windows . and so that 's the way we should go .
A: so as it stands within the channeltrans interface , it 's possible to do find and play . you can find searched string and play . so are you so you 're adding like , , are they fuzzy matches or are they ?
H: it 's standard , text - retrieval - based so it 's term frequency , inverse document frequency scoring . and then there are all sorts of metrics for spacing how far apart they have to be and things like that .
A: it 's lot more sophisticated than the the windows - based
H: it 's like doing google query or anyth anything else like that . so it uses so it pr produces an index ahead of time so you don't you 're not doing linear search through all the documents . cuz you can imagine if with if we have the sixty hours ' worth you do wouldn't wanna do search .
A: hm - mmm .
H: you have to do preindexing and so that these tools do all that . and so the work to get the front - end to work would be porting it to get it to work on the unix systems , our side is just rewriting them and modifying them to work for meetings . so that it understands that they 're different speakers and that it 's one big audio file instead of bunch of little ones and just sorta things like that .
F: so what does the user see as the result of the query ?
H: on which tool ? the thisl gui tool which is the one that dan wrote , tcl - tk you type in query and then you get back list of hits and you can type on them and listen to them . click on them rather with mouse .
F: so if you typed in "" small heads "" you could
H: right , you 'd get
F: get back something that would let you click and listen to some audio where that phrase had occurred
H: you you 'd get to listen to "" beep "" .
B: that was really good look . it 's too bad that couldn't come into the
H: you couldn't get video .
G: who practice on ?
A: at some point we 're gonna have to say what that private joke is , that keeps coming up .
B: and then again , maybe not . that soun that sounds reasonable . it loo it my recollection of it is it 's it 's pretty reasonable demo format .
F: that sounds good .
H: and so there 'd be minimal effort to get it to work , minimally
F: that sounds really neat .
H: and then we 'd wanna add things like query by speaker and by meeting and all that . dave gelbart expressed some interest in working on that so 'll work with him on it . and it 's looking pretty good , the fact that got the query system working . so if we wanna just do video - based one that 'll be easy . if we wanna get it to windows it 's gonna be little more work because the thisl ir , the information retrieval tool 's , had difficulty just compiling them on solaris . so getting them to compile on windows might be challenging .
F: but you were saying that the that there 's that set of tools , , cygnus tools , that
H: it certainly helps . without those wouldn't even attempt it . but what those they what those do is provide bsd compatibility layer , so that the normal unix function calls all work .
F: and you have to have all the
H: but the problem is that the thisl tools didn't use anything like autoconf and so you have the normal porting problems of different header files and th some things are defined and some things aren't and different compiler work - arounds and so on . so the fact that it took me day to get it to compile under solaris means it 's probably gonna take me significantly more than that to get it to compile under windows .
B: how about having it run under free bsd ?
H: free bsd would probably be easier .
E: all you need to do is say to dan "" gee it would be if this worked under autoconf "" and it 'll be done in day .
H: that 's true . because he did port it to sprachcore so he might have done that already .
E: wouldn't be surprised .
H: 'll check at that
B: but it would what would serve would serve both purposes , is if you contact him and ask him if he 's already done it .
F: how does it play ?
B: if he has then you learn , if he hasn't then he 'll do it .
F: hope he never listens to these meetings .
H: that 's right . so , and 've been corresponding with dan and also with , softsound guy ,
A: it 's amazing .
H: blanking on his name . or or steve renals .
B: steve renal - steve renals .
H: which one do ?
E: steve renals is not softsound ,
H: my brain is not working , don't remember who 've been corresponding with .
E: steve wro it 's ste - steve renals wrote thisl ir .
H: then it 's steve renals . so just getting documentation and and and formats , so that 's all going pretty ,
F: what about issues of playing sound files @ @ between the two platforms ?
H: we 'll be with that . that 's good point too .
E: here 's here 's crazy idea actually . why don't you try and merge transcriber and thisl ir ? they 're both tcl interfaces .
H: this is one of the reasons this is the one of the reasons that 'm gonna have dave gelbart having him volunteer to work on it is really good thing because he 's worked on the transcriber and he 's more familiar with tcl - tk than am .
E: and then you get they then you get the windows media playing for free .
H: that 's snack , not transcriber .
E: right . but that the transcriber uses snack and then you can but you can use lot of the same functionality
H: , , thisl gui probably uses snack . and so my intention was just to base it on that .
E: my thought was is that it would be it would be to have the running transcripts , from speaker to speaker .
H: and if it doesn't
E: do you have you have , , speaker mark here and speaker mark here ?
H: right , we 'll have to figure out user interface for that , so .
E: right . that my thought was if you had like multitrans or whatever do it .
H: it might be fairly difficult to get that to work in the little short segments we 'd be talking about and having the search tools and so on . we we can look into it ,
B: the thing was asking about with , , free bsd is that it might be easier to get powerpoint shows running in free bsd than to get this other package running in
H: we have to have to sit down and try it before make too many judgments , my experience with the gnu compatibility library is really it 's just as hard and just as easy to port to any system . the windows system isn't any harder because it looks like bsd system . it 's just , , just like all of them , the "" include "" files are little different and the function calls are little different . so it might be little easier but it 's not gonna be lot easier .
B: so there was that demo , which was one of the main ones , then we talked about some other which would be showing off the transcriber interface itself and as you say , maybe we could even merge those in some sense , and part of that was showing off what the speech - non nonspeech that thilo has done looks like .
A: can ask one more thing about thisl ? so with the ir then you end up with somewhat prioritized ?
G: so another idea had just now actually for the demo was whether it might be of interest to sh to show some of the prosody work that don 's been doing . actually show some of the features and then show task like finding sentence boundaries or finding turn boundaries . you can show that graphically , what the features are doing . it , , it doesn't work great but it 's definitely giving us something .
B: at the very least we 're gonna want something illustrative with that
G: if that would be of interest or not .
B: cuz 'm gonna want to talk about it and so if there 's something that shows it graphically it 's much better than me just having bullet point pointing at something much about ,
G: you 're looking at this now are you looking at waves or matlab ?
C: we can probably find some examples of different type of prosodic events going on .
B: so when we here were having this demo meeting , what we 're coming up with is that we wanna have all these pieces together , to first order , by the end of the month and then that 'll give us week or so .
C: ooo . the end of
G: the end of this month or next month ? you mean like today ?
B: june . june .
H: today isn't june first ,
F: there 's another one .
B: that 'll give us that 'll give us week or so to to port things over to my laptop and make that works ,
C: 'll be here .
G: if if don can talk to whoever 's cuz we 're doing this anyway as part of our , the research , visualizing what these features are doing it might not be integrated but it could potentially be in it .
B: , this is to an audience of researchers
G: could find some .
B: to let the goal is to let them it is we 're doing .
G: it 's different . don't think anyone has done this on meeting data so it might be neat , .
B: done with that .
H: so 've been doing bunch of xml tools where you we 're moving to xml as the general format for everything and that 's definitely the right way to go because there are lot of tools that let you do extraction and reformatting of xml tools . so yet again we should probably meet to talk about transcription formats in xml because 'm not particularly happy with what we have now . it works with transcriber but it 's pain to use it in other tools because it doesn't mark start and end .
F: start and end of each ?
H: so it 's implicit in there but you have to do lot of processing to get it . and so and also 'd like to do the indirect time line business . but regardless , , that 's something that you , me , and jane can talk about later . but 've installed xml tools of various sorts in various languages and so if people are interested in doing extracting any information from any of these files , either information on users because the user database is that way 'm converting the key files to xml so that you can extract various inf sorted information on individual meetings and then also the transcripts . and so just let me know there it 's mostly java and perl but we can get other languages too if that 's desirable .
G: quick question on that . is do we have the seat information ? in in the key files now ?
H: the seat information is on the key files for the ones which
G: for the new one
H: it 's been recorded , where where you 're sitting .
B: ! not not the quality or anything . no .
H: "" it 's pretty soft and squishy . "" but that might just be me .
B: that 's more seat information than we wanted .
G: 'm just trying to figure out , , when morgan 's voice appears on someone 's microphone are they next to him or are they across from him ?
H: maybe we should bleep that out .
F: how where is it in the key file ?
H: the square bracket .
G: cuz haven't been putting it in
H: you haven't been putting it in .
A: isn't it always on the digits ?
B: some of these are missing .
A: isn't it always on the digits forms ?
B: some fall out of
H: so we can go back and fill them in for the ones we have .
G: they 're on th right , these , but hadn't ever been putting it in the key files . and don't think chuck was either
F: never knew we were supposed to put it in the key file .
H: had told you guys about it
G: so we 're both .
H: this is why wanna use tool to do it rather than the plain text because with the plain text it 's very easy to skip those things . if you use the edit - key , or key - edit
D: edit - key .
H: it 's edit - key , command did show you guys that ?
F: you mentioned it ,
H: did show it to you , but you both said "" no , you 'll just use text file "" . it has it in there , place to fill it in . and so if you don't fill it in , you 're not gonna get it in the meetings .
G: right . realized hadn't been doing it
H: and then the other thing also that thilo noticed is , on the microphone , on channel zero it says hand - held mike or crown mike , you actually have to say which one .
F: ! . didn't do that either . takes me no time to edit these .
G: but it 's almost
H: that 's cuz you kn
F: 'm not doing anything .
G: and was was looking at chuck 's , like , "" what did chuck do , 'll do that "" .
H: and then also in couple of places instead of filling the participants under "" participants "" they were filled in under "" description "" . and so that 's also problem .
G: we will do better .
H: that 's it . also 'm working on another version of this tool , the one that shows up here , that will flash yellow if the mike isn't connected . and it 's not quite ready to go yet because it 's hard to tell whether the mike 's connected or not because the best quality ones , the crown ones , are about the same level if they 're off and no one 's off or if they 're on and no one 's talking . these ones , they are much easier , there 's bigger difference . so 'm working on that and it sorta works and so eventually we will change to that and then you 'll be able to see graphically if your mike is dropping in or out .
C: will that also include like batteries dying ? just any time the mike 's putting out zeros .
F: but with the screensaver kicking in , it
H: 'll turn off the screensaver too .
C: speaking of which .
H: the other thing is as 've said before , it is actually on there 's little level meter but no one ever pays attention to it . so having it on the screen is more easy to notice .
A: it would be if these had little light indicators ,
H: "" bamp , bamp ! "" disk backup , et cetera ? spoke with dave johnson about putting all the meeting recorder on non - backed - up disk to save the overhead of backup and he said "" , you could do that if you want "" but he thought it was bad idea . what he said is doing the manual one , doing nw archive to copy it is good idea and we should do that and have it backed up . he he 's firm believer in lots of different modalities of backup . his point was taken . this data cannot be recovered . and so if mistake is made and we lose the backup we should have the archive and if then mistake is made and we lose the archive we should have the backup .
B: it is true that even with something that 's backed up it 's not gonna if it 's stationary it 's not going to go through the increment it 's not gonna burden things in the incremental backups .
H: just just the monthly full .
B: so the monthly full will be bear
H: but he said that we sh shouldn't worry too much about that , that we 're getting new backup system and we 're far enough away from saturation on full backups that it 's probably . and , so the only issue here is the timing between getting more disks and recording meetings .
B: so the idea is that we would be reserving the non - backed - up space for things that took less than twenty - four hours to recreate like that ,
H: things that are recreatable easily and also , things that are recreatable . the expanded files and things like that . they take up lot more room anyway . but we do need more disk .
B: so we can get more disk .
H: and agree with him . his point was taken that if we lose one of these we cannot get it back . don't think there was any other et cetera there .
B: was allowing someone else to come up with something related that they had
E: you guys were gonna burn ds ?
H: unfortunately we could burn ds but first of all it 's pain . because you have to copy it down to the pc and then burn it and that 's multi - step procedure . and second of all the write - once burners as opposed to professional press don't last . so burning them for distribution is fine but burning them for backup is not good idea . cuz th they fail after couple years .
A: do have it 's different topic . can add one top topic ? we have time ? wanted to ask , know that that thilo you were , , bringing the channeltrans interface onto the windows machine ? and wanted to th
D: it 's it it 's done ,
A: it 's all done ? that 's wonderful . great .
H: yes , since tcl - tk runs on it , things 'll just work .
D: it was just problem with the snack version and the transcriber version but it 's solved .
A: does and that does that mean , maybe should know this but don't . does this mean that the that this could be por ported to think - pad note or some other type of
D: did install it on my laptop
B: good . crosspads ?
H: got an email from james landay who said "" if you 're not using them , could you return them ? "" so he said he doesn't need them , he just periodically at the end of each term sends out email to everyone who was recorded as having them and asks them if they 're still using them .
B: so we 've never used them .
A: we used them once .
H: we we used them couple times ,
F: there 's more than one ?
H: we have two . my opinion on it is , first , never take notes anyway so 'm not gonna use it , and second , it 's another level of infrastructure that we have to deal with .
A: and have so my feeling on it is that in principle it 's really idea , and you have the time tags which makes it better tha than just taking ra raw notes . on the other hand , the down side for me was that the pen is really noisy . so you have ka kaplunk , kaplunk . and and if it 's audible on the but that was disadvantage . do take notes , could be taking notes on these things and the plus with the crosspads would be the time markings
D: what is crosspad ?
B: so it 's it 's it 's regular pad , just regular pad of paper but there 's this pen which indicates position . and so you have time and position stored so that you can you have record of whatever it is you 've written .
H: and then you can download it and they have ocr and searching and all sorts of things . so if you take notes it 's great little device . but don't take notes ,
B: and one of the reasons that it was brought up originally was because we were interested in higher - level things , not just the , , microphone but also summarization and and the question is if you were going to go to some gold standard of what wa what was it that happened in the meeting , where would it come from ? and that was one of the things , and so the it seemed like neat idea . we 'll have , have scribe , have somebody take good notes and then that 's part of the record of the meeting . and then we did it once or twice and we
H: and then just died out .
B: probably chose the wrong scribe but it was it 's
H: that 's right .
A: did it one time but the other thing 'm thinking is if we wanted that thing wonder if we 'd lose that much by having someone be scribe by listening to the tape , to the recording afterwards and taking notes in some other interface .
F: we 're transcribing it anyways , why do we need notes ?
A: it 's la it 's useful ,
H: because that 's summary .
A: have summary and high points .
G: there 's this use that
F: summarize it from the transcription .
G: what if you 're sitting there and you just wanna make an and you don't wanna take notes and you 're you just wanna get the summary of the transcript from this time location like , and then while you 're bored you don't do anything and once in while , maybe there 's joke and you put in other words you can use that just to highlight times in very simple way . also with was thinking and know morgan disagrees with me on this but suppose you have group in here and you wanna let them note whenever they think there might be something later that they might not wanna distribute in terms of content , they could just make an near that point or question mark that alerts them that when they get the transcript back they could get some red flags in that transcript region and they can then look at it . know we haven't been using it but imagine it being useful just for marking time periods which you then get back in transcript
B: so , , what makes one is maybe we should actually schedule some periods where people go over something later and and put some summary some there 'd be some scribe who would actually listen , who 'd to actually listen to the whole thing , not transcribe it , but just write down things that struck them as important . but then you don't you don't have the time reference that you 'd have if you had it live .
G: and you don't have lot of other cues that might be useful ,
F: how do you synchronize the time in the crosspad and the time of the recording ?
H: that was one of the issues we talked about originally and that 's part of the difficulty is that we need an infrastructure for using the time the crosspads and so that means synchronizing the time you want it pretty close and there 's fair amount of skew because it 's hand - held unit with battery so you have to synchronize at the beginning of each meeting all the pads that are being used , so that it 's synchronized with the time on that and then you have to download to an application , and then you have to figure out what the data formats are and convert it over if you wanna do anything with this information . and so there 's lot of infrastructure which
A: there is an alternative . there is an alternative , it 's still , there 's , your point stands about there be needing to be an infrastructure , but it doesn't have to be synchronized with the little clock 's timer on it . you , when did it synchronized it by voice , by whispering "" one , two , three , four "" onto the microphone
H: but then there 's the infrastructure at the other end which someone has to listen to that and find that point ,
A: it 's transcribed . it 's in the transcript .
H: and then mark it .
A: it 's in the transcript .
G: could we keep one of these things for another year ? would is there big cau
H: we can keep all both of them for the whole year .
G: just in case we even maybe some of the transcribers who might be wanting to annotate just there 's bunch of things that might be neat to do but it might not be the case that we can actually synchronize them and then do all the infrastructure but we could at least try it out .
B: one thing that we might try is on some set of meetings , some collection of meetings , maybe edu is the right one or maybe something else , we get somebody to buy into the idea of doing this as part of the task . part of the reason part of the reason that adam was so interested in the speechcorder idea from the beginning is he said from the beginning he hated taking notes so and jane is more into it if you wanna really do this all the time so to get someone to actually buy into it and have at least some series of meetings where we do it . and if so , it 's probably worth having one . the the problem with the more extended view , all these other with quibbling about particular applications of it is that it looks like it 's hard to get people to routinely use it , it just hasn't happened anyway . but maybe if we can get person to
G: don't has to be part of what everybody does in meeting but it might be useful , neat part of the project that we can , , show off as mechanism for synchronizing events in time that happen that you just wanna make note of , like what jane was talking about with some later browsing , just as convenience , even if it 's not full - blown note taking substitute .
E: if you wanted to do that maybe the right architecture for it is to get pda with wireless card . and and that way you can synchronize very easily with the the meeting because you 'll be synchroni you can synchronize with the linux server
G: so what input would you be ?
E: so , , if you 're not worried about
G: you 'd just be pressing like
E: and may and you could have the same interface or whatever , you 'd have to do little little bit of coding to do it . but you could imagine ,
G: that be good .
E: if all you really wanted was you didn't want this secondary note - taking channel but just being able to use markers of some sort , pda with wireless card would be the probably the right way to go . even buttons you could do , as you said .
H: for what you 've been describing buttons would be even more convenient than anything else ,
G: that would be fine too . don't have , , grandiose ideas in mind but 'm just thinking we 've we 're getting into the next year now and we have lot of these things worked out at in terms of the speech maybe somebody will be interested in this
A: like this pda idea .
B: do like the idea of having couple buttons where like one button was "" - "" and then another button was "" that 's great "" and another button "" that 's ""
G: or like this is my "" 'm supposed to do this "" button , like "" better remember to ""
H: the crosspad idea is good one . it 's just question of getting people to use it and getting the infrastructure set up in such way that it 's not lot of extra work . that 's part of the reason why it hasn't happened is that it 's been lot of extra work for me
A: and not just for you . but it 's also , it has this problem of having to go from an analog to digital record too ,
H: it 's digital but it 's in format that is not particularly standard .
A: but , say , if if you 're writing if you 're writing notes in it does it can't do handwriting recognition ,
B: no , no , but it 's just it 's just storing the pixel informa position information , it 's all digital .
A: what 'm thinking is that the pda solution you you have it already without needing to go from the pixelization to to
B: you don't have to
E: the transfer function is less errorful ,
G: it also it 's maybe realistic cuz people are supposed to be bringing their as to the meeting eventually , that 's why we have this little what don't wanna more work for anyone but imagine some interesting things that you could do with it and so if we don't have to return it and we can keep it for year
H: we don't we certainly don't have to return it , as said . all all he said is that if you 're not using it could you return it , if you are using it feel free to keep it . that we haven't used it and are we going to ?
B: so we have no but by would suggest you return one . because we , we haven't used it . we have some aspirations of using them
G: one would probably be fine . maybe we could do like student project , maybe someone who wants to do this as their main like project would be .
H: if we had them out and sitting on the table people might use them little more
B: maybe jeremy could sit in some meetings and press button when there when somebody laughed .
H: although there is little
G: 'm , that 's not bad jeremy 's gonna be an he 's new student starting on modeling brea breath and laughter , actually , but it should be ,
H: sounds breathy to me .
G: "" ha - ha . ""
H: "" ha - ha - ha "" . "" ha - ha - ha . "" that reminded me of something . it slipped out .
G: you 're you 're gonna tease me ?
H: 'm always gonna do that . we ordered more wireless , and so they should be coming in at some point . and then at the same time 'll probably rewire the room as per jane 's suggestion so that the first channels are wireless , are the the close - talking and the next are far - field .
B: but isn't that funny sounding ? "" we ordered more wireless . "" it 's like wires are the things so you 're wiring you 're you we 're we ordered more absence of the thing .
G: that 's very philosophical statement from morgan .
H: wired less , wired more .
G: it 's anachronism , it 's great .
H: should we do digits ? do we have anything else ?
B: there 's there 's all this going on between andreas and and dave and chuck and others with various kinds of runs trying to figure things out about the features but it 's it 's all in process , so there 's not much to say why don't we start with our esteemed guest .
H: so just the transcript number and then the then the
E: yes , this is number two for me today .
B: see all you have to do is go away to move way up in the
G: we could do simultaneous .
B: we we could .
H: should we do simultaneous ?
G: 'm just thinking , are you gonna try to save the data before this next group comes in ? so we might wanna do it simultaneous .
H: you hav sorta have to .
B: so let 's do one of those simultaneous ones .
G: so we might we might need to do that actually .
B: that sounds good .
G: you have to plug your ears , eric ,
D: you don't have to .
G: or you start laughing .
H: about other people .
B: one and two and three . babble , take five .
","This meeting of the Berkley Meeting Recorder group charts the progress of their project and covers ongoing issues as well as some new ones.
The most pressing issue concerns the demos which the group are preparing for the DARPA meeting next month.
Here they discuss the querying and indexing tool which is progressing well albeit with a few front-end issues , and also the transcriber tool.
Transcription is progressing well , with new people hired , and double checking almost complete.
Work is also going on in parallel with IBM.
Additionally , the group have progressed further with data storage issues , with backing-up their data now regarded as a priority , and more disk space required.
Tools for accessing key file information have been developed which should ensure all meeting information is present.
The collection of CrossPad note-taking data will be pursued in future meetings.
Finally , other progress made includes getting the ChannelTrans interface working , ordering more wireless microphones , and analysing recognition runs.
DARPA demo illustrating prosody of meeting events will be completed by the end of the ( next ) month , so as to allow a week or so for transferring data across to laptops.
After consulting others , the group decide that not backing up their meeting data is a bad idea , since this cannot be recovered.
Therefore , meeting recorder data will be backed up , and also stored manually using the NW archive.
More disk space will be purchased , however for now , data which is easily re-creatable will not be backed up.
After evaluating the use of the CrossPads , the group decide to return one , and also keep one which will be left out in meetings to encourage its use.
Use of PDAs and buttons for note-taking will be investigated , along with using the data for a student research project.
Because of time constraints , the group decide to do simultaneous digits.
Improving the THISL front-end user interface may be difficult if it is to run on Windows as a web server Tcl-TK may need to be used instead.
More information on XML transcription formats is required for the creation of the tools.
Information for key files , such as Microphone type , seating , and participant information , is not being properly recorded , and in some cases the microphones aren't working properly.
However this should be rectified by the use of appropriate XML tools.
The CrossPads have not been used to their full potential , which is because of a number of problems regarding their use:
First , they need to be synchronised with the time of the meeting recording , and secondly , they use a non standard data format which needs converting.
Additionally , some people tend not to make notes in meetings.
Several transcribers have now been hired , and double-checking is almost finished.
Information retrieval will progress using uncorrected transcripts.
In parallel to the transcription , the first five EDU meetings are chunked and ready to go to IBM , once the IBM transcript is checked and satisfactory.
For the DARPA demo:
Tools have been written to convert everything into the correct file formats , an now the THISTL back-end querying and indexing tool is now working on the command line.
Work is also underway to improve the front-end THISTL interface.
The demo of Transcriber interface was discussed , and may include graphical illustration of prosodic features indicating sentence or turn boundaries.
Work is continuing to create tools for handling XML data , which extract data from the XML key files.
Tools will also be provided to ensure that appropriate meeting information is present , and that microphones and recording is working.
The ChannelTrans interface is now working on Windows machines.
More wireless microphones have been ordered , and the room is to be re-wired as suggested by Jane , using the wireless close-talking microphones first , and then the far-field microphones.
Analysis of the recognition runs to identify features and their characteristics is on-going.
"
ami_abstractive_summary,Bro011.txt,"B: blow into it , it works really .
A: people say the strangest things when their microphones are on . so everybody 's on ? so you guys had meeting with with hynek which unfortunately had to miss . chuck you weren't there either , you were there ? so everybody knows what happened except me . maybe somebody should tell me .
C: first we discussed about some of the points that was addressing in the mail sent last week . about the , the downsampling problem . and about the the length of the filters
A: what was the what was the downsampling problem again ?
C: so the fact that there is no low - pass filtering before the downsampling . there is because there is lda filtering but that 's perhaps not the best
A: depends what it 's frequency characteristic is , . so you could do you could do stricter one .
C: so we discussed about this , about the
A: was there any conclusion about that ?
C: "" try it "" .
A: so again this is th this is the downsampling of the the feature vector stream the lda filters they were doing do have let 's see , so the the feature vectors are calculated every ten milliseconds the question is how far down they are at fifty hertz . at twenty - five hertz since they 're downsampling by two . so . does anybody the frequency characteristic is ?
C: we don't have yet we should have look first at , perhaps , the modulation spectrum . so there is this , there is the length of the filters . so the this idea of trying to find filters with shorter delays . we started to work with this . and the third point was the , the on - line normalization where , the recursion recursion for the mean estimation is filter with some delay and that 's not taken into account right now . and there again , . for this , the conclusion of hynek was , , "" we can try it but ""
A: try try what ?
C: so try to take into account the delay of the recursion for the mean estimation . and this we 've not worked on this yet . and so while discussing about these lda filters , some issues appeared , like the fact that if we look at the frequency response of these filters it 's , we really what 's the important part in the frequency response and there is the fact that in the very low frequency , these filters don't don't really remove lot . compared to the to the standard rasta filter . and that 's probably reason why , , on - line normalization helps because it , it removed this mean . , but perhaps everything could should be could be in the filter , the mean normalization and so that was that 's all we discussed about . we discussed about good things to do also , generally good to do for the research . and this was this lda tuning perhaps and hynek proposed again to his traps ,
A: the key thing for me is figuring out how to better coordinate between the two sides was talking with hynek about it later and the had the sense that neither group of people wanted to bother the other group too much . and and don't think anybody is , , closed in their thinking or are unwilling to talk about things but that you were waiting for them to tell you that they had something for you and that and expected that they would do certain things and they were sor they didn't wanna bother you and they were waiting for you and and we ended up with this thing where they were filling up all of the possible latency themselves , and they just had hadn't thought of that . it 's true that maybe no one really thought about that this latency thing would be such strict issue
C: what happened really , but it 's it 's also so the time constraints . because , , we discussed about that about this problem and they told us "" , we will do all that 's possible to have enough space for network "" but then , , perhaps they were too short with the time and
A: then they couldn't .
C: but there was also problem perhaps problem of communication . now we will try to
A: just talk more .
C: slikes and send mails .
A: maybe we should just you 're you 're bus other than that you folks are busy doing all the all the things that you 're trying that we talked about before and this machines are busy and you 're busy let 's let 's , , that as we said before that one of the things that we 're imagining is that there will be in the system we end up with there 'll be something to explicitly do something about noise in addition to the other things that we 're talking about and that 's probably the best thing to do . and there was that one email that said that it sounded like things looked very promising up there in terms of they were using ericsson 's approach and in addition to they 're doing some noise removal thing ,
C: so we 're will start to do this also . so carmen is just looking at the ericsson code .
D: modifying studied barry 's sim code , more or less . to take @ @ the first step the spectral subtraction . and we have some the feature for italian database and we will try with this feature with the filter to find the result . but we haven't result until this moment . but , we are working in this also and maybe try another type of spectral subtraction , don't
A: when you say you don't have result yet you mean it 's it 's just that it 's in process or that you it finished and it didn't get good result ?
D: no , no we have do the experiment only have the feature the feature but the experiment have we have not make the experiment maybe will be good result or bad result ,
A: so suggest actually now we we sorta move on and hear what 's what 's happening in other areas like what 's happening with your investigations about echos and so on .
F: haven't started writing the test yet , 'm meeting with adam today and he 's going show me the scripts he has for running recognition on mee meeting recorder digits . also haven't got the code yet , haven't asked hynek for the for his code yet . cuz looked at avendano 's thesis and don't really understand what he 's doing yet but it it sounded like the channel normalization part of his thesis was done in bit of what the word is , bit of rough way it sounded like he he it wasn't really fleshed out and maybe he did something that was interesting for the test situation but 'm not if it 's what 'd wanna use so have to have to read it more , don't really understand what he 's doing yet .
A: haven't read it in while so 'm not gonna be too much help unless read it again ,
D: know this is mine here .
A: so you , and then you 're also gonna be doing this echo cancelling between the close mounted and the and the what we 're calling cheating experiment of sorts
F: or 'm hoping 'm hoping espen will do it .
A: that 's good . it 's good to delegate .
F: he 's at least planning to do it for the cl close - mike cross - talk and so maybe just take whatever setup he has and use it .
A: wonder who else is maybe it 's dan ellis is going to be doing different cancellation . one of the things that people working in the meeting task wanna get at is they would like to have cleaner close - miked recordings . so this is especially true for the lapel but even for the close - miked cases we 'd like to be able to have other sounds from other people and removed from so when someone isn't speaking you 'd like the part where they 're not speaking to actually be so what they 're talking about doing is using ec echo cancellation - like techniques . it 's not really echo but just taking the input from other mikes and using an adaptive filtering approach to remove the effect of that other speech . what was it , there was there was some some point where eric or somebody was speaking and he had lots of silence in his channel and was saying something to somebody else which was in the background and it was not it was recognizing my words , which were the background speech on the close mike .
B: the what we talked about yesterday ? that was actually my was wearing the was wearing the lapel and you were sitting next to me ,
A: it was you was
B: and only said one thing but you were talking and it was picking up all your words .
A: so they would like clean channels . and for that mmm that purpose they 'd like to pull it out . so dan ellis or somebody who was working with him was going to work on that . and if we 've talked lately about the plans you 're developing that we talked about this morning don't remember if we talked about that last week or not , but maybe just quick reprise of what we were saying this morning .
E: so continuing to extend
B: what about the that mirjam has been doing ? and and shawn , . so they 're training up nets to try to recognize these acoustic features ?
A: but that 's all that 's is certainly relevant study and , , what are the features that they 're finding . we have this problem with the overloading of the term "" feature "" what are the variables , what we 're calling this one , what are the variables that they 're found finding useful
B: and their targets are based on canonical mappings of phones to acoustic features .
A: and that 's certainly one thing to do and we 're gonna try and do something more more fine than that so what , was trying to remember some of the things we were saying , do you ha still have that ? there 's those that some of some of the issues we were talking about was in just getting good handle on what "" good features "" are
B: what does what did larry saul use for it was the sonorant detector , how did he do that ? wh - what was his detector ? so how did he combine all these features ? what what mmm classifier did he you were talking about that , .
A: and the other thing you were talking about is is where we get the targets from . so , there 's these issues of what are the what are the variables that you use and do you combine them using the soft "" and - or "" or you do something , , more complicated and then the other thing was so where do you get the targets from ? the initial thing is just the obvious that we 're discussing is starting up with phone labels from somewhere and then doing the transformation . but then the other thing is to do something better and why don't you tell us again about this database ? and then tell them to talk naturally ?
B: you could just mount it to that and they wouldn't even notice .
A: maybe you could go to these parlors and you could , have , , reduced rates if you if you can do the measurements .
B: that 's right . you could what you could do is you could sell little rings and with embedded , transmitters in them and things
A: be and help science .
B: there 's bunch of data that around , that people have done studies like that way back 't remember where wisconsin or someplace that used to have big database of remember there was this guy at - andt , or what was his name ? do you remember that guy ? researcher at - andt while back that was studying , trying to do speech recognition from these kinds of features . 't remember what his name was . now 'll think of it . that 's interesting .
A: do you mean but you mar
C: he was the guy the guy that was using
A: you mean when was mark randolph there , or ? he 's he 's at motorola now .
C: is it the guy that was using the pattern of pressure on the tongue
B: 't remember exactly what he was using , now . but know remember it had to do with positional parameters and trying to do speech recognition based on them .
A: so the only the only hesitation had about it since , haven't see the data is it sounds like it 's continuous variables and bunch of them . how complicated it is to go from there what you really want are these binary labels , and just few of them . and maybe there 's trivial mapping if you wanna do it and it 's but it worry little bit that this is research project in itself , whereas if you did something instead that like having some manual annotation by , linguistics students , this would there 'd be limited set of things that you could do as per our discussions with john before but the things that you could do , like nasality and voicing and couple other things you probably could do reasonably . and then there would it would really be this binary variable . course then , that 's the other question is do you want binary variables . the other thing you could do is boot trying to get those binary variables and take the continuous variables from the data itself there ,
B: could you cluster the just do some clustering ?
A: you could , .
B: bin them up into different categories and
A: so anyway that 's that 's that 's another whole direction that cou could be looked at . in general it 's gonna be for new data that you look at , it 's gonna be hidden variable because we 're not gonna get everybody sitting in these meetings to wear the pellets and
B: so you 're talking about using that data to get instead of using canonical mappings of phones . so you 'd use that data to give you what the true mappings are for each phone ?
A: so wh , where this fits into the rest in my mind , , is that we 're looking at different ways that we can combine different kinds of rep front - end representations in order to get robustness under difficult or even , , typical conditions . and part of it , this robustness , seems to come from multi - stream or multi - band sorts of things and saul seems to have reasonable way of looking at it , at least for one articulatory feature . the question is can we learn from that to change some of the other methods we have , since one of the things that 's about what he had was that it the decision about how strongly to train the different pieces is based on reasonable criterion with hidden variables rather than just assuming that you should train every detector with equal strength towards it being this phone or that phone . so it so he 's got these he "" and 's "" between these different features . it 's soft "" and "" , but in principle you wanna get strong concurrence of all the different things that indicate something and then he "" or 's "" across the different soft "" or 's "" across the different multi - band channels . the target for the training of the "" and "" "" and ' ed "" things is something that 's kept as hidden variable , and is learned with . whereas what we were doing is taking the phone target and then just back propagating from that
B: so he doesn't have
A: which means that it 's it 's it could be that for particular point in the data you don't want to train particular band train the detectors for particular band . you you wanna ignore that band , cuz that 's ban - band is noisy measure . we 're we 're still gonna try to train it up . in our scheme we 're gonna try to train it up to do as as it can at predicting . maybe that 's not the right thing to do .
B: so he doesn't have to have truth marks
E: and he doesn't have to have hard labels .
A: at the at the tail end , , he has to 's where it 's sonorant . but he 's but what he 's - but what he 's not training up what he doesn't depend on as truth is
E: for the full band .
A: one way of describing would be if sound is sonorant is it sonorant in this band ? is it sonorant in that band ? is it sonorant in that band ? it 's hard to even answer that what you really mean is that the whole sound is sonorant . then it comes down to , , to what extent should you make use of information from particular band towards making your decision . and we 're making in sense this hard decision that you should you should use everything with equal strength . and because in the ideal case we would be going for posterior probabilities , if we had enough data to really get posterior probabilities and if the if we also had enough data so that it was representative of the test data then we would be doing the right thing to train everything as hard as we can . but this is something that 's more built up along an idea of robustness from the beginning and so you don't necessarily want to train everything up towards the
B: so where did he get his his tar his high - level targets about what 's sonorant and what 's not ?
E: from canonical mappings at first and then it 's unclear right , right . and then he does some fine tuning for special cases .
A: we ha we have iterative training because we do this embedded viterbi , so there is some something that 's suggested , based on the data but it 's it 's not it doesn't seem like it 's quite the same , cuz of this cuz then whatever that alignment is , it 's that for all bands . no , that 's not quite right , we did actually do them separate tried to do them separately so that would be little more like what he did . but it 's still not quite the same because then it 's it 's setting targets based on where you would say the sound begins in particular band . where he 's this is not labeling per se . might be closer if we did soft target embedded neural net training like we 've done few times the forward do the forward calculations to get the gammas and train on those . what 's next ?
B: could say little bit about 've been playing with .
A: you 're playing ? you 're playing ?
B: yes , 'm playing . so wanted to do this experiment to see what happens if we try to improve the performance of the back - end recognizer for the aurora task and see how that affects things . and so had this sent around last week this plan had for an experiment , this matrix where would take the the original the original system . so there 's the original system trained on the mel cepstral features and then com and then optimize the htk system and run that again . so look at the difference there and then do the same thing for the icsi - ogi front - end .
A: what which test set was this ?
B: that looked at ? 'm looking at the italian right now . so as far as 've gotten is 've been able to go through from beginning to end the full htk system for the italian data and got the same results that that stephane had . so started looking to and now 'm 'm lookin at the point where wanna should change in the htk back - end in order to try to to improve it . one of the first things of was the fact that they use the same number of states for all of the models and so went on - line and found pronunciation dictionary for italian digits and just looked at , , the number of phones in each one of the digits . the canonical way of setting up an system is that you use three states per phone and so then the total number of states for word would just be , , the number of phones times three . and so when did that for the italian digits , got number of states , ranging on the low end from nine to the high end , eighteen . now you have to really add two to that because in htk there 's an initial null and final null so when they use models that have eighteen states , there 're really sixteen states . they 've got those initial and final null states . and so their of eighteen states seems to be pretty matched to the two longest words of the italian digits , the four and five which , according to my , , off the cuff calculation , should have eighteen states each . and so they had sixteen . so that 's pretty close . but for the most of the words are sh much shorter . so the majority of them wanna have nine states . and so theirs are twice as long . and then if you printed out confusion matrix for the - matched case , and it turns out that the longest words are actually the ones that do the best . so my about what 's happening is that , if you assume fixed the same amount of training data for each of these digits and fixed length model for all of them but the actual words for some of them are half as long you really have , , half as much training data for those models . because if you have long word and you 're training it to eighteen states , you 've got , you 've got the same number of gaussians , you 've gotta train in each case , but for the shorter words , , the total number of frames is actually half as many . so it could be that , , for the short words there 's because you have so many states , you just don't have enough data to train all those gaussians . so 'm going to try to create more word - specific prototype ms to start training from .
A: , it 's not uncommon you do worse on long word on short words than long words anyway just because you 're accumulating more evidence for the for the longer word ,
B: so 'll 'll , the next experiment 'm gonna try is to just create models that seem to be more matched to my about how long they should be . and as part of that wanted to see how the how these models were coming out , , what when we train up th , the model for "" one "" , which wants to have nine states , , what is the what do the transition probabilities look like in the self - loops , look like in those models ? and so talked to andreas and he explained to me how you can calculate the expected duration of an just by looking at the transition matrix and so wrote little matlab script that calculates that so 'm gonna print those out for each of the words to see what 's happening , , how these models are training up , the long ones versus the short ones . quickly , did the silence model that 's coming out with about one point two seconds as its average duration and the silence model 's the one that 's used at the beginning and the end of each of the string of digits .
A: lots of silence .
B: and so the model , which is what they put in between digits , haven't calculated that for that one yet , so they their model for whole digit string is silence digit , sp , digit , sp blah - blah and then silence at the end .
A: are the sp 's optional ?
B: have to look at that , but 'm not that they are . now the one thing about the model is really it only has single emitting state to it . so if it 's not optional , , it 's it 's not gonna hurt whole lot and it 's tied to the center state of the silence model so it 's not its own it doesn't require its own training data , it just shares that state . so it , , it 's pretty good the way that they have it set up , so wanna play with that little bit more . 'm curious about looking at , how these models have trained and looking at the expected durations of the models and wanna compare that in the - matched case to the unmatched case , and see if you can get an idea of just from looking at the durations of these models , , what 's happening .
A: , that , as much as you can , it 's good to not do anything really tricky . not do anything that 's really finely tuned , but just you you the premise is you have good person look at this for few weeks and what do you come up with ?
B: and hynek , when wa told him about this , he had an interesting point , and that was th the final models that they end up training up have probably something on the order of six gaussians per state . so they 're fairly , , hefty models . and hynek was saying that , probably in real application , you wouldn't have enough compute to handle models that are very big or complicated . so what we may want are simpler models . and compare how they perform to that . but , it depends on what the actual application is and it 's really hard to your limits are in terms of how many gaussians you can have .
A: and that , , at the moment that 's not the limitation , what you were gonna say but which was thinking was where did six come from ? probably came from the same place eighteen came from . that 's another parameter , that maybe , , you really want three or nine or
B: one thing , if if start reducing the number of states for some of these shorter models that 's gonna reduce the total number of gaussians . so in sense it 'll be simpler system .
A: but right now again the idea is doing just very simple things how much better can you make it ? and since they 're only simple things there 's nothing that you 're gonna do that is going to blow up the amount of computation if you found that nine was better than six that would be , , actually . doesn't have to go down .
B: really wasn't even gonna play with that part of the system yet , was just gonna change the
A: just work with the models ,
B: just look at the length of the models and just see what happens .
A: your plan for you you guys ' plan for the next week is just continue on these same things we 've been talking about for aurora and
C: we can try to have some new baseline for next week perhaps . with all these minor things modified . and then do other things , play with the spectral subtraction , and retry the msg and things like that .
A: we have big list . you have big list of things to do . that 's good . that after all of this confusion settles down in another some point little later next year there will be some standard and it 'll get out there and hopefully it 'll have some effect from something that has been done by our group of people even if it doesn't there 's there 's go there 'll be standards after that .
B: does anybody know how to run matlab in batch mode like you send it bunch of commands to run and it gives you the output . is it possible to do that ?
E: and he says it 's impossible so he went to octave . octave is the unix clone of matlab which you can batch .
B: was going crazy trying to do that .
C: what is octave so ? it 's free software ?
E: what 's that ? it 's it 's free . we have it here running somewhere .
C: and it does the same syntax and everything like matlab , or ?
E: it 's little behind , it 's the same syntax but it 's little behind in that matlab went to these like you can have cells and you can implement object - oriented type things with matlab . octave doesn't do that yet , octave is kinda like matlab four point something or .
B: if it 'll do like lot of the basic matrix and vector
E: the basic , right .
B: that 's perfect .
A: we 're done .
","The Berkeley Meeting Recorder Group met to discuss their recent progress.
This included a recap of a meeting with one of the members of their research partner OGI.
There were progress reports from group members working on echo cancellation , acoustic feature detection , and HTK optimization , along with discussion of many issues arising from this topics.
The group must try to communicate more with research partners OGI.
There have been communication problems between the group and their partners at OGI , with both groups waiting for the other to be the one to make contact.
This has made it hard to coordinate efforts.
When looking at articulatory features , the data will be continuous , so may need a mapping to binary decisions.
This could end up as a huge research project by itself , so must be careful.
Mn002 and fe002 are continuing with try to reduce delays and improve the system of the groups main digit recogniser project.
This includes look at filers , and trying to remove noise.
In the coming weeks they have much to try.
Speaker Me018 has also been looking to improve results on the Aurora digit task.
More specifically he is looking at the number of states in the HMMs representing the digits , and is interested in shortening some of them , making them more word specific and hence more accurate.
Speaker Me026 reports his minimal progress on echo cancellation work , in that he is awaiting code along with a better understanding of the original process he is studying.
Me006 is looking to combine previous sonorant detection work with other articulatory feature work.
"
ami_abstractive_summary,Bmr007.txt,"B: we 're , we we didn't have house before .
D: we 're on again ?
A: that is really great .
H: so if so if anyone hasn't signed the consent form , do so .
A: that 's terrific .
H: the new consent form . the new and improved consent form .
A: now you won't be able to walk or ride your bike , ?
H: and , shall go ahead and do some digits ?
D: we were gonna do that at the end ,
H: whatever you want .
D: just just to be consistent , from here on in at least , that we 'll do it at the end .
B: the new consent form .
H: it 's , it doesn't matter .
D: it ju it might be that someone here has to go ,
F: testing , one , two , three .
D: that was that was the point . so , had asked actually anybody who had any ideas for an agenda to send it to me and no one did .
H: so we all forgot .
F: from last time wanted to the an iss one topic from last time .
D: so one item for an agenda is jane has some some research to talk about , research issues . and , adam has some short research issues .
H: and have some short research issues .
D: have list of things that were done over the last three months was supposed to send off , and , sent note about it to to adam and jane but 'll just run through it also and see if someone thinks it 's inaccurate or insufficient .
A: list that you have to send off to who ?
D: to , ibm . so , so , 'll go through that . and , anything else ? anyone wants to talk about ?
A: what about the , your trip , yesterday ?
D: off - topic . cuz that 's cuz that was all about the , chat with you about that off - line . that 's another thing . and , anything else ? there 's , there is , telephone call tomorrow , which will be conference call that some of us are involved in for possible proposal . we 'll talk we 'll talk about it next week if something
H: do you want me to be there for that ? noticed you ' ed me , but wasn't actually recipient . didn't quite to make of that .
D: we 'll talk about that after our meeting . so it sounds like the three main things that we have to talk about are , this list , jane and jane and adam have some research items , and , other than that , anything , as usual , anything goes beyond that . , jane , since you were cut off last time why don't we start with yours , make we get to it .
F: it 's it 's very it 's very brief , just let me just hand these out .
H: is this the same as the email or different ?
F: it 's slightly different . but , same idea . so , if you 've looked at this you 've seen it before , so , as , part of the encoding includes mark that indicates an overlap . it 's not indicated with , , tight precision , it 's just indicated that , so , it 's indicated to so the people parts of sp which stretches of speech were in the clear , versus being overlapped by others . so , used this mark and , and , , divided the wrote script which divides things into individual minutes , of which we ended up with forty five , and little bit . and , , minute zero , , is the first minute up to sixty seconds . and , what you can see is the number of overlaps and then to the right , whether they involve two speakers , three speakers , or more than three speakers . and , and , what was looking for sp specifically was the question of whether they 're distributed evenly throughout or whether they 're bursts of them . and it looked to me as though this is just , this would this is not statistically verified , but it did look to me as though there are bursts throughout , rather than being localized to particular region . the part down there , where there 's the maximum number of , overlaps is an area where we were discussing whether or not it would be useful to indi to to code stress , , sentence stress as possible indication of , information retrieval . so it 's like , , rather , lively discussion there .
D: what was what 's the parenthesized that says , like the first one that says six overlaps and then two point eight ?
F: th that 's the per cent . so , six is , two point eight percent of the total number of overlaps in the session . at the very end , this is when people were , , packing up to go , there 's this final , we don't remember where the digits fell . 'd have to look at that . but the final three there are no overlaps . and couple times there are not . so , it seems like it goes through bursts but , that 's it . now , another question is there are there individual differences in whether you 're likely to be overlapped with or to overlap with others . and , again want to emphasize this is just one particular one particular meeting , and also there 's been no statistical testing of it all , but , took the coding of the , my had this script figure out , who was the first speaker , who was the second speaker involved in two - person overlap , didn't look at the ones involving three or more . and , this is how it breaks down in the individual cells of who tended to be overlapping most often with who else , and if you look at the marginal totals , which is the ones on the right side and across the bottom , you get the totals for an individual . so , if you look at the bottom , those are the , numbers of overlaps in which adam was involved as the person doing the overlapping and if you look 'm , but you 're alphabetical , that 's why 'm choosing you and then if you look across the right , then that 's where he was the person who was the sp first speaker in the pair and got overlap overlapped with by somebody . and , then if you look down in the summary table , then you see that , th they 're differences in whether person got overlapped with or overlapped by .
H: is this just raw counts or is it so it would be interesting to see how much each person spoke .
F: yes , very true very true
H: normalized to how much
F: it would be good to normalize with respect to that . now on the table did take one step toward , away from the raw frequencies by putting , percentages . so that the percentage of time of the times that person spoke , what percentage , so . of the times person spoke and furthermore was involved in two - person overlap , what percentage of the time were they the overlapper and what percent of the time were they th the overlappee ? and there , it looks like you see some differences , that some people tend to be overlapped with more often than they 're overlapped , but , , this is just one meeting , there 's no statistical testing involved , and that would be required for for finding of any scientific reliability .
D: so , it would be statistically incorrect to conclude from this that adam talked too much .
H: no no actually , that would be actually statistically correct ,
F: no , no . that 's right . that 's right . and 'm , 'm don't see point of singling people out ,
D: rather enjoyed it , but this
F: now , this is case where
A: but the numbers speak for themselves .
E: he 's , .
F: , it 's like 'm not saying on the tape who did better or worse
H: yes , that 's right , so you don't nee .
F: because don't think that it 's and th here 's case where , human subjects people would say be that you anonymize the results , and , so , might as do this .
H: when this is what this is actually when jane sent this email first , is what caused me to start thinking about anonymizing the data .
F: and actually , , not about an individual , it 's the point about tendencies toward , different styles , different speaker styles . and it would be , , there 's also the question of what type of overlap was this , and what were they , and and and know that distinguish at least three types and , probably more , the general cultural idea which , the conversation analysts originally started with in the seventies was that we have this strict model where politeness involves that you let the person finish th before you start talking , and , , we know that an and they 've loosened up on that too in the intervening time , that that 's that 's viewed as being culturally - relative thing , that you have the high - involvement style from the east coast where people will overlap often as an indication of interest in what the other person is saying . there you go . fine , that 's alright , that 's . and and , , in contrast , so deborah and also deborah tannen 's thesis she talked about differences of these types , that they 're just different styles , and it 's you can't impose model of there of the ideal being no overlaps , and , conversational analysts also agree with that , so it 's now , universally ag with . and and , als 't say universally , but anyway , the people who used to say it was strict , now , don't . they also , , ack acknowledge the influence of sub of subcultural norms and cross - cultural norms and things . so , then it beco though so just superficially to give couple ideas of the types of overlaps involved , have at the bottom several that noticed . so , , there are backchannels , like what adam just did now and , , anticipating the end of question and simply answering it earlier , and there are several of those in this in these data where because we 're people who 've talked to each other , we the topic is , what the possibilities are and and we 've spoken with each other so we the other person 's style is likely to be and so and there are number of places where someone just answered early . and places also which were interesting , where two or more people gave exactly th the same answer in unison different words but , the , everyone 's saying "" yes "" or , or ev even more sp specific than that . so , , that , overlap 's not necessarily bad thing and that it would be im useful to subdivide these further and see if there are individual differences in styles with respect to the types involved . and that 's all wanted to say on that , unless people have questions .
D: th the biggest , result here , which is one we 've we 've talked about many times and isn't new to us , but which would be interesting to show someone who isn't familiar with this is just the sheer number of overlaps . that that right ? that ,
E: yes , yes !
D: here 's relatively short meeting , it 's forty plus minute meeting , and not only were there two hundred and fifteen overlaps but , there 's one minute there where there where there wasn't any overlap ?
H: hundred ninety - seven .
D: it 's throughout this thing ?
A: it 'd be interesting
D: it 's you have
F: at the bottom , you have the bottom three . so four minutes all together with none .
D: so the bottom three did have going on ? there was speech ?
F: yes , - . but just no overlaps .
D: so if the this
A: it 'd be interesting to see what the total amount of time is in the overlaps , versus
F: yes , exactly and that 's that 's where jose 's pro project comes in .
E: , have this that infor have th that information now .
G: was about to ask
D: about how much is it ?
E: the the duration of of each of the overlaps .
D: what 's what 's the average length ?
E: haven't averaged it now but , will , will do the study of the with the with the program with the , the different , the , nnn , distribution of the duration of the overlaps .
D: you don you don't have feeling for roughly how much it is ?
E: mmm , because the , @ @ is @ @ . the duration is , the variation of the duration is , very big on the dat
F: suspect that it will also differ , depending on the type of overlap involved . so backchannels will be very brief
E: because , on your surface bit of zone of overlapping with the duration , overlapped and another very short . probably it 's very difficult to because the overlap is , on is only the in the final "" "" of the of the fin the end the end word of the , previous speaker with the next word of the new speaker . considered that 's an overlap but it 's very short , it 's an "" "" with and the idea is probably , when , we studied th that zone , , we we have confusion with noise . with that fricative sounds , but have new information but have to study .
G: you split this by minute , so if an overlap straddles the boundary between two minutes , that counts towards both of those minutes .
F: actually , actually not . so le let 's think about the case where starts speaking and then overlaps with , and then the minute boundary happens . and let 's say that after that minute boundary , is still speaking , and overlaps with , that would be new overlap . but otherwise , let 's say comes to the conclusion of that turn without anyone overlapping with him or her , in which case there would be no overlap counted in that second minute .
G: no , but suppose they both talk simultaneously both portion of it is in minute one and another portion of minute two .
F: in that case , my the coding that was using since we haven't , incorporated adam 's , coding of overlap yets , the coding of "" yets "" is not word . since we haven't incorporated adam 's method of handling overl overlaps yet then that would have fallen through the cra cracks . it would be an underestimate of the number of overlaps because , wou wouldn't be able to pick it up from the way it was encoded so far . we just haven't done th the precise second to sec , second to second coding of when they occur .
D: 'm 'm confused now . so let me restate what andreas was saying and see . let 's say that in second fifty - seven of one minute , you start talking and start talking and we ignore each other and keep on talking for six seconds . so we go over so we were we were talking over one another , and it 's just in each case , it 's just one interval . so , we talked over the minute boundary . is this considered as one overlap in each of the minutes , the way you have done this .
F: no , it wouldn't . it would be considered as an overlap in the first one .
D: so that 's good , , in the sense that andreas meant the question ,
B: that 's that 's good , , cuz the overall rate is
F: they 're not double counted .
G: other - otherwise you 'd get double counts , here and there . and then it would be harder
F: should also say did simplifying , count in that if was speaking overlapped with and then came back again and overlapped with again , didn't count that as three - person overlap , counted that as two - person overlap , and it was being overlapped with by . because the idea was the first speaker had the floor and the second person started speaking and then the the first person reasserted the floor thing . these are simplifying assumptions , didn't happen very often , there may be like three overlaps affected that way in the whole thing .
H: want to go back and listen to minute forty - one . cuz find it interesting that there were large number of overlaps and they were all two - speaker . what what would have thought in is that when there were large number of overlaps , it was because everyone was talking at once , but not .
F: that 's interesting . that 's interesting .
H: that 's really neat .
F: there 's lot of backchannel , lot lot of
H: this is really interesting data .
B: what 's really interesting though , it is before saying "" yes , meetings have lot of overlaps "" is to actually find out how many more we have than two - party . cuz in two - party conversations , like switchboard , there 's an awful lot too if you just look at backchannels , if you consider those overlaps ? it 's also ver it 's huge . it 's just that people haven't been looking at that because they 've been doing single - channel processing for speech recognition . so , the question is , , how many more overlaps do you have of , say the two - person type , by adding more people . to meeting , and it may be lot more but it may it may not be .
D: but see , find it interesting even if it wasn't any more , because since we were dealing with this full duplex thing in switchboard where it was just all separated out we just everything was just , so that so the issue is in situation where th that 's
B: it 's not really "" "" . it depends what you 're doing . so if you were actually having , depends what you 're doing , if right now we 're do we have individual mikes on the people in this meeting . so the question is , "" are there really more overlaps happening than there would be in two - person party "" . and and there may be , but
D: let let let me rephrase what 'm saying cuz don't 'm getting it across . what what what shouldn't use words like "" "" because maybe that 's too too imprecise . but what is that , in switchboard , despite the many other problems that we have , one problem that we 're not considering is overlap . and what we 're doing now is , aside from the many other differences in the task , we are considering overlap and one of the reasons that we 're considering it , , one of them not all of them , one of them is that at least , 'm very interested in the scenario in which , both people talking are equally audible , and from single microphone . and so , in that case , it does get mixed in , and it 's pretty hard to jus to just ignore it , to just do processing on one and not on the other .
B: agree that it 's an issue here but it 's also an issue for switchboard and if you think of meetings being recorded over the telephone , which , , this whole point of studying meetings isn't just to have people in room but to also have meetings over different phone lines . maybe far field mike people wouldn't be interested in that but all the dialogue issues still apply , so if each of us was calling and having meeting that way you kn like conference call . and , just the question is , , in switchboard you would think that 's the simplest case of meeting of more than one person , and 'm wondering how much more overlap of the types that jane described happen with more people present . so it may be that having three people is very different from having two people or it may not be .
D: that 's an important question to ask . what 'm all 'm really saying is that don't think we were considering that in switchboard .
B: not you , me .
H: though it wasn't in the design .
D: were you were you were you measuring it ?
B: actually to tell you the truth , the reason why it 's hard to measure is because of so , from the point of view of studying dialogue , , which dan jurafsky and andreas and had some projects on , you want to know the sequence of turns . so what happens is if you 're talking and have backchannel in the middle of your turn , and then you keep going what it looks like in dialogue model is your turn and then my backchannel , even though my backchannel occurred completely inside your turn . so , for things like language modeling or dialogue modeling it 's we know that 's wrong in real time . but , because of the acoustic segmentations that were done and the fact that some of the acoustic data in switchboard were missing , people couldn't study it , but that doesn't mean in the real world that people don't talk that way . so , it 's
D: wasn't saying that . was just saying that now we 're looking at it . and and , you maybe wanted to look at it before but , for these various technical reasons in terms of how the data was you weren't .
B: we 're looking at it here .
D: so that 's why it 's coming to us as new even though it may be , if your if your hypothes the hypothesis you were offering right ? if it 's the null poth hypothesis , and if actually you have as much overlap in two - person , we the answer to that . the reason we the answer to is cuz it wasn't studied and it wasn't studied because it wasn't set up . right ?
B: all is that if you 're asking the question from the point of view of what 's different about meeting , studying meetings of , say , more than two people versus what kinds of questions you could ask with two - person meeting . it 's important to distinguish that , , this project is getting lot of overlap but other projects were too , but we just couldn't study them .
D: may have been . may have been .
B: there is high rate ,
D: we do kn we the numbers .
B: it 's but how high ,
A: here have question .
B: that would be interesting to know .
D: see , , le let me my point was just if you wanted to say to somebody , "" what have we learned about overlaps here ? "" just never mind comparison with something else , what we 've learned about is overlaps in this situation , is that the first the first - order thing would say is that there 's lot of them . in in the sense that if you said if
B: don't di agree with that .
D: in way , what 'm comparing to is more the common sense notion of how much people overlap . the fact that when when , , adam was looking for stretch of speech before , that didn't have any overlaps , and he he was having such hard time and now look at this and go , "" , see why he was having such hard time "" .
B: that 's also true of switchboard .
D: it 's happening lot .
B: it may not be
D: wasn't saying it wasn't .
B: so it 's just ,
D: was commenting about this .
B: all 'm saying is that from the
D: 'm saying if have this complicated thing in front of me , and we sh which , we 're gonna get much more sophisticated about when we get lots more data , but then , if was gonna describe to somebody what did you learn right here , about , , the modest amount of data that was analyzed 'd say , "" , the first - order thing was there was lot of overlaps "" . and it 's not just an overlap bunch of overlaps second - order thing is it 's not just bunch of overlaps in one particular point , but that there 's overlaps , throughout the thing .
B: no , agree with that .
D: and that 's interesting . that 's all .
B: 'm just saying that it may the reason you get overlaps may or may not be due to the number of people in the meeting . and that 's all .
D: wasn't making any statement about that .
B: and and it would actually be interesting to find out because some of the data say switchboard , which isn't exactly the same context , these are two people who each other and , but we should still be able to somehow say what is the added contra contribution to overlap time of each additional person , like that .
D: that would be good to know ,
H: could certainly see it going either way .
F: wh - , agree agree with adam . and the reason is because there 's limit there 's an upper bound on how many you can have , simply from the standpoint of audibility . when we speak we do make judgment of "" can "" , as adults . children don't adjust so , if truck goes rolling past , adults will , depending , but mostly , adults will will hold off to what to finish the end of the sentence till the till the noise is past . and we generally do monitor things like that , about whether we whether our utterance will be in the clear or not . and partly it 's related to rhythmic structure in conversation , so , , you , this is also , people tend to time their their , when they come into the conversation based on the overall rhythmic , , ambient thing . so you don't want to be cross - cutting . and and , just to finish this , that that that there may be an upper bound on how many overlaps you can have , simply from the standpoint of audibility and how loud the other people are who are already in the fray . but , of certain types . now if it 's just backchannels , people may be doing that with less intention of being heard , just spontaneously doing backchannels , in which case that those might there may be no upper bound on those .
G: have feeling that backchannels , which are the vast majority of overlaps in switchboard , , don't play as big role here , because it 's very unnatural , to backchannel if in multi - audience , in multi - person audience .
B: if you can see them , actually . it 's interesting , so if you watch people are going like right right , like this here , but that may not be the case if you couldn't see them .
G: but but , it 's odd if one person 's speaking and everybody 's listening , and it 's unusual to have everybody going "" - , - ""
D: actually , 've done it fair number of times today .
B: there 's lot of head - nodding , in this
H: we need to put trackers on it .
A: in in the two - person
F: he could , he could .
G: so so actually , that 's in part because the nodding , if you have visual contact , the nodding has the same function , but on the phone , in switchboard you that wouldn't work . so so you need to use the backchannel .
H: you don't have it .
A: so , in the two - person conversations , when there 's backchannel , is there great deal of overlap in the speech ?
H: that is an earphone , so if you just put it so it 's on your ear .
A: cuz my impression is sometimes it happens when there 's pause ,
H: there you go .
A: like you get lot of backchannel , when somebody 's pausing
F: she 's doing that .
B: what were you saying ?
A: it 's hard to do both , no , when when there 's backchannel , , just was just listening , and when there 's two people talking and there 's backchannel it seems like , the backchannel happens when , , the pitch drops and the first person and lot of times , the first person actually stops talking and then there 's backchannel and then they start up again , and so 'm wondering about wonder how much overlap there is . is there lot ?
B: there 's lot of the kind that jose was talking about , where , this is called "" precision timing "" in conversation analysis , where they come in overlapping , but at point where the information is mostly complete . so all you 're missing is some last syllables or the last word or some highly predictable words . so technically , it 's an overlap .
A: but maybe just small overlap ?
B: but , from information flow point of view it 's not an overlap in the predictable information .
H: it 'd be interesting if we could do prediction .
A: was just thinking more in terms of alignment , alignment overlap .
H: language model prediction of overlap , that would be really interesting .
B: that 's exactly , exactly why we wanted to study the precise timing of overlaps ins in switchboard , say , because there 's lot of that .
G: so so here 's here 's first interesting labeling task . to distinguish between , say , backchannels precision timing , benevolent overlaps , and and and , , hostile overlaps , where someone is trying to grab the floor from someone else .
H: let 's pick different word .
G: that might be an interesting , problem to look at .
F: you could do that . ju that in this meeting really had the feeling that wasn't happening , that the hostile type . these were these were benevolent types , as people finishing each other 's sentences , and .
G: could imagine that as there 's fair number of cases where , and this is , not really hostile , but competitive , where one person is finishing something and you have , like , two or three people jumping trying to trying to , grab the next turn .
H: trying to get the floor .
G: and so it 's not against the person who talks first because actually we 're all waiting for that person to finish . but they all want to be next .
D: have feeling most of these things are that are not benevolent kind are are , are competitive as opposed to real really hostile .
A: wonder what determines who gets the floor ?
F: there are various things , you have the
D: vote in florida .
H: it 's been studied lot .
D: one thing wanted to or you can tell good joke and then everybody 's laughing and you get chance to break in . the other thing was thinking was that , these all these interesting questions are , , pretty hard to answer with , , small amount of data . so , wonder if what you 're saying suggests that we should make conscious attempt to have , fair number of meetings with , smaller number of people . we most of our meetings are , meetings currently with say five , six , seven , eight people should we really try to have some two - person meetings , or some three - person meetings and re record them just to to beef up the statistics on that ?
F: that 's control . it seems like there are two possibilities there , it seems like if you have just two people it 's not really , like meeting , is not as similar as the rest of the of the sample . it depends on what you 're after , , but it seems like that would be more case of the control condition , compared to , an experimental condition , with more than two .
D: liz was raising the question of whether it 's the number there 's relationship between the number of people and the number of overlaps or type of overlaps there , and , if you had two people meeting in this circumstance then you 'd still have the visuals . you wouldn't have that difference also that you have in the say , in switchboard data .
F: 'm just thinking that 'd be more like control condition .
H: but from the acoustic point of view , it 's all good .
E: is the same .
D: acoustic is fine ,
G: if if the goal were to just look at overlap you would you could serve yourself save yourself lot of time but not even transcri transcribe the words .
B: was thinking you should be able to do this from the acoustics , on the close - talking mikes ,
H: that 's the that was my status report ,
F: you 've been working on that .
B: right , adam was
H: so once we 're done with this discussing ,
B: not as as what , you wouldn't be able to have any typology , , but you 'd get some rough statistics .
D: but what do you think about that ? do you think that would be useful ? 'm just thinking that as an action item of whether we should try to record some two - person meetings .
B: my first comment was , only that we should not attribute overlaps only to meetings , but maybe that 's obvious , maybe everybody knew that , but that in normal conversation with two people there 's an awful lot of the same kinds of overlap , and that it would be interesting to look at whether there are these kinds of constraints that jane mentioned , that what maybe the additional people add to this competition that happens right after turn , because now you can have five people trying to grab the turn , but pretty quickly there 're they back off and you go back to this only one person at time with one person interrupting at time . to answer your question it don't 's crucial to have controls but it 's worth recording all the meetings we can .
G: have an idea .
B: wouldn't not record two - person meeting just because it only has two people .
G: could we could we , we have in the past and continue will continue to have fair number of phone conference calls . and , , and as to , as another comparison condition , we could see what happens in terms of overlap , when you don't have visual contact .
H: we talked about this repeatedly .
B: can we actually record ?
H: it just seems like that 's very different thing than what we 're doing .
D: we 'll have to set up for it .
B: physically can we record the the other
D: we 're not really set up for it to do that .
G: or , this is getting little extravagant , we could put up some blinds to remove , visual contact .
B: that 's what they did on map task , , this map task corpus ? they ran exactly the same pairs of people with and without visual cues and it 's quite interesting .
D: we record this meeting so regularly it wouldn't be that little strange .
H: we can record , but no one can look at each other .
B: we could just put blindfolds on .
H: close your eyes . turn off the lights .
B: and we 'd take picture of everybody sitting here with blindfolds .
D: th that was the other thing , weren't we gonna take picture at the beginning of each of these meetings ?
H: what had thought we were gonna do is just take pictures of the whiteboards . rather than take pictures of the meeting .
F: linguistic anthropologists would suggest it would be useful to also take picture of the meeting .
D: there 's head nodding here vigorously , .
A: why why do we want to have picture of the meeting ?
B: ee - you mean , transc no
F: the because you get then the spatial relationship of the speakers . and that could be
G: you could do that by just noting on the enrollment sheet the seat number .
H: seat number , that 's good idea . 'll do that . 'll do that on the next set of forms .
G: so you 'd number them somehow .
E: is possible to get information from the rhythmic from the ge , , files .
H: finally remembered to put , put native language on the newer forms .
A: we can't you figure it out from the mike number ?
H: the wireless ones . and even the jacks , , 'm sitting here and the jack is over in front of you .
B: but probably from these you could 've infer it .
G: but it 's it would be trivial
H: it would be another task .
B: it would be research task .
H: having having ground tu truth would be , so seat number would be good .
A: where you could get it ? beam - forming during the digit .
H: so 'm gonna put little labels on all the chairs with the seat number . that 's good idea .
B: but you have to keep the chairs in the same pla like here .
G: not the chairs . the chairs are chairs are movable . put them like , put them on the table where they
F: but , they the the linguistic anthropologists would say it would be good to have digital picture anyway ,
A: just remembered joke .
F: because you get sense also of posture . posture , and we could like , , block out the person 's face or whatever
G: what people were wearing .
B: the fashion statement .
F: but , , these are important cues ,
A: how big their heads are .
F: the how person is sitting is
D: but if you just but from one picture , that you really get that .
G: andreas was wearing that same old sweater again .
D: you 'd want video for that , .
F: it 'd be better than nothing , is from single picture you can tell some aspects . could tell you , if if 'm in certain meetings notice that there are certain people who really do the body language is very is very interesting in terms of the dominance aspect .
G: and and morgan had that funny hair again .
F: , you black out the that part . but it 's just , , the body
H: the where we sit at the table , find is very interesting , that we do tend to cong to gravitate to the same place each time . and it 's somewhat coincidental . 'm sitting here so that run into the room if the hardware starts , , catching fire .
G: no , you just like to be in charge , that 's why you 're sitting
H: want to be at the head of the table .
D: speaking of taking control , you said you had some research to talk about .
H: 've been playing with , , using the close - talking mike to do to try to figure out who 's speaking . so my first attempt was just using thresholding and filtering , that we talked about two weeks ago , and so played with that little bit , and it works , except that it 's very sensitive to your choice of your filter width and your threshold . so if you fiddle around with it little bit and you get good numbers you can actually do pretty good job of segmenting when someone 's talking and when they 're not . but if you try to use the same paramenters on another speaker , it doesn't work anymore , even if you normalize it based on the absolute loudness .
B: but does it work for that one speaker throughout the whole meeting ?
H: it does work for the one speaker throughout the whole meeting .
A: how did you do it adam ?
H: how did do it ? what do you mean ?
A: wh what was the
H: the algorithm was , take every frame that 's over the threshold , and then median - filter it , and then look for runs . so there was minimum run length ,
A: every frame that 's over what threshold ?
H: threshold that you pick .
A: in terms of energy ?
F: say that again ? frame over fres threshold .
H: so you take each frame , and you compute the energy and if it 's over the threshold you set it to one , and if it 's under the threshold you set it to zero , so now you have bit stream of zeros and ones . and then median - filtered that using , fairly long filter length . actually depends on what you mean by long , , tenth of second sorts of numbers . and that 's to average out , pitch , , the pitch contours , and things like that . and then , looked for long runs . and that works , if you fil if you tune the filter parameters , if you tune how long your median filter is and how high you 're looking for your thresholds .
A: did you ever try running the filter before you pick threshold ?
H: certainly could though . but this was just had the program mostly written already so it was easy to do . and then the other thing did , was took javier 's speaker - change detector acoustic - change detector , and implemented that with the close - talking mikes , and unfortunately that 's not working real , and it looks like it 's the problem is he does it in two passes , the first pass is to find candidate places to do break . and he does that using neural net doing broad phone classification and he has the , one of the phone classes is silence . and so the possible breaks are where silence starts and ends . and then he has second pass which is modeling gaussian mixture model . looking for whether it improves or degrades to split at one of those particular places . and what looks like it 's happening is that the even on the close - talking mike the broad phone class classifier 's doing really bad job .
A: who was it trained on ?
H: have no idea . does an do you remember , morgan , was it broadcast news ? so , at any rate , my next attempt , which 'm in the midst of and haven't quite finished yet was actually using the , thresholding as the way of generating the candidates . because one of the things that definitely happens is if you put the threshold low you get lots of breaks . all of which are definitely acoustic events . they 're definitely someone talking . but , like , it could be someone who isn't the person here , but the person over there or it can be the person breathing . and then feeding that into the acoustic change detector . and so that might work . but , haven't gotten very far on that . but all of this is close - talking mike , it 's , just trying to get some ground truth .
E: but , when , saw the the speech from pda and , close talker . the there is great difference in the in the signal . but that in the mixed file you can find , zone with , great different , level of energy .
H: so my intention for this is as an aide for ground truth .
E: for , algorithm based on energy , , that mmm , more or less , , like , mmm , first sound energy detector .
H: say it again ?
E: when you the detect the the first at the end of the detector of , ehm princ . what is the name in english ? the , mmm , the de detector of , ehm of word in the in the in an isolated word in the background that ,
H: 'm 'm not what you 're saying ,
E: that when you use , any
A: he 's saying the onset detector .
H: onset detector , .
E: it 's probably to work , because , you have , in the mixed files great level of energy . and great difference between the sp speaker . and probably is not so easy when you use the pda , that because the signal is , the in the energy level . in that , speech file is , more similar . between the different , speaker , is , it will is my opinion .
H: but different speakers .
E: it will be , more difficult to detect bass - tone energy .
H: in the clo in the , you mean ?
E: in the pda .
H: it 'll be much harder .
E: and the another question , that when review the the work of javier . the , nnn , the , nnn , that the idea of using neural network to get broad class of phonetic , from , candidate from the the speech signal . if you have , , 'm considering , only because javier , only consider , like candidate , the , nnn , the silence , because it is the only model , , he used that , nnn , to detect the possibility of change between the between the speaker , another research thing , different groups , working , on broadcast news prefer to , to consider hypothesis between each phoneme .
H: when phone changes .
E: because , it 's more realistic that , only consider the the silence between the speaker . there exists silence between , speaker . is , acoustic , event , important to consider . found that the , silence in many occasions in the in the speech file , but , when you have , , two speakers together without enough silence between them , is better to use the acoustic change detector and ix or , mmm , bic criterion for consider all the frames in my opinion .
D: the , the reason that he , just used silence was not because he thought it was better , it was it was the place he was starting . so , he was trying to get something going , and , , as as is in your case , if you 're here for only modest number of months you try to pick realistic goal , but his goal was always to proceed from there to then allow broad category change also .
E: but , do you think that if you consider all the frames to apply the , the bic criterion to detect the the different acoustic change , between speaker , without , with , silence or with overlapping , like , general , way of process the acoustic change . in first step , . an - and then , without considering the you you , you can consider the energy like another parameter in the in the feature vector , this this is the idea . and if , if you do that , , with bic criterion , or with another , of distance in first step , and then you , you get the , the hypothesis to the this change acoustic , to po process because , , probably you can find the small gap of silence between speaker with ga mmm , small duration less than , two hundred milliseconds and apply another algorithm , another approach like , detector of ene , detector of bass - tone energy to consider that , zone . of small silence between speaker , or another algorithm to process , the segment between marks founded by the the bic criterion and applied for each frame . is , nnn , it will be an more general approach the if we compare with use , neural net or another , speech recognizer with broad class or narrow class , because , in my opinion it 's in my opinion , if you if you change the condition of the speech , , if you adjust to your algorithm with mixed speech file and to , to , adapt the neural net , used by javier with mixed file . with mixed file ,
H: with the what file ?
A: "" mixed "" .
E: with the mix , mix .
F: "" mixed . ""
H: "" mixed ? ""
E: and and then you , you try to apply that , , , speech recognizer to that signal , to the pda , speech file , you will have problems , because the condition you will need suppose that you will need to to retrain it .
H: this is this is not what was suggesting to do .
D: look , this is one once it 's used to work , like , on voiced on voice silence detection , , and this is this thing . if you have somebody who has some experience with this thing , and they work on it for couple months , they can come up with something that gets most of the cases fairly easily . then you say , "" , don't just wanna get most of the cases want it to be really accurate . "" then it gets really hard no matter what you do . so , the the problem is that if you say , "" have these other data over here , that learn things from , either explicit training of neural nets or of gaussian mixture models or whatever . "" suppose you don't use any of those things . you say you have looked for acoustic change . what does that mean ? that that means you set some thresholds somewhere , and so where do you get your thresholds from ? from something that you looked at . so you always have this problem , you 're going to new data how are you going to adapt whatever you can very quickly learn about the new data ? , if it 's gonna be different from old data that you have ? and that 's problem with this .
H: also what 'm doing right now is not intended to be an acoustic change detector for far - field mikes . what 'm doing is trying to use the close - talking mike and just use can - and just generate candidate and just try to get first pass at something that works .
A: you have candidates . to make marking easier .
H: and haven't spent lot of time on it and 'm not intending to spend lot of time on it .
G: , unfortunately , have to run , but , imagine building model of speaker change detection that takes into account both the far - field and the actually , not just the close - talking mike for that speaker , but actually for all of th for all of the speakers . if you model the effect that me speaking has on your microphone and everybody else 's microphone , as as on that , and you build , you 'd you would build an that has as state space all of the possible speaker combinations and , you can control
H: it 's little big .
G: it 's not that big actually ,
H: two to the . two to the number of people in the meeting .
D: but actually , andreas may maybe just something simpler but along the lines of what you 're saying , was just realizing , used to know this guy who used to build , , mike mixers automatic mike mixers where , , in order to able to turn up the gain , , as much as you can , you you lower the gain on the mikes of people who aren't talking , and then he had some reasonable way of doing that , but , what if you were just looking at very simple measures like energy measures but you don't just compare it to some threshold overall but you compare it to the energy in the other microphones .
H: was thinking about doing that originally to find out who 's the loudest , and that person is certainly talking . but also wanted to find threshold , excuse me , mol overlap . so , not just the loudest .
E: have found that when analyzed the speech files from the , mike , from the close microphone , found zones with different level of energy .
G: have to go .
H: could you fill that out anyway ? just , put your name in . are you want me to do it ? 'll do it .
A: but he 's not gonna even read that .
E: including overlap zone . because , depend on the position of the of the microph of the each speaker to , , to get more or less energy in the mixed sign in the signal . and then , if you consider energy to detect overlapping in , , and you process the in the speech file from the the mixed signals . the mixed signals , . it 's it 's difficult , only to en with energy to consider that in that zone we have , overlapping zone , if you process only the energy of the , of each frame .
D: it 's probably harder , but what was nnn noting just when he when andreas raised that , was that there 's other information to be gained from looking of the microphones and you may not need to look at very sophisticated things , because if there 's if most of the overlaps , this doesn't cover , say , three , but if most of the overlaps , say , are two , if the distribution looks like there 's couple high ones and the rest of them are low ,
H: and everyone else is low , .
D: there 's some information there about their distribution even with very simple measures . , had an idea with while was watching chuck nodding at lot of these things , is that we can all wear little bells on our heads , so that then you 'd know that
H: ding , ding , ding .
F: "" ding "" . that 's cute !
B: that 'd be really interesting too , with blindfolds .
H: nodding with blindfolds ,
B: the question is , like whether
H: "" what are you nodding about ? ""
B: trying with and with and without , .
H: "" , 'm just 'm just going to sleep . ""
B: but then there 's just one @ @ , like .
A: actually , saw woman at the bus stop the other day who , , was talking on her cell phone speaking japanese , and was bowing .
B: , that 's really common . it 's very difficult if you try while you 're trying , say , to convince somebody on the phone it 's difficult not to move your hands . not , if you watch people they 'll actually do these things . still think we should try meeting or two with the blindfolds , at least of this meeting that we have lots of recordings of maybe for part of the meeting , we don't have to do it the whole meeting .
D: it 's great idea .
B: that could be fun . it 'll be too hard to make barriers , was thinking because they have to go all the way see chuck even if you put barrier here .
H: we could just turn out the lights .
F: actually also say made barr barriers for so that the was doing with collin wha which just used , this foam board . you can you can masking tape it together , these are , pretty large partitions .
B: but then we also have these mikes , is the other thing was thinking , so we need barrier that doesn't disturb the sound ,
F: it 's true , it would disturb the , the long - range
D: blindfolds would be good .
B: it sounds weird but it 's it 's cheap and , be interesting to have the camera going .
D: probably we should until after adam 's set up the mikes ,
F: we 're going to have to work on the , on the human subjects form .
A: 'll be peeking .
H: that 's right , we didn't tell them we would be blindfolding .
F: "" do you mind being blindfolded while you 're interviewed ? ""
D: that 's that 's the one that we videotape . wanna move this along . did have this other agenda item which is , @ @ it 's list which sent to couple folks , but wanted to get broader input on it , so this is the things that we did in the last three months not everything we did but highlights that tell some outside person , , what were you actually working on . in no particular order , one , , ten more hours of meeting meetings recorded , something like that , from , three months ago . xml formats and other transcription aspects sorted out and sent to ibm . pilot data put together and sent to ibm for transcription , next batch of recorded data put together on the cd - roms for shipment to ibm ,
H: hasn't been sent yet , but it 's getting ready .
D: but , that 's why phrased it that way , . human subjects approval on campus , and release forms worked out so the meeting participants have chance to request audio pixelization of selected parts of the spee their speech . audio pixelization software written and tested . preliminary analysis of overlaps in the pilot data we have transcribed , and exploratory analysis of long - distance inferences for topic coherence , that was was wasn't if those were the right way that was the right way to describe that because of that little exercise that you and lokendra did .
F: what was that called ?
D: 'm probably saying this wrong , but what said was exploratory analysis of long - distance inferences for topic coherence .
F: the , say again ?
D: something like that . so , lot of that was from , , what what you two were doing so sent it to you , and , mail me , , the corrections or suggestions for changing don't want to make this twice it 's length but , just im improve it . is there anything anybody
H: did bunch of for supporting of digits .
D: "" bunch of for "" maybe send me sentence that 's little thought through about that .
H: so , , 'll send you sentence that doesn't just say "" bunch of "" ?
D: "" bunch of "" , , "" "" is probably bad too ,
H: "" "" is not very technical . 'll try to phrase it in passive voice .
D: "" range of things "" , . and , threw in what you did with what jane did on in under the , preliminary analysis of overlaps . thilo , can you tell us about all the work you 've done on this project in the last , last three months ?
C: so what is what .
A: it 's too complicated .
C: didn't get it . wh - what is "" audio pixelization "" ?
D: audio pix wh he did it , so why don't you explain it quickly ?
H: it 's just , beeping out parts that you don't want included in the meeting so , you can say things like , "" , this should probably not be on the record , but beep ""
D: we we spent fair amount of time early on just talk dealing with this issue about op we realized , "" , people are speaking in an impromptu way and they might say something that would embarrass them or others later "" , and , how do you get around that so in the consent form it says , you we will look at the transcripts later and if there 's something that you 're unhappy with , .
C: and you can say
D: but you don't want to just excise it you have to be careful about excising it , how you excise it keeping the timing right and so that at the moment tho th the idea we 're running with is putting the beep over it .
H: you can either beep or it can be silence . couldn't decide . which was the right way to do it . beep is good auditorily , if someone is listening to it , there 's no mistake that it 's been beeped out , but for software it 's probably better for it to be silence .
A: no , no . you can , you could make as long as you keep using the same beep , people could make model of that beep ,
F: like that idea .
H: and use it 's , it 's an below middle beep ,
B: the beep is really good idea .
F: it 's very clear . then you don't 's long pause .
A: it 's more obvious that there was something there than if there 's just silence .
D: that , he 's he 's removing the old thing
A: yea - right . but if you just replaced it with silence , it 's not clear whether that 's really silence or
F: one one question . do you do it on all channels ?
H: you have to do it on all channels because it 's , audible . it 's it 's potentially audible , you could potentially recover it .
D: ke - keep back door .
F: the other thing that , the alternative might be to
H: haven't thrown away any of the meetings that beeped . actually yours is the only one that beeped and then , the ar darpa meeting .
B: notice how quiet am .
H: and then the darpa meeting excised completely , so it 's in private directory .
B: you have some people who only have beeps as their speech in these meetings .
F: that 's great .
A: they 're easy to find , then .
D: alright , so , we should , , go on to the digits ?
F: have one concept want to say , which is that it 's that you 're preserving the time relations , so you 're you 're not just cutting you 're not doing scissor snips . you 're you 're keeping the , the time duration of de - deleted part . good , digits .
H: since we wanna possibly synchronize these things as . should have done that .
F: it 's great .
B: so if there 's an overlap , like , if 'm saying something that 's bleepable and somebody else overlaps during it they also get bleeped , too ?
H: you 'll lose it . there 's no way around that .
D: did before we do the digits , did also wanna remind people , do send me , , thoughts for an agenda , that would be that 'd be good . so that , , people 's ideas don't get
H: thursday crept up on me this week .
D: it does creep up ,
B: and , wanted to say , this is really interesting analysis .
H: it 's , definitely .
B: to say that before started off on the switchboard .
H: was gonna say "" can you do that for the other meetings ,
B: it 's neat .
H: can you do it for them ? "" and , no actually , you can't .
A: actually actually that 's what you were giving us was another meeting and was like , "" , ! ""
H: "" ooo , ! ""
B: how long does it take , just briefly , like to . to label the ,
F: have the script now , so , , it can work off the , other thing ,
H: it 's as soon as we get labels , .
A: but it has to be hand - labeled first ?
F: because , , once his algorithm is up and running then we can do it that way .
H: if it works enough . right now it 's not . not quite to the point where it works .
F: but worked off of my
B: it 's really neat .
F: what what this has , , caused me so this discussion caused me to wanna subdivide these further . 'm gonna take look at the , backchannels , how much we have anal hope to have that for next time .
A: that 'd be interesting .
H: my algorithm worked great actually on these , but when you wear it like that or with the , lapel or if you have it very far from your face , that 's when it starts failing .
B: wear it , if you
H: it doesn't matter . we want it to work ,
A: it 's too late now .
H: don't want to change the way we do the meeting .
B: feel like this troublemaker .
H: it 's so , it was just comment on the software , not comment on prescriptions on how you wear microphones .
D: that 's let 's let 's do digits .
H: get the bolts , "" whh ""
F: let 's do it . do you want us to put mark on the bottom of these when they 've actually been read , or the only one that wasn't read is is known , so we don't do it .
","The Berkeley Meeting Recorder group focussed its discussion on overlapping speech segments.
Speaker fe008 presented raw counts and percentages for one transcribed meeting , revealing a large number of overlaps throughout the 40-plus-minute transcript.
Efforts by speakers fe008 and fe016 are in progress to categorize and subcategorize types of overlapping speech and evaluate the contribution of multiple speakers in an interaction to the amount and types of overlap observed.
Speaker me011 described his attempts to automatically identify speakers via the close-talking microphone channels using thresholding and filtering methods and an existing speaker-change detection algorithm.
The group also tentatively discussed the erection of visual barriers during meeting recordings , and speaker me013 presented a list of work performed by BMR over the previous three months to be included in a forthcoming report to IBM.
For future meetings , speaker me011 will generate a system for mapping speakers and their positions in the recording room.
Speaker fe008 will analyze backchannels for a subset of meeting data and givee a report in the next meeting.
For language and dialogue modelling , current methods of marking and segmenting overlap are abstracted from real time , as individual speaker turns are indicated sequentially.
A large amount of data must be collected to address research questions concerning overlapping speech.
For automatic speaker identification , thresholding and filtering methods are sensitive regarding the particular filter width and threshold selected.
While such parameters can be finely tuned for one speaker to achieve good results , extending the same parameters to another speaker is problematic.
The broad phone classifier of the speaker-change detector is peforming poorly.
The prospect of erecting visual barriers during meetings would require partitioning off each of the participants.
Also , barriers that do not affect the overall room acoustics would be required.
Efforts are in progress to mark where regions of speaker overlap occur in meeting transcripts and note the number of speakers involved.
Such information is currently being encoded within relatively loose time boundaries.
A large number of overlapping speech regions were identified throughout one recorded meeting , wherein overlaps were found to occur in bursts , rather than being evenly distributed throughout the meeting.
A cursory analysis was done on regions of overlap involving two speakers to determine whether speakers are more likely to be overlapped with or to cause overlap with other speakers.
Attempts were also made to classify types of speaker overlap---e.g . backchannels , answering questions as they are being asked , and responding in unison---with future work focussed on subcategorizing types of backchannels.
Speaker fe016 is interested in the contribution of multiple speakers in an interaction to the amount and types of overlap observed , and comparing this to findings from the Switchboard corpus.
Future work includes generating predictive models of overlap , and the tentative erection of visual barriers during meeting recordings.
Speaker me011 described his attempts to automatically identify speakers via the close-talking microphone channels using thresholding and filtering methods and an existing speaker-change detection algorithm.
"
ami_abstractive_summary,Bed008.txt,"A: alright , so 'm - should read all of these numbers ?
E: piece of paper ? could borrow ?
B: whether ami 's coming or not but we oughta just get started .
E: nancy is currently in berkeley but not here ?
C: nancy 's still stick ?
B: so there you go . anyway , so my idea for today and we can decide that isn't the right thing to do was to at spend at least part of the time trying to build the influence links , which sets of things are relevant to which decisions and actually had specific suggestion to start first with the path ones . the database ones being in some sense less interesting to us although probably have to be done and so to do that so there 's and the idea was we were gonna do two things
C: is your mike on ?
B: we were gonna do two things one of which is just lay out the influence structure of what we nfluences what
D: that 's funny .
B: and then as separate but related task particularly bhaskara and were going to try to decide what kinds of belief nodes are needed in order to do what we what we need to do . so but du we should have all of the basic design of what influences what done before we decide exactly how to compute it . so didn't did you get chance to look yet ?
D: looked at some of that .
B: so let 's start with the belief - nets , the general influence and then we 'll then we 'll also at some point break and talk about the techy .
E: one could go there 's we can di discuss everything . first of all this added , knew from this has to be there
B: are you gonna go there or not ?
E: given given not transverse the castle , the decision is does the person want to go there or is it just
B: does have to be there . and 'm we 'll find more as we go that
E: so go - there in the first place or not is definitely one of the basic ones . we can start with that . is this true or false or maybe we 'll get
A: "" go there "" .
B: so there is this question about
E: we actually get just probabilities , for each down here .
B: when we 're when we 're done . the reason it might not be true or false is that we did have this idea of when so it 's , current @ @ and and so on or not , and so that decision would be do we want that so you could two different things you could do , you could have all those values for go - there or you could have go - there be binary and given that you 're going there when . we 'll see .
A: it seems that you could it seems that those things would be logically independent like you would wanna have them separate or binary , go - there and then the possibilities of how to go there
B: that 's let 's start that way .
A: because , it might be easy to figure out that this person is going to need more film eventually from their utterance but it 's much more complex to query when would be the most appropriate time .
E: and so 've tried to come up with some initial things one could observe so who is the user ? everything that has user comes from the user model everything that has situation comes from the situation model - . we should be clear . but when it comes to writing down when you when you do these things is it here ? you have to write the values this can take . and here was really in some sometimes was really standing in front of wall feeling very stupid because this case it 's pretty simple , but as we will see the other ones if it 's running budget so what are the discrete values of running budget ? so maybe my understanding there is too impoverished . how can write here that this is something , number that cr keeps on changing ? thus is understandable ?
B: you 've have you seen this before keith , these belief - net things ?
A: but 'm following it .
E: so here is the we had that the user 's budget may influence the outcome of decisions . there we wanted to keep running total of things .
D: is this like number that represents how much money they have left to spend ? how is it different from user finance ?
E: the finance is here thought of as the financial policy person carries out in his life , he is he cheap , average , or spendy ? didn't want to write greediness ,
B: thrift , that 's good .
E: there it is .
B: so keith what 's behind this is actually program that will once you fill all this in actually solve your belief - nets for you and . so this is not just display , this is actually gui to simulator that will if we tell it all the right things we 'll wind up with functioning belief - net at the other end .
E: and it 's so simple even use it .
A: that is simple .
E: think of people being cheap , average , or spendy or we can even have finer scale moderately cheap , but here wasn't what to write in .
D: you 've written in you 've written in what seems to be required like what else is do you want ?
E: if that 's permissible then 'm happy .
B: so here 's here 's what 's permissible is that you can arrange so that the the value of that is gonna have to be updated and it 's not belief update , it 's you took some actions , you spent money and , so the update of that is gonna have to be essentially external to the belief - net . and then what you 're going to need is for the things that it influences . let 's first of all let 's see if it does influence anything . and if it does influence anything then you 're gonna need something that converts from the number here to something that 's relevant to the decision there . so it could be ra they create different ranges that are relevant for different decisions or whatever but for the moment this is just node that is conditioned externally and might influence various things .
E: let 's forget it .
B: that 's fine . anyway , go ahead .
E: and so this , that
D: the other thing is that every time that 's updated beliefs will have to be propagated but then the question is do you do we wanna propagate beliefs every single time it 's updated or only when we need to ?
B: that 's good question . and does it have lazy mode ?
D: , in srini 's thing there was this thing there was this option like proper inferences which suggests that doesn't happen , automatically .
B: someone has to track that down , one of the we items for the user home base should be essentially non - local . they 're only there for the day and they don't have place that they 're staying .
E: just accidentally erased this , had values here such as is he we had in our list we had "" is he staying in our hotel ? "" , "" is he staying with friends ? "" ,
B: it 's clear where where we are right now . so my suggestion is we just pick
E: something down here ?
B: one , one particular one of the let 's do the first one let 's do the one that we already think we did so that was the of the endpoint ?
D: so it 's true or false ?
B: no , that 's that 's
E: missed that one .
C: what 's the difference between mode and endpoint ?
D: mode of transportation ? also true or false .
B: no , he has he hasn't filled them in yet , is what 's true .
E: did or didn't ? probably nothing done yet , did it on the upper ones , . so this was eva . maybe we can think of more things ,
A: climb , rob .
B: these are ju that 's just point ,
D: some of those are subsumed by approach .
C: would it be an endpoint if you were crossing over it ?
A: the charles bridge , .
B: would be for given segment . you you go first go the town square
A: no , , if you go to re if you go to prague or whatever one of your key points that you have to do is cross the charles bridge and doesn't really matter which way you cross which where you end up at the end but the part the good part is walking over it ,
B: that 's subtle , but true . so let 's just leave it three with three for now and let 's see if we can get it linked up just to get ourselves started . you 'll see it you 'll see something comes up immediately , that the reason wanna do this .
E: the user was definitely more likely to enter if he 's local more likely to view if he 's tourist and then we had the fact that given the fact that he 's thrifty and there will be admission then we get all these cross
B: we did , but the three things that it contributed to this the other two aren't up there . so one was the ontology
E: we 'll what type of building is it ?
B: and the and the third thing we talked about was something from the discourse .
E: what he has mentioned before .
B: right , so what what we seem to need here , this is why it starts getting into the technical the way we had been designing this , there were three intermediate nodes which were the endpoint decision as seen from the user model as seen from the ontology and as seen from the discourse . so each of those the way we had it designed , now we can change the design , but the design we had was there was decision with the same three outcomes based on the th those three separate considerations so if we wanted to do that would have to put in three intermediate nodes
E: we can load it up it very simple .
B: and then what you and have to talk about is , if we 're doing that and they get combined somehow how do they get combined ? but the they 're undoubtedly gonna be more things to worry about .
E: so this was adjusted for this one mode thing . so that 's in our in johno 's pictogram everything that could contribute to whether person wants to enter , view , or approach something .
B: it was called mode , so this is mode here means the same as endpoint .
E: is now this endpoint .
B: why don't we ch can we change that ?
E: we can just rename that , .
B: but that was actually , unfortunately that was an intermediate versio that 's don't think what we would currently do .
A: can ask about "" slurred "" and "" angry "" as inputs to this ?
D: like they 're either true or false
C: if the if the person talking is angry or slurs their speech they might be tired or , and , , possibly
A: less likely to enter .
D: was thinking less likely to view
B: but that 's - that seems to , so so my advice to do is get this down to what we actually likely to be strong influence . but , that was what he had in mind . so let 's think about this question of how do we wanna handle so there 're two separate things . at least two . one is how do we want to handle the notion of the ontology now what we talked about , and this is another technical thing bhaskara , is can we arrange so that so that the belief - net itself has properties and the properties are filled in from on ontology items . so the let 's take the case of the this endpoint thing , the notion was that if you had few key properties like is this tourist site , some landmark is it place of business is it something you physically could enter so that there 'd be certain properties that would fit into the decision node and then again as part of the ou outer controlling conditioning of this thing those would be set , so that some somehow someone would find this word , look it up in the ontology , pull out these properties , put it into the belief - net , and then the decision would flow .
E: seems to me that we 've embedded lot , embedded lot of these things we had in there previously in in some of the other final decisions done here , if we would know that this thing is exhibiting something if it 's exhibiting itself it is landmark , meaning more likely to be viewed if it is exhibiting pictures or sculptures and like this , then it 's more likely to be entered .
B: that 's that 's completely right and that 's good , so what that says is that we might be able to take and so the ones we talked about were exhibiting and selling no , accessibility meant
E: if it 's closed one probably won't enter . or if it 's not accessible to tourist ever the likelihood of that person actually wanting to enter it , given that he knows it , .
B: so let me suggest this . could you move those up about halfway . the ones that you th and selling .
E: if it 's fixing things selling things , or servicing things
B: so here 's what it looks like to me . is that you want an intermediate structure which is essentially the or of for this purpose of selling , fixing , or servicing . that is , for certain purposes , it becomes important but for this purpose one of these places is quite like the other . does that seem right ?
C: you 're just merging those for just the sake of endpoint decision ?
B: so if it may be more than endpoint decisions , so the idea would be that you might wanna merge those three ser selling , fixing , and servicing .
D: what ex and so either those is true or false ?
B: it here 's where it gets little tricky . from the belief - net point of view it is from another point of view it 's interest it 's it 's important to it 's selling or servicing and . so for this decision it 's just true or false and in th this is case where the or seems just what you want . that that if any of those things is true then it 's the place that you
E: more likely to enter .
B: are more likely to enter .
D: so you just wanna have them all pointing to summary thing ?
B: you could , . so let 's do that . no no , no to an inter no , an intermediate node . that 's the part of the idea , is
E: is that the object type node ? so are they the is it the object that sells , fixes , or services things ?
B: open up object type and let 's see what its values are .
E: created it , it has none so far .
B: first of all it 's not objects , we called them entities ,
E: and then we have the
B: let 's say put commercial .
E: commercial action inside where people
B: couldn't do let 's do commercial
E: and where was the accessible , .
B: cuz that 's tempor that varies temporally ,
C: what would hotel fall under ?
B: would call that service ,
C: in terms of entity type ?
B: say it 's co would again for this purpose it 's commercial . someplace you want to go in to do some business .
D: what does the underscore - at the end of each of those things signify ?
E: so places that service things sell things or fix things and pe places that exhibit things .
D: that also points to entity type .
A: so we 're deriving this the this feature of whether the main action at this place happens inside or outside or what we 're deriving that from what activity is done there ? couldn't you have it as just primitive feature of the entity ?
B: that 's that 's choice .
A: it seems like that 's much more reliable cuz you could have outdoor places that sell things and indoor places that do something else
B: the problem with it is that it putting in feature just for one decision , now we may wind up having to do that this anyway , this at mental level that 's what we 're gonna have to sort out . so , what does this look like , what are what are intermediate things that are worth computing , what are the features we need in order to make all these decisions and what 's the best way to organize this so that it 's clean and consistent and all that .
A: 'm just thinking about how people , human beings who know about places and places to go and so on would store this and it would probably you wouldn't just remember that they sell and then deduce from that it must be going on inside .
E: an entity maybe should be regard as vector of several possible things , it can either do do sell things , fix things , service things , exhibit things , it can be landmark at the same time as doing these things , it 's not either or mmm certainly place can be hotel and famous site . many come to mind . things can be generally landmark and be accessible . or can be landmark or not accessible , some statue can go inside .
B: anyway so let me suggest you do something else . which is to get rid get rid of that long link between who the user and the endpoint .
E: could we just move it like this ?
B: no no , don't want the link there . because what we 're gonna want is an intermediate thing which is the endpoint decisi the endpoint decision based on the user models , so what we what we talked about is three separate endpoint decisions , so let 's make new node
C: just as suggestion maybe you could "" save as "" to keep your old one and clean and so you can mess with this one .
E: the old one was not that important ,
C: , not big deal then .
E: let 's do it then .
C: isn't there "" save as "" inside of java base ?
E: but just take this copy it somewhere else . this was user something
B: let 's put it this let 's do endpoint underbar - . endpoint , end poi it 's the endpoint let 's say underbar - , so that 's the endpoint decision as seen through the
C: as related from the user model .
B: so let 's let 's actually so lin you can link that up to the
E: should rename this too ?
B: so that , that 's endpoint
E: it 's underscore - .
B: underscore - for entity , and we may change all this ,
E: shouldn't be able to move them all ?
B: actually , the easiest thing would move mo move the endpoint , just do whatever .
E: wasn't this possible ?
C: you have to be in move mode before
E: so now we 're looking for user related things that
B: and maybe th maybe it 's just one who is the user , maybe there 's more .
E: if he 's usi if he 's in car right now people with harry drove the car into the cafe
B: anyway , this is crude . now but the now so but then the question is so and we assume that some of these properties would come indirectly through an ontology , but then we had this third idea of input from the discourse .
E: let 's should we finish this , but surely the user interests
C: the user thrift , the user budget .
B: but what we 're gonna wanna do is actually
E: here this was one of my problems we have the user interest is is vector of five hundred values , that 's from the user model ,
D: you mean level of interest ?
E: no not levels of interest but things you can be interested in .
B: somebody else has built this user model .
E: gothic churches versus baroque townhouses versus
D: so why is it it , so it 's like vector of five hundred one 's or zero 's ?
E: yea - is that
D: like for each thing are we are you interested in it or not ?
B: so you cou and so here let me give you two ways to handle that . one is you could ignore it . but the other thing you could do is have an and this will give you the flavor of the of what you could have node that 's that was measure of the match between the object 's feature , , the match between the object the entity , 'm and the user . so you could have "" fit "" node that would have to be computed by someone else
E: just as mental note
B: that 's all .
E: and and should we say that this interests affects the likelihood of entering ? and also if it 's an expensive place to enter , this may also
A: "" do have time to go in and climb all the way to the top of the koelner dome or do have to "" "" time to take picture of the outside ? ""
C: it seems like everything in user model affects
B: that 's what we don't wanna do , cuz then we get into huge combinatorics and like that
C: cuz if the , , and if the user is tired , the user state , it would affect , but 't see why anything everything in the model wouldn't be
B: that 's we can't do that , so we 're gonna have to but this is good discussion , we 're gonna have to somehow figure out some way to encapsulate that so if there 's some general notion of the relation to the time to do this to the amount of time the guy has like that is the compatibility with his current state , so that 's what you 'd have to do , you 'd have to get it down to something which was itself relatively compact , so it could be compatibility with his current state which would include his money and his time and his energy
C: just seems like it 'd push the problem back level .
D: no but , it 's more than that , like the more you break it up like because if you have everything pointing to one node it 's like exponential whereas if you like keep breaking it up more and more it 's not exponential anymore .
B: so it , there are two advantages . that 's tha there 's one technical one and the other is it gets used
C: so we 'd be doing subgrouping ? so make it more tree like going backwards ?
B: but it there 's two advantages , one is the technical one that you don't wind up with such big exponential cbt 's , the other is it can be it presumably can be used for multiple decisions . so that if you have this idea of the compatibility with the requirements of an action to the state of the user one could imagine that was not only is it sim is it cleaner to compute it separately but it could be that it 's used in multiple places . anyway th so in general this is the design , this is really design problem . you 've got signal , set of decisions how do we do this ?
E: what do have under user state anyhow cuz named that already something . that 's tired , fresh , maybe should be renamed into physical state .
B: or fat user fatigue even .
E: that 's with "" "" ? then we can make user state .
B: what 's th what we 're talking about is compatibility .
C: it 's hard for me to imagine how everything wouldn't just contribute to user state again . or user compatibility .
B: but that we we had some things that
E: the user interests and the user who who the user is are completely apart from the fact whether he is tired broke
C: but other though the node we 're creating right now is user compatibility to the current action , seems like everything in the user model would contribute to whether or not the user was compatible with something .
B: the that 's the issue is would even if it was true in some abstract general sense it might not be true in terms of the information we actually had and can make use of . and anyway we 're gonna have to find some way to cl get this sufficiently simple to make it feasible .
E: maybe if we look at the if we split it up again into if we look at the the endpoint again we said that for each of these things there are certain preconditions so you can only enter place if you are not too tired to do so and also have the money to do so if it costs something so if you can afford it and perform it is preconditions . viewing usually is cheap or free . is that always true ?
C: with the way we 're defining it .
B: but that viewing it without ent view with our definition of view it 's free
E: and so is approaching .
A: what about the grand canyon , no , never mind . are there are there large things that you would have to pay to get up close to not in the current
B: no we have to enter the park . almost by definition paying involves entering , ge going through some so let me suggest we switch to another one , clearly there 's more work to be done on this but it 's gonna be more instructive to think about other decisions that we need to make in path land . and what they 're gonna look like .
C: so you can save this one as and open up the old one , and then everything would be clean . you could do it again .
B: why , it 's worth saving this one but 'd 'd like to keep this one cuz wanna see if we 're gonna reuse any of this .
E: so this might be
B: you tell me , so in terms of the planner what 's what 's good one to do ?
E: let 's th this go there or not is good one . is very basic one . what makes things more likely that
B: the fir see the first thing is , getting back to thing we left out of the other is the actual discourse . so keith this is gonna get into your world because we 're gonna want to know , which constructions indicate various of these properties don't yet know how to do this , we 're gonna wind up pulling out discourse properties like we have object properties and we what they are yet . so that the go - there decision will have node from discourse , and why don't we just stick discourse thing up there to be as placeholder for
E: we we also had discourse features for the endpoint . and so again re that 's completely correct , we have the user model , the situation model here , we don't have the discourse model here yet . much the same way as we didn't we don't have the ontology here .
B: the ontology we said we would pull these various kinds of properties from the ontology like exhibiting , selling , and . so in some sense it 's it 's there . but the discourse we don't have it represented yet .
E: this be specific for second year ? and and we probably will have something like discourse for endpoint .
B: but if we do it 'll have the three values . it 'll have the eva values if we have it . for go - there , probably is true and false , let 's say . that 's what we talked about .
E: we 're looking at the little data that we have , so people say how do get to the castle and this usually means they wanna go there . so this should push it in one direction however people also sometimes say how do get there in order to find out how to get there without wanting to go there . and sometimes people say where is it because they wanna know where it is but in most cases they probably
B: but that doesn't change the fact that you 're you want these two values .
E: so this is some external thing that takes all the discourse and then says here it 's either , yay , , or nay .
B: and they 'll be , user go - there and maybe that 's all ,
D: situation go - there , because it 's whether it 's open or not . but that now that what 's the word the that interacts with the eva thing if they just wanna view it then it 's fine to go there when it 's closed whereas if they want to
B: right , so that 's that 's where it starts getting to be essentially more interesting , so what bhaskara says which is completely right is if that they 're only going to view it then it doesn't matter whether it 's closed or not in terms of , whether you wanna go there .
D: the time of day ,
C: it does matter though if there 's like strike or riot .
B: there are other situational things that do matter .
D: that 's what said just having one situational node may not be enough because this that node by itself wouldn't distinguish
B: it can have di various values . but we you 're right it might not be enough .
D: , see 'm 'm thinking that any node that begins with "" go - there "" is either gonna be true or false .
B: that could be .
A: also , that node , the go - there node would just be fed by separate ones for there 's different things , the strikes and the
D: like situation traffic and so on .
A: the time of day .
B: so so now the other thing that bhaskara pointed out is what this says is that there sh should be link , and this is where things are gonna get very messy from the endpoint decision maybe the they 're final re and , the very bottom endpoint decision to the go - there node . and don't worry about layout , then we 'll go we 'll go nuts
D: maybe we could have intermediate node that just the endpoint and the go - there node fed into ? because that 's what we , that 's why this situation comes up .
B: the go - there , actually the endpoint node could feed into the go - there that 's right , so the endpoint node , make that up to the go - there then we 'll have to do layout at some point , but something like that . now it 's gonna be important not to have loops . really important in the belief worl net world not to have loops
E: how long does it take you to compute
B: no it 's much worse than that . it if loo it it 's not def it 's not defined if you 're there are loops ,
D: it things don't converge , .
B: you just you have to there are all sorts of ways of breaking it up so that there isn't
E: but this isn't , this is this line is just coming from over here .
B: no it 's not loop yet , 'm just saying we , in no , in
D: but the good thing is we could have loopy belief propagation which we all love .
B: so anyway , so that 's another decision . what 's what 's another decision you like ?
E: these have no parents yet , but that doesn't matter .
B: the idea is that you go there , you go comes from something about the user from something about the situation and the the discourse is mystery .
E: this comes from traffic and , . sh - should we just make some
B: if you want .
E: if there 's parking maybe and if he has seen it already or not and , and discourse is something that should we make keith note here ? that comes from keith . just so we don't forget . have to get used to this .
B: and then also the discourse endpoint , endpoint sub - is if you wanna make it consistent .
A: actually is this the right way to have it where go there from the user and go there from the situation just about each other but they both feed the go there decision because isn't the , but that still allows for the possibility of the of the user model affecting our decision about whether strike is the thing which is going to keep this user away from th that decision making happens at the go - there node .
B: you you you if you needed to do that .
A: if you needed it to do that . but was just thinking maybe 'm conflating that user node with possible asking of the user hey there 's strike on , does that affect whether or not you wanna go
B: good point , don't how we 're going to
A: so that might not come out of user model but , , directly out of interaction .
B: gu yes my curr , don't that 's enough . my current idea on that would be that each of these decision nodes has questions associated with it . and the question wouldn't itself be one of these conditional things given that there 's strike do you still wanna go ? but if you told him bunch of , then you would ask him do you wanna go ? but trying to formulate the conditional question , that sounds too much .
A: right , right . right , , .
B: alright , but let me let 's stay with this minute because want to do little bit of organization . before we get more into details . the organization is going to be that the flavor of what 's going on is going to be that as we going to this detail keith is going to worry about the various constructions that people might use and johno has committed himself to being the parser wizard , so what 's going to happen is that eventually like by the time he graduates , they 'll be some system which is able to take the discourse in context and have outputs that can feed the rest of belief - net . wa assume everybody knows that , wanna , get closure that 'll be the game then , so the semantics that you 'll get out of the discourse will be of values that go into the various discourse - based decision nodes . and now some of those will get fancier like mode of transportation and so it isn't by any means necessarily simple thing that you want out . so if there is an and there is mode of transportation
E: and it there 's also split if you loo if you blow this up and look at it in more detail there 's something that comes from the discourse in terms of what was actually just said what 's the utterance go giving us and then what 's the discourse history give us .
B: that , , we 'll have to decide how much of th where that goes .
E: that 's two things then .
B: an and it 's not clear yet . it could be those are two separate things , it could be that the discourse gadget itself integrates as which would be my that you 'd have to do see in order to do reference and like that you 've gotta have both the current discourse and the context to say wanna go back there , what does that mean
E: but is th is this picture that 's emerging here just my wish that you have noticed already for symmetry or is it that we get for each decision on the very bottom we get the sub - , sub - , sub - and maybe sub - "" "" for "" ontology "" meta node but it might just
B: it could be . this is this is getting into the thing wanna talk about next , which is if that 's true how do we wanna combine those ? or when it 's true ?
E: but this wou would be though that , , we only have at most four at the moment arrows going to each of the bottom decisions . and four you we can handle . it 's too much ?
B: it see if it 's fou if it 's four things and each of them has four values it turns out to be big cpt , it 's not completely impossi it 's it 's not beyond what the system could solve but it 's probably beyond what we could actually write down . or learn .
E: right , true .
B: but , it 's four to the fourth . it 's pretty big .
C: two fifty - six , is that what that
B: it 's and don't 's gonna don't 'll get worse than that , so le that 's that 's good
E: but but four didn't we decide th of these had true or false ? so is it 's four
B: for go there , but not but not for the other one 's three values for endpoint already .
D: you need actually three to the five because if it has four inputs and then it itself has three values it can get big fast .
E: no it 's it 's sh
B: ev - it 's the eva .
E: but this one only has two .
D: no it still has three ,
B: since ta they will still have three . each so you 're from each point of view you 're making the same decision . so from the point of view of the ob of the entity
E: want to view that ,
D: this and also , , the other places where , like consider endpoint view , it has inputs coming from user budget , user thrift
B: those are not necessarily binary . so we 're we 're gonna have to use some care in the knowledge engineering to not have this explode . and it doesn't in the sense that actually with the underlying semantics and it isn't like you have two hundred and fifty - six different ways of thinking about whether this user wants to go to some place . so we just have to figure out what the regularities are and code them . but what was gonna suggest next is maybe we wanna work on this little longer but do want to also talk about the thing that we started into now of it 's all fine to say all these arrows come into the si same place what rule of combination is used there . so th yes they so these things all affect it , how do they affect it ? and belief - nets have their own beliefs about what are good ways to do that . so is it 's it 's clearer clear enough what the issue is , so do we wanna switch that now or we wanna do some more of this ?
E: we just need to in order to get some closure on this figure out how we 're gonna get this picture completely messy .
B: here he here 's one of the things that th you sh how easy it is to do this in the interface but you it would be great if you could actually just display at given time all the things that you pick up , you click on "" endpoint "" , and everything else fades and you just see the links that are relevant to that . does anybody remember the gui on this ?
C: would almost say the other way to do that would be to open or make - many belief - nets and then open them every time you wanted to look at different one
E: it 's probably pretty easy do it to do it in html , have each of these thing each of the end belief - nets be page and then you click on the thing and then li consider that it 's respective ,
B: anyway so it clear that even with this if we put in all the arrows nobody is gonna be able to read the diagram . so we have to figure out some display hack to do this anyway let me consi suggest that 's not first - order consideration , we have two first - order considerations which is what are the influences , and how do they get combined mathematically , how do we display them is an issue ,
C: don't , don't think this has been designed to support something like that .
D: , it might soon , if this is gonna be used in serious way like java base then it might soon be necessary to start modifying it for our purposes .
B: and that seems like perfectly feasible thing to get into , but we have to we want first . so why don't you tell us little bit about decision nodes and what the choices might be for these ?
C: you can technically wear that as you 're talking .
D: it 's right , do that .
B: put it in your ,
D: this board works fine . so recall the basic problem which is that you have belief - net and you have like lot of different nodes all contributing to one node . so as we discussed specifying this thing is big pain and it 's so will take long time to write down because if these have three possibilities each and this has three possibilities then you have two hundred and forty - three possibilities which is already lot of numbers to write down . so what helps us in our situation is that these all have values in the same set , these are all like saying ev or , so it 's not just generalized situation like we wanna just take combination of we wanna view each of these as experts ea who are each of them is making decision based on some factors and we wanna combine their decisions and create , sorta weighted combination .
E: rover , the rover decision .
D: the what decision ?
E: all of their outputs combined to make decision .
D: so the problem is to specify the so the conditional property of this given all those , that 's the way belief - nets are defined , like each node given its parents , so that 's what we want , let 's call this guy and let 's call these - one , - two xn , so we want probability that equals , , given that these guys are 'll just refer to this as like hat , the co like all of them ? given that the data says , , , , , so we would like to do this combination .
B: wanna make everybody is with us before he goes on . it 's it 's cl is it clear what he wants to compute ?
D: so , right . so what we don't wanna do is to for every single combination of and and and every single letter , give number because that 's not desirable . what we wanna do is find some principled way of saying what each of these is and we want it to be valid probability distribution , so we want it to add up to one , so those are the two things that we need . so what , what jerry suggested earlier was that we , view these guys as voting and we just take the we essentially take averages , so here two people have voted for , one has voted for , and one has voted for , so we could say that the probabilities are , , probability of being is one over four , because one person voted for out of four and similarly , probability of so this is probability of and then probability of given all that is two out of four and probability of is one out of four . so that 's step that 's the that 's the that 's the basic thing .
E: and that one outcome , that 's it 's - one voted for - two voted for
B: so this assumes symmetry and equal weights and all this things , which may or may not be good assumption ,
E: that 's the outcome .
D: so step two is so we 've assumed equal weights whereas it might turn out that , some be that , what the the actual the verbal content of what the person said , like what what might be somehow more important than the
C: - one matters more than - two or
D: so we don't wanna like give them all equal weight so currently we 've been giving them all weight one fourth so we could replace this by - one , - two , - three , and - four and in order for this to be valid probability distribution for each - hat , we just need that the 's sum to one . so they can be , you could have point one , point three , point two , and point four , say .
E: that 's one .
D: and that 'd be one . so that also seems to work fine .
C: so jus just to make understand this , so in this case we would still compute the average ?
D: you 'd compute the weighted average , so the probability of would be
C: so it 'd be so in this case the probability that equals would be one times let 's see , one full quarter times point one
D: not one quarter , so these numbers have been replaced with point one , point three , point two , and point four . so you can view these as gone . so this is step two . so the next possibility is that we 've given just single weight to each expert , whereas it might be the case that in certain situations one of the experts is more reliable and in certain situations the other expert is more reliable . so the way this is handled is by what 's called mixture of experts , so what you can have is you augment these diagrams like this you have new thing called "" "" , this is hidden variable . and what this is it gets its input from - one , - two , - three , and - four , and what it does is it decides which of the experts is to be trusted in this particular situation . and then these guys all come here . so this is sightly more complicated . so what 's going on is that this node looks at these four values of those guys and it decides in given these values which of these isn't likely to be more reliable or most reliable . so produces some , it produces number , either one , two , three , or four , in our situation , now this guy he looks at the value of say it 's two , and then he just selects the thing . that 's all there is to say , about it . right , so you can have mixture that
A: so so the function of the thing that comes out of is very different from the function of the other inputs . it 's driving how the other four are interpreted .
C: so passes vector on to the next node ? vector of the weights as the se
A: vector with three zero 's and one ,
C: it 's to tell the bottom node which one of the situations that it 's in or which one of the weighting systems
D: right , so the way you desc
C: was just , if you wanted to pay attention to more than one you could pass weighting system though too ,
A: does have to have another input to tell it alpha , beta , whatever , or is the that 's determined by what the experts are saying , like the type of situ it it just seems that like without that outside input that you 've got situation where , , like if - one says no , low value coming out of - on or if - one says no then ignore - one , that seems like that 'd be weird ,
D: could be things like if - two and - three say yes then ignore - one also .
A: alright , right .
C: the situations that has , are they built into the net so they could either be hand coded or learned or based on training data , so you specify one of these things for every one of those possi possible situations .
D: to learn them we need data , where are we gonna get data ? we need data with people intentions ,
A: right , right .
D: which is slightly tricky . but what 's the data about like , are we able to get these nodes from the data ?
A: like how thrifty the user is , or do we have access to that ?
D: but that 's my question , like how do we , how do we have data about something like endpoint sub - , or endpoint sub ?
C: you would say , based on in this dialogue that we have which one of the things that they said whether it was the entity relations or whatever was the thing that determined what mode it was ,
D: so this is what we wanna learn . can you bring up the function thing ? where is the thing thows you to
C: that 's on the added variable ,
D: is that it ? and it so either it 'll allow us to do everything which is unlikely , more likely it 'll allow us to do very few of these things and in that case we 'll have to just write up little things thow you to create such cpu 's on your own in the java base format . was assuming that 's what we 'd always do was assuming that 's what we 'd always do ,
C: in terms of java base it 's what you see is what you get in would be surprised if it supports anything more than what we have right here .
A: just talking about about that general end of things is there gonna be data soon from what people say when they 're interacting with the system and so on ? like , , what questions are being given being asked ? fey , you mean . 'm just wondering , because in terms of , , the figure was thinking about this figure that we talked about , fifty constructions or whatever that 's that 's whole lot of constructions and , one might be fairly pleased with getting really good analysis of five maybe ten in summer so , know we 're going for rough and ready . was was talking about the , , if you wanted to do it really in detail and we don't really need all the detail for what we 're doing right now but anyway in terms of just narrowing that task which fifty do do , wanna see what people are using , it will inspire me .
","A detailed diagram of the belief-net had already been disseminated.
Its structure was discussed during the meeting.
There are several endpoints ( User , Ontology , Discourse etc ) with separate EVA ( Enter/View/Approach ) values.
Details of how different inputs feed into them were discussed at length.
Ideas mentioned included grouping features of buildings like ""selling"" , ""fixing"" and ""exhibiting"" , as well as creating a User-compatibility node that would take different values depending on the situation and the user status.
Similarly , a Go-there ( towards a building ) node can be influenced by things like the user's budget and discourse parameters amongst other things.
The latter are still ill-defined at this stage.
The study of the linguistic constructions that people use in this kind of navigational domain is expected to be prove useful in that respect.
As each node in the tree is the decision point of the combination of its parent nodes , which rules govern this combination is an important issue.
There are several approaches ranging from simply averaging the inputs to using a hidden variable in order to weight them differently depending on context.
If the latter architecture is used , the net could -to an extent- be trained with the data that is currently being collected.
Although this was mainly a brainstorming meeting , some minor tasks were allocated for the near future.
Since the net architecture and possible decision algorithms were discussed , it is necessary to examine how much of this JavaBayes can accommodate and , if not , what modifications would be necessary.
Additionally , the german partners visiting the institute will need to see some results of the new system design.
Finally , the analysis of the linguistic constructions for the current research domain can begin even with limited data , as , at this stage , they need not be very detailed.
The is only a diagrammatic view of how the decision tree for the EVA task looks like.
A lot of the details have been glossed over: the user model can potentially comprise a huge number of factors; a planning ""go-there"" node needs input from several other areas of the net; there are intricate interactions between discourse and the situation model.
Similarly , what discourse properties are of importance and how they influence EVA probabilities is still a mystery.
On a more general note , there is also the question of whether the net should be updated continuously or only when it is needed.
No final decision was taken as to the rules of computation applying in the belief-net.
The more interesting solutions would ideally require training data , and it is still debatable whether the current collection would be appropriate for this particular task.
In any case , how different architectures can be implemented in JavaBayes and what modifications would be necessary for the purposes of this project also need to be investigated.
A simulator of the set of influence links forming the belief-net was created and put up for discussion.
Different sections of the analysis , such as the user model , the ontology and the discourse are represented as a layer of nodes each with its own EVA probabilities.
They form endpoints to which other nodes like Go-there , User_Budget , User_Thrift and Prosody feed into.
The second presentation concerned the set of computational rules that are to be used with the net.
The simple way to decide on the final output is the majority vote ( which E , V or A form the majority of the parent nodes' outputs ).
This assumes that all inputs are of equal importance.
Alternatively , each input can be weighted in a fixed way.
A third option is to create a hidden variable that makes the decision of which of the inputs is more trusted in a particular situation.
The same variable can potentially also change the weighting of each input.
"
ami_abstractive_summary,Bmr015.txt,"B: and we seem to be working . we didn't crash we 're not crashing anymore
C: one , two , three , four ,
B: and it really bothers me .
G: crashed when started this morning .
B: you crashed this morning ? did not crash this morning .
A: maybe it 's just , , how many how many times you crash in day . first time first time in the day ,
G: or maybe it 's once you 've done enough meetings it won't crash on you anymore . it 's matter of experience .
F: self - learning , .
A: that 's that 's great . do we have an agenda ? liz and andreas can't sh can't , can't come . so , they won't be here .
B: and it 's all me . cuz no one sent me anything else .
G: did they send , , the messages to you about the meeting today ?
B: but got it few minutes ago . right when you were in my office it arrived .
G: cuz checked my mail . didn't have anything .
B: so , does anyone have any agenda items other than me ? actually have one more also which is to talk about the digits .
A: right , so was just gonna talk briefly about the nsf itr . and then , you have won't say much , but , but then , , you said wanna talk about digits ?
B: have short thing about digits and then wanna talk little bit about naming conventions , although it 's unclear whether this is the right place to talk about it . so maybe just talk about it very briefly and take the details to the people who for whom it 's relevant .
F: could always say something about transcription . 've been but ,
A: if we , we shouldn't add things in just to add things in . 'm actually pretty busy today , so if we can we short meeting would be fine .
F: this does sound like we 're doing fine , that won't do .
B: so the only thing wanna say about digits is , we are done with the first test set . there are probably forms here and there that are marked as having been read that weren't really read . so won't really know until go through all the transcriber forms and extract out pieces that are in error . so wa . two things . the first is what should we do about digits that were misread ? my opinion is , , we should just throw them out completely , and have them read again by someone else . the grouping is completely random , so it 's perfectly fine to put group together again and have them re - read , just to finish out the test set .
F: ! by throw them out completely ?
B: the other thing you could do is change the transcript to match what they really said . so those are those are the two options .
A: but there 's often things where people do false starts . 've done it , where say
B: what the transcribers did with that is if they did correction , and they eventually did read the right string , you extract the right string .
G: you 're talking about where they completely read the wrong string and didn't correct it ?
B: and didn't notice . which happens in few places .
F: and and you 're talking string - wise , you 're not talking about the entire page ?
B: and so the two options are change the transcript to match what they really said , but then but then the transcript isn't the aurora test set anymore . don't think that really matters because the conditions are so different . and that would be little easier .
G: how many are how often does that happen ?
B: mmm , five or six times .
G: so it 's not very much .
B: no , it 's not much .
G: seems like we should just change the transcripts
A: it 's five or six times out of thousands ?
C: four thous ! four thousand .
A: would , , tak do the easy way , it it 's kinda wh who knows what studies people will be doing on speaker - dependent things and so having it all the speakers who we had is at least interesting .
G: so you , how many digits have been transcribed now ?
B: four thousand lines . and each line is between one and about ten digits .
G: four thousand lines ?
B: didn't didn't compute the average . the average was around four or five .
A: so that 's couple hours of , , speech , probably . which is reasonable test set .
B: and , jane , do have set of forms which you have copies of somewhere .
F: - . , true . - . - .
B: had all of them back from you . and then the other thing is that , , the forms in front of us here that we 're gonna read later , were suggested by liz
F: no , not yet .
B: because she wanted to elicit some different prosodics from digits . and so , , wanted people to , take quick look at the instructions
E: eight eight two nine .
B: and the way it wa worked and see if it makes sense and if anyone has any comments on it .
A: and the decision here , , was to continue with the words rather than the numerics .
B: although we could switch it back . the problem was and zero . although we could switch it back and tell them always to say "" zero "" or always to say "" "" .
A: but it 's just two thing ways that you can say it . that 's the only thought have because if you start talking about these , tr she 's trying to get at natural groupings , but it there 's nothing natural about reading numbers this way . if you saw telephone number you would never see it this way .
B: the the problem also is she did want to stick with digits . 'm speaking for her since she 's not here . but , , the other problem we were thinking about is if you just put the numerals , they might say forty - three instead of four three .
F: if there 's space , though , between them . with when you space them out they don't look like , , forty - three anymore .
B: she and were talking about it , and she felt that it 's very , very natural to do that chunking .
A: she 's right . it 's it 's different problem . it 's it 's an interesting problem we 've done with numbers before , if you say "" three nine eight one "" sometimes people will say "" thirty - nine eighty - one "" or "" three hundred three hundred eighty - nine one "" , or don't think they 'd say that ,
B: but , they certainly could .
A: th thirty - eight ninety - one is probably how they 'd do it .
B: so . , this is something that liz and spoke about and , since this was something that liz asked for specifically , we need to defer to her .
A: , we 're probably gonna be collecting meetings for while and if we decide we still wanna do some digits later we might be able to do some different ver different versions ,
B: do something different ,
A: but this is the next suggestion , so , let me , , get my short thing out about the nsf . actually this is maybe little side thing . sent to what we had , , in some previous mail , as the right joint thing to send to , which was "" mtg rcdr hyphen joint "" . but then got some funny mail saying that the moderator was going to
B: that 's because they set the one up at uw that 's not on our side , that 's on the - dub side . and so - uw set it up as moderated list . and , have no idea whether it actually ever goes to anyone so you might just wanna mail to mari
A: no no , th got got , , little excited notes from mari and jeff and so on ,
B: so the moderator actually did repost it . cuz had sent one earlier actually the same thing happened to me had sent one earlier . the message says , "" you 'll be informed "" and then was never informed but got replies from people indicating that they had gotten it , it 's just to prevent spam .
A: so . , anyway , everybody here are are you are on that list , so you got the note ? so this was , , , , proposal that we put in before on more higher level , , issues in meetings , from higher level from my point of view . and , , meeting mappings , so is for it was proposal for the itr program , information technology research program 's part of national science foundation . it 's the second year of their doing , , these grants . they 're they 're lot of them are some of them anyway , are larger grants than the usual , small nsf grants , so , they 're very competitive , and they have first phase where you put in pre - proposals , and we , , got through that . and so th the next phase will be we 'll actually be doing larger proposal . and 'm hope to be doing very little of it . which was also true for the pre - proposal , there 'll be bunch of people working on it .
B: when 's when 's the full proposal due ?
A: april ninth , . so it 's about month .
B: and they said end of business day you could check on the reviewer forms ,
A: march second , said .
B: 've been day off all week . that 's good thing cuz that way got my papers done early .
G: it would be interesting
A: so that 's amazing you showed up at this meeting !
B: it is . it is actually quite amazing .
G: it 'll be interesting to see the reviewer 's comments .
A: my favorite is was when when one reviewer says , , "" , this should be far more detailed "" , and the nex the next reviewer says , "" , there 's way too much detail "" .
B: or "" this is way too general "" , and the other reviewer says , "" this is way too specific "" . "" this is way too hard "" , "" way too easy "" .
A: we 'll see . maybe there 'll be something useful .
B: it sounded like they the first gate was pretty easy . is that right ? that they didn't reject lot of the pre - proposals ?
A: do anything about the numbers ?
G: it 's just from his message it sounded like that .
E: said something , .
G: there was sentence at the end of one of his paragraphs
A: should go back and look . didn't don't think that 's true .
G: he said the next phase 'll be very , competitive because we didn't want to weed out much in the first phase .
A: we 'll have to see what the numbers are . but they have to weed out enough so that they have enough reviewers . so , , , maybe they didn't weed out as much as usual , but it 's it 's usually pretty it 's it 's certainly not 'm that it 's not down to one in two of what 's left . 'm it 's ,
B: how how many awards are there ,
A: there 's different numbers of awards for different size they have three size grants . this one there 's , see the small ones are less than five hundred thousand total over three years and that they have fair number of them . and the large ones are , boy , forget , more than million and half , more than two million like that . and and we 're in the middle forget what it was . but it 's pr probably along the li could be wrong on this but probably along the lines of fifteen or that they 'll fund , or twenty . when they do you do how many they funded when they in chuck 's , that he got last year ?
B: it was smaller , that it was like four or five , it doesn't matter , we 'll find out one way or another .
A: last time they just had two categories , small and big , and this time they came up with middle one , so it 'll there 'll be more of them that they fund than of the big .
G: if we end up getting this , , what will it mean to icsi in terms of , wh where will the money go to , what would we be doing with it ?
B: exactly what we say in the proposal .
G: which part is icsi though .
A: none of it will go for those yachts that we 've talking about . no , it 's
G: it 's just for the research to continue the research on the meeting recorder ?
A: it 's extending the research ,
B: it 's go higher level than we 've been talking about for meeting recorder .
A: the other things that we have , , been working on with , , the with communicator especially with the newer things with the more acoustically - oriented things are are lower level . this is dealing with , , mapping on the level of , , the conversation of mapping the conversations
G: right , right .
A: to different planes . so . . but , . so it 's all that none of us are doing right now , or none of us are funded for , so it 's it would be new .
G: so assuming everybody 's completely busy now , it means we 're gonna hafta , hire more students , or , something ?
A: there 's evenings , and there 's weekends , there would be there would be new hires , and there would be expansion , also , there 's always for everybody there 's there 's always things that are dropping off , grants that are ending , or other things that are ending , there 's there 's continual need to bring in new things . but but there definitely would be new new , , students , and , both at uw and here .
B: are there any students in your class who are expressing interest ?
A: not clear yet . not clear yet .
B: other than the one who 's already here .
A: we got we have two of them are two in the there 're two in the class already here , then there 's third who 's doing project here , who , but he he won't be in the country that long , maybe another will end up . actually there is one other guy who 's looking that 's that anyway , that 's that 's all was gonna say is that 's , that 's and we 're sorta preceding to the next step , and , it 'll mean some more work , , , in march in getting the proposal out , and then , it 's , , we 'll see what happens . the last one was that you had there , was about naming ?
B: it just , we 've been cutting up sound files , in for ba both digits and for , , doing recognition . and liz had some suggestions on naming and it just brought up the whole issue that hasn't really been resolved about naming . so , , one thing she would like to have is for all the names to be the same length so that sorting is easier . same number of characters so that when you 're sorting filenames you can easily extract out bits and pieces that you want . and that 's easy enough to do . and don't think we have so many meetings that 's big deal just to change the names . so that means , , instead of calling it "" mr one "" , "" mr two "" , you 'd call it "" mrm zero one "" , "" mrm zero two "" , things like that . just so that they 're they 're all the same length .
F: but , , when you , do things like that you can always as long as you have you can always search from the beginning or the end of the string .
B: the problem is that they 're lot of fields .
F: so "" zero two ""
B: so we have th we 're gonna have the speaker id , information on the microphones ,
F: , your example was really
B: information on the speak on the channels and all that . and so if each one of those is fixed length , the sorting becomes lot easier .
D: she wanted to keep them the same lengths across different meetings also . so like , the nsa meeting lengths , all filenames are gonna be the same length as the meeting recorder meeting names ?
B: and as said , the it 's we just don't have that many that 's big deal .
G: cuz of digits .
B: and so , , , at some point we have to take few days off , let the transcribers have few days off , make no one 's touching the data and reorganize the file structures . and when we do that we can also rationalize some of the naming .
F: would think though that the transcribe the transcripts themselves wouldn't need to have such lengthy names . so , , you 're dealing with different domain there , and with start and end times and all that , and channels and ,
B: right . so the only thing that would change with that is just the directory names ,
F: so , it 's different set .
B: would change them to match . so instead of being mr one it would be mrm zero one . but don't think that 's big deal .
F: fine . fine .
B: so for the meetings we were thinking about three letters and three numbers for meeting ds . for speakers , or and then three numbers , for , and , , that also brings up the point that we have to start assembling speaker database so that we get those links back and forth and keep it consistent . and then , , the microphone issues . we want some way of specifying , more than looking in the "" key "" file , what channel and what mike . what channel , what mike , and what broadcaster . or how to say it . so with this one it 's this particular headset with this particular transmitter as wireless . and that one is different headset and different channel . and so we just need some naming conventions on that . that 's gonna become especially important once we start changing the microphone set - up . we have some new microphones that 'd like to start trying out , once test them . and then we 'll we 'll need to specify that somewhere . so was just gonna do fixed list of , , microphones and types . so , as said
G: that sounds good .
A: since we have such short agenda list wi will ask how are the transcriptions going ?
F: the the news is that 've so 've switched to start my new sentence . switched to doing the channel - by - channel transcriptions to provide , , the , tighter time bins for partly for use in thilo 's work and also it 's of relevance to other people in the project . and , , discovered in the process couple of interesting things , one of them is that , , it seems that there are time lags involved in doing this , using an interface that has so much more complexity to it . and and wanted to maybe ask , , chuck to help me with some of the questions of efficiency . maybe was thinking maybe the best way to do this in the long run may be to give them single channel parts and then piece them together later . and have script , piece them together . so it 's like , know that take them apart and put them together and 'll end up with the representation which is where the real power of that interface is . and it may be that it 's faster to transcribe channel at time with only one , , sound file and one , , set of , , utterances to check through .
A: 'm little confused . that one of the reason we thought we were so much faster than , , the other transcription , , thing was that we were using the mixed file .
F: but , , with the mixed , when you have an overlap , you only have choice of one start and end time for that entire overlap , which means that you 're not tightly , , tuning the individual parts th of that overlap by different speakers . so someone may have only said two words in that entire big chunk of overlap . and for purposes of , , things like so things like training the speech - nonspeech segmentation thing . th - it 's necessary to have it more tightly tuned than that . and and , , is it would be wonderful if , , it 's possible then to use that algorithm to more tightly tie in all the channels after that but , , , 've th the exactly where that 's going at this point . but was experimenting with doing this by hand really do think that it 's wise that we 've had them start the way we have with , , working off the mixed signal , having the interface that doesn't require them to do the ti , the time bins for every single channel at , through the entire interaction . did discover couple other things by doing this though , and one of them is that , once in while backchannel will be overlooked by the transcriber . as you might expect , because when it 's backchannel could happen in very densely populated overlap . and if we 're gonna study types of overlaps , which is what wanna do , an analysis of that , then that really does require listening to every single channel all the way through the entire length for all the different speakers . now , for only four speakers , that 's not gonna be too much time , but if it 's nine speakers , then that that is more time . so it 's li , wondering it 's like this it 's really valuable that thilo 's working on the speech - nonspeech segmentation because maybe , , we can close in on that wi without having to actually go to the time that it would take to listen to every single channel from start to finish through every single meeting .
E: but those backchannels will always be problem . especially if they 're really short and they 're not very loud and so it can it will always happen that also the automatic detection system will miss some of them ,
F: so then , maybe the answer is to , , listen especially densely in places of overlap , just so that they 're they 're not being overlooked because of that , and count on accuracy during the sparser phases . cuz there are large spaces of the that 's good point . there are large spaces where there 's no overlap . someone 's giving presentation , that 's that 's good thought . and , , let 's see , there was one other thing was gonna say . it 's really interesting data to work with , have to say , it 's very enjoyable . really , not problem spending time with these data . and not just because 'm in there . no , it 's real interesting .
A: it 's short meeting . you 're you 're still in the midst of what you 're doing from what you described last time , assume ,
C: haven't results , , yet 'm continue working with the mixed signal now , after the last experience . and and 'm tried to , , adjust the to improve , , an harmonicity , , detector that , , implement . because , , get , , very much harmonics now . harmonic possi possible harmonics , and now 'm 'm trying to find , , some , of of help , , using the energy to distinguish between possible harmonics , and other fre frequency peaks , that , , corres not harmonics . have to talk with with you , with the group , , about the instantaneous frequency , because have , , an algorithm , and , get , results similar results , like , , the paper , , that am following . but , , the rules , , that , , people used in the paper to distinguish the harmonics , is doesn't work . and not that , the way to ob the way to obtain the instantaneous frequency is right , or it 's it 's not right . haven't enough file feeling to to distinguish what happened .
A: 'd like to talk with you about it . if if , if don't have enough time and you wanna discuss with someone else some someone else besides us that you might want to talk to , , might be stephane .
C: talked with stephane and thilo they nnn they they didn't
E: 'm not too experienced with harmonics
C: they think that the experience is not enough to
G: is is this the algorithm where you hypothesize fundamental , and then get the energy for all the harmonics of that fundamental ?
C: no , no it 's no
G: and then hypothesize new fundamental and get the energy
C: no . don't proth process the fundamental . ehm calculate the phase derivate using the fft . the algorithm said that , , if you if you change the the , the - the frequency "" "" , , using the in the instantaneous frequency , you can find , , how , , in several frequencies that proba probably the harmonics , , the errors of peaks the frequency peaks , , move around these , frequency harmonic the frequency of the harmonic . and , , if you if you compare the instantaneous frequency , , of the of the , , continuous , , , filters , that , that , , they used , to to get , , the instantaneous frequency , it probably too , you can find , , that the instantaneous frequency for the continuous , , the output of the continuous filters are very near . and in my case in equal with our signal , it doesn't happened .
A: 'd hafta look at that and think about it . it 's it 's haven't worked with that either the way the simple - minded way suggested was what chuck was just saying , is that you could make sieve . you actually say that here is let 's let 's hypothesize that it 's this frequency or that frequency , maybe you maybe you could use some other cute methods to , , short cut it by , making some guesses , you could make some guesses from , from the auto - correlation but then , given those guesses , try , only looking at the energy at multiples of the of that frequency , and see how much of the take the one that 's maximum .
C: using the energy of the of the multiple of the frequency .
A: of all the harmonics of that . .
G: do you hafta do some , , low - pass filter before you do that ?
C: but , know many people use , , low - pass filter to to get , , the pitch .
A: to get the pitch , yes .
C: to get the pitch , yes .
E: to get the pitch , .
C: but the harmonic , no .
G: but the harmonics are gonna be , what the right word is . they 're gonna be dampened by the , vocal tract , the response of the vocal tract . and so just looking at the energy on those at the harmonics , is that gonna ?
A: this is for ,
G: what you 'd like to do is get rid of the effect of the vocal tract . and just look at the at the signal coming out of the glottis .
A: that 'd be good . but , but that you need to but don't need if you need to get rid of it . that 'd that 'd be but if it 's ess if it 's essential . cuz the main thing is that , , you 're trying wha what are you doing this for ? you 're trying distinguish between the case where there is , where there are more than , where there 's more than one speaker and the case where there 's only one speaker . so if there 's more than one speaker , you 're so you 're not distinguished between voiced and unvoiced , so , if you don't if you don't care about that see , if you also wanna just determine if you also wanna determine whether it 's unvoiced , then you want to look at high frequencies also , because the the fact that there 's more energy in the high frequencies is gonna be an ob obvious cue that it 's unvoiced . other than that as far as the one person versus two persons , it would be primarily low frequency phenomenon . and if you looked at the low frequencies , yes the higher frequencies are gonna there 's gonna be spectral slope . the higher frequencies will be lower energy . but so what . that 's that 's
C: will prepare for the next week , all my results about the harmonicity and will try to come in and to discuss here , because , , haven't enough feeling to many time to understand what happened with the with , , so many peaks , and see the harmonics there many time but , , there are lot of peaks , that , , they are not harmonics . have to discover what is the the best way to to to use them
A: but don't think you can you 're not gonna be able to look at every frame , really really thought that the best way to do it , and 'm speaking with no experience on this particular point , but , my impression was that the best way to do it was however you you 've used instantaneous frequency , whatever . however you 've come up you with your candidates , you wanna see how much of the energy is in that as coppo as opposed to all of the all the total energy . and , , if it 's voiced , so maybe you do need voiced - unvoiced determination too . but if it 's voiced , the fraction of the energy that 's in the harmonic sequence that you 're looking at is relatively low , then it should be then it 's more likely to be an overlap .
C: this this is the idea the idea had to compare the ratio of the energy of the harmonics with the , with the , , total energy in the spectrum and try to get ratio to distinguish between overlapping and speech .
A: but you 're looking you 're looking at let 's take second with this . you 're looking at at the phase derivative , this is this is in in bands ?
C: no , no . it 's it 's the band the band is , , from zero to four kilohertz .
A: and you just take the instantaneous frequency ?
C: used two two method two methods . one , , based on the , ftt . to obtain the or to study the harmonics from the spectrum directly , and to study the energy and the multiples of and another algorithm have is the in the instantaneous frequency , on the fft to to calculate the phase derivate in the time . have two algorithms . but , , in in my opinion the the instantaneous frequency , the the behavior , th it was very interesting . because saw , how the spectrum concentrate , , around the harmonic . when apply the rule , of the in the instantaneous frequency of the ne of the continuous filter in the near filter , the rule that , , people propose in the paper
A: but the instantaneous frequency , wouldn't that give you something more like the central frequency of the , of the where most of the energy is ? does does it why would it correspond to pitch ?
C: when first calculate , , using the fft ,
F: di - digital camera .
C: get the spectrum , all the frequency . obtained the instantaneous frequency . and change the @ @ , instantaneous frequency , here .
A: so you scale you you do scaling along that axis according to instantaneous it 's kinda normalization .
C: use these frequency , the range is different , and the resolution is different . more or less , thing like this . the paper said that , , but , , they used , based in the in the they use hanning window . and , they said that , , if these peak are , , harmonics , are very near , or have to be very near . but , , phh ! and what is the what is the distance . and tried to put different distance , to put difference , length of the window , different front sieve , and not what happened .
A: 'm not following it enough . 'll probably gonna hafta look at the paper , but which 'm not gonna have time to do in the next few days , but 'm 'm curious about it .
F: did it did occur to me that this is , the return to the transcription , that there 's one third thing wanted to ex raise as to as an issue which is , , how to handle breaths . so , wanted to raise the question of whether people in speech recognition want to know where the breaths are . and the reason ask the question is , aside from the fact that they 're very time - consuming to encode , the fact that there was some had the indication from dan ellis in the email that sent to you , that in principle we might be able to , , handle breaths by accessi by using cross - talk from the other things , in principle , maybe we could get rid of them , we had this an and didn't couldn't get back to you , but the question of whether it 'd be possible to eliminate them from the audio signal , which would be the ideal situation ,
A: it 'd be ideal . we - see , we 're we 're dealing with real speech and we 're trying to have it be as real as possible and breaths are part of real speech .
F: except that these are really truly ther there 's segment in the one did the first one that did for for this , where truly we 're hearing you breathing like as if we 're you 're in our ear , and it 's like it 's like breath is natural ,
A: it is but it is if you record it .
F: except that we 're we 're trying to mimic see what you 're saying . you 're saying that the pda application would have , have to cope with breath .
G: an - any application may have to .
B: the might not have to , but more people than just pda users are interested in this corpus . so so mean you 're right
F: then the then have two questions .
B: we could remove it , but we don't wanna remove it from the corpus , in terms of delivering it because the people will want it in there .
F: so maybe the question is notating it .
A: if if it gets in the way of what somebody is doing with it then you might wanna have some method which will allow you to block it , but you it 's real data . you don't wanna but you don't if , if there 's little bit of noise out there , and somebody is talking about something they 're doing , that 's part of what we accept as part of real meeting , we have the the fan and the in the projector up there , and , , this is it 's this is actual that we wanna work with .
F: this is in very interesting because it has it shows very clearly the contrast between , , speech recognition research and discourse research because in discourse and linguistic research , what counts is what 's communit communicative . they breathe all the time . and once in while breath is communicative , but very rarely . so now , had discussion with chuck about the data structure and the idea is that the transcripts will that get stored as master there 'll be master transcript which has in it everything that 's needed for both of these uses . and the one that 's used for speech recognition will be processed via scripts . like , don 's been writing scripts to process it for the speech recognition side . discourse side will have this side over he the we 'll have ch not being very fluent here . this the discourse side will have script which will stri strip away the things which are non - communicative . so then the then let 's think about the practicalities of how we get to that master copy with reference to breaths . so what would what would wonder is would it be possible to encode those automatically ? could we get breath detector ?
B: just to save the transcribers time .
F: , you just have no idea . if you 're getting breath several times every minute , and just simply the keystrokes it takes to negotiate , to put the boundaries in , to type it in , it 's just huge amount of time . and you wanna be it 's used , and you wanna be it 's done as efficiently as possible , and if it can be done automatically , that would be ideal .
A: what if you put it in but didn't put the boundaries ? so you just 's between these other things ,
F: . so now there 's there 's another possibility which is , , the time boundaries could mark off words from nonwords . and that would be extremely time - effective , if that 's sufficient .
A: 'm it 's too if it 's too hard for us to annotate the breaths per se , we are gonna be building up models for these things and these things are somewhat self - aligning , so if so , we if we say there is some thing which we call "" breath "" or "" breath - in "" or "" breath - out "" , the models will learn that thing . so but you do want them to point them at some region where the breaths really are .
F: but that would maybe include pause as ,
G: there 's there 's
F: and that wouldn't be problem to have it , , pause plus breath plus laugh plus sneeze ?
A: there is there 's this dynamic tension between marking everything , as , marking just little bit and counting on the statistical methods . the more we can mark the better . but if there seems to be lot of effort for small amount of reward in some area , and this might be one like this although 'd be interested to get input from liz and andreas on this to see if they cuz they 've - they 've got lots of experience with the breaths in , , their transcripts .
B: they have lots of experience with breathing ?
A: yes they do , but we can handle that without them here . but but , , you were gonna say something about
G: , , one possible way that we could handle it is that , as the transcribers are going through , and if they get hunk of speech that they 're gonna transcribe , th they 're gonna transcribe it because there 's words in there or whatnot . if there 's breath in there , they could transcribe that .
F: that 's what they 've been doing . so , within an overlap segment , they do this .
G: right . but if there 's big hunk of speech , let 's say on morgan 's mike where he 's not talking , , don't don't worry about that . so what we 're saying is , there 's no guarantee that , so for the chunks that are transcribed , everything 's transcribed . but outside of those boundaries , there could have been that wasn't transcribed . so you just somebody can't rely on that data and say "" that 's perfectly clean data "" . do you see what 'm saying ?
F: you 're saying it 's uncharted territory .
G: so would say don't tell them to transcribe anything that 's outside of grouping of words .
A: that sounds like reasonable compromise .
E: and that 's that quite co corresponds to the way try to train the speech - nonspeech detector , as really try to not to detect those breaths which are not within speech chunk but with which are just in silence region . and they so they hopefully won't be marked in those channel - specific files .
A: wanted to comment little more just for clarification about this business about the different purposes . see , in in way this is really key point , that for speech recognition , , research , it 's not just minor part . the would say the core thing that we 're trying to do is to recognize the actual , meaningful components in the midst of other things that are not meaningful . so it 's critical it 's not just incidental it 's critical for us to get these other components that are not meaningful . because that 's what we 're trying to pull the other out of . that 's our problem . if we had nothing if we had only linguistically - relevant things if we only had changes in the spectrum that were associated with words , with different spectral components , and , , we didn't have noise , we didn't have convolutional errors , we didn't have extraneous , , behaviors , and , and moving your head and all these sorts of things , then , actually speech recognition isn't that bad right now . it 's it 's the technology 's come along pretty . the the reason we still complain about it is because is when you have more realistic conditions then things fall apart .
F: , , what was wondering is what at what level does the breathing aspect enter into the problem ? because if it were likely that pda would be able to be built which would get rid of the breathing , so it wouldn't even have to be processed at thi at this computational le let me see , it 'd have to be computationally processed to get rid of it , but if there were , , like likely on the frontier , good breath extractor then , , and then you 'd have to
A: but that 's research question ,
F: , see and that 's what wouldn't know .
A: and we don't either . so it 's it right now it 's just raw it 's just data that we 're collecting , and so we don't wanna presuppose that people will be able to get rid of particular degradations because that 's actually the research that we 're trying to feed . so , , an and maybe in five years it 'll work really , and it 'll only mess - up ten percent of the time , but then we would still want to account for that ten percent ,
F: there 's another aspect which is that as we 've improved our microphone technique , we have lot less breath in the in the more recent , , recordings , so it 's in way it 's an artifact that there 's so much on the on the earlier ones .
G: just to add to this one of the ways that we will be able to get rid of breath is by having models for them . that 's what lot of people do nowadays . and so in order to build the model you need to have some amount of it marked , so that where the boundaries are . don't think we need to worry lot about breaths that are happening outside of , , conversation . we don't have to go and search for them to mark them , but , , if they 're there while they 're transcribing some hunk of words , 'd say put them in if possible .
F: and it 's also the fact that they differ lot from one channel to the other because of the way the microphone 's adjusted .
A: should we do the digits ?
D: mmm . alright .
","Topics discussed by the Berkeley Meeting Recorder group included the status of the first test set of digits data , naming conventions for files , speaker identification tags , and encoding files with details about the recording.
The group also discussed a proposal for a grant from the NSF's ITR ( Information Technology Research ) program , transcriptions , and efforts by speaker mn005 to detect speaker overlap using harmonicity-related features.
Particular focus was paid to questions about transcription procedures , i.e . how to deal with overlooked backchannels , and audible breaths.
A small percentage of transcripts will be changed to reflect mis-read , uncorrected digits.
A speaker database will be compiled to establish consistent links between speakers and their corresponding identification tags.
Sections of densely overlapping speech will require hand-checking so that overlooked backchannels may be manually segmented and labelled.
The transcribers should only code audible breaths within a grouping of words , and not outside regions of continuous speech.
It was further determined that audible breaths are an important facet of recorded speech , and that removing them from the corpus would be contrary to the aims of the project.
Speaker mn005 will prepare his results for detecting speaker overlap and present them in the next meeting.
During digits readings , subjects tend to chunk numbers together rather than reading each number separately.
When working from the mixed channel , transcribers may select only one start and end time for overlapping speech , resulting in points of overlap that are less tightly tuned.
Transcribers are likely to overlook backchannels in densely populated sections of speaker overlap.
Speaker mn014 reported that this is also problematic for the automatic detection of speech and non-speech , as backchannels that are very short and not loud enough will inevitably be overlooked.
Speaker mn005 reported problems distinguishing between possible harmonics and other frequency peaks , and creating an algorithm for obtaining the instantaneous frequency.
The encoding of all audible breaths is too time-consuming.
The first test set of digits is complete and includes 4,000 lines , each comprising between 1-10 digits.
New digits forms were distributed for eliciting different prosodic groupings of numbers.
New naming conventions were discussed as means for facilitating the sorting process.
Existing files will be changed so that all filenames are of equal length.
Similar changes will be made to speaker identification tags.
Files will also contain information specifying channel , microphone , and broadcaster information.
A proposal is being drafted for a grant from the NSF's ITR program for extending the research initiatives of the Meeting Recorder project.
Speaker fe008 is performing channel-by-channel transcriptions to create tighter time bins.
Tentative plans are to assign single channels to the transcriber pool and then piece them together afterwards.
Efforts by speaker mn005 are in progress to detect speaker overlap in the mixed signal using harmonicity-related features.
For determining the instantaneous frequency , speaker me013 recommended deriving the maxima from energy multiples of a given frequency.
It was also suggested that speaker mn005 should determine whether portions of the signal are voiced or unvoiced , as voiced intervals reflecting a relatively low fraction of energy in the harmonic sequence are likely to indicate sections of overlap.
"
ami_abstractive_summary,Bro023.txt,"A: we 're going .
C: and hans - , hans - guenter will be here , , by next tuesday or so . so he 's he 's going to be here for about three weeks ,
A: just for visit ?
C: we 'll see . we might end up with some longer collaboration . so he 's gonna look in on everything we 're doing and give us his thoughts . and so it 'll be another good person looking at things .
E: th - that 's his spectral subtraction group ? is that right ? so should probably talk to him bit too ?
C: no , he 'll be around for three weeks . he 's , , , very , easygoing , easy to talk to , and , , very interested in everything .
B: we met him in amsterdam .
C: he 's been here before . he 's he 's he 's
A: wh - back when was grad student he was here for , year or six months .
B: haven't noticed him .
A: something like that .
C: something like that . he 's he 's done couple stays here .
A: so , , we got lots to catch up on . and we haven't met for couple of weeks . we didn't meet last week , morgan . went around and talked to everybody , and it seemed like they had some new results but rather than them coming up and telling me figured we should just week and they can tell both , all of us . why don't we why don't we start with you , dave , and then , , we can go on .
E: so , , since we 're looking at putting this , mean log magnitude spectral subtraction , , into the smartkom system , did test seeing if , , it would work using past only and plus the present to calculate the mean . so , did test , , where used twelve seconds from the past and the present frame to , , calculate the mean .
A: twelve twelve seconds back from the current frame , is that what you mean ?
E: twelve seconds , , counting back from the end of the current frame , so it was , , twen it was twenty - one frames and that worked out to about twelve seconds . and compared to , , do using twelve second centered window , there was drop in performance but it was just slight drop . is is that right ?
C: , it was pretty it was pretty tiny .
E: so that was encouraging . that , that 's encouraging for the idea of using it in an interactive system like and , , another issue 'm 'm thinking about is in the smartkom system . so say twe twelve seconds in the earlier test seemed like good length of time , but what happens if you have less than twelve seconds ? so bef before , back in may , did some experiments using , say , two seconds , or four seconds , or six seconds . in those trained the models using mean subtraction with the means calculated over two seconds , or four seconds , or six seconds . here , was curious , what if trained the models using twelve seconds but gave it situation where the test set was subtracted using two seconds , or four seconds , or six seconds . so did that for about three different conditions . th it was , , four se it was , , something like four seconds and , , six seconds , and eight seconds . something like that . and it seems like it it hurts compared to if you actually train the models using th that same length of time but it doesn't hurt that much . usually less than point five percent , although did see one where it was point eight percent or so rise in word error rate . but this is , , where , , even if train on the , , model , and mean subtracted it with the same length of time as in the test , it the word error rate is around , , ten percent or nine percent . so it doesn't seem like that big difference .
C: but it but looking at it the other way , isn't it what you 're saying that it didn't help you to have the longer time for training , if you were going to have short time for
E: that that 's true .
C: why would you do it , if you knew that you were going to have short windows in testing .
A: it seems like for your , in normal situations you would never get twelve seconds of speech ,
B: you need twelve seconds in the past to estimate , right ? or or you 're looking at six sec seconds in future and six in
C: no , total .
E: for the test it 's just twelve seconds in the past .
B: no , it 's all
A: is this twelve seconds of , regardless of speech or silence ? or twelve seconds of speech ?
E: of of speech .
C: the other thing , , which maybe relates little bit to something else we 've talked about in terms of windowing and so on is , that , , wonder if you trained with twelve seconds , and then when you were two seconds in you used two seconds , and when you were four seconds in , you used four seconds , and when you were six and you build up to the twelve seconds . so that if you have very long utterances you have the best , but if you have shorter utterances you use what you can .
E: and that 's actually what we 're planning to do in so so the que the question was trying to get at with those experiments is , "" does it matter what models you use ? does it matter how much time you use to calculate the mean when you were , , tra doing the training data ? ""
C: but the other thing is that 's the other way of looking at this , going back to , , mean cepstral subtraction versus rasta things , is that you could look at mean cepstral subtraction , especially the way you 're doing it , , as being filter . and so , the other thing is just to design filter . you 're you 're doing high - pass filter or band - pass filter of some sort and just design filter . and then , , filter will have certain behavior and you loo can look at the start up behavior when you start up with nothing . and and , , it will , , if you have an iir filter , it will , , , not behave in the steady - state way that you would like it to behave until you get long enough period , by just constraining yourself to have your filter be only subtraction of the mean , you 're , , tying your hands behind your back because there 's filters have all sorts of be temporal and spectral behaviors . and the only thing , , consistent that we know about is that you want to get rid of the very low frequency component .
B: but do you really want to calculate the mean ? and you neglect all the silence regions or you just use everything that 's twelve seconds ,
E: you do you mean in my tests so far ? most of the silence has been cut out . just there 's just inter - word silences .
B: and they are , like , pretty short . so you really need lot of speech to estimate the mean of it .
E: if only use six seconds , it still works pretty . saw in my test before . was trying twelve seconds cuz that was the best in my test before and that increasing past twelve seconds didn't seem to help . it 's something need to play with more to decide how to set that up for the smartkom system . like , may maybe if trained on six seconds it would work better when only had two seconds or four seconds , and
C: , if you take this filtering perspective and if you essentially have it build up over time . if you computed means over two and then over four , and over six , essentially what you 're getting at is , , ramp up of filter anyway . and so you may just want to think of it as filter . but , , if you do that , then , , in practice somebody using the smartkom system , one would they 're using it for while , it means that their first utterance , instead of , , getting , , forty percent error rate reduction , they 'll get , over what , , you 'd get without this , , , policy , , you get thirty percent . and then the second utterance that you give , they get the full , , full benefit of it if it 's this ongoing thing .
A: so you cache the utterances ? that 's how you get your ,
C: 'm saying in practice , , that 's if somebody 's using system to ask for directions , they 'll say something first . and and to begin with if it doesn't get them quite right , ma maybe they 'll come back and say , "" excuse me ? "" it should have some policy like that anyway . and and , , in any event they might ask second question . and it 's not like what he 's doing doesn't , , improve things . it does improve things , just not as much as he would like . and so , , there 's higher probability of it making an error , , in the first utterance .
A: what would be really is if you could have this probably users would never like this but if you had could have system where , before they began to use it they had to introduce themselves , verbally . my name is so - and - so , 'm from blah - blah . "" and you could use that initial speech to do all these adaptations
C: the other thing which , much about as much as should about the rest of the system couldn't you , , if you if you did first pass what , , capability we have at the moment for doing second passes on , , some little small lattice , or graph , or confusion network , . but if you did first pass with , , the with either without the mean sub subtraction or with very short time one , and then , , once you , , actually had the whole utterance in , if you did , , the , , longer time version then , based on everything that you had , , and then at that point only used it to distinguish between , , top , , possible utterances , you might it might not take very much time . the large vocabulary stu , systems , people were evaluating on in the past , some people really pushed everything in to make it in one pass but other people didn't and had multiple passes . the argument , , against multiple passes was has often been "" but we want to this to be have interactive response "" . and the counterargument to that which , say , , bbn had , was "" , but our second responses are second , , passes and third passes are really , really fast "" . so , , if your second pass takes millisecond who cares ?
E: the idea of the second pass would be waiting till you have more recorded speech ?
C: so if it turned out to be problem , that you didn't have enough speech because you need longer window to do this processing , then , , one tactic is , looking at the larger system and not just at the front - end is to take in , , the speech with some simpler mechanism or shorter time mechanism , do the best you can , and come up with some al possible alternates of what might have been said . and , , either in the form of an - best list or in the form of lattice , or confusion network , or whatever . and then the decoding of that is much , much faster or can be much , much faster if it isn't big bushy network . and you can decode that now with speech that you 've actually processed using this longer time , , subtraction . so , it 's it 's common that people do this thing where they do more things that are more complex or require looking over more time , whatever , in some second pass . , if the second pass is really , really fast , another one 've heard of is in connected digit , , going back and and through backtrace and finding regions that are considered to be digit , but , , which have very low energy . so , , there 's lots of things you can do in second passes , sorts of levels . anyway , 'm throwing too many things out .
A: so is that , that it ?
E: that 's it .
A: do you wanna go , sunil ?
B: the last two weeks was , like so 've been working on that wiener filtering . found that , , single like , do normal wiener filtering , like the standard method of wiener filtering . and that doesn't actually give me any improvement over like , it actually improves over the baseline but it 's not like it doesn't meet something like fifty percent . so , 've been playing with the
A: improves over the base line mfcc system ?
B: so that 's the improvement is somewhere around , like , thirty percent over the baseline .
C: is that using in combination with something else ?
B: just one stage wiener filter which is standard wiener filter .
C: no , no , but in combination with our on - line normalization or with the lda ?
B: so plug in the wiener filtering . in the in our system , where so , di di
C: so , does it does that mean it gets worse ?
B: it actually improves over the baseline of not having wiener filter in the whole system . like have an lda lda plus on - line normalization , and then plug in the wiener filter in that , so it improves over not having the wiener filter . but it doesn't take it like be beyond like thirty percent over the baseline .
C: but that 's what 'm confused about , cuz that our system was more like forty percent without the wiener filtering .
B: it 's like , ,
A: is this with the new vad ?
B: no , it 's the old vad . so my baseline was , , nine this is like the baseline is ninety - five point six eight , and eighty - nine , and
C: so , if you can do all these in word errors it 's lot lot easier actually .
B: what was that ?
C: if you do all these in word error rates it 's lot easier , right ?
B: errors , right , don't have .
C: cuz then you can figure out the percentages .
B: it 's all accuracies .
D: the baseline is something similar to the the baseline that you are talking about is the mfcc baseline , right ?
B: there are two baselines . so the baseline one baseline is mfcc baseline that when said thirty percent improvement it 's like mfcc baseline .
C: so what 's it start on ? the mfcc baseline is what ? is at what level ?
B: it 's just the mel frequency and that 's it .
C: no , what 's what 's the number ?
B: so don't have that number here . have it here . it 's the vad plus the baseline actually . 'm talking about the mfcc plus do frame dropping on it . so that 's like the word error rate is like four point three . like ten point seven .
C: four point three . what 's ten point seven ?
B: it 's medium misma there 's ma matched , medium mismatched , and high matched . so don't have the like the
C: four point three , ten point seven ,
B: forty percent is the high mismatch . and that becomes like four point three it 's like ten point one . still the same . and the high mismatch is like eighteen point five .
C: eighteen point five . and what were you just describing ?
B: the one is this one is just the baseline plus the , , wiener filter plugged into it .
C: but where 's the , , on - line normalization and so on ?
B: so , with the with the on - line normalization , the performance was , , ten so it 's like four point three . that 's the ba the ten point , , four and twenty point one . that was with on - line normalization and lda . so the matched has like literally not changed by adding on - line or lda on it . even the medium mismatch is the same . and the high mismatch was improved by twenty percent absolute .
C: an and what are we talking about here ?
B: it 's the it - it 's italian .
C: is this ti - digits
B: 'm talking about italian ,
C: so , what was the , , , corresponding number , say , for , , , the alcatel system ?
D: so it looks to be ,
B: you have it ?
D: it 's three point four , eight point , , seven , and , , thirteen point seven .
B: this is the single stage wiener filter , with the noise estimation was based on first ten frames . actually started with using the vad to estimate the noise and then found that it works it doesn't work for finnish and spanish because the vad endpoints are not good to estimate the noise because it cuts into the speech sometimes , so end up overestimating the noise and getting worse result . so it works only for italian by for using vad to estimate noise . it works for italian because the vad was trained on italian . so this was , and so this was giving this was like not improving lot on this baseline of not having the wiener filter on it . ran this with one more stage of wiener filtering on it but the second time , what did was estimated the new wiener filter based on the cleaned up speech , and did , , smoothing in the frequency to reduce the variance have 've observed there are , like , lot of bumps in the frequency when do this wiener filtering which is more like musical noise . and so by adding another stage of wiener filtering , the results on the speechdat - car was like , so , still don't have the word error rate . 'm about it . but the overall improvement was like fifty - six point four six . this was again using ten frames of noise estimate and two stage of wiener filtering . and the rest is like the lda plu and the on - line normalization all remaining the same . so this was , like , compared to , fifty - seven is what you got by using the french telecom system ,
D: no , don't . is it on italian ?
B: this is over the whole speechdat - car .
D: , fifty - seven
B: so the new the new wiener filtering schema is like some fifty - six point four six which is like one percent still less than what you got using the french telecom system .
C: but it 's pretty similar number in any event .
B: it 's very similar .
C: but again , you 're you 're more or less doing what they were doing ,
B: it 's it 's different in sense like 'm actually cleaning up the cleaned up spectrum which they 're not doing . they 're what they 're doing is , they have two stage stages of estimating the wiener filter , but the final filter , what they do is they take it to their time domain by doing an inverse fourier transform . and they filter the original signal using that fil filter , which is like final filter is acting on the input noisy speech rather than on the cleaned up . so this is more like 'm doing wiener filter twice , but the only thing is that the second time 'm actually smoothing the filter and then cleaning up the cleaned up spectrum first level . and so that 's that 's what the difference is . and actually tried it on the original clean , the original spectrum where , like , the second time estimate the filter but actually clean up the noisy speech rather the first output of the first stage and that doesn't seems to be giving , , that much improvement . didn't run it for the whole case . and what what tried was , by using the same thing so we actually found that the vad is very , like , crucial . just by changing the vad itself gives you the lot of improvement by instead of using the current vad , if you just take up the vad output from the channel zero , when instead of using channel zero and channel one , because that was the that was the reason why was not getting lot of improvement for estimating the noise . so used the channel zero vad to estimate the noise so that it gives me some reliable mar markers for this noise estimation .
C: what 's channel zero vad ? 'm 'm confused about that .
B: so , it 's like
D: so it 's the close - talking microphone .
B: the close - talking without so because the channel zero and channel one are like the same speech , but only , the same endpoints . but the only thing is that the speech is very noisy for channel one , so you can actually use the output of the channel zero for channel one for the vad . that 's like cheating method .
C: so are they going to pro what are they doing to do , do we know yet ? about as far as what they 're what the rules are going to be and what we can use ?
D: so actually received new document , describing this . and what they did finally is to , mmm , , not to align the utterances but to perform recognition , only on the close - talking microphone ,
B: which is the channel zero .
D: and to take the result of the recognition to get the boundaries , of speech .
C: so it 's not like that 's being done in one place or one time . that 's that 's just rule and we 'd you were permitted to do that . is is that it ?
D: they will send , , files but we don't ,
C: so they will send files so everybody will have the same boundaries to work with ?
B: but actually their alignment actually is not seems to be improving in like on all cases .
D: so what happened here is that , , the overall improvement that they have with this method so , to be more precise , what they have is , they have these alignments and then they drop the beginning silence and the end silence but they keep , , two hundred milliseconds before speech and two hundred after speech . and they keep the speech pauses also . and the overall improvement over the mfcc baseline so , when they just , , add this frame dropping in addition it 's , forty percent , right ? fourteen percent , . which is the overall improvement . but in some cases it doesn't improve . like , , do you remember which case ?
B: it gives like negative , in like some italian and ti - digits ,
D: some @ @ .
B: so by using the endpointed speech , actually it 's worse than the baseline in some instances , which could be due to the word pattern .
D: and , the other thing also is that fourteen percent is less than what you obtain using real vad . so with without cheating like this . so this shows that there is still work , working on the vad is still important .
A: can ask just high level question ? can you just say like one or two sentences about wiener filtering and why are people doing that ? what 's what 's the deal with that ?
B: the wiener filter , it 's it 's like you try to minimize so the basic principle of wiener filter is like you try to minimize the , , , difference between the noisy signal and the clean signal if you have two channels . like let 's say you have clean signal and you have an additional channel where what is the noisy signal . and then you try to minimize the error between these two . so that 's the basic principle . you can do that if you have only noisy signal , at level which you , you try to estimate the noise from the assuming that the first few frames are noise or if you have voice activity detector , , you estimate the noise spectrum .
A: do you assume the noise is the same ?
B: in , after the speech starts . but that 's not the case in , , many of our cases but it works reasonably . and and then you what you do is you , write down some of these eq and then you do this this is the transfer function of the wiener filter , so "" sf "" is clean speech spectrum , power spectrum and "" "" is the noisy power spectrum . and so this is the transfer function . and then you multiply your noisy power spectrum with this . you get an estimate of the clean power spectrum . but that you have to estimate the sf from the noisy spectrum , what you have . so you estimate the nf from the initial noise portions and then you subtract that from the current noisy spectrum to get an estimate of the sf . so sometimes that becomes zero because you do you don't have true estimate of the noise . so the filter will have like sometimes zeros in it because some frequency values will be zeroed out because of that . and that creates lot of discontinuities across the spectrum because @ @ the filter . so that 's what that was just the first stage of wiener filtering that tried .
A: so is this , , , similar to just regular spectral subtraction ?
C: it 's all pretty related , it 's it 's there 's di there 's whole class of techniques where you try in some sense to minimize the noise . and it 's typically mean square sense , , in in some way . and , , spectral subtraction is , , one approach to it .
A: do people use the wiener filtering in combination with the spectral subtraction typically , or is are they competing techniques ?
B: they are very similar techniques . so it 's like haven't seen anybody using wiener filter with spectral subtraction .
C: in the long run you 're doing the same thing but but there you make different approximations , and in spectral subtraction , , there 's an estimation factor . you sometimes will figure out what the noise is and you 'll multiply that noise spectrum times some constant and subtract that even though this really should be in the power domain , sometimes people work in the magnitude domain because it it works better . and , , .
A: so why did you choose , , wiener filtering over some other one of these other techniques ?
B: the reason was , like , we had this choice of using spectral subtraction , wiener filtering , and there was one more thing which 'm trying , is this sub space approach . stephane is working on spectral subtraction .
A: so you 're trying @ @ them all .
B: we just wanted to have few noise production compensation techniques and then pick some from that
C: , there 's car - carmen 's working on another , on the vector taylor series .
B: va , vad .
C: so they were just trying to cover bunch of different things with this task and see , , what are what are the issues for each of them .
A: that makes sense .
B: so one of one of the things that tried , like said , was to remove those zeros in the fri filter by doing some smoothing of the filter . like , you estimate the edge of square and then you do smoothing across the frequency so that those zeros get , like , flattened out . and that doesn't seems to be improving by trying it on the first time . so what did was like did this and then you plugged in the one more the same thing but with the smoothed filter the second time . and that seems to be working . so that 's where got like fifty - six point five percent improvement on speechdat - car with that . so the other thing what tried was used still the ten frames of noise estimate but used this channel zero vad to drop the frames . so 'm not still not estimating . and that has taken the performance to like sixty - seven percent in speechdat - car , which is which like shows that by using proper vad you can just take it to further , better levels .
A: so that 's like , , best - case performance ?
B: so far 've seen sixty - seven haven't seen like sixty - seven percent . using the channel zero vad to estimate the noise also seems to be improving but don't have the results for all the cases with that . so used channel zero vad to estimate noise as lesser 2 frame , which is like , everywhere use the channel zero vad . and that seems to be the best combination , , rather than using few frames to estimate and then drop channel .
C: so 'm 'm still little confused . is that channel zero information going to be accessible during this test .
B: this is just to test whether we can really improve by using better vad . so this is like the noise compensation is fixed but you make better decision on the endpoints . that 's , like seems to be so , which means , like , by using this technique what we improve just the vad we can just take the performance by another ten percent or better . so , that was just the , , reason for doing that experiment . but this all these things , have to still try it on the ti - digits , which is like 'm just running . and there seems to be not improving lot on the ti - digits , so 'm like investigating that , why it 's not . so the other the other thing is like 've been 'm doing all this on the power spectrum . tried this on the mel as mel and the magnitude , and mel magnitude , and all those things . but it seems to be the power spectrum seems to be getting the best result . so , one of one of reasons like doing the averaging , after the filtering using the mel filter bank , that seems to be maybe helping rather than trying it on the mel filter ba filtered outputs . th that 's that 's the only thing that could think of why it 's giving improvement on the mel . so that 's it .
C: how about the subspace ?
B: subspace , 'm 'm like that 's still in little bit in the back burner because 've been putting lot effort on this to make it work , on tuning things and other . was like going parallely but not much of improvement . 'm just have some skeletons ready , need some more time for it .
A: tha - that it ? do you wanna go , stephane ?
D: so , 've been , , working still on the spectral subtraction . so to to remind you little bit of what did before , is just to apply some spectral subtraction with an overestimation factor also to get , , an estimate of the noise , , spectrum , and subtract this estimation of the noise spectrum from the , , signal spectrum , but subtracting more when the snr is , , low , which is technique that it 's often used .
A: "" subtracting more "" , meaning ?
D: so you overestimate the noise spectrum . you multiply the noise spectrum by factor , , which depends on the snr . so , above twenty db , it 's one , so you just subtract the noise . and then it 's generally , use , actually , linear , , function of the snr , which is bounded to , like , two or three , when the snr is below zero db . doing just this , , either on the fft bins or on the mel bands , , doesn't yield any improvement
C: , what are you doing with negative , , powers ?
D: so there is also threshold , , because after subtraction you can have negative energies , so what do is to put , to add to put the threshold first and then to add small amount of noise , which right now is speech - shaped .
A: speech - shaped ?
D: so it 's it has the overall energy , it has the overall power spectrum of speech . so with bump around one kilohertz .
A: so when when you talk about there being something less than zero after subtracting the noise , is that at particular frequency bin ?
D: there can be frequency bins with negative values .
A: and so when you say you 're adding something that has the overall shape of speech , is that in in particular frequency bin ? or you 're adding something across all the frequencies when you get these negatives ?
D: for each frequencies 'm adding some , , noise , but the the amount of the amount of noise add is not the same for all the frequency bins . right now don't it makes sense to add something that 's speech - shaped , because then you have silence portion that have some spectra similar to the sp the overall speech spectra . so this is something still work on ,
A: so what does that mean ? 'm trying to understand what it means when you do the spectral subtraction and you get negative . it means that at that particular frequency range you subtracted more energy than there was actually
D: so so , you have an estimation of the noise spectrum , but sometimes , , it 's as the noise is not perfectly stationary , sometimes this estimation can be , , too small , so you don't subtract enough . but sometimes it can be too large also . if if the noise , , energy in this particular frequency band drops for some reason .
A: so in an ideal word world if the noise were always the same , then , when you subtracted it the worst that you would get would be zero . the lowest you would get would be zero , cuz if there was no other energy there you 're just subtracting exactly the noise .
C: there 's all there 's all sorts of , , deviations from the ideal here . , you 're you 're talking about the signal and noise , , at particular point . and even if something is stationary in ster terms of statistics , there 's no guarantee that any particular instantiation or piece of it is exactly particular number or bounded by particular range . so , you 're figuring out from some chunk of of the signal what you think the noise is . then you 're subtracting that from another chunk , and there 's no reason to think that you 'd know that it wouldn't , , be negative in some places . on the other hand that just means that in some sense you 've made mistake because you certainly have stra subtracted bigger number than is due to the noise . also , we speak the whole where all this comes from is from an assumption that signal and noise are uncorrelated . and that certainly makes sense in in statistical interpretation , that , , over , , all possible realizations that they 're uncorrelated or assuming , , ergodicity that , across time , , it 's uncorrelated . but if you just look at quarter second , , and you cross - multiply the two things , , you could very , , end up with something that sums to something that 's not zero . so , the two signals could have some relation to one another . and so there 's all sorts of deviations from ideal in this . and and given all that , you could definitely end up with something that 's negative . but if down the road you 're making use of something as if it is power spectrum , , then it can be bad to have something negative . now , the other thing wonder about actually is , what if you left it negative ?
B: is that the log ?
C: are you taking the log before you add them up to the mel ? so , wonder how if you put your thresholds after that , wonder how often you would end up with , with negative values .
B: but you end up reducing some neighboring frequency bins @ @ in the average , right ? when you add the negative to the positive value which is the true estimate .
C: but nonetheless , , , these are it 's another smoothing , right ? that you 're doing . so , you 've done your best shot at figuring out what the noise should be , and now then you 've subtracted it off . and then after that , instead of instead of , , leaving it as is and adding things adding up some neighbors , you artificially push it up . which is , , it 's there 's no particular reason that 's the right thing to do either , what you 'd be doing is saying , "" , we 're we 're we 're going to definitely diminish the effect of this frequency in this little frequency bin in the in the overall mel summation "" . it 's just thought . if it would be
A: the opposite of that would be if you find out you 're going to get negative number , you don't do the subtraction for that bin .
B: that is true .
A: that would be almost the opposite , instead of leaving it negative , you don't do it . if your if your subtraction 's going to result in negative number , you don't do subtraction in that .
C: but that means that in situation where you thought that the bin was almost entirely noise , you left it .
A: 'm just saying that 's like the opposite .
C: that 's that 's the opposite ,
D: some people also if it 's negative value they , , re - compute it using inter interpolation from the edges and bins .
B: for frames , frequency bins .
D: there are different things that you can do .
C: people can also , , reflect it back up and essentially do full wave rectification instead of instead of half wave . but it was just thought that it might be something to try .
D: actually tried , something else based on this , , is to put some smoothing , because it seems to help or it seems to help the wiener filtering so what did is , , some nonlinear smoothing . actually have recursion that computes let me go back little bit . actually , when you do spectral subtraction you can , , find this equivalent in the in the spectral domain . you can compute , you can say that your spectral subtraction is filter , and the gain of this filter is the , , signal energy minus what you subtract , divided by the signal energy . and this is gain that varies over time , and , , , , depending on the on the noise spectrum and on the speech spectrum . what happen actually is that during low snr values , the gain is close to zero but it varies lot . and this is the of musical noise and all these the fact you we go below zero one frame and then you can have an energy that 's above zero . so the smoothing is did smoothing actually on this gain , , trajectory . but it 's the smoothing is nonlinear in the sense that tried to not smooth if the gain is high , because in this case we know that , , the estimate of the gain is correct because we are not close to to zero , and to do more smoothing if the gain is low . that 's this idea , and it seems to give pretty good results , although 've just tested on italian and finnish . and on italian it seems my result seems to be little bit better than the wiener filtering ,
B: the one you showed yesterday .
D: if you have these improvement the detailed improvements for italian , finnish , and spanish there
B: no , don't have , for each ,
D: or you have just have your own .
B: have the final number here .
C: so these numbers he was giving before with the four point three , and the ten point one , and , those were italian , right ?
B: so so , no , actually didn't give you the number which is the final one , which is , after two stages of wiener filtering . that was , like the overall improvement is like fifty - six point five . his number is still better than what got in the two stages of wiener filtering .
D: but on finnish it 's little bit worse , .
C: but do you have numbers in terms of word error rates on italian ? so just so you have some sense of reference ?
D: so , it 's , , three point , , eight . and then , , , nine point , , one . and finally , , sixteen point five .
C: and this is , , spectral subtraction plus what ?
D: plus plus nonlinear smoothing . it 's the system it 's exactly the sys the same system as sunil tried ,
C: on - line normalization and lda ?
D: but instead of double stage wiener filtering , it 's it 's this smoothed spectral subtraction .
A: what is it the , , france telecom system uses for do they use spectral subtraction , or wiener filtering ,
B: they use spectral subtraction ,
D: it it 's wiener filtering ,
B: it 's it 's wiener filtering .
D: it 's some wiener filtering
B: it 's not exactly wiener filtering but some variant of wiener filtering .
C: plus , , they have some cepstral normalization , as .
B: th the just noise compensation technique is variant of wiener filtering , plus they do some smoothing techniques on the final filter . the th they actually do the filtering in the time domain . so they would take this hf squared back , taking inverse fourier transform . and they convolve the time domain signal with that . and they do some smoothing on that final filter , impulse response .
D: but they also have two different smoothing @ @ .
B: 'm 'm @ @ .
D: one in the time domain and one in the frequency domain by just taking the first , , coefficients of the impulse response . so , it 's similar . what you did , it 's similar
B: it 's similar in the smoothing
D: because you have also two smoothing . one in the time domain , and one in the frequency domain ,
B: the frequency domain .
A: does the smoothing in the time domain help do you get this musical noise with wiener filtering or is that only with , , spectral subtraction ?
B: no , you get it with wiener filtering also .
A: does the smoothing in the time domain help with that ? or some other smoothing ?
B: you still end up with zeros in the spectrum .
C: it 's not clear that these musical noises hurt us in recognition . we if they do . they sound bad . but we 're not listening to it , usually .
D: actually the smoothing that did do here reduced the musical noise . not you cannot hear beca actually what did not say is that this is not in the fft bins . this is in the mel frequency bands . it could be seen as smoothing in the frequency domain because used , in ad mel bands in addition and then the other phase of smoothing in the time domain . but , when you look at the spectrogram , if you don't have an any smoothing , you clearly see , like in silence portions , and at the beginning and end of speech , you see spots of high energy randomly distributed over the spectrogram .
A: that 's the musical noise ?
D: which is musical noise , if it if you listen to it if you do this in the fft bins , then you have spots of energy randomly distributing . and if you if you re - synthesize these spot sounds as , like , sounds ,
C: none of these systems , , have , you both are working with , , our system that does not have the neural net , so one would hope , presumably , that the neural net part of it would improve things further as they did before .
D: although if we , , look at the result from the proposals , one of the reason , , the system with the neural net was , , more than , around five percent better , is that it was much better on highly mismatched condition . 'm thinking , , on the ti - digits trained on clean speech and tested on noisy speech . for this case , the system with the neural net was much better . but not much on the in the other cases . if we have no , , spectral subtraction or wiener filtering , , the system is , we thought the neural network is much better than before , even in these cases of high mismatch . so , maybe the neural net will help less
A: could you train neural net to do spectral subtraction ?
C: it could do nonlinear spectral subtraction you have to figure out what your targets are .
A: was thinking if you had clean version of the signal and noisy version , and your targets were the - , , whatever , frequency bins
C: , that 's not so much spectral subtraction then , but but it 's but at any rate , , people ,
A: people do that ?
C: we had visitors here who did that when you were here ba way back when . people done lots of experimentation over the years with training neural nets . and it 's not bad thing to do . it 's another approach . it 's it , the objection everyone always raises , which has some truth to it is that , , it 's good for mapping from particular noise to clean but then you get different noise . and the experiments we saw that visitors did here showed that it there was at least some , , gentleness to the degradation when you switched to different noises . it did seem to help . so that you 're right , that 's another way to go .
A: how did it compare on , for good cases where it , that it was trained on ? did it do pretty ?
C: it did very . but to some extent that 's what we 're doing . we 're not doing exactly that , we 're not trying to generate good examples but by trying to do the best classifier you possibly can , for these little phonetic categories ,
A: you could say it 's built in .
C: it 's built into that . and and that 's why we have found that it does help . , we 'll just have to try it . but would would imagine that it will help some . it we 'll just have to see whether it helps more or less the same , but would imagine it would help some . so in any event , all of this was just confirming th of this was with simpler system .
D: so this is th the , actually , this was the first try with this spectral subtraction plus smoothing , and was excited by the result . then started to optimize the different parameters . the first thing tried to optimize is the , , time constant of the smoothing . and it seems that the one that chose for the first experiment was the optimal one ,
C: it 's amazing how often that happens .
D: so this is the first thing . another thing that it 's important to mention is , , that this has this has some additional latency . because when do the smoothing , , it 's recursion that estimated the means , so of the of the gain curve . this is filter that has some latency . and noticed that it 's better if we take into account this latency . so , instead of using the current estimated mean to , , subtract the current frame , it 's better to use an estimate that 's some somewhere in the future .
A: and that 's what causes the latency ?
B: you mean , the the mean is computed based on some frames in the future also ? or or no ?
D: it 's the recursion , so it 's it 's the center recursion , and the latency of this recursion is around fifty milliseconds .
B: why is that delay coming ? like , you estimate the mean ?
D: the mean estimation has some delay , the filter that estimates the mean has time constant .
B: so it 's like it looks into the future also .
C: what if you just look into the past ?
D: it 's , , not as good . it 's not bad .
C: how by how much ?
D: it helps lot over the ba the baseline
C: by how much ?
D: it 's around three percent , , relative .
C: it 's depending on how all this comes out we may or may not be able to add any latency .
D: so , , it depends . actually , it 's it 's it 's three percent . but don't think we have to worry too much on that right now while you kno .
C: , the only thing is that would worry about it little . because if we completely ignore latency , and then we discover that we really have to do something about it , we 're going to be find ourselves in bind . maybe you could make it twenty - five . just , , just be little conservative because we may end up with this crunch where all of sudden we have to cut the latency in half .
D: there are other things in the , , algorithm that didn't , , @ @ lot yet ,
A: quick question just about the latency thing . if if there 's another part of the system that causes latency of hundred milliseconds , is this an additive thing ? or or is yours hidden in that ?
D: it 's it 's added .
A: it 's additive .
B: we can do something in parallel also , in some like some cases like , if you wanted to do voice activity detection . and we can do that in parallel with some other filtering you can do . so you can make decision on that voice activity detection and then you decide whether you want to filter or not . but by then you already have the sufficient samples to do the filtering . so , sometimes you can do it anyway .
A: couldn't you just also , if that the the largest latency in the system is two hundred milliseconds , don't you couldn't you just buffer up that number of frames and then everything uses that buffer ? and that way it 's not additive ?
C: , everything is sent over in buffers cuz of isn't it the tcp buffer some ?
B: you mean , the data , the super frame ? but that has variable latency because the last frame doesn't have any latency and first frame has twenty framed latency . so you can't rely on that latency all the time . the transmission over the air interface is like buffer . twenty four frames . but the only thing is that the first frame in that twenty - four frame buffer has twenty - four frame latency . and the last frame doesn't have any latency . because it just goes as
A: wasn't thinking of that one in particular but more of , , if there is some part of your system that has to buffer twenty frames , , can't the other parts of the system draw out of that buffer and therefore not add to the latency ?
C: and and that 's one of the all of that is things that they 're debating in their standards committee .
D: there is , these parameters that still have to look at . like , played little bit with this overestimation factor , but still have to look more at this , at the level of noise add after . , know that adding noise helped , , the system just using spectral subtraction without smoothing , but right now if it 's still important or not , and if the level choose before is still the right one . same thing for the shape of the noise . maybe it would be better to add just white noise instead of speech shaped noise .
C: that 'd be more like the jrasta thing in sense .
D: and another thing is to for this use as noise estimate the mean , , spectrum of the first twenty frames of each utterance . don't remember for this experiment what did you use for these two stage
B: used ten just ten frames .
D: the ten frames ?
B: the reason was like in ti - digits don't have lot . had twenty frames most of the time .
D: but , so what 's this result you told me about , the fact that if you use more than ten frames you can improve by
B: that 's that 's using the channel zero . if use channel zero vad to estimate the noise .
D: but this is ten frames plus
B: channel zero dropping .
D: these results with two stage wiener filtering is ten frames but possibly more . if channel one vad gives you but in this experiment did didn't use any vad . used the twenty first frame to estimate the noise . and so expected it to be little bit better , if , , use more frames . that 's it for spectral subtraction . the second thing was working on is to , , try to look at noise estimation , mmm , and using some technique that doesn't need voice activity detection . and for this simply used some code that , , had from belgium , which is technique that , , takes bunch of frame , and for each frequency bands of this frame , takes look at the minima of the energy . and then average these minima and take this as an energy estimate of the noise for this particular frequency band . and there is something more to this actually . what is done is that , , these minima are computed , , based on , , high resolution spectra . so , compute an fft based on the long , , signal frame which is sixty - four millisecond
A: so you have one minimum for each frequency ?
D: what what , do actually , is to take bunch of to take tile on the spectrogram and this tile is five hundred milliseconds long and two hundred hertz wide . in this tile appears , like , the harmonics if you have voiced sound , because it 's it 's the ftt bins . and when you take the the minima of these this tile , when you don't have speech , these minima will give you some noise level estimate , if you have voiced speech , these minima will still give you some noise estimate because the minima are between the harmonics . and if you have other speech sounds then it 's not the case , but if the time frame is long enough , , like five hundred milliseconds seems to be long enough , you still have portions which , , are very close whi which minima are very close to the noise energy .
C: you said five hundred milliseconds but you said sixty - four milliseconds . which is which ?
D: sixty - four milliseconds is to compute the fft , , bins . the the fft . actually it 's better to use sixty - four milliseconds because , , if you use thirty milliseconds , then , , because of the this short windowing and at low pitch , , sounds , the harmonics are not , wha , correctly separated . so if you take these minima , it they will overestimate the noise lot .
C: so you take sixty - four millisecond ts and then you average them over five hundred ? what do you do over five hundred ?
D: so take to take bunch of these sixty - four millisecond frame to cover five hundred milliseconds , and then look for the minima , on the on the bunch of fifty frames , right ? so the interest of this is that , as with this technique you can estimate some reasonable noise spectra with only five hundred milliseconds of signal , so if the the noise varies lot , , you can track better track the noise , which is not the case if you rely on the voice activity detector . so even if there are no speech pauses , you can track the noise level . the only requirement is that you must have , in these five hundred milliseconds segment , you must have voiced sound at least . cuz this these will help you to track the noise level . so what did is just to simply replace the vad - based , , noise estimate by this estimate , first on speechdat - car only on speechdat - car actually . and it 's , , slightly worse , like one percent relative compared to the vad - based estimates . the reason why it 's not better , is that the speechdat - car noises are all stationary . there really is no need to have something that 's adaptive they are mainly stationary . but , expect maybe some improvement on ti - digits because , nnn , in this case the noises are all sometimes very variable . so have to test it .
C: but are you comparing with something 'm little confused again , when you compare it with the - based , vad - is this is this the ?
D: it 's the france - telecom - based spectra , , wiener filtering and vad . so it 's their system but just replace their noise estimate by this one .
C: you 're not doing this with our system ?
D: no , no . it 's our system but with just the wiener filtering from their system . actually , th the best system that we still have is , , our system but with their noise compensation scheme , so 'm trying to improve on this , and by replacing their noise estimate by , , something that might be better .
C: but the spectral subtraction scheme that you reported on also re requires noise estimate . couldn't you try this for that ? do you might help ?
D: because did this in parallel , and was working on one and the other . try also , mmm , the spectral subtraction .
B: so 'm also using that new noise estimate technique on this wiener filtering what 'm trying . so have , like , some experiments running , don't have the results . don't estimate the noise on the ten frames but use his estimate .
D: , also implemented sp spectral whitening idea which is in the , , ericsson proposal . the idea is just to , flatten the log , , spectrum , , and to flatten it more if the probability of silence is higher . so in this way , you can also reduce somewhat reduce the musical noise and you reduce the variability if you have different noise shapes , because the spectrum becomes more flat in the silence portions . with this , no improvement , but there are lot of parameters that we can play with actually , this could be seen as soft version of the frame dropping because , , you could just put the threshold and say that "" below the threshold , will flatten comp completely flatten the spectrum "" . and above this threshold , , keep the same spectrum . so it would be like frame dropping , because during the silence portions which are below the threshold of voice activity probability , , you would have some dummy frame which is perfectly flat spectrum . and this , , whitening is something that 's more soft because , , you whiten you just , , have function the whitening is function of the speech probability , so it 's not hard decision . so maybe it can be used together with frame dropping and when we are not about if it 's speech or silence , maybe it has something do with this .
C: it 's interesting . , , in jrasta we were essentially adding in , , white , white noise dependent on our estimate of the noise . on the overall estimate of the noise . it never occurred to us to use probability in there . you could imagine one that that made use of where the amount that you added in was , , function of the probability of it being speech or noise .
D: right now it 's constant that just depending on the noise spectrum .
C: cuz that brings in powers of classifiers that we don't really have in , , this other estimate . so it could be it could be interesting . what what point does the , , system stop recording ?
A: it 'll keep going till when they run out of disk space ,
C: it went little long ?
D: so there are with this technique there are some did something exactly the same as the ericsson proposal but , , the probability of speech is not computed the same way . and , for , for lot of things , actually good speech probability is important . like for frame dropping you improve , like you can improve from ten percent as sunil showed , if you use the channel zero speech probabilities . for this it might help , the next thing started to do is to , , try to develop better voice activity detector . for this we can maybe try to train the neural network for voice activity detection on all the data that we have , including all the speechdat - car data . and so 'm starting to obtain alignments on these databases . and the way mi do that is that use the htk system but train it only on the close - talking microphone . and then aligned obtained the viterbi alignment of the training utterances . it seems to be , actually what observed is that for italian it doesn't seem th - there seems to be problem .
B: so , it doesn't seems to help by their use of channel zero or channel one . you mean their the frame dropping , right ?
D: so , but actually the vad was trained on italian also , the the current vad that we have was trained on , , spine , right ?
B: ti - digits .
D: italian , and ti - digits with noise and and it seems to work on italian but not on the finnish and spanish data . so , maybe one reason is that finnish and spanish noise are different . actually we observed we listened to some of the utterances and sometimes for finnish there is music in the recordings and strange things , so the idea was to train all the databases and obtain an alignment to train on these databases , also to , , try different features , , as input to the vad network . we came up with bunch of features that we want to try like , , the spectral slope , the , , the degree degree of voicing with the features that , , we started to develop with carmen , , with , , the correlation between bands and different features ,
B: the energy also .
C: hans - guenter will be here next week so he 'll be interested in all of these things . and , so .
A: shall we , , do digits ? want to go ahead , morgan ?
","The ICSI Meeting Recorder Group of Berkeley met for the first time in two weeks.
Group members reported their progress in the areas of spectral subtraction , Wiener filtering and noise estimation.
They also discusses topics relating to the rules and preferences of the project they are working on , including single vs multiple passes.
A number of the group also took time to explain the basics of their approaches to the group.
There are hopes that a visitor coming for three weeks , may lead to a longer term collaboration.
The visitor works on spectral subtraction , so speaker me026 will make sure he talks to him.
Speaker mn007 agreed , at me013's suggestion , to try his noise compensation scheme in compensation with the prior work on spectral subtraction.
In implementing smoothing to the spectral subtraction , latency has been increased; while some feel this is nothing to worry about , others feel it is better to worry now , in case it turns out to be something to worry about.
Speaker me026 has been experimenting with spectral subtraction using different data window sizes.
One possible idea is to use increasing windows as more data becomes available.
Speaker mn049 has been working on Wiener filtering , and testing with just the base system provides 30% improvement.
Using a second stage of filtering led to even more improvement.
Speaker mn007 is working on spectral subtraction , still with minimal results.
Smoothing seems to help , and implementing alongside the neural net should also be positive.
He has also been working on noise estimation with an energy minima approach that does not require the voice activity detector.
"
ami_abstractive_summary,Bro017.txt,"B: is it starting now ? so what from what whatever we say from now on , it can be held against us ,
E: that 's right .
A: it 's your right to remain silent .
B: so the problem is that actually how th these held meetings are held , if they are very informal and just people are say what 's going on
E: that 's usually what we do . we just sorta go around and people say what 's going on , what 's the latest
B: so that what may be reasonable is if first make report on what 's happening in aurora in general , at least what from my perspective .
E: that would be great .
B: and and so , that carmen and stephane reported on amsterdam meeting , because it was for the first time we realized we are not friends really , but we are competitors . cuz until then it was like everything was like wonderful
E: it seemed like there were still some issues , that they were trying to decide ?
B: there is plenty of there 're plenty of issues .
E: like the voice activity detector ,
B: and what happened was that they realized that if two leading proposals , which was french telecom alcatel , and us both had voice activity detector . and said "" big surprise , we could have told you that four months ago , except we didn't because nobody else was bringing it up "" . french telecom didn't volunteer this information either , cuz we were working on mainly on voice activity detector for past several months because that 's buying us the most thing . and everybody said "" but this is not fair . we didn't know that . "" and the it 's not working on features really . you are right , if wish that you provided better end point at speech because or at least that if we could modify the recognizer , to account for these long silences , because otherwise that th that wasn't correct thing . "" and so then ev everybody else says "" we should we need to do new eval evaluation without voice activity detector , or we have to do something about it "" . and in principle we . we said "" "" . but in that case , we would like to change the the algorithm because if we are working on different data , we probably will use different set of tricks . but unfortunately nobody ever officially can somehow acknowledge that this can be done , because french telecom was saying "" no , no , now everybody has access to our code , so everybody is going to copy what we did . "" our argument was everybody ha has access to our code , and everybody always had access to our code . we never denied that . we thought that people are honest , that if you copy something and if it is protected by patent then you negotiate , , if you find our technique useful , we are very happy . but and french telecom was saying "" no , no , there is lot of little tricks which cannot be protected and you guys will take them , "" which probably is also true . , it might be that people will take th the algorithms apart and use the blocks from that . but somehow think that it wouldn't be so bad , as long as people are happy abou honest about it . and they have to be honest in the long run , because winning proposal again what will be available th is will be code . so the the people can go to code and say "" listen this is what you stole from me "" "" so let 's deal with that "" . so don't see the problem . the biggest problem is that that alcatel french telecom cl claims "" we fulfilled the conditions . we are the best . we are the standard . "" and and other people don't feel that , because they so they now decided that is the whole thing will be done on - endpointed data , essentially that somebody will endpoint the data based on clean speech , because most of this the speechdat - car has the also close speaking mike and endpoints will be provided . and we will run again still not clear if we are going to run the if we are allowed to run new algorithms , but assume so . because we would fight for that , really . at least our experience is that only endpointing mel cepstrum gets gets you twenty - one percent improvement overall and twenty - seven improvement on speechdat - car then obvious the database the the baseline will go up . and nobody can then achieve fifty percent improvement . so they that there will be twenty - five percent improvement required on bad mis badly mismatched
E: the endpointing really only helped in the noisy cases . but you still have that with the mfcc .
B: but you have the same prob mfcc has an enormous number of insertions . and so , so now they want to say "" we will require fifty percent improvement only for matched condition , and only twenty - five percent for the serial cases . "" and and they almost on that except that it wasn't hundred percent . and so last time during the meeting , brought up the issue , said "" quite frankly 'm surprised how lightly you are making these decisions because this is major decision . for two years we are fighting for fifty percent improvement and suddenly you are saying "" no we will do something less "" , but maybe we should discuss that . and everybody said "" we discussed that and you were not mee there "" and said "" lot of other people were not there because not everybody participates at these teleconferencing things . "" then they said "" no because everybody is invited . "" however , there is only ten or fifteen lines , so people can't even con participate . so they , and so they said "" , we will discuss that . "" immediately nokia raised the question and they said "" we agree this is not good to dissolve the the criterion . "" so now officially , nokia is complaining and said they are looking for support , qualcomm is saying , too "" we shouldn't abandon the fifty percent yet . we should at least try once again , one more round . "" so this is where we are . hope that hope that this is going to be adopted . next wednesday we are going to have another teleconferencing call , so we 'll see what where it goes .
E: so what about the issue of the weights on the for the different systems , the - matched , and medium - mismatched and
B: that 's what that 's very good point , because david says "" we ca we can manipulate this number by choosing the right weights anyways . "" so while you are right but but if if you put zero weight zero on mismatched condition , or highly mismatched then you are done . but weights were also deter already decided half year ago .
E: and they 're the staying the same ?
B: people will not like it . now what is happening now is that th that people try to match the criterion to solution . they have solution . now they want to make their criterion is and that this is not the right way . it may be that eventually it may ha it may have to happen . but it 's should happen at point where everybody feels comfortable that we did all what we could . and don't think we did . that this test was little bit bogus because of the data and essentially there were these arbitrary decisions made , and everything . so , so this is so this is where it is . so what we are doing at ogi now is working on our parts which we little bit neglected , like noise separation . so we are looking in ways is in which with which we can provide better initial estimate of the mel spectrum , which would be , more robust to noise , and so far not much success . we tried things which long time ago bill byrne suggested , instead of using fourier spectrum , from fourier transform , use the spectrum from lpc model . their argument there was the lpc model fits the peaks of the spectrum , so it may be naturally more robust in noise . and "" , that makes sense , "" but so far we can't get much out of it . we may try some standard techniques like spectral subtraction and
E: you haven't tried that yet ?
B: not not much . or even was thinking about looking back into these ad - hoc techniques like dennis klatt was suggesting the one way to deal with noisy speech is to add noise to everything . so . , add moderate amount of noise to all data . so that makes th any additive noise less addi less effective , because you already had the noise in and it was working at the time . it was like one of these things , , but if you think about it , it 's actually pretty ingenious . so , , just take take spectrum and and add of the constant , , to every value .
E: you 're you 're so you 're making all your training data more uniform .
B: and if then if this data becomes noisy , it it becomes eff effectively becomes less noisy . but you cannot add too much noise because then you 'll then you 're clean recognition goes down , but it 's yet to be seen how much , it 's very simple technique . yes it 's very simple technique , you just take your spectrum and use whatever is coming from fft , add constant , on onto power spectrum . or the other thing is if you have spectrum , what you can start doing , you can leave start leaving out the the parts which are low in energy and then perhaps one could try to find all - pole model to such spectrum . because all - pole model will still try to to put the continuation of the of the model into these parts where the issue set to zero . that 's what we want to try . have visitor from brno . he 's like young faculty . pretty hard - working so he so he 's looking into that . and then most of the effort is now also aimed at this trap recognition . this this is this recognition from temporal patterns .
E: what is that ?
B: you about traps !
E: the traps sound familiar , but don't
B: this is familiar like because we gave you the name , but , what it is , is that normally what you do is that you recognize speech based on shortened spectrum . essentially - lpc , mel cepstrum , , everything starts with spectral slice . so if you so , given the spectrogram you essentially are sliding the spectrogram along the frequency axis and you keep shifting this thing , and you have spectrogram . so you can say "" you can also take the time trajectory of the energy at given frequency "" , and what you get is then , that you get vector . and this vector can be assigned to some phoneme . namely you can say it will say that this vector will will describe the phoneme which is in the center of the vector . and you can try to classify based on that . and you so you classi so it 's very different vector , very different properties , we much about it , but the truth is
E: but you have many of those vectors per phoneme ,
B: so you get many decisions . and then you can start dec thinking about how to combine these decisions . exactly , that 's what , that 's what it is . because if you run this recognition , you get you still get about twenty percent error twenty percent correct . on like for the frame by frame basis , so so it 's much better than chance .
E: how wide are the frequency bands ?
B: that 's another thing . currently we start we start always with critical band spectrum . for various reasons . but the latest observation is that you you are you can get quite big advantage of using two critical bands at the same time .
A: are they adjacent ,
B: adjacent , adjacent . and the reasons there are some reasons for that . because there are some reasons could talk about , will have to tell you about things like masking experiments which yield critical bands , and also experiments with release of masking , which actually tell you that something is happening across critical bands , across bands .
E: how do you how do you convert this energy over time in particular frequency band into vector of numbers ?
B: it 's time - zero is one number , time
E: but what 's the number ? is it just the
B: it 's spectral energy , logarithmic spectral energy ,
E: it 's just the amount of energy in that band from in that time interval .
B: yes , yes . yes , yes . and that 's what that 's what 'm saying then , so this is this is starting vector . it 's just like shortened spectrum , . but now we are trying to understand what this vector actually represents , question is like "" how correlated are the elements of this vector ? "" turns out they are quite correlated , because , especially the neighboring ones , they they represent the same almost the same configuration of the vocal tract . so there 's very high correlation . so the classifiers which use the diagonal covariance matrix don't like it . so we 're thinking about de - correlating them . then the question is "" can you describe elements of this vector by gaussian distributions "" , or to what extent ? and and so on and so on . so we are learning quite lot about that . and then another issue is how many vectors we should be using , the so the minimum is one . but is the is the critical band the right dimension ? so we somehow made arbitrary decision , "" yes "" . then but then now we are thinking lot how to how to use at least the neighboring band because that seems to be happening this somehow start to believe that 's what 's happening in recognition . cuz lot of experiments point to the fact that people can split the signal into critical bands , so you can you are quite capable of processing signal in independently in individual critical bands . that 's what masking experiments tell you . but at the same time you most likely pay attention to at least neighboring bands when you are making any decisions , you compare what 's happening in this band to what 's happening to the band to the to the neighboring bands . and that 's how you make decisions . that 's why the articulatory events , which fletcher talks about , they are about two critical bands . you need at least two , . you need some relative , relative relation . absolute number doesn't tell you the right thing . you need to you need to compare it to something else , what 's happening but it 's what 's happening in the in the close neighborhood . so if you are making decision what 's happening at one kilohertz , you want to 's happening at nine hundred hertz and it and maybe at eleven hundred hertz , but you don't much care what 's happening at three kilohertz .
E: so it 's really it 's like saying that what 's happening at one kilohertz depends on what 's happening around it . it 's relative to it .
B: to some extent , it that is also true . but it 's but , th what humans are very much capable of doing is that if th if they are exactly the same thing happening in two neighboring critical bands , recognition can discard it . is what 's happening we need us another voice here . and so so if you if you if you add the noise that normally masks the the signal and you can show that in that if the if you add the noise outside the critical band , that doesn't affect the decisions you 're making about signal within critical band . unless this noise is modulated . if the noise is modulated , with the same modulation frequency as the noise in critical band , the amount of masking is less . the moment you moment you provide the noise in neighboring critical bands . so the masking curve , normally it looks like start from here , so you have no noise then you you are expanding the critical band , so the amount of maching is increasing . and when you hit certain point , which is critical band , then the amount of masking is the same . so that 's the famous experiment of fletcher , long time ago . like that 's where people started thinking "" this is interesting ! "" but , if you if you modulate the noise , the masking goes up and the moment you start hitting the another critical band , the masking goes down . so essentially that 's very clear indication that cognition can take into consideration what 's happening in the neighboring bands . but if you go too far in if you if the noise is very broad , you are not increasing much more , so if you if you are far away from the signal from the signal the frequency at which the signal is , then the even the when the noise is co - modulated it 's not helping you much . so things like this we are playing with with the hope that perhaps we could eventually use this in in real recognizer . like partially we promised to do this under the the aurora program .
E: but you probably won't have anything before the next time we have to evaluate ,
B: maybe , most likely we will not have anything which would comply with the rules .
E: latency and things .
B: latency currently chops the require significant latency amount of processing , because we any better , yet , than to use the neural net classifiers , and and traps . though the work which everybody is looking at now aims at trying to find out what to do with these vectors , so that simple gaussian classifier would be happier with it . or to what extent gaussian classifier should be unhappy that , and how to gaussian - ize the vectors , so this is what 's happening . then sunil is asked me for one month 's vacation and since he did not take any vacation for two years , had no didn't have heart to tell him no . so he 's in india .
E: is he getting married ?
B: he may be looking for girl , for don't don't ask . know that naran - when last time narayanan did that he came back engaged .
E: , 've known other friends who they go to ind - they go back home to india for month , they come back married ,
B: know , know , and then then what happened with narayanan was that he start pushing me that he needs to get phd because they wouldn't give him his wife . and she 's very pretty and he loves her and so we had to really
E: so he finally had some incentive to finish ,
B: we had had incentive because he always had this plan except he never told me . figured that that was that he he told me the day when we did very at our nist evaluations of speaker recognition , the technology , and he was involved there . we were after presentation we were driving home and he told me .
E: when he knew you were happy ,
B: so said "" , , "" so he took another three quarter of the year but he was out . so wouldn't surprise me if he has plan like that , though pratibha still needs to get out first . cuz pratibha is there year earlier . and and satya needs to get out very first because he 's he already has four years served , though one year he was getting masters .
E: when is the next evaluation ? no , for aurora ?
B: there , we about evaluation , next meeting is in june . and but like getting get together .
E: are people supposed to rerun their systems ,
B: nobody said that yet . yes , , but nobody even set up yet the date for delivering endpointed data . and this that . what would be extremely useful , if we can come to our next meeting and say "" we did get fifty percent improvement . if if you are interested we eventually can tell you how "" , but we can get fifty percent improvement . because people will will be saying it 's impossible .
E: do what the new baseline is ? if you don't have
B: twenty - two twenty - two percent better than the old baseline .
E: using your voice activity detector ?
B: but assume that it will be similar , don't don't see the reason why it shouldn't be . don't see reason why it should be worse . cuz if it is worse , then we will raise the objection , we say "" how come ? "" because if we just use our voice activity detector , which we don't claim even that it 's wonderful , it 's just like one of them . we get this improvement , how come that we don't see it on on your endpointed data ?
C: it could be even better , because the voice activity detector that choosed is something that cheating , it 's using the alignment of the speech recognition system , and only the alignment on the clean channel , and then mapped this alignment to the noisy channel .
B: and on clean speech data . david told me yesterday or harry actually he told harry from qualcomm and harry brought up the suggestion we should still go for fifty percent he says are you aware that your system does only thirty percent comparing to endpointed baselines ? so they must have run already something . and harry said "" . but we think that we didn't say the last word yet , that we have other things which we can try . "" so . so there 's lot of discussion now about this new criterion . because nokia was objecting , with qualcomm 's we supported that , we said "" yes "" . now everybody else is saying "" you guys might must be out of your mind . "" the guenter hirsch who doesn't speak for ericsson anymore because he is not with ericsson and ericsson may not may withdraw from the whole aurora activity because they have so many troubles now . ericsson 's laying off twenty percent of people .
E: where 's guenter going ?
B: guenter is already he got the job already was working on it for past two years or three years he got job at some fachschule , the technical college not too far from aachen . so it 's like professor university professor not quite university , not quite it 's not aachen university , but it 's good school and he 's happy . and he , he was hoping to work with ericsson like on like consulting basis , but right now he says it doesn't look like that anybody is even thinking about speech recognition . they think about survival . so . but this is being now discussed right now , and it 's possible that that it may get through , that we will still stick to fifty percent . but that means that nobody will probably get this im this improvement . yet , wi with the current system . which event es essentially that we should be happy with because that would mean that at least people may be forced to look into alternative solutions
C: but maybe we are not too far from fifty percent , from the new baseline . which would mean like sixty percent over the current baseline , which is
B: yes . yes . we we getting there , right .
C: we are around fifty , fifty - five .
B: is it like is how did you come up with this number ? if you improve twenty by twenty percent the the the all baselines , it 's just quick comp co computation ?
C: exactly if it 's
B: it 's about right .
C: because it de it depends on the weightings
E: how 's your documentation or whatever it what was it you guys were working on last week ?
C: finally we 've not finished with this .
D: more or less it 's finished . ma - nec to need little more time to improve the english , and maybe to fill in something some small detail , something like that , but it 's more or less ready .
C: we have document that explain big part of the experiments ,
D: necessary to include the bi the bibliography .
C: it 's not , , finished yet .
E: so have you been running some new experiments ? saw some jobs of yours running on some of the machine
C: we 've fff done some strange things like removing - zero or - one from the vector of parameters , and we noticed that - one is almost not useful . you can remove it from the vector , it doesn't hurt .
E: that has no effect ? is this in the baseline ?
C: in the proposal .
E: - , - .
B: so we were just discussing , since you mentioned that , in it driving in the car with morgan this morning , we were discussing good experiment for for beginning graduate student who wants to run lot of who wants to get lot of numbers on something which is , like , "" imagine that you will you will start putting every co any coefficient , which you are using in your vector , in some general power .
E: in some what ?
B: general pow power . like you take power of two , or take square root , . so suppose that you are working with - zer - one . so if you put it in square root , that effectively makes your model half as efficient . because your gaussian mixture model , computes the mean . but it 's the mean is an exponent of the whatever , the this gaussian function .
E: you 're compressing the range ,
B: so you 're compressing the range of this coefficient , so it 's becoming less efficient . morgan was @ @ and he was he was saying this might be the alternative way how to play with with fudge factor , just compress the whole vector . and said "" in that case why don't we just start compressing individual elements , like when because in old days we were doing when people still were doing template matching and euclidean distances , we were doing this liftering of parameters , because we observed that higher parameters were more important than lower for recognition . and the - ze - one contributes mainly slope , and it 's highly affected by frequency response of the of the recording equipment and that thing , so we were coming with all these various lifters . bell labs had he this raised cosine lifter which still is built into htk for reasons unknown to anybody , but we had exponential lifter , or triangle lifter , basic number of lifters . and . but so they may be way to fiddle with the insertions , deletions , or the giving relative modifying relative importance of the various parameters . the only problem is that there 's an infinite number of combinations and if the if you if
E: you need like some
B: you need lot of graduate students , and lot of computing power .
E: you need to have genetic algorithm , that tries random permutations of these things .
B: if you were at bell labs or shouldn't be saying this in on mike , that 's what maybe that 's what somebody would be doing . the places which have lot of computing power , so because it is really it 's it 's it 's it will be reasonable search but wonder if there isn't some way of doing this search like when we are searching say for best discriminants .
E: actually , that this wouldn't be all that bad . you compute the features once , and then these exponents are just applied to that
B: and hev everything is fixed . everything is fixed .
E: and is this something that you would adjust for training ? or only recognition ?
B: for both , you would have to do .
E: you would do it on both .
B: you have to do bo both .
E: so you 'd actually
B: because essentially you are saying "" this feature is not important "" . or less important , so that 's th that 's that 's painful one ,
E: so for each set of exponents that you would try , it would require training and recognition ?
B: but but minute . you may not need to re retrain the model . you just may may need to give less weight to mod component of the model which represents this particular feature . you don't have to retrain it .
E: instead of altering the feature vectors themselves , you modify the the gaussians in the models .
B: you just multiply . you modify the gaussian in the model , but in the in the test data you would have to put it in the power , but in training what you in training in trained model , all you would have to do is to multiply model by appropriate constant .
E: but why if you 're multi if you 're altering the model , why in the test data , why would you have to muck with the cepstral coefficients ?
B: because in test in test data you ca don't have model . you have only data . but in in tr
E: no . but you 're running your data through that same model .
B: that is true , but , so what you want to do you want to say if obs you if you observe something like stephane observes , that - one is not important , you can do two things . if you have trained recognizer , in the model , the the component which di dimension wh
E: all of the all of the mean and variances that correspond to - one , you put them to zero .
B: to the it . but what 'm proposing now , if it is important but not as important , you multiply it by point one in model .
E: but what are you multiplying ? cuz those are means ,
A: you 're multiplying the standard deviation ?
B: that you multiply the would would have to look in the in the math , how does the model
E: you 'd have to modify the standard deviation , so that you make it wider or narrower .
B: effectively , that 's that 's what you do . that 's what you do , you you modify the standard deviation as it was trained . effectively you , in in front of the of the model , you put constant . effectively what you 're doing is you is you are modifying the the deviation .
A: it 's the same mean ,
E: so by making th the standard deviation narrower , your scores get worse for unless it 's exactly right on the mean .
B: by making it narrower ,
E: there 's you 're allowing for less variance .
B: so you making this particular dimension less important . because see what you are fitting is the multidimensional gaussian , it 's it has thirty - nine dimensions , or thirteen dimensions if you ignore deltas and double - deltas . so in order if you in order to make dimension which stephane sees less important , not useful , less important , what you do is that this particular component in the model you can multiply by you can you can de - weight it in the model . but you can't do it in in test data because you don't have model for th when the test comes , but what you can do is that you put this particular component in and you compress it . that becomes th gets less variance , subsequently becomes less important .
E: couldn't you just do that to the test data and not do anything with your training data ?
B: that would be very bad , because your your model was trained expecting , that wouldn't work . because your model was trained expecting certain var variance on - one . and because the model thinks - one is important . after you train the model , you you could do you could do still what was proposing initially , that during the training you compress - one that becomes then it becomes less important in training . but if you have if you want to run ex extensive experiment without retraining the model , you don't have to retrain the model . you train it on the original vector . but after , you wh when you are doing this parametric study of importance of - one you will de - weight the - one component in the model , and you will put in the you will compress the this component in in the test data . by the same amount .
E: could you also if you wanted to if you wanted to try an experiment by leaving out say , - one , couldn't you , in your test data , modify the all of the - one values to be way outside of the normal range of the gaussian for - one that was trained in the model ? so that effectively , the - one never really contributes to the score ?
B: that would be severe mismatch ,
E: do what 'm say
B: what you are proposing ? no you don't want that . because that would then your model would be unlikely . your likelihood would be low , because you would be providing severe mismatch .
E: but what if you set if to the mean of the model , then ? and it was cons you set all - ones coming in through your test data , you change whatever value that was there to the mean that your model had .
B: no that would be very good match ,
C: , but we have several means .
B: see what you are sa saying , no , no don't think that it would be the same . no , the if you set it to mean , that would no , you can't do that . you ca ch - chuck , you can't do that .
E: that 's true ,
B: because that would be really fiddling with the data , you can't do that .
E: - . - .
B: but what you can do , 'm confident you ca 'm reasonably confident and putting it on the record , people will listen to it for centuries now , is what you can do , is you train the model with the with the original data . then you decide that you want to see how important - one is . so what you will do is that component in the model for - one , you will divide it by two . and you will compress your test data by square root . then you will still have perfect match . except that this component of - one will be half as important in in overall score . then you divide it by four and you take square , fourth root . then if you think that some component is more is more important then th it then it is , based on training , then you multiply this particular component in the model by by
E: you 're talking about the standard deviation ?
B: multiply this component it by number larger than one , and you put your data in power higher than one . then it becomes more important . in the overall score , believe .
C: but , at the
E: but don't you have to do something to the mean , also ?
C: but it 's the the variance is on the denominator in the in the gaussian equation . so . it 's maybe it 's the contrary . if you want to decrease the importance of parameter , you have to increase it 's variance .
B: so you so you may want to do it other way around ,
C: that 's right .
E: if your original data for - one had mean of two . and now you 're you 're changing that by squaring it . now your mean of your - one original data has is four . but your model still has mean of two . so even though you 've expended the range , your mean doesn't match anymore .
B: let 's see .
E: do you see what ?
C: what see what could be done is you don't change your features , which are computed once for all , but you just tune the model . so . you have your features . you train your model on these features . and then if you want to decrease the importance of - one you just take the variance of the - one component in the in the model and increase it if you want to decrease the importance of - one or decrease it
B: you would have to modify the mean in the model . you agree with you . but , but it 's it 's it 's do - able , it 's predictable .
E: it 's predictable , .
B: it 's predictable .
E: but as simple thing , you could just muck with the variance .
C: just adjust the model ,
E: to get this the effect that you 're talking about ,
B: it might be .
E: could increase the variance to decrease the importance . because if you had huge variance , you 're dividing by large number , you get very small contribution .
C: it becomes more flat
A: the sharper the variance , the more important to get that one right .
E: actually , this reminds me of something that happened when was at bbn . we were playing with putting pitch into the mandarin recognizer . and this particular pitch algorithm when it didn't think there was any voicing , was spitting out zeros . so we were getting when we did clustering , we were getting groups of features
B: pretty new outliers , interesting outliers ,
E: with mean of zero and zero variance . so , when ener when anytime any one of those vectors came in that had zero in it , we got great score . it was just , {nonvocalsound} , incredibly {nonvocalsound} high score , and so that was throwing everything off . so if you have very small variance you get really good scores when you get something that matches . so . so that 's way , that 's way to increase the , that 's interesting . so , that would be that doesn't require any retraining .
B: no . no .
C: that 's right .
E: so that means it 's just
C: just tuning the models and testing , actually . it would be quick .
E: you you have step where you modify the models , make copy of your models with whatever variance modifications you make , and rerun recognition . and then do whole bunch of those . that could be set up fairly easily , and you have whole bunch of
B: chuck is getting himself in trouble .
E: that 's an interesting idea , actually .
A: didn't you say you got these htk 's set up on the new linux boxes ?
E: that 's right . and they 're just right now they 're installing increasing the memory on that the linux box .
B: and chuck is really fishing for how to keep his computer busy ,
E: we 've got five processors on that .
B: that 's , that 's good thing
A: that 's right .
B: because then you just write the "" do "" - loops and then you pretend that you are working while you are you you can go fishing .
E: and two gigs of memory . see how many cycles we used ?
B: then you are in this mode like all of those arpa people are , since it is on the record , 't say which company it was , but it was reported to me that somebody visited company and during during discussion , there was this guy who was always hitting the carriage returns on computer . so after two hours the visitor said "" wh why are you hitting this carriage return ? "" and he said "" , we are being paid by computer ty we are we have government contract . and they pay us by amount of computer time we use . "" it was in old days when there were of pdp - eights and that thing .
E: so he had to make it look like
B: because so they had they literally had to monitor at the time at the time on computer how much time is being spent or on this particular project . nobody was looking even at what was coming out .
E: have you ever seen those little it 's it 's this thing that 's the shape of bird and it has red ball and its beak dips into the water ? so if you could hook that up so it hit the keyboard that 's an interesting experiment .
B: it would be similar to knew some people who were that was in old communist czechoslovakia , so we were watching for american airplanes , coming to spy on on us at the time , so there were three guys stationed in the middle of the woods on one lonely watching tower , spending year and half there because there was this service and so they very quickly they made friends with local girls and local people in the village and so but they there was one plane flying over always above , and so that was the only work which they had . they like four in the afternoon they had to report there was plane from prague to brno flying there , so they very first thing was that they would always run back and at four ' clock and quickly make call , "" this plane is passing "" then second thing was that they took the line from this post to local pub . and they were calling from the pub . and they but third thing which they made , and when they screwed up , they finally they had to the pub owner to make these phone calls because they didn't even bother to be there anymore . and one day there was there was no plane . at least they were smart enough that they looked if the plane is flying there , and the pub owner says "" my four ' clock , , quickly pick up the phone , call that there 's plane flying . "" there was no plane for some reason ,
E: and there wasn't ?
B: it was downed , so they got in trouble . but . but .
E: that 's that 's really that wouldn't be too difficult to try . maybe could set that up . and we 'll just
B: at least go test the test the assumption about - one to begin with . but then one can then think about some predictable result to change all of them . it 's just like we used to do these the distance measures . it might be that
E: so the first set of variance weighting vectors would be just one modifying one and leaving the others the same . and and do that for each one .
B: because you see , , what is happening here in in in such model is that it 's tells you what has low variance is is more reliable ,
E: that would be one set of experiment wh - , when the data matches that , then you get really
B: how do we know , especially when it comes to noise ?
E: but there could just naturally be low variance . because like , 've noticed in the higher cepstral coefficients , the numbers seem to get smaller ,
C: they have smaller means , also .
E: and so it seems like they 're already compressed . the range of values .
B: that 's why people used these lifters were inverse variance weighting lifters that makes euclidean distance more like mahalanobis distance with diagonal covariance when you knew wh the variances were over the old data . what they would do is that they would weight each coefficient by inverse of the variance . turns out that the variance decreases at least at fast , believe , as the index of the cepstral coefficients . you can show that analytically . so typically what happens is that you need to weight the weight the higher coefficients more than the lower coefficients . when we talked about aurora still wanted to make plea encourage for more communication between different parts of the distributed center . even when there is nothing to to say but the weather is good in ore - in berkeley . 'm that it 's being appreciated in oregon and maybe it will generate similar responses down here ,
C: we can set up webcam maybe .
B: what , nowadays , it 's actually do - able , almost .
E: if we mail to "" aurora - inhouse "" , does that go up to you guys also ?
B: so we should do that .
E: so what is it
B: we should definitely set up
E: do we have mailing list that includes the ogi people ?
C: we don't have .
E: maybe we should set that up . that would make it much easier .
B: that would make it easier .
E: so maybe just call it "" aurora "" that would
B: and then we also can send the dis to the same address and it goes to everybody
E: maybe we can set that up .
B: because what 's happening naturally in research , know , is that people essentially start working on something and they don't want to be much bothered , but what the then the danger is in group like this , is that two people are working on the same thing and both of them come with the very good solution , but it could have been done somehow in half of the effort . there 's another thing which wanted to report . lucash , , wrote the software for this aurora - two system . reasonably good one , because he 's doing it for intel , but trust that we have rights to use it or distribute it and everything . cuz intel 's intentions originally was to distribute it free of charge anyways . and so we will make that at least you can see the software and if if it is of any use . it might be reasonable point for perhaps start converging . because morgan 's point is that he is an experienced guy . he says "" it 's very difficult to collaborate if you are working with supposedly the same thing , in quotes , except which is not is not the same . which which one is using that set of hurdles , another one set is using another set of hurdles . so . and then it 's difficult to compare .
C: what about harry ? we received mail last week and you are starting to do some experiments .
B: he got the he got the software . they sent the release .
C: and use this intel version .
B: because intel paid us should say on microphone ? some amount of money , not much . not much say on microphone . much less then we should have gotten for this amount of work . and they wanted to have software so that they can also play with it , which means that it has to be in certain environment they use actu actually some intel libraries , but in the process , lucash just rewrote the whole thing because he figured rather than trying to make sense of including icsi software not for training on the nets but he rewrote the or so maybe somehow reused over the parts of the thing so that the whole thing , including mlp , trained mlp is one piece of software . is it useful ?
A: remember when we were trying to put together all the icsi software for the submission .
B: that 's what he was saying , he said that it was like it was like just so many libraries and nobody knew what was used when , and so that 's where he started and that 's where he realized that it needs to be needs to be at least cleaned up , and so it this is available .
C: the only thing would check is if he does he use intel math libraries , because if it 's the case , it 's maybe not so easy to use it on another architecture .
B: not maybe maybe not in first maybe not in first ap approximation because he started first just with plain or - plus before check on that . and in otherwise the intel libraries , they are available free of freely . but they may be running only on on windows .
C: on intel architecture maybe .
B: on intel architecture , may not run in sun . that is that is that is possible . that 's why intel is distributing it ,
C: there are at least there are optimized version for their architecture . never checked carefully these sorts of
B: know there was some issues that initially we do all the development on linux but we use we don't have we have only three suns and we have them only because they have spert board in . otherwise otherwise we almost exclusively are working with pc 's now , with intel . in that way intel succeeded with us , because they gave us too many good machines for very little money or nothing . so . so we run everything on intel .
E: does anybody have anything else ? shall we read some digits ?
B: have to take my glasses
E: hynek , if you 've ever done this . the way that it works is each person goes around in turn , and you say the transcript number and then you read the digits , the strings of numbers as individual digits . so you don't say "" eight hundred and fifty "" , you say "" eight five "" , and .
B: so can maybe can maybe start then ?
","The Meeting Recorder Group of ICSI at Berkeley met without their most senior member , but attending instead was a visitor from research partner OGI.
He reported on a recent project meeting from his group's perspective.
There was much politics involved , and disagreement between groups.
He also brought the ICSI members up to date with his group's latest work.
The ICSI group reported their most recent progress and detailed their recent findings.
Having discussed this with the ICSI project leader , the OGI member told of some future investigation they had devised , which would look at the adjusting the importance of some features.
This led to a great deal of discussion.
There were also further calls for greater communication between the groups.
ICSI currently has no mailing list which includes OGI personnel , so they will set one up.
There was disagreement at the project meeting over two group development of Voice Activity Detectors , particularly since one group makes their code available to all and the others do not.
There were also issues relating to the amount of improvement required if the baseline is improved.
OGI are looking at methods of making the initial estimations more robust to noise , though with little success.
Most of their effort is now on TRAP recognition from temporal patterns.
ICSI members have almost finished their report , and have been trying some things out which has led to the conclusion that C-1 channel is not at all useful.
"
